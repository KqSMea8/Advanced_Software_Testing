<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:22:32 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-11368/HBASE-11368.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-11368] Multi-column family BulkLoad fails if compactions go on too long</title>
                <link>https://issues.apache.org/jira/browse/HBASE-11368</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Compactions take a read lock.  If a multi-column family region, before bulk loading, we want to take a write lock on the region.  If the compaction takes too long, the bulk load fails.&lt;/p&gt;

&lt;p&gt;Various recipes include:&lt;br/&gt;
+ Making smaller regions (lame)&lt;br/&gt;
+ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=victorunique&quot; class=&quot;user-hover&quot; rel=&quot;victorunique&quot;&gt;Victor Xu&lt;/a&gt; suggests major compacting just before bulk loading over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10882&quot; title=&quot;Bulkload process hangs on regions randomly and finally throws RegionTooBusyException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10882&quot;&gt;&lt;del&gt;HBASE-10882&lt;/del&gt;&lt;/a&gt; as a work around.&lt;/p&gt;

&lt;p&gt;Does the compaction need a read lock for that long?  Does the bulk load need a full write lock when multiple column families?  Can we fail more gracefully at least?&lt;/p&gt;

&lt;p&gt;Note:  Fixed in subtask &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14575&quot; title=&quot;Relax region read lock for compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14575&quot;&gt;&lt;del&gt;HBASE-14575&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12721577">HBASE-11368</key>
            <summary>Multi-column family BulkLoad fails if compactions go on too long</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Jun 2014 03:52:45 +0000</created>
                <updated>Wed, 14 Sep 2016 19:06:17 +0000</updated>
                            <resolved>Wed, 14 Sep 2016 19:04:00 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>16</watches>
                                                                                                            <comments>
                            <comment id="14033409" author="stack" created="Tue, 17 Jun 2014 03:53:44 +0000"  >&lt;p&gt;This is an old issue, &lt;a href=&quot;http://search-hadoop.com/m/0AGoj1C1AXY/org.apache.hadoop.hbase.RegionTooBusyException%253A+failed+to+get+a+lock+in+60000ms&amp;amp;subj=Bulk+loading+HFiles+via+LoadIncrementalHFiles+fails+at+a+region+that+is+being+compacted+a+bug+&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search-hadoop.com/m/0AGoj1C1AXY/org.apache.hadoop.hbase.RegionTooBusyException%253A+failed+to+get+a+lock+in+60000ms&amp;amp;subj=Bulk+loading+HFiles+via+LoadIncrementalHFiles+fails+at+a+region+that+is+being+compacted+a+bug+&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="14163024" author="tianq" created="Wed, 8 Oct 2014 03:43:29 +0000"  >&lt;p&gt;As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; mentioned in &lt;a href=&quot;http://search-hadoop.com/m/DHED4NR0wT&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search-hadoop.com/m/DHED4NR0wT&lt;/a&gt;, the HRegion#lock is to protect region close. the comments in HRegion.java and the fact that only HRegion#doClose locks the writelock(if we do not consider HRegion#startBulkRegionOperation) also show that.&lt;/p&gt;

&lt;p&gt;so using HRegion#lock to protect multi-CF bulkload in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4552&quot; title=&quot;multi-CF bulk load is not atomic across column families&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4552&quot;&gt;&lt;del&gt;HBASE-4552&lt;/del&gt;&lt;/a&gt; looks too heavy-weight?&lt;br/&gt;
from the stacktrace of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10882&quot; title=&quot;Bulkload process hangs on regions randomly and finally throws RegionTooBusyException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10882&quot;&gt;&lt;del&gt;HBASE-10882&lt;/del&gt;&lt;/a&gt;, all the read/scan are blocked since bulkload is waiting for lock.writelock, however compaction already acquired lock.readlock and is reading data, a time-consuming operation.&lt;/p&gt;

&lt;p&gt;and related topic is discussed again in &lt;a href=&quot;http://search-hadoop.com/m/DHED4I11p31&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search-hadoop.com/m/DHED4I11p31&lt;/a&gt;. perhaps we need another region level lock.&lt;/p&gt;








</comment>
                            <comment id="14163162" author="tianq" created="Wed, 8 Oct 2014 06:42:28 +0000"  >&lt;p&gt;ideas for lowering down the lock granularity(based on 0.98.5 code base)&lt;br/&gt;
1)read/scan &lt;br/&gt;
is it the primary goal for atomic multi-CF bulkload in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4552&quot; title=&quot;multi-CF bulk load is not atomic across column families&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4552&quot;&gt;&lt;del&gt;HBASE-4552&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;After DefaultStoreFileManager#storefiles is updated in HStore#bulkLoadHFile, notifyChangedReadersObservers is called to reset the StoreScanner#heap,  so checkReseek-&amp;gt;resetScannerStack will be triggered in next scan/read to recreate store scanners based on new storefiles.&lt;/p&gt;

&lt;p&gt;so we could introduce a new region level rwlock multiCFLock,  HRegion#bulkLoadHFiles acquires the writelock before multi-CF HStore.bulkLoadHFile call. and StoreScanner#resetScannerStack acquires the readlock. this way the scanners are recreated after all CFs&apos; store files are populated.&lt;/p&gt;

&lt;p&gt;2)split region.&lt;br/&gt;
the region will be closed in SplitTransaction#stepsBeforePONR, which falls into the HRegion#lock protection area. bulk load still still need to acquire its readlock at start.&lt;/p&gt;

&lt;p&gt;3) memstore flush.&lt;br/&gt;
we flush to a new file which is not related to the loaded files.&lt;/p&gt;

&lt;p&gt;4)compaction.&lt;br/&gt;
the compaction is performed store by store. if bulkload inserts new files to &lt;tt&gt;storefiles&lt;/tt&gt; during the selectCompaction process, the file list to be compacted might be impacted. e.g., the compaction for some CF do not include new loaded files, while others might include. but this does not impact the data integrity and read behavior?&lt;br/&gt;
at the end of compaction,  &lt;tt&gt;storefiles&lt;/tt&gt; access is still protected by HStore#lock if there is bulk load change to the same CF.&lt;/p&gt;

&lt;p&gt;comments?&lt;br/&gt;
thanks&lt;/p&gt;












</comment>
                            <comment id="14163697" author="jinghe" created="Wed, 8 Oct 2014 16:24:18 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tianq&quot; class=&quot;user-hover&quot; rel=&quot;tianq&quot;&gt;Qiang Tian&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The idea may be feasible:&lt;/p&gt;

&lt;p&gt;bulk load begins:  acquire region read lock + new bulk load write lock.&lt;br/&gt;
Scan//next begins:  acquire region read lock + new bulk load read lock.&lt;br/&gt;
Other region operations:  only acquire region read lock  &lt;/p&gt;

&lt;p&gt;This will save the compaction and bulk load from blocking each other.&lt;/p&gt;

&lt;p&gt;Do you mind drafting a patch and run thru the test suite?&lt;/p&gt;
</comment>
                            <comment id="14163705" author="jinghe" created="Wed, 8 Oct 2014 16:27:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Other region operations: only acquire region read lock&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;--&amp;gt; Other region operations: only acquire region read or write lock, no change from existing behavior.&lt;/p&gt;</comment>
                            <comment id="14164957" author="tianq" created="Thu, 9 Oct 2014 09:48:06 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jinghe&quot; class=&quot;user-hover&quot; rel=&quot;jinghe&quot;&gt;Jerry He&lt;/a&gt;,&lt;br/&gt;
is it right way to run the bulkload test? &lt;tt&gt;mvn test -Dtest=TestHRegionServerBulkLoad&lt;/tt&gt;&lt;br/&gt;
the test is supposed to run for 5 minutes, but only after about 1 minutes then it exits. is it expected?&lt;/p&gt;</comment>
                            <comment id="14165411" author="jinghe" created="Thu, 9 Oct 2014 17:40:47 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  /**
   * Atomic bulk load.
   */
  @Test
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testAtomicBulkLoad() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; TABLE_NAME = &lt;span class=&quot;code-quote&quot;&gt;&quot;atomicBulkLoad&quot;&lt;/span&gt;;

    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; millisToRun = 30000;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This test case is 30 sec.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  /**
   * Run test on an HBase instance &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 5 minutes. This assumes that the table
   * under test only has a single region.
   */
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; args[]) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;main is not invoked during JUnit run.&lt;/p&gt;</comment>
                            <comment id="14166466" author="tianq" created="Fri, 10 Oct 2014 06:45:59 +0000"  >&lt;p&gt;update: &lt;br/&gt;
the idea will cause deadlock since bulkload and scanner follow different orders to acquire bulkload lock and StoreScanner.lock. will look at if we could lower the granularity of storescanner lock.&lt;/p&gt;</comment>
                            <comment id="14170644" author="tianq" created="Tue, 14 Oct 2014 08:03:47 +0000"  >&lt;p&gt;I forgot StoreScanner is per CF..earlier analysis is wrong:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After DefaultStoreFileManager#storefiles is updated in HStore#bulkLoadHFile, notifyChangedReadersObservers is called to reset the StoreScanner#heap, so checkReseek-&amp;gt;resetScannerStack will be triggered in next scan/read to recreate store scanners based on new storefiles.&lt;/p&gt;

&lt;p&gt;so we could introduce a new region level rwlock multiCFLock, HRegion#bulkLoadHFiles acquires the writelock before multi-CF HStore.bulkLoadHFile call. and StoreScanner#resetScannerStack acquires the readlock. this way the scanners are recreated after all CFs&apos; store files are populated.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;instead, the new lock should put at regionScanner layer.  see the patch attached.&lt;/p&gt;

&lt;p&gt;the &quot;mvn test&quot; and &quot;TestHRegionServerBulkLoad&quot;(large test for atomic bulkload test) passed, still need to run large tests and performance test(any suggestions for it? YCSB?).&lt;/p&gt;

&lt;p&gt;the lock can be further limited to a smaller scope by split HStore#bulkLoadHFile into 2 parts:1) rename the bulkload files and put new files into store files list 2) notifyChangedReadersObservers. only #2 needs the lock. &lt;br/&gt;
if HDFS file rename is fast, the split may not be needed.&lt;/p&gt;
</comment>
                            <comment id="14170649" author="tianq" created="Tue, 14 Oct 2014 08:09:25 +0000"  >&lt;p&gt;it looks to me the patch could show the value only when there is long compaction + gets/scans,  not sure if &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=victorunique&quot; class=&quot;user-hover&quot; rel=&quot;victorunique&quot;&gt;Victor Xu&lt;/a&gt; wants to try it in some test env?&lt;br/&gt;
thanks.&lt;/p&gt;</comment>
                            <comment id="14181168" author="tianq" created="Thu, 23 Oct 2014 09:32:55 +0000"  >&lt;p&gt;initial YCSB test:&lt;/p&gt;

&lt;p&gt;Env:&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
hadoop 2.2.0&lt;br/&gt;
YCSB 1.0.4(Andrew&apos;s branch)&lt;br/&gt;
3 nodes, 1 master, 2 RS  //ignore cluster details since just to evaluate the new lock&lt;/p&gt;

&lt;p&gt;Steps:&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
Followed Andrew&apos;s steps(see &lt;a href=&quot;http://search-hadoop.com/m/DHED4hl7pC/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search-hadoop.com/m/DHED4hl7pC/&lt;/a&gt;)&lt;br/&gt;
the seed table has 3 CFs, pre-split to 20 regions&lt;br/&gt;
load 1 million rows to CF &apos;f1&apos;, using workloada&lt;br/&gt;
run 3 iterations for workloadc and workloada respectively. the parameter in each run:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;-p columnfamily=f1 -p operationcount=1000000 -s -threads 10&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;Results:&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
0.98.5:&lt;br/&gt;
workload c:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 496.225811&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 510.206831&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 501.256123&lt;/p&gt;

&lt;p&gt;workload a:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 676.4527555821747&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 622.5544771452717&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 628.1365657163067&lt;/p&gt;


&lt;p&gt;0.98.5+patch:&lt;br/&gt;
workload c:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 536.334437&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 508.405555&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 491.416182&lt;/p&gt;


&lt;p&gt;workload a:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 640.3625218319231&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 642.9719823488798&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 631.7491770928287&lt;/p&gt;

&lt;p&gt;looks little performance penalty.&lt;/p&gt;

&lt;p&gt;I also ran PE in the cluster, since the test table has only 1 CF, the new lock is actually not used. interestingly, with the patch the performance is even a bit better...&lt;/p&gt;</comment>
                            <comment id="14182646" author="tianq" created="Fri, 24 Oct 2014 10:02:21 +0000"  >&lt;p&gt;A simple comparison test using updated TestHRegionServerBulkLoad.java the number is for just for reference. the real perf improvement might depend on a combination of factors, such as campaction time, bulkload time, scan/read workload type, request currency etc)&lt;/p&gt;


&lt;p&gt;98.5:&lt;br/&gt;
-----------&lt;br/&gt;
2014-10-24 02:30:03,399 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(345):   loaded 16&lt;br/&gt;
2014-10-24 02:30:03,399 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(346):   compations 16&lt;/p&gt;

&lt;p&gt;2014-10-24 02:30:03,399 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(348): Scanners:&lt;br/&gt;
//average # with 50 scanners&lt;br/&gt;
2014-10-24 02:30:03,399 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(350):   scanned 73&lt;br/&gt;
2014-10-24 02:30:03,400 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(351):   verified 18000 rows&lt;/p&gt;


&lt;p&gt;98.5+patch&lt;br/&gt;
--------&lt;br/&gt;
//since bulkload has smaller conflict with compaction, we get more bulkload/compaction request in fixed test cycle(5 minutes)&lt;br/&gt;
2014-10-24 02:41:19,071 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(344): Loaders:&lt;br/&gt;
2014-10-24 02:41:19,072 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(345):   loaded 43&lt;br/&gt;
2014-10-24 02:41:19,072 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(346):   compations 43&lt;/p&gt;

&lt;p&gt;2014-10-24 02:41:19,073 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(348): Scanners:&lt;br/&gt;
 //since bulkload has smaller conflict with scan, we get more scans in fixed test cycle(5 minutes)&lt;br/&gt;
//average # for 50 scanners&lt;br/&gt;
2014-10-24 02:41:19,073 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(350):   scanned 92  &lt;br/&gt;
2014-10-24 02:41:19,073 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestHRegionServerBulkLoad(351):   verified 25000 rows&lt;/p&gt;
</comment>
                            <comment id="14182647" author="tianq" created="Fri, 24 Oct 2014 10:04:16 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;,&lt;br/&gt;
any comments?&lt;br/&gt;
thanks!&lt;/p&gt;</comment>
                            <comment id="14183019" author="stack" created="Fri, 24 Oct 2014 16:37:54 +0000"  >&lt;p&gt;Is this meant to be in the patch?&lt;/p&gt;

&lt;p&gt;1449	    LOG.info(&quot;###compaction get the closelock, sleep 20s to simulate slow compaction&quot;);&lt;br/&gt;
1450	    try &lt;/p&gt;
{
1451	      Thread.sleep(20000);
1452	    }
&lt;p&gt; catch (InterruptedException e) &lt;/p&gt;
{
1453	      LOG.info(&quot;###sleep interrupted&quot;);
1454	    }

&lt;p&gt;What change did you do &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tianq&quot; class=&quot;user-hover&quot; rel=&quot;tianq&quot;&gt;Qiang Tian&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14184051" author="tianq" created="Sat, 25 Oct 2014 10:25:44 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;,&lt;br/&gt;
Sorry for confusing. let me explain from scratch:&lt;br/&gt;
1)the root cause of problem - HRegion#lock.&lt;br/&gt;
From the stacktrace in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10882&quot; title=&quot;Bulkload process hangs on regions randomly and finally throws RegionTooBusyException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10882&quot;&gt;&lt;del&gt;HBASE-10882&lt;/del&gt;&lt;/a&gt;(also see key_stacktrace_hbase10882.TXT attached),  the event sequence is: &lt;br/&gt;
1.1)the compaction acquires the readlock of HRegion#lock, &lt;br/&gt;
1.2)the bulkload try to acquire the writelock of HRegion#lock if there are multiple CFs. it has to wait for compaction to release the readlock.&lt;br/&gt;
1.3)scanners try to acquire the readlock of HRegion#lock. they have to wait for the bulkload to release the writelock.&lt;br/&gt;
so both bulkload and scanners are blocked on HRegion#lock by compaction.&lt;/p&gt;

&lt;p&gt;2)what is HRegion#lock used for?&lt;br/&gt;
Investigation on the HRegion#lock shows, it is originally designed to protect region close ONLY. if someone, such as region split, wants to close the region, it needs to wait for others release the readlock.  &lt;br/&gt;
Then &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4552&quot; title=&quot;multi-CF bulk load is not atomic across column families&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4552&quot;&gt;&lt;del&gt;HBASE-4552&lt;/del&gt;&lt;/a&gt; used the lock to solve the multi-CF bulkload consistency issue. now we see it is too heavy.&lt;/p&gt;

&lt;p&gt;3)can we not use HRegion#lock in bulkload?&lt;br/&gt;
the answer is yes. &lt;br/&gt;
Internally, HStore#DefaultStoreFileManager#storefiles keeps track of the on-disk HFiles for a CF. we have below steps for the bulkload:&lt;br/&gt;
3.1)moves HFiles directly to region directory&lt;br/&gt;
3.2)add them into the &lt;tt&gt;storefiles&lt;/tt&gt; list&lt;br/&gt;
3.3)notify StoreScanner that the HFile list is changed, which is done by resetting the StoreScanner#heap to null. this forces existing StoreScanner instances to reinitialize based on new the HFiles seen on disk in next scan/read request.&lt;br/&gt;
the step 3.2 and 3.3 is synchronized by HStore#lock. so we have CF level scan-bulkload consistency.&lt;/p&gt;

&lt;p&gt;To achieve multi-CF scan-bulkload consistency, if we do not use HRegion#lock, we still need another region level lock &amp;#8212; a RegionScanner is composed of multiple StoreScanner, a StoreScanner(a CF scanner) is composed of a MemStoreScanner and multiple StoreFileScanner.&lt;/p&gt;

&lt;p&gt;the RegionScannerImpl#sortheap(and joinedHeap) is just the entry point of multiple StoreScanners. to have multi-CF consistency, we need synchronization here - a lock is needed, but it is used only between scan and bulkload.&lt;/p&gt;



&lt;p&gt;Regarding the code change you referenced, performance_improvement_verification_98.5.patch is to simulate the event sequence described in #1, for testing purpose only.&lt;/p&gt;

&lt;p&gt;currently I use 98.5 for test since it is stable and easy to evaluate the effect of the change.&lt;br/&gt;
thanks.&lt;/p&gt;






</comment>
                            <comment id="14184066" author="tianq" created="Sat, 25 Oct 2014 11:40:52 +0000"  >&lt;p&gt;the attachments:&lt;br/&gt;
&lt;tt&gt;key_stacktrace_hbase10882.TXT&lt;/tt&gt; : the problem stacktrace&lt;br/&gt;
&lt;tt&gt;hbase-11368-0.98.5.patch&lt;/tt&gt; : the fix&lt;br/&gt;
&lt;tt&gt;performance_improvement_verification_98.5.patch&lt;/tt&gt;: the testcase to verify performance improvement&lt;/p&gt;

</comment>
                            <comment id="14186476" author="tianq" created="Tue, 28 Oct 2014 06:47:51 +0000"  >&lt;p&gt;patch for master branch&lt;/p&gt;</comment>
                            <comment id="14186581" author="hadoopqa" created="Tue, 28 Oct 2014 08:36:02 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12677543/hbase11368-master.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12677543/hbase11368-master.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12677543&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 3781 checkstyle errors (more than the trunk&apos;s current 3780 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestHCM&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestSplitLogManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11489//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14682493" author="syuanjiang" created="Tue, 11 Aug 2015 20:57:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tianq&quot; class=&quot;user-hover&quot; rel=&quot;tianq&quot;&gt;Qiang Tian&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, any update or concern on this patch?  We have a customer seeing this issue recently.&lt;/p&gt;</comment>
                            <comment id="14693166" author="enis" created="Wed, 12 Aug 2015 08:55:22 +0000"  >&lt;p&gt;My concern with the patch is that it is acquiring yet another lock per get/scan on top of the already existing ones. Agreed that the region close lock is abused here for multi-CF bulkloads and have to be fixed. &lt;/p&gt;

&lt;p&gt;I believe the actual long term solution to this is to do ref-counting to Store files in the store, and have the store file list per scan immutable. Then we do not need the costly mechanism for keeping the store files updated between KVHea, scanner and store file list (&lt;tt&gt;notifyChangedReadersObservers&lt;/tt&gt;). leveldb is doing ref counting for files I believe. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; you had a jira for this? &lt;/p&gt;</comment>
                            <comment id="14695115" author="enis" created="Thu, 13 Aug 2015 12:04:26 +0000"  >&lt;p&gt;I was reading &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4552&quot; title=&quot;multi-CF bulk load is not atomic across column families&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4552&quot;&gt;&lt;del&gt;HBASE-4552&lt;/del&gt;&lt;/a&gt; and RegionScannerImpl code again to try to understand why we need the write lock for multi-CF bulk loads in the first place. It seems that it was put there to ensure atomicity, but that should be guaranteed with the seqId / mvcc combination and not via region write lock. However, the bulk load files obtain a seqId, and acquiring the region write lock will block all flushes which may be the reason. On bulk load, we call HStore.notifyChangedReadersObservers(), which resets the KVHeap, but we never reset the RegionScanner from my reading of code. Is this a bug? The current scanners should not see the new bulk loaded data (via mvcc) so maybe it is ok? &lt;/p&gt;</comment>
                            <comment id="14695884" author="jinghe" created="Thu, 13 Aug 2015 20:28:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;but that should be guaranteed with the seqId / mvcc combination and not via region write lock.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;How?  Would the following case be true without the bulk load getting the region write lock?&lt;br/&gt;
a.  the bulk load obtain a seqId&lt;br/&gt;
b. a read request comes in and gets the seqId as mvcc.&lt;br/&gt;
c. The read will be able to see the partially loaded data while the bulk is still in process&lt;/p&gt;

&lt;p&gt;In the 0.98 code line, we don&apos;t have seqid, and the atomicity is still guaranteed there.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On bulk load, we call HStore.notifyChangedReadersObservers(), which resets the KVHeap, but we never reset the RegionScanner from my reading of code. Is this a bug?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think it is being propagated properly to the scanner.  Think about the same notifyChangedReadersObservers is being used at the end of compaction and flushes as well.  The reset of the readers should work.&lt;/p&gt;

&lt;p&gt;I think the region write lock is still the only guarantee for bulk load atomicity.  On the high level, the region scan and next calls are within the region read lock, which is mutually elusive with bulk load process which needs the region write lock.  This is heavy.&lt;/p&gt;</comment>
                            <comment id="14696223" author="ndimiduk" created="Fri, 14 Aug 2015 00:29:53 +0000"  >&lt;p&gt;Atomicity may be a false blanket considering &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4652&quot; title=&quot;Mechanism for atomic recovery from partial failure when atomically bulk-loading multi-CF rows.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4652&quot;&gt;HBASE-4652&lt;/a&gt; is still unresolved.&lt;/p&gt;</comment>
                            <comment id="14696335" author="jinghe" created="Fri, 14 Aug 2015 02:15:20 +0000"  >&lt;p&gt;You are right, Nick.  That is the unsolved issue.&lt;/p&gt;</comment>
                            <comment id="14696724" author="enis" created="Fri, 14 Aug 2015 08:55:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;How? Would the following case be true without the bulk load getting the region write lock?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We do not do this now, but in theory it can be done similarly to regular writes. &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;obtain new seqId as a write transaction&lt;/li&gt;
	&lt;li&gt;bulk load all files across CFs with the seqId.&lt;/li&gt;
	&lt;li&gt;advance mvcc read point only when all bulk loads are complete.&lt;br/&gt;
This way the scanners are guaranteed to atomically observe the bulk loaded data atomically without the region-write-lock. 
&lt;blockquote&gt;&lt;p&gt;In the 0.98 code line, we don&apos;t have seqid, and the atomicity is still guaranteed there.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. Not worth changing 0.98 line. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I think it is being propagated properly to the scanner. Think about the same notifyChangedReadersObservers is being used at the end of compaction and flushes as well. The reset of the readers should work.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am not sure about that. Agreed that the cells at the store level will actually get re-ordered, but the heap at the region level is never re-ordered. So, after a bulk load, the ordering of store scanners at the region level might change, but the scanner will miss it if I understand this correctly. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Atomicity may be a false blanket considering &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4652&quot; title=&quot;Mechanism for atomic recovery from partial failure when atomically bulk-loading multi-CF rows.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4652&quot;&gt;HBASE-4652&lt;/a&gt; is still unresolved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Very good point. We need a transactional commit for the BL files. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14705298" author="esteban" created="Thu, 20 Aug 2015 17:08:53 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tianq&quot; class=&quot;user-hover&quot; rel=&quot;tianq&quot;&gt;Qiang Tian&lt;/a&gt; are you still working on this? &lt;/p&gt;

&lt;p&gt;Also I agree with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; regarding ref-counting might be an alternative but I couldn&apos;t find the JIRA for that, any pointer &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14728155" author="ndimiduk" created="Wed, 2 Sep 2015 22:35:06 +0000"  >&lt;p&gt;Check my facts:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the only uses of the write lock are region close and bulkload, two rare events.&lt;/li&gt;
	&lt;li&gt;the only long-running read lock holders are compactions, frequent events.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;What if we allow write lock access requests to interrupt running compactions?&lt;/p&gt;</comment>
                            <comment id="14730105" author="ndimiduk" created="Fri, 4 Sep 2015 00:36:30 +0000"  >&lt;p&gt;Looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6028&quot; title=&quot;Implement a cancel for in-progress compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6028&quot;&gt;HBASE-6028&lt;/a&gt; wants to implement the meat of what I&apos;ve proposed above. It also happens to be 2/3 of the work for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12446&quot; title=&quot;[list | abort] Compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12446&quot;&gt;&lt;del&gt;HBASE-12446&lt;/del&gt;&lt;/a&gt;. Seems like good bang for the buck on this approach.&lt;/p&gt;

&lt;p&gt;Chatting with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=devaraj&quot; class=&quot;user-hover&quot; rel=&quot;devaraj&quot;&gt;Devaraj Das&lt;/a&gt; about this offline. Another idea is we can reduce the scope of when the read lock is held during compaction. In theory the compactor only needs a region read lock while deciding what files to compact and at the time of committing the compaction. We&apos;re protected from the case of region close events because compactions are checking (between every Cell!) if the store has been closed in order to abort in such a case. Is there another reason why we would want to hold the read lock for the entire duration of the compaction? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14730140" author="lhofhansl" created="Fri, 4 Sep 2015 01:20:11 +0000"  >&lt;p&gt;See also discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt;. (somewhat related, but talks about the locks in StoreScanner that we need to safely reset the scanner stack)&lt;/p&gt;</comment>
                            <comment id="14730283" author="stack" created="Fri, 4 Sep 2015 04:12:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt; I like the idea of narrowing the lock scope but started to look and its a bit of a rats nest where locks are held (compactions checking on each row seems well dodgy... )  Yeah, a review of the attempt at undoing scanner locks so only a region-level lock sounds like it would help.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14947820" author="ndimiduk" created="Wed, 7 Oct 2015 23:50:56 +0000"  >&lt;p&gt;FYI, opened subtask &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14575&quot; title=&quot;Relax region read lock for compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14575&quot;&gt;&lt;del&gt;HBASE-14575&lt;/del&gt;&lt;/a&gt; to give &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=devaraj&quot; class=&quot;user-hover&quot; rel=&quot;devaraj&quot;&gt;Devaraj Das&lt;/a&gt;&apos;s idea a spin. Mind having a look?&lt;/p&gt;</comment>
                            <comment id="14983879" author="ram_krish" created="Sat, 31 Oct 2015 07:15:43 +0000"  >&lt;p&gt;This comment &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11368?focusedCommentId=14693166&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14693166&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-11368?focusedCommentId=14693166&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14693166&lt;/a&gt; is getting addressed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt;.  So doing that JIRA would mean that any current on going scan will not be able to see the bulk loaded hfiles which is loaded just after the current scan has started. I think that behaviour should be acceptable, right?&lt;/p&gt;</comment>
                            <comment id="14984102" author="ndimiduk" created="Sat, 31 Oct 2015 18:38:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;any current on going scan will not be able to see the bulk loaded hfiles which is loaded just after the current scan has started. I think that behaviour should be acceptable, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I believe this should be correct behavior, yes.&lt;/p&gt;</comment>
                            <comment id="15101219" author="jinghe" created="Fri, 15 Jan 2016 05:20:14 +0000"  >&lt;p&gt;This ticket can be closed because the only sub-task would fix the problem. Right?&lt;/p&gt;</comment>
                            <comment id="15120874" author="hadoopqa" created="Thu, 28 Jan 2016 06:28:58 +0000"  >&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; patch &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 5s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11368&quot; title=&quot;Multi-column family BulkLoad fails if compactions go on too long&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11368&quot;&gt;&lt;del&gt;HBASE-11368&lt;/del&gt;&lt;/a&gt; does not apply to master. Rebase required? Wrong Branch? See &lt;a href=&quot;https://yetus.apache.org/documentation/latest/precommit-patchnames&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://yetus.apache.org/documentation/latest/precommit-patchnames&lt;/a&gt; for help. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12677543/hbase11368-master.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12677543/hbase11368-master.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Issue &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11368&quot; title=&quot;Multi-column family BulkLoad fails if compactions go on too long&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11368&quot;&gt;&lt;del&gt;HBASE-11368&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Powered by &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Apache Yetus 0.1.0   &lt;a href=&quot;http://yetus.apache.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://yetus.apache.org&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/331/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/331/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12823010">HBASE-13530</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12674719" name="hbase-11368-0.98.5.patch" size="4131" author="tianq" created="Tue, 14 Oct 2014 08:03:47 +0000"/>
                            <attachment id="12677543" name="hbase11368-master.patch" size="4274" author="tianq" created="Tue, 28 Oct 2014 06:47:51 +0000"/>
                            <attachment id="12677097" name="key_stacktrace_hbase10882.TXT" size="11214" author="tianq" created="Sat, 25 Oct 2014 10:25:44 +0000"/>
                            <attachment id="12676874" name="performance_improvement_verification_98.5.patch" size="7066" author="tianq" created="Fri, 24 Oct 2014 10:02:21 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12903188">HBASE-14575</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Oct 2014 03:43:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>399773</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            46 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1wtj3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>399881</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>