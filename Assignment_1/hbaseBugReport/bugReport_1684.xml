<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:55:31 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1684/HBASE-1684.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1684] Backup (Export/Import) contrib tool for 0.20</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1684</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Add a new Result/KeyValue based Export MapReduce job to contrib for 0.20.&lt;/p&gt;

&lt;p&gt;Make it in the hadoop 0.20 and hbase 0.20 MR API, and hbase 0.20 API (Result/Put).&lt;/p&gt;</description>
                <environment></environment>
        <key id="12431187">HBASE-1684</key>
            <summary>Backup (Export/Import) contrib tool for 0.20</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="streamy">Jonathan Gray</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jul 2009 22:04:43 +0000</created>
                <updated>Fri, 20 Nov 2015 13:01:25 +0000</updated>
                            <resolved>Thu, 17 Sep 2009 03:26:28 +0000</resolved>
                                    <version>0.20.0</version>
                                    <fixVersion>0.20.1</fixVersion>
                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12734354" author="streamy" created="Wed, 22 Jul 2009 22:09:49 +0000"  >&lt;p&gt;Untested, just quick code dump.  There is not much to this, utilizes TIF for Export and TOF for Import.&lt;/p&gt;

&lt;p&gt;What&apos;s the best way to distribute this MR job as contrib?  Need to make an individual build.xml and add it to main build?&lt;/p&gt;

&lt;p&gt;Once I have that, will add class comments / package-info about how to use it.  Could use some help on how to properly build it though.&lt;/p&gt;</comment>
                            <comment id="12734914" author="stack" created="Fri, 24 Jul 2009 05:52:55 +0000"  >&lt;p&gt;What should the contrib be called? &apos;backupmr&apos;?  How about dump?  ExportMR and ImportMR should implement Tool.  See the HStoreFileToStoreFile for sample.  Then they can take command line arguments.  Why have a map in ExportMR?  It does nothing.  Same for reducer?  Just use Identity Map?  For ImportMR, reduce does nothing either.   Just don&apos;t have it in there and set reducer to zero in the job setup.  Rather than a contrib, lets just add this to mapreduce package?&lt;/p&gt;</comment>
                            <comment id="12735182" author="streamy" created="Fri, 24 Jul 2009 21:54:51 +0000"  >&lt;p&gt;Punting to 0.20.1&lt;/p&gt;

&lt;p&gt;Will commit when it&apos;s ready, whenever that is.  Will probably move it to mapreduce package instead of contrib.&lt;/p&gt;</comment>
                            <comment id="12741285" author="larsgeorge" created="Mon, 10 Aug 2009 12:22:10 +0000"  >&lt;p&gt;Attached RestoreTable and BackupTable that we use internally to backup a table into gzipped text files and then restore on a different (or the same of course) cluster. The only thing missing is also base64 encode the row key, but otherwise it works as-is. &lt;/p&gt;

&lt;p&gt;If you like I can pretty this up and add next to RowCounter as a hbase.jar tool. What do you think?&lt;/p&gt;</comment>
                            <comment id="12741292" author="larsgeorge" created="Mon, 10 Aug 2009 12:35:21 +0000"  >&lt;p&gt;Stack, about your comments re: reducer/mapper needed. For the RestoreTable I am using both, the mapper reads from the backup files and then randomizes the rows using a random intermediate key. This is along what Ryan did with his pure randomizer MR class. That way all the RegionServers are hit equally.&lt;/p&gt;

&lt;p&gt;For the BackupTable I am using an IdentityTableMapper and encode the data in the reducer to have it written out in the TextOutputFormat. After we discussed that a while ago with you and Jon it should also be possible to use only a Mapper and do the work there and set the Reducers to 0, which then hands out the Mapper records straight to the TextOutputFormat.&lt;/p&gt;

&lt;p&gt;Lastly, implementing Tool seems deprecated. The new mapreduce WordCounter sample that comes with Hadoop 0.20 abandons it too. That is also why I changed RowCounter not to use it when I cleaned up the hbase.mapreduce package. The parsing of the generic options is done using the GenericParser directly inside the main(), and the remaining arguments used for the specific MR job. I have done the same in the attached two classes.&lt;/p&gt;</comment>
                            <comment id="12744693" author="stack" created="Tue, 18 Aug 2009 20:25:44 +0000"  >&lt;p&gt;Classes look good but why toString binary data?  Why not write out KeyValues to SequenceFiles?  And yes, I you are right, I noticed that Tool seems deprecated now.&lt;/p&gt;</comment>
                            <comment id="12744949" author="larsgeorge" created="Wed, 19 Aug 2009 08:05:47 +0000"  >&lt;p&gt;This is from before all binary KV&apos;s. The advantage is I guess that you can still somewhat read the base64 encoded backup files. Of course they are larger than the plain KV-dumped-into-SequenceFile version. The code above uses TextOutputFormat and does so with minimal extra effort. But that is no strict requirement of course and could be changed. &lt;/p&gt;</comment>
                            <comment id="12746182" author="stack" created="Fri, 21 Aug 2009 19:46:02 +0000"  >&lt;p&gt;I think the toString+base64&apos;ing messy.  I think a tool that did binary dump&apos;ll be more performant and more generally useful.  Regards readability, its a non-issue since you added that fancy usage and options to hfile.  Folks can look at their binary data in hfiles easy enough.&lt;/p&gt;</comment>
                            <comment id="12755890" author="stack" created="Wed, 16 Sep 2009 05:47:54 +0000"  >&lt;p&gt;This is based on Jon&apos;s code &amp;#8211; some cleanup, using the inner-class idiom &amp;#8211; but its not right yet. It puts the import/export together in one class.  I think it&apos;d just be cleaner doing them as separate classes as Jon had it.&lt;/p&gt;</comment>
                            <comment id="12756206" author="stack" created="Wed, 16 Sep 2009 19:51:50 +0000"  >&lt;p&gt;Patch that adds import and export jobs to the hbase mapreduce MR driver.&lt;/p&gt;

&lt;p&gt;Export does like Jon&apos;s writing out to sequence files.&lt;/p&gt;

&lt;p&gt;Import reads in from said sequence files.&lt;/p&gt;

&lt;p&gt;These classes are more inline w/ the the 0.20.0 MR idiom (and not unnecessary reduce, etc.).&lt;/p&gt;

&lt;p&gt;Also fixed RowCounter so no longer an output dir.&lt;/p&gt;

&lt;p&gt;Fixed tableinputformat so no longer need to specify columns (if no columns, then all columns).&lt;/p&gt;

&lt;p&gt;Changed some of the util so it can take null classes.. sometimes need this (e.g. above imports/exports).&lt;/p&gt;

&lt;p&gt;Please review.&lt;/p&gt;</comment>
                            <comment id="12756236" author="stack" created="Wed, 16 Sep 2009 21:24:38 +0000"  >&lt;p&gt;I tested this by loading a table, exporting it, dropping it, recreating it, then reimporting, then running rowcounter to confirm.&lt;/p&gt;</comment>
                            <comment id="12756328" author="streamy" created="Thu, 17 Sep 2009 01:39:57 +0000"  >&lt;p&gt;Version of stack&apos;s patch that applies cleanly to trunk.&lt;/p&gt;</comment>
                            <comment id="12756329" author="streamy" created="Thu, 17 Sep 2009 01:40:21 +0000"  >&lt;p&gt;Patch looks good to me.  +1 for commit&lt;/p&gt;</comment>
                            <comment id="12756345" author="stack" created="Thu, 17 Sep 2009 03:26:28 +0000"  >&lt;p&gt;Committed branch and trunk.&lt;/p&gt;</comment>
                            <comment id="12759060" author="schubertzhang" created="Thu, 24 Sep 2009 08:03:16 +0000"  >&lt;p&gt;The Export(backup)/Import tools in this issue seem just get and insert data by normal API. &lt;/p&gt;

&lt;p&gt;For the bulk backup/export tool: Why not just copy out the HFiles?&lt;br/&gt;
For the bulk import tool: it should be &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-48&quot; title=&quot;[hbase] Bulk load tools&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-48&quot;&gt;&lt;del&gt;HBASE-48&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12759134" author="streamy" created="Thu, 24 Sep 2009 14:36:58 +0000"  >&lt;p&gt;@Schubert What do you mean just use the normal API?  These are MapReduce jobs.  You are referring to wanting to do imports/exports at the HDFS level instead?  (that is not this issue)&lt;/p&gt;

&lt;p&gt;Bulk importing can be done with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-48&quot; title=&quot;[hbase] Bulk load tools&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-48&quot;&gt;&lt;del&gt;HBASE-48&lt;/del&gt;&lt;/a&gt;, but it is not yet fully-featured (only works on single families, doesn&apos;t work into existing tables, etc)&lt;/p&gt;

&lt;p&gt;Bulk exporting at HFile level is going to require some form of freezing/snapshotting so it&apos;s 100% safe and consistent to do that (though it&apos;s still possible now, and we&apos;re doing it in production here).  There is an old issue for this as well, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12759175" author="stack" created="Thu, 24 Sep 2009 16:54:26 +0000"  >&lt;p&gt;@Schubert Yeah, these use normal API.  Fellas might use them if they want to backup a table then reload it.  Using these tools, there is no need to mess with .META. (presuming table already exists).  Regards bulk exporting by copying hfiles, do you want to make an issue?  It shouldn&apos;t be hard to do.  Just copy the table directory in hdfs.  On restore, would probably need to wipe the table from .META. and then add entries per region in the backup (using the content of the .regioninfo file that is underneath the region directory).  Shouldn&apos;t be hard.  If you need it, lets work on it together.&lt;/p&gt;</comment>
                            <comment id="15017796" author="lars_francke" created="Fri, 20 Nov 2015 13:01:25 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12416053" name="BackupTable.java" size="9828" author="larsgeorge" created="Mon, 10 Aug 2009 12:22:10 +0000"/>
                            <attachment id="12419730" name="ExportImport.java" size="5398" author="stack" created="Wed, 16 Sep 2009 05:47:54 +0000"/>
                            <attachment id="12419838" name="HBASE-1684-trunk.patch" size="15878" author="streamy" created="Thu, 17 Sep 2009 01:39:57 +0000"/>
                            <attachment id="12414272" name="HBASE-1684-v1.patch" size="7412" author="streamy" created="Wed, 22 Jul 2009 22:09:49 +0000"/>
                            <attachment id="12416054" name="RestoreTable.java" size="12473" author="larsgeorge" created="Mon, 10 Aug 2009 12:22:10 +0000"/>
                            <attachment id="12419814" name="exportimport.patch" size="17249" author="stack" created="Wed, 16 Sep 2009 19:51:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jul 2009 05:52:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32225</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0heof:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99640</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>