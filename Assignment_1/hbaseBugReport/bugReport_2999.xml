<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:06:31 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2999/HBASE-2999.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2999] hbase TTL can be suboptimal and leave small regions after compaction</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2999</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Yes, Current TTL based on compaction is working as advertised if the key &lt;br/&gt;
randomly distribute the incoming data&lt;br/&gt;
among all regions.  However, if the key is designed in chronological order, &lt;br/&gt;
the TTL doesn&apos;t really work, as  no compaction&lt;br/&gt;
will happen for data already written. So we can&apos;t say  that current TTL &lt;br/&gt;
really work as advertised, as it is key structure dependent.&lt;/p&gt;

&lt;p&gt;This is a pity, because a major use case for hbase is for people to store &lt;br/&gt;
history or log data. normally people only&lt;br/&gt;
want to retain the data for a fixed period. for example, US government &lt;br/&gt;
default data retention policy is 7 years. Those&lt;br/&gt;
data are saved in chronological order. Current TTL implementation doesn&apos;t &lt;br/&gt;
work at all for those kind of use case.&lt;/p&gt;

&lt;p&gt;In order for that use case to really work, hbase needs to have an active &lt;br/&gt;
thread that periodically runs and check if there&lt;br/&gt;
are data older than TTL, and delete the data older than TTL is necessary, &lt;br/&gt;
and compact small regions older than certain time period&lt;br/&gt;
into larger ones to save system resource. It can optimize the deletion by &lt;br/&gt;
delete the whole region if it detects that the last time&lt;br/&gt;
stamp for the region is older than TTL.  There should be 2 parameters  to &lt;br/&gt;
configure for hbase:&lt;/p&gt;

&lt;p&gt;1. whether to disable/enable the TTL thread.&lt;br/&gt;
2. the interval that TTL will run. maybe we can use a special value like 0 &lt;br/&gt;
to indicate that we don&apos;t run the TTL thread, thus saving one configuration &lt;br/&gt;
parameter.&lt;br/&gt;
for the default TTL, probably it should be set to 1 day.&lt;br/&gt;
3. How small will the region be merged. it should be a percentage of the &lt;br/&gt;
store size. for example, if 2 consecutive region is only 10% of the store &lt;br/&gt;
szie ( default is 256M), we can initiate a region merge.  We probably need a &lt;br/&gt;
parameter to reduce the merge too. for example , we only merge for regions &lt;br/&gt;
who&apos;s largest timestamp&lt;br/&gt;
is older than half of TTL.&lt;/p&gt;

&lt;p&gt;We are tracking min/max timestamps in storefiles currently, so it&apos;s possible that we could expire some files of a region as well, even if the region was not completely expired. So At minimum, we should be able to implement dropping  the stores that is older than TTL. if all stores for a region is dropped, we should drop the whole region,&lt;br/&gt;
and update the key range of the adjacent region, so there is not a key hole left.&lt;/p&gt;



</description>
                <environment>&lt;p&gt;All&lt;/p&gt;</environment>
        <key id="12474200">HBASE-2999</key>
            <summary>hbase TTL can be suboptimal and leave small regions after compaction</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jimmy888">Jimmy Hu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Sep 2010 18:21:45 +0000</created>
                <updated>Wed, 16 Jul 2014 22:27:49 +0000</updated>
                            <resolved>Wed, 16 Jul 2014 22:27:49 +0000</resolved>
                                    <version>0.89.20100621</version>
                                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12910230" author="jimmy888" created="Thu, 16 Sep 2010 17:16:43 +0000"  >&lt;p&gt;It turns out that the hbase will do daily major_compac  for the tables. for data that is older than TTL, the major_compact will actually remove all records if the region &apos;s last timestamp is older than TTL. This resolved the old data issue. However,  the majjr_compaction should be optimized so that when it notices a region&apos;s last timestamp is older than TTL, it should just go ahead and remove&lt;br/&gt;
the file, instead of reading the file and discard record by record. It improves speed and reduce cpu/memory usage.&lt;/p&gt;


&lt;p&gt;However, after the major_compaction test,  I found that I end up having several regions that have no data &lt;br/&gt;
inside.&lt;br/&gt;
and the regions are not merged even though they are empty  and consecutive.&lt;/p&gt;

&lt;p&gt;That means, if we run this in production system and key is chronological &lt;br/&gt;
order, we will end up&lt;br/&gt;
having thousands of regions as time goes on and the number of regions never &lt;br/&gt;
decrease,&lt;br/&gt;
even though old data are compacted away. we don&apos;t really mind having several &lt;br/&gt;
empty regions, but the fact that the region number continue to grow &lt;br/&gt;
unlimited without stop as time goes on, is really troublesome. It waste &lt;br/&gt;
hadoop namenode resource, and waste memory resource on regionserver, as each &lt;br/&gt;
region takes some memory to store region info.&lt;/p&gt;

&lt;p&gt;J.D mentions that&lt;/p&gt;

&lt;p&gt;Currently merging regions can only be done while HBase is offline, a&lt;br/&gt;
long time ago this was opened:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-420&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-420&lt;/a&gt;. And some work was to&lt;br/&gt;
at least be able to merge regions in disabled tables:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1621&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-1621&lt;/a&gt; but it requires a lot&lt;br/&gt;
more engineering.&lt;/p&gt;

&lt;p&gt;Stack mentions that:&lt;/p&gt;

&lt;p&gt;It&apos;d be easy enough to write a script to do this run out of cron but&lt;br/&gt;
yeah, we should have a facility to sweep hbase and in particular if&lt;br/&gt;
regions are empty of store files, merge to neighbour.&lt;/p&gt;

</comment>
                            <comment id="12910234" author="jimmy888" created="Thu, 16 Sep 2010 17:30:00 +0000"  >&lt;p&gt;What I suggest is to make  the sweep part of the major_compact. basically, it needs to merge consecutive empty regions to the neighboring region that is not empty.  it need to merge the records in .META. table, and delete the empty directories in the HDFS for the empty regions. it should then instruct the region servers to unload the original regions and reload the merged regions.&lt;/p&gt;</comment>
                            <comment id="14064254" author="apurtell" created="Wed, 16 Jul 2014 22:27:49 +0000"  >&lt;p&gt;Not actionable&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12474246">HBASE-3004</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 16 Jul 2014 22:27:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32867</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 22 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hk8v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100542</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>