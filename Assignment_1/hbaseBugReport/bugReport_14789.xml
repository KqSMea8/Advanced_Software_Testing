<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:56:28 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-14789/HBASE-14789.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-14789] Enhance the current spark-hbase connector</title>
                <link>https://issues.apache.org/jira/browse/HBASE-14789</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;This JIRA is to optimize the RDD construction in the current connector implementation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12911693">HBASE-14789</key>
            <summary>Enhance the current spark-hbase connector</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="zzhan">Zhan Zhang</assignee>
                                    <reporter username="zzhan">Zhan Zhang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Nov 2015 22:41:56 +0000</created>
                <updated>Fri, 1 Apr 2016 19:54:57 +0000</updated>
                                                            <fixVersion>2.0.0</fixVersion>
                                    <component>spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>18</watches>
                                                                                                            <comments>
                            <comment id="14997555" author="zzhan" created="Mon, 9 Nov 2015 22:43:51 +0000"  >&lt;p&gt;Design doc attached.&lt;/p&gt;</comment>
                            <comment id="14997556" author="zzhan" created="Mon, 9 Nov 2015 22:44:29 +0000"  >&lt;p&gt;Preliminary implementation is available at &lt;br/&gt;
&lt;a href=&quot;https://github.com/zhzhan/shc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/zhzhan/shc&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="14999385" author="ted.m" created="Tue, 10 Nov 2015 21:37:16 +0000"  >&lt;p&gt;Can you help me understand what components this has that don&apos;t already exist in the current HBase-Spark module and also what requirements are not met by the current Spark-Module implementation but are supported with this code?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14999422" author="ted.m" created="Tue, 10 Nov 2015 22:03:12 +0000"  >&lt;p&gt;Cool I read the doc so there are two points.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Bulk Get - Do bulk Gets on an executor&lt;/li&gt;
	&lt;li&gt;TableInputFormat - Don&apos;t use this because or the thought that only one can run at a time&lt;/li&gt;
	&lt;li&gt;Change the table description format - Add more JSON like definition&lt;/li&gt;
	&lt;li&gt;Add write support - For SparkSQL writes to HBase&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;#First lets talk to each point first:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Bulk Get: - As we have talked about in other jira&apos;s executing this on the executor side really doesn&apos;t add much value.  It would be vary odd if people would have more then a 1000 equals in a where cause.  If they did then we need to figure out at what point 1000, 10000, 50000 does it become faster to run the code on the executor.  The normal use case is just a couple = per where cause so this is not a real concern, now if you want to do a real bulk get then use the bulk get command, that will be much better for a lot of reasons.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Not Using TableInputFormat: In the code today Spark if given the TablInputFormat in different requests so they are at different points on the DAG.  So why does Spark not read from both?  Also the locality is given and we are not reinventing the wheel.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Change the table description format: This is a preference thing is current version is more like the HBase shell.  Ether way makes sense it makes no real difference.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Add write support: Yes we should add this.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;#Summery&lt;br/&gt;
First I think any and all changes would fit into the current implementation of the HBase-Spark module with little changes.  This are pretty pointed changes that effect a scoped area of the code.  &lt;/p&gt;

&lt;p&gt;Second we should separate out this jira into 4 different jiras each focusing on the different points, for these different points are not dependent or related. We should open up a jira to address each features and then discuss the approach for each one and how it can be added and or if it should be added.&lt;/p&gt;

&lt;p&gt;Thanks Zhan&lt;/p&gt;

&lt;p&gt;Let me know if I missed anything&lt;/p&gt;


</comment>
                            <comment id="14999566" author="zzhan" created="Tue, 10 Nov 2015 23:15:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=malaskat&quot; class=&quot;user-hover&quot; rel=&quot;malaskat&quot;&gt;Ted Malaska&lt;/a&gt; Thanks for reviewing this. I agree that  table write, json format, and customized sedes are all able to fit into the current implementation with some changes, and I would love to contribute on this part.&lt;/p&gt;

&lt;p&gt;Given that, there is no straightforward way to support multi-scans and bulkget with TableInputFormat with the scenario mentioned in the document.  The argument regarding the BulkGet may be reasonable in most cases, but there do have chances that driver becomes bottleneck. More importantly,  driver is actually processing data with HBase client library. If there is any exception happens, the whole job will crash.&lt;/p&gt;

&lt;p&gt;Regarding the multiple scan, here is my understanding. Correct me if I am wrong.&lt;br/&gt;
Current implementation will construct a RDD for each non-overlapping scan. Then all these RDDs are union together. With the current TableInputFormat limitation, there is no easy way to walkaround this, unless TableInputFormat is changed to handle multiple scans in one shot.&lt;/p&gt;

&lt;p&gt;Now suppose we have 10 regions, but the user query may consists of 100 non-overlapping scans. Then there will be 100 RDDs constructed and union together.  The Union RDD returned by buildScan will consists of at least 100 partitions, assume that each RDD only have one partitions (there is high chance that each RDD may consists of multiple partitions).&lt;/p&gt;

&lt;p&gt;100 partitions means that Spark will has to launch 100 tasks to process the scan. Given that we only have 10 regions (10 servers to simplify the discussion).  The scheduler cannot allocate 100 tasks to 10 severs (10 executors co-located with region server with 1 core each to simply the discussion). In this scenario, the executors finishes its assigned task earlier will get more tasks, which may retrieve data from other region server (hurt the data locality). In addition, the scheduler has to schedule and serialize 100 tasks, which increase the overhead.&lt;/p&gt;

&lt;p&gt;In the architecture proposed in this JIRA, the driver will construct 10 tasks (or less) with each consists of multiple scans. These 10 tasks can be scheduled to 10 executors concurrently, which achieve better data locality, sedes and scheduling overhead.&lt;/p&gt;

&lt;p&gt;In addition, in multi-tenant environment the current approach may suffer more because it has to construct much more tasks but the overall executor slot is limited.&lt;/p&gt;

&lt;p&gt;Also in this architecture, the Scan and Get are treated in a unified way, which seems to be more natural. I think in real deployment, the proposed architecture does have its advantage in many scenarios. &lt;/p&gt;
</comment>
                            <comment id="14999569" author="zzhan" created="Tue, 10 Nov 2015 23:17:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=malaskat&quot; class=&quot;user-hover&quot; rel=&quot;malaskat&quot;&gt;Ted Malaska&lt;/a&gt; By the way, I didn&apos;t mean &quot;do not use TableInputFormat&quot;. I mean to make two approaches as plugins so that users can choose the one that fitting into their requirements.&lt;/p&gt;</comment>
                            <comment id="14999622" author="ted.m" created="Tue, 10 Nov 2015 23:54:41 +0000"  >&lt;p&gt;This is a sub jira&lt;/p&gt;</comment>
                            <comment id="14999623" author="ted.m" created="Tue, 10 Nov 2015 23:55:24 +0000"  >&lt;p&gt;Put response to TableInputFormat design in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14795&quot; title=&quot;Enhance the spark-hbase scan operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14795&quot;&gt;&lt;del&gt;HBASE-14795&lt;/del&gt;&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="14999628" author="ted.m" created="Wed, 11 Nov 2015 00:00:52 +0000"  >&lt;p&gt;Put comments related to the bulk get implementation in jira &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14796&quot; title=&quot;Enhance the Gets in the connector&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14796&quot;&gt;&lt;del&gt;HBASE-14796&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15000943" author="zzhan" created="Wed, 11 Nov 2015 19:34:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ted.m&quot; class=&quot;user-hover&quot; rel=&quot;ted.m&quot;&gt;Theodore michael Malaska&lt;/a&gt; Thanks for the comments and open sub jiras for it. Do you mean migrating to the new approach instead of using plugins by modifying &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/hbase/blob/master/hbase-spark/src/main/scala/org/apache/hadoop/hbase/spark/DefaultSource.scala#L330&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hbase/blob/master/hbase-spark/src/main/scala/org/apache/hadoop/hbase/spark/DefaultSource.scala#L330&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15001083" author="ted.m" created="Wed, 11 Nov 2015 21:05:14 +0000"  >&lt;p&gt;Hey Zhan,&lt;/p&gt;

&lt;p&gt;I&apos;m not sure I understand the question.&lt;/p&gt;

&lt;p&gt;What I&apos;m thinking is the changes you are asking for should fit nicely into the existing code.&lt;/p&gt;

&lt;p&gt;And we can use the sub jira to discuss the implementations of each.  Example with the Scan implementation I would like to ask if that functionality could be added to tableInputFormat because it could be of value to more then just SparkSQL and because we can consolidate code.  For the BulkGet implementation I would like to see some performance tests to make sure we are not introducing latancy, also if we should use the existing BulkGet functionality in HBase-Spark because we might want to execute the gets in more then one task. &lt;/p&gt;

&lt;p&gt;But lets have this discussions in the sub jiras, for they are completely different components that are not dependent on each other.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15003062" author="ted.m" created="Thu, 12 Nov 2015 22:18:02 +0000"  >&lt;p&gt;Adding Jira for Changing the table definition to JSON&lt;/p&gt;</comment>
                            <comment id="15046003" author="zzhan" created="Mon, 7 Dec 2015 23:54:13 +0000"  >&lt;p&gt;solve review comments.&lt;/p&gt;</comment>
                            <comment id="15168106" author="zzhan" created="Thu, 25 Feb 2016 23:29:05 +0000"  >&lt;p&gt;Add a number extra jiras to improve the current connector.&lt;/p&gt;</comment>
                            <comment id="15168157" author="ted.m" created="Fri, 26 Feb 2016 00:07:51 +0000"  >&lt;p&gt;This looks really cool.  Can we add a couple more.&lt;/p&gt;

&lt;p&gt;5. Add support for DECIMAL&lt;br/&gt;
6. Add support for Nested Types&lt;br/&gt;
7. Add support for write with Bulk Load vs Puts with SparkSQL&lt;br/&gt;
8. Add support for pluggable change cell format (This is be implemented for item 2)&lt;/p&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12912624">HBASE-14801</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12955040">HBASE-15572</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12912023">HBASE-14795</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12912024">HBASE-14796</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12771451" name="shc.pdf" size="237225" author="zzhan" created="Mon, 9 Nov 2015 22:43:51 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12944692">HBASE-15333</subtask>
                            <subtask id="12944694">HBASE-15334</subtask>
                            <subtask id="12944696">HBASE-15335</subtask>
                            <subtask id="12944701">HBASE-15336</subtask>
                            <subtask id="12945054">HBASE-15350</subtask>
                            <subtask id="12912624">HBASE-14801</subtask>
                            <subtask id="12951055">HBASE-15473</subtask>
                            <subtask id="12969649">HBASE-15825</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Nov 2015 21:37:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            42 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2o5zr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>