<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:01:11 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2357/HBASE-2357.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2357] Coprocessors: Add read-only region replicas (slaves) for availability and fast region recovery</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2357</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I dont plan on working on this in the short term, but the idea is to extend region ownership to have two modes. Each region has one primary region server and N slave region servers. The slaves would follow the master (probably by streaming the relevant HLog entries directly from it) and be able to serve stale reads. The benefit is twofold: (a) provides the ability to spread read load, (b) enables very fast region failover/rebalance since the memstore is already nearly up to date on the slave RS.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12459886">HBASE-2357</key>
            <summary>Coprocessors: Add read-only region replicas (slaves) for availability and fast region recovery</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                    </labels>
                <created>Mon, 22 Mar 2010 17:46:37 +0000</created>
                <updated>Tue, 12 Aug 2014 19:08:16 +0000</updated>
                            <resolved>Tue, 12 Aug 2014 19:08:16 +0000</resolved>
                                                                    <component>master</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>24</watches>
                                                                <comments>
                            <comment id="12850426" author="apurtell" created="Sat, 27 Mar 2010 00:32:19 +0000"  >&lt;p&gt;Stream edits with no freshness guarantee or use ZAB or Paxos over small (N=3) cliques? The latter can do away with the WAL as an option or the leader can maintain the WAL as part of the write transaction. This would still allow (a) and (b) but strengthen the consistency of both. It&apos;s not clear if there would be a significant write penalty beyond what we already take with durable WAL (hflush), especially if the WAL is only used if all members of a clique fail, so the consensus protocol and hflush can happen in parallel. Crazy idea? &lt;/p&gt;</comment>
                            <comment id="12850432" author="ryanobjc" created="Sat, 27 Mar 2010 00:42:30 +0000"  >&lt;p&gt;that is so crazy it just might work!&lt;/p&gt;

&lt;p&gt;i wonder how slow updates might get?&lt;/p&gt;
</comment>
                            <comment id="12850464" author="tlipcon" created="Sat, 27 Mar 2010 02:59:10 +0000"  >&lt;p&gt;well, this whole thing is a crazy idea, I don&apos;t anticipate working on it until a lot of other much more important things are done &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;As for your specific brand of crazy idea, I think log shipping is a well proven and simple method that should really cover the majority of use cases. Consensus is tricky to get right, and while using an underlying well tested protocol like ZAB helps, it still is nowhere near easy. It also means that writes on one node are blocked by slaves. So I&apos;m -1 on that, but only as much as one can be -1 on a crazy idea while proposing another crazy idea &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12850588" author="apurtell" created="Sat, 27 Mar 2010 22:11:32 +0000"  >&lt;p&gt;Writes would be blocked by the slowest of the clique but if this scheme is allowing (strongly consistent!) read load to be more spread out, then in theory anyway the probability of hot accesses to a particular region server starving the write side is lowered accordingly. We could mock it and see what happens and/or try to work through some of the particulars formally. Like Ryan I wonder how slow updates might get. Consider if we run ZAB on a 3-node clique and hflush in parallel to commit with a barrier on completion of both. Who wins the race? How often would hflush take longer? Could be a substantial percentage, especially in a mixed HBase and HDFS (plain mapreduce or Hive or Pig or Cascading or...) loaded environment. It&apos;s not clear that hflush would not dominate, is my point.&lt;/p&gt;

&lt;p&gt;What I don&apos;t like about log shipping is the read replicas are not going to be useful to someone who is using HBase for its strong consistency and needs it, with exception for use cases where one could accept consistent results looking back from the timestamp of the last replication. (But that timestamp could be different on each slave, so master and slaves might all have different views!) But with a consensus protocol, read load can be spread as is the intent of this issue and yet the data is still strongly consistent. &lt;/p&gt;

&lt;p&gt;So I might humbly suggest that both ideas have pros and cons and neither warrants a -1 nor a +1 at this point, IMO. &lt;/p&gt;</comment>
                            <comment id="12850591" author="apurtell" created="Sat, 27 Mar 2010 22:23:56 +0000"  >&lt;p&gt;Minor clarification&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;But with a consensus protocol, read load can be spread as is the intent of this issue and yet the data is still strongly consistent&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;at any time on any region server hosting the region (or a replica)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;so an ICV is atomic no matter what region server any client is talking to, for example.&lt;/p&gt;</comment>
                            <comment id="12932760" author="apurtell" created="Wed, 17 Nov 2010 01:23:00 +0000"  >&lt;p&gt;We are going to attempt this with coprocessors. &lt;/p&gt;</comment>
                            <comment id="12932761" author="tlipcon" created="Wed, 17 Nov 2010 01:25:02 +0000"  >&lt;p&gt;cool! looking forward to seeing it!&lt;/p&gt;</comment>
                            <comment id="12933759" author="larsgeorge" created="Fri, 19 Nov 2010 10:25:57 +0000"  >&lt;p&gt;Ah this is nice! I had asked this many times and insinuated something like that to avoid that dreaded &quot;region is a goner for a while until redeployed&quot; in high availability environments. Using a consensus brings us into the realm of using a Dynamo like RegionServer architecture. With all the pros and cons, the latter being if a strict consistency is asked for then you pay a performance penalty. That is the case with any other open source projects implementing &quot;R+W&amp;gt;N&quot;. Can&apos;t we employ ZooKeeper for this somehow? &lt;/p&gt;

&lt;p&gt;I love it!&lt;/p&gt;</comment>
                            <comment id="12988508" author="apurtell" created="Sat, 29 Jan 2011 21:27:24 +0000"  >&lt;p&gt;I just committed to doing this (eventually) up on Quora so I guess I better own it.&lt;/p&gt;</comment>
                            <comment id="13030529" author="apurtell" created="Sun, 8 May 2011 18:50:48 +0000"  >&lt;p&gt;Looks like someone may have extracted ZAB some time around the 3.1.0 timeframe: &lt;a href=&quot;https://svn.cs.hmc.edu/svn/linkedin08/zab-multibranch/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://svn.cs.hmc.edu/svn/linkedin08/zab-multibranch/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13030773" author="jasonrutherglen" created="Mon, 9 May 2011 15:30:12 +0000"  >&lt;p&gt;@Andrew Can Zookeeper be used (as is) to elect a master (eg, why is ZAB necessary)?  Is there a solidified design for this issue?  I think simply using the MySQL replication paradigm is sufficient for the first implementation?&lt;/p&gt;</comment>
                            <comment id="13030870" author="apurtell" created="Mon, 9 May 2011 19:37:39 +0000"  >&lt;p&gt;@Jason No, no design doc yet. I mean to do one when I can get a suitable block of time for this. &lt;/p&gt;

&lt;p&gt;ZAB is not necessary for basic read replicas that sync &quot;eventually&quot;, basic MySQL-like master-slave. That would be the first step of course since most would only need that. Initial thoughts on this is a region slave can get notice from the region owner via zk that a log has rolled and process the new edits from there. Slaves will be under different memory pressure for their mix of regions than the owner, is the only significant detail to work through I think. So for this possibly shadow/temporary flush file storage for slaves that are managing shadow memstores, while sharing the permanent store files with the owner. Also need some zk-mediated coordination around splitting and compaction. Preferably the owner can do splits and compactions leaving the shared store files alone to the last possible moment, then do a change notification via zk and a HDFS rename. And, when all slaves have stopped sharing old storefiles, then garbage collection.&lt;/p&gt;

&lt;p&gt;ZAB would be for a next step, getting cliques to all see and agree upon edits coming in, in effect master-master-master replication. This is blue sky stuff. Regions would have higher availability than single region server hosting, yet all clients would have a consistent view of the data contained therein at any moment. However a region would need be deployed to 2N+1 regionservers, where N is the number of expected concurrent node failures, or it would not be writable as long as lacking quorum.&lt;/p&gt;</comment>
                            <comment id="13030892" author="jasonrutherglen" created="Mon, 9 May 2011 20:44:27 +0000"  >&lt;p&gt;@Andrew The ZAB would be very cool, as then there wouldn&apos;t be a need for too much logic when a master fails?  However I wonder about the write performance, as it means additional network overhead (to each node) per write?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Initial thoughts on this is a region slave can get notice from the region owner via zk that a log has rolled and process the new edits from there&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What is the expected latency between a write and then reading the new value(s) from the slave?  I&apos;m not sure if this means writing a series of WAL edits to a file, then waiting for the file to reach a given limit &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, and then the slave reads from the newly flushed log in HDFS?  If this is the case, perhaps we&apos;ll want to implement replication that is more immediate (like MySQL)?&lt;/p&gt;</comment>
                            <comment id="13047983" author="jasonrutherglen" created="Sat, 11 Jun 2011 21:03:37 +0000"  >&lt;p&gt;Another way to implement this functionality is for the slave(s) to loop on the HLog.Reader?  Are there any potential problems with that?&lt;/p&gt;

&lt;p&gt;I&apos;m not sure how the Coprocessor implementation would look, would the master push entries out?  Isn&apos;t that somewhat problematic, eg, when a slave goes down, an entry isn&apos;t sent or is skipped?&lt;/p&gt;</comment>
                            <comment id="13048364" author="apurtell" created="Sun, 12 Jun 2011 16:02:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;Another way to implement this functionality is for the slave(s) to loop on the HLog.Reader?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Are there any potential problems with that?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Like with my above &quot;first cut&quot; proposal to scan HLogs upon roll, it would miss anything not .writeToWAL(true).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure how the Coprocessor implementation would look, would the master push entries out? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, it would either stream updates out of all hooks for mutations or run a consensus protocol in parallel with WAL commit out of the same.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Isn&apos;t that somewhat problematic, eg, when a slave goes down, an entry isn&apos;t sent or is skipped?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;With simple streaming, when a slave goes down its replica becomes invalid and should be simply discarded. So then I suppose there will be a period of time after that happens, when a new slave is allocated and is behind until the master sends over all the memstore. With ZAB, a transaction log and updates from peers is part of the protocol.&lt;/p&gt;</comment>
                            <comment id="13048378" author="jasonrutherglen" created="Sun, 12 Jun 2011 17:26:18 +0000"  >&lt;p&gt;Andrew, looping on the HLog sounds good.  I guess the next thing to conclude is how replication is defined in Zookeeper?  Should we implement something similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1295&quot; title=&quot;Multi data center replication&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1295&quot;&gt;&lt;del&gt;HBASE-1295&lt;/del&gt;&lt;/a&gt; or change that system to accommodate master -&amp;gt; slave(s)?&lt;/p&gt;</comment>
                            <comment id="13048487" author="apurtell" created="Mon, 13 Jun 2011 06:32:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;Andrew, looping on the HLog sounds good.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;-1&lt;/p&gt;

&lt;p&gt;Directly accessing HFiles from a coprocessor should be discouraged, this is something I&apos;ve seen have general agreement in discussions where it comes up. We created the WALObserver interface for exactly the purpose of capturing (and/or altering) the stream of edits going to the WAL.&lt;/p&gt;
</comment>
                            <comment id="13048494" author="apurtell" created="Mon, 13 Jun 2011 07:04:44 +0000"  >&lt;p&gt;I do have mixed feelings. Slaves would need to access foreign store files for regions that are not open on the RS. So then tailing HLogs, more foreign files, at the slave is not unreasonable. But that is a major violation of assumptions that store files are private. Sharing store files will require a coordination dance between master and slaves upon compaction and flushes. Sharing active HLogs is more evil given the master may become involved. &lt;/p&gt;

&lt;p&gt;Also, the trouble with watching the WAL either on the slave side at the file or on the master side with WALObserver is that .writeToWAL(false) edits will be unnoticed until flush. I&apos;d like to reevaluation if this limitation could be acceptable. Your thoughts? A solution is for the master to stream edits to slaves from Put, Delete, etc. post hooks via synchronous replication (or ZAB transaction). Could also be via asynchronously drained replication queues that don&apos;t block the current client operation unless full, but one should worry about increasing heap pressure.&lt;/p&gt;</comment>
                            <comment id="13048640" author="jasonrutherglen" created="Mon, 13 Jun 2011 16:39:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;A solution is for the master to stream edits to slaves from Put, Delete, etc. post hooks via synchronous replication (or ZAB transaction). Could also be via asynchronously drained replication queues that don&apos;t block the current client operation unless full, but one should worry about increasing heap pressure&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Maybe we should call this &apos;push&apos; based Coprocessor replication.  A queue would probably be necessary, as if a slave server goes down, we&apos;d want to mitigate the errant network calls.  Would the push be multi-threaded?  &lt;/p&gt;

&lt;p&gt;I think the MySQL approach is the slave(s) connect to the master, then read the transaction log starting from a given sequence id.  The Coprocessor doesn&apos;t enable that?&lt;/p&gt;</comment>
                            <comment id="13048644" author="apurtell" created="Mon, 13 Jun 2011 16:43:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think the MySQL approach is the slave(s) connect to the master, then read the transaction log starting from a given sequence id.  The Coprocessor doesn&apos;t enable that?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Coprocessors can register arbitrary RPC endpoints, so yes slaves can contact the CP on the master to drain their respective queues in a pull model.&lt;/p&gt;

</comment>
                            <comment id="13048656" author="jasonrutherglen" created="Mon, 13 Jun 2011 17:01:32 +0000"  >&lt;p&gt;@Andrew What happens if the queue is drained and the client is well behind?  I think it then falls into general recovery?  &lt;/p&gt;</comment>
                            <comment id="13048668" author="apurtell" created="Mon, 13 Jun 2011 17:48:51 +0000"  >&lt;p&gt;I&apos;d agree. If a slave finds a replica too far behind or desynchronized due to error the replica should be torn down.&lt;/p&gt;

&lt;p&gt;General recovery is then replacing a failed replica on a new slave elsewhere.&lt;/p&gt;
</comment>
                            <comment id="13048701" author="jasonrutherglen" created="Mon, 13 Jun 2011 18:37:07 +0000"  >&lt;p&gt;Sounds like the basic design is there are N slaves that connect to one master using a socket based protocol.  There will be a socket connection open per-region per slave.  The Coprocessor will place edits into a per region queue, and a separate thread will write the edits onto the slave socket connections.&lt;/p&gt;

&lt;p&gt;How will this look in Zookeeper?  Or should it function in the HMaster?&lt;/p&gt;</comment>
                            <comment id="13048710" author="apurtell" created="Mon, 13 Jun 2011 18:56:51 +0000"  >&lt;p&gt;CP Endpoints operate over HBase RPC.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Sounds like the basic design is there are N slaves that connect to one master using a socket based protocol.  There will be a socket connection open per-region per slave.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That is not how HBase RPC works. One connection between the endpoints (in this case regionserver and regionserver) is established upon demand, reaped when idle too long, and multiplexed over in the meantime.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The Coprocessor will place edits into a per region queue&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And spill the queues under heap pressure presumably. Or give up on a too laggy slave and have it killed to avoid blowing out heap in the alternative. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Or should it function in the HMaster?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No we need to think of the HMaster as always on the verge of going away to be supplanted by ZooKeeper mediated distributed actions.&lt;/p&gt;
</comment>
                            <comment id="13048716" author="jasonrutherglen" created="Mon, 13 Jun 2011 19:04:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;That is not how HBase RPC works. One connection between the endpoints (in this case regionserver and regionserver) is established upon demand, reaped when idle too long, and multiplexed over in the meantime.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok, great.  The replication master will need to examine ZK, and find out which slaves to RPC connect to.  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;And spill the queues under heap pressure presumably. Or give up on a too laggy slave and have it killed to avoid blowing out heap in the alternative&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Spilling would probably add too much complexity (eg, where would it spill to?).  I think we need to define how a slave gets too far behind, and then assume it&apos;ll need to refresh itself when it does (on a per-region basis, or does the entire RS need to recover?).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;No we need to think of the HMaster as always on the verge of going away to be supplanted by ZooKeeper mediated distributed actions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok, good to know.  Before implementing we should hammer this part of the design out.&lt;/p&gt;</comment>
                            <comment id="13050514" author="jasonrutherglen" created="Thu, 16 Jun 2011 15:58:57 +0000"  >&lt;p&gt;In a discussion about read replicas, I don&apos;t think the push model works, because it&apos;s difficult for the master to determine where a slave is at in downloading a stream of events.  Instead the slaves can read off the queue (per region)?  A slave is behind when it&apos;s sequence ID is behind the last item in the queue?  &lt;/p&gt;

&lt;p&gt;I think what&apos;s nice is HBase seems to have built in conflict resolution.  However on the slave will a Put use a local timestamp or the one on the master?&lt;/p&gt;</comment>
                            <comment id="14094525" author="apurtell" created="Tue, 12 Aug 2014 19:08:16 +0000"  >&lt;p&gt;This has been effectively superseded by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10070&quot; title=&quot;HBase read high-availability using timeline-consistent region replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10070&quot;&gt;&lt;del&gt;HBASE-10070&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12441378">HBASE-2001</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12441379">HBASE-2002</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12682280">HBASE-10070</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 27 Mar 2010 00:32:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32538</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 18 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hhen:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100082</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>