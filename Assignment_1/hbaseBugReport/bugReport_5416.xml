<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:27:32 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5416/HBASE-5416.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5416] Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5416</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;When the scan is performed, whole row is loaded into result list, after that filter (if exists) is applied to detect that row is needed.&lt;/p&gt;

&lt;p&gt;But when scan is performed on several CFs and filter checks only data from the subset of these CFs, data from CFs, not checked by a filter is not needed on a filter stage. Only when we decided to include current row. And in such case we can significantly reduce amount of IO performed by a scan, by loading only values, actually checked by a filter.&lt;/p&gt;

&lt;p&gt;For example, we have two CFs: flags and snap. Flags is quite small (bunch of megabytes) and is used to filter large entries from snap. Snap is very large (10s of GB) and it is quite costly to scan it. If we needed only rows with some flag specified, we use SingleColumnValueFilter to limit result to only small subset of region. But current implementation is loading both CFs to perform scan, when only small subset is needed.&lt;/p&gt;

&lt;p&gt;Attached patch adds one routine to Filter interface to allow filter to specify which CF is needed to it&apos;s operation. In HRegion, we separate all scanners into two groups: needed for filter and the rest (joined). When new row is considered, only needed data is loaded, filter applied, and only if filter accepts the row, rest of data is loaded. At our data, this speeds up such kind of scans 30-50 times. Also, this gives us the way to better normalize the data into separate columns by optimizing the scans performed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12542919">HBASE-5416</key>
            <summary>Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sershe">Sergey Shelukhin</assignee>
                                    <reporter username="shmuma">Max Lapan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Feb 2012 20:26:20 +0000</created>
                <updated>Thu, 29 Sep 2016 10:09:43 +0000</updated>
                            <resolved>Mon, 14 Jan 2013 23:02:28 +0000</resolved>
                                    <version>0.90.4</version>
                                    <fixVersion>0.94.5</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>Filters</component>
                    <component>Performance</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>31</watches>
                                                                                                            <comments>
                            <comment id="13209710" author="hadoopqa" created="Thu, 16 Feb 2012 20:32:30 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12514861/0001-Optimization-of-scans-using-filters.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12514861/0001-Optimization-of-scans-using-filters.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/971//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/971//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13209742" author="shmuma" created="Thu, 16 Feb 2012 21:11:59 +0000"  >&lt;p&gt;Patch against 0.90.4&lt;/p&gt;</comment>
                            <comment id="13209750" author="shmuma" created="Thu, 16 Feb 2012 21:24:17 +0000"  >&lt;p&gt;Patch against trunk.&lt;/p&gt;</comment>
                            <comment id="13209759" author="hadoopqa" created="Thu, 16 Feb 2012 21:32:26 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12514884/Filtered-scans_trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12514884/Filtered-scans_trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/973//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/973//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13209760" author="stack" created="Thu, 16 Feb 2012 21:32:41 +0000"  >&lt;p&gt;Interesting idea.  Patch looks pretty non-invasive to add some nice functionality.  Would appreciate some better doc in the filters package doc or over in the manual to accompany this change.  Nice one Max.&lt;/p&gt;

&lt;p&gt;Comments on patch:&lt;/p&gt;

&lt;p&gt;Please follow the convention you see in the surrounding file and parenthesize code blocks.  E.g. in the below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+
+  @Override
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isFamilyEssential(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] name) {
+    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Filter filter : filters)
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (filter.isFamilyEssential(name))
+        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What is a &apos;joinedScanner&apos; in the below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      List&amp;lt;KeyValueScanner&amp;gt; joinedScanners = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;KeyValueScanner&amp;gt;();

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It needs a bit of a comment I&apos;d say.&lt;/p&gt;

&lt;p&gt;Why drop the check for empty results in below?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (results.isEmpty() || filterRow()) {
+          &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; filtered = filterRow();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please submit a patch with a --no-prefix so we can see how your patch does against hadoopqa.&lt;/p&gt;</comment>
                            <comment id="13209764" author="shmuma" created="Thu, 16 Feb 2012 21:40:00 +0000"  >&lt;p&gt;Empty result is checked later, after values loaded from joinedHeap scanners. If check before load, we can lost rows when filter is SingleColumnValueExcludeFilter.&lt;/p&gt;</comment>
                            <comment id="13209768" author="nspiegelberg" created="Thu, 16 Feb 2012 21:43:57 +0000"  >&lt;p&gt;I&apos;m confused about implementation.  We already have a way to only load single CF data in a scan.  Why don&apos;t you just use a 2-phase RPC in the HBase Client where the first phase scans &apos;flag&apos; and then issues explicit multi-gets to the &apos;snap&apos; family.  Additionally, you can use bloom filters to filter out unnecessary HFiles if your doing this on an actively-written system.&lt;/p&gt;

&lt;p&gt;This sounds like an application detail or possibly coprocessor use case instead of something that should belong in the core.  Maybe I&apos;m missing something?&lt;/p&gt;</comment>
                            <comment id="13209771" author="stack" created="Thu, 16 Feb 2012 21:44:43 +0000"  >&lt;p&gt;@Max You need a test too.&lt;/p&gt;</comment>
                            <comment id="13209778" author="shmuma" created="Thu, 16 Feb 2012 21:54:56 +0000"  >&lt;p&gt;In our case, multi-gets is not a solution, because in our schema we have much more than 2 CFs (it was only the example). We have 7 CFs, and different scans are using different sets of CFs. Also, we have no prior knowlege about how many rows will be accepted by filter, so, it could be too many gets.&lt;/p&gt;

&lt;p&gt;Bloom filters also don&apos;t help much, because they filters whole files, not blocks as seek() does.&lt;/p&gt;</comment>
                            <comment id="13209782" author="shmuma" created="Thu, 16 Feb 2012 21:55:46 +0000"  >&lt;p&gt;@stack ok&lt;/p&gt;</comment>
                            <comment id="13209786" author="hadoopqa" created="Thu, 16 Feb 2012 21:59:49 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12514892/Filtered-scans_trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12514892/Filtered-scans_trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -136 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 157 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.filter.TestFilter&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/974//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/974//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/974//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/974//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/974//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/974//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13209850" author="nspiegelberg" created="Thu, 16 Feb 2012 22:50:25 +0000"  >&lt;p&gt;@Max, you can use Scan.setBatch() and Scan.setMaxResultsPerColumnFamily() to limit your batching factor to stream this operation.  The main advantage of a 1-pass solution versus 2-pass is read atomicity across CFs, but that isn&apos;t guaranteed in 90 (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2856&quot; title=&quot;TestAcidGuarantee broken on trunk &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2856&quot;&gt;&lt;del&gt;HBASE-2856&lt;/del&gt;&lt;/a&gt;).  I&apos;m just trying to think about proper API design.  Scan is an easy API to accumulate functionality.  It seems like this is emulating a server-side, 2-phase filter &amp;amp; join.&lt;/p&gt;</comment>
                            <comment id="13210041" author="shmuma" created="Fri, 17 Feb 2012 04:04:19 +0000"  >&lt;p&gt;@Nicolas: Hm, dont&apos;t understand how to implement 2-phase approach in map-reduce job, without extra complications. Also, haven&apos;t found Scan.setMaxResultsPerColumnFamily in current hbase source, only your patch for 0.89.&lt;/p&gt;

&lt;p&gt;Atomicity is not critical to us in this case - only performance and usage simplicity. &lt;/p&gt;</comment>
                            <comment id="13211887" author="shmuma" created="Mon, 20 Feb 2012 14:42:35 +0000"  >&lt;p&gt;Fixed mistake when seek() skips rows sometimes.&lt;/p&gt;

&lt;p&gt;Style fixes and extra comments.&lt;/p&gt;</comment>
                            <comment id="13211903" author="hadoopqa" created="Mon, 20 Feb 2012 15:00:07 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12515249/Filtered_scans.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12515249/Filtered_scans.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -136 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.filter.TestFilter&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/993//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/993//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/993//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/993//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/993//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/993//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13212109" author="stack" created="Mon, 20 Feb 2012 21:48:18 +0000"  >&lt;p&gt;@Max What you think about the failed TestFilter in the above? Is it your patch?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13212327" author="shmuma" created="Tue, 21 Feb 2012 03:34:00 +0000"  >&lt;p&gt;Quite probable, have plans to find this out today.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Would appreciate some better doc in the filters package doc or over in the manual to accompany this change.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I have a question about this. &quot;Manual&quot; == hbase book? And what &apos;filters package doc&apos; is? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Is it comments in source processed by javadoc, or somethinc else? Sorry for these questions - have no java experience &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                            <comment id="13212375" author="stack" created="Tue, 21 Feb 2012 05:30:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;I have a question about this. &quot;Manual&quot; == hbase book? And what &apos;filters package doc&apos; is?  Is it comments in source processed by javadoc, or somethinc else? Sorry for these questions - have no java experience .&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No problem.&lt;/p&gt;

&lt;p&gt;Yes, the &apos;reference guide&apos; or manual is this &lt;a href=&quot;http://hbase.apache.org/book.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/book.html&lt;/a&gt;  Its a bit tough making a patch for it if you don&apos;t know doc book too well so could just put a paragraph here and i&apos;ll get the doc in for you.  Or, the filters package doc I was referring to is here: &lt;a href=&quot;http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/package-summary.html#package_description&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/package-summary.html#package_description&lt;/a&gt;... but the doc here is pretty pathetic and describing this facility there might not go so well (its of a subtlety the current doc does not allow).&lt;/p&gt;

&lt;p&gt;Just stick a bit of a paragraph here and I&apos;ll figure where to put it.&lt;/p&gt;

&lt;p&gt;Go easy Max.&lt;/p&gt;

&lt;p&gt;You saw the failed test above?  The fail in TestFilter?  Do you see that when you run your tests local?  On trunk you do it so:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
% mvn test -P localTests -Dtest=TestFilter
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


</comment>
                            <comment id="13212565" author="shmuma" created="Tue, 21 Feb 2012 13:02:59 +0000"  >&lt;p&gt;Thanks for the instruction. It caused by internal filter state broken by my patch (filterRow called in wrong time). Working on that.&lt;/p&gt;</comment>
                            <comment id="13213468" author="shmuma" created="Wed, 22 Feb 2012 09:00:29 +0000"  >&lt;p&gt;The problem was a little bit tricky than I expected.&lt;/p&gt;

&lt;p&gt;The failed tests are caused by PageFilter and WhileMatchFilter expecting that filterRow method are called only once per non-empty row. Previous version of patch breaks this, so, tests are failed. I resolved this by checking that row is not empty right before filterRow(List) called, but this requires to slightly modify SingleColumnValueExcludeFilter logic - move exclude phase from filterKeyValue method to filterRow(List). The main reason for this is beacuse there is no way to distinguish at RegionScanner::nextInternal level empty row which is empty because of filter accepts row, but excludes all it&apos;s KVs and row which is empty due to filter rejects it.&lt;/p&gt;</comment>
                            <comment id="13213479" author="hadoopqa" created="Wed, 22 Feb 2012 09:18:56 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12515558/Filtered_scans_v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12515558/Filtered_scans_v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -136 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 151 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.filter.TestSingleColumnValueExcludeFilter&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1007//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1007//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1007//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1007//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1007//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1007//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13215491" author="shmuma" created="Fri, 24 Feb 2012 08:25:10 +0000"  >&lt;p&gt;Fixed all failed tests, added test for joined scanners functionality.&lt;/p&gt;</comment>
                            <comment id="13215498" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 08:40:33 +0000"  >&lt;p&gt;@Max:&lt;br/&gt;
This is a useful feature.&lt;br/&gt;
I see some typo. e.g. for Filter.isFamilyEssential():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * filters are always &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; here, but some could have more sophisticated
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;should read &apos;filters always return true&apos;.&lt;br/&gt;
You should also add @param for name parameter.&lt;/p&gt;

&lt;p&gt;Do you mind uploading latest patch onto &lt;a href=&quot;https://reviews.apache.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org&lt;/a&gt; (leaving Bugs field empty) ?&lt;br/&gt;
That would make reviewing more smoothly.&lt;/p&gt;</comment>
                            <comment id="13215501" author="thomaspan" created="Fri, 24 Feb 2012 08:50:38 +0000"  >&lt;p&gt;This really looks like a very interesting patch. Just want to add my 2 cents to verify a use case without thoroughly reviewing the whole implementation details. Here is the use case: Assume that in a table, there are two column families as CF_A and CF_B. We have MapReduce job running a scan with a SingleColumnValueFilter against CF_A:Column_1. For rows that don&apos;t contain CF_A, the code has nothing to load, thus dropping these type of rows quickly. I just want to make sure that it is case with this patch.&lt;/p&gt;</comment>
                            <comment id="13215502" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 08:51:26 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+              KeyValue nextKV = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap.peek();
+              &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) {
+                &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap.next(results, limit - results.size());
+                nextKV = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap.peek();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the first peek() isn&apos;t needed because there is another peek() inside the loop.&lt;/p&gt;</comment>
                            <comment id="13215504" author="shmuma" created="Fri, 24 Feb 2012 08:54:55 +0000"  >&lt;p&gt;@Thomas:&lt;/p&gt;

&lt;p&gt;Yes, this is the primary goal of this patch. When CF_B is large, we&apos;ll load only needed blocks from it (via seek), which could give a huge speedup in scan.&lt;/p&gt;

&lt;p&gt;@Zhihong:&lt;/p&gt;

&lt;p&gt;Thanks, I&apos;ll fix this, now waiting to jenkins results.&lt;br/&gt;
Didn&apos;t know about reviews.apache.org, thanks. I&apos;ll post there, of couse &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                            <comment id="13215519" author="hadoopqa" created="Fri, 24 Feb 2012 09:10:14 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12515904/Filtered_scans_v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12515904/Filtered_scans_v3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -133 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 155 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1041//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1041//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1041//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1041//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1041//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1041//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13215521" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 09:18:00 +0000"  >&lt;p&gt;The following line is too long:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap.seek(KeyValue.createFirstOnRow(currentRow))) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please limit to 80 chars per line.&lt;/p&gt;

&lt;p&gt;You can get Eclipse formatter from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3678&quot; title=&quot;Add Eclipse-based Apache Formatter to HBase Wiki&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3678&quot;&gt;&lt;del&gt;HBASE-3678&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13215528" author="shmuma" created="Fri, 24 Feb 2012 09:44:20 +0000"  >&lt;p&gt;Fixed comment, removed extra peek() call and folded long line.&lt;/p&gt;</comment>
                            <comment id="13215529" author="shmuma" created="Fri, 24 Feb 2012 09:46:46 +0000"  >&lt;p&gt;@Zhihong: Have trouble with post new review request - it gives 500 error. Maybe this is related with apache jira issues, will try later.&lt;/p&gt;</comment>
                            <comment id="13215550" author="shmuma" created="Fri, 24 Feb 2012 10:53:44 +0000"  >&lt;p&gt;@stack:&lt;br/&gt;
Documentation paragraph to include. I think it should go there: &lt;a href=&quot;http://hbase.apache.org/book.html#number.of.cfs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/book.html#number.of.cfs&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There&#160;is&#160;a&#160;performance&#160;option&#160;to&#160;keep&#160;in&#160;mind&#160;on&#160;schema&#160;design.&#160;In&#160;some&#160;situations,&#160;two&#160;(or&#160;more)&#160;columns&#160;family&#160;schema&#160;could&#160;be&#160;much&#160;faster&#160;than&#160;a&#160;single-CF&#160;design.&#160;It&#160;could&#160;be&#160;the&#160;case&#160;when&#160;you&#160;have&#160;one&#160;column&#160;which&#160;is&#160;used&#160;to&#160;sieve&#160;larger&#160;rows&#160;from&#160;other&#160;columns.&#160;If&#160;SingleColumnValueFilter&#160;or&#160;SingleColumnValueExcludeFilter&#160;is&#160;used&#160;to&#160;find&#160;the&#160;needed&#160;rows,&#160;only&#160;a&#160;small&#160;column&#160;is&#160;scanned,&#160;other&#160;columns&#160;are&#160;&#160;loaded&#160;only&#160;when&#160;matching&#160;row&#160;has&#160;been&#160;found.&#160;This&#160;could&#160;reduce&#160;the&#160;amount&#160;of&#160;data&#160;loaded&#160;significantly&#160;and&#160;lead&#160;to&#160;faster&#160;scans.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13215634" author="shmuma" created="Fri, 24 Feb 2012 14:37:48 +0000"  >&lt;p&gt;There is still a mistake somewhere, our stats scan return different results.&lt;/p&gt;</comment>
                            <comment id="13215643" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 14:46:06 +0000"  >&lt;p&gt;Patch v5 is based on v4, with grammatical corrections.&lt;/p&gt;

&lt;p&gt;@Max:&lt;br/&gt;
What do you think ?&lt;/p&gt;

&lt;p&gt;@Override is missing for isFamilyEssential() in a few files.&lt;/p&gt;</comment>
                            <comment id="13215677" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 15:33:44 +0000"  >&lt;p&gt;Same as patch v5.&lt;br/&gt;
I verified that patch v6 can be used to generate new review request.&lt;/p&gt;</comment>
                            <comment id="13215720" author="nspiegelberg" created="Fri, 24 Feb 2012 16:25:03 +0000"  >&lt;p&gt;Overall, I agree that this is a useful design pattern.  We use this pattern in our messages deployment and other production use cases as well.  I&apos;m more concerned about this being in the critical path.  This is deep in the core logic, which has a lot of complicated usage and is extremely bug-prone (even after extensive unit tests).&lt;/p&gt;

&lt;p&gt;If you don&apos;t need atomicity, then you don&apos;t get much benefit from solving this in the critical path.  The change introduces a lot of risk and design decisions that we have to worry about years later.  It might be some work to understand how to use a batch factor; but don&apos;t you think it would take more work to understand the variety of use cases for scans to ensure that we don&apos;t introduce side effects and make a scalable architectural decision?&lt;/p&gt;

&lt;p&gt;At the very least, we should get a scan expert to look at this code before committing.  I&apos;m not one, but I know this isn&apos;t the same as making a business logic change.  I just have one question about the patch right now:  Should we have unit tests case for ensuring the interop between this feature and &apos;limit&apos;?  For example, ensure that joinedHeap is scanned before going to the next row if the storeHeap results.size() == limit&lt;/p&gt;</comment>
                            <comment id="13215771" author="shmuma" created="Fri, 24 Feb 2012 17:42:12 +0000"  >&lt;p&gt;@Nicolas:&lt;br/&gt;
Still, have no idea how to resolve our slow scans problem different way. Two-phase rpc would be very inefficient in map-reduce job, when we need to issue lots of gets for each obtained &apos;flag&apos; row and and have no good place to save them for multi-get (which could be huge in some cases). Batching also have little help there, because slowness not caused by a large Results, but tons of useless work, performed by a regionserver on such scans. Or, maybe, I missed something?&lt;/p&gt;

&lt;p&gt;I agree that this solution is not elegant and complicates scan machinery, but all other approaches looks worse.&lt;/p&gt;</comment>
                            <comment id="13215789" author="mikhail" created="Fri, 24 Feb 2012 18:23:48 +0000"  >&lt;p&gt;@Max: if you scan the &apos;flag&apos; column family first, find the rows that you are interested in, and query only those rows from the &apos;snap&apos; column family, you will avoid the slowness from scanning every row in &apos;snap&apos;. With proper batching, the two-pass approach should work fine if you don&apos;t need atomicity.&lt;/p&gt;

&lt;p&gt;The problem with such deep changes to the scanner framework is that it would require comprehensive new unit tests. The included unit test only writes three rows and does not really check the new feature (or the old functionality) on a large scale. Take a look at TestMultiColumnScanner and TestSeekOptimizations. We will need something at least as comprehensive as those tests for this improvement, probably even a multithreaded test case to ensure we don&apos;t break atomicity. If we do not do that testing now, we will still have to do it before the next stable release, but it would be unfair to pass the hidden costs of testing to those who don&apos;t need this particular optimization right now but will soon need a stable system for another production release.&lt;/p&gt;</comment>
                            <comment id="13216009" author="kannanm" created="Fri, 24 Feb 2012 22:33:58 +0000"  >&lt;p&gt;+1 to what Mikhail said.&lt;/p&gt;

&lt;p&gt;Max--- This is an interesting use case. I will take a closer look at the changes. But, if it is indeed the case that the set of rows you need to lookup in the second CF is a small % of the total data in that CF, then issuing subsequent gets (point lookups) for the relevant keys in that CF should work reasonably well, correct? BTW, are you doing this using HTableInputFormat? Perhaps you can detail the structure of your MR job more, and we can work through some specific options.&lt;/p&gt;</comment>
                            <comment id="13216355" author="thomaspan" created="Sat, 25 Feb 2012 07:36:00 +0000"  >&lt;p&gt;Atomcity can be achieved by applying the filter set twice. I agree with Mikhail that we need to have good code quality and decent unit test coverage. Complexity in the critical path might be a concern. Performance might be another as certain use cases benefit from the approach while others don&apos;t. Thus, we could consider execution plan from the relational database world for SQL tuning. Once the data is in the table, tune the execution plan (which way to go) against particular use case(s). Just my $0.02.&lt;/p&gt;</comment>
                            <comment id="13216370" author="shmuma" created="Sat, 25 Feb 2012 08:27:14 +0000"  >&lt;p&gt;@all&lt;br/&gt;
Thanks for a discussion, I&apos;ll benchmark 2-phase approach, maybe it&apos;s a solution indeed.&lt;br/&gt;
One thing still is not clear for me: how the batching factor could improve gets performance? The get request is synchronous, isn&apos;t it? So, in mapper, I issue get to obtain value from large column, and wait for it to be ready. In fact, single get won&apos;t be significantly havier than seek in scanner, but batching seems no help there. In fact, could be wrong there, didn&apos;t experiment much with that.&lt;/p&gt;</comment>
                            <comment id="13282487" author="shmuma" created="Thu, 24 May 2012 13:16:39 +0000"  >&lt;p&gt;Fixed issues with limits in next() call.&lt;/p&gt;</comment>
                            <comment id="13282495" author="hadoopqa" created="Thu, 24 May 2012 13:23:27 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12529061/Filtered_scans_v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12529061/Filtered_scans_v5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1982//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1982//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13282497" author="shmuma" created="Thu, 24 May 2012 13:23:38 +0000"  >&lt;p&gt;After a long delay, I decided to return to this optimization.&lt;br/&gt;
We have this patch on our production system (300TB HBase data, 160 nodes) during last two months without issues. 2-phase approach tests demonstrated much worse performance improvement over this patch - only 2 times speedup vs near 20 times.&lt;/p&gt;

&lt;p&gt;I extended tests, but don&apos;t feel myself experienced enougth to implement concurrent, multithread test as suggested, sorry. &lt;/p&gt;</comment>
                            <comment id="13282520" author="zhihyu@ebaysf.com" created="Thu, 24 May 2012 14:25:48 +0000"  >&lt;p&gt;@Max:&lt;br/&gt;
The new patch is much larger than previous version. Can you provide more detailed description on the change ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13282528" author="shmuma" created="Thu, 24 May 2012 14:38:23 +0000"  >&lt;p&gt;Additional code handled the case when InternalScanner::next called with limit != -1. In this case, we must remember KeyValueHeap we populated when limit reached, and restart this population on next method issue.&lt;/p&gt;

&lt;p&gt;I also added a test case for such situation.&lt;/p&gt;</comment>
                            <comment id="13282534" author="zhihyu@ebaysf.com" created="Thu, 24 May 2012 14:45:01 +0000"  >&lt;p&gt;Will go over the patch when I get into office.&lt;/p&gt;

&lt;p&gt;It would be nice to use &lt;a href=&quot;https://reviews.apache.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org&lt;/a&gt; to facilitate reviews.&lt;/p&gt;</comment>
                            <comment id="13282539" author="shmuma" created="Thu, 24 May 2012 14:49:54 +0000"  >&lt;p&gt;I tried to post it there, but constantly get Internal server error.&lt;/p&gt;</comment>
                            <comment id="13282543" author="shmuma" created="Thu, 24 May 2012 14:55:36 +0000"  >&lt;p&gt;Ahhh, I&apos;m stupid, it works with hbase-git repository. Posted &lt;a href=&quot;https://reviews.apache.org/r/5225/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/5225/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13283329" author="shmuma" created="Fri, 25 May 2012 12:08:01 +0000"  >&lt;p&gt;Fixed issues with incorrect rebase, applied suggested changes from first review.&lt;/p&gt;</comment>
                            <comment id="13283357" author="hadoopqa" created="Fri, 25 May 2012 12:56:54 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12529706/Filtered_scans_v5.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12529706/Filtered_scans_v5.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop23.  The patch compiles against the hadoop 0.23.x profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 33 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestRegionRebalancing&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1994//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1994//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1994//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1994//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1994//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1994//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13288196" author="zhihyu@ebaysf.com" created="Sun, 3 Jun 2012 16:36:56 +0000"  >&lt;p&gt;Rebased Max&apos;s latest patch on trunk.&lt;/p&gt;</comment>
                            <comment id="13288212" author="hadoopqa" created="Sun, 3 Jun 2012 17:24:11 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12530695/5416-Filtered_scans_v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12530695/5416-Filtered_scans_v6.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to cause Findbugs (version 1.3.9) to fail.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestSplitLogManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2094//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2094//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2094//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2094//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13288230" author="hadoopqa" created="Sun, 3 Jun 2012 18:37:59 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12530699/5416-Filtered_scans_v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12530699/5416-Filtered_scans_v6.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestSplitLogManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2095//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13404947" author="shmuma" created="Mon, 2 Jul 2012 08:52:48 +0000"  >&lt;p&gt;Implemented benchmark of joined scanners.&lt;br/&gt;
You can run it with &lt;tt&gt;mvn test -P localTests --Dtest=TestJoinedScanners&lt;/tt&gt;. It lasts for about an hour, so, don&apos;t foreget to increase &lt;tt&gt;forkedProcessTimeoutInSeconds&lt;/tt&gt; it pom.xml file.&lt;/p&gt;

&lt;p&gt;On my notebook I got the following output:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2012-06-29 22:12:00,182 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(102): Make 100000 rows, total size = 9765.0 MB&lt;br/&gt;
2012-06-29 22:56:51,231 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(128): Data generated in 2691.048310914 seconds&lt;br/&gt;
2012-06-29 23:03:03,865 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(152): Slow scanner finished in 372.634075184 seconds, got 1000 rows&lt;br/&gt;
2012-06-29 23:04:02,443 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(172): Joined scanner finished in 58.577552657 seconds, got 1000 rows&lt;br/&gt;
2012-06-29 23:09:41,837 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(195): Slow scanner finished in 339.394307354 seconds, got 1000 rows&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I run slow scanners test twice to be sure that it&apos;s not a cache effect. So, it&apos;s about 5.7 times speedup on this toy data.&lt;/p&gt;</comment>
                            <comment id="13405062" author="zhihyu@ebaysf.com" created="Mon, 2 Jul 2012 13:23:08 +0000"  >&lt;p&gt;@Andrew, @Mikhail:&lt;br/&gt;
What do you think of the performance comparison shown above ?&lt;/p&gt;</comment>
                            <comment id="13415879" author="zhihyu@ebaysf.com" created="Tue, 17 Jul 2012 04:04:15 +0000"  >&lt;p&gt;I ran TestJoinedScanners on Linux and observed the following in test output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2012-07-16 17:31:52,339 INFO  [main] regionserver.TestJoinedScanners(152): Slow scanner finished in 96.393137286 seconds, got 1000 rows
...
2012-07-16 17:32:05,026 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 12.687607287 seconds, got 1000 rows
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13428614" author="zhihyu@ebaysf.com" created="Sat, 4 Aug 2012 14:32:21 +0000"  >&lt;p&gt;Can I assume that there is no further review comment for this feature ?&lt;/p&gt;</comment>
                            <comment id="13484497" author="sershe" created="Thu, 25 Oct 2012 21:28:08 +0000"  >&lt;p&gt;Hi. Should this be ok to commit to trunk? Thanks.&lt;/p&gt;</comment>
                            <comment id="13484783" author="anoopsamjohn" created="Fri, 26 Oct 2012 08:18:38 +0000"  >&lt;p&gt;I got a chance to go throw this and the discussion around&lt;br/&gt;
@Max clearly it is a good idea. Improvement in your scenario will be huge..&lt;br/&gt;
The concerns about the change is worth considering I guess. It is very critical path..&lt;br/&gt;
I have one idea for you to solve the problem with out 2 phase RPC&lt;br/&gt;
How about the below way?&lt;br/&gt;
eg: I have one table with 2 CFs(cf1, cf2) I have a SCVF condition on cf1 (cf1:c1=v1)&lt;br/&gt;
1. Create a Scan from the client side with only cf1 specified and with the filter&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
SingleColumnValueFilter filter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SingleColumnValueFilter(cf1, c1,
        CompareOp.EQUAL, v1);
Scan scan = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Scan();
scan.setFilter(filter);
scan.addFamily(cf1);
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Result result : ht.getScanner(scan)){
&lt;span class=&quot;code-comment&quot;&gt;// deal with result
&lt;/span&gt;}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;2. Implement a RegionObserver CP and implement the preScannerNext() hook.. This hook execution will happen within the server&lt;br/&gt;
In the hook for every rowkey which the scan selects, create a Get request with CF specified as the remaining CFs and add those KVs also to the Result&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; postScannerNext(ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; e,
      InternalScanner s, List&amp;lt;Result&amp;gt; results, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; limit, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; hasMore) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-comment&quot;&gt;// Next call happen on one region from HRS
&lt;/span&gt;    HRegion region = e.getEnvironment().getRegion();
    List&amp;lt;Result&amp;gt; finalResults = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;Result&amp;gt;(results.size());
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Result result : results) {
      &lt;span class=&quot;code-comment&quot;&gt;// Every result corresponds to one row.. Assume there is no batching being used
&lt;/span&gt;      &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] row = result.getRow();
      Get get = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Get(row);
      get.addFamily(cf2);&lt;span class=&quot;code-comment&quot;&gt;// cf1 is already fetched
&lt;/span&gt;      Result result2 = region.get(get, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
      List&amp;lt;KeyValue&amp;gt; finalKVs = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;KeyValue&amp;gt;();
      finalKVs.addAll(result.list());
      finalKVs.addAll(result2.list());
      finalResults.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Result(finalKVs));
    }
    &lt;span class=&quot;code-comment&quot;&gt;// replace the results with the &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; finalResults
&lt;/span&gt;    results.clear();
    results.addAll(finalResults);
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; hasMore;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This hook is at the HRS level and after the Result object preperation. Right now we dont have any other hook during the scanner next() calls down the line so that we can deal with the KVs list.. So we need to recreate the Result and some ugly way of coding...&lt;br/&gt;
This way it should be possible to fetch the data what you want. May be not as optimal as the way with the internal change.. But still be far far better than the 2 RPC calls...&lt;br/&gt;
Now with CP we can achieve many things..&lt;/p&gt;</comment>
                            <comment id="13484842" author="shmuma" created="Fri, 26 Oct 2012 10:47:40 +0000"  >&lt;p&gt;Yes, I think CP will work, thanks. The sad thing is that we use 0.90.6 (CDH) version of HBase, which don&apos;t have CPs. In fact, we use this patch on our production system without major issues and quite happy with it. But I don&apos;t think it&apos;s a good idea to include it in trunk, when much better approach exists. &lt;/p&gt;</comment>
                            <comment id="13486195" author="sershe" created="Mon, 29 Oct 2012 17:48:27 +0000"  >&lt;p&gt;I am not very familiar with the actual user scenarios of many HBase users yet, but the example outlined above (filter on small column, get big column only as needed) seems very general.&lt;br/&gt;
Am I missing something?&lt;br/&gt;
For any media (images/videos/documents)/binary storage, where contents don&apos;t change that often, that is a straightforward and legitimate perf boost.&lt;br/&gt;
Maybe this can be made optional, with old behavior as default?&lt;br/&gt;
CP approach seems kind of hacky for everyone to re-implement.&lt;/p&gt;</comment>
                            <comment id="13486327" author="zhihyu@ebaysf.com" created="Mon, 29 Oct 2012 20:43:15 +0000"  >&lt;p&gt;I agree with Sergey&apos;s point above.&lt;/p&gt;</comment>
                            <comment id="13486649" author="anoopsamjohn" created="Tue, 30 Oct 2012 04:56:59 +0000"  >&lt;p&gt;Sergey and Ted&lt;br/&gt;
I do agree 100% that it is a great idea. I think that this is some thing the core can do rather than asking users to do..&lt;/p&gt;</comment>
                            <comment id="13486651" author="anoopsamjohn" created="Tue, 30 Oct 2012 04:59:48 +0000"  >&lt;p&gt;My only point was that it is possible using CP.. Above I have seen only people suggesting ways with 2 level RPCs..  So this solution came to my mind, I was just expressing so that people in need can get a solution way. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
I agree that it is a kind of hacky.. It is ugly code also &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
</comment>
                            <comment id="13492064" author="sershe" created="Wed, 7 Nov 2012 02:12:52 +0000"  >&lt;p&gt;Hmm... then, are there other specific objections/disagreement with the above, or should we proceed with the patch? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13492173" author="shmuma" created="Wed, 7 Nov 2012 07:18:41 +0000"  >&lt;p&gt;If no one against inclusion, let&apos;s include it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. But I have a small improvement to do. Personally, I don&apos;t like filters interface alteration. When I started, I thought that it would be more filters to conform to optimization, but only SingleColumnValueFiler and SingleColumnValueFilter are. So, I&apos;d better to just check for these filters in HRegionScanner than introduce extra method in interface.&lt;/p&gt;</comment>
                            <comment id="13492718" author="stack" created="Wed, 7 Nov 2012 21:27:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; See the concerns raised above by the likes of Nicolas and Mikhail where this patch messes in critical code path and so we should be careful committing it ensuring first sufficient test coverage and no degradation in perf.&lt;/p&gt;</comment>
                            <comment id="13493399" author="sershe" created="Thu, 8 Nov 2012 19:10:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; My point was that the approach is sound and that change being risky is not a good reason to not make it, on its own. +1 on tests/perf tests &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13493410" author="stack" created="Thu, 8 Nov 2012 19:16:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; If after sufficient tests (and perf), for sure.  I think the case that the change has sufficient test needs to be built before it goes in.&lt;/p&gt;</comment>
                            <comment id="13530584" author="sershe" created="Thu, 13 Dec 2012 01:29:12 +0000"  >&lt;p&gt;I&apos;ve rebased the latest patch (not sure if I did it right, code changed around there) and the new large test now times out on my machine... I will look into it further.&lt;/p&gt;</comment>
                            <comment id="13530714" author="shmuma" created="Thu, 13 Dec 2012 06:04:37 +0000"  >&lt;p&gt;Have you increased forkedProcessTimeoutInSeconds option it pom.xml?&lt;/p&gt;</comment>
                            <comment id="13531492" author="sershe" created="Thu, 13 Dec 2012 20:51:33 +0000"  >&lt;p&gt;Hmm, no... let me try with increased. Should this setting be set in the patch too? This test is going to run with other tests every time I assume.&lt;/p&gt;</comment>
                            <comment id="13531586" author="sershe" created="Thu, 13 Dec 2012 22:33:17 +0000"  >&lt;p&gt;With default setting, I got tired of waiting for it after an ~hour and canceled it. I think it was still inserting rows, although my laptop drive was extreley sluggish so maybe logs haven&apos;t flushed so I didn&apos;t see &quot;Data inserted&quot; log message.&lt;br/&gt;
However, after changing the number of writes to 5k, I get very impressive performance improvement:&lt;br/&gt;
2012-12-13 14:25:48,699 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(155): Slow scanner finished in 5.15852 seconds, got 50 rows&lt;br/&gt;
...&lt;br/&gt;
2012-12-13 14:25:48,931 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; regionserver.TestJoinedScanners(175): Joined scanner finished in 0.231946 seconds, got 50 rows&lt;/p&gt;

&lt;p&gt;It looks like it would be a good idea from perf standpoint to include this in trunk.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shmuma&quot; class=&quot;user-hover&quot; rel=&quot;shmuma&quot;&gt;Max Lapan&lt;/a&gt; do you want to continue on the patch? Otherwise I can continue on it.&lt;br/&gt;
I think we&apos;d want to make it optional (in config and/or per request) to address some of the stability concerns.&lt;br/&gt;
I want to look at patch in more detail too to see what more testing can be done. It seems like maybe two LoadTestTool-s writing and verifying against the same table in parallel could be used, or something, in an integration test.&lt;/p&gt;

&lt;p&gt;I get &quot;Filter with filterRow(List&amp;lt;KeyValue&amp;gt;) incompatible with scan with limit!&quot; in testScanner_JoinedScannersAndLimits after rebase, I&apos;ll look into it.&lt;/p&gt;</comment>
                            <comment id="13531923" author="sershe" created="Fri, 14 Dec 2012 02:24:09 +0000"  >&lt;p&gt;Hmm, on reruns, I cannot repro the gains above on small datasets. However I see difference in IO activity during slow and joined scanner &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13531950" author="sershe" created="Fri, 14 Dec 2012 03:31:27 +0000"  >&lt;p&gt;Ok, here&apos;s the rebased patch, mvn test appears to pass at least small tests, rest are running now. &lt;br/&gt;
Can you please sanity check?&lt;/p&gt;

&lt;p&gt;I modified the perf test to run within normal test time and to run scan 10 times (at least on my laptop most of the time is taken by load, due to compactions probably). When it settles after 1-2 iterations, I see perf improvement, about 20-25% on small dataset.&lt;/p&gt;

&lt;p&gt;Tomorrow I will probably look at config/more tests.&lt;/p&gt;</comment>
                            <comment id="13532037" author="yuzhihong@gmail.com" created="Fri, 14 Dec 2012 04:28:28 +0000"  >&lt;p&gt;Based on patch v7, I got the following result on MacBook:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
grep &apos;scanner finished in&apos; ../testJoinedScanners-output.txt
2012-12-13 20:09:26,809 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 112.792634 seconds, got 100 rows
2012-12-13 20:10:15,726 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 48.915989 seconds, got 100 rows
2012-12-13 20:10:33,006 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 17.280432 seconds, got 100 rows
2012-12-13 20:10:38,514 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 5.508207 seconds, got 100 rows
2012-12-13 20:10:51,095 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 12.580323 seconds, got 100 rows
2012-12-13 20:11:00,517 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 9.422024 seconds, got 100 rows
2012-12-13 20:11:22,650 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 22.132854 seconds, got 100 rows
2012-12-13 20:11:31,890 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 9.23955 seconds, got 100 rows
2012-12-13 20:11:34,421 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 2.531598 seconds, got 100 rows
2012-12-13 20:11:36,694 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 2.272578 seconds, got 100 rows
2012-12-13 20:11:39,197 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 2.502777 seconds, got 100 rows
2012-12-13 20:11:58,269 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 19.071438 seconds, got 100 rows
2012-12-13 20:12:01,043 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 2.774262 seconds, got 100 rows
2012-12-13 20:12:03,317 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 2.273745 seconds, got 100 rows
2012-12-13 20:12:05,981 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 2.664124 seconds, got 100 rows
2012-12-13 20:12:08,574 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 2.593234 seconds, got 100 rows
2012-12-13 20:12:11,130 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 2.555977 seconds, got 100 rows
2012-12-13 20:12:13,381 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 2.250275 seconds, got 100 rows
2012-12-13 20:12:15,721 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 2.340003 seconds, got 100 rows
2012-12-13 20:12:18,075 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 2.354218 seconds, got 100 rows
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I am running the test on Linux.&lt;/p&gt;

&lt;p&gt;Will take another look at the patch and test result tomorrow.&lt;/p&gt;</comment>
                            <comment id="13532040" author="yuzhihong@gmail.com" created="Fri, 14 Dec 2012 04:39:12 +0000"  >&lt;p&gt;Here is test result from Linux:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
grep &apos;scanner finished in&apos; testJoinedScanners-output.txt
2012-12-13 20:28:36,780 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 29.421479079 seconds, got 100 rows
2012-12-13 20:28:47,617 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 10.836890451 seconds, got 100 rows
2012-12-13 20:28:58,637 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 11.019543361 seconds, got 100 rows
2012-12-13 20:29:07,865 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 9.227820454 seconds, got 100 rows
2012-12-13 20:29:17,690 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 9.824966218 seconds, got 100 rows
2012-12-13 20:29:26,317 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 8.626794601 seconds, got 100 rows
2012-12-13 20:29:36,288 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 9.97033987 seconds, got 100 rows
2012-12-13 20:29:45,033 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 8.745137076 seconds, got 100 rows
2012-12-13 20:29:55,023 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 9.989630848 seconds, got 100 rows
2012-12-13 20:30:03,416 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 8.392952897 seconds, got 100 rows
2012-12-13 20:30:12,267 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 8.850649054 seconds, got 100 rows
2012-12-13 20:30:20,985 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 8.718266736 seconds, got 100 rows
2012-12-13 20:30:30,108 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 9.122057799 seconds, got 100 rows
2012-12-13 20:30:38,669 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 8.561782079 seconds, got 100 rows
2012-12-13 20:30:47,898 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 9.228045508 seconds, got 100 rows
2012-12-13 20:30:57,057 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 9.158965127 seconds, got 100 rows
2012-12-13 20:31:07,428 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 10.370526135 seconds, got 100 rows
2012-12-13 20:31:16,586 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 9.157627332 seconds, got 100 rows
2012-12-13 20:31:25,612 INFO  [main] regionserver.TestJoinedScanners(172): Slow scanner finished in 9.026821302 seconds, got 100 rows
2012-12-13 20:31:34,553 INFO  [main] regionserver.TestJoinedScanners(172): Joined scanner finished in 8.93992941 seconds, got 100 rows
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13532055" author="yuzhihong@gmail.com" created="Fri, 14 Dec 2012 05:10:51 +0000"  >&lt;p&gt;There is significant performance gain for Joined scanner in the first few iterations.&lt;br/&gt;
The test generates data and then runs scans alternately using normal and joined scanners. I think we should test scenarios where write and scan operations interleave.&lt;/p&gt;</comment>
                            <comment id="13532110" author="hadoopqa" created="Fri, 14 Dec 2012 06:59:15 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12560912/HBASE-5416-v7-rebased.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12560912/HBASE-5416-v7-rebased.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any additional warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 23 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3542//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13532465" author="yuzhihong@gmail.com" created="Fri, 14 Dec 2012 17:16:31 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
     KeyValueHeap storeHeap = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
+    KeyValueHeap joinedHeap = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Add a comment explaining the role of joinedHeap.&lt;br/&gt;
joinedHeap is only referenced in RegionScannerImpl. So it can be private.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// state flag which indicates when joined heap data gather interrupted due to scan limits&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;data gather interrupted&apos; -&amp;gt; &apos;data gathering is interrupted&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-comment&quot;&gt;// Here we separate all scanners into two lists - first is scanners,
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// providing data required by the filter to operate (scanners list) and&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;first is scanners, providing&apos; -&amp;gt; &apos;first are scanners that provide&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+     * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; limit reached, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; ovewise.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;ovewise&apos; -&amp;gt; &apos;otherwise&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isEmptyRow /* TODO: || filterRow() is gone in trunk */) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can the TODO be removed ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
           }
+          &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: lift else to follow }&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+                &lt;span class=&quot;code-comment&quot;&gt;// As the data obtained from two independent heaps, we need to&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;the data obtained&apos; -&amp;gt; &apos;the data is obtained&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+                &lt;span class=&quot;code-comment&quot;&gt;// Result list population was interrupted by limits, we need to restart it on next() invocation.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: wrap long line.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+            &lt;span class=&quot;code-comment&quot;&gt;// the &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; when SingleValueExcludeFilter is used.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;SingleValueExcludeFilter&apos; -&amp;gt; &apos;SingleColumnValueExcludeFilter&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; KeyValue peekKv() {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeapHasMoreData ? &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap.peek() : &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeHeap.peek();
+    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above method is only called once. Consider merging the body into caller.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testScanner_JoinedScannersAndLimits() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: JoinedScannersAndLimits -&amp;gt; JoinedScannersWithLimits&lt;/p&gt;

&lt;p&gt;For TestJoinedScanners.java, remove year in license header.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Make &quot;&lt;/span&gt; + &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.toString(rows_to_insert) + &lt;span class=&quot;code-quote&quot;&gt;&quot; rows, total size = &quot;&lt;/span&gt; + &lt;span class=&quot;code-object&quot;&gt;Float&lt;/span&gt;.toString(rows_to_insert * large_bytes / 1024 / 1024) + &lt;span class=&quot;code-quote&quot;&gt;&quot; MB&quot;&lt;/span&gt;);
...
+      LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Data generated in &quot;&lt;/span&gt; + &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;.toString((&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() - time) / 1000000000.0) + &lt;span class=&quot;code-quote&quot;&gt;&quot; seconds&quot;&lt;/span&gt;);
...
+    SingleColumnValueFilter flt = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SingleColumnValueFilter(cf_essential, col_name, CompareFilter.CompareOp.EQUAL, flag_yes);
...
+      + &lt;span class=&quot;code-quote&quot;&gt;&quot; scanner finished in &quot;&lt;/span&gt; + &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;.toString(timeSec) + &lt;span class=&quot;code-quote&quot;&gt;&quot; seconds, got &quot;&lt;/span&gt; + &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.toString(rows_count/2) + &lt;span class=&quot;code-quote&quot;&gt;&quot; rows&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: wrap long line&lt;/p&gt;</comment>
                            <comment id="13532531" author="sershe" created="Fri, 14 Dec 2012 18:34:14 +0000"  >&lt;p&gt;I wonder if it could be the issue with the rebase, or with changes to trunk after the last patch; or if 100k rows are needed to show improvement?&lt;br/&gt;
I get similar results now.&lt;br/&gt;
Need to add some logging to see if the new code paths are actually being run.&lt;/p&gt;</comment>
                            <comment id="13532583" author="sershe" created="Fri, 14 Dec 2012 19:42:13 +0000"  >&lt;p&gt;Looks like scanner serialization issue, probably due to PB, I&apos;ll update the patch.&lt;/p&gt;</comment>
                            <comment id="13532584" author="sershe" created="Fri, 14 Dec 2012 19:42:35 +0000"  >&lt;p&gt;...or maybe not. Hmm&lt;/p&gt;</comment>
                            <comment id="13532604" author="sershe" created="Fri, 14 Dec 2012 19:58:21 +0000"  >&lt;p&gt;ok I fixed it, patch coming after lunch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13532827" author="sershe" created="Sat, 15 Dec 2012 00:26:33 +0000"  >&lt;p&gt;Patch: fix issues with rebase; test modifications compared to v7 patch as outlined above; make configurable globally and per request (and per table when &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7236&quot; title=&quot;add per-table/per-cf configuration via metadata&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7236&quot;&gt;&lt;del&gt;HBASE-7236&lt;/del&gt;&lt;/a&gt; goes in &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;).&lt;br/&gt;
With this patch I get the perf gains back on my laptop.&lt;/p&gt;</comment>
                            <comment id="13532856" author="yuzhihong@gmail.com" created="Sat, 15 Dec 2012 01:03:56 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; KeyValue createFirstOnRow(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] row, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; roffset, &lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt; rlength) {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, roffset, rlength,
+        &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, 0, 0, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, 0, 0, HConstants.LATEST_TIMESTAMP, Type.Minimum, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, 0, 0);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The other createFirstOnRow() methods use Type.Maximum&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;enum&lt;/span&gt; LazyCfLoadingValue {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above enum is a tri-state boolean. I think using Boolean should suffice.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// Heap of key-values that are not necessary &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the provided filters and are thus read
&lt;/span&gt;+    &lt;span class=&quot;code-comment&quot;&gt;// on demand, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; lazy cf loading is enabled.
&lt;/span&gt;+    KeyValueHeap joinedHeap = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;not necessary&apos; -&amp;gt; &apos;not essential&apos;&lt;br/&gt;
&apos;cf loading&apos; -&amp;gt; &apos;column family loading&apos;&lt;/p&gt;</comment>
                            <comment id="13532918" author="hadoopqa" created="Sat, 15 Dec 2012 03:06:53 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12561070/HBASE-5416-v8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12561070/HBASE-5416-v8.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any additional warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 26 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3556//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13532937" author="yuzhihong@gmail.com" created="Sat, 15 Dec 2012 05:07:32 +0000"  >&lt;p&gt;I ran test suite with the following change based on patch v8:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; KeyValue createFirstOnRow(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] row, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; roffset, &lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt; rlength) {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, roffset, rlength,
+        &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, 0, 0, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, 0, 0, HConstants.LATEST_TIMESTAMP, Type.Maximum, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, 0, 0);
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I got:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[INFO] HBase ............................................. SUCCESS [3.012s]
[INFO] HBase - Common .................................... SUCCESS [14.056s]
[INFO] HBase - Protocol .................................. SUCCESS [13.557s]
[INFO] HBase - Client .................................... SUCCESS [0.654s]
[INFO] HBase - Hadoop Compatibility ...................... SUCCESS [0.733s]
[INFO] HBase - Hadoop One Compatibility .................. SUCCESS [1.753s]
[INFO] HBase - Server .................................... SUCCESS [44:06.793s]
[INFO] HBase - Hadoop Two Compatibility .................. SUCCESS [9.770s]
[INFO] HBase - Integration Tests ......................... SUCCESS [3.340s]
[INFO] HBase - Examples .................................. SUCCESS [30.981s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For TestJoinedScanners:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2012-12-14 19:40:01,764 INFO  [pool-1-thread-1] regionserver.TestJoinedScanners(168): Slow scanner finished in 31.798885086 seconds, got 100 rows
2012-12-14 19:40:03,710 INFO  [pool-1-thread-1] regionserver.TestJoinedScanners(168): Joined scanner finished in 1.946100741 seconds, got 100 rows
...
2012-12-14 19:43:29,757 INFO  [pool-1-thread-1] regionserver.TestJoinedScanners(168): Slow scanner finished in 44.846782189 seconds, got 100 rows
2012-12-14 19:43:31,871 INFO  [pool-1-thread-1] regionserver.TestJoinedScanners(168): Joined scanner finished in 2.11452886 seconds, got 100 rows
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13534158" author="sershe" created="Mon, 17 Dec 2012 18:50:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;The above enum is a tri-state boolean. I think using Boolean should suffice.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Imho the Boolean is not as expressive... I did Boolean first then replaced with enum because the null checks looked sketchy.&lt;br/&gt;
I guess I can replace it back if there&apos;s strong opinion.&lt;/p&gt;

&lt;p&gt;Rest fixed.&lt;/p&gt;</comment>
                            <comment id="13534293" author="hadoopqa" created="Mon, 17 Dec 2012 20:54:49 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12561329/HBASE-5416-v9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12561329/HBASE-5416-v9.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any additional warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 26 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are zombie tests. See build logs for details.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3573//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13534606" author="sershe" created="Tue, 18 Dec 2012 03:48:24 +0000"  >&lt;p&gt;I have an integration test for this which I will probably put in separate JIRA. It would do repeated scans and verification specific to this feature plus similar to MultiThreadedReader while multiple writer threads are running. Need to check whether it works &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Any other updates on the patch/requirements if it works?&lt;br/&gt;
Thanks. &lt;/p&gt;</comment>
                            <comment id="13534750" author="shmuma" created="Tue, 18 Dec 2012 08:23:58 +0000"  >&lt;p&gt;Hi!&lt;/p&gt;

&lt;p&gt;The patch misses one small fix I made this summer (foregot to post it here, sorry). It is trivial in code, but a little tricky in logic.&lt;/p&gt;

&lt;p&gt;The problem is in SingleColumnValueFilter with filterIfMissing=false (default). In that case, filter must allow records with filtered columns not present in row. But this performance optimisation have no way to detect such rows, because we first scan CFs added to filters. So, it can miss these rows completely in a result. The solution is quite simple - turn off optimisation when filterIfMissing is false.&lt;/p&gt;

&lt;p&gt;My patch for 0.90.6, could you, please, apply it?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
commit 66b32a09e59fe12bfab55e819336678114269bb8
Author: Max Lapan &amp;lt;max.lapan@gmail.com&amp;gt;
Date:   Thu Aug 30 17:22:45 2012 +0400

    Disable fast scans when filterIfMissed=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;

diff --git a/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java b/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java
index 105009e..2983a5f 100644
--- a/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java
+++ b/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java
@@ -276,9 +276,14 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class SingleColumnValueFilter &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FilterBase {
 
   /**
    * The only thing &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; filter need to check row is given column family. So,
-   * it&apos;s the only essential column in whole scan.
+   * it&apos;s the only essential column in whole scan. If filterIfMissing==&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;,
+   * all families are essential, because of a possibility to skip valid rows
+   * without data in filtered CF.
    */
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isFamilyEssential(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] name) {
-    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Bytes.equals(name, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.columnFamily);
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filterIfMissing)
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
+    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Bytes.equals(name, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.columnFamily);
   }
 }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13535357" author="sershe" created="Tue, 18 Dec 2012 21:32:49 +0000"  >&lt;p&gt;Hi, I will incorporate that.&lt;/p&gt;</comment>
                            <comment id="13535480" author="sershe" created="Tue, 18 Dec 2012 23:58:48 +0000"  >&lt;p&gt;Finding from integration test - if scan is running concurrently with splits and with more than 2 column families, column families can be lost.&lt;br/&gt;
I run the same test with table pre-split into 20 regions, and it passes all the time. &lt;br/&gt;
Run it again with table pre-split into 5 region, causing splits and it fails when it can only find 2 column families out of 3 for one row or another.&lt;br/&gt;
Max: is this part of acceptable inconsistency that was discussed above? I understand this can be a valid scenario (speedup is huge at the cost of very few (or none if pre-split) easily recoverable errors), but just wonder if you are aware of that...&lt;/p&gt;</comment>
                            <comment id="13535501" author="sershe" created="Wed, 19 Dec 2012 00:29:21 +0000"  >&lt;p&gt;Integration test attached to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7383&quot; title=&quot;create integration test for HBASE-5416 (improving scan performance for certain filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7383&quot;&gt;&lt;del&gt;HBASE-7383&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13535502" author="sershe" created="Wed, 19 Dec 2012 00:31:07 +0000"  >&lt;p&gt;Patch v10: expanded comment, incorporated latest suggestion.&lt;/p&gt;</comment>
                            <comment id="13535543" author="hadoopqa" created="Wed, 19 Dec 2012 01:26:33 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12561614/HBASE-5416-v10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12561614/HBASE-5416-v10.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 28 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 232 release audit warnings (more than the trunk&apos;s current 84 warnings).&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.TestDrainingServer&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are zombie tests. See build logs for details.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3601//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13536069" author="shmuma" created="Wed, 19 Dec 2012 16:07:50 +0000"  >&lt;p&gt;&amp;gt; is this part of acceptable inconsistency that was discussed above? I understand this can be a valid scenario (speedup is huge at the cost of very few (or none if pre-split) easily recoverable errors), but just wonder if you are aware of that...&lt;/p&gt;

&lt;p&gt;No. It is very strange, because spliting process is handled on lower level of Store class and should be transparent to HRegion level (at least in 0.90.6 codebase, maybe something changed dramatically). In our production split is quite common operation, run without issues. We had one problem (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6499&quot; title=&quot;StoreScanner&amp;#39;s QueryMatcher not reset on store update&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6499&quot;&gt;&lt;del&gt;HBASE-6499&lt;/del&gt;&lt;/a&gt;), which was caused by no one calling seek/reseek frequently, it may be similiar issue.&lt;/p&gt;</comment>
                            <comment id="13536211" author="ram_krish" created="Wed, 19 Dec 2012 18:07:59 +0000"  >&lt;p&gt;Some initial comments&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
getAllowLazyCfLoadingRaw(), getAllowLazyCfLoading()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It can be renamed better?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;enum&lt;/span&gt; LazyCfLoadingValue 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Enum constants can be in CAPS.&lt;/p&gt;</comment>
                            <comment id="13536236" author="sershe" created="Wed, 19 Dec 2012 18:20:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shmuma&quot; class=&quot;user-hover&quot; rel=&quot;shmuma&quot;&gt;Max Lapan&lt;/a&gt; I actually had to change (re)seek during rebase, can you take a look if there&apos;s some error there? Other than that, I attached the test to linked JIRA, I can repro it consistently by changing the initial regions-per-server constant in the test to low value (1-5). &lt;/p&gt;</comment>
                            <comment id="13536238" author="sershe" created="Wed, 19 Dec 2012 18:21:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Thanks!&lt;/p&gt;</comment>
                            <comment id="13536316" author="jxiang" created="Wed, 19 Dec 2012 19:05:11 +0000"  >&lt;p&gt;I have not looked into the change to the critical core part.  For the pb related, I think we don&apos;t need the LazyCfLoadingValue enum.  If not set, it means&lt;br/&gt;
disabled.&lt;/p&gt;

&lt;p&gt;It will be helpful to put the patch on the RB.&lt;/p&gt;</comment>
                            <comment id="13536425" author="stack" created="Wed, 19 Dec 2012 21:03:45 +0000"  >&lt;p&gt;I do not see enough by way of tests yet to allay strong concerns raised above about intrusiveness of this patch.  There is a bunch of new code in here in HRegion scanning.   It is not all excluded if new feature flag is not set.  I&apos;ve not reviewed the changes in here closely (it is not a critical nor a blocker issue so is secondary to my thinking).  I do not see evidence of close review by others.  Has it been done?&lt;/p&gt;

&lt;p&gt;This changes Filter Interface so 0.96 only (as said above).&lt;/p&gt;

&lt;p&gt;+   * This can deliver huge perf gains when there&apos;s a cf with lots of data; however, it can&lt;br/&gt;
+   * also lead to some inconsistent results (e.g. due to concurrent updates, or splits).&lt;/p&gt;

&lt;p&gt;Can we have more detail on what the inconsistency referred to above is about?&lt;/p&gt;

&lt;p&gt;What is happening in SingleColumnValueExcludeFilter?  We are removing filterKeyValue and putting in place filterRow and hasFilterRow?&lt;/p&gt;

&lt;p&gt;Should filterBase do return filter.isFamilyEssential(name); rather than just return true in isEssentialFamily.&lt;/p&gt;

&lt;p&gt;Why is below in Region and not in RegionScanner?&lt;/p&gt;

&lt;p&gt;+    // Heap of key-values that are not essential for the provided filters and are thus read&lt;br/&gt;
+    // on demand, if lazy column family loading is enabled.&lt;br/&gt;
+    KeyValueHeap joinedHeap = null;&lt;/p&gt;


&lt;p&gt;This is a little obscene:&lt;/p&gt;

&lt;p&gt;+                Collections.sort(results, comparator);&lt;/p&gt;

&lt;p&gt;inside in HRegion merging results of &apos;essential&apos; and &apos;non-essential&apos; data (this probably should be rephrased...).  Can&apos;t be avoided though given what is going on here.&lt;/p&gt;





</comment>
                            <comment id="13536441" author="sershe" created="Wed, 19 Dec 2012 21:38:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; wrt tests, aside from the tests in the patch, have you seen &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7383&quot; title=&quot;create integration test for HBASE-5416 (improving scan performance for certain filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7383&quot;&gt;&lt;del&gt;HBASE-7383&lt;/del&gt;&lt;/a&gt;? It has an integration test.&lt;/p&gt;</comment>
                            <comment id="13536450" author="stack" created="Wed, 19 Dec 2012 21:52:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; An IT was mentioned in the above comments.  That sounds great (sounds like it found interesting issues around splitting &amp;#8211; good stuff).  Anyone that you know of done close review (I see reviews that address formatting and grammar but little on the machinery &amp;#8211; maybe its because the details are w/o blemish?)?  Any other unit tests we could get in there that poke at possible issues particularly regards changes made in default path?&lt;/p&gt;</comment>
                            <comment id="13536458" author="sershe" created="Wed, 19 Dec 2012 21:57:29 +0000"  >&lt;p&gt;I thought &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; was going to continue reviewing. In general it has no full +1 at this time.&lt;br/&gt;
I will address minor feedback since last patch, and put the patch in review tool.&lt;/p&gt;</comment>
                            <comment id="13536465" author="sershe" created="Wed, 19 Dec 2012 22:00:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; The enum is tri-value in order to allow per-request override; e.g. there&apos;s cluster/table default, but you can override it for each scan.&lt;br/&gt;
Do you want to remove that? In that case, given that feature is for specific types of tables and thus override-on is more likely than override-off, I&apos;d prefer to make false/absent do cluster setting (and default for cluster setting would be off).&lt;/p&gt;</comment>
                            <comment id="13536473" author="jxiang" created="Wed, 19 Dec 2012 22:14:58 +0000"  >&lt;p&gt;With PB, there is a method for optional parameter to check if it is set: hasXXX(). Does this help?&lt;/p&gt;</comment>
                            <comment id="13536480" author="jxiang" created="Wed, 19 Dec 2012 22:19:42 +0000"  >&lt;p&gt;If you make the type a Boolean object instead of primitive, then you use null to indicate not_set.  Not sure if this is better.&lt;/p&gt;</comment>
                            <comment id="13536488" author="yuzhihong@gmail.com" created="Wed, 19 Dec 2012 22:30:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why is below in Region and not in RegionScanner?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The joinedHeap is added to RegionScannerImpl, along side storeHeap.&lt;/p&gt;</comment>
                            <comment id="13536507" author="sershe" created="Wed, 19 Dec 2012 22:45:22 +0000"  >
&lt;blockquote&gt;&lt;p&gt;What is happening in SingleColumnValueExcludeFilter? We are removing filterKeyValue and putting in place filterRow and hasFilterRow?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Max commented above:&lt;br/&gt;
&quot;...I resolved this by checking that row is not empty right before filterRow(List) called, but this requires to slightly modify SingleColumnValueExcludeFilter logic - move exclude phase from filterKeyValue method to filterRow(List). The main reason for this is beacuse there is no way to distinguish at RegionScanner::nextInternal level empty row which is empty because of filter accepts row, but excludes all it&apos;s KVs and row which is empty due to filter rejects&quot;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should filterBase do return filter.isFamilyEssential(name); rather than just return true in isEssentialFamily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;FilterBase is base class, and Filter::isFamilyEssential is abstract. I guess it&apos;s just the default behavior for most filters.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why is below in Region and not in RegionScanner?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It is in fact in RegionScanner, together with StoreHeap:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 class RegionScannerImpl &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; RegionScanner {
    &lt;span class=&quot;code-comment&quot;&gt;// Package local &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; testability
&lt;/span&gt;    KeyValueHeap storeHeap = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
    &lt;span class=&quot;code-comment&quot;&gt;// Heap of key-values that are not essential &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the provided filters and are thus read
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// on demand, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; lazy column family loading is enabled.
&lt;/span&gt;    KeyValueHeap joinedHeap = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;blockquote&gt;
&lt;p&gt;This is a little obscene:&lt;/p&gt;

&lt;p&gt;+ Collections.sort(results, comparator);&lt;/p&gt;

&lt;p&gt;inside in HRegion merging results of &apos;essential&apos; and &apos;non-essential&apos; data (this probably should be rephrased...). Can&apos;t be avoided though given what is going on here.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is actually an interesting point, is there anything that prevents us from only sorting results at the end, not for each row?&lt;/p&gt;</comment>
                            <comment id="13536536" author="sershe" created="Wed, 19 Dec 2012 22:59:39 +0000"  >&lt;p&gt;As in, for each next call on the heap.&lt;/p&gt;</comment>
                            <comment id="13536550" author="sershe" created="Wed, 19 Dec 2012 23:06:58 +0000"  >&lt;p&gt;Review on &lt;a href=&quot;https://reviews.apache.org/r/8689/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/8689/&lt;/a&gt;. Changed the value in Scan to Boolean due to popular demand, renamed the settings, other various feedback.&lt;/p&gt;</comment>
                            <comment id="13536571" author="sershe" created="Wed, 19 Dec 2012 23:24:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; the only change on the main path not conditional on joinedScanners/joinedHeap/etc. being there seems to be refactoring the while loop under &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (filterRowKey(currentRow, offset, length)) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;into populateResult, which in this case will do one extra matchingRow check of storeHeap current row against itself (it pre-checks current heap KV instead of post-checking, but in this case the row we use to check was just created from this very heap). I don&apos;t think test could be that targeted even though when refactoring there&apos;s potential to add bugs...&lt;/p&gt;</comment>
                            <comment id="13536583" author="stack" created="Wed, 19 Dec 2012 23:32:57 +0000"  >&lt;p&gt;Thanks for feedback.&lt;/p&gt;

&lt;p&gt;Use case is valid.  So are concerns that we are tinkering w/ a critical path raised by more than one dev.  What do you think lads we could do to put folks at ease with this patch.  The integration testing helps big time.  Keeping all the new code optionally enabled helps too.  Any chance of more careful reviews?  That would help as well.  Can we think of any other unit tests we could add?&lt;/p&gt;</comment>
                            <comment id="13536622" author="hadoopqa" created="Thu, 20 Dec 2012 00:07:08 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12561806/HBASE-5416-v11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12561806/HBASE-5416-v11.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 28 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaReaderEditor&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are zombie tests. See build logs for details.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3622//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13536630" author="sershe" created="Thu, 20 Dec 2012 00:16:19 +0000"  >&lt;p&gt;Hmm, I will look at all these tests&lt;/p&gt;</comment>
                            <comment id="13536670" author="sershe" created="Thu, 20 Dec 2012 01:25:17 +0000"  >&lt;p&gt;Appear to pass on local&lt;/p&gt;</comment>
                            <comment id="13536758" author="anoopsamjohn" created="Thu, 20 Dec 2012 04:07:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; &lt;br/&gt;
The issue which coming while split may be a concern.. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
This is only with this new patch right?&lt;br/&gt;
I will have a look at the patch and the flow and will see whether can help&lt;/p&gt;
</comment>
                            <comment id="13536767" author="ram_krish" created="Thu, 20 Dec 2012 04:31:39 +0000"  >&lt;p&gt;I will continue to look at the patch.. I have looked into half of the things.&lt;br/&gt;
The testcase failures could  be a concern.  Will continue the review today.&lt;/p&gt;</comment>
                            <comment id="13537208" author="ram_krish" created="Thu, 20 Dec 2012 18:05:04 +0000"  >&lt;p&gt;Ok groked up the patch.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!scan.getAllowLazyCfLoading()
          || &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter.isFamilyEssential(entry.getKey())) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Move the this.filter == null as first condition.  Because when you don have filters then the entire joinedHeap is not going to used right?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 correct_row = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap.seek(KeyValue.createFirstOnRow(currentRow, offset, length));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So here we move on to the KV just before the row we got in the current next() call?&lt;br/&gt;
After this suppose due to limits it says that joinedHeapHasMoreData =true, now when the next call comes&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (joinedHeapHasMoreData) {
          joinedHeapHasMoreData =
            populateResult(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.joinedHeap, limit, currentRow, offset, length, metric);
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think we should get the return val from the populateResult and if it returns a false we may need to check if we have reached the stopRow or not right?&lt;br/&gt;
Filters need not be checked anyway.  &lt;/p&gt;

&lt;p&gt;So one thing is if i say in my Scan that i need LazyLoading but my filter is NOT of the type SCVF and the ones that implement isFamilyEssential then it goes thro normal flow.  May be this we need to document clearly as user may think that setting that property is going to give him a better optimized scan.&lt;/p&gt;

&lt;p&gt;Reg, the TestHRegion testcases.  Actually the testcases does not test the behaviour of joinedScanners.  Is it intended? But the testcase names suggests it tests joinedScanners.  &lt;br/&gt;
I will leave it to other scan experts in deciding whether this can go in.  Overall a very good improvment.&lt;/p&gt;

&lt;p&gt;Thanks to Max, Sergey and Ted.&lt;/p&gt;</comment>
                            <comment id="13537230" author="ram_krish" created="Thu, 20 Dec 2012 18:22:44 +0000"  >&lt;p&gt;@Sergey&lt;br/&gt;
The split related failure has to be investigated.  Will try looking into the possible reason for failure.&lt;/p&gt;</comment>
                            <comment id="13537444" author="sershe" created="Thu, 20 Dec 2012 22:34:40 +0000"  >&lt;p&gt;Hmm... I am trying to clean up code a bit now and write comments.&lt;br/&gt;
It seems that this patch shouldn&apos;t work with limits at all... in the big else clause, if we get false from populateResult on storeHeap, we&apos;d go on to start getting stuff from joinedMap. Suppose stopRow is true e.g. storeHeap.peek() now points at the stop-row.&lt;br/&gt;
Suppose now we hit the limit and set joinedHeapHasMoreData, and return true.&lt;br/&gt;
On the next call, storeHeap is still pointing to stop-row, so we won&apos;t even reach else if (joinedHeapHasMoreData) condition (well, and if we did we&apos;d populate nothing because matchingRow will always return false).&lt;/p&gt;

&lt;p&gt;Can someone please sanity check me?&lt;br/&gt;
I&apos;ll see how to fix it.&lt;/p&gt;</comment>
                            <comment id="13537599" author="sershe" created="Fri, 21 Dec 2012 01:26:12 +0000"  >&lt;p&gt;Cleaned up the method and added a bunch of comments so that it&apos;d be clear what is going on. Fixed the above issues.&lt;br/&gt;
I will look at integration test issue next. &lt;/p&gt;</comment>
                            <comment id="13537628" author="sershe" created="Fri, 21 Dec 2012 02:25:37 +0000"  >&lt;p&gt;It appears that I have accidentally fixed something. I can repro with v11 patch but not v12...&lt;/p&gt;</comment>
                            <comment id="13537631" author="hadoopqa" created="Fri, 21 Dec 2012 02:28:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562021/HBASE-5416-v12.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562021/HBASE-5416-v12.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 28 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are zombie tests. See build logs for details.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3641//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13537690" author="hadoopqa" created="Fri, 21 Dec 2012 05:30:10 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562033/HBASE-5416-v12.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562033/HBASE-5416-v12.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 8 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 28 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplication&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTable&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are zombie tests. See build logs for details.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3644//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13538236" author="ram_krish" created="Fri, 21 Dec 2012 17:37:13 +0000"  >&lt;p&gt;I will take a look at the updated patch by tomorrow evening.&lt;/p&gt;</comment>
                            <comment id="13538272" author="stack" created="Fri, 21 Dec 2012 18:22:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;It appears that I have accidentally fixed something. I can repro with v11 patch but not v12...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Smile&lt;/p&gt;</comment>
                            <comment id="13538441" author="yuzhihong@gmail.com" created="Fri, 21 Dec 2012 21:39:21 +0000"  >&lt;p&gt;Looks like ClientProtos.java needs to be regenerated due to recent changes in trunk.&lt;/p&gt;</comment>
                            <comment id="13538453" author="sershe" created="Fri, 21 Dec 2012 21:52:58 +0000"  >&lt;p&gt;I replaced v12 patch to do that yesterday evening. Or you mean again? I will regen at next iteration, just in case &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13538563" author="yuzhihong@gmail.com" created="Sat, 22 Dec 2012 00:09:54 +0000"  >&lt;p&gt;I think the rewritten logic is easier to understand.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; LOAD_CFS_ON_DEMAND_CONFIG_KEY = &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hregion.scan.loadColumnFamiliesOnDemand&quot;&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Wrap long line.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isLoadingCfsOnDemandDefault() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can the &apos;Default&apos; be dropped from the method name ? We&apos;re interested in whether on demand loading is on.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      List&amp;lt;KeyValueScanner&amp;gt; joinedScanners = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;KeyValueScanner&amp;gt;();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should we check scan.doLoadColumnFamiliesOnDemand() first so that we don&apos;t allocate ArrayList if this feature is turned off ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+     * Fetches records with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; row into result list, until next row or limit (&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not -1).
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;this row&apos; -&amp;gt; &apos;currentRow&apos;&lt;br/&gt;
&apos;result list&apos; -&amp;gt; &apos;results list&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-comment&quot;&gt;// Check &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we were getting data from the joinedHeap abd hit the limit.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;abd&apos; -&amp;gt; &apos;and&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-comment&quot;&gt;// Techically, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we hit limits before on &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; row, we don&apos;t need &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; call.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Typo: Techically&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-comment&quot;&gt;// Populating from the joined map was stopped by limits, populate some more.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;joined map&apos; -&amp;gt; &apos;joined heap&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-comment&quot;&gt;// the &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; when SingleValueExcludeFilter is used.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;SingleValueExcludeFilter -&amp;gt; SingleColumnValueExcludeFilter&lt;/p&gt;</comment>
                            <comment id="13539286" author="ram_krish" created="Mon, 24 Dec 2012 16:17:41 +0000"  >&lt;p&gt;I could find one thing here&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-comment&quot;&gt;// Let&apos;s see what we have in the storeHeap.
&lt;/span&gt;        KeyValue current = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeHeap.peek();
        &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; stopRow = isStopRow(current);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Assume i have one CF and i have a filter with isFamilyEssential = true.  Also scan says lazy loading of CF is allowed.&lt;br/&gt;
Now in this case i will have only the joinedScanner heap.&lt;br/&gt;
So now when the next() is called&lt;br/&gt;
current will be null as nothing is there in storeHeap.&lt;br/&gt;
Inside isStopRow&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; kv == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || kv.getBuffer() == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ||
          (stopRow != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp;
          comparator.compareRows(stopRow, 0, stopRow.length,
              kv.getBuffer(), kv.getRowOffset(), kv.getRowLength()) &amp;lt;= isScan);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This will give me true. So stopRow is true.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (stopRow) {
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (filter != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; filter.hasFilterRow()) {
              filter.filterRow(results);
            }
            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
          }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So this code will just return without scanning.  Pls correct me if am wrong?&lt;/p&gt;
</comment>
                            <comment id="13540054" author="yuzhihong@gmail.com" created="Thu, 27 Dec 2012 17:21:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Now in this case i will have only the joinedScanner heap.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think you meant we only have storeHeap.&lt;/p&gt;

&lt;p&gt;Here is related code from HRegion.nextInternal() of 0.94 branch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isStopRow(currentRow, offset, length)) {
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (filter != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; filter.hasFilterRow()) {
            filter.filterRow(results);
          }
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (filter != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; filter.filterRow()) {
            results.clear();
          }

          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can see the logic is the same as that in patch v12.&lt;/p&gt;</comment>
                            <comment id="13540058" author="yuzhihong@gmail.com" created="Thu, 27 Dec 2012 17:22:17 +0000"  >&lt;p&gt;Patch v13 rebases on trunk.&lt;br/&gt;
TestSingleColumnValueExcludeFilter, TestHRegion and TestJoinedScanners pass.&lt;/p&gt;</comment>
                            <comment id="13540062" author="shmuma" created="Thu, 27 Dec 2012 17:31:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think you meant we only have storeHeap.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, exactly one KVS in joinedScanner heap and empty storeHeap. It was caused by &lt;tt&gt;!scan.doLoadColumnFamiliesOnDemand()&lt;/tt&gt; extra condition in constructor.&lt;/p&gt;</comment>
                            <comment id="13540069" author="ram_krish" created="Thu, 27 Dec 2012 17:40:18 +0000"  >&lt;p&gt;Yes Max that&apos;s what i meant.&lt;br/&gt;
Ted, just take the condition where  isFamilyEssential = true. Also scan says lazy loading of CF is allowed. (and also only one CF).&lt;br/&gt;
So storeHeap will be null in this case. &lt;/p&gt;</comment>
                            <comment id="13540070" author="yuzhihong@gmail.com" created="Thu, 27 Dec 2012 17:42:38 +0000"  >&lt;p&gt;Here is the change related to Max&apos;s comment above:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || !scan.doLoadColumnFamiliesOnDemand()
+          || &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter.isFamilyEssential(entry.getKey())) {
+          scanners.add(scanner);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Ram said:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Also scan says lazy loading of CF is allowed.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So the condition &lt;tt&gt;!scan.doLoadColumnFamiliesOnDemand()&lt;/tt&gt; should be false, right ?&lt;/p&gt;</comment>
                            <comment id="13540078" author="yuzhihong@gmail.com" created="Thu, 27 Dec 2012 17:57:00 +0000"  >&lt;p&gt;Here is code from patch v7:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter.isFamilyEssential(entry.getKey())) {
+          scanners.add(scanner);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the above case, I don&apos;t see difference between v7 and v12 w.r.t. populating scanners List.&lt;/p&gt;</comment>
                            <comment id="13540105" author="hadoopqa" created="Thu, 27 Dec 2012 18:54:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562493/5416-v13.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562493/5416-v13.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplication&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 4 zombie test(s): &lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3718//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13540386" author="ram_krish" created="Fri, 28 Dec 2012 08:20:10 +0000"  >&lt;p&gt;@Ted&lt;br/&gt;
You are correct.  My bad.  So if &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || !scan.doLoadColumnFamiliesOnDemand()
+          || &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter.isFamilyEssential(entry.getKey())) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So even if first two condition fail if isFamilyEssential= true then it will add to scanners.&lt;br/&gt;
But still if isFamilyEssentail = false then what will happen wrt the stopRow that is added in the latest patches.  What you feel?&lt;br/&gt;
Because the current is always got from the storeHeap.  &lt;/p&gt;</comment>
                            <comment id="13540388" author="yuzhihong@gmail.com" created="Fri, 28 Dec 2012 08:26:25 +0000"  >&lt;p&gt;I need to go over the logic one more time. But for non-essential column family, I think it is correct too. &lt;/p&gt;</comment>
                            <comment id="13541166" author="lhofhansl" created="Sun, 30 Dec 2012 21:53:53 +0000"  >&lt;p&gt;I will try to make a 0.94 patch and do some performance testing, if that turns out well, let&apos;s pull this into 0.94 as well.&lt;/p&gt;</comment>
                            <comment id="13541172" author="lhofhansl" created="Sun, 30 Dec 2012 22:33:25 +0000"  >&lt;p&gt;v13 is undoing some of the optimization I had put it. HRegion.RegionScannerImpl.isStopRow should continue to take a byte[], offset, and length, rather than a KeyValue.&lt;/p&gt;</comment>
                            <comment id="13541174" author="lhofhansl" created="Sun, 30 Dec 2012 22:55:07 +0000"  >&lt;p&gt;Even when I fix that, it does slow down the tight loop case by about 10-20%.&lt;br/&gt;
(That is a scan on a single column with a filter that happens to filter everything, and everything is in the blockcache)&lt;/p&gt;

&lt;p&gt;Without this patch I can scan 20m single column rows in ~5.8s, which this patch it&apos;s ~6.9s.&lt;br/&gt;
This is with onDemand loading disabled.&lt;/p&gt;</comment>
                            <comment id="13541175" author="lhofhansl" created="Sun, 30 Dec 2012 23:10:23 +0000"  >&lt;p&gt;This is probably due to the extra calls to KeyValueHeap.peek().&lt;/p&gt;</comment>
                            <comment id="13541178" author="lhofhansl" created="Sun, 30 Dec 2012 23:17:57 +0000"  >&lt;p&gt;If the while loop in populateResults is change back to the original do/while loop the results are closer to what it was before. I understand why you changed it to the while loop (it looks better), but it does unnecessary peeks into the heap.&lt;/p&gt;</comment>
                            <comment id="13541179" author="lhofhansl" created="Sun, 30 Dec 2012 23:26:29 +0000"  >&lt;p&gt;It&apos;s still 5.8s vs 6.2s (without vs with patch).&lt;/p&gt;</comment>
                            <comment id="13541183" author="lhofhansl" created="Sun, 30 Dec 2012 23:39:06 +0000"  >&lt;p&gt;Preliminary 0.94 patch.&lt;br/&gt;
The scan flag is communicated via the scan attributes (so that the wire protocol does not have to change).&lt;br/&gt;
I ran the two included/changed tests and did the before-mentioned performance tests.&lt;/p&gt;</comment>
                            <comment id="13541185" author="hadoopqa" created="Sun, 30 Dec 2012 23:43:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562737/5416-0.94-v1.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562737/5416-0.94-v1.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3772//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3772//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13541191" author="lhofhansl" created="Mon, 31 Dec 2012 00:20:48 +0000"  >&lt;p&gt;Here&apos;s another experiment I did against the 0.94 patch:&lt;br/&gt;
Two column families, a SingleColumnValueFilter that filters everything based on the 1st CF.&lt;br/&gt;
When I run this against 2 CFs (with on demand disabled) it takes about 60s.&lt;br/&gt;
When I run this a single CF it takes ~30s.&lt;br/&gt;
When I enable on demand loading and run against both CFs it still takes 60s. I would have expected that that would have been closer to 30s.&lt;/p&gt;</comment>
                            <comment id="13541200" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 00:43:10 +0000"  >&lt;p&gt;Thanks for doing the experiments, Lars. &lt;br/&gt;
Can you take a look at the use case shown in the test in the patch to see if it matches the way you did experiment ?&lt;/p&gt;</comment>
                            <comment id="13541202" author="lhofhansl" created="Mon, 31 Dec 2012 00:54:21 +0000"  >&lt;p&gt;There&apos;s something amiss here. Filer.filterRow is not called anywhere in trunk except for some filterwrappers and in tests (so we could just remove it, or there&apos;s a more general bug in trunk).&lt;br/&gt;
It seems it is not used. SCVF does not implement filterRow(List&amp;lt;KeyValue) so this entire thing cannot work (I did these checks on the trunk patch).&lt;/p&gt;

&lt;p&gt;I assumed what I tested was the use case: You have multiple column families and use a SCVF based on one of the families, which should then avoid even touching the other CFs.&lt;/p&gt;</comment>
                            <comment id="13541229" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 02:40:11 +0000"  >&lt;p&gt;@Lars:&lt;br/&gt;
Here is how SingleColumnValueFilter is used in the test:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    SingleColumnValueFilter filter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SingleColumnValueFilter(
+        cf_essential, col_name, CompareFilter.CompareOp.EQUAL, flag_yes);
+    filter.setFilterIfMissing(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here is the reason for setting filterIfMissing to true:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isFamilyEssential(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] name) {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; !&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filterIfMissing || Bytes.equals(name, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.columnFamily);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think what you experienced was that the default value of false for filterIfMissing was in effect and both column families were examined.&lt;/p&gt;

&lt;p&gt;We should definitely emphasize this intricacy in release notes.&lt;/p&gt;</comment>
                            <comment id="13541237" author="lhofhansl" created="Mon, 31 Dec 2012 03:19:01 +0000"  >&lt;p&gt;Thanks Ted. You&apos;re right. I&apos;ll redo my test in a bit.&lt;/p&gt;</comment>
                            <comment id="13541241" author="lhofhansl" created="Mon, 31 Dec 2012 03:31:03 +0000"  >&lt;p&gt;Actually. That should make it work with my 0.94 patch. In 0.96 Filter.filterRow() is never called, so this it would never skip any rows that way.&lt;/p&gt;</comment>
                            <comment id="13541250" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 03:58:30 +0000"  >&lt;p&gt;@Lars:&lt;br/&gt;
Pardon me for not explaining in more detail.&lt;br/&gt;
In HRegion.RegionScannerImpl():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (scan.hasFilter()) {
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FilterWrapper(scan.getFilter());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In FilterWrapper:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void filterRow(List&amp;lt;KeyValue&amp;gt; kvs) {
    &lt;span class=&quot;code-comment&quot;&gt;//To fix HBASE-6429, 
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//Filter with filterRow() returning &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; is incompatible with scan with limit
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//1. hasFilterRow() returns &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; either filterRow() or filterRow(kvs) is implemented.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//2. filterRow() is merged with filterRow(kvs),
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//so that to make all those row related filtering stuff in the same function.
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter.filterRow(kvs);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!kvs.isEmpty() &amp;amp;&amp;amp; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.filter.filterRow()) {
      kvs.clear();
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you have further questions, please let me know.&lt;/p&gt;

&lt;p&gt;Once you confirm that the 0.94 patch works, I will attach patch v14 for trunk which addresses the two issues you raised this afternoon.&lt;/p&gt;</comment>
                            <comment id="13541257" author="lhofhansl" created="Mon, 31 Dec 2012 04:14:15 +0000"  >&lt;p&gt;Cool... You&apos;re right here too. We should probably merge these two in 0.94 as well, but that&apos;s another story.&lt;br/&gt;
(It&apos;s all getting a bit messy. We have Filter, FilterBase, FilterWrapper. Now we even have logic in FilterWrapper)&lt;/p&gt;</comment>
                            <comment id="13541258" author="lhofhansl" created="Mon, 31 Dec 2012 04:20:55 +0000"  >&lt;p&gt;I confirmed that when I set filterIfMissing the scan time is very close to 30s.&lt;br/&gt;
Note that I am not giving a +1, yet. This needs a bit more looking at. Especially the slow down the regular path is a bit disconcerting.&lt;/p&gt;</comment>
                            <comment id="13541265" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 04:38:50 +0000"  >&lt;p&gt;Patch v14 addresses the two issues Lars raised.&lt;/p&gt;

&lt;p&gt;Thanks to Lars who verified that this feature is helpful in the described scenario.&lt;/p&gt;

&lt;p&gt;For the regular path, what we can do is to optimize away all the new code based on disabling on demand column family loading. We should be able to spot the difference from existing code more easily.&lt;/p&gt;</comment>
                            <comment id="13541280" author="lhofhansl" created="Mon, 31 Dec 2012 05:10:58 +0000"  >&lt;p&gt;It might help to inline the populateResults code again. That would save us an extra call to KeyValueHeap.peek().&lt;/p&gt;</comment>
                            <comment id="13541281" author="lhofhansl" created="Mon, 31 Dec 2012 05:13:09 +0000"  >&lt;p&gt;Or populateResult could return the nextKv to indicate that we&apos;re not done (null to indicate that a limit was hit)&lt;/p&gt;</comment>
                            <comment id="13541286" author="hadoopqa" created="Mon, 31 Dec 2012 05:37:42 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562752/5416-v14.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562752/5416-v14.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplication&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): &lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3778//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13541287" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 05:42:08 +0000"  >&lt;p&gt;Patch v15 adopts Lars&apos; suggestion above and saves one heap.peek() call.&lt;/p&gt;</comment>
                            <comment id="13541291" author="lhofhansl" created="Mon, 31 Dec 2012 06:07:46 +0000"  >&lt;p&gt;Lemme do the same to the 0.94 patch and try my test again.&lt;br/&gt;
(If we want this in 0.94 we have to maintain these two patches separately now, as 0.94 and 0.96 are sufficiently different in this area. Maybe 0.96 is indeed better.)&lt;/p&gt;</comment>
                            <comment id="13541303" author="lhofhansl" created="Mon, 31 Dec 2012 06:49:33 +0000"  >&lt;p&gt;Same changes for the 0.94 patch.&lt;br/&gt;
With this change I cannot detect a performance detriment when disabled (will try with a larger data set too).&lt;/p&gt;</comment>
                            <comment id="13541306" author="hadoopqa" created="Mon, 31 Dec 2012 06:53:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562766/5416-0.94-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562766/5416-0.94-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3781//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3781//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13541307" author="hadoopqa" created="Mon, 31 Dec 2012 06:54:37 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562757/5416-v15.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562757/5416-v15.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestHCM&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestMasterReplication&lt;br/&gt;
                  org.apache.hadoop.hbase.TestHBaseTestingUtility&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 3 zombie test(s): 	at org.apache.hadoop.hbase.io.encoding.TestUpgradeFromHFileV1ToEncoding.testUpgrade(TestUpgradeFromHFileV1ToEncoding.java:83)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3780//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13541382" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 15:02:57 +0000"  >&lt;p&gt;Patch v16 corrects spelling and wraps long line.&lt;/p&gt;</comment>
                            <comment id="13541415" author="hadoopqa" created="Mon, 31 Dec 2012 17:02:12 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12562796/5416-v16.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12562796/5416-v16.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 4 zombie test(s): 	at org.apache.hadoop.hbase.io.encoding.TestUpgradeFromHFileV1ToEncoding.testUpgrade(TestUpgradeFromHFileV1ToEncoding.java:83)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13541420" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 17:09:11 +0000"  >&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//console:&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3783//console:&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;pool-1-thread-1&quot;&lt;/span&gt; prio=10 tid=0x773bc800 nid=0x451 in &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() [0x772fe000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: WAITING (on object monitor)
  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method)
  - waiting on &amp;amp;lt;0x803da7e8&amp;gt; (a org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread)
  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.join(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:1186)
  - locked &amp;amp;lt;0x803da7e8&amp;gt; (a org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread)
  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.join(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:1239)
  at org.apache.hadoop.hbase.util.JVMClusterUtil.shutdown(JVMClusterUtil.java:245)
  at org.apache.hadoop.hbase.LocalHBaseCluster.shutdown(LocalHBaseCluster.java:430)
  at org.apache.hadoop.hbase.MiniHBaseCluster.shutdown(MiniHBaseCluster.java:501)
  at org.apache.hadoop.hbase.HBaseTestingUtility.shutdownMiniHBaseCluster(HBaseTestingUtility.java:856)
  at org.apache.hadoop.hbase.HBaseTestingUtility.shutdownMiniCluster(HBaseTestingUtility.java:826)
  at org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.after(TestSplitTransactionOnCluster.java:109)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13541422" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 17:14:17 +0000"  >&lt;p&gt;Local run of tests flagged by QA script was successful:&lt;/p&gt;

&lt;p&gt;  172  mt -Dtest=TestRestartCluster,TestSplitTransactionOnCluster&lt;br/&gt;
  173  mt -Dtest=TestUpgradeFromHFileV1ToEncoding&lt;/p&gt;</comment>
                            <comment id="13543138" author="ram_krish" created="Thu, 3 Jan 2013 18:05:45 +0000"  >&lt;p&gt;I can check on this tomorrow with the latest patch and the doubts i had earlier.&lt;/p&gt;</comment>
                            <comment id="13544619" author="ram_krish" created="Sat, 5 Jan 2013 07:36:45 +0000"  >&lt;p&gt;@Ted&lt;br/&gt;
Went thro the patch.. Wrote some tests to see that things work fine.  Anyway did not do any perf tests.&lt;br/&gt;
Looks good to me.  Thanks for doing this.&lt;/p&gt;</comment>
                            <comment id="13544708" author="yuzhihong@gmail.com" created="Sat, 5 Jan 2013 13:19:33 +0000"  >&lt;p&gt;Thanks for the review, Ram.&lt;/p&gt;

&lt;p&gt;+1 from me too.&lt;/p&gt;</comment>
                            <comment id="13544746" author="hadoopqa" created="Sat, 5 Jan 2013 16:28:54 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12563428/5416-v16.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12563428/5416-v16.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestSplitTransaction&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3876//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13544755" author="ram_krish" created="Sat, 5 Jan 2013 16:50:41 +0000"  >&lt;p&gt;+1 from me.&lt;/p&gt;</comment>
                            <comment id="13544773" author="hadoopqa" created="Sat, 5 Jan 2013 17:46:03 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12563434/5416-v16.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12563434/5416-v16.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplicationWithCompression&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3877//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13545182" author="yuzhihong@gmail.com" created="Sat, 5 Jan 2013 21:32:47 +0000"  >&lt;p&gt;I plan to integrate patch v16 Monday (the 7th) afternoon.&lt;/p&gt;</comment>
                            <comment id="13545200" author="lhofhansl" created="Sat, 5 Jan 2013 22:32:13 +0000"  >&lt;p&gt;Can we rule out first that there are no more general approaches?&lt;br/&gt;
For example: What about declaring the columns that will have filters applied to them in the scan object? Maybe there are more way to look at this.&lt;/p&gt;

&lt;p&gt;I would also feel better if some of the Facebooks folks took a look at this (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikhail&quot; class=&quot;user-hover&quot; rel=&quot;mikhail&quot;&gt;Mikhail Bautin&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=karthik.ranga&quot; class=&quot;user-hover&quot; rel=&quot;karthik.ranga&quot;&gt;Karthik Ranganathan&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kannanm&quot; class=&quot;user-hover&quot; rel=&quot;kannanm&quot;&gt;Kannan Muthukkaruppan&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Generally I like the patch, and I think we should even have this in 0.94.&lt;/p&gt;</comment>
                            <comment id="13546301" author="sershe" created="Mon, 7 Jan 2013 21:44:46 +0000"  >&lt;p&gt;Btw, the integration test for this is in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7383&quot; title=&quot;create integration test for HBASE-5416 (improving scan performance for certain filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7383&quot;&gt;&lt;del&gt;HBASE-7383&lt;/del&gt;&lt;/a&gt;. I will run it locally for latest patch.&lt;/p&gt;</comment>
                            <comment id="13546430" author="sershe" created="Tue, 8 Jan 2013 00:07:03 +0000"  >&lt;p&gt;Btw, the test appears to pass. &lt;/p&gt;</comment>
                            <comment id="13547076" author="yuzhihong@gmail.com" created="Tue, 8 Jan 2013 18:15:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikhail&quot; class=&quot;user-hover&quot; rel=&quot;mikhail&quot;&gt;Mikhail Bautin&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=karthik.ranga&quot; class=&quot;user-hover&quot; rel=&quot;karthik.ranga&quot;&gt;Karthik Ranganathan&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kannanm&quot; class=&quot;user-hover&quot; rel=&quot;kannanm&quot;&gt;Kannan Muthukkaruppan&lt;/a&gt;:&lt;br/&gt;
Your opinion would be helpful.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13548688" author="karthik.ranga" created="Wed, 9 Jan 2013 17:15:38 +0000"  >&lt;p&gt;I think the specific description (of making filters apply to only some CF&apos;s) is a good idea.But we continue down this path of generalizing filters, it could  lead to an explosion of ad-hoc filters. In that case, it might be better to expose more co-processor hooks. Overall, +1 (only skimmed the changes though).&lt;/p&gt;</comment>
                            <comment id="13548713" author="yuzhihong@gmail.com" created="Wed, 9 Jan 2013 17:34:29 +0000"  >&lt;p&gt;Thanks for the review, Karthik.&lt;br/&gt;
I will think about how co-processor hooks can be used to reduce changes in filters.&lt;/p&gt;</comment>
                            <comment id="13549006" author="lhofhansl" created="Wed, 9 Jan 2013 21:07:15 +0000"  >&lt;p&gt;I don&apos;t necessarily think that ad hoc filters are bad. They are nice in that they are per store, can do skip scans, etc. They fill a different use case compare to coprocs.&lt;br/&gt;
If anything, this might be an impetus to support filters better (load them dynamically like coprocs, maybe even invent a general filter descriptions, etc, etc).&lt;/p&gt;

&lt;p&gt;Since nobody has better API ideas I&apos;m +1 on committing (both 0.94 and 0.96).&lt;/p&gt;</comment>
                            <comment id="13549012" author="yuzhihong@gmail.com" created="Wed, 9 Jan 2013 21:17:46 +0000"  >&lt;p&gt;We have 4 +1&apos;s for this JIRA.&lt;br/&gt;
It is time to integrate.&lt;br/&gt;
I plan to do that in trunk by this evening.&lt;/p&gt;

&lt;p&gt;@Lars:&lt;br/&gt;
I haven&apos;t run test suite for 0.94 patch, do you want to integrate to 0.94 branch ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13549040" author="yuzhihong@gmail.com" created="Wed, 9 Jan 2013 21:39:50 +0000"  >&lt;p&gt;Integrated to trunk.&lt;/p&gt;

&lt;p&gt;Thanks for the patch, Max and Sergey.&lt;/p&gt;

&lt;p&gt;Thanks for the review, Stack, Lars, Ram and Karthik.&lt;/p&gt;</comment>
                            <comment id="13549091" author="hudson" created="Wed, 9 Jan 2013 22:20:11 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3716 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3716/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3716/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; Improve performance of scans with some kind of filters (Max Lapan and Sergey) (Revision 1431103)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/Filter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterWrapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/WhileMatchFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestJoinedScanners.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13549208" author="lhofhansl" created="Wed, 9 Jan 2013 23:58:59 +0000"  >&lt;p&gt;Looks like the trunk patch was not changed since I made the 0.94 patch (except for wrapping the long line, etc).&lt;br/&gt;
I&apos;ll commit in the next day or so (unless somebody objects)&lt;/p&gt;</comment>
                            <comment id="13549238" author="hudson" created="Thu, 10 Jan 2013 00:33:33 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #338 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/338/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/338/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; Improve performance of scans with some kind of filters (Max Lapan and Sergey) (Revision 1431103)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/Filter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterWrapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/filter/WhileMatchFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestJoinedScanners.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13549955" author="sershe" created="Thu, 10 Jan 2013 19:19:14 +0000"  >&lt;p&gt;Is this JIRA unresolved pending 0.94 commit? Just checking as it shows up in my filter &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                            <comment id="13550431" author="yuzhihong@gmail.com" created="Thu, 10 Jan 2013 21:20:14 +0000"  >&lt;p&gt;For 0.94 patch, I saw the following on my Mac:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testScanner_JoinedScannersWithLimits(org.apache.hadoop.hbase.regionserver.TestHRegion)  Time elapsed: 0.001 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
junit.framework.AssertionFailedError: expected:&amp;lt;3&amp;gt; but was:&amp;lt;1&amp;gt;
  at junit.framework.Assert.fail(Assert.java:50)
  at junit.framework.Assert.failNotEquals(Assert.java:287)
  at junit.framework.Assert.assertEquals(Assert.java:67)
  at junit.framework.Assert.assertEquals(Assert.java:199)
  at junit.framework.Assert.assertEquals(Assert.java:205)
  at org.apache.hadoop.hbase.regionserver.TestHRegion.testScanner_JoinedScannersWithLimits(TestHRegion.java:2976)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13550680" author="lhofhansl" created="Fri, 11 Jan 2013 01:36:43 +0000"  >&lt;p&gt;I ran all 0.94 tests. They all pass on my machines.&lt;/p&gt;</comment>
                            <comment id="13550726" author="yuzhihong@gmail.com" created="Fri, 11 Jan 2013 02:36:24 +0000"  >&lt;p&gt;Test output from 0.94.&lt;br/&gt;
Here is my environment:&lt;/p&gt;

&lt;p&gt;Darwin TYus-MacBook-Pro.local 12.2.1 Darwin Kernel Version 12.2.1: Thu Oct 18 12:13:47 PDT 2012; root:xnu-2050.20.9~1/RELEASE_X86_64 x86_64&lt;br/&gt;
TYus-MacBook-Pro:hbase-snapshot-0103 tyu$ java -version&lt;br/&gt;
java version &quot;1.6.0_37&quot;&lt;br/&gt;
Java(TM) SE Runtime Environment (build 1.6.0_37-b06-434-11M3909)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 20.12-b01-434, mixed mode)&lt;/p&gt;</comment>
                            <comment id="13550731" author="lhofhansl" created="Fri, 11 Jan 2013 02:44:19 +0000"  >&lt;p&gt;Does this test fail consistently for you?&lt;/p&gt;</comment>
                            <comment id="13550737" author="lhofhansl" created="Fri, 11 Jan 2013 02:52:15 +0000"  >&lt;p&gt;On my machine at this test fails too in 0.94.&lt;/p&gt;</comment>
                            <comment id="13550772" author="lhofhansl" created="Fri, 11 Jan 2013 03:18:25 +0000"  >&lt;p&gt;Found the problem. For the part of the patch that I had applied manually I mistook{{kv != KV_LIMIT}} for &lt;tt&gt;kv == KV_LIMIT&lt;/tt&gt;.&lt;br/&gt;
No idea how on earth the test on my server machine passed.&lt;/p&gt;</comment>
                            <comment id="13550780" author="lhofhansl" created="Fri, 11 Jan 2013 03:25:13 +0000"  >&lt;p&gt;Patch that has this fixed.&lt;br/&gt;
I think I should do a bit more double-checking before committing.&lt;/p&gt;</comment>
                            <comment id="13550794" author="yuzhihong@gmail.com" created="Fri, 11 Jan 2013 03:52:04 +0000"  >&lt;p&gt;Thanks Lars for the finding. I am running test suite based on patch v3.&lt;br/&gt;
Will report back if there is any abnormality.&lt;br/&gt;
I was looking for long lines.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; LOAD_CFS_ON_DEMAND_CONFIG_KEY = &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hregion.scan.loadColumnFamiliesOnDemand&quot;&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: wrap long line above.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+     * @param heap KeyValueHeap to fetch data from. It must be positioned on correct row before call.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Long line: it would be 100 characters wide if the trailing period is removed.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          stopRow = nextKv == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || isStopRow(nextKv.getBuffer(), nextKv.getRowOffset(), nextKv.getRowLength());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13550796" author="lhofhansl" created="Fri, 11 Jan 2013 03:56:06 +0000"  >&lt;p&gt;Thanks Ted. Will wrap lines upon commit (unless there&apos;s another version needed).&lt;/p&gt;</comment>
                            <comment id="13550820" author="yuzhihong@gmail.com" created="Fri, 11 Jan 2013 04:53:35 +0000"  >&lt;p&gt;The following tests failed locally:&lt;br/&gt;
TestMultiSlaveReplication,TestMasterReplication,TestZKLeaderManager&lt;/p&gt;

&lt;p&gt;The first two failed without the patch, too.&lt;/p&gt;

&lt;p&gt;I think patch v3 should be good to go.&lt;/p&gt;</comment>
                            <comment id="13551652" author="lhofhansl" created="Fri, 11 Jan 2013 23:44:39 +0000"  >&lt;p&gt;I think I convinced myself that this is good to go for 0.94.&lt;/p&gt;

&lt;p&gt;Going forward this could be useful for all kinds of filters. I can see many scenarios where we want filters to be evaluated on selected CFs only and include the other CFs when the row is not filtered based on the former.&lt;/p&gt;</comment>
                            <comment id="13553167" author="sershe" created="Mon, 14 Jan 2013 21:50:51 +0000"  >&lt;p&gt;Can this be counted as +1 to commit? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13553221" author="lhofhansl" created="Mon, 14 Jan 2013 22:47:20 +0000"  >&lt;p&gt;Yes. I will commit this today.&lt;/p&gt;</comment>
                            <comment id="13553236" author="lhofhansl" created="Mon, 14 Jan 2013 23:02:28 +0000"  >&lt;p&gt;Committed to 0.94. Thanks for the patch!&lt;/p&gt;</comment>
                            <comment id="13553329" author="hudson" created="Tue, 15 Jan 2013 00:26:57 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #732 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/732/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/732/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; Improve performance of scans with some kind of filters. (Sergey Shelukhin) (Revision 1433195)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/Filter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/FilterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/WhileMatchFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13553406" author="hudson" created="Tue, 15 Jan 2013 02:01:37 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3745 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3745/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3745/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7383&quot; title=&quot;create integration test for HBASE-5416 (improving scan performance for certain filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7383&quot;&gt;&lt;del&gt;HBASE-7383&lt;/del&gt;&lt;/a&gt; create integration test for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; (improving scan performance for certain filters) (Sergey) (Revision 1433224)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/test/LoadTestDataGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/test/LoadTestKVGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestLazyCfLoading.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedAction.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/RestartMetaTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13553712" author="hudson" created="Tue, 15 Jan 2013 11:55:07 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #348 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/348/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/348/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7383&quot; title=&quot;create integration test for HBASE-5416 (improving scan performance for certain filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7383&quot;&gt;&lt;del&gt;HBASE-7383&lt;/del&gt;&lt;/a&gt; create integration test for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; (improving scan performance for certain filters) (Sergey) (Revision 1433224)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/test/LoadTestDataGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/test/LoadTestKVGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestLazyCfLoading.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedAction.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/RestartMetaTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13554223" author="hudson" created="Tue, 15 Jan 2013 19:40:18 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #95 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/95/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/95/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; Improve performance of scans with some kind of filters. (Sergey Shelukhin) (Revision 1433195)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/Filter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/FilterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/WhileMatchFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13570945" author="hudson" created="Tue, 5 Feb 2013 03:58:17 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #11 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/11/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/11/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5416&quot; title=&quot;Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5416&quot;&gt;&lt;del&gt;HBASE-5416&lt;/del&gt;&lt;/a&gt; Improve performance of scans with some kind of filters. (Sergey Shelukhin) (Revision 1433195)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/Filter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/FilterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/filter/WhileMatchFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13584553" author="davelatham" created="Fri, 22 Feb 2013 19:05:40 +0000"  >&lt;p&gt;I have a class that directly implements the Filter interface.  This change looks to me like it will prevent me from doing a rolling upgrade to 0.94.5 of region servers while my client is using this filter on scans because the filter will fail to implement the changed interface.  Is that correct?  Is that acceptable?&lt;/p&gt;</comment>
                            <comment id="13584971" author="sershe" created="Sat, 23 Feb 2013 02:53:01 +0000"  >&lt;p&gt;Hmm, this is correct. I am not sure if this is acceptable, iirc I saw someone pondering that (on the mailing list?) but deciding that most people would use FilterBase, but I cannot find it now.&lt;br/&gt;
How hard is it to change filter to use FilterBase and replace it first?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Do you have an opinion?&lt;/p&gt;</comment>
                            <comment id="13585018" author="stack" created="Sat, 23 Feb 2013 05:45:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Would suggest backing out this change if it breaks compatibility, especially if it breaks compatibility for our homies in SOMA, SF.&lt;/p&gt;</comment>
                            <comment id="13585021" author="stack" created="Sat, 23 Feb 2013 05:47:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Thanks for adding it to trunk.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shmuma&quot; class=&quot;user-hover&quot; rel=&quot;shmuma&quot;&gt;Max Lapan&lt;/a&gt; Any chance of a paragraph on your fancy new feature?  If you draft it &amp;#8211; including the possibilities your patch enables &amp;#8211; I&apos;ll take care of getting it into the ref guide.  Good stuff.&lt;/p&gt;</comment>
                            <comment id="13585041" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 06:11:02 +0000"  >&lt;p&gt;The 0.94 patch did introduce subtle issue.&lt;/p&gt;

&lt;p&gt;But this feature is useful. See email thread entitled &apos;Co-Processor in scanning the HBase&apos;s Table&apos; on mailing list.&lt;/p&gt;

&lt;p&gt;The cause seems to be the addition of a new method to Filter interface. Can we do the following ?&lt;br/&gt;
1. introduce new interface, say Filter2 (open to other names), where isFamilyEssential(byte[] name) is added&lt;br/&gt;
2. move isFamilyEssential(byte[] name) out of Filter interface&lt;br/&gt;
3. let FilterBase implement Filter2&lt;br/&gt;
4. declare filter field of RegionScannerImpl to be of type Filter2&lt;/p&gt;

&lt;p&gt;Since 0.94.5 has been rolled out, it is another kind of regression if this feature is taken out.&lt;/p&gt;

&lt;p&gt;My two cents.&lt;/p&gt;</comment>
                            <comment id="13585048" author="lhofhansl" created="Sat, 23 Feb 2013 06:18:17 +0000"  >&lt;p&gt;IMHO this is similar to the coprocessor changes we had made in some 0.94 point releases that also break coprocessors (unless they derive from classes like BaseRegionObserver). In fact our own Phoenix folks ran into issues with this.&lt;/p&gt;

&lt;p&gt;These are somewhat internal APIs and we should be able to change them... Although I admit Filters are more stable in terms of APIs than coprocessors. Still, I&apos;d vote for keep this patch, unchanged.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davelatham&quot; class=&quot;user-hover&quot; rel=&quot;davelatham&quot;&gt;Dave Latham&lt;/a&gt;, I&apos;d be interested in why you had to implement Filter directly rather than extending FilterBase.&lt;/p&gt;</comment>
                            <comment id="13585055" author="stack" created="Sat, 23 Feb 2013 06:27:40 +0000"  >&lt;p&gt;There is no argument that this a &apos;useful&apos; feature.  &apos;useful&apos; is not good enough reason to break &apos;public&apos; Interface.  Why would we put any obstacle in the way of the group that is running the largest hbase deploy?  Don&apos;t they have enough headache already w/o having to jump a gratuitous incompatibility hurdle Anyone even &apos;need&apos; this feature in 0.94?  Suggest removing it for 0.90.6 so our man Dave can just go there.&lt;/p&gt;</comment>
                            <comment id="13585058" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 06:34:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davelatham&quot; class=&quot;user-hover&quot; rel=&quot;davelatham&quot;&gt;Dave Latham&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;:&lt;br/&gt;
What do you think of my proposal above (@23/Feb/13 06:11) ?&lt;/p&gt;

&lt;p&gt;Would that allow Dave to get over the hurdle ?&lt;/p&gt;

&lt;p&gt;If you think so, I can open a new JIRA with a patch.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13585062" author="lhofhansl" created="Sat, 23 Feb 2013 07:06:28 +0000"  >&lt;p&gt;A rolling upgrade is still possible if a stub isFamilyEssential(...) is added to the Filter implementation before the rolling upgrade.&lt;/p&gt;

&lt;p&gt;Anyway, I am not attached to this feature in 0.94.&lt;/p&gt;

&lt;p&gt;At the same time I do not want to cripple our ability to make some changes to these APIs. We have not frozen the coprocessor APIs and neither should we freeze the Filter APIs.&lt;br/&gt;
What if somebody had implemented a coprocessor API that we had changed. In the past we have stated that we will change these (coprocessor) APIs.&lt;/p&gt;

&lt;p&gt;Ted, I think your approach will just make things more complicated going forward. And I&apos;d prefer to either keep this or revert altogether.&lt;/p&gt;</comment>
                            <comment id="13585064" author="lhofhansl" created="Sat, 23 Feb 2013 07:25:35 +0000"  >&lt;p&gt;One last comment &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The reason why I am arguing keeping this is that this is one of the few features that allows HBase to make use to of its columnar nature to speed up queries.&lt;br/&gt;
HBase is not known for its scan performance and this is one features to point to where we allow HBase to not even look at another column family unless a filter is matched for potentially significant speedups. I was planning on extending this to other filters as well.&lt;/p&gt;</comment>
                            <comment id="13585131" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 14:48:58 +0000"  >&lt;p&gt;I am with Lars on this one. The feature should be part of 0.94&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ted, I think your approach will just make things more complicated going forward&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Another option is to drop the new method from Filter interface. Server side implementation depends on FilterBase which has the stub isFamilyEssential().&lt;br/&gt;
HRegion.RegionScannerImpl can use instanceof check which is fast.&lt;/p&gt;</comment>
                            <comment id="13585142" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 15:22:16 +0000"  >&lt;p&gt;A small patch illustrating my second approach.&lt;br/&gt;
All Filter tests passed based on this patch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Tests run: 108, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-surefire-plugin:2.10:test (secondPartTestsExecution) @ hbase ---
[INFO] Tests are skipped.
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;All scanner related tests also passed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Tests run: 65, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-surefire-plugin:2.10:test (secondPartTestsExecution) @ hbase ---
[INFO] Tests are skipped.
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:24.352s
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If people think this approach is Okay, I will open new JIRA and attach it there.&lt;/p&gt;</comment>
                            <comment id="13585148" author="davelatham" created="Sat, 23 Feb 2013 15:43:31 +0000"  >&lt;blockquote&gt;
&lt;p&gt;How hard is it to change filter to use FilterBase and replace it first?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The change is very simple for us.  It means we need to a wait a bit before deploying the hbase upgrade until we can upgrade our client apps first, though.  This is what we&apos;ve decided to do, so this incompatibility is not going to be a blocker for us, just a slight delay.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&apos;d be interested in why you had to implement Filter directly rather than extending FilterBase.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This particular Filter implementation was made as a wrapper around any other Filter as part of some experiments we were doing for more dynamic Filter classloading a couple years back.  I don&apos;t think there was a FilterBase class at the time or we may have just chose to make it a generic Filter (or actually RowFilterInterface back then) to make sure it implements and wraps every method.&lt;/p&gt;

&lt;p&gt;I think leaving the method in FilterBase only for 0.94 would be a good move.  However, it&apos;s a bit tricky since 0.94.5 has already been released.  If the method is dropped from Filter in 0.94.6 then we&apos;re saying 0.94.6 is compatible with everything but 0.94.5.  However if you were unfortunate enough to start on 0.94.5 and implement Filter directly then you&apos;re going to break again.  Perhaps that&apos;s a rare enough case.&lt;/p&gt;</comment>
                            <comment id="13585151" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 16:10:42 +0000"  >&lt;p&gt;@Dave:&lt;br/&gt;
0.94.5 was announced on 2013-02-16. If 0.94.6 is released within 10 days, the window of someone implementing 0.94.5 version of Filter interface is very short.&lt;/p&gt;

&lt;p&gt;In hindsight, we should have implemented this feature in 0.94 without touching Filter interface.&lt;br/&gt;
We have a good lesson (for other interfaces).&lt;/p&gt;

&lt;p&gt;If you want to deploy 0.94.5 in the next few days, try not adding @Override in your Filter implementation.&lt;/p&gt;

&lt;p&gt;Again, thanks for reporting this - other HBase users would get benefit.&lt;/p&gt;</comment>
                            <comment id="13585167" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 17:10:15 +0000"  >&lt;p&gt;testScanner_JoinedScanners passed as well:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Running org.apache.hadoop.hbase.regionserver.TestHRegion
2013-02-23 09:07:06.614 java[57714:1203] Unable to load realm info from SCDynamicStore
Tests run: 73, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.586 sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13585211" author="lhofhansl" created="Sat, 23 Feb 2013 20:33:45 +0000"  >&lt;p&gt;Moving the method to FilterBase is a great idea and a good compromise.&lt;/p&gt;

&lt;p&gt;Personally I think implementing Filters directly is rare and I would have a preference for keeping this in the interface since it is cleaner.&lt;br/&gt;
isFamilyEssential is very useful for future scan performance enhancements, I would hate to see it vanish again from the Filter interface. (Incidentally in trunk Filter is now a class, which would have allowed us to make changes without this problem).&lt;/p&gt;

&lt;p&gt;As alternative can we add to the Javadoc of Filter a note to avoid implementing it directly and rather extend FilterBase?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davelatham&quot; class=&quot;user-hover&quot; rel=&quot;davelatham&quot;&gt;Dave Latham&lt;/a&gt; If this is a hassle for you I think we&apos;re all in agreement that we should push the method down to FilterBase.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; I think you&apos;d prefer the push into FilterBase. Let&apos;s just do that.&lt;/p&gt;</comment>
                            <comment id="13585230" author="davelatham" created="Sat, 23 Feb 2013 23:48:23 +0000"  >&lt;p&gt;It&apos;s not going to make a difference for me any longer as we&apos;re planning to move forward with an application update then a 0.94.5 upgrade.  However, it sounds like a good plan to move to FilterBase (in the 0.94 branch only) to preserve compatibility for anyone else who comes along.&lt;/p&gt;</comment>
                            <comment id="13585233" author="stack" created="Sun, 24 Feb 2013 00:11:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;It&apos;s not going to make a difference for me any longer as we&apos;re planning to move forward with an application update then a 0.94.5 upgrade.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So, you don&apos;t need us back anything out?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What do you think of my proposal above (@23/Feb/13 06:11) ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can&apos;t find what you are referring to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ted_yu&quot; class=&quot;user-hover&quot; rel=&quot;ted_yu&quot;&gt;Ted Yu&lt;/a&gt;.  If i search I only see the above pointer.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Dave Latham If this is a hassle for you I think we&apos;re all in agreement that we should push the method down to FilterBase.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For 0.94?  If it means a better compatibility story (with a hiccup, i.e. we warn folks about prob. in 0.90.5 but its fixed in 0.90.6), then I&apos;m for it.&lt;/p&gt;</comment>
                            <comment id="13585237" author="yuzhihong@gmail.com" created="Sun, 24 Feb 2013 00:27:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;If i search I only see the above pointer.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was referring to approach #1 which Lars said is too complicated.&lt;/p&gt;</comment>
                            <comment id="13585242" author="yuzhihong@gmail.com" created="Sun, 24 Feb 2013 00:39:35 +0000"  >&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7920&quot; title=&quot;Move isFamilyEssential(byte[] name) out of Filter interface in 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7920&quot;&gt;&lt;del&gt;HBASE-7920&lt;/del&gt;&lt;/a&gt; to move the new method out of Filter interface.&lt;/p&gt;</comment>
                            <comment id="13585246" author="davelatham" created="Sun, 24 Feb 2013 01:30:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;So, you don&apos;t need us back anything out?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s right, we&apos;re just going to work around it.&lt;/p&gt;</comment>
                            <comment id="13585281" author="lhofhansl" created="Sun, 24 Feb 2013 04:07:34 +0000"  >&lt;p&gt;It feels a bit like an overreaction. Not many folks implement their own filters, of those not many implement Filter directly, there are workarounds, and for Dave it no longer matters.&lt;/p&gt;</comment>
                            <comment id="13625623" author="sershe" created="Mon, 8 Apr 2013 18:15:22 +0000"  >&lt;p&gt;what is this patch for in this JIRA? It&apos;s been closed months ago&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12624535">HBASE-7383</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13008490">HBASE-16731</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12633773">HBASE-7920</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12380212">HBASE-74</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13008481">HBASE-16729</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12642241">HBASE-8334</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12601187">HBASE-6499</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12562737" name="5416-0.94-v1.txt" size="33389" author="lhofhansl" created="Sun, 30 Dec 2012 23:39:06 +0000"/>
                            <attachment id="12562766" name="5416-0.94-v2.txt" size="33513" author="lhofhansl" created="Mon, 31 Dec 2012 06:49:33 +0000"/>
                            <attachment id="12564340" name="5416-0.94-v3.txt" size="33513" author="lhofhansl" created="Fri, 11 Jan 2013 03:25:13 +0000"/>
                            <attachment id="12530699" name="5416-Filtered_scans_v6.patch" size="22350" author="zhihyu@ebaysf.com" created="Sun, 3 Jun 2012 17:48:53 +0000"/>
                            <attachment id="12577471" name="5416-TestJoinedScanners-0.94.txt" size="6937" author="yuzhihong@gmail.com" created="Sun, 7 Apr 2013 23:11:39 +0000"/>
                            <attachment id="12570620" name="5416-drop-new-method-from-filter.txt" size="4633" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 15:22:16 +0000"/>
                            <attachment id="12562493" name="5416-v13.patch" size="60014" author="yuzhihong@gmail.com" created="Thu, 27 Dec 2012 17:22:17 +0000"/>
                            <attachment id="12562752" name="5416-v14.patch" size="59907" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 04:38:50 +0000"/>
                            <attachment id="12562757" name="5416-v15.patch" size="60056" author="yuzhihong@gmail.com" created="Mon, 31 Dec 2012 05:42:08 +0000"/>
                            <attachment id="12563434" name="5416-v16.patch" size="60073" author="yuzhihong@gmail.com" created="Sat, 5 Jan 2013 16:49:07 +0000"/>
                            <attachment id="12515923" name="5416-v5.txt" size="16315" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 14:46:06 +0000"/>
                            <attachment id="12515929" name="5416-v6.txt" size="15263" author="zhihyu@ebaysf.com" created="Fri, 24 Feb 2012 15:33:44 +0000"/>
                            <attachment id="12515249" name="Filtered_scans.patch" size="8474" author="shmuma" created="Mon, 20 Feb 2012 14:42:35 +0000"/>
                            <attachment id="12515558" name="Filtered_scans_v2.patch" size="10375" author="shmuma" created="Wed, 22 Feb 2012 09:06:19 +0000"/>
                            <attachment id="12515904" name="Filtered_scans_v3.patch" size="16353" author="shmuma" created="Fri, 24 Feb 2012 08:25:10 +0000"/>
                            <attachment id="12515906" name="Filtered_scans_v4.patch" size="16318" author="shmuma" created="Fri, 24 Feb 2012 09:44:20 +0000"/>
                            <attachment id="12529706" name="Filtered_scans_v5.1.patch" size="23182" author="shmuma" created="Fri, 25 May 2012 12:08:01 +0000"/>
                            <attachment id="12529071" name="Filtered_scans_v5.patch" size="22158" author="shmuma" created="Thu, 24 May 2012 14:32:47 +0000"/>
                            <attachment id="12534189" name="Filtered_scans_v7.patch" size="32508" author="shmuma" created="Mon, 2 Jul 2012 08:52:48 +0000"/>
                            <attachment id="12561614" name="HBASE-5416-v10.patch" size="61258" author="sershe" created="Wed, 19 Dec 2012 00:31:07 +0000"/>
                            <attachment id="12561806" name="HBASE-5416-v11.patch" size="61912" author="sershe" created="Wed, 19 Dec 2012 23:07:18 +0000"/>
                            <attachment id="12562033" name="HBASE-5416-v12.patch" size="65539" author="sershe" created="Fri, 21 Dec 2012 03:23:22 +0000"/>
                            <attachment id="12562021" name="HBASE-5416-v12.patch" size="65527" author="sershe" created="Fri, 21 Dec 2012 01:26:12 +0000"/>
                            <attachment id="12560912" name="HBASE-5416-v7-rebased.patch" size="33268" author="sershe" created="Fri, 14 Dec 2012 03:31:27 +0000"/>
                            <attachment id="12561070" name="HBASE-5416-v8.patch" size="60644" author="sershe" created="Sat, 15 Dec 2012 00:26:33 +0000"/>
                            <attachment id="12561329" name="HBASE-5416-v9.patch" size="60661" author="sershe" created="Mon, 17 Dec 2012 18:54:48 +0000"/>
                            <attachment id="12564330" name="org.apache.hadoop.hbase.regionserver.TestHRegion-output.txt" size="4437693" author="yuzhihong@gmail.com" created="Fri, 11 Jan 2013 02:36:24 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12641769">HBASE-8316</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>27.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 Feb 2012 20:32:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>228205</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 36 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i00shz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2549</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>New method is added to Filter which allows filter to specify which CF is needed to it&amp;#39;s operation.&lt;br/&gt;
&lt;br/&gt;
public boolean isFamilyEssential(byte[] name);&lt;br/&gt;
&lt;br/&gt;
When new row is considered, only data for essential family is loaded and filter applied. And only if filter accepts the row, rest of data is loaded.&lt;br/&gt;
&lt;br/&gt;
This feature is off by default. You can use Scan.setLoadColumnFamiliesOnDemand() to enable it on a per Scan basis. If not indicated for the Scan, boolean value for &amp;quot;hbase.hregion.scan.loadColumnFamiliesOnDemand&amp;quot; would be used (default to false).</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>