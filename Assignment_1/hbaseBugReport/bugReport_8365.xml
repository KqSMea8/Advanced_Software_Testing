<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:54:32 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8365/HBASE-8365.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8365] Duplicated ZK notifications cause Master abort (or other unknown issues)</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8365</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The duplicated ZK notifications should happen in trunk as well. Since the way we handle ZK notifications is different in trunk, we don&apos;t see the issue there. I&apos;ll explain later.&lt;/p&gt;

&lt;p&gt;The issue is causing TestMetaReaderEditor.testRetrying flaky with error message &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;reader: count=2, t=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; A related link is at &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/941/testReport/junit/org.apache.hadoop.hbase.catalog/TestMetaReaderEditor/testRetrying/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/941/testReport/junit/org.apache.hadoop.hbase.catalog/TestMetaReaderEditor/testRetrying/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The test case failure is due to an IllegalStateException and master is aborted so the rest test cases also failed after testRetrying.&lt;/p&gt;

&lt;p&gt;Below are steps why the issue is happening(region fa0e7a5590feb69bd065fbc99c228b36 is in interests):&lt;/p&gt;

&lt;p&gt;1) Got first notification event RS_ZK_REGION_FAILED_OPEN at 2013-04-04 17:39:01,197&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; DEBUG [pool-1-thread-1-EventThread] master.AssignmentManager(744): Handling transition=RS_ZK_REGION_FAILED_OPEN, server=janus.apache.org,42093,1365097126155, region=fa0e7a5590feb69bd065fbc99c228b36&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the step, AM tries to open the region on another RS in a separate thread&lt;/p&gt;

&lt;p&gt;2) Got second notification event RS_ZK_REGION_FAILED_OPEN at 2013-04-04 17:39:01,200 &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DEBUG [pool-1-thread-1-EventThread] master.AssignmentManager(744): Handling transition=RS_ZK_REGION_FAILED_OPEN, server=janus.apache.org,42093,1365097126155, region=fa0e7a5590feb69bd065fbc99c228b36&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;3) Later got opening notification event result from the step 1 at 2013-04-04 17:39:01,288 &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; DEBUG [pool-1-thread-1-EventThread] master.AssignmentManager(744): Handling transition=RS_ZK_REGION_OPENING, server=janus.apache.org,54833,1365097126175, region=fa0e7a5590feb69bd065fbc99c228b36&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Step 2 ClosedRegionHandler throws IllegalStateException because &quot;Cannot transit it to OFFLINE&quot;(state is in opening from notification 3) and abort Master. This could happen in 0.94 because we handle notifications using executorService which opens the door to handle events out of order through receive them in order of updates.&lt;/p&gt;

&lt;p&gt;I&apos;ve confirmed that we don&apos;t have duplicated AM listeners and both events triggered by same ZK data of exact same version. The issue can be reproduced once by running testRetrying test case 20 times in a loop.&lt;/p&gt;

&lt;p&gt;There are several issues for the failure:&lt;/p&gt;

&lt;p&gt;1) duplicated ZK notifications. Since ZK watcher is one time trigger, the duplicated notification should not happen from the same data of the same version in the first place&lt;/p&gt;

&lt;p&gt;2) ZooKeeper watcher handling is wrong in both 0.94 and trunk as following:&lt;br/&gt;
a) 0.94 handle notifications in async way which may lead to handle notifications out of order of the events happened&lt;br/&gt;
b) In trunk, we handle ZK notifications synchronously which slows down other components such as SSH, LogSplitting etc. because we have a single notification queue&lt;br/&gt;
c) In trunk &amp;amp; 0.94, we could use stale event data because we have a long listener list. ZK node state could have changed at the time when handling the event. If a listener needs to act upon latest state, it should re-fetch the data to verify if the data triggered the handler hasn&apos;t changed.&lt;/p&gt;

&lt;p&gt;Suggestions:&lt;br/&gt;
For 0.94, we can bandit the CloseRegionHandler to pass in the expected ZK data version to skip event handling on stale data with min impact.&lt;/p&gt;

&lt;p&gt;For trunk, I&apos;ll open an improvement JIRA on ZK notification handling to provide more parallelism to handle unrelated notifications.&lt;/p&gt;

&lt;p&gt;For the duplicated ZK notifications, we need bring some ZK experters to take a look at this.&lt;/p&gt;

&lt;p&gt;Please let me know what you think or any better idea.&lt;br/&gt;
Thanks!&lt;/p&gt;</description>
                <environment></environment>
        <key id="12643030">HBASE-8365</key>
            <summary>Duplicated ZK notifications cause Master abort (or other unknown issues)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="ram_krish">ramkrishna.s.vasudevan</assignee>
                                    <reporter username="jeffreyz">Jeffrey Zhong</reporter>
                        <labels>
                    </labels>
                <created>Wed, 17 Apr 2013 20:56:02 +0000</created>
                <updated>Tue, 28 May 2013 21:09:04 +0000</updated>
                                            <version>0.94.6</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13634437" author="jeffreyz" created="Wed, 17 Apr 2013 21:03:04 +0000"  >&lt;p&gt;Attached test failure log in case it&apos;s removed from Jenkins later.&lt;/p&gt;</comment>
                            <comment id="13634447" author="jxiang" created="Wed, 17 Apr 2013 21:10:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;a) 0.94 handle notifications in async way which may lead to handle notifications out of order of the events happened&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do you mean the events generated on one same znode?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;b) In trunk, we handle ZK notifications synchronously which slows down other components such as SSH, LogSplitting etc. because we have a single notification queue&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Which patch is in 0.94, but not in trunk to make this difference?&lt;/p&gt;</comment>
                            <comment id="13634452" author="jeffreyz" created="Wed, 17 Apr 2013 21:19:16 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Do you mean the events generated on one same znode?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, on the same unsigned region znode and the znode data has the ZK same version for the two notification events on failed_open. I also confirmed that we don&apos;t have two AM listeners at the same time(by added more trace and reproed the issue)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Which patch is in 0.94, but not in trunk to make this difference?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Since trunk handle notifications synchronously, that&apos;s why we don&apos;t see the issue in trunk. I saw there was a patch(changing to sync way) before 0.95 module changes But I don&apos;t have much history on that.&lt;/p&gt;
</comment>
                            <comment id="13634479" author="jxiang" created="Wed, 17 Apr 2013 21:45:40 +0000"  >&lt;p&gt;As to assignment related ZK notifications, in 0.94, it is very likely because different entities (assignment manager, timeout monitor, open/close region handlers) race against each other.&lt;/p&gt;

&lt;p&gt;In trunk, as to the assignment related ZK events processing, a separated thread pool is used, so other components should not be slowed down.&lt;/p&gt;</comment>
                            <comment id="13634530" author="jeffreyz" created="Wed, 17 Apr 2013 22:30:22 +0000"  >&lt;blockquote&gt;
&lt;p&gt;In trunk, as to the assignment related ZK events processing, a separated thread pool is used, so other components should not be slowed down&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You&apos;re right. I think we can do better to generalize this strategy into ZooKeeperWatcher to all listeners so that listeners won&apos;t interfere with each other. I&apos;ve some suggestions documented in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8368&quot; title=&quot;Improve ZK notification handling in Master&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8368&quot;&gt;HBASE-8368&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="13635031" author="ram_krish" created="Thu, 18 Apr 2013 09:37:51 +0000"  >&lt;p&gt;I went thro the logs once again. One thing that is surprising is How did two nodeDataChangedEvent occur for FAILED_OPEN.&lt;/p&gt;


&lt;p&gt;Is it like when the znode got changed to OPENING twice and then to FAILED_OPEN for each change we got one event and by the time it tried to process the first two times the data it got was FAILED_OPEN but the third time it was OPENING due to some other latest assign opeartion?&lt;/p&gt;

&lt;p&gt;Thanks.  &lt;/p&gt;</comment>
                            <comment id="13635041" author="ram_krish" created="Thu, 18 Apr 2013 09:50:56 +0000"  >&lt;p&gt;If i recollect from what i have debugged is that the nodeDataChangeEvent only will give the latest data because it will not be able to read the old data.&lt;br/&gt;
I may be wrong here.&lt;/p&gt;</comment>
                            <comment id="13635488" author="jeffreyz" created="Thu, 18 Apr 2013 18:29:46 +0000"  >&lt;blockquote&gt;
&lt;p&gt;nodeDataChangeEvent only will give the latest data because it will not be able to read the old data&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;ZooKeeper intentionally only sends out notifications without passing the original state which triggers the notification. It relies on clients to fetch the latest state. In addition, ZooKeeper watcher is one-time trigger which means it only fire once and client need re-setup watcher on the same znode to get next notification.&lt;/p&gt;

&lt;p&gt;In our case, from the log, the related updates with watcher set on the region are: 1) opening-&amp;gt;opening 2) opening-&amp;gt;failed_open 3) failed_open-&amp;gt;offline 4) offline-&amp;gt;opening&lt;/p&gt;

&lt;p&gt;The first notification(when we got FAILED_OPEN) is triggered by the update of opening-&amp;gt;opening. When Master got the notification and znode was already changed to failed_open, that&apos;s the first trace nodeDataChange. &lt;/p&gt;

&lt;p&gt;The thing puzzles me is that ZooKeeper watcher will reset up on failed_open state after receiving the first failed_open and should only get more notifications when failed_open state changes. While we still get one more failed_open later from the same znode and data has the same version as we received the first notification. I guess we may trigger ZK client reads stale cache data when the node state changes from failed_open -&amp;gt; offline OR race conditions in ZK side to cause the dup notifications.&lt;/p&gt;



</comment>
                            <comment id="13635505" author="rajesh23" created="Thu, 18 Apr 2013 18:40:59 +0000"  >&lt;p&gt;Recently I have also observed duplicated zk notifications. FYI attaching logs. These also may useful for analysis. I have tried to debug but not able to reproduce.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-04-07 12:14:50,735 INFO  [hbase-am-zkevent-worker-pool-20-thread-7] master.RegionStates(264): Region {NAME =&amp;gt; &apos;testLogSplittingAfterMasterRecoveryDueToZKExpiry,,1365336889784.fb4182aef4ce07f011871ae0a083aee0.&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;1&apos;, ENCODED =&amp;gt; fb4182aef4ce07f011871ae0a083aee0,} transitioned from {testLogSplittingAfterMasterRecoveryDueToZKExpiry,,1365336889784.fb4182aef4ce07f011871ae0a083aee0. state=OPENING, ts=1365336890719, server=asf001.sp2.ygridcore.net,60884,1365336878389} to {testLogSplittingAfterMasterRecoveryDueToZKExpiry,,1365336889784.fb4182aef4ce07f011871ae0a083aee0. state=OPEN, ts=1365336890735, server=asf001.sp2.ygridcore.net,60884,1365336878389}
2013-04-07 12:14:50,735 DEBUG [hbase-am-zkevent-worker-pool-2-thread-20] master.AssignmentManager(740): Handling transition=RS_ZK_REGION_OPENED, server=asf001.sp2.ygridcore.net,60884,1365336878389, region=fb4182aef4ce07f011871ae0a083aee0, current state from region state map ={testLogSplittingAfterMasterRecoveryDueToZKExpiry,,1365336889784.fb4182aef4ce07f011871ae0a083aee0. state=OPEN, ts=1365336890727, server=asf001.sp2.ygridcore.net,60884,1365336878389}
2013-04-07 12:14:50,736 WARN  [hbase-am-zkevent-worker-pool-2-thread-20] master.AssignmentManager(934): Received OPENED &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region fb4182aef4ce07f011871ae0a083aee0 from server asf001.sp2.ygridcore.net,60884,1365336878389 but region was in the state {testLogSplittingAfterMasterRecoveryDueToZKExpiry,,1365336889784.fb4182aef4ce07f011871ae0a083aee0. state=OPEN, ts=1365336890727, server=asf001.sp2.ygridcore.net,60884,1365336878389} and not in expected PENDING_OPEN or OPENING states, or not on the expected server
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13635915" author="yuzhihong@gmail.com" created="Fri, 19 Apr 2013 01:14:50 +0000"  >&lt;p&gt;As an interim measure, can we maintain the tuples (znode path, data, version) from zk notifications so that we can detect duplicate notification ?&lt;br/&gt;
The tuples would expire after configurable period of time.&lt;/p&gt;</comment>
                            <comment id="13636029" author="ram_krish" created="Fri, 19 Apr 2013 04:04:16 +0000"  >&lt;p&gt;Pls let me know if we can solve this with something like this,&lt;br/&gt;
Have an Atomic Integer that is assocaited with every state in handle region.  &lt;br/&gt;
Create a map with regionName and this atomic integer.&lt;/p&gt;

&lt;p&gt;Assume OPENING - 1, FAILED_OPEN -2 and OPENED - 3.&lt;br/&gt;
When OPENING handleRegion() gets called since the value is not 1 we go and set the atomic integer in the map to 1.&lt;br/&gt;
Next if FAILED_OPEN update the same to 2.&lt;/p&gt;

&lt;p&gt;Now as in this case if two times FAILED_OPEN comes we don&apos;t set this and avoid handleRegion from processing.  &lt;br/&gt;
As Jeff also pointed out, the notification happens but it is left to the listener to read the data.  So this means that we are going to work on the latest data only. And so what ever handleREgion() operation we are doing is for the latest data.&lt;/p&gt;

&lt;p&gt;After OPENED is done we need to clear this map also like we clear RIT and onlineRegions map.&lt;/p&gt;

&lt;p&gt;Cons:&lt;br/&gt;
Another map and need to handle synchronization issues.  &lt;/p&gt;

&lt;p&gt;What do you suggest?  Is it possible to do like this?&lt;/p&gt;</comment>
                            <comment id="13636173" author="jeffreyz" created="Fri, 19 Apr 2013 08:05:54 +0000"  >&lt;p&gt;I think both Ram &amp;amp; Ted&apos;s suggestion should work assuming the duplicated notifications come in together. &lt;/p&gt;

&lt;p&gt;The third option is to use trunk AssignmentManager way to handle assignment notifications in a separate thread pool, proces notifications in the order of receiving and act upon almost up to date data. It seems the code isn&apos;t that much to copy over.&lt;/p&gt;</comment>
                            <comment id="13640065" author="ram_krish" created="Wed, 24 Apr 2013 04:30:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;&lt;br/&gt;
But taking up the third option will have an impact on performance on the assignments?&lt;br/&gt;
I can take this up and implement either third or any of the suggestion made above?&lt;/p&gt;</comment>
                            <comment id="13640089" author="jeffreyz" created="Wed, 24 Apr 2013 05:16:13 +0000"  >&lt;blockquote&gt;
&lt;p&gt;But taking up the third option will have an impact on performance on the assignments?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The 0.96 AM ZK notification handling does a very good job. It basically handles same region synchronously while still keep parallelism for different regions. The main difference between option3 and option2 is that option3 can guarantee to handle ZK notifications in the receiving order.&lt;/p&gt;

&lt;p&gt;Please take it over otherwise I can pick it up next week. Thanks.&lt;/p&gt;</comment>
                            <comment id="13641336" author="ram_krish" created="Thu, 25 Apr 2013 02:56:35 +0000"  >&lt;p&gt;Let me try working on the backport this week.&lt;/p&gt;</comment>
                            <comment id="13659201" author="ram_krish" created="Thu, 16 May 2013 04:08:07 +0000"  >&lt;p&gt;I will prepare the backport patch and also one of the suggestions above.&lt;/p&gt;</comment>
                            <comment id="13663780" author="ram_krish" created="Wed, 22 May 2013 05:04:35 +0000"  >&lt;p&gt;So if i go with backport only the ZkEventworkers and the runnable things need to be backported?  In trunk there are also these Locking mechanisms also.&lt;br/&gt;
What others feel? &lt;/p&gt;</comment>
                            <comment id="13663833" author="jeffreyz" created="Wed, 22 May 2013 06:16:56 +0000"  >&lt;p&gt;If we backport then we need to backport ZkEventworkers, interface RegionRunnable and two other data structures: zkEventWorkerWaitingList and regionsInProgress. &lt;/p&gt;

&lt;p&gt;This maybe a little bit too much for 0.94, I think you can go with other options listed above for simplifications. The cons are just that we may still possibly handle ZK notifications not in receiving order.&lt;/p&gt;</comment>
                            <comment id="13663836" author="ram_krish" created="Wed, 22 May 2013 06:20:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;interface RegionRunnable and two other data structures: zkEventWorkerWaitingList and regionsInProgress.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;These are simple changes and basically things work on introducing these stuff. But only the locking mechanism seems to be a big change.&lt;br/&gt;
Ok will anyway try out the other options also and post here.&lt;/p&gt;</comment>
                            <comment id="13666234" author="ram_krish" created="Fri, 24 May 2013 11:57:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;&lt;br/&gt;
I think though the trunk handles the notifications in order there is chance that the duplicate notification may happen at a later point of time?&lt;br/&gt;
So whatever happened in the above logs could happen in trunk also right?  Just asking to confirm so that can think of solving this in both trunk and 0.94.&lt;/p&gt;</comment>
                            <comment id="13668679" author="jeffreyz" created="Tue, 28 May 2013 21:09:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Actually it&apos;s very unlikely to cause any issue in trunk(Zookeeper may still generate dup notifications). Because trunk Assignment Manager code handle one region at one time and only re-register watcher right before AM handling a notification. Let&apos;s say in trunk we firstly get a &quot;failed_open&quot; ZK notification, we only re-register a watcher right before the handling starts. In other words, the time window between we received a notification and we process the notification, we won&apos;t receive any ZK notification. &lt;/p&gt;

&lt;p&gt;In 0.94, because of the async(executorService.submit) nature, we immediately reregister watcher on a region which triggered the notification while actual handling may happen later at some time. In addition, there is no sync control, multiple sources could touch same region concurrently. It creates the possibility that two handlers to handle same notification in 0.94.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12579198" name="TestResult.txt" size="912312" author="jeffreyz" created="Wed, 17 Apr 2013 21:03:04 +0000"/>
                            <attachment id="12579387" name="TestZookeeper.txt" size="1013975" author="rajesh23" created="Thu, 18 Apr 2013 18:40:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 17 Apr 2013 21:10:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323440</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 29 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1jsxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323785</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>