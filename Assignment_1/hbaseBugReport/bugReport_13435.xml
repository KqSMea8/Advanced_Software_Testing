<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:43:18 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-13435/HBASE-13435.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-13435] Scan with PrefixFilter, Range filter, column filter, or all 3 returns OutOfOrderScannerNextException</title>
                <link>https://issues.apache.org/jira/browse/HBASE-13435</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We&apos;ve run this with an hbase shell prefix filter, tried with column, range filters, and limits, and tried doing a pig script &amp;#8211; which we knew was going to be less performant but thought it could work with the same, simple purpose. We wanted to select a specific user&apos;s data from a few days (14 ish) worth of data. We also tried selecting a few hours worth of data as a work around, to no avail. In pig, we switched it to just give us all the data for the two week time range.&lt;/p&gt;

&lt;p&gt;The errors look like RPC timeouts, but we don&apos;t feel it should be happening and that pig/hbase/both should be able to handle these &quot;queries&quot;, if you will.&lt;/p&gt;

&lt;p&gt;The error we get in both the hbase shell and in pig boils down to &quot;possible RPC timeout?&quot;. Literally says &quot;?&quot; in the message. &lt;/p&gt;

&lt;p&gt;We saw this stack overflow, but it&apos;s not very helpful. I also saw a few hbase tickets, none of which are super helpful and none indicate that this was an issue fixed in hbase 0.99 or anything newer that what we have. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/26437830/hbase-shell-outoforderscannernextexception-error-on-scanner-count-calls&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/26437830/hbase-shell-outoforderscannernextexception-error-on-scanner-count-calls&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Here are the down and dirty deets: &lt;/p&gt;

&lt;p&gt;Pig script: &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; 
hbase_records = LOAD &apos;hbase:&lt;span class=&quot;code-comment&quot;&gt;//impression_event_production_hbase&apos; 
&lt;/span&gt;USING org.apache.pig.backend.hadoop.hbase.HBaseStorage( 
&apos;cf1:uid:chararray,cf1:ts:chararray,cf1:data_regime_id:chararray,cf1:ago:chararray,cf1:ao:chararray,cf1:aca:chararray,cf1:si:chararray,cf1:ci:chararray,cf1:kv0:chararray,cf1:g_id:chararray,cf1:h_id:chararray,cf1:cg:chararray,cf1:kv1:chararray,cf1:kv2:chararray,cf1:kv3:chararray,cf1:kv4:chararray,cf1:kv5:chararray,cf1:kv6:chararray,cf1:kv7:chararray,cf1:kv8:chararray,cf1:kv9:chararray&apos;,
&apos;-loadKey=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; -minTimestamp=1427299200000 -maxTimestamp=1428551999000&apos;) 
AS 
(uid,ts,data_regime_id,ago,ao,aca,si,ci,kv0,g_id,h_id,cg,kv1,kv2,kv3,kv4,kv5,kv6,kv7,kv8,kv9); 

store hbase_records into &apos;output_place&apos;; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Error: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; 
2015-04-08 20:18:35,316 [main] INFO org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Failed! 
2015-04-08 20:18:35,610 [main] ERROR org.apache.pig.tools.grunt.GruntParser - ERROR 2997: Unable to recreate exception from backed error: Error: org.apache.hadoop.hbase.DoNotRetryIOException: Failed after retry of OutOfOrderScannerNextException: was there a rpc timeout? 
at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:403) 
at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.nextKeyValue(TableRecordReaderImpl.java:232) 
at org.apache.hadoop.hbase.mapreduce.TableRecordReader.nextKeyValue(TableRecordReader.java:138) 
at org.apache.pig.backend.hadoop.hbase.HBaseTableInputFormat$HBaseTableRecordReader.nextKeyValue(HBaseTableInputFormat.java:162) 
at org.apache.pig.backend.hadoop.hbase.HBaseStorage.getNext(HBaseStorage.java:645) 
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.nextKeyValue(PigRecordReader.java:204) 
at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533) 
at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80) 
at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91) 
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144) 
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764) 
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340) 
at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:415) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557) 
at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162) 
Caused by: org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: Expected nextCallSeq: 1 But the nextCallSeq got from client: 0; request=scanner_id: 4919882396333524452 number_of_rows: 100 close_scanner: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; next_call_seq: 0 
at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3110) 
at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:28861) 
at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2008) 
at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:92) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110) 
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744) 

at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) 
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) 
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) 
at java.lang.reflect.Constructor.newInstance(Constructor.java:526) 
at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) 
at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95) 
at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:285) 
at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:204) 
at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59) 
at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:114) 
at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:90) 
at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:355) 
... 16 more 
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException): org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: Expected nextCallSeq: 1 But the nextCallSeq got from client: 0; request=scanner_id: 4919882396333524452 number_of_rows: 100 close_scanner: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; next_call_seq: 0 
at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3110) 
at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:28861) 
at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2008) 
at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:92) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110) 
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744) 

at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1457) 
at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661) 
at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719) 
at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:29990) 
at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:174) 
... 20 more 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 


&lt;p&gt;HBase shell command: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; 
1.9.3-p194 :014 &amp;gt; scan &apos;impression_event_production_hbase&apos;, {FILTER=&amp;gt;&lt;span class=&quot;code-quote&quot;&gt;&quot;(PrefixFilter(&apos;oPbHNBCaRn6T&apos;))&quot;&lt;/span&gt;} 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Error: &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; 
ROW COLUMN+CELL 

ERROR: org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: Expected nextCallSeq: 1 But the nextCallSeq got from client: 0; request=scanner_id: 2229260827522260650 number_of_rows: 100 close_scanner: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; next_call_seq: 0 
at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3110) 
at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:28861) 
at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2008) 
at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:92) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38) 
at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110) 
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744) 

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
</description>
                <environment></environment>
        <key id="12819468">HBASE-13435</key>
            <summary>Scan with PrefixFilter, Range filter, column filter, or all 3 returns OutOfOrderScannerNextException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="wattsinabox">William Watson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Apr 2015 21:44:22 +0000</created>
                <updated>Fri, 12 Jun 2015 00:46:09 +0000</updated>
                            <resolved>Fri, 12 Jun 2015 00:46:09 +0000</resolved>
                                                                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="14510445" author="qixi" created="Fri, 24 Apr 2015 04:21:44 +0000"  >&lt;p&gt;I add timerange on hbae 0.98.6 cdh verion,have the same error. &lt;/p&gt;</comment>
                            <comment id="14510462" author="lhofhansl" created="Fri, 24 Apr 2015 04:56:28 +0000"  >&lt;p&gt;You should really ask these things on the HBase mailing lists.&lt;/p&gt;</comment>
                            <comment id="14515146" author="wattsinabox" created="Mon, 27 Apr 2015 22:33:25 +0000"  >&lt;p&gt;I don&apos;t think my affects version was right and I edited the name of the error. I&apos;ll post to the mailing list.&lt;/p&gt;</comment>
                            <comment id="14516352" author="anoop.hbase" created="Tue, 28 Apr 2015 04:48:31 +0000"  >&lt;p&gt;The issue here is that the filters filtering out cells at server and you might have a bigger caching value for the Scan.  By the time the server side is able to get those many rows, the scanner timeout and/or rpc time outs are happening. The client, on time out , will issue the same call again. But at server we have advanced the scanner. So this duplicate request we can not agree for.  This is by the server throws OutOfOrderException.  On receiving this, the client restart the scan.  (Not just call next but setup it newly).  But I guess again the same issue of longer time happens.  At client, we will retry for only one more time after a OutOfOrderScannerNextException.    You have tune your scan caching value and/or timeouts values.&lt;/p&gt;

&lt;p&gt;Though in trunk we have nice feature addition, where we will return heart beat Results back to client and avoid the timeouts for such longer scans. JFYI.&lt;/p&gt;</comment>
                            <comment id="14521781" author="lhofhansl" created="Thu, 30 Apr 2015 16:35:11 +0000"  >&lt;p&gt;I suppose the main issue is that - in the extreme - there&apos;s not a single Cell in an entire region that matches the filter condition. Even when scanner caching is set to 1 the region server will still exhaust the entire region before returning anything to the client. By that time the client might have timed out.&lt;/p&gt;

&lt;p&gt;The short fix is to increase the timeouts for the client.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13090&quot; title=&quot;Progress heartbeats for long running scanners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13090&quot;&gt;&lt;del&gt;HBASE-13090&lt;/del&gt;&lt;/a&gt; allows the server to heartbeat the client.. In 1.1+.&lt;/p&gt;

&lt;p&gt;The other question is, why does it take that long to scan through an entire region? Region are 10g max (by default), to scan through that in 1 minute would require 170mb/s. With a few disks that should be in the realm of the possible (note that since we&apos;re filtering it&apos;s just the work of locally reading through the cell at the server)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13109&quot; title=&quot;Make better SEEK vs SKIP decisions during scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13109&quot;&gt;&lt;del&gt;HBASE-13109&lt;/del&gt;&lt;/a&gt; will help too. It will speed up the scanning in most cases when filters skip with SEEK_COL and SEEK_ROW.&lt;/p&gt;</comment>
                            <comment id="14582746" author="apurtell" created="Fri, 12 Jun 2015 00:46:09 +0000"  >&lt;p&gt;We have several JIRAs that duplicate this. Search for &apos;OutOfOrderScannerNextException&apos;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Apr 2015 04:21:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 27 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2czxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>