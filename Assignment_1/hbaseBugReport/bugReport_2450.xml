<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:02:00 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2450/HBASE-2450.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2450] For single row reads of specific columns, seek to the first column in HFiles rather than start of row</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2450</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently we will always seek to the start of a row.  If we are getting specific columns, we should seek to the first column in that row.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12462095">HBASE-2450</key>
            <summary>For single row reads of specific columns, seek to the first column in HFiles rather than start of row</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pranavkhaitan">Pranav Khaitan</assignee>
                                    <reporter username="streamy">Jonathan Gray</reporter>
                        <labels>
                            <label>moved_from_0_20_5</label>
                    </labels>
                <created>Wed, 14 Apr 2010 23:46:18 +0000</created>
                <updated>Fri, 20 Nov 2015 12:42:24 +0000</updated>
                            <resolved>Wed, 22 Sep 2010 23:52:51 +0000</resolved>
                                                    <fixVersion>0.90.0</fixVersion>
                                    <component>io</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="12857152" author="streamy" created="Wed, 14 Apr 2010 23:47:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2450&quot; title=&quot;For single row reads of specific columns, seek to the first column in HFiles rather than start of row&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2450&quot;&gt;&lt;del&gt;HBASE-2450&lt;/del&gt;&lt;/a&gt; is a good first step towards &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1517&quot; title=&quot;Implement inexpensive seek operations in HFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1517&quot;&gt;&lt;del&gt;HBASE-1517&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12857327" author="erik_h" created="Thu, 15 Apr 2010 14:07:24 +0000"  >&lt;p&gt;If you seek to the to the start column instead of the beginning of the row, wouldn&apos;t there be a chance&lt;br/&gt;
of missing deletes?&lt;/p&gt;</comment>
                            <comment id="12857340" author="stack" created="Thu, 15 Apr 2010 14:48:03 +0000"  >&lt;p&gt;@Erik Good point&lt;/p&gt;</comment>
                            <comment id="12857476" author="karthik.ranga" created="Thu, 15 Apr 2010 18:33:36 +0000"  >&lt;p&gt;The reason that we might miss the delete is because the minor compactions do not respect deletes. Would it be worthwhile investigating if the minor compactions can process the deletes but leave the delete tombstone till the major compactions? &lt;/p&gt;

&lt;p&gt;On a broader note, it seems to me that the design and the code will get a lot simpler if we can maintain only one compaction path (except for minors leaving behind some tombstones). Jonathan told me this was done to make the minor compactions more efficient - do we have an idea on how much we gain with this optimization?&lt;/p&gt;
</comment>
                            <comment id="12857482" author="streamy" created="Thu, 15 Apr 2010 18:51:26 +0000"  >&lt;p&gt;I&apos;m not sure it&apos;s actually only related to minors not respecting deletes (and actually, they currently do process the deletes and leave the tombstones as well to keep our existing invariant that the current files deletes only apply to later files).&lt;/p&gt;

&lt;p&gt;If we have a delete row, for example, it would be at the start of the row so if we seeked directly to the column in question, we would skip past the delete row which could actually apply to the column we&apos;re looking for.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure how much additional complexity is added by having separate minor and major code paths.  There&apos;s not a heck of a lot of difference and it&apos;s mostly just having one path use certain elements of our normal read path stuff (delete trackers, query matcher, etc).  As I recall, there was a significant performance hit doing the processing required for majors vs minors, but also I don&apos;t think at the time we were using the ScanDeleteTracker on minors as we are today.  We should probably do some benchmarking to just find out.&lt;/p&gt;

&lt;p&gt;Good catch Erik.  We need to think about this more.  We should still be able to start at the front of the row and once past any full row deletes then skip down to the column in question (using something like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1517&quot; title=&quot;Implement inexpensive seek operations in HFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1517&quot;&gt;&lt;del&gt;HBASE-1517&lt;/del&gt;&lt;/a&gt;)... right?&lt;/p&gt;</comment>
                            <comment id="12857491" author="kannanm" created="Thu, 15 Apr 2010 19:10:03 +0000"  >&lt;p&gt;I like the idea of having the same code for minor &amp;amp; major compactions the same-- to avoid having another class of subtle behavioral differences.&lt;/p&gt;

&lt;p&gt;If minor compactions processed deletes like major compactions, then the case Erik is concerned about shouldn&apos;t arise, correct?&lt;/p&gt;

&lt;p&gt;regards,&lt;br/&gt;
Kannan&lt;/p&gt;</comment>
                            <comment id="12857495" author="streamy" created="Thu, 15 Apr 2010 19:15:16 +0000"  >&lt;p&gt;Read my above comment about why there&apos;s a problem with deletes that doesn&apos;t only relate to minors.&lt;/p&gt;

&lt;p&gt;So is argument for same code to not have behavioral differences?  or to reduce code complexity?  Sounded like you are saying the former, karthik the latter.&lt;/p&gt;

&lt;p&gt;One of the reasons they are different is this is how it is explained in the bigtable paper.  There will be a cost to processing stuff.&lt;/p&gt;

&lt;p&gt;In any case, they will always need to be different in some way.  Minors must always retain deletes, whether they are actually deleted in the compacted files themselves or not.  Majors are able to actually clear away deletes because a major is always every single file.&lt;/p&gt;</comment>
                            <comment id="12857512" author="streamy" created="Thu, 15 Apr 2010 19:54:02 +0000"  >&lt;p&gt;Spoke w/ kannan/karthik offline and added clarity to the issue here by talking about case of multiple files.  Whether a minor removes deleted stuff or not, we&apos;ll always have to read any row deletes because they could apply to both newer and older storefiles.  This is the major difference between majors and minors, that a major always includes all files.&lt;/p&gt;

&lt;p&gt;Another issue we brought up, beyond the scope of this jira but still interesting, is whether even during a major we should actually remove deletes.  The problem is just that this creates a scenario where a background process impacts user-facing behavior.  This is really just an issue w/ manual stamps, but we are moving towards a world where we support all kinds of weird out of order stuff.  If I have a delete row @ ts=10, then everything I insert with ts &amp;lt; 10 will not get read.  But after major compaction, this will no longer be the case and inserts with ts &amp;lt; 10 will now show up.  Again I&apos;m not a big proponent of supporting wonky use cases like that but it&apos;s weird nonetheless and maybe there are other less wonky scenarios this could lead to weird user-facing behavior that differs pre/post major compactions.&lt;/p&gt;

&lt;p&gt;Back to the jira at hand, it looks like we&apos;ll have to take the approach of either seeking first to the start of a row, looking for row deletes, then once done we re-seek down to the first column... or we get fancy.  One fancy idea is we could have a separate &quot;delete&quot; bloom which marks all rows which contain deletes (or just delete rows).  Another idea would be to add a small flag in the block index marking a bit of extra information for each block (does it have deletes in it, for example)... could potentially do some neat stuff there, but need to determine if/when it would be worth it.&lt;/p&gt;

&lt;p&gt;In any case, the simpler solution should suffice for now, and will be a big improvement over today where we never seek to anything but the start of a row so will always have to iterate through all the columns until we find what we want.  For hot rows, the first block in the row will get in the block cache and further requests for columns in that row will be able to get the initial row seek cheaply because it&apos;s already cached.&lt;/p&gt;</comment>
                            <comment id="12858518" author="ryanobjc" created="Mon, 19 Apr 2010 14:45:52 +0000"  >
&lt;p&gt;   [[ Old comment, sent by email on Thu, 15 Apr 2010 13:34:44 -0700 ]]&lt;/p&gt;

&lt;p&gt;FYI&lt;/p&gt;

&lt;p&gt;Minor compactions enforce deletes and prune them out.  I&apos;ve variously&lt;br/&gt;
attempted to do more in minor compactions but I had to roll it back&lt;br/&gt;
because it would take way too long to minor compact.  I was hoping we&lt;br/&gt;
could enforce version count at some point but I&apos;m not sure if that&apos;ll&lt;br/&gt;
be possible.&lt;/p&gt;

&lt;p&gt;So yes, complexity of the minor compaction process does become a problem.&lt;/p&gt;

</comment>
                            <comment id="12866817" author="stack" created="Wed, 12 May 2010 23:48:31 +0000"  >&lt;p&gt;Bulk move of 0.20.5 issues into 0.21.0 after vote that we merge branch into TRUNK up on list.&lt;/p&gt;</comment>
                            <comment id="12905993" author="stack" created="Fri, 3 Sep 2010 18:03:04 +0000"  >&lt;p&gt;So, we just had an interesting case here where an ICV was running real slow &amp;#8211; two orders of magnitude slower than old Get 0.20.x codepath, see hbase-2959 &amp;#8211; because the ICV was being done on a row that had thousands of columns (The ICV to update was somewhere in the midst of these thousands of columns).   At first blush, the fix was changing ScanQueryMatcher so that the startrow was changed from &apos;    this.startKey = KeyValue.createFirstOnRow(scan.getStartRow());&apos; to instead consider column.  But then, reading this issue, I&apos;m reminded of deletes and of how a delete row is first thing on the row and of how a delete family is first thing in a family.&lt;/p&gt;

&lt;p&gt;Having to go to the start of the row and move forward is slowing Gets (and ICVs).&lt;/p&gt;

&lt;p&gt;Above its mentioned that get on a row needs to look at start of row to see if a delete of all the row (and we need to look at start of family to see if family is deleted) but, yeah, this seems wrong.&lt;/p&gt;

&lt;p&gt;The other ideas sound better &amp;#8211; delete dynamic bloom or extra info in index.&lt;/p&gt;

&lt;p&gt;Meantime we&apos;ve changed our schema here so ICVs done in a row of one column only but this issue is going to burn us again.&lt;/p&gt;</comment>
                            <comment id="12906006" author="ryanobjc" created="Fri, 3 Sep 2010 18:31:45 +0000"  >&lt;p&gt;The previous code Also did This same read case. Are you sure its at fault?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2450?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=12905993#action_12905993&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-2450?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=12905993#action_12905993&lt;/a&gt;]&lt;br/&gt;
slow &amp;#8211; two orders of magnitude slower than old Get 0.20.x codepath, see&lt;br/&gt;
hbase-2959 &amp;#8211; because the ICV was being done on a row that had thousands of&lt;br/&gt;
columns (The ICV to update was somewhere in the midst of these thousands of&lt;br/&gt;
columns). At first blush, the fix was changing ScanQueryMatcher so that the&lt;br/&gt;
startrow was changed from &apos; this.startKey =&lt;br/&gt;
KeyValue.createFirstOnRow(scan.getStartRow());&apos; to instead consider column.&lt;br/&gt;
But then, reading this issue, I&apos;m reminded of deletes and of how a delete&lt;br/&gt;
row is first thing on the row and of how a delete family is first thing in a&lt;br/&gt;
family.&lt;br/&gt;
ICVs).&lt;br/&gt;
if a delete of all the row (and we need to look at start of family to see if&lt;br/&gt;
family is deleted) but, yeah, this seems wrong.&lt;br/&gt;
index.&lt;br/&gt;
only but this issue is going to burn us again.&lt;br/&gt;
HFiles rather than start of row&lt;br/&gt;
-----------------------------------------------------------------------------------------------------&lt;br/&gt;
specific columns, we should seek to the first column in that row.&lt;/p&gt;</comment>
                            <comment id="12906009" author="stack" created="Fri, 3 Sep 2010 18:39:04 +0000"  >&lt;p&gt;@Ryan Yes.  The schema was redone here at SU so no longer thousands of columns in rows and ICV went back up to patched 0.20.3 speeds.&lt;/p&gt;</comment>
                            <comment id="12906020" author="stack" created="Fri, 3 Sep 2010 19:01:08 +0000"  >&lt;p&gt;Chatting w/ Benoit, its kinda crazy having to look at start of row/start of family before trusting found cell.  What if we went back to the old scheme where we added a delete for every cell deleted so if you deleted a row it&apos;d add a delete marker for every value in that row?  Deletes of rows or column familiies would be expensive but so what... &lt;/p&gt;</comment>
                            <comment id="12906026" author="tlipcon" created="Fri, 3 Sep 2010 19:17:07 +0000"  >&lt;p&gt;The bloom filter seems like a pretty decent approach. Given we expect only something &amp;lt;1% deletions, it should be only a couple hundred KB per 1GB region worth of bloom data for a very low false positive rate.&lt;/p&gt;</comment>
                            <comment id="12906044" author="ryanobjc" created="Fri, 3 Sep 2010 19:52:47 +0000"  >&lt;p&gt;ran a profiler-based timing test and with this patch things seem to be faster:&lt;/p&gt;

&lt;p&gt;diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java b/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;br/&gt;
index 286cb64..b24b28f 100644&lt;br/&gt;
&amp;#8212; a/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;br/&gt;
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;br/&gt;
@@ -77,17 +77,22 @@ public class ScanQueryMatcher {&lt;br/&gt;
     this.rowComparator = rowComparator;&lt;br/&gt;
     this.deletes =  new ScanDeleteTracker();&lt;br/&gt;
     this.stopRow = scan.getStopRow();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.startKey = KeyValue.createFirstOnRow(scan.getStartRow());&lt;br/&gt;
     this.filter = scan.getFilter();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Single branch to deal with two types of reads (columns vs all in family)&lt;br/&gt;
     if (columns == null || columns.size() == 0) &lt;/p&gt;
{
       // use a specialized scan for wildcard column tracker.
       this.columns = new ScanWildcardColumnTracker(maxVersions);
+      this.startKey = KeyValue.createFirstOnRow(scan.getStartRow());
     }
&lt;p&gt; else &lt;/p&gt;
{
       // We can share the ExplicitColumnTracker, diff is we reset
       // between rows, not between storefiles.
-      this.columns = new ExplicitColumnTracker(columns,maxVersions);
+      this.columns = new ExplicitColumnTracker(columns, maxVersions);
+      final ColumnCount hint = this.columns.getColumnHint();
+      this.startKey = KeyValue.createFirstOnRow(scan.getStartRow(),
+          0, scan.getStartRow().length,
+          family, 0, family.length,
+          hint.getBuffer(), hint.getOffset(), hint.getLength());
     }
&lt;p&gt;   }&lt;/p&gt;</comment>
                            <comment id="12906046" author="ryanobjc" created="Fri, 3 Sep 2010 19:54:25 +0000"  >&lt;p&gt;reiterating what stack says... the performance improvement in the profiler is stark, which leads me to believe we will have to switch to this, meaning getting rid of DeleteFamily and converting them to delete columns in the server-side.&lt;/p&gt;

&lt;p&gt;Expensive to be sure, but perf boost on get is just too good to pass up.&lt;/p&gt;</comment>
                            <comment id="12906055" author="pranavkhaitan" created="Fri, 3 Sep 2010 20:13:29 +0000"  >&lt;p&gt;@Stack: The submitted patch will make this case much better. Using the reseek option, read the start of a row to see if any row deletes are there. If there is no such delete, skip directly to required columns rather than reading all (possibly hundreds of) columns sequentially.&lt;/p&gt;</comment>
                            <comment id="12913754" author="ryanobjc" created="Wed, 22 Sep 2010 20:04:27 +0000"  >&lt;p&gt;i did some tests, and it overall this patch is a net win.  When the data is very dense, it slows things down very slightly, eg 60.7ms vs 59.25ms for scans.  &lt;/p&gt;

&lt;p&gt;In a 1 column out of 100 scan, the performance improvement was big - 6.1ms becomes 3.9ms with the new code.&lt;/p&gt;</comment>
                            <comment id="12913850" author="ryanobjc" created="Wed, 22 Sep 2010 23:52:50 +0000"  >&lt;p&gt;committed, thanks pranav.  I also added an additional optimization for &apos;next row&apos; case too.&lt;/p&gt;</comment>
                            <comment id="15017239" author="lars_francke" created="Fri, 20 Nov 2015 12:42:24 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12427822">HBASE-1517</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12463796">HBASE-2517</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471583">HBASE-2916</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12473267">HBASE-2959</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 15 Apr 2010 14:07:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32592</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hhr3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100138</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>