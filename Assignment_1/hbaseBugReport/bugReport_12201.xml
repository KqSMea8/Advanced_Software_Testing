<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:30:43 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12201/HBASE-12201.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12201] Close the writers in the MOB sweep tool</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12201</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt; When running the sweep tool, we encountered such an exception.&lt;br/&gt;
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /hbase/mobdir/.tmp/mobcompaction/SweepJob-SweepMapper-SweepReducer-testSweepToolExpiredNoMinVersion-data/working/names/all (inode 46500): File does not exist. Holder DFSClient_NONMAPREDUCE_-1863270027_1 does not have any open files.&lt;br/&gt;
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3319)&lt;br/&gt;
  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3407)&lt;br/&gt;
  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3377)&lt;br/&gt;
  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:673)&lt;br/&gt;
  at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.complete(AuthorizationProviderProxyClientProtocol.java:219)&lt;br/&gt;
  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:520)&lt;br/&gt;
  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)&lt;br/&gt;
  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)&lt;br/&gt;
  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)&lt;br/&gt;
  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)&lt;br/&gt;
  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)&lt;br/&gt;
  at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
  at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)&lt;br/&gt;
  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)&lt;br/&gt;
  at org.apache.hadoop.ipc.Client.call(Client.java:1411)&lt;br/&gt;
  at org.apache.hadoop.ipc.Client.call(Client.java:1364)&lt;br/&gt;
  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)&lt;br/&gt;
  at com.sun.proxy.$Proxy15.complete(Unknown Source)&lt;br/&gt;
  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:435)&lt;br/&gt;
  at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
   at java.lang.reflect.Method.invoke(Method.java:606)&lt;br/&gt;
   at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)&lt;br/&gt;
   at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)&lt;br/&gt;
   at com.sun.proxy.$Proxy16.complete(Unknown Source)&lt;br/&gt;
   at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2180)&lt;br/&gt;
   at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2164)&lt;br/&gt;
   at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:908)&lt;br/&gt;
  at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:925)&lt;br/&gt;
  at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:861)&lt;br/&gt;
  at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2687)&lt;br/&gt;
  at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2704)&lt;br/&gt;
  at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)&lt;/p&gt;

&lt;p&gt;This is because we have several writers opened by fs.create(path, true) are not closed properly.&lt;br/&gt;
Meanwhile, in the current implementation, we save the temp files under sweepJobDir/working/..., and when we remove the directory of the sweep job only the working is deleted. We should remove the whole sweepJobDir instead.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12746629">HBASE-12201</key>
            <summary>Close the writers in the MOB sweep tool</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingcheng.du@intel.com">Jingcheng Du</assignee>
                                    <reporter username="jingcheng.du@intel.com">Jingcheng Du</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Oct 2014 06:28:02 +0000</created>
                <updated>Wed, 22 Jul 2015 22:48:50 +0000</updated>
                            <resolved>Thu, 9 Oct 2014 04:22:33 +0000</resolved>
                                    <version>hbase-11339</version>
                                    <fixVersion>hbase-11339</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="14163157" author="jingcheng.du@intel.com" created="Wed, 8 Oct 2014 06:40:38 +0000"  >&lt;p&gt;Upload the patch to fix this issue.&lt;/p&gt;</comment>
                            <comment id="14163174" author="hadoopqa" created="Wed, 8 Oct 2014 06:51:50 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12673549/HBASE-12201.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12673549/HBASE-12201.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12673549&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11264//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11264//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14163180" author="anoop.hbase" created="Wed, 8 Oct 2014 06:59:04 +0000"  >&lt;p&gt;One suggestion&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!fs.exists(nameFilePath)) {
-        fs.create(nameFilePath, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
+        IOUtils.closeStream(fs.create(nameFilePath, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;));
       }
       writer = SequenceFile.createWriter(fs, context.getConfiguration(), nameFilePath,
           &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.class, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.class);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can make use of the OutputStream created above and pass that to SequenceFile.createWriter &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Here in effect what we do is opening up a stream and close an again open.&lt;br/&gt;
As this is not a critical code path, this is ok.   If simple can try checking.&lt;/p&gt;</comment>
                            <comment id="14163217" author="jingcheng.du@intel.com" created="Wed, 8 Oct 2014 08:14:32 +0000"  >&lt;p&gt;Update the patch(V2) according to Anoop&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="14163228" author="hadoopqa" created="Wed, 8 Oct 2014 08:31:43 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12673560/HBASE-12201-V2.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12673560/HBASE-12201-V2.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12673560&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11265//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11265//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14163641" author="jmhsieh" created="Wed, 8 Oct 2014 15:57:20 +0000"  >&lt;p&gt;tested locally and the run looks good.  &lt;/p&gt;

&lt;p&gt;The patch&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;changes the compaction working dir so that multiple jobs or subsequent jobs don&apos;t use the same path.&lt;/li&gt;
	&lt;li&gt;other updates improve the hygiene around output stream closing.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Can you give a quick explanation of why or how we would potentially open a file for append? (I believe there is a obscure race possible there, &amp;#8211; two get to !exists and then both trry to create) but let&apos;s ignore that for now).&lt;/p&gt;</comment>
                            <comment id="14164138" author="jmhsieh" created="Wed, 8 Oct 2014 20:52:25 +0000"  >&lt;p&gt;Some more context/information:&lt;/p&gt;

&lt;p&gt;This happens after the MR job and all its mapping and reducing has completed, and seem to be triggered by the cleanup() call when it tries to close the dir with the list of live files.  &lt;/p&gt;

&lt;p&gt;At the worst i believe it the thrown exception exception blocked a the timely zk node removal but that all the main work of the sweeper job completes.&lt;/p&gt;

&lt;p&gt;Does this sound right &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingchengdu&quot; class=&quot;user-hover&quot; rel=&quot;jingchengdu&quot;&gt;JingchengDu&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;Anyway, I&apos;ve tested it on a yarn cluster now and have been able to reproduce and see that this patch fixes the problem.&lt;/p&gt;</comment>
                            <comment id="14164556" author="anoop.hbase" created="Thu, 9 Oct 2014 01:29:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;This happens after the MR job and all its mapping and reducing has completed, and seem to be triggered by the cleanup() &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. &lt;/p&gt;

&lt;p&gt;Good work Jingcheng&lt;/p&gt;</comment>
                            <comment id="14164560" author="anoop.hbase" created="Thu, 9 Oct 2014 01:34:12 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      IOUtils.closeStream(writer);
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (writer != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+        IOUtils.closeStream(writer);
+      }
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (fout != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+        IOUtils.closeStream(fout);
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;writer&apos; wraps the &apos;fout&apos; stream and so close call on &apos;writer&apos; is enough? which will close &apos;fout&apos; also?&lt;/p&gt;

&lt;p&gt;Same in SweepReducer.java as well&lt;/p&gt;
</comment>
                            <comment id="14164573" author="jingcheng.du@intel.com" created="Thu, 9 Oct 2014 01:54:13 +0000"  >&lt;p&gt;Thanks Jon, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;changes the compaction working dir so that multiple jobs or subsequent jobs don&apos;t use the same path.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Previously we have the working dir like mobCompactionDirOfJobName/working/... (the job name is mapperclass-reducerclass-table-cf), when we remove the working dir, only working is deleted, the mobCompactionDirOfJobName will be left there. It won&apos;t impact the logic, but it&apos;s better to remove it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you give a quick explanation of why or how we would potentially open a file for append? (I believe there is a obscure race possible there, &#8211; two get to !exists and then both trry to create) but let&apos;s ignore that for now).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We have lock that surrounds the logic, right? There&apos;s only one sweeper running at the same time for the same table and cf, so there&apos;s not race condition here. Actually we don&apos;t need to check the existence here (1, the whole working dir is deleted/created in the beginning of the sweeper. 2, the file name is a UUID), we could create it directly here. Will provide a new patch(V3) to fix this.&lt;/p&gt;</comment>
                            <comment id="14164577" author="jingcheng.du@intel.com" created="Thu, 9 Oct 2014 01:57:24 +0000"  >&lt;p&gt;Thanks Anoop, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&apos;writer&apos; wraps the &apos;fout&apos; stream and so close call on &apos;writer&apos; is enough? which will close &apos;fout&apos; also?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I read the code of the Writer, it has such logic in close.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(wrtierOwnThisOutput){
  out.close();
} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
  out.flush();
}
out = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the output is created by the Writer, it owns it. If it&apos;s passed from outside, it doesn&apos;t, the output is only flushed when the writer is closed. So we have to close it after the writer is closed.&lt;/p&gt;</comment>
                            <comment id="14164582" author="jingcheng.du@intel.com" created="Thu, 9 Oct 2014 02:01:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;At the worst i believe it the thrown exception exception blocked a the timely zk node removal but that all the main work of the sweeper job completes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes Jon, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;. The logic won&apos;t be impacted, and I believe the zk will be closed too, zk.close() resides in the finally.&lt;br/&gt;
We don&apos;t close the output created by the fs.create(path, true), when the JVM exits, the shutdown hook tries to close this output while this file had been deleted by the sweeper. I think this exception occurs at that time, it means all the logic of the sweeper had been finished before this exception is thrown.&lt;/p&gt;</comment>
                            <comment id="14164583" author="anoop.hbase" created="Thu, 9 Oct 2014 02:05:04 +0000"  >&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14164588" author="jingcheng.du@intel.com" created="Thu, 9 Oct 2014 02:09:23 +0000"  >&lt;p&gt;Upload the patch(V3) to remove the unnecessary check of file existence in SweepReducer, now we directly use fs.create(path, true) to create that file.&lt;/p&gt;</comment>
                            <comment id="14164593" author="hadoopqa" created="Thu, 9 Oct 2014 02:13:25 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12673814/HBASE-12201-V3.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12673814/HBASE-12201-V3.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12673814&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/11279//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/11279//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14164631" author="ram_krish" created="Thu, 9 Oct 2014 02:58:00 +0000"  >&lt;p&gt;+1 on patch.  We need to have a seperate close for the FSOutputStream and the writer.&lt;br/&gt;
Will commit this?&lt;/p&gt;</comment>
                            <comment id="14164636" author="anoop.hbase" created="Thu, 9 Oct 2014 03:04:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;Will commit this?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes Ram. Pls.&lt;/p&gt;</comment>
                            <comment id="14164705" author="ram_krish" created="Thu, 9 Oct 2014 04:22:33 +0000"  >&lt;p&gt;Committed to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11339&quot; title=&quot;HBase MOB&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11339&quot;&gt;&lt;del&gt;HBASE-11339&lt;/del&gt;&lt;/a&gt; branch. Thanks for the patch and thanks to all for the reviews.&lt;/p&gt;</comment>
                            <comment id="14637846" author="hudson" created="Wed, 22 Jul 2015 22:48:50 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6672 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6672/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6672/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12201&quot; title=&quot;Close the writers in the MOB sweep tool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12201&quot;&gt;&lt;del&gt;HBASE-12201&lt;/del&gt;&lt;/a&gt; Close the writers in the MOB sweep tool (Jingcheng Du) (ramkrishna: rev aa523164e825567d93eb0b2a191955ca195ea242)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepJob.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepReducer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12673560" name="HBASE-12201-V2.diff" size="7263" author="jingcheng.du@intel.com" created="Wed, 8 Oct 2014 08:26:43 +0000"/>
                            <attachment id="12673814" name="HBASE-12201-V3.diff" size="7272" author="jingcheng.du@intel.com" created="Thu, 9 Oct 2014 02:09:23 +0000"/>
                            <attachment id="12673549" name="HBASE-12201.diff" size="3291" author="jingcheng.du@intel.com" created="Wed, 8 Oct 2014 06:40:38 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Oct 2014 06:51:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 21 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i20x5z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>