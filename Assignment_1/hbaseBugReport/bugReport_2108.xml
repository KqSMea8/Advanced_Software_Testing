<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:59:02 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2108/HBASE-2108.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2108] [HA] hbase cluster should be able to ride over hdfs &apos;safe mode&apos; flip and namenode restart/move</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2108</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Todd Lipcon wrote up the following speculation on what happens when NN is restarted/goes away/replaced by backup under hbase (see Dhruba&apos;s note here, &lt;a href=&quot;http://hadoopblog.blogspot.com/2009/11/hdfs-high-availability.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoopblog.blogspot.com/2009/11/hdfs-high-availability.html&lt;/a&gt;, that Eli pointed us at for some background on the 0.21 BackupNode feature):&lt;/p&gt;

&lt;p&gt;&quot;For regions that are already open, HBase can continue to serve reads so long as the regionservers are up and do not change state. This is because the HDFS client APIs cache the DFS block locations (a map of block ID -&amp;gt; datanode addresses) for open files.&lt;/p&gt;

&lt;p&gt;&quot;If any HBase action occurs that causes the regionservers to reopen a region (eg a region server fails, load balancing rebalances the region assignment, or a compaction finishes) then the reopen will fail as the new file will not be able to access the NameNode to receive the block locations. As these are all periodic operations for HBase, it&apos;s impossible to put a specific bound on this time, but my guess is that at least one region server is likely to crash within less than a minute of a NameNode unavailability.&lt;/p&gt;

&lt;p&gt;&quot;Similar properties hold for writes. HBase&apos;s writing behavior is limited to Commit Logs which are kept open by the region servers. Writes to commit logs that are already open will continue to succeed, since they only involve the datanodes, but if a region server rolls an edit log, the open() for the new log will fail if the NN is unavailable. There is currently some work going on in HBase trunk to preallocate open files for commit logs to avoid this issue, but it is not complete, and it is not a full solution for the issue. The other issue is that the close() call that completes the write of a commit log also depends on a functioning NameNode - if it is unavailable, the log will be left in an indeterminate state and the edits may become lost when the NN recovers.&lt;/p&gt;

&lt;p&gt;&quot;The rolling of commit logs is triggered either when a timer elapses or when a certain amount of data has been written. Thus, this failure mode will trigger quickly when data is constantly being written to the cluster. If little data is being written, it still may trigger due to the automatic periodic log rolling.&lt;/p&gt;

&lt;p&gt;&quot;Given these above failure modes, I don&apos;t believe there is an effective HA solution for HBase at this point. Although HBase may continue to operate for a short time period while a NN recovers, it is also possible that it will fail nearly immediately, depending on when HBase&apos;s periodic operations happen to occur. Even with an automatic failover like DRBD+Heartbeat on the NN, the downtime may last 5-10 minutes as the new NN must both replay the edit log and receive block reports from every datanode before it can exit safe mode. I believe this will cause most NN failovers to be accompanied by a partial or complete failure of the HBase cluster.&quot;&lt;/p&gt;

&lt;p&gt;The above makes sense to me.  Lets fix.  Generally our mode up to this has been that if hdfs goes away, we&apos;ve dealt with it on a regionserver by regionserver basis shutting itself down to protect against dataloss.    We need to handle riding over NN restart/change of server.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12445215">HBASE-2108</key>
            <summary>[HA] hbase cluster should be able to ride over hdfs &apos;safe mode&apos; flip and namenode restart/move</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12455267">HBASE-2183</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Mon, 11 Jan 2010 20:52:26 +0000</created>
                <updated>Sat, 13 Apr 2013 01:08:17 +0000</updated>
                            <resolved>Sat, 13 Apr 2013 01:08:17 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="12798863" author="apurtell" created="Mon, 11 Jan 2010 21:09:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Even with an automatic failover like DRBD+Heartbeat on the NN, the downtime may last 5-10 minutes as the new NN must both replay the edit log and receive block reports from every datanode before it can exit safe mode. I believe this will cause most NN failovers to be accompanied by a partial or complete failure of the HBase cluster.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. &lt;/p&gt;

&lt;p&gt;We should be able to catch IOExceptions related to NN unavailability and handle them by deferring the work?&lt;/p&gt;

&lt;p&gt;Also, I can see a useful 0.20 HBase release which includes some backport of the fix for this issue. DRDB+Heartbeat is already used to fail over the 0.20 NameNode. &lt;/p&gt;</comment>
                            <comment id="12843409" author="dhruba" created="Wed, 10 Mar 2010 02:52:12 +0000"  >&lt;p&gt;Hi folks, we are in the process of deploying some form of namenode HA via AvatarNode, details here: &lt;br/&gt;
&lt;a href=&quot;http://hadoopblog.blogspot.com/2010/02/hadoop-namenode-high-availability.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoopblog.blogspot.com/2010/02/hadoop-namenode-high-availability.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is similar to where the Hadoop BackupNode might navigate towards (in the future). The NN failover using this method is within a few seconds.&lt;/p&gt;

&lt;p&gt;Given the above, is anybody working on this issue? If not, may I work on it?&lt;/p&gt;</comment>
                            <comment id="12843410" author="apurtell" created="Wed, 10 Mar 2010 02:57:45 +0000"  >&lt;p&gt;@Dhruba: Have at it. I was about to start an audit of all places in the master and regionserver where an IOException from the filesystem might cause an abort. Then from there, introduce some retry logic. Is this what you have in mind? &lt;/p&gt;</comment>
                            <comment id="12843685" author="dhruba" created="Wed, 10 Mar 2010 18:35:06 +0000"  >&lt;p&gt;Thanks Andrew. &lt;/p&gt;

&lt;p&gt;I am thinking of making a few hdfs client parameters configurable (e.g. #of block-metadata cached by dfs ciient, maybe pre-allocate hdfs files, etc). HBase could then set/tune these parameters to survive namenode unavailability for upto a minute or so. If then correctly, then Hbase code should not even encounter any hdfs-related exception when the NN failover occurs. Do you think this is a feasible approach?&lt;/p&gt;
</comment>
                            <comment id="12843696" author="apurtell" created="Wed, 10 Mar 2010 18:50:31 +0000"  >&lt;p&gt;My internal customers will want to be able to survive a 10 minute outage (or longer, but we need to set a reasonable expectation). Switching to some degraded operational mode would be acceptable. Perhaps you should open a HDFS jira to do what you propose and we can link this issue? They are related but have different aims, and both are worth doing.&lt;/p&gt;
</comment>
                            <comment id="12867008" author="stack" created="Thu, 13 May 2010 04:41:43 +0000"  >&lt;p&gt;Moved from 0.21 to 0.22 just after merge of old 0.20 branch into TRUNK.&lt;/p&gt;</comment>
                            <comment id="13047553" author="stack" created="Fri, 10 Jun 2011 22:45:48 +0000"  >&lt;p&gt;Moving out of 0.92.0. Pull it back in if you think different.&lt;/p&gt;</comment>
                            <comment id="13630843" author="apurtell" created="Sat, 13 Apr 2013 01:08:17 +0000"  >&lt;p&gt;Superseded by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8338&quot; title=&quot;Latency Resilience; umbrella list of issues that will help us ride over bad disk, bad region, ec2, etc.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8338&quot;&gt;HBASE-8338&lt;/a&gt; and related.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12462910">HDFS-1108</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12403128">HBASE-846</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12440202">HBASE-1964</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12551766">HBASE-5843</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12456222">HDFS-976</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 11 Jan 2010 21:09:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32414</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 35 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hgfr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99925</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>