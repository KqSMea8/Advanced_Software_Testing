<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:02:09 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-15314/HBASE-15314.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-15314] Allow more than one backing file in bucketcache</title>
                <link>https://issues.apache.org/jira/browse/HBASE-15314</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Allow bucketcache use more than just one backing file: e.g. chassis has more than one SSD in it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12941438">HBASE-15314</key>
            <summary>Allow more than one backing file in bucketcache</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12938047">HBASE-15240</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="aartokhy">Aaron Tokhy</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 23 Feb 2016 16:14:05 +0000</created>
                <updated>Sat, 10 Dec 2016 05:15:40 +0000</updated>
                                                                            <component>BucketCache</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="15160211" author="anoop.hbase" created="Wed, 24 Feb 2016 05:52:42 +0000"  >&lt;p&gt;Implement as another IOEngine &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;   MultiFile&lt;/p&gt;</comment>
                            <comment id="15175049" author="amal joshy" created="Wed, 2 Mar 2016 05:17:58 +0000"  >&lt;p&gt;I have started working on this.&lt;/p&gt;</comment>
                            <comment id="15175063" author="stack" created="Wed, 2 Mar 2016 05:29:14 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Amal+Joshy&quot; class=&quot;user-hover&quot; rel=&quot;Amal Joshy&quot;&gt;Amal Joshy&lt;/a&gt; Idea is you have more than one SSD plugged into the chassis and you&apos;d like to make use of all.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; Should it be another ioengine? Why not current file rather than add another choice? You just list a set of files to use?&lt;/p&gt;</comment>
                            <comment id="15175071" author="anoop.hbase" created="Wed, 2 Mar 2016 05:36:04 +0000"  >&lt;p&gt;Ya that just a first thought and comment..  We can include this in the current FileIOEngine itself.  Now we read single file path. We can allow users to pass a comma separated list of files.. The path of files they can give such that all mounted SSDs will get used.    Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Amal+Joshy&quot; class=&quot;user-hover&quot; rel=&quot;Amal Joshy&quot;&gt;Amal Joshy&lt;/a&gt;..  &lt;/p&gt;</comment>
                            <comment id="15184443" author="amal joshy" created="Tue, 8 Mar 2016 05:42:25 +0000"  >&lt;p&gt;Submitted initial patch. Please review.&lt;/p&gt;</comment>
                            <comment id="15185544" author="danielpol" created="Tue, 8 Mar 2016 19:16:00 +0000"  >&lt;p&gt;If I understand the code correctly, you fill one file before you switch to the next one. For performance reasons I would recommend filling all files at once in parallel. Take for example a 100GB bucketcache on 4 files (25GB per file), each file on a separate physical disk. If your bucketcache usedsize is only 20GB you get the performance of a single physical disk with the proposed patch. If you use all files in parallel you get the performance of all 4 disks. &lt;/p&gt;</comment>
                            <comment id="15186497" author="amal joshy" created="Wed, 9 Mar 2016 04:56:11 +0000"  >&lt;p&gt;I understand your concern &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=danielpol&quot; class=&quot;user-hover&quot; rel=&quot;danielpol&quot;&gt;Daniel Pol&lt;/a&gt;. But it is not possible to obtain parallel writes with the current BucketAllocator implementation. Either we need to change the current implementation or plugin  a different BucketAllocator only for FileIOEngine. With this patch, atleast once all the files are filled, we can guarantee random reads utilizing all the disks.&lt;/p&gt;</comment>
                            <comment id="15186544" author="stack" created="Wed, 9 Mar 2016 05:30:00 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Amal+Joshy&quot; class=&quot;user-hover&quot; rel=&quot;Amal Joshy&quot;&gt;Amal Joshy&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;But it is not possible to obtain parallel writes with the current BucketAllocator implementation. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why is this please? A bucket can&apos;t have an associated file? That&apos;d be breaking change?&lt;/p&gt;</comment>
                            <comment id="15186552" author="ram_krish" created="Wed, 9 Mar 2016 05:36:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;fileEndSizes&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;this is more like fileEndingOffset?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;atleast once all the files are filled, we can guarantee random reads utilizing all the disks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes this is true. Reads are random always. &lt;/p&gt;</comment>
                            <comment id="15186575" author="amal joshy" created="Wed, 9 Mar 2016 05:53:16 +0000"  >&lt;blockquote&gt;
&lt;p&gt;this is more like fileEndingOffset?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Exactly, I&apos;ll rename it in the next patch. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15186584" author="ram_krish" created="Wed, 9 Mar 2016 06:06:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;If your bucketcache usedsize is only 20GB you get the performance of a single physical disk with the proposed patch. If you use all files in parallel you get the performance of all 4 disks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am trying learn more here. So here the point is as and when the cache is filling up only then the usedSize will be growing and reaching upto 100GB (which is the total size of bucketCache).&lt;br/&gt;
The point and need here is that as when you are filling up try to parallelize the files instead of filling it up one by one. So that initial 20G itself should be distributed among the four files. Is that so?&lt;/p&gt;</comment>
                            <comment id="15186620" author="amal joshy" created="Wed, 9 Mar 2016 06:39:03 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The point and need here is that as when you are filling up try to parallelize the files instead of filling it up one by one. So that initial 20G itself should be distributed among the four files. Is that so?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, that is what we are trying to achieve. But the problem is that the BucketAllocator finds us an offset to store a block and this offset will be generated in such a way that all the blocks will be mapped into the same file until it is filled completely. We cannot obtain any random writes due to this. &lt;/p&gt;</comment>
                            <comment id="15187053" author="danielpol" created="Wed, 9 Mar 2016 12:53:48 +0000"  >&lt;p&gt;I was thinking about something that basically salts the offset. Like a modulo function for example.&lt;br/&gt;
public FileChannel getFileChannel(long offset) &lt;/p&gt;
{
    return fileChannels.get(offset % NumberOfFiles);
}</comment>
                            <comment id="15187363" author="anoop.hbase" created="Wed, 9 Mar 2016 16:35:33 +0000"  >&lt;p&gt;Amal said it.&lt;br/&gt;
The decision of where to write (I mean which offset) is being taken NOT within IOEngine impl but at BucketAllocator level.&lt;br/&gt;
It is NOT always true that we will 1st write and fill 1st file and then go to 2nd.  There is a bucket allocation happening 1st.  The buckets will be having some fixed size. By default we have 4+1 KB, 8+1 KB... 512+1 KB sized buckets.  (This is configurable)..  So we will make buckets and fix offset to each of these buckets.    When a new block comes to be cached, we will 1st see which bucket it can go. We will pick up a size which is least size with size &amp;gt;= block size.   And we will see within that where to write. This offset is being passed.&lt;br/&gt;
So in order to make sure we have equi distribution while writing blocks, we will need change in top layer of bucket allocator.&lt;br/&gt;
Ya once the cache is almost filled, the read will be distributed. Write happens in an async way. So perf gain because of parallel writes to diff disks might not be that relevant.   Ya still it will be best we can distribute load from begin and write load also..  &lt;/p&gt;</comment>
                            <comment id="15187759" author="danielpol" created="Wed, 9 Mar 2016 19:41:01 +0000"  >&lt;p&gt;My favorite use case is when you have the hottest table that you want to cache completely and make sure you get the best performance for it (and the table doesn&apos;t fit into RAM). Right now its a matter of adding software raid on top of multiple SSDs to achieve that. I would like to remove the software raid overhead by doing the parallelism in Hbase. I agree it&apos;s not easy, mostly because the Hbase blocksize is not really fixed. So you have to end up adding logic to handle that. &lt;br/&gt;
Funny you mentioned the buckets of fixed size. I&apos;m thinking about filling another JIRA related to a lot of wasted space in bucketcache because of that. When you have a small bucketcache that&apos;s not an issue, but when you get to a few TiB and you end up with half the space unused but allocated it becomes a serious issue.&lt;/p&gt;</comment>
                            <comment id="15188804" author="anoop.hbase" created="Thu, 10 Mar 2016 06:55:39 +0000"  >&lt;p&gt;As what I checked in BC code area, yes we are not utilizing full area of BC.  Seems buckets in some of the specific size will not get used.. This is when u have all the tables with same block size.   Ya the issue with block sizes in HFiles is that we really can not guarentee the size...  Checking these area as well..&lt;/p&gt;</comment>
                            <comment id="15189247" author="anoop.hbase" created="Thu, 10 Mar 2016 13:01:45 +0000"  >&lt;p&gt;So in order to have the clear randomness while filling in files itself, we may have to have all sized buckets (we have by def 14 buckets of diff sizes) in all files.  The buckets allocation in entire BC&apos;s capacity (offset of each bucket being decided) and allocation for each of the HFile block happens at an upper layer to IOEngine impl (BucketAllocator)..  I feel this will be a much bigger change.  Can we do that as a follow on issue?&lt;br/&gt;
In read case we will have randomness mostly.. That depends on which blocks we will read..&lt;/p&gt;</comment>
                            <comment id="15189324" author="danielpol" created="Thu, 10 Mar 2016 14:10:23 +0000"  >&lt;p&gt;Getting back to the available patch. It looks like there could be an issue when you end up using a block that straps the file boundary. Basically when fileOffset + length &amp;gt; filesize. &lt;/p&gt;</comment>
                            <comment id="15199267" author="amal joshy" created="Thu, 17 Mar 2016 10:19:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=danielpol&quot; class=&quot;user-hover&quot; rel=&quot;danielpol&quot;&gt;Daniel Pol&lt;/a&gt; Sorry i couldn&apos;t get back to you sooner. Thanks for pointing out the issue. I have attached a new patch to check if a particular block crosses the file boundary. If it does, a different offset will be used for its allocation.&lt;br/&gt;
 Any other suggestions to solve this issue are welcome.&lt;/p&gt;</comment>
                            <comment id="15691553" author="aartokhy" created="Wed, 23 Nov 2016 22:43:20 +0000"  >&lt;p&gt;I have started working on improving v2 of this patch to add some additional tests, while keeping the implementation mostly the same.  I&apos;ve addressed some issues such as guaranteeing the total aggregate file size is greater than or equal to the total allocatable size (using long ceiling division).  This also adds some cleanup logic if an exception is thrown on allocation failure.&lt;/p&gt;

&lt;p&gt;Included with the change is a set of parameterized tests as well as some changes to have TestBucketCache to also test various configurable IOEngine types.&lt;/p&gt;</comment>
                            <comment id="15710487" author="aartokhy" created="Thu, 1 Dec 2016 01:30:04 +0000"  >&lt;p&gt;I created a github pull request with my patch applied as I am unable to attach my patch here:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hbase/pull/42&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hbase/pull/42&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15712744" author="wutaklon@amazon.com" created="Thu, 1 Dec 2016 18:53:11 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="15715676" author="zyork" created="Fri, 2 Dec 2016 17:10:11 +0000"  >&lt;p&gt;+1 I have reviewed the patch and think it is much better than the original v2.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; can you review this? If it needs to be a patch (instead of a PR), can you change the assignee so that Aaron can attach the patch?&lt;/p&gt;</comment>
                            <comment id="15716075" author="stack" created="Fri, 2 Dec 2016 19:44:43 +0000"  >&lt;p&gt;I added you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aartokhy&quot; class=&quot;user-hover&quot; rel=&quot;aartokhy&quot;&gt;Aaron Tokhy&lt;/a&gt; I started to review up on gh but probably best to do it here.  Use the little tool ./dev-support/submit-patch.py  Thanks for working on this.&lt;/p&gt;</comment>
                            <comment id="15716076" author="stack" created="Fri, 2 Dec 2016 19:45:06 +0000"  >&lt;p&gt;Oh, are you running w/ your patch?&lt;/p&gt;</comment>
                            <comment id="15717715" author="anoop.hbase" created="Sat, 3 Dec 2016 08:32:51 +0000"  >&lt;p&gt;Assigned to Aaron.  Can u attach the patch pls?&lt;/p&gt;</comment>
                            <comment id="15723424" author="aartokhy" created="Mon, 5 Dec 2016 21:30:21 +0000"  >&lt;p&gt;Attached the patch just now.&lt;/p&gt;</comment>
                            <comment id="15729846" author="zyork" created="Wed, 7 Dec 2016 20:35:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; can you take a look at the patch?&lt;/p&gt;</comment>
                            <comment id="15737243" author="stack" created="Sat, 10 Dec 2016 05:15:40 +0000"  >&lt;p&gt;Sorry for the delay &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aartokhy&quot; class=&quot;user-hover&quot; rel=&quot;aartokhy&quot;&gt;Aaron Tokhy&lt;/a&gt;. Patch looks good. Any chance of a short description of how it works (see &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=danielpol&quot; class=&quot;user-hover&quot; rel=&quot;danielpol&quot;&gt;Daniel Pol&lt;/a&gt; remarks above; would be good if you could say what you do from his suggestion and what you do not). How do we fill the multiple files? Can you say more in the new methods isSegmented what this means for implementors?&lt;/p&gt;

&lt;p&gt;Please fill out the release note here with an example of how to use/configure multifiles.&lt;/p&gt;

&lt;p&gt;On the patch:&lt;/p&gt;

&lt;p&gt;&apos;files:&apos; is a nice way of specifying the multifile ioengine.&lt;/p&gt;

&lt;p&gt;Otherwise after a skim, it looks good.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12793955" name="HBASE-15314-v2.patch" size="11186" author="Amal Joshy" created="Thu, 17 Mar 2016 10:14:26 +0000"/>
                            <attachment id="12841815" name="HBASE-15314-v3.patch" size="45358" author="aartokhy" created="Mon, 5 Dec 2016 21:28:50 +0000"/>
                            <attachment id="12791940" name="HBASE-15314.patch" size="10073" author="Amal Joshy" created="Tue, 8 Mar 2016 05:41:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 24 Feb 2016 05:52:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2t81b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>