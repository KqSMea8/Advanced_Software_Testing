<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:37:49 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6561/HBASE-6561.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6561] Gets/Puts with many columns send the RegionServer into an &quot;endless&quot; loop</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6561</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;This came from the mailing this:&lt;br/&gt;
We were able to replicate this behavior in a pseudo-distributed hbase&lt;br/&gt;
(hbase-0.94.1) environment. We wrote a test program that creates a test&lt;br/&gt;
table &quot;MyTestTable&quot; and populates it with random rows, then it creates a&lt;br/&gt;
row with 60,000 columns and repeatedly updates it. Each column has a 18&lt;br/&gt;
byte qualifier and a 50 byte value. In our tests, when we ran the&lt;br/&gt;
program, we usually never got beyond 15 updates before it would flush&lt;br/&gt;
for a really long time. The rows that are being updated are about 4MB&lt;br/&gt;
each (minues any hbase metadata).&lt;/p&gt;

&lt;p&gt;It doesn&apos;t seem like it&apos;s caused by GC. I turned on gc logging, and&lt;br/&gt;
didn&apos;t see any long pauses. This is the gc log during the flush.&lt;br/&gt;
&lt;a href=&quot;http://pastebin.com/vJKKXDx5&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://pastebin.com/vJKKXDx5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is the regionserver log with debug on during the same flush&lt;br/&gt;
&lt;a href=&quot;http://pastebin.com/Fh5213mg&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://pastebin.com/Fh5213mg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is the test program we wrote.&lt;br/&gt;
&lt;a href=&quot;http://pastebin.com/aZ0k5tx2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://pastebin.com/aZ0k5tx2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You should be able to just compile it, and run it against a running&lt;br/&gt;
HBase cluster.&lt;br/&gt;
$ java TestTable&lt;/p&gt;

&lt;p&gt;Carlos&lt;/p&gt;</description>
                <environment></environment>
        <key id="12603148">HBASE-6561</key>
            <summary>Gets/Puts with many columns send the RegionServer into an &quot;endless&quot; loop</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Sun, 12 Aug 2012 21:26:02 +0000</created>
                <updated>Sun, 7 Apr 2013 04:46:20 +0000</updated>
                            <resolved>Thu, 16 Aug 2012 17:52:14 +0000</resolved>
                                                    <fixVersion>0.94.2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                <comments>
                            <comment id="13432839" author="lhofhansl" created="Sun, 12 Aug 2012 21:26:53 +0000"  >&lt;p&gt;Found two things:&lt;br/&gt;
1. Store.internalFlushCache(...) should be calling StoreScanner.next(List&amp;lt;KeyValue&amp;gt;, int limit) - currently it does not set a limit.(But this is not the problem).&lt;/p&gt;

&lt;p&gt;2. With jstack I found that the code is stuck in a loop in Memstore.MemstoreScanner.getNext(...)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Here&apos;s the relevant part of the jstack:
&lt;span class=&quot;code-quote&quot;&gt;&quot;IPC Server handler 6 on 60020&quot;&lt;/span&gt; daemon prio=10 tid=0x00007f0574625000 nid=0x720c runnable [0x00007f05669e7000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
        at org.apache.hadoop.hbase.regionserver.MemStore$MemStoreScanner.getNext(MemStore.java:726)
        at org.apache.hadoop.hbase.regionserver.MemStore$MemStoreScanner.seekInSubLists(MemStore.java:761)
        - locked &amp;lt;0x00000000c4a8a860&amp;gt; (a org.apache.hadoop.hbase.regionserver.MemStore$MemStoreScanner)
        at org.apache.hadoop.hbase.regionserver.MemStore$MemStoreScanner.reseek(MemStore.java:800)
        - locked &amp;lt;0x00000000c4a8a860&amp;gt; (a org.apache.hadoop.hbase.regionserver.MemStore$MemStoreScanner)
        at org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:54)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:299)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:244)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:522)
        - eliminated &amp;lt;0x00000000ccb54860&amp;gt; (a org.apache.hadoop.hbase.regionserver.StoreScanner)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:403)
        - locked &amp;lt;0x00000000ccb54860&amp;gt; (a org.apache.hadoop.hbase.regionserver.StoreScanner)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:127)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3459)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3406)
        - locked &amp;lt;0x00000000c59ee610&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3423)
        - locked &amp;lt;0x00000000c59ee610&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4171)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4144)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1958)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1389)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;p&gt;At the same time I find that flush cannot finish:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-quote&quot;&gt;&quot;regionserver60020.cacheFlusher&quot;&lt;/span&gt; daemon prio=10 tid=0x00007f05749ab000 nid=0x71fe waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; monitor entry [0x00007f05677f6000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.updateReaders(StoreScanner.java:443)
        - waiting to lock &amp;lt;0x00000000ccb54860&amp;gt; (a org.apache.hadoop.hbase.regionserver.StoreScanner)
        at org.apache.hadoop.hbase.regionserver.Store.notifyChangedReadersObservers(Store.java:904)
        at org.apache.hadoop.hbase.regionserver.Store.updateStorefiles(Store.java:893)
        at org.apache.hadoop.hbase.regionserver.Store.access$600(Store.java:107)
        at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.commit(Store.java:2291)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1455)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1353)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1294)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:406)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:380)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:243)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:722)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Both StoreScanner.updateReaders and StoreScanner.reseek are synchronized.&lt;/p&gt;


&lt;p&gt;So the problem seems to be that MemStoreScanner loops forever in getNext(...). I took a jstack a bunch of times during execution, this always shows up.&lt;br/&gt;
Need to dig a bit more, I do not see a good way to deal with this, yet.&lt;/p&gt;</comment>
                            <comment id="13432841" author="lhofhansl" created="Sun, 12 Aug 2012 21:35:10 +0000"  >&lt;p&gt;When I instrument the code slightly further I see that MemStoreScanner.getNext(...) has to skip over a large number of KVs with a higher memstoreTS (many millions), which causes the complete unresponsiveness of the RS (I tried to let the RS run for a while after I stopped the Puts/Gets from the client, but after 30mins I just killed it).&lt;/p&gt;

&lt;p&gt;As a test I changed ScanWildcardColumnTracker.checkVersion to return MatchCode.SKIP instead of MatchCode.SEEK_NEXT_COL (when the max number of versions is reached); and I do not see this behavior.&lt;/p&gt;

&lt;p&gt;It seems the problem here stems from the excessive reseeking in this case. The StoreScanner is smart and instructs its KeyValueHeap to seek to the next column (which can potentially skip many columns). Only in this case, this is in fact not so smart, because reseek needs to reset the current iterators, and hence all KV with higher memstoreTS have to be searched again (see also comment in MemStoreScanner.reseek).&lt;/p&gt;

&lt;p&gt;There&apos;s is no way (that I found) to isolate this issue before it happens.&lt;br/&gt;
I have a patch where in reseek the MemStoreScanner opportunistically iterates &quot;a bit&quot; (1000 iterations in my patch), and only then actually reseeks forward.&lt;br/&gt;
This eliminates the problem for me.&lt;br/&gt;
I have no good numbers of when it is more efficient to seek ahead (and skip many versions, columns, or rows) (i.e. how many iterations the MemStoreScanner should attempt before seeking).&lt;/p&gt;

&lt;p&gt;Edit: Spelling.&lt;/p&gt;</comment>
                            <comment id="13432843" author="lhofhansl" created="Sun, 12 Aug 2012 21:40:22 +0000"  >&lt;p&gt;Here&apos;s a 0.94 (that where the problem was reported) patch that does what I describe above. Can&apos;t say I like it.&lt;/p&gt;</comment>
                            <comment id="13432856" author="lhofhansl" created="Sun, 12 Aug 2012 22:39:55 +0000"  >&lt;p&gt;And a trunk patch.&lt;br/&gt;
Please take a careful look. I&apos;m also very open for better suggestions.&lt;/p&gt;

&lt;p&gt;In the long run, we should probably use a different data structure for the MemStoreScanner.&lt;/p&gt;</comment>
                            <comment id="13432861" author="hadoopqa" created="Sun, 12 Aug 2012 23:33:42 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12540593/6561-0.96.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12540593/6561-0.96.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 9 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2550//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13432862" author="lhofhansl" created="Sun, 12 Aug 2012 23:34:01 +0000"  >&lt;p&gt;Looking at the code again, I am actually not sure anymore why building tailSet in MemStoreScanner and then calling next on the iterators would be scanning through so many more KVs with newer memstoreTSs. There might be something else at play here.&lt;/p&gt;</comment>
                            <comment id="13432941" author="lhofhansl" created="Mon, 13 Aug 2012 06:04:37 +0000"  >&lt;p&gt;A little more detail. When this happens I see the following pattern:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;a seek to column X (at readpoint 1)&lt;/li&gt;
	&lt;li&gt;all versions of &lt;b&gt;all&lt;/b&gt; columns &amp;gt; X only have a readpoint &amp;gt; 1, hence all need to be skipped&lt;/li&gt;
	&lt;li&gt;goto 1. with column X+1, still at readpoint 1, until we exhausted all columns&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;So for each KVs we reseek to, we skip over all KVs larger than this KV. This leads to many millions (hundreds of millions) of KVs that are needlessly skipped multiple times.&lt;br/&gt;
MemStoreScanner.getNext() simply does not find a single KV with the right readpoint and iterates all the way to end (and does so again for each reseek).&lt;/p&gt;

&lt;p&gt;This is very pathological scenario. Somehow a previous Get is not finished before the next Put inserts (see the sample code in pastebin in the description), which seems impossible.&lt;/p&gt;</comment>
                            <comment id="13432954" author="lhofhansl" created="Mon, 13 Aug 2012 06:35:36 +0000"  >&lt;p&gt;An idea would be to have a special comparator that would always sort by memstoreTS first (reverse) and use that to sort the KeyValueSkipListSet. That all new kvs can be skipped cheaply.&lt;/p&gt;</comment>
                            <comment id="13432976" author="stack" created="Mon, 13 Aug 2012 07:46:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;all versions of all columns &amp;gt; X only have a readpoint &amp;gt; 1, hence all need to be skipped&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t follow the above Lars.... So, we seek to column X+1, we need to skip all versions (because they have readpoint &amp;gt; 1) &amp;#8211; so we keep reseeking until the end.  That&apos;d be crazy for sure.&lt;/p&gt;

&lt;p&gt;Why does the Put throw off the Get?  Because memStoreTS gets updated during the Get?&lt;/p&gt;

&lt;p&gt;(No need to answer... you are probably way beyond the above by now).&lt;/p&gt;</comment>
                            <comment id="13433203" author="lhofhansl" created="Mon, 13 Aug 2012 15:14:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;So, we seek to column X+1, we need to skip all versions (because they have readpoint &amp;gt; 1) &#8211; so we keep reseeking until the end. That&apos;d be crazy for sure.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s exactly what I am seeing.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why does the Put throw off the Get? Because memStoreTS gets updated during the Get?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Somehow there&apos;s an older Get that did not finish (or is retried?), and the Puts keep piling on versions that need to be skipped.&lt;/p&gt;

&lt;p&gt;BTW. The idea with sorting leading with memstoreTS does not work, because for flush we need them in normal key order.&lt;/p&gt;</comment>
                            <comment id="13433221" author="lhofhansl" created="Mon, 13 Aug 2012 15:39:48 +0000"  >&lt;p&gt;Another option is to have the MemStoreScanner memorize the last key it iterated to (for both the kvSet and tailSet) and use that to build tailSet first in reseek (i.e. the closest we can get to save the iterator state).&lt;/p&gt;</comment>
                            <comment id="13433226" author="stack" created="Mon, 13 Aug 2012 15:44:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Another option is to have the MemStoreScanner memorize the last key it iterated to (for both the kvSet and tailSet) and use that to build tailSet first in reseek (i.e. the closest we can get to save the iterator state).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That could work.  I was worried something could be inserted between our get of last key and build of tailset but should be fine since the read point will be lagging the write point used by the insertion?&lt;/p&gt;</comment>
                            <comment id="13433269" author="lhofhansl" created="Mon, 13 Aug 2012 16:39:38 +0000"  >&lt;p&gt;That would already be the case if we just iterated with next().&lt;br/&gt;
I think the reasoning is that no new KVs with a older memstoreTS can possible be inserted later, and a scan is not guaranteed to pick up KVs that were inserted later anyway, so it should be OK.&lt;br/&gt;
I&apos;ll make a patch with that soon.&lt;/p&gt;</comment>
                            <comment id="13433533" author="lhofhansl" created="Mon, 13 Aug 2012 20:59:51 +0000"  >&lt;p&gt;Here&apos;s a better patch. A MemStoreScanner now remembers the last KV that was ever iterated to and makes sure we never go backwards from that in a reseek (reseeks must be going forward).&lt;br/&gt;
The other observation is that taking continuous tailSets of tailSets will make things worse (from looking the code... the amount of work is the same, but through more layers of indirection).&lt;/p&gt;

&lt;p&gt;As before, please have a careful look, this is a pretty core part of HBase.&lt;/p&gt;</comment>
                            <comment id="13433682" author="zhihyu@ebaysf.com" created="Mon, 13 Aug 2012 22:37:01 +0000"  >&lt;p&gt;So with latest patch region server becomes responsive, I assume.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// last iterated KVs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; kvser and snapshot (to restore iterator state after reseek)&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;kvser&apos; -&amp;gt; &apos;kvset&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; KeyValue getHighest(KeyValue first, KeyValue second) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above method can be private, right ?&lt;br/&gt;
Since only two keyvalues are involved, maybe call it getHigher() ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; compactionKVMax = conf.getInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hstore.compaction.kv.max&quot;&lt;/span&gt;, 10);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above constant appears in Compactor.java&lt;br/&gt;
Consider introducing a constant and reference the constant.&lt;/p&gt;</comment>
                            <comment id="13433702" author="hadoopqa" created="Mon, 13 Aug 2012 22:57:08 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12540754/6561-0.96-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12540754/6561-0.96-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 9 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2558//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13433728" author="lhofhansl" created="Mon, 13 Aug 2012 23:34:06 +0000"  >&lt;p&gt;Thanks Ted. getHighest was really copied from getLowest &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Open for best suggestions to combine the two without bad readability. I can make both of them private.&lt;br/&gt;
Will fix the spelling, and introduce a constant for the setting.&lt;/p&gt;

&lt;p&gt;Do you see any logical problem with the patch. It should work because is scanner is forward only unless seek() is used. I would still consider this a somewhat risky change, though.&lt;br/&gt;
I&apos;d like to get some comments on this new logic (and some +1&apos;s &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;</comment>
                            <comment id="13433746" author="lhofhansl" created="Mon, 13 Aug 2012 23:58:13 +0000"  >&lt;p&gt;Patch addressing Ted&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13433763" author="zhihyu@ebaysf.com" created="Tue, 14 Aug 2012 00:11:54 +0000"  >&lt;p&gt;The fact that patch v2 passed unit test suite gave me confidence in the approach.&lt;/p&gt;

&lt;p&gt;+1 from me.&lt;/p&gt;

&lt;p&gt;Of course, review from Mikhail, et. al would be appreciated.&lt;/p&gt;</comment>
                            <comment id="13434013" author="hadoopqa" created="Tue, 14 Aug 2012 09:11:20 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12540804/6561-0.96-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12540804/6561-0.96-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 9 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2565//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13434044" author="nkeywal" created="Tue, 14 Aug 2012 10:27:53 +0000"  >&lt;p&gt;If I understand well the problem you&apos;re addressing, we may have a reseek asking to go before the point we have already reached by the next()?&lt;/p&gt;

&lt;p&gt;In your implementation, do you have to keep the row pointed by the iterator? You could use the existing iterator with next(), as the iterators will be recreated at the end of the reseek?&lt;/p&gt;
</comment>
                            <comment id="13434280" author="lhofhansl" created="Tue, 14 Aug 2012 17:14:32 +0000"  >&lt;p&gt;You cannot get the current state of an iterator without advancing it, that&apos;s why I think I need to hold on to the current &quot;state&quot; of the iterator.&lt;/p&gt;</comment>
                            <comment id="13434305" author="nkeywal" created="Tue, 14 Aug 2012 17:44:59 +0000"  >&lt;p&gt;Yes, but you will be resetting the iterators in seekInSubLists, called at the end of reseek.&lt;/p&gt;
</comment>
                            <comment id="13434376" author="lhofhansl" created="Tue, 14 Aug 2012 18:42:51 +0000"  >&lt;p&gt;Oh, I see what you are saying. Because we&apos;re seeking forward it is OK to go to the immediate next key of both iterators because it&apos;ll never be smaller than what we are seeking to? I could buy that if we never reseek to the current top key.&lt;/p&gt;

&lt;p&gt;Also need an extra check then for whether the iterator is exhausted and ignore a call to reseek then.&lt;/p&gt;</comment>
                            <comment id="13434501" author="nkeywal" created="Tue, 14 Aug 2012 20:56:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;I could buy that if we never reseek to the current top key.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Hum. I think it would work, as the iterator would be reset to the current top key again.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also need an extra check then for whether the iterator is exhausted and ignore a call to reseek then.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed, but if we are at the end, may be it has a specific meaning as well (i.e. we&apos;re done), so it&apos;s not that bad to manage it explicitly?&lt;/p&gt;

&lt;p&gt;On the same line, why have you chosen&lt;br/&gt;
      kvTail = kvsetAtCreation.tailSet(getHighest(key, kvsetItRow));&lt;br/&gt;
      snapshotTail = snapshotAtCreation.tailSet(getHighest(key, snapshotItRow));&lt;br/&gt;
vs.&lt;br/&gt;
      kvTail = kvTail.tailSet(getHighest(key, kvsetItRow));&lt;br/&gt;
      snapshotTail = snapshotTail.tailSet(getHighest(key, snapshotItRow));&lt;/p&gt;

&lt;p&gt;?&lt;/p&gt;</comment>
                            <comment id="13434637" author="lhofhansl" created="Tue, 14 Aug 2012 23:38:03 +0000"  >&lt;p&gt;New patch. Uses the iterators directly.&lt;br/&gt;
Also does away with kvTail and snapshotTail.&lt;br/&gt;
(To N.&apos;s question: Building the tail of a tail repeatedly with KeyValueSkiplistSet, does not really help, in fact it just makes it worse).&lt;/p&gt;

&lt;p&gt;The stalling the RS is still gone. Let&apos;s see what HadoopQA says.&lt;br/&gt;
Again, please have a careful, this stuff is tricky.&lt;/p&gt;</comment>
                            <comment id="13434645" author="lhofhansl" created="Tue, 14 Aug 2012 23:40:01 +0000"  >&lt;p&gt;@N: It would not work if we repeatedly reseek to the &lt;b&gt;same&lt;/b&gt; key. The iterator would always be one key ahead (hence the highest of the two would always be the next key). Reseek should always be forward, though. So it should work.&lt;/p&gt;</comment>
                            <comment id="13434764" author="lhofhansl" created="Wed, 15 Aug 2012 02:29:27 +0000"  >&lt;p&gt;Let&apos;s try hadoop qa again.&lt;/p&gt;</comment>
                            <comment id="13434767" author="lhofhansl" created="Wed, 15 Aug 2012 02:39:11 +0000"  >&lt;p&gt;Attaching patch again&lt;/p&gt;</comment>
                            <comment id="13434815" author="lhofhansl" created="Wed, 15 Aug 2012 05:14:56 +0000"  >&lt;p&gt;The new patch fails these tests:&lt;br/&gt;
Failed tests:   testFlushCacheWhileScanning(org.apache.hadoop.hbase.regionserver.TestHRegion): i=20 expected:&amp;lt;2&amp;gt; but was:&amp;lt;1&amp;gt;&lt;br/&gt;
  testWritesWhileGetting(org.apache.hadoop.hbase.regionserver.TestHRegion): expected:&amp;lt;0&amp;gt; but was:&amp;lt;2&amp;gt;&lt;/p&gt;

&lt;p&gt;I think relying on the iterators is too brittle. I&apos;ll go back to the approach of explicitly saving the iterator state.&lt;/p&gt;</comment>
                            <comment id="13434819" author="hadoopqa" created="Wed, 15 Aug 2012 05:37:14 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12541000/6561-0.96-v4.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12541000/6561-0.96-v4.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 9 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestHRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;br/&gt;
                  org.apache.hadoop.hbase.TestAcidGuarantees&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2576//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13434824" author="lhofhansl" created="Wed, 15 Aug 2012 05:57:10 +0000"  >&lt;p&gt;Almost the same as v3 (not v4). Also does away with kvTail snapshotTail, as they are not needed.&lt;/p&gt;

&lt;p&gt;This should be close to final patch.&lt;/p&gt;</comment>
                            <comment id="13434875" author="nkeywal" created="Wed, 15 Aug 2012 08:11:58 +0000"  >&lt;p&gt;+1 for me on v5, thanks Lars for the explanation and the attempt with the iterators!&lt;/p&gt;</comment>
                            <comment id="13434897" author="hadoopqa" created="Wed, 15 Aug 2012 09:18:08 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12541008/6561-0.96-v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12541008/6561-0.96-v5.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 9 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplication&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2580//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13435652" author="lhofhansl" created="Thu, 16 Aug 2012 00:33:52 +0000"  >&lt;p&gt;Going to commit tomorrow.&lt;/p&gt;</comment>
                            <comment id="13436152" author="lhofhansl" created="Thu, 16 Aug 2012 17:52:14 +0000"  >&lt;p&gt;Committed to 0.94 and 0.96.&lt;/p&gt;</comment>
                            <comment id="13436215" author="hudson" created="Thu, 16 Aug 2012 18:47:41 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3226 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3226/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3226/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6561&quot; title=&quot;Gets/Puts with many columns send the RegionServer into an &amp;quot;endless&amp;quot; loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6561&quot;&gt;&lt;del&gt;HBASE-6561&lt;/del&gt;&lt;/a&gt; Gets/Puts with many columns send the RegionServer into an &apos;endless&apos; loop (Revision 1373943)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Compactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13436221" author="hudson" created="Thu, 16 Aug 2012 18:54:10 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #400 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/400/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/400/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6561&quot; title=&quot;Gets/Puts with many columns send the RegionServer into an &amp;quot;endless&amp;quot; loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6561&quot;&gt;&lt;del&gt;HBASE-6561&lt;/del&gt;&lt;/a&gt; Gets/Puts with many columns send the RegionServer into an &apos;endless&apos; loop (Revision 1373951)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13436434" author="hudson" created="Thu, 16 Aug 2012 23:53:59 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #132 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/132/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/132/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6561&quot; title=&quot;Gets/Puts with many columns send the RegionServer into an &amp;quot;endless&amp;quot; loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6561&quot;&gt;&lt;del&gt;HBASE-6561&lt;/del&gt;&lt;/a&gt; Gets/Puts with many columns send the RegionServer into an &apos;endless&apos; loop (Revision 1373943)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Compactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13439498" author="hudson" created="Wed, 22 Aug 2012 13:48:08 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #48 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/48/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/48/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6561&quot; title=&quot;Gets/Puts with many columns send the RegionServer into an &amp;quot;endless&amp;quot; loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6561&quot;&gt;&lt;del&gt;HBASE-6561&lt;/del&gt;&lt;/a&gt; Gets/Puts with many columns send the RegionServer into an &apos;endless&apos; loop (Revision 1373951)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13448320" author="hudson" created="Wed, 5 Sep 2012 00:57:15 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #7 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/7/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/7/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6561&quot; title=&quot;Gets/Puts with many columns send the RegionServer into an &amp;quot;endless&amp;quot; loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6561&quot;&gt;&lt;del&gt;HBASE-6561&lt;/del&gt;&lt;/a&gt; Gets/Puts with many columns send the RegionServer into an &apos;endless&apos; loop (Revision 1373951)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13624662" author="stack" created="Sun, 7 Apr 2013 04:46:20 +0000"  >&lt;p&gt;Fix up after bulk move overwrote some 0.94.2 fix versions w/ 0.95.0 (Noticed by Lars Hofhansl)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12540583" name="6561-0.94.txt" size="3389" author="lhofhansl" created="Sun, 12 Aug 2012 21:40:22 +0000"/>
                            <attachment id="12540754" name="6561-0.96-v2.txt" size="5711" author="lhofhansl" created="Mon, 13 Aug 2012 20:59:51 +0000"/>
                            <attachment id="12540804" name="6561-0.96-v3.txt" size="7796" author="lhofhansl" created="Mon, 13 Aug 2012 23:58:13 +0000"/>
                            <attachment id="12541000" name="6561-0.96-v4.txt" size="8658" author="lhofhansl" created="Wed, 15 Aug 2012 02:39:11 +0000"/>
                            <attachment id="12540976" name="6561-0.96-v4.txt" size="8658" author="lhofhansl" created="Tue, 14 Aug 2012 23:38:03 +0000"/>
                            <attachment id="12541008" name="6561-0.96-v5.txt" size="9217" author="lhofhansl" created="Wed, 15 Aug 2012 05:57:10 +0000"/>
                            <attachment id="12540593" name="6561-0.96.txt" size="3894" author="lhofhansl" created="Sun, 12 Aug 2012 22:39:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 12 Aug 2012 23:33:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>245274</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 36 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i067if:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34148</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>