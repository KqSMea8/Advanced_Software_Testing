<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:39:25 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6737/HBASE-6737.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6737] NullPointerException at regionserver.wal.SequenceFileLogWriter.append</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6737</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Real cluster, scenario in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5843&quot; title=&quot;Improve HBase MTTR - Mean Time To Recover&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5843&quot;&gt;&lt;del&gt;HBASE-5843&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
There are two exceptions, I create a single JIRA with both of them.&lt;/p&gt;

&lt;p&gt;2012-09-04 18:14:49,264 FATAL org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: WriterThread-1 Got while writing log entry to log&lt;br/&gt;
java.io.IOException: java.lang.NullPointerException&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:229)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:949)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:919)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:891)&lt;br/&gt;
Caused by: java.lang.NullPointerException&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Writer.checkAndWriteSync(SequenceFile.java:1026)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1068)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1035)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:226)&lt;br/&gt;
	... 3 more&lt;/p&gt;


&lt;p&gt;2012-09-04 18:15:52,546 ERROR org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Error in log splitting write thread&lt;br/&gt;
java.lang.reflect.UndeclaredThrowableException&lt;br/&gt;
	at $Proxy7.getFileInfo(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:875)&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:513)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:768)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getRegionSplitEditsPath(HLogSplitter.java:559)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.createWAP(HLogSplitter.java:974)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.access$800(HLogSplitter.java:82)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$OutputSink.getWriterAndPath(HLogSplitter.java:1309)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:942)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:919)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:891)&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:261)&lt;br/&gt;
	... 11 more&lt;br/&gt;
Caused by: java.io.IOException: Call to BOX1/192.168.15.5:9000 failed on local exception: java.nio.channels.ClosedByInterruptException&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1107)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)&lt;br/&gt;
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)&lt;br/&gt;
	at $Proxy7.getFileInfo(Unknown Source)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)&lt;br/&gt;
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)&lt;br/&gt;
	at $Proxy7.getFileInfo(Unknown Source)&lt;br/&gt;
	... 15 more&lt;br/&gt;
Caused by: java.nio.channels.ClosedByInterruptException&lt;br/&gt;
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)&lt;br/&gt;
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)&lt;br/&gt;
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)&lt;br/&gt;
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)&lt;br/&gt;
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)&lt;br/&gt;
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)&lt;br/&gt;
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)&lt;br/&gt;
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)&lt;br/&gt;
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:783)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.call(Client.java:1051)&lt;br/&gt;
	... 23 more&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12606599">HBASE-6737</key>
            <summary>NullPointerException at regionserver.wal.SequenceFileLogWriter.append</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="nkeywal">Nicolas Liochon</reporter>
                        <labels>
                    </labels>
                <created>Fri, 7 Sep 2012 14:41:17 +0000</created>
                <updated>Tue, 25 Jun 2013 10:45:13 +0000</updated>
                            <resolved>Tue, 25 Jun 2013 10:45:13 +0000</resolved>
                                    <version>0.95.2</version>
                                                    <component>master</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13462701" author="nkeywal" created="Tue, 25 Sep 2012 12:40:59 +0000"  >&lt;p&gt;Stack 1: It seems to be an expected case, from the code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void append(HLog.Entry entry) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    entry.setCompressionContext(compressionContext);
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.writer.append(entry.getKey(), entry.getEdit());
    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (NullPointerException npe) {
      &lt;span class=&quot;code-comment&quot;&gt;// Concurrent close...
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(npe);
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13554521" author="sershe" created="Tue, 15 Jan 2013 23:37:04 +0000"  >&lt;p&gt;+1, I&apos;ve seen this while doing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7329&quot; title=&quot;remove flush-related records from WAL and make locking more granular&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7329&quot;&gt;&lt;del&gt;HBASE-7329&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13554522" author="sershe" created="Tue, 15 Jan 2013 23:37:24 +0000"  >&lt;p&gt;I will fix it there&lt;/p&gt;</comment>
                            <comment id="13555324" author="sershe" created="Wed, 16 Jan 2013 18:40:05 +0000"  >&lt;p&gt;sorry, maybe not, caller still has to handle the IOException&lt;/p&gt;</comment>
                            <comment id="13555342" author="sershe" created="Wed, 16 Jan 2013 19:05:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; Hi, is it possible to repro the former case, or get more logs? From cursory look it appears that the writers are only closed after some attempt to stop writer threads in HLogSplitter. Were there errors stopping writer threads?&lt;/p&gt;</comment>
                            <comment id="13555414" author="nkeywal" created="Wed, 16 Jan 2013 20:14:23 +0000"  >&lt;p&gt;Hi Sergey,&lt;/p&gt;

&lt;p&gt;I had the issue with this scenario, but it wasn&apos;t reproduced all the time:&lt;br/&gt;
1) Setting:    dfs.replication = 2&lt;br/&gt;
2)    Start with 2 DN and 2 RS. Create a table with 100 regions in the second one. The first holds meta &amp;amp; root.&lt;br/&gt;
3)    Insert 10M rows, distributed on all regions. That creates 8 logs files of 60Mb each, on a single server.&lt;br/&gt;
4)    Start another box with a DN and a RS. This box is empty (no regions, no blocks).&lt;br/&gt;
5)    Unplug (physically) the box with the 100 regions and the or 8 log files.&lt;/p&gt;

&lt;p&gt;I will work on this again in two weeks or so, so I will update the JIRA if I have more info.&lt;/p&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12551766">HBASE-5843</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 15 Jan 2013 23:37:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>241736</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 48 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02buf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11520</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>