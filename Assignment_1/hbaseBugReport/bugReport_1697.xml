<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:55:37 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1697/HBASE-1697.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1697] Discretionary access control</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1697</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Consider implementing discretionary access control for HBase.&lt;/p&gt;

&lt;p&gt;Access control has three aspects: authentication, authorization and audit.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Authentication: Access is controlled by insisting on an authentication procedure to establish the identity of the user. The authentication procedure should minimally require a non-plaintext authentication factor (e.g. encrypted password with salt) and should ideally or at least optionally provide cryptographically strong confidence via public key certification.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Authorization: Access is controlled by specifying rights to resources via an access control list (ACL). An ACL is a list of permissions attached to an object. The list specifies who or what is allowed to access the object and what operations are allowed to be performed on the object, f.e. create, update, read, or delete.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Audit: Important actions taken by subjects should be logged for accountability, a chronological record which  enables the full reconstruction and examination of a sequence of events, e.g. schema changes or data mutations. Logging activity should be protected from all subjects except for a restricted set with administrative privilege, perhaps to only a single super-user.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Discretionary access control means the access policy for an object is determined by the owner of the object. Every object in the system must have a valid owner. Owners can assign access rights and permissions to other users. The initial owner of an object is the subject who created it. If subjects are deleted from a system, ownership of objects owned by them should revert to some super-user or otherwise valid default. &lt;/p&gt;

&lt;p&gt;HBase can enforce access policy at table, column family, or cell granularity. Cell granularity does not make much sense. An implementation which controls access at both the table and column family levels is recommended, though a first cut could consider control at the table level only. The initial set of permissions can be: Create (table schema or column family), update (table schema or column family), read (column family), delete (table or column family), execute (filters), and transfer ownership. The subject identities and access tokens could be stored in a new administrative table. ACLs on tables and column families can be stored in META. &lt;/p&gt;

&lt;p&gt;Access other than read access to catalog and administrative tables should be restricted to a set of administrative users or perhaps a single super-user. A data mutation on a user table by a subject without administrative or superuser privilege which results in a table split is an implicit temporary privilege elevation where the regionserver or master updates the catalog tables as necessary to support the split. &lt;/p&gt;

&lt;p&gt;Audit logging should be configurable on a per-table basis to avoid this overhead where it is not wanted.&lt;/p&gt;

&lt;p&gt;Consider supporting external authentication and subject identification mechanisms with Java library support: RADIUS/TACACS, Kerberos, LDAP.&lt;/p&gt;

&lt;p&gt;Consider logging audit trails to an HBase table (bigtable type schemas are natural for this) and optionally external logging options with Java library support &amp;#8211; syslog, etc., or maybe commons-logging is sufficient and punt to administrator to set up appropriate commons-logging/log4j configurations for their needs. &lt;/p&gt;

&lt;p&gt;If &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1002&quot; title=&quot;Coprocessors: Support small query language as filter on server side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1002&quot;&gt;&lt;del&gt;HBASE-1002&lt;/del&gt;&lt;/a&gt; is considered, and the option to support filtering via upload of (perhaps complex) bytecode produced by some little language compiler is implemented, the execute privilege could be extended in a manner similar to how stored procedures in SQL land execute either with the privilege of the current user or the (table/procedure) creator.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12431322">HBASE-1697</key>
            <summary>Discretionary access control</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jul 2009 02:13:09 +0000</created>
                <updated>Mon, 12 May 2014 00:31:55 +0000</updated>
                            <resolved>Mon, 12 May 2014 00:31:55 +0000</resolved>
                                                                    <component>security</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>34</watches>
                                                                                                            <comments>
                            <comment id="12780387" author="apurtell" created="Fri, 20 Nov 2009 02:36:19 +0000"  >&lt;p&gt;Bring in to 0.22. Discussions about needing this are heating up here. &lt;/p&gt;</comment>
                            <comment id="12780900" author="apurtell" created="Sat, 21 Nov 2009 03:01:35 +0000"  >&lt;p&gt;What about bringing this into 0.21 (with sufficient sponsored development)? &lt;/p&gt;</comment>
                            <comment id="12780910" author="jdcryans" created="Sat, 21 Nov 2009 04:29:01 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12780916" author="stack" created="Sat, 21 Nov 2009 05:42:18 +0000"  >&lt;p&gt;No objection from me.  Its mostly orthogonal to other dev.  Just has to be done by the time hadoop 0.21 releases (smile).&lt;/p&gt;</comment>
                            <comment id="12781259" author="stack" created="Sun, 22 Nov 2009 23:44:53 +0000"  >&lt;p&gt;This looks like it might be pertinent to this issue: &lt;a href=&quot;http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#sc_ZooKeeperPluggableAuthentication&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#sc_ZooKeeperPluggableAuthentication&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12890805" author="esammer" created="Wed, 21 Jul 2010 18:15:51 +0000"  >&lt;p&gt;As part of this addition, it would be extremely useful to be able to attribute resource consumption to individual users in addition to normal action auditing. Specifically, we&apos;d like to be able to attach quotas to users or tables to users and quotas to tables. It would be sufficient to simply defer to HDFS for quotas provided tables could be given specific root directories and user information was pushed down to the HDFS level. In this case, a table would be owned by a specific user.&lt;/p&gt;</comment>
                            <comment id="12897295" author="stack" created="Wed, 11 Aug 2010 15:00:36 +0000"  >&lt;p&gt;Andrew: You need something on this issue?&lt;/p&gt;</comment>
                            <comment id="12990679" author="suchisubhra" created="Fri, 4 Feb 2011 19:05:34 +0000"  >&lt;p&gt;Hi  Andrew,&lt;/p&gt;

&lt;p&gt;   In our platform, we need to have ACL on object  level. We are planning to build it. But we like to know if you  guys have any plan to build it.&lt;br/&gt;
If we know your plan,  we can execute it and contribute. We have resources. &lt;/p&gt;

&lt;p&gt;Thanks.&lt;br/&gt;
~Suchi&lt;/p&gt;</comment>
                            <comment id="12990709" author="ghelmling" created="Fri, 4 Feb 2011 20:00:34 +0000"  >&lt;p&gt;Hi Suchi,&lt;/p&gt;

&lt;p&gt;Thanks, that is great!&lt;/p&gt;

&lt;p&gt;We&apos;ve discussed per-KeyValue ACLs as a future feature, but have deferred the implementation due to other HBase internal changes that would be required to support them efficiently.&lt;/p&gt;

&lt;p&gt;Our rough plan was to implement a new &apos;metacolumn&apos; feature for HBase (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2893&quot; title=&quot;Table metacolumns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2893&quot;&gt;&lt;del&gt;HBASE-2893&lt;/del&gt;&lt;/a&gt;).  A &apos;metacolumn&apos; would be a special, internal only (or coprocessor only?) column family associated with each table.  Table level and column family level ACLs would still apply in the normal case, but the metacolumn would allow storing per-row or per-KeyValue override ACLs directly inline with the row data.&lt;/p&gt;

&lt;p&gt;For read operations, scans would then probably use a special filter to allow specific KVs to be included in results back to the client.  For write operations, the org.apache.hadoop.hbase.security.rbac.AccessController.prePut() method would check for entries in the row metacolumn in addition to the normal ACLs.&lt;/p&gt;

&lt;p&gt;See also &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3435&quot; title=&quot;Per-column-qualifier and per-key-value security for HBASE-3025&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3435&quot;&gt;&lt;del&gt;HBASE-3435&lt;/del&gt;&lt;/a&gt; for a discussion of adding per-column-qualifier ACLs to our scheme.  I have some work in progress that would enable column-qualifier ACLs to be used.  It incorporates the use of an AccessControlFilter to allow returning only those KVs matching the granted column qualifiers for a scan.  I&apos;ll be posting a patch for that soon.&lt;/p&gt;

&lt;p&gt;So summing it all up, we&apos;d ultimately like to have a hierarchy for applying ACLs as follows:&lt;/p&gt;

&lt;p&gt;global -&amp;gt; table -&amp;gt; column family -&amp;gt; column qualifier -&amp;gt; row -&amp;gt; key value&lt;/p&gt;

&lt;p&gt;The assumption so far has been that the ACLs granted at each level are additive &amp;#8211; if I have &quot;read&quot; access at the table level, then you can&apos;t revoke that access for specific KVs (and we don&apos;t have to continue checking for authorization down the full hierarchy).  This is mainly a performance consideration.  We can discuss if that meets your needs or not.&lt;/p&gt;

&lt;p&gt;If you&apos;d like to work out a way to collaborate on getting all of this done, we&apos;d love the help!  Please email me directly at garyh@apache.org.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Gary&lt;/p&gt;</comment>
                            <comment id="12993731" author="suchisubhra" created="Fri, 11 Feb 2011 22:24:42 +0000"  >&lt;p&gt;I have sent you email. Let&apos;s talk  about this in detail.&lt;br/&gt;
Thanks.&lt;br/&gt;
~Suchi&lt;/p&gt;</comment>
                            <comment id="13047580" author="stack" created="Fri, 10 Jun 2011 22:45:55 +0000"  >&lt;p&gt;Moving out of 0.92.0. Pull it back in if you think different.&lt;/p&gt;</comment>
                            <comment id="13241232" author="lakshman" created="Thu, 29 Mar 2012 13:47:18 +0000"  >&lt;p&gt;No updates here from long time.&lt;br/&gt;
From my understanding, to make HBase secure, we need huge contributions in this area.&lt;br/&gt;
Also, this involves many challenges (architectural changes, maintain/break compatibility, ...).&lt;br/&gt;
In spite of these challenges, it adds more value to HBase.&lt;/p&gt;

&lt;p&gt;Anyone interested to look into these security issues?&lt;/p&gt;</comment>
                            <comment id="13241997" author="ghelmling" created="Fri, 30 Mar 2012 01:27:03 +0000"  >&lt;p&gt;@Laxman,&lt;/p&gt;

&lt;p&gt;We probably need to do some JIRA housekeeping here.  There hasn&apos;t been much activity in this ticket because it&apos;s really just an umbrella issue tying together the individual efforts.&lt;/p&gt;

&lt;p&gt;Initial security features are in place with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3025&quot; title=&quot;Coprocessor based simple access control&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3025&quot;&gt;&lt;del&gt;HBASE-3025&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2418&quot; title=&quot;add support for ZooKeeper authentication&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2418&quot;&gt;&lt;del&gt;HBASE-2418&lt;/del&gt;&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2742&quot; title=&quot;Provide strong authentication with a secure RPC engine&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2742&quot;&gt;&lt;del&gt;HBASE-2742&lt;/del&gt;&lt;/a&gt;.  These are released in 0.92.  Currently access control is performed by use of ACLs stored at the global (forthcoming), table, column family, or column qualifier level.&lt;/p&gt;

&lt;p&gt;There are definitely additional features that can be built to contribute to our security solution:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;adding client authentication for thrift and REST clients&lt;/li&gt;
	&lt;li&gt;proxying HBase access from thrift and REST servers as the authenticated clients (currently these server can simply be configured to authenticate and access HBase as their own principals)&lt;/li&gt;
	&lt;li&gt;supporting or moving to alternate access control schemes (RBAC)&lt;/li&gt;
	&lt;li&gt;row or key-value based access control&lt;/li&gt;
	&lt;li&gt;supporting other authentication mechanisms than kerberos and authentication tokens&lt;/li&gt;
	&lt;li&gt;probably many others&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Anyone interested in working on these would certainly be welcomed.  But we do currently have a working security implementation that integrates nicely with HDFS and map reduce.&lt;/p&gt;</comment>
                            <comment id="13242081" author="lakshman" created="Fri, 30 Mar 2012 05:36:49 +0000"  >&lt;p&gt;Thanks Gary for the info on Security.&lt;br/&gt;
I&apos;m going through the current implementation.&lt;br/&gt;
Soon will take up some jiras.&lt;/p&gt;</comment>
                            <comment id="13277677" author="lakshman" created="Thu, 17 May 2012 08:58:22 +0000"  >&lt;p&gt;We are trying to setup a secure HBase (HBase-HDFS-ZooKeeper) cluster.&lt;br/&gt;
After resolving initial issues, finally we are blocked with &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1467&quot; title=&quot;Server principal on client side is derived using hostname.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1467&quot;&gt;ZOOKEEPER-1467&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;And also, I found it to be more difficult to use Kerberos principals bound to host names.&lt;br/&gt;
When we bind Kerberos principals with host names (as recommended in CDH 4 security guide), we are frequently &amp;amp; randomly hitting ZooKeeper &quot;Auth Failed&quot; exception. &lt;/p&gt;

&lt;p&gt;So we proceed with the cluster-id instead of host name. i.e., one user - one principal - one key tab. Following are the principals we are using.&lt;/p&gt;

&lt;p&gt;zookeeper/clusterid - to run ZK cluster (3-node ZooKeeper cluster)&lt;br/&gt;
hdfs/clusterid - to run HDFS cluster  (NameNode, DataNode)&lt;br/&gt;
hbase/clusterid - to run HBase cluster (Master, Region Server)&lt;/p&gt;

&lt;p&gt;Is this approach correct?&lt;/p&gt;</comment>
                            <comment id="13278051" author="apurtell" created="Thu, 17 May 2012 18:15:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;When we bind Kerberos principals with host names (as recommended in CDH 4 security guide), we are frequently &amp;amp; randomly hitting ZooKeeper &quot;Auth Failed&quot; exception.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1437&quot; title=&quot;Client uses session before SASL authentication complete&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1437&quot;&gt;&lt;del&gt;ZOOKEEPER-1437&lt;/del&gt;&lt;/a&gt; perhaps? ZooKeeper wants us to tunnel SASL in the ZK protocol instead of wrapping at the socket layer as is customarily done. Internally we implemented a CountDownLatch on SASL auth but Eugene is iterating a more architecturally appropriate solution with Patrick.&lt;/p&gt;</comment>
                            <comment id="13280832" author="lakshman" created="Tue, 22 May 2012 09:23:23 +0000"  >&lt;p&gt;Thanks for the info Andrew. I&apos;m discussing this issue with Eugene. (&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1467&quot; title=&quot;Server principal on client side is derived using hostname.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1467&quot;&gt;ZOOKEEPER-1467&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;We got struck with another problem in HBase client authentication.&lt;br/&gt;
Client is not able to establish connection with HBase server successfully.&lt;/p&gt;

&lt;p&gt;Exception we got here:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2012-05-22 09:42:22,627 WARN org.apache.hadoop.ipc.SecureClient: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
2012-05-22 09:42:22,627 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:testuser (auth:KERBEROS) cause:java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
2012-05-22 09:42:22,630 DEBUG org.apache.hadoop.ipc.SecureClient: closing ipc connection to HOST-10-18-40-19/10.18.40.19:60020: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection$1.run(SecureClient.java:227)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.util.Methods.call(Methods.java:37)
	at org.apache.hadoop.hbase.security.User.call(User.java:586)
	at org.apache.hadoop.hbase.security.User.access$700(User.java:50)
	at org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:440)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection.handleSaslConnectionFailure(SecureClient.java:194)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection.setupIOstreams(SecureClient.java:274)
	at org.apache.hadoop.hbase.ipc.SecureClient.getConnection(SecureClient.java:485)
	at org.apache.hadoop.hbase.ipc.SecureClient.getConnection(SecureClient.java:69)
	at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:897)
	at org.apache.hadoop.hbase.ipc.SecureRpcEngine$Invoker.invoke(SecureRpcEngine.java:164)
	at $Proxy6.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.hbase.ipc.SecureRpcEngine.getProxy(SecureRpcEngine.java:208)
	at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:303)
	at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:280)
	at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:332)
	at org.apache.hadoop.hbase.ipc.HBaseRPC.waitForProxy(HBaseRPC.java:236)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHRegionConnection(HConnectionManager.java:1284)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHRegionConnection(HConnectionManager.java:1240)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHRegionConnection(HConnectionManager.java:1227)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:936)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:832)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:801)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:933)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:836)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:801)
	at org.apache.hadoop.hbase.client.HTable.finishSetup(HTable.java:234)
	at org.apache.hadoop.hbase.client.HTable.&amp;lt;init&amp;gt;(HTable.java:174)
	at org.apache.hadoop.hbase.client.HTable.&amp;lt;init&amp;gt;(HTable.java:133)
	at hbase.test.Hbasetest.main(Hbasetest.java:37)
Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:194)
	at org.apache.hadoop.hbase.security.HBaseSaslRpcClient.saslConnect(HBaseSaslRpcClient.java:138)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection.setupSaslConnection(SecureClient.java:176)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection.access$500(SecureClient.java:84)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection$2.run(SecureClient.java:267)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection$2.run(SecureClient.java:264)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.util.Methods.call(Methods.java:37)
	at org.apache.hadoop.hbase.security.User.call(User.java:586)
	at org.apache.hadoop.hbase.security.User.access$700(User.java:50)
	at org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:440)
	at org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection.setupIOstreams(SecureClient.java:263)
	... 23 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
	at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:130)
	at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:106)
	at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:172)
	at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:209)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:195)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:175)
	... 40 more
2012-05-22 09:42:22,636 DEBUG org.apache.hadoop.ipc.SecureClient: IPC Client (1778276127) connection to HOST-10-18-40-19/10.18.40.19:60020 from testuser: closed
2012-05-22 09:42:22,638 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: locateRegionInMeta parentTable=-ROOT-, metaLocation={region=-ROOT-,,0.70236052, hostname=HOST-10-18-40-19, port=60020}, attempt=0 of 120 failed; retrying after sleep of 1000 because: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
2012-05-22 09:42:22,640 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@6ecf829d; serverName=HOST-10-18-40-19,60020,1337574445438
2012-05-22 09:42:23,641 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@6ecf829d; serverName=HOST-10-18-40-19,60020,1337574445438
2012-05-22 09:42:23,642 DEBUG org.apache.hadoop.ipc.SecureClient: RPC Server Kerberos principal name for protocol=org.apache.hadoop.hbase.ipc.HRegionInterface is hbase/hadoop@HADOOP.COM
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Other details:&lt;/p&gt;

&lt;p&gt;HBase version: 0.94.0&lt;br/&gt;
Hadoop version: 0.23.1&lt;br/&gt;
Kerberos version: 1.10.1&lt;br/&gt;
Java version: 1.6.0_31, 64 bit&lt;br/&gt;
Linux version: SuSE 11.1 &lt;span class=&quot;error&quot;&gt;&amp;#91;Kernel version : 2.6.32.12-0.7-default x86_64 GNU/Linux&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;We had gone thru the solutions available @&lt;br/&gt;
&lt;a href=&quot;http://docs.oracle.com/javase/1.5.0/docs/guide/security/jgss/tutorials/Troubleshooting.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://docs.oracle.com/javase/1.5.0/docs/guide/security/jgss/tutorials/Troubleshooting.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://ccp.cloudera.com/display/CDHDOC/Appendix+A+-+Troubleshooting#AppendixA-Troubleshooting-Problem2%3AJavaisunabletoreadtheKerberoscredentialscachecreatedbyversionsofMITKerberos1.8.1orhigher&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://ccp.cloudera.com/display/CDHDOC/Appendix+A+-+Troubleshooting#AppendixA-Troubleshooting-Problem2%3AJavaisunabletoreadtheKerberoscredentialscachecreatedbyversionsofMITKerberos1.8.1orhigher&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But none of then seems to work. Any clues?&lt;/p&gt;</comment>
                            <comment id="13280904" author="lakshman" created="Tue, 22 May 2012 12:14:59 +0000"  >&lt;p&gt;Able to find the issue. In client machines we didn&apos;t replace the JCE policy jars.&lt;br/&gt;
I think its worth documenting this.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12556018">ZOOKEEPER-1467</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12431530">HBASE-1712</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12500976">HBASE-3615</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12407018">HADOOP-4487</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12474775">HBASE-3025</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12441378">HBASE-2001</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12470574">HBASE-2893</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12461439">HBASE-2418</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12558146">HBASE-6096</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="12441792">HBASE-2014</subtask>
                            <subtask id="12441875">HBASE-2016</subtask>
                            <subtask id="12461448">HBASE-2420</subtask>
                            <subtask id="12474775">HBASE-3025</subtask>
                            <subtask id="12475312">HBASE-3045</subtask>
                            <subtask id="12514096">HBASE-4099</subtask>
                            <subtask id="12514098">HBASE-4100</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 21 Nov 2009 04:29:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32232</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 30 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02fw7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12176</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>