<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:42:43 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-276/HBASE-276.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-276] mapreduce input and output formats to go against hbase</title>
                <link>https://issues.apache.org/jira/browse/HBASE-276</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Inputs should allow specification of row range, columns and column versions.  Outputs should allow specification of where to put the mapreduce result in hbase&lt;/p&gt;</description>
                <environment></environment>
        <key id="12372168">HBASE-276</key>
            <summary>mapreduce input and output formats to go against hbase</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Thu, 21 Jun 2007 21:55:48 +0000</created>
                <updated>Wed, 3 Apr 2013 05:49:51 +0000</updated>
                            <resolved>Sat, 30 Jun 2007 11:25:40 +0000</resolved>
                                                    <fixVersion>0.95.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12507949" author="jimk" created="Mon, 25 Jun 2007 18:53:35 +0000"  >&lt;p&gt;Contributed by Vuk Ercegovac. Will require some examination as it includes changes to some of the core Hadoop classes&lt;/p&gt;</comment>
                            <comment id="12508286" author="jimk" created="Tue, 26 Jun 2007 18:54:21 +0000"  >&lt;p&gt;Vuk,&lt;/p&gt;

&lt;p&gt;Many of the HBase sources are different from the trunk revision. Can you provide a list of the files you needed to change to support Map/Reduce?&lt;/p&gt;</comment>
                            <comment id="12508358" author="jimk" created="Tue, 26 Jun 2007 23:27:59 +0000"  >&lt;p&gt;I am wondering why you needed to create the RecordWritable class. Couldn&apos;t you use ArrayWritable(KeyedData.class) ?&lt;/p&gt;

&lt;p&gt;Also, in the future, it would be most beneficial if you could create a patch instead of sending all the files. If you use eclipse, it is as simple as right click on the project -&amp;gt; Team -&amp;gt; Create Patch...&lt;/p&gt;

&lt;p&gt;Since you sent all the sources, I had to diff all the HBase files to find out that all you had changed was HClient and that change was only the addition of the method getStartKeys.&lt;/p&gt;</comment>
                            <comment id="12508685" author="jimk" created="Wed, 27 Jun 2007 23:24:19 +0000"  >&lt;p&gt;Vuk,&lt;/p&gt;

&lt;p&gt;It would be really nice if you could provide a self contained test case for this code. What you have is good, but I have no way to verify that it is working the way that you expect.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="12508705" author="vercegovac" created="Thu, 28 Jun 2007 01:31:05 +0000"  >&lt;p&gt;Patch for map/reduce to work with hbase.&lt;/p&gt;</comment>
                            <comment id="12508710" author="vercegovac" created="Thu, 28 Jun 2007 02:11:27 +0000"  >&lt;p&gt;Thanks for the feedback and apologies for the initial tgz file. Let me know if the patch works for you.&lt;/p&gt;

&lt;p&gt;I included a sample driver, org.apache.hadoop.mapred.TableJobExample, that scans an input table&apos;s columns and writes to an output table. The input/output tables along with the columns to scan are user specified. Filtering can be done by extending TableMap. Specifying a row range and versions are good suggestions.&lt;/p&gt;

&lt;p&gt;I tried ArrayWritable but ran into the following problem at line 444 of MapTask.java. Value is instantiated&lt;br/&gt;
with the given class, say ArrayWritable, using its empty constructor. Then in line 459, value.readFields&lt;br/&gt;
is called. At this point, the valueClass in ArrayWritable is null, since it was not instantiated or set appropriately. However, ArrayWritable assumes that it is set, rather than reading it off the stream. My workaround is through RecordWritable but am certainly open to better suggestions.&lt;/p&gt;

&lt;p&gt;I have tried this code using MiniHBaseCluster and on a distributed cluster (thanks for the new start/stop scripts!) for the simple example of copying tables.&lt;/p&gt;</comment>
                            <comment id="12508771" author="udanax" created="Thu, 28 Jun 2007 08:34:19 +0000"  >&lt;p&gt;Useful for me.&lt;/p&gt;</comment>
                            <comment id="12508916" author="jimk" created="Thu, 28 Jun 2007 19:32:44 +0000"  >&lt;p&gt;Vuk,&lt;/p&gt;

&lt;p&gt;Thanks for the explanation about ArrayWritable, makes perfect sense now. Also thanks for the extra effort creating the patch, etc. Very much appreciated.&lt;/p&gt;

&lt;p&gt;I just need to do a bit of testing, etc and then I&apos;ll commit it.&lt;/p&gt;</comment>
                            <comment id="12508920" author="jimk" created="Thu, 28 Jun 2007 19:45:55 +0000"  >&lt;p&gt;One more question: Since TableInputFormat.configure does an open table, do you think it is necessary to also do an openTable in HClient.getStartKeys?&lt;/p&gt;</comment>
                            <comment id="12508924" author="vercegovac" created="Thu, 28 Jun 2007 20:29:12 +0000"  >&lt;p&gt;I use openTable in getStartKeys in order to make sure that tableServers is populated.&lt;br/&gt;
I&apos;d like not to depend on the caller for this to be the case (even though there currently is no&lt;br/&gt;
other example of a caller). &lt;/p&gt;

&lt;p&gt;I included openTable in TableInputFormat simply to follow the convention of openning a table before use.&lt;br/&gt;
The subsequent invocation of openTable by getStartKeys should be cheap (hashtable lookup).&lt;/p&gt;

&lt;p&gt;BTW, why is there a distinction between openTable and enableTable?&lt;/p&gt;</comment>
                            <comment id="12508933" author="jimk" created="Thu, 28 Jun 2007 21:16:47 +0000"  >&lt;p&gt;enableTable is the opposite of disableTable. These operations bring a table on-line or take it off-line respectively. The only real purpose for these APIs is for administrative operations that must be done when a table is not on-line (like addColumn for example).&lt;/p&gt;

&lt;p&gt;In general, I would not recommend calling enableTable as tables are on-line by default and if a table is off-line, it means that an administrator is performing an off-line operation on it.&lt;/p&gt;

&lt;p&gt;With respect to openTable, all the other table oriented operations (startUpdate, obtainScanner, get, etc) require openTable to be called first, so in the interest of consistency, I think getStartKeys should behave the same.&lt;/p&gt;</comment>
                            <comment id="12509236" author="jimk" created="Sat, 30 Jun 2007 02:39:13 +0000"  >&lt;p&gt;Applies and runs tests cleanly in my environment. See if Hudson agrees.&lt;/p&gt;</comment>
                            <comment id="12509237" author="jimk" created="Sat, 30 Jun 2007 02:40:33 +0000"  >&lt;p&gt;Works in my environment. Confirm with Hudson prior to committing.&lt;/p&gt;</comment>
                            <comment id="12509238" author="hadoopqa" created="Sat, 30 Jun 2007 02:47:26 +0000"  >&lt;p&gt;-1, could not apply patch.&lt;/p&gt;

&lt;p&gt;The patch command could not apply the latest attachment &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12360855/patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12360855/patch.txt&lt;/a&gt; as a patch to trunk revision r551979.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/348/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/348/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please note that this message is automatically generated and may represent a problem with the automation system and not the patch.&lt;/p&gt;</comment>
                            <comment id="12509239" author="jimk" created="Sat, 30 Jun 2007 03:01:56 +0000"  >&lt;p&gt;Forgot to do svn update before generating patch&lt;/p&gt;</comment>
                            <comment id="12509240" author="jimk" created="Sat, 30 Jun 2007 03:02:29 +0000"  >&lt;p&gt;New patch after svn update&lt;/p&gt;</comment>
                            <comment id="12509241" author="jimk" created="Sat, 30 Jun 2007 03:03:06 +0000"  >&lt;p&gt;Works in my environment confirm with Hudson&lt;/p&gt;</comment>
                            <comment id="12509243" author="hadoopqa" created="Sat, 30 Jun 2007 03:13:12 +0000"  >&lt;p&gt;-1, could not apply patch.&lt;/p&gt;

&lt;p&gt;The patch command could not apply the latest attachment &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12360856/patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12360856/patch.txt&lt;/a&gt; as a patch to trunk revision r551979.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/349/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/349/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please note that this message is automatically generated and may represent a problem with the automation system and not the patch.&lt;/p&gt;</comment>
                            <comment id="12509249" author="jimk" created="Sat, 30 Jun 2007 05:17:09 +0000"  >&lt;p&gt;svn diff does not deal well with files that are moved&lt;/p&gt;</comment>
                            <comment id="12509250" author="jimk" created="Sat, 30 Jun 2007 05:17:59 +0000"  >&lt;p&gt;svn diff does not deal well with files that move&lt;/p&gt;</comment>
                            <comment id="12509254" author="hadoopqa" created="Sat, 30 Jun 2007 06:32:36 +0000"  >&lt;p&gt;-1, build or testing failed&lt;/p&gt;

&lt;p&gt;2 attempts failed to build and test the latest attachment &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12360858/patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12360858/patch.txt&lt;/a&gt; against trunk revision r551979.&lt;/p&gt;

&lt;p&gt;Test results:   &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/350/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/350/testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/350/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/350/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please note that this message is automatically generated and may represent a problem with the automation system and not the patch.&lt;/p&gt;</comment>
                            <comment id="12509258" author="vercegovac" created="Sat, 30 Jun 2007 07:42:51 +0000"  >&lt;p&gt;Should I move the mapred package under hbase, i.e., org.apache.hadoop.hbase.mapred? Similar question for io?&lt;/p&gt;</comment>
                            <comment id="12509271" author="jimk" created="Sat, 30 Jun 2007 10:02:19 +0000"  >&lt;p&gt;Change number of retries, increase timeout from 3 to 5 seconds&lt;/p&gt;</comment>
                            <comment id="12509273" author="jimk" created="Sat, 30 Jun 2007 10:03:52 +0000"  >&lt;p&gt;Test was failing because timeout was set too low or there were not enough retries&lt;/p&gt;</comment>
                            <comment id="12509278" author="jimk" created="Sat, 30 Jun 2007 10:18:04 +0000"  >&lt;p&gt;Vuk,&lt;/p&gt;

&lt;p&gt;Michael (Stack) and I decided to do what you suggest. We also made a&lt;br/&gt;
couple of other minor changes. No big deal, we are almost ready to&lt;br/&gt;
commit, as soon as we can get the test we wrote (based on your example)&lt;br/&gt;
to run under Hudson (it does run in our environment - but seems to run&lt;br/&gt;
out of retries or times out before it can run in the build environment).&lt;/p&gt;

&lt;p&gt;Thanks for your contribution here. It saved us quite a bit of work.&lt;/p&gt;

&lt;p&gt;-Jim&lt;/p&gt;

&lt;p&gt;&amp;#8211; &lt;br/&gt;
Jim Kellerman, Senior Engineer; Powerset&lt;br/&gt;
jim@powerset.com&lt;/p&gt;</comment>
                            <comment id="12509280" author="hadoopqa" created="Sat, 30 Jun 2007 10:40:00 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12360864/patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12360864/patch.txt&lt;/a&gt; applied and successfully tested against trunk revision r551979.&lt;/p&gt;

&lt;p&gt;Test results:   &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/351/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/351/testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/351/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/351/console&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12509284" author="jimk" created="Sat, 30 Jun 2007 11:25:40 +0000"  >&lt;p&gt;I just committed this. Thanks for the contribution Vuk!&lt;/p&gt;</comment>
                            <comment id="12509363" author="hudson" created="Sun, 1 Jul 2007 11:32:49 +0000"  >&lt;p&gt;Integrated in Hadoop-Nightly #141 (See &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/141/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/141/&lt;/a&gt;)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12360506" name="hbaseMR.tgz" size="100980" author="jimk" created="Mon, 25 Jun 2007 18:53:35 +0000"/>
                            <attachment id="12360864" name="patch.txt" size="65973" author="jimk" created="Sat, 30 Jun 2007 10:02:18 +0000"/>
                            <attachment id="12360858" name="patch.txt" size="65086" author="jimk" created="Sat, 30 Jun 2007 05:17:09 +0000"/>
                            <attachment id="12360856" name="patch.txt" size="63917" author="jimk" created="Sat, 30 Jun 2007 03:02:28 +0000"/>
                            <attachment id="12360855" name="patch.txt" size="63917" author="jimk" created="Sat, 30 Jun 2007 02:39:13 +0000"/>
                            <attachment id="12360700" name="patch.txt" size="40614" author="vercegovac" created="Thu, 28 Jun 2007 01:31:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 25 Jun 2007 18:53:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25060</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 25 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h65r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98260</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>