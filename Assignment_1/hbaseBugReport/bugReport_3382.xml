<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:09:44 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3382/HBASE-3382.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3382] Make HBase client work better under concurrent clients</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3382</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The HBase client uses 1 socket per regionserver for communication.  This is good for socket control but potentially bad for latency.  How bad?  I did a simple YCSB test that had this config:&lt;/p&gt;

&lt;p&gt; readproportion=0&lt;br/&gt;
 updateproportion=0&lt;br/&gt;
 scanproportion=1&lt;br/&gt;
 insertproportion=0&lt;/p&gt;

&lt;p&gt; fieldlength=10&lt;br/&gt;
 fieldcount=100&lt;/p&gt;

&lt;p&gt; requestdistribution=zipfian&lt;br/&gt;
 scanlength=300&lt;br/&gt;
 scanlengthdistribution=zipfian&lt;/p&gt;


&lt;p&gt;I ran this with 1 and 10 threads.  The summary is as so:&lt;/p&gt;

&lt;p&gt;1 thread:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;	 Operations	1000&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;	 AverageLatency(ms)	35.871&lt;/p&gt;

&lt;p&gt;10 threads:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;	 Operations	1000&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;	 AverageLatency(ms)	228.576&lt;/p&gt;

&lt;p&gt;We are taking a 6.5x latency hit in our client.  But why?&lt;/p&gt;

&lt;p&gt;First step was to move the deserialization out of the Connection thread, this seemed like it could have a big win, an analog change on the server side got a 20% performance improvement (already commited as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2941&quot; title=&quot;port HADOOP-6713 - threading scalability for RPC reads - to HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2941&quot;&gt;&lt;del&gt;HBASE-2941&lt;/del&gt;&lt;/a&gt;).  I did this and got about a 20% improvement again, with that 228ms number going to about 190 ms.  &lt;/p&gt;

&lt;p&gt;So I then wrote a high performance nanosecond resolution tracing utility.  Clients can flag an API call, and we get tracing and numbers through the client pipeline.  What I found is that a lot of time is being spent in receiving the response from the network.  The code block is like so:&lt;/p&gt;

&lt;p&gt;        NanoProfiler.split(id, &quot;receiveResponse&quot;);&lt;br/&gt;
        if (LOG.isDebugEnabled())&lt;br/&gt;
          LOG.debug(getName() + &quot; got value #&quot; + id);&lt;/p&gt;

&lt;p&gt;        Call call = calls.get(id);&lt;/p&gt;

&lt;p&gt;        size -= 4;  // 4 byte off for id because we already read it.&lt;/p&gt;

&lt;p&gt;        ByteBuffer buf = ByteBuffer.allocate(size);&lt;/p&gt;

&lt;p&gt;        IOUtils.readFully(in, buf.array(), buf.arrayOffset(), size);&lt;/p&gt;

&lt;p&gt;        buf.limit(size);&lt;br/&gt;
        buf.rewind();&lt;br/&gt;
        NanoProfiler.split(id, &quot;setResponse&quot;, &quot;Data size: &quot; + size);&lt;/p&gt;

&lt;p&gt;I came up with some numbers:&lt;br/&gt;
11726 (receiveResponse) split: 64991689 overall: 133562895 Data size: 4288937&lt;br/&gt;
12163 (receiveResponse) split: 32743954 overall: 103787420 Data size: 1606273&lt;br/&gt;
12561 (receiveResponse) split: 3517940 overall: 83346740 Data size: 4&lt;br/&gt;
12136 (receiveResponse) split: 64448701 overall: 203872573 Data size: 3570569&lt;/p&gt;

&lt;p&gt;The first number is the internal counter for keeping requests unique from HTable on down.  The numbers are in ns, the data size is in bytes.&lt;/p&gt;

&lt;p&gt;Doing some simple calculations, we see for the first line we were reading at about 31 MB/sec.  The second one is even worse.  Other calls are like:&lt;/p&gt;

&lt;p&gt;26 (receiveResponse) split: 7985400 overall: 21546226 Data size: 850429&lt;/p&gt;

&lt;p&gt;which is 107 MB/sec which is pretty close to the maximum of gige.  In my set up, the ycsb client ran on the master node and HAD to use network to talk to regionservers.&lt;/p&gt;

&lt;p&gt;Even at full line rate, we could still see unacceptable hold ups of unrelated calls that just happen to need to talk to the same regionserver.&lt;/p&gt;

&lt;p&gt;This issue is about these findings, what to do, how to improve. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12493811">HBASE-3382</key>
            <summary>Make HBase client work better under concurrent clients</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="7">Later</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ryanobjc">ryan rawson</reporter>
                        <labels>
                            <label>delete</label>
                    </labels>
                <created>Tue, 21 Dec 2010 22:29:45 +0000</created>
                <updated>Tue, 6 Jan 2015 16:53:52 +0000</updated>
                            <resolved>Tue, 6 Jan 2015 16:53:52 +0000</resolved>
                                                                    <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="12973948" author="ryanobjc" created="Tue, 21 Dec 2010 22:37:40 +0000"  >&lt;p&gt;There are a number of issues going on here, and several solutions for them:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;During scans we need at least 3 RPCs just to do work.  If a lighter weight RPC (eg: scanner.close) gets stuck behind a big response that will increase the latency.&lt;/li&gt;
	&lt;li&gt;The reads from the network seem really slow. Ping time is .1 ms (100 microsec!).  I tried to set a 256k send/recv buffer on both sides but that was ineffective.&lt;/li&gt;
	&lt;li&gt;Even at the theoretical maximum 110-120MB/sec gige speed, we would have to wait 41 ms to receive 5 MB in the best case.  Without chunking and interleaving of responses we will be held up behind the big responses.&lt;/li&gt;
	&lt;li&gt;We are using old io, its possible the new io APIs are more efficient at reading chunks of data.  I am not sure though, and it&apos;s hard to find info about this online.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So there are a few avenues to investigate:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;reduction of RPC calls for scans&lt;/li&gt;
	&lt;li&gt;nio instead of oio for better efficiency of reads&lt;/li&gt;
	&lt;li&gt;some way of interleaving responses, either via multiple sockets or chunking on the wire to interleave responses.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12984571" author="ryanobjc" created="Fri, 21 Jan 2011 05:21:35 +0000"  >&lt;p&gt;I did some work to minimally rewrite the HBase client to use nio instead of oio, no actual architectural changes, just changes to see if we can&apos;t improve the performance of straight line reading of bytes off the network socket.&lt;/p&gt;

&lt;p&gt;I used the aforemetioned tracing system to get time for receiving the response, then used the data log to come up with a few different timings, here are the semi-raw data:&lt;/p&gt;


&lt;p&gt;nio:&lt;/p&gt;

&lt;p&gt;hadoop@sv4borg235:/homes/hadoop/borg221/hbase$ grep receiveResponse prof_1.txt | perl -n -e &apos; /split: (\d+?) .*size: (\d+)/ ; if ($2 &amp;gt; 100)&lt;/p&gt;
{ print ((int((1000000000/$1)*$2))/(1024*1024)); print &quot; $2 \n&quot;; }&apos; | sort -n | cut -f1 -d&apos; &apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END {print $sum/$count, &quot;\n&quot;}&apos;&lt;br/&gt;
124.836689844131&lt;br/&gt;
&lt;br/&gt;
hadoop@sv4borg235:/homes/hadoop/borg221/hbase$ grep receiveResponse prof_10.txt | perl -n -e &apos; /split: (\d+?) .*size: (\d+)/ ; if ($2 &amp;gt; 100){ print ((int((1000000000/$1)*$2))/(1024*1024)); print &quot; $2 n&quot;; }
&lt;p&gt;&apos; | sort -n | cut -f1 -d&apos; &apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END &lt;/p&gt;
{print $sum/$count, &quot;\n&quot;}&apos;&lt;br/&gt;
112.391825942993&lt;br/&gt;
&lt;br/&gt;
OIO:&lt;br/&gt;
&lt;br/&gt;
hadoop@sv4borg235:/homes/hadoop/borg221/hbase$ grep receiveResponse new_1thr.txt | perl -n -e &apos; /split: (\d+?) .*size: (\d+)/ ; if ($2 &amp;gt; 100){ print ((int((1000000000/$1)*$2))/(1024*1024)); print &quot; $2 \n&quot;; }&apos; | sort -n | cut -f1 -d&apos; &apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END {print $sum/$count, &quot;n&quot;}
&lt;p&gt;&apos;&lt;br/&gt;
135.158706989288&lt;/p&gt;

&lt;p&gt;hadoop@sv4borg235:/homes/hadoop/borg221/hbase$ grep receiveResponse new_10thr.txt | perl -n -e &apos; /split: (\d+?) .*size: (\d+)/ ; if ($2 &amp;gt; 100)&lt;/p&gt;
{ print ((int((1000000000/$1)*$2))/(1024*1024)); print &quot; $2 \n&quot;; }
&lt;p&gt;&apos; | sort -n | cut -f1 -d&apos; &apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END &lt;/p&gt;
{print $sum/$count, &quot;\n&quot;}
&lt;p&gt;&apos;&lt;br/&gt;
120.16641916275&lt;/p&gt;


&lt;p&gt;As you can see, the OIO client actually performed a bit better than the NIO client, under the same YCSB config (which is listed above), cached workload, etc.  This is probably due to needing to cycle thru a select() call to wait for more data, rather than just letting the OS handle it. &lt;/p&gt;</comment>
                            <comment id="12984572" author="ryanobjc" created="Fri, 21 Jan 2011 05:22:39 +0000"  >&lt;p&gt;a non-async, but nio port of hbase client.&lt;/p&gt;</comment>
                            <comment id="12984576" author="ryanobjc" created="Fri, 21 Jan 2011 05:34:30 +0000"  >&lt;p&gt;So it&apos;s pretty clear that to improve performance under load, we should be using multiple sockets.&lt;/p&gt;

&lt;p&gt;Here is a rough block diagram of how the client works:&lt;/p&gt;

&lt;p&gt;HTable  &amp;#8211; calls --&amp;gt;  HConnectionImplementation &amp;#8211; calls --&amp;gt; HBaseRPC.waitForProxy()&lt;/p&gt;

&lt;p&gt;In waitForProxy, a HBaseClient object is grabbed and associated with the proxy via the embedded Invoker object.  Let&apos;s call this &apos;client&apos; (as does the code)&lt;/p&gt;

&lt;p&gt;HCI  &amp;#8211; calls -&amp;gt; ProxyObject  (anonymous) --&amp;gt;client.call()&lt;/p&gt;


&lt;p&gt;Now a few notes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The HCI will reuse the same proxy object a few times, if not a LOT of times.&lt;/li&gt;
	&lt;li&gt;The proxy object has 1 reference to 1 HBaseClient object.&lt;/li&gt;
	&lt;li&gt;The HBaseClient object has 1 socket/connection per Regionserver.  Multiple threads will interleave their requests &amp;amp; replies (in any order, out of order replies ok) on the 1 socket.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;So there are a few different approaches, in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2939&quot; title=&quot;Allow Client-Side Connection Pooling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2939&quot;&gt;&lt;del&gt;HBASE-2939&lt;/del&gt;&lt;/a&gt; a patch allows for every new call to grab a different connection off the pool, with different pool types.  This has the disadvantage of needing 1 thread per extra socket to a RS.  Another solution is to change the Connection object &amp;amp; thread to do async on multiple sockets to allow 1 thread per regionserver, but multiple sockets under it all.&lt;/p&gt;

&lt;p&gt;another solution is to use a nio framework to implement this instead of doing raw nio programming. &lt;/p&gt;</comment>
                            <comment id="12987076" author="stack" created="Wed, 26 Jan 2011 16:07:40 +0000"  >&lt;p&gt;Can you explain this line more @Ryan:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
11726 (receiveResponse) split: 64991689 overall: 133562895 Data size: 4288937
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What the numbers mean?  I&quot;m being a bit thick.&lt;/p&gt;</comment>
                            <comment id="12987078" author="stack" created="Wed, 26 Jan 2011 16:14:37 +0000"  >&lt;p&gt;Can you get Karthiks patch over in hbase-2939 working to show improved throughput if multiple sockets?  Any way of &apos;proving&apos; contention on the single socket?  If bandwidth is full, will multiple sockets make any difference?&lt;/p&gt;</comment>
                            <comment id="12987883" author="ryanobjc" created="Fri, 28 Jan 2011 02:04:49 +0000"  >&lt;p&gt;Doing more testing with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2939&quot; title=&quot;Allow Client-Side Connection Pooling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2939&quot;&gt;&lt;del&gt;HBASE-2939&lt;/del&gt;&lt;/a&gt; I ran some tests using YCSB, it was very confusing at first because I wasnt getting the performance boost I was hoping for.&lt;/p&gt;

&lt;p&gt;So with a configuration that does scan only load, I am seeing a base line performance of about 50-60ms for 1 thread.  Upping this to 10 threads the performance gets much worse, up to 400ms or so.  Doing some custom tracing in our client code it revealed that the source of the slowness was waiting for other responses to be streamed to the client.  That is thread1 asks for a big fat reply, but it takes 100ms to read off the wire, thread2 which did a little-itty-bitty request (close scanner for example), must wait or that 100ms thus being unnecessarily slowed down.  &lt;/p&gt;

&lt;p&gt;So I tried this patch with ThreadLocal, and while I see improvement I am not seeing enough improvement, with lines like this:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;, AverageLatency(ms), 363.44&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;, AverageLatency(ms), 448.31&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;SCAN&amp;#93;&lt;/span&gt;, AverageLatency(ms), 426.53&lt;/p&gt;

&lt;p&gt;The data size is small enough and fully cached, and I added logging that verifies that we are CREATING multiple connections (1 per thread it seems).&lt;/p&gt;

&lt;p&gt;But the &quot;call_wait&quot; profile time (the time spent between sending the request and when the connection code starts to receive our response) is pretty high, in previous tests I saw something like this;&lt;br/&gt;
cat new_1thr.txt | perl -ne &apos;if(/call_wait&amp;#41; split: (\d+?) /) &lt;/p&gt;
{ print $1/1000000, &quot;\n&quot;;}&apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END {print $sum/$count, &quot;\n&quot;}&apos;&lt;br/&gt;
3.86964071428571&lt;br/&gt;
cat new_10thr.txt | perl -ne &apos;if(/call_wait&amp;#41; split: (\d+?) /) { print $1/1000000, &quot;n&quot;;}
&lt;p&gt;&apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END &lt;/p&gt;
{print $sum/$count, &quot;\n&quot;}&apos;&lt;br/&gt;
56.1530285016722&lt;br/&gt;
&lt;br/&gt;
As you can see going from an average wait time of 3ms to an average wait time of 56ms is pretty hurting!&lt;br/&gt;
&lt;br/&gt;
But using the work to add ThreadLocal connections I did not get as much boost as I hoped for, instead I saw call_wait time like:&lt;br/&gt;
&lt;br/&gt;
cat 10_thr.txt| perl -ne &apos;if(/call_wait&amp;#41; split: (\d+?) /) { print $1/1000000, &quot;\n&quot;;}&apos; | perl -ne &apos;$sum &lt;ins&gt;= $_; $count&lt;/ins&gt;+; END {print $sum/$count, &quot;n&quot;}
&lt;p&gt;&apos; &lt;br/&gt;
19.9225164798658&lt;/p&gt;

&lt;p&gt;while 19ms &amp;lt; 56ms that is still a lot of ms of wait.&lt;/p&gt;

&lt;p&gt;At this point we might be also seeing server side slowness.  I think the next step is to extend the NanoProfiler code into the server side so we can have extensive tracing between both the server and client. &lt;/p&gt;

&lt;p&gt;This result suggests we are seeing server-side slowness under concurrency, which is reasonable, but I wasn&apos;t seeing in previous profiler runs, but a lot of performance code has been committed in the mean time.&lt;/p&gt;

</comment>
                            <comment id="14266313" author="clehene" created="Tue, 6 Jan 2015 16:08:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ryanobjc&quot; class=&quot;user-hover&quot; rel=&quot;ryanobjc&quot;&gt;ryan rawson&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; this is an improvement,  can this be closed/transformed in a set of updated issues if still the case?&lt;/p&gt;</comment>
                            <comment id="14266383" author="apurtell" created="Tue, 6 Jan 2015 16:53:52 +0000"  >&lt;p&gt;I&apos;d argue the old YCSB client code was poor both in terms of YCSB&apos;s objective and server loading management (stampeding via multiple threads flushing deep write buffers). We should redo the analysis using LoadTestTool or the new YCSB client at &lt;a href=&quot;https://github.com/apurtell/ycsb/tree/new_hbase_client&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apurtell/ycsb/tree/new_hbase_client&lt;/a&gt;. Resolving as Later. Can reopen if someone wants to take it up. I&apos;m guessing probably that won&apos;t happen.&lt;/p&gt;

&lt;p&gt;Thanks for the nudge &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=clehene&quot; class=&quot;user-hover&quot; rel=&quot;clehene&quot;&gt;Cosmin Lehene&lt;/a&gt;. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12498300">HBASE-3523</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12468948" name="HBASE-3382-nio.txt" size="13957" author="ryanobjc" created="Fri, 21 Jan 2011 05:22:39 +0000"/>
                            <attachment id="12466769" name="HBASE-3382.txt" size="26366" author="ryanobjc" created="Tue, 21 Dec 2010 22:30:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Jan 2011 16:07:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26822</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 49 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02c87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11582</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>