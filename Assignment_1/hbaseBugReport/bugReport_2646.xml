<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:03:36 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2646/HBASE-2646.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2646] Compaction requests should be prioritized to prevent blocking</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2646</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;While testing the write capacity of a 4 machine hbase cluster we were getting long and frequent client pauses as we attempted to load the data.  Looking into the problem we&apos;d get a relatively large compaction queue and when a region hit the &quot;hbase.hstore.blockingStoreFiles&quot; limit it would get block the client and the compaction request would get put on the back of the queue waiting for many other less important compactions.  The client is basically stuck at that point until a compaction is done.  Prioritizing the compaction requests and allowing the request that is blocking other actions go first would help solve the problem.&lt;/p&gt;

&lt;p&gt;You can see the problem by looking at our log files:&lt;/p&gt;

&lt;p&gt;You&apos;ll first see an event such as a too many HLog which will put a lot of requests on the compaction queue.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2010-05-25 10:53:26,570 INFO org.apache.hadoop.hbase.regionserver.HLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 22 regions(s): responseCounts,RS_6eZzLtdwhGiTwHy,1274232223324, responses,RS_0qhkL5rUmPCbx3K-1274213057242,1274513189592, responses,RS_1ANYnTegjzVIsHW-12742177419
21,1274511001873, responses,RS_1HQ4UG5BdOlAyuE-1274216757425,1274726323747, responses,RS_1Y7SbqSTsZrYe7a-1274328697838,1274478031930, responses,RS_1ZH5TB5OdW4BVLm-1274216239894,1274538267659, responses,RS_3BHc4KyoM3q72Yc-1274290546987,1274502062319, responses,RS_3ra9BaBMAXFAvbK-127421457
9958,1274381552543, responses,RS_6SDrGNuyyLd3oR6-1274219941155,1274385453586, responses,RS_8AGCEMWbI6mZuoQ-1274306857429,1274319602718, responses,RS_8C8T9DN47uwTG1S-1274215381765,1274289112817, responses,RS_8J5wmdmKmJXzK6g-1274299593861,1274494738952, responses,RS_8e5Sz0HeFPAdb6c-1274288
641459,1274495868557, responses,RS_8rjcnmBXPKzI896-1274306981684,1274403047940, responses,RS_9FS3VedcyrF0KX2-1274245971331,1274754745013, responses,RS_9oZgPtxO31npv3C-1274214027769,1274396489756, responses,RS_a3FdO2jhqWuy37C-1274209228660,1274399508186, responses,RS_a3LJVxwTj29MHVa-12742
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then you see the too many log files:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2010-05-25 10:53:31,364 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region responses-index,--1274799047787--R_cBKrGxx0FdWjPso,1274804575862/783020138 because: regionserver/192.168.0.81:60020.cacheFlusher
2010-05-25 10:53:32,364 WARN org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Region responses-index,--1274799047787--R_cBKrGxx0FdWjPso,1274804575862 has too many store files, putting it back at the end of the flush queue.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which leads to this: &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2010-05-25 10:53:27,061 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &apos;IPC Server handler 60 on 60020&apos; on region responses-index,--1274799047787--R_cBKrGxx0FdWjPso,1274804575862: memstore size 128.0m is &amp;gt;= than blocking 128.0m size
2010-05-25 10:53:27,061 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &apos;IPC Server handler 84 on 60020&apos; on region responses-index,--1274799047787--R_cBKrGxx0FdWjPso,1274804575862: memstore size 128.0m is &amp;gt;= than blocking 128.0m size
2010-05-25 10:53:27,065 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &apos;IPC Server handler 1 on 60020&apos; on region responses-index,--1274799047787--R_cBKrGxx0FdWjPso,1274804575862: memstore size 128.0m is &amp;gt;= than blocking 128.0m size
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;p&gt;Once the compaction / split is done a flush is able to happen which unblocks the IPC allowing writes to continue.  Unfortunately this process can take upwards of 15+ minutes (the specific case shown here from our logs took about 4 minutes).&lt;/p&gt;</description>
                <environment>&lt;p&gt;ubuntu server 10; hbase 0.20.4; 4 machine cluster (each machine is an 8 core xeon with 16 GB of ram and 6TB of storage); ~250 Million rows;&lt;/p&gt;</environment>
        <key id="12465893">HBASE-2646</key>
            <summary>Compaction requests should be prioritized to prevent blocking</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="whitingj">Jeff Whiting</assignee>
                                    <reporter username="whitingj">Jeff Whiting</reporter>
                        <labels>
                            <label>compaction</label>
                            <label>split</label>
                    </labels>
                <created>Tue, 1 Jun 2010 18:43:20 +0000</created>
                <updated>Fri, 20 Nov 2015 12:43:34 +0000</updated>
                            <resolved>Fri, 6 May 2011 17:03:36 +0000</resolved>
                                    <version>0.20.4</version>
                                    <fixVersion>0.90.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12874149" author="whitingj" created="Tue, 1 Jun 2010 18:48:57 +0000"  >&lt;p&gt;We were able to mitigate our problem somewhat by changing the following configuration parameters:&lt;/p&gt;

&lt;p&gt;hbase.hregion.memstore.block.multiplier =&amp;gt; 3&lt;br/&gt;
hbase.hstore.blockingStoreFiles =&amp;gt; 28&lt;br/&gt;
hbase.hstore.compactionThreshold =&amp;gt; 7&lt;/p&gt;

&lt;p&gt;Unfortunately this just puts off compaction and may make it last a lot longer.  I&apos;ve already begun developing a PriorityCompactionQueue to see if that could be a solution. &lt;/p&gt;</comment>
                            <comment id="12874156" author="streamy" created="Tue, 1 Jun 2010 18:56:37 +0000"  >&lt;p&gt;Hey Jeff.  Prioritized compactions and a bunch of other really good compaction/split improvements are on the way for the next major hbase release.&lt;/p&gt;

&lt;p&gt;The work started in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2375&quot; title=&quot;Revisit compaction configuration parameters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2375&quot;&gt;&lt;del&gt;HBASE-2375&lt;/del&gt;&lt;/a&gt; but a remaining bug in the patch from that issue has led to a larger refactoring.&lt;/p&gt;</comment>
                            <comment id="12874172" author="whitingj" created="Tue, 1 Jun 2010 19:23:24 +0000"  >&lt;p&gt;Here is my first go at a patch to prioritize compaction requests.  Right now there are 3 levels that a request can take, LOW, NORMAL, HIGH_BLOCKING.  Right now the only request that has a HIGH_BLOCKING priority is when the memstore cannot do a flush because it has too many hstore files.  All other requests are NORMAL.  LOW currently is unused.  &lt;/p&gt;

&lt;p&gt;One thing I really like about the patch it that it abstracts everything about the queue.  CompactSplitThread no longer has to maintain both the queue and the hashset as all of that is now handled by the PriorityCompactionQueue.  It now only has to put on and take off the regions and that is it.&lt;/p&gt;

&lt;p&gt;PriorityCompactionQueue basically has 2 modes of operation.  The default mode is to always give the higher priority compaction requests precedence.  The only downside to this is it could lead to starvation of lower priority requests (although if there is more important work to be done shouldn&apos;t just be doing that?).  The second mode prevents the starvation by allowing a request to raise its priority after it has been in the queue for a specified amount of time.  For example with a 10 second priority elevation time, a LOW priority request would be elevated to a NORMAL priority request after 10 seconds.  This parameter can be tuned with the hbase.regionserver.thread.priorityElevationTime configuration parameter (a value of -1 means it uses the first mode).&lt;/p&gt;

&lt;p&gt;The patch is against the 0.20.4 tag and I&apos;ve included two new files PriorityCompactionQueue.java and TestPriorityCompactionQueue.java.  Those two files are thew new compaction queue and a unit test for it.  In addition I made all the necessary changes to the CompactSplitThread and MemStoreFlusher.  &lt;/p&gt;

&lt;p&gt;We&apos;ve tested this patch in our environment with great results.  We were able to lower our parameters to the following with no client pauses:&lt;/p&gt;

&lt;p&gt;hbase.hregion.memstore.block.multiplier =&amp;gt; 2&lt;br/&gt;
hbase.hstore.blockingStoreFiles =&amp;gt; 2&lt;br/&gt;
hbase.hstore.compactionThreshold =&amp;gt; 4&lt;/p&gt;</comment>
                            <comment id="12874180" author="whitingj" created="Tue, 1 Jun 2010 19:31:36 +0000"  >&lt;p&gt;That is great news to hear about optimizations being made on the compaction queue.  Looking at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2375&quot; title=&quot;Revisit compaction configuration parameters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2375&quot;&gt;&lt;del&gt;HBASE-2375&lt;/del&gt;&lt;/a&gt; I see a lot of improvement in how the compaction is being done and being more intelligent on when to compact and split but I don&apos;t seem to see any prioritization of the compaction requests (I may be overlooking it).  Maybe some of the improvements in the patch here would integrate nicely with what is already being done? It seems that whenever the an action is blocking on a compaction that the request should take precedence.  But that is just my two cents.&lt;/p&gt;</comment>
                            <comment id="12874238" author="streamy" created="Tue, 1 Jun 2010 21:06:31 +0000"  >&lt;p&gt;This looks good and is very similar to the design I was going with.  The patches up in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2375&quot; title=&quot;Revisit compaction configuration parameters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2375&quot;&gt;&lt;del&gt;HBASE-2375&lt;/del&gt;&lt;/a&gt; don&apos;t do prioritized queues but that was part of the redesign that I am currently working on that grew out of that jira.  There is a new prioritized executor service that will be going in as part of the master rewrite in trunk that I was planning on using for this.&lt;/p&gt;

&lt;p&gt;My implementation does not have a LOW priority, I&apos;m not sure where that would make sense.&lt;/p&gt;

&lt;p&gt;And for preventing starvation, I would agree with your question that this doesn&apos;t actually make sense, though a cool feature that might make sense in a different context.  Any request for a high priority compaction is assumed to be under the premise that it is the most important thing to happen.  The desired behavior would be to complete it before allowing any lower priority compactions to complete?  If a system is starved for resources, we would still prefer to allow high priority compactions to complete before allowing any low priority?  With a poorly set elevation time you would end up with everything in one priority defeating the purpose.&lt;/p&gt;

&lt;p&gt;This is too big of a chance for the 0.20 line but definitely something we should do in trunk.  Can we put this jira on hold for another week or two when I get back to working on compaction improvements?  I&apos;d like to get some of the new master changes in before rebasing this on trunk.&lt;/p&gt;

&lt;p&gt;Thanks for all the work, this looks great.&lt;/p&gt;</comment>
                            <comment id="12874255" author="whitingj" created="Tue, 1 Jun 2010 21:42:01 +0000"  >&lt;p&gt;Your plan sounds good.  There is a lot going on with the master rewrite and a lot of variables up in the air so it seems good to push this out to 0.21.  Although I plan to to keep using in my environment &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I agree that in a situation where there isn&apos;t enough resources we should just focus on high priority items and not worry about starvation of low priority items.  I also agree that the priorityElevationTime would be a tricky parameter to mess with and could make the priority queue worthless.  Besides if a low priority item somehow becomes critical it will naturally be re-requested with a higher priority.  As far as the LOW priority I&apos;m don&apos;t really know when that would be used.  I included it to provide a more complete implementation thinking that someone else might have a good reason to use it.  &lt;/p&gt;

&lt;p&gt;Here is a random thought on when a low priority compaction would make sense.  Lets say a the region just barely went above &quot;hbase.hstore.compactionThreshold&quot; (t) but was still a long ways off from &quot;hbase.hstore.blockingStoreFiles&quot; (b) so it would request a compaction but of low priority.  But once it got halfway between compactionThreshold and blockingStoreFiles, (b+t) / 2, it would then re-request the compaction but at a normal priority.  I&apos;m not really sure how beneficial this would be but it the only thing coming to mind as to why you&apos;d use a low priority.&lt;/p&gt;</comment>
                            <comment id="12874271" author="streamy" created="Tue, 1 Jun 2010 22:03:53 +0000"  >&lt;p&gt;I think doing something that complex is asking for trouble &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  In most cases, you&apos;ll want things that are not high priority to be processed in the order they were submitted.  Assuming random distribution of writes, I think you would most often end up with the same ordering of compactions w/ or w/o the low priority.&lt;/p&gt;

&lt;p&gt;In reality, you&apos;re either not saturating IO, in which case none of this is really necessary (though generally you&apos;d want high/low priority so if somehow anything blocking did happen it would go first).  Or you&apos;re saturated and your compaction queue is building.  In this case you want to process anything high priority (blocking) before you do anything low priority (maintenance).  I think everything we do falls into one of the those buckets.  If something goes into low pri queue when it hits threshold, you expect it to move up in that queue as time goes one, thereby naturally moving up when it will happen.  There are no free lunches so making it a medium priority instead of low will not give you any new IO.  You still generally want high pri first, then low pri in order of submission.&lt;/p&gt;

&lt;p&gt;I do think it could make sense in other use cases just think this is a bit too complex for compactions.&lt;/p&gt;

&lt;p&gt;Also, I&apos;m planning on extending the same prio queue idea to flushes.  The other part of the change is to allow concurrent compactions and flushes.&lt;/p&gt;</comment>
                            <comment id="12874283" author="whitingj" created="Tue, 1 Jun 2010 22:27:26 +0000"  >&lt;p&gt;I agree that for compactions having more than 2 priorities is overkill and is bound to have problems.  In the general case having a low priority for a priority queue would make sense.  I&apos;m glad to hear about the concurrent compaction and flushes as that would be a huge improvement.  &lt;/p&gt;

&lt;p&gt;Also has there been any talk of multiple compaction threads per region server?  That way multiple regions could be compacted in parallel.  You&apos;d have to move the compaction queue to a more global location and have all the threads pull from one source.  On lower end machines running compactions in parallel may not make sense.  But for higher end machines it seems like it could pay dividends.  Looking at my cluster (8 core xeons, 16gb ram, jbod 3 x 2TB) we almost always have some resources available to do parallel compactions.  &lt;/p&gt;</comment>
                            <comment id="12874288" author="streamy" created="Tue, 1 Jun 2010 22:49:11 +0000"  >&lt;p&gt;That is what I am referring to by concurrent compactions and flushes.  I didn&apos;t mean compactions concurrent with flushes, I meant multiple compactions and flushes running concurrently.&lt;/p&gt;

&lt;p&gt;Reasoning is exactly as you describe.  There are some clusters being built with 4, 8, even 12 disks per node.  This would be configurable and single disk nodes would probably have it set to 1.&lt;/p&gt;</comment>
                            <comment id="12880341" author="stack" created="Fri, 18 Jun 2010 22:00:02 +0000"  >&lt;p&gt;This is a nice looking patch (just looked at it).  Tempted to put it into 0.20.5 but its too risky a change.&lt;/p&gt;</comment>
                            <comment id="12908089" author="tlipcon" created="Fri, 10 Sep 2010 16:55:26 +0000"  >&lt;p&gt;Hey Jeff. Thanks for pointing to this issue on the list. Any chance you&apos;d be willing to update it to trunk like you suggested?&lt;/p&gt;

&lt;p&gt;I agree that we&apos;re better with this than nothing, while we wait on Jonathan&apos;s fancier patch. (unless you&apos;re pretty much done, jgray?)&lt;/p&gt;</comment>
                            <comment id="12908970" author="whitingj" created="Mon, 13 Sep 2010 19:55:37 +0000"  >&lt;p&gt;A patch for this fix against trunk at revision 9966644.&lt;/p&gt;</comment>
                            <comment id="12908972" author="whitingj" created="Mon, 13 Sep 2010 19:59:44 +0000"  >&lt;p&gt;I&apos;m not sure how long we&apos;ll actually need the code before the concurrent compaction refactor goes in, but here it is.  I think it is a solid improvement that would only be superseded by concurrent priority compactions.  &lt;/p&gt;

&lt;p&gt;As per the discussion in this jira I&apos;ve removed the priorityElevationTime feature and simplified the code.&lt;/p&gt;</comment>
                            <comment id="12909121" author="apurtell" created="Tue, 14 Sep 2010 05:56:47 +0000"  >&lt;p&gt;Target for branch 0.20 also.&lt;/p&gt;</comment>
                            <comment id="12915547" author="stack" created="Mon, 27 Sep 2010 23:42:56 +0000"  >&lt;p&gt;Something wrong w/ original patch and it was a little unorthodox anyways...Making it apply to TRUNK.  Not done yet.  Want to make the test junit4 too.......&lt;/p&gt;</comment>
                            <comment id="12915548" author="stack" created="Mon, 27 Sep 2010 23:43:17 +0000"  >&lt;p&gt;Oh, sorry, yeah, I&apos;m trying to patch this in.   It looks great.&lt;/p&gt;</comment>
                            <comment id="12915617" author="stack" created="Tue, 28 Sep 2010 05:25:24 +0000"  >&lt;p&gt;Here&apos;s what I&apos;m applying.  Its formatting and change of test from junit3 to junit4 (Nice test Jeff).&lt;/p&gt;</comment>
                            <comment id="12915620" author="stack" created="Tue, 28 Sep 2010 05:29:02 +0000"  >&lt;p&gt;Committed to TRUNK.  Leaving issue open in case we do a 0.20.7; if we do we can commit it there too.&lt;/p&gt;

&lt;p&gt;Thanks for the patch Jeff and thanks for your patience w/ our slow application of it.&lt;/p&gt;</comment>
                            <comment id="12915921" author="streamy" created="Tue, 28 Sep 2010 20:54:34 +0000"  >&lt;p&gt;FYI v3 patch is not complete (contains &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3038&quot; title=&quot;WALReaderFSDataInputStream.getPos() fails if Filesize &amp;gt; MAX_INT&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3038&quot;&gt;&lt;del&gt;HBASE-3038&lt;/del&gt;&lt;/a&gt; and does not contain the two new files)&lt;/p&gt;</comment>
                            <comment id="12915952" author="ted_yu" created="Tue, 28 Sep 2010 22:40:29 +0000"  >&lt;p&gt;Summarizing discussion with Jeff:&lt;br/&gt;
Ted: In PriorityCompactionQueue.addToRegionsInQueue(), I noticed the following call which is not synchronized:&lt;br/&gt;
      queue.remove(queuedRequest);&lt;/p&gt;

&lt;p&gt;Now suppose before the above is executed, PriorityCompactionQueue.take() is called. So queuedRequest is returned to the caller of take(). Later, this line in take():&lt;br/&gt;
removeFromRegionsInQueue(cr.getHRegion());&lt;br/&gt;
would remove the newly added, higher priority request from regionsInQueue.&lt;/p&gt;

&lt;p&gt;Jeff:&lt;br/&gt;
That is an astute observation.  Stepping through the code with the threads stopping execution at the points in code you suggest would indeed make it so take() would return the lower priority compactionRequest, remove the higher priority compaction request from regionsInQueue, and finally the add() method would complete and add the higher priority compaction onto the queue with no corresponding entry in the regionsInQueue hash (this is bad).  Even if I move the queue.remove(queuedRequest) into the synchronized(regionsInQueue) we will run into the same problem.  &lt;/p&gt;

&lt;p&gt;Fortunately the worst thing that can happen is there is a request that doesn&apos;t have an entry in regionsInQueue that will eventually be executed with no adverse problem for the system other than extra work.  This wont actually cause any problems to the system but PriorityCompactionQueue will have an inconsistent state which should be fixed.  An immediate solution is not jumping out at me.  So I need to think through the problem and see if I can&apos;t come up with a way to prevent the inconsistency.&lt;/p&gt;

&lt;p&gt;Ted:&lt;br/&gt;
Except for remove(Object r), all callers of removeFromRegionsInQueue() have CompactionRequest information.&lt;br/&gt;
So CompactionRequest, cr, can be passed to removeFromRegionsInQueue() so that we can perform some sanity check.&lt;br/&gt;
If cr.getPriority() is lower than the priority of the CompactionRequest currently in regionsInQueue, removeFromRegionsInQueue() can return null which indicates inconsistency.&lt;br/&gt;
The caller can discard cr upon seeing null from removeFromRegionsInQueue() and try to get the next request from queue.&lt;/p&gt;

&lt;p&gt;The above avoids introducing another synchronization between accesses to queue and regionsInQueue.&lt;/p&gt;

&lt;p&gt;Jeff:&lt;br/&gt;
I was thinking along the same lines.  Adding an additional synchronization didn&apos;t seem like the right approach.  So if we make sure we are taking off what we are expecting to then there wont be a problem.&lt;/p&gt;</comment>
                            <comment id="12915975" author="stack" created="Tue, 28 Sep 2010 23:59:45 +0000"  >&lt;p&gt;On commit, I&apos;d added missing files and then afterward backed out hbase-3038.&lt;/p&gt;</comment>
                            <comment id="12917693" author="whitingj" created="Mon, 4 Oct 2010 18:39:04 +0000"  >&lt;p&gt;As per my discussion with Ted Yu, here is a patch that addresses the potential race condition with queue.remove(queuedRequest).  It does a sanity check to make sure that what I&apos;m removing from regionsInQueue is what I expect otherwise I leave it on.  The patch views this.queue as the authoritative source on the which requests to run and will always return whatever was removed from the queue.  &lt;/p&gt;</comment>
                            <comment id="12917695" author="whitingj" created="Mon, 4 Oct 2010 18:41:10 +0000"  >&lt;p&gt;Incorrectly named the attachment.&lt;/p&gt;</comment>
                            <comment id="12917722" author="stack" created="Mon, 4 Oct 2010 19:26:34 +0000"  >&lt;p&gt;Thank you Jeff.  I applied your patch.  Best to get it in now before we start in on 0.90 stabilizations.  Thanks for persistting (And Ted for review).&lt;/p&gt;</comment>
                            <comment id="13008021" author="otis" created="Thu, 17 Mar 2011 17:30:27 +0000"  >&lt;p&gt;Should Fix Version/s be set for this one, so it doesn&apos;t get missed?  Looks important and ready with a patch. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13008039" author="yuzhihong@gmail.com" created="Thu, 17 Mar 2011 17:58:53 +0000"  >&lt;p&gt;This has been integrated - PriorityCompactionQueue is used by CompactSplitThread now.&lt;/p&gt;</comment>
                            <comment id="13030022" author="stack" created="Fri, 6 May 2011 17:03:36 +0000"  >&lt;p&gt;This was applied a while back.  Resolving.  Thanks for the patch Jeff (Assigned it to you).&lt;/p&gt;</comment>
                            <comment id="15017560" author="lars_francke" created="Fri, 20 Nov 2015 12:43:34 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12469138">HBASE-2832</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12478482">HBASE-3160</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12460243">HBASE-2375</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12473830">HBASE-2981</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12456304" name="2646-fix-race-condition-r1004349.txt" size="4245" author="whitingj" created="Mon, 4 Oct 2010 18:41:10 +0000"/>
                            <attachment id="12455780" name="2646-v2.txt" size="35385" author="stack" created="Mon, 27 Sep 2010 23:42:56 +0000"/>
                            <attachment id="12455798" name="2646-v3.txt" size="8730" author="stack" created="Tue, 28 Sep 2010 05:25:24 +0000"/>
                            <attachment id="12454478" name="PriorityQueue-r996664.patch" size="24392" author="whitingj" created="Mon, 13 Sep 2010 19:55:36 +0000"/>
                            <attachment id="12446048" name="prioritycompactionqueue-0.20.4.patch" size="27388" author="whitingj" created="Tue, 1 Jun 2010 19:23:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 1 Jun 2010 18:56:37 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32693</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hil3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100273</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>