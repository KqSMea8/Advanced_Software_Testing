<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:28:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5564/HBASE-5564.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5564] Bulkload is discarding duplicate records</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5564</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Duplicate records are getting discarded when duplicate records exists in same input file and more specifically if they exists in same split.&lt;br/&gt;
Duplicate records are considered if the records are from diffrent different splits.&lt;/p&gt;

&lt;p&gt;Version under test: HBase 0.92&lt;/p&gt;</description>
                <environment>&lt;p&gt;HBase 0.92&lt;/p&gt;</environment>
        <key id="12546108">HBASE-5564</key>
            <summary>Bulkload is discarding duplicate records</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lakshman">Laxman</assignee>
                                    <reporter username="lakshman">Laxman</reporter>
                        <labels>
                            <label>bulkloader</label>
                    </labels>
                <created>Mon, 12 Mar 2012 15:15:00 +0000</created>
                <updated>Mon, 23 Sep 2013 18:30:37 +0000</updated>
                            <resolved>Fri, 15 Jun 2012 16:53:08 +0000</resolved>
                                    <version>0.95.2</version>
                                    <fixVersion>0.95.0</fixVersion>
                                    <component>mapreduce</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                <comments>
                            <comment id="13227597" author="lakshman" created="Mon, 12 Mar 2012 15:16:01 +0000"  >&lt;p&gt;I think this is a bug and its not any intentional behavior. &lt;/p&gt;

&lt;p&gt;Usage of TreeSet in the below code snippet is causing the issue.&lt;/p&gt;

&lt;p&gt;PutSortReducer.reduce()&lt;br/&gt;
======================&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      TreeSet&amp;lt;KeyValue&amp;gt; map = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;KeyValue&amp;gt;(KeyValue.COMPARATOR);
      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; curSize = 0;
      &lt;span class=&quot;code-comment&quot;&gt;// stop at the end or the RAM threshold
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (iter.hasNext() &amp;amp;&amp;amp; curSize &amp;lt; threshold) {
        Put p = iter.next();
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (List&amp;lt;KeyValue&amp;gt; kvs : p.getFamilyMap().values()) {
          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (KeyValue kv : kvs) {
            map.add(kv);
            curSize += kv.getLength();
          }
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Changing this back to List and then sort explicitly will solve the issue.&lt;/p&gt;</comment>
                            <comment id="13227678" author="lakshman" created="Mon, 12 Mar 2012 16:51:15 +0000"  >&lt;p&gt;I tested again with the proposed patch.&lt;br/&gt;
&amp;gt; &amp;gt; Changing this back to List and then sort explicitly will solve the issue.&lt;/p&gt;

&lt;p&gt;Still the same problem persists making this issue bit more complicated. &lt;br/&gt;
I think the usage of same timestamp for all records in split causing the issue.&lt;/p&gt;

&lt;p&gt;Currently in code,&lt;br/&gt;
a) If configured, we are using static timestamp for all mappers.&lt;br/&gt;
b) If not configured, we are using current system time generated for each split.&lt;/p&gt;

&lt;p&gt;TsvImporterMapper.doSetup&lt;br/&gt;
====================&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ts = conf.getLong(ImportTsv.TIMESTAMP_CONF_KEY, &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Should we think of an approach to generate a unique sequence number and use it as a timestamp?&lt;/p&gt;

&lt;p&gt;Any other thoughts?&lt;/p&gt;</comment>
                            <comment id="13227696" author="jesse_yates" created="Mon, 12 Mar 2012 17:15:13 +0000"  >&lt;p&gt;Hmm, I think your right with this being a problem. It would be totally reasonable to change &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       KeyValue kv = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(
            lineBytes, parsed.getRowKeyOffset(), parsed.getRowKeyLength(),
            parser.getFamily(i), 0, parser.getFamily(i).length,
            parser.getQualifier(i), 0, parser.getQualifier(i).length,
            ts,
            KeyValue.Type.Put,
            lineBytes, parsed.getColumnOffset(i), parsed.getColumnLength(i));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;to use something like: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ts++&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The question is, if you have a TSV file with the same row key, which value should be considered the most recent version? Should any of them - maybe that is actually a problem and we want to have a warning/error when that occurs?&lt;/p&gt;</comment>
                            <comment id="13227740" author="stack" created="Mon, 12 Mar 2012 18:21:11 +0000"  >&lt;p&gt;The TreeSet is whats going to be used once the edits make it into the server so losing them in the reducer is probably optimal?  The Jesse ts++, or ts--, could be an option?&lt;/p&gt;</comment>
                            <comment id="13227742" author="tlipcon" created="Mon, 12 Mar 2012 18:25:36 +0000"  >&lt;p&gt;I think it&apos;s a feature, not a bug, that the timestamps are all identical. The whole point is that, in a bulk-load-only workflow, you can identify each bulk load exactly, and correlate it to the MR job that inserted it. If you want to use custom timestamps, you should specify a timestamp column in your data, or write your own MR job (ImportTsv is just an example which use useful for some cases, but for anything advanced I would expect users to write their own code)&lt;/p&gt;</comment>
                            <comment id="13227926" author="lhofhansl" created="Mon, 12 Mar 2012 21:27:31 +0000"  >&lt;p&gt;So this is only about ImportTsv? Should change the title in that case.&lt;/p&gt;

&lt;p&gt;I agree with Todd, at least for ImportTsv.&lt;br/&gt;
Import/Export should not (and hopefully do not) exhibit this behavior (since we want to be able to import/export KVs with multiple versions).&lt;/p&gt;</comment>
                            <comment id="13228212" author="lakshman" created="Tue, 13 Mar 2012 05:04:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;ts++, or ts--, could be an option?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ts++ or ts-- will not solve this problem. Reason being each mapper spawns a new JVM and ts will be reset to initial value. so, still there is a chance of ts collision.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;that the timestamps are all identical. The whole point is that, in a bulk-load-only workflow, you can identify each bulk load exactly, and correlate it to the MR job that inserted it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No Todd. At least the implementation is buggy enough and not matching with this expected behavior.&lt;br/&gt;
New timestamp is generated for each map task (i.e., for each split) in TsvImporterMapper.doSetup.&lt;br/&gt;
Please check my previous comments.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So this is only about ImportTsv? Should change the title in that case.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m not aware what other tools comes under bulkload. Bulkload documentation talks only about importtsv.&lt;br/&gt;
&lt;a href=&quot;http://hbase.apache.org/bulk-loads.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/bulk-loads.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But if you feel we should change the title, feel free to modify the title.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If you want to use custom timestamps, you should specify a timestamp column in your data, or write your own MR job (ImportTsv is just an example which use useful for some cases, but for anything advanced I would expect users to write their own code)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think we can provide the provision to specify the timestamp column (Like ROWKEY column) as arguments.&lt;br/&gt;
Example : importtsv.columns=&apos;HBASE_ROW_KEY, HBASE_TS_KEY, emp:name,emp:sal,dept:code&apos;&lt;/p&gt;

&lt;p&gt;This makes importtsv more usable. Otherwise, user has to copy paste entire importtsv code and do this minor modification.&lt;/p&gt;

&lt;p&gt;Please let me know your suggestions on this.&lt;/p&gt;</comment>
                            <comment id="13228219" author="zhihyu@ebaysf.com" created="Tue, 13 Mar 2012 05:16:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think we can provide the provision to specify the timestamp column (Like ROWKEY column) as arguments.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The above is reasonable.&lt;/p&gt;</comment>
                            <comment id="13228221" author="lhofhansl" created="Tue, 13 Mar 2012 05:25:34 +0000"  >&lt;p&gt;@Laxman: so what you have in your CSV file is entries like:&lt;br/&gt;
rowA, colA, val1&lt;br/&gt;
rowA, colA, val2&lt;/p&gt;

&lt;p&gt;And the expectation is that HBase should create two versions:&lt;br/&gt;
(rowA, colA, ts1) -&amp;gt; val1&lt;br/&gt;
(rowA, colA, ts2) -&amp;gt; val2&lt;br/&gt;
?&lt;/p&gt;

&lt;p&gt;Seems like a pretty constructed case to me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
How would know ahead of time how many versions you&apos;d need to configure for your column family? 3 is the default, but what if you have 100 versions of the same row/col combo in your CSV file?&lt;/p&gt;

&lt;p&gt;But anyway, having an option to specify a column for the TS is a good idea.&lt;br/&gt;
Do you want to take a stab at it Laxman?&lt;/p&gt;</comment>
                            <comment id="13228297" author="lakshman" created="Tue, 13 Mar 2012 09:37:38 +0000"  >&lt;p&gt;Scope of this issue.&lt;/p&gt;

&lt;p&gt;1) Avoid the behavioral inconsistency with timestamp parameter.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Currently in code,
a) If timstamp parameter is configured, duplicate records will be overwritten.
b) If not configured, some duplicate records are maintained as different version.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This fix should be inline with the expectation Todd has mentioned.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The whole point is that, in a bulk-load-only workflow, you can identify each bulk load exactly, and correlate it to the MR job that inserted it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;2) Provide an option to look up timestamp column value from input data. (Like ROWKEY column)&lt;br/&gt;
Example : importtsv.columns=&apos;HBASE_ROW_KEY, HBASE_TS_KEY, emp:name,emp:sal,dept:code&apos;&lt;/p&gt;

&lt;p&gt;I will submit the patch with the above mentioned approach.&lt;/p&gt;

&lt;p&gt;Any other addons?&lt;/p&gt;</comment>
                            <comment id="13228406" author="lakshman" created="Tue, 13 Mar 2012 14:26:59 +0000"  >&lt;p&gt;While testing the patch in local, I&apos;m getting the following error in trunk.&lt;br/&gt;
Any hints on this please?&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.RuntimeException: java.io.IOException: Call to localhost/127.0.0.1:0 failed on local exception: java.net.BindException: Cannot assign requested address: no further information
	at org.apache.hadoop.mapred.MiniMRCluster.waitUntilIdle(MiniMRCluster.java:323)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:524)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:462)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:454)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:446)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:436)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:426)
	at org.apache.hadoop.mapred.MiniMRCluster.&amp;lt;init&amp;gt;(MiniMRCluster.java:417)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniMapReduceCluster(HBaseTestingUtility.java:1269)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniMapReduceCluster(HBaseTestingUtility.java:1255)
	at org.apache.hadoop.hbase.mapreduce.TestImportTsv.doMROnTableTest(TestImportTsv.java:189)
	at org.apache.hadoop.hbase.mapreduce.TestImportTsv.testMROnTable(TestImportTsv.java:162)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13228467" author="stack" created="Tue, 13 Mar 2012 15:58:03 +0000"  >&lt;p&gt;Googling it, its either something is already listening on the port of your 127.0.0.1 has been removed?   See &lt;a href=&quot;http://www-01.ibm.com/support/docview.wss?uid=swg21233733&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www-01.ibm.com/support/docview.wss?uid=swg21233733&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13228936" author="lakshman" created="Wed, 14 Mar 2012 04:00:08 +0000"  >&lt;p&gt;Thanks Stack. Let me give a try.&lt;/p&gt;</comment>
                            <comment id="13233176" author="lakshman" created="Tue, 20 Mar 2012 03:54:25 +0000"  >&lt;p&gt;Initial patch on trunk for review.&lt;/p&gt;</comment>
                            <comment id="13233179" author="yuzhihong@gmail.com" created="Tue, 20 Mar 2012 04:10:10 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; getTimestapKeyColumnIndex() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please fix typo in the above method name.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-quote&quot;&gt;&quot;  -D&quot;&lt;/span&gt; + TIMESTAMP_CONF_KEY + &lt;span class=&quot;code-quote&quot;&gt;&quot;=currentTimeAsLong - use the specified timestamp &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt;. This option is ignored &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; HBASE_TS_KEY is specfied in &apos;importtsv.columns&apos;\n&quot;&lt;/span&gt; +
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please wrap the long line above.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// Should never get 0.
&lt;/span&gt;+    ts = conf.getLong(ImportTsv.TIMESTAMP_CONF_KEY, 0);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please explain why 0 wouldn&apos;t be returned.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (parser.getTimestapKeyColumnIndex() != -1)
+        ts = parsed.getTimestamp();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please use curly braces around the assignment.&lt;/p&gt;</comment>
                            <comment id="13233204" author="hadoopqa" created="Tue, 20 Mar 2012 04:50:31 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12519017/HBASE-5564_trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12519017/HBASE-5564_trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 165 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1229//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1229//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1229//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1229//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1229//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1229//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13233238" author="anoopsamjohn" created="Tue, 20 Mar 2012 06:02:39 +0000"  >&lt;p&gt;@Laxman&lt;br/&gt;
ImportTsv&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// If timestamp option is not specified, use current system time.
&lt;/span&gt;+    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timstamp = conf.getLong(TIMESTAMP_CONF_KEY, &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis());
+
+    &lt;span class=&quot;code-comment&quot;&gt;// Set it back to replace invalid timestamp (non-numeric) with current system time
&lt;/span&gt;+    conf.setLong(TIMESTAMP_CONF_KEY, timstamp);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Doing this will use the same TS across all the mappers. Is this the intention for this change? So in TsvImporterMapper, conf.getLong(ImportTsv.TIMESTAMP_CONF_KEY, 0) will always have value to get from conf.&lt;/p&gt;</comment>
                            <comment id="13233240" author="lakshman" created="Tue, 20 Mar 2012 06:08:17 +0000"  >&lt;p&gt;Ted, Thanks for your review. Attached the patch after fixing the review comments.&lt;/p&gt;</comment>
                            <comment id="13233283" author="lakshman" created="Tue, 20 Mar 2012 07:21:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;Doing this will use the same TS across all the mappers. Is this the intention for this change? So in TsvImporterMapper, conf.getLong(ImportTsv.TIMESTAMP_CONF_KEY, 0) will always have value to get from conf.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes Anoop. we should have same timestamp for all mappers.&lt;br/&gt;
Please check my previous comments on the scope of the issue.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564?focusedCommentId=13228297&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13228297&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-5564?focusedCommentId=13228297&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13228297&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13233328" author="lakshman" created="Tue, 20 Mar 2012 09:31:44 +0000"  >&lt;p&gt;QA bot didn&apos;t pick up previous patch. so, resubmitting...&lt;/p&gt;</comment>
                            <comment id="13233356" author="lakshman" created="Tue, 20 Mar 2012 11:26:27 +0000"  >&lt;p&gt;Any idea why QA bot is not testing this patch?&lt;br/&gt;
Can someone trigger this explicitly?&lt;/p&gt;</comment>
                            <comment id="13233417" author="anoopsamjohn" created="Tue, 20 Mar 2012 14:07:26 +0000"  >&lt;p&gt;Comment from Jesse Yates&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The question is, if you have a TSV file with the same row key, which value should be considered the most recent version? Should any of them - maybe that is actually a problem and we want to have a warning/error when that occurs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do we need to handle this? The issue is TreeSet used by PutSortReducer and KeyValueSortReducer as mentioned by Laxman. &lt;br/&gt;
In normal data insertion using Puts, all the duplicate values will go into the memstore (and finally to HFiles) and while scan the last entered one will get retrieved. In this bulk load case the 1st data only will get inserted as DS avoid the duplicates. Is this a behaviour mismatch?  But this depends on which entry in the TSV file needs to be considered as the recent version.If we say that last entry coming in the file is the recent version.....&lt;/p&gt;</comment>
                            <comment id="13233424" author="zhihyu@ebaysf.com" created="Tue, 20 Mar 2012 14:11:26 +0000"  >&lt;p&gt;@Laxman:&lt;br/&gt;
Please take a look at &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1229/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1229/console&lt;/a&gt; and see which test timed out.&lt;/p&gt;

&lt;p&gt;I have sent an email to builds@apache.org, informing them of the issue for Hadoop QA.&lt;/p&gt;</comment>
                            <comment id="13233910" author="hadoopqa" created="Tue, 20 Mar 2012 22:52:12 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12519054/HBASE-5564_trunk.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12519054/HBASE-5564_trunk.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 165 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1231//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1231//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1231//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1231//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1231//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1231//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13234082" author="lakshman" created="Wed, 21 Mar 2012 04:39:43 +0000"  >&lt;p&gt;All MR tests seems to be failing. Failures are not because of the patch.&lt;br/&gt;
I will check these failures.&lt;/p&gt;

&lt;p&gt;@anoop&lt;br/&gt;
In bulkload, if multiple records are having same timestamp, then the last KV entry processed by reducer only will be persisted (TreeSet in Reducer). I don&apos;t see this as behavior inconsistency. Bulkload can&apos;t judge which KV entry to be retained (Considering duplicate records exists across input splits/files). So, in this case, user can develop custom MR to achieve this functionality.&lt;/p&gt;</comment>
                            <comment id="13234157" author="lakshman" created="Wed, 21 Mar 2012 06:35:03 +0000"  >&lt;p&gt;These tests are passing in my dev environment.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Running org.apache.hadoop.hbase.mapreduce.TestImportTsv
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 168.578 sec

Results :

Tests run: 9, Failures: 0, Errors: 0, Skipped: 0

[INFO]
[INFO] --- maven-surefire-plugin:2.12-TRUNK-HBASE-2:test (secondPartTestsExecution) @ hbase ---
[INFO] Tests are skipped.
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also, I can see these MR tests are failing in previous builds as well &lt;span class=&quot;error&quot;&gt;&amp;#91;HBase-5529&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;Will check more. &lt;/p&gt;</comment>
                            <comment id="13234244" author="ram_krish" created="Wed, 21 Mar 2012 10:03:11 +0000"  >&lt;p&gt;The test cases that fail is common in HadoopQA.  As your patch is changing the ImportTsv part people will be worried.&lt;br/&gt;
But as you have run it locally and ensured that it is passing the main build should be able to pass it.&lt;/p&gt;</comment>
                            <comment id="13234281" author="lakshman" created="Wed, 21 Mar 2012 11:14:20 +0000"  >&lt;p&gt;thanks for the info Ram.&lt;/p&gt;

&lt;p&gt;I had spent sometime in analyzing these failures. But couldn&apos;t get a clue.&lt;br/&gt;
Filed a separate JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5608&quot; title=&quot;MR testcases are failing in QA builds&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5608&quot;&gt;&lt;del&gt;HBASE-5608&lt;/del&gt;&lt;/a&gt; to fix these test failures.&lt;/p&gt;

&lt;p&gt;As mentioned earlier all these test are passing in my local environment.&lt;/p&gt;

&lt;p&gt;Should we wait for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5608&quot; title=&quot;MR testcases are failing in QA builds&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5608&quot;&gt;&lt;del&gt;HBASE-5608&lt;/del&gt;&lt;/a&gt; or proceed with review &amp;amp; commit?&lt;/p&gt;</comment>
                            <comment id="13234450" author="zhihyu@ebaysf.com" created="Wed, 21 Mar 2012 16:05:08 +0000"  >&lt;p&gt;@Laxman:&lt;br/&gt;
5564.lint contains the warnings &apos;arc lint&apos; found w.r.t. your patch.&lt;/p&gt;</comment>
                            <comment id="13235320" author="lakshman" created="Thu, 22 Mar 2012 03:57:23 +0000"  >&lt;p&gt;Ted, all these comments are related to line wrapping.&lt;br/&gt;
IMO, 80 characters length is too low &amp;amp; it makes the code bit ugly.&lt;/p&gt;

&lt;p&gt;If you strongly feel we need to stick this 80-length, I will fix these comments.&lt;/p&gt;</comment>
                            <comment id="13235327" author="zhihyu@ebaysf.com" created="Thu, 22 Mar 2012 04:03:59 +0000"  >&lt;p&gt;We have been using 80 characters as line length for a while.&lt;/p&gt;

&lt;p&gt;At Google, line length is enforced, though the limit is bit longer.&lt;/p&gt;

&lt;p&gt;Feel free to start discussion on dev@hbase about the acceptable limit.&lt;/p&gt;</comment>
                            <comment id="13235342" author="lakshman" created="Thu, 22 Mar 2012 04:42:53 +0000"  >&lt;p&gt;Thanks Ted, for taking pain in getting the lint comments.&lt;br/&gt;
As you suggested, I will start a discussion on dev@hbase.&lt;/p&gt;

&lt;p&gt;I just wanted to quote one example from this patch here.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timstamp = conf.getLong(TIMESTAMP_CONF_KEY, &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Above code snippet after formatting, it turned to&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timstamp = conf
        .getLong(TIMESTAMP_CONF_KEY, &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13236441" author="anoopsamjohn" created="Fri, 23 Mar 2012 08:01:11 +0000"  >&lt;blockquote&gt;
&lt;p&gt;In bulkload, if multiple records are having same timestamp, then the last KV entry processed by reducer only will be persisted (TreeSet in Reducer)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The 1st KV processed by the Reducer right...&lt;/p&gt;

&lt;p&gt;Yes agree with you which one is the latest might not be possible to be predicted in the reducer side...&lt;/p&gt;</comment>
                            <comment id="13237781" author="stack" created="Sun, 25 Mar 2012 05:20:01 +0000"  >&lt;p&gt;Patch seems reasonable.&lt;/p&gt;

&lt;p&gt;Add curlies here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (parser.getTimestampKeyColumnIndex() != -1)
+        ts = parsed.getTimestamp();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Convention is you can do w/o curlies if all in one line (as you do later in this file) but if not on one line, need curlies.&lt;/p&gt;

&lt;p&gt;Can you confirm that current behavior &amp;#8211; setting ts to System.currentTimeMillis &amp;#8211; is default?  It seems to be ... we set System.currentTimeMillis as time to use setting up the job.&lt;/p&gt;

&lt;p&gt;A define for NO_TIMESTAMP_KEYCOLUMN_INDEX instead of using -1 directly might help for timestampKeyColumnIndex == -1?  Or put this test into a method whose name makes it obvious what the test is about ... e.g. hasTimeStampColumn()....&lt;/p&gt;

&lt;p&gt;Patch adds nice usage commentary explaining new facility.&lt;/p&gt;

&lt;p&gt;Looks good.&lt;/p&gt;</comment>
                            <comment id="13238095" author="lakshman" created="Mon, 26 Mar 2012 04:33:38 +0000"  >&lt;p&gt;@Anoop, thanks for clarification.&lt;/p&gt;

&lt;p&gt;@Stack, thanks for the review. I will update the patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;need curlies&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;NO_TIMESTAMP_KEYCOLUMN_INDEX &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I will update the patch for above 2 comments.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you confirm that current behavior &#8211; setting ts to System.currentTimeMillis &#8211; is default? It seems to be ... we set System.currentTimeMillis as time to use setting up the job.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Before patch, we are setting ts to System.currentTimeMillis in TsvImporterMapper.doSetup. This setup methos will be called for each mapper, i.e, for each input split. That means it uses a new timestamp for each map task.&lt;/p&gt;

&lt;p&gt;After patch, we are setting ts to conf.getLong which is same in all map tasks.&lt;/p&gt;

&lt;p&gt;Hope, I understood your question correctly.&lt;/p&gt;</comment>
                            <comment id="13238452" author="lakshman" created="Mon, 26 Mar 2012 14:57:05 +0000"  >&lt;p&gt;@Stack, updated the patch after fixing your comments. Thanks for the review.&lt;/p&gt;</comment>
                            <comment id="13238506" author="hadoopqa" created="Mon, 26 Mar 2012 15:52:44 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12519960/HBASE-5564_trunk.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12519960/HBASE-5564_trunk.2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1305//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1305//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1305//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1305//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1305//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1305//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13239222" author="lakshman" created="Tue, 27 Mar 2012 06:18:12 +0000"  >&lt;p&gt;Findbugs reported by QA bot are about usage of default encoding. This behavior is inline with existing code.&lt;/p&gt;


&lt;p&gt;bug #1&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TEST 	Unknown bug pattern DM_DEFAULT_ENCODING in org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getTimestamp()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;bug #2&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TEST 	Unknown bug pattern DM_DEFAULT_ENCODING in org.apache.hadoop.hbase.mapreduce.ImportTsv.createSubmittableJob(Configuration, String[])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;bug #2 already existing in code. just included in patch file with no changes.&lt;/p&gt;

&lt;p&gt;And test case failures are not because of this patch. Test failures to be addressed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5608&quot; title=&quot;MR testcases are failing in QA builds&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5608&quot;&gt;&lt;del&gt;HBASE-5608&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13239377" author="lakshman" created="Tue, 27 Mar 2012 11:00:13 +0000"  >&lt;p&gt;Final patch for commit to trunk.&lt;br/&gt;
Changes from previous patch&lt;br/&gt;
1) Minor improvements to getTimestamp (Readability).&lt;br/&gt;
2) Find bug - Default encoding - corrected using Base64 utility&lt;/p&gt;</comment>
                            <comment id="13239392" author="hadoopqa" created="Tue, 27 Mar 2012 11:47:38 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12520096/HBASE-5564_trunk.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12520096/HBASE-5564_trunk.3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1319//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1319//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1319//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1319//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1319//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1319//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13239626" author="stack" created="Tue, 27 Mar 2012 16:53:14 +0000"  >&lt;p&gt;Patch looks good.  Is this right:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.parseLong(Base64.encodeBytes(lineBytes,
+            getColumnOffset(timestampKeyColumnIndex), getColumnLength(timestampKeyColumnIndex)));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As I read it, encode some passed bytes into a base64 String and then try to parse it as a long (it doesn&apos;t look like parseLong can interpret base64&apos;d longs)?  Am I reading it wrong?&lt;/p&gt;

&lt;p&gt;I was going to mark this an incompatible change but thinking on it, setting timestamp for the MR job once rather than per mapper seems like a bug fix.&lt;/p&gt;

&lt;p&gt;Please write a bit of a release note at least explaining the changed behavior.&lt;/p&gt;

&lt;p&gt;If the above is right and I&apos;m just reading it wrong, will commit.  Let me know.  Thanks Laxman.&lt;/p&gt;</comment>
                            <comment id="13240189" author="lakshman" created="Wed, 28 Mar 2012 05:27:06 +0000"  >&lt;p&gt;Its my mistake stack. While fixing findbug, I overlooked Base64 behavior. I was expecting UTF-8 encoding from this utiliny. Thanks for pointing it out. I will fix this.&lt;/p&gt;

&lt;p&gt;Will also add some unit tests for parsing the timestamps properly.&lt;br/&gt;
Thanks stack for pointing out the problem.&lt;/p&gt;</comment>
                            <comment id="13240241" author="lakshman" created="Wed, 28 Mar 2012 07:02:17 +0000"  >&lt;p&gt;Another problem found in my testing. Invalid timestamp is not respecting skip.bad.lines configuration.&lt;br/&gt;
I will update the patch for this as well. Adding some unit tests too.&lt;/p&gt;</comment>
                            <comment id="13240330" author="lakshman" created="Wed, 28 Mar 2012 09:58:21 +0000"  >&lt;p&gt;Attached the final patch for review and commit.&lt;/p&gt;

&lt;p&gt;Changes from previous patch&lt;br/&gt;
1) Encoding issue&lt;br/&gt;
2) Proper handling for bad records (with invalid timestamp)&lt;br/&gt;
3) New unit tests to test the parser (with valid &amp;amp; invalid timestamp)&lt;/p&gt;

&lt;p&gt;Note: QA may report 2 new findbugs. As explained earlier, these findings are due to usage of default encoding (String.getBytes, new String) which is inline with the existing behavior.&lt;/p&gt;</comment>
                            <comment id="13240345" author="hadoopqa" created="Wed, 28 Mar 2012 10:49:50 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12520255/HBASE-5564_trunk.4_final.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12520255/HBASE-5564_trunk.4_final.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1326//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1326//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1326//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1326//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1326//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1326//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13240999" author="stack" created="Thu, 29 Mar 2012 05:47:20 +0000"  >&lt;p&gt;Same as  v4 but uses Bytes to try and get rid of the findbug warnings (Laxman, you have probably noticed our new &apos;sensitivity&apos; to the findbug output... you did not introduce these warnings, they were in the original code &amp;#8211; but let me try and get rid of them w/ this v5 ... thanks).&lt;/p&gt;</comment>
                            <comment id="13241021" author="hadoopqa" created="Thu, 29 Mar 2012 06:41:46 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12520371/5564v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12520371/5564v5.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1336//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1336//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1336//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1336//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1336//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1336//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13241076" author="ram_krish" created="Thu, 29 Mar 2012 08:27:13 +0000"  >&lt;p&gt;+1 on v5.  &lt;/p&gt;

&lt;p&gt;Thanks for the patch Lakshman and Stack.  &lt;br/&gt;
@Stack&lt;br/&gt;
So any new patches that we give should not have any findbugs even if in the old existing code? Ok i will take care of this and ensure people submitting patches over here also do that. Thanks.&lt;/p&gt;</comment>
                            <comment id="13241078" author="lakshman" created="Thu, 29 Mar 2012 08:29:20 +0000"  >&lt;p&gt;@stack, thanks for your review and clearing the findbugs.&lt;br/&gt;
I was avoiding these changes as these are unrelated to this JIRA.&lt;/p&gt;

&lt;p&gt;@ram, thanks for reviewing the patch.&lt;/p&gt;</comment>
                            <comment id="13241167" author="umamaheswararao" created="Thu, 29 Mar 2012 12:05:53 +0000"  >&lt;p&gt;Also don&apos;t forget to update the count in test-patch.properties according to the present count if we fix any existing findbugs.&lt;/p&gt;

&lt;p&gt;+Uma&lt;/p&gt;</comment>
                            <comment id="13241307" author="stack" created="Thu, 29 Mar 2012 15:26:59 +0000"  >&lt;p&gt;Committed to trunk.  Thanks for the patch Laxman.  Thanks for the reminder on updating the count Uma. It seems that my minor addition only stopped the count rising so I didn&apos;t have to change the findbugs count (the test build was seeing two new findbug warnings when in fact there were none &amp;#8211; a variable name change was making it think the findbugs count had gone up).&lt;/p&gt;</comment>
                            <comment id="13241341" author="jmhsieh" created="Thu, 29 Mar 2012 16:06:25 +0000"  >&lt;p&gt;maybe not worry about find bugs for normal patches? (ideally it does go up though) the find bugs number isn&apos;t the focus of this patch.&lt;/p&gt;

&lt;p&gt;Sent from my iPhone&lt;/p&gt;

</comment>
                            <comment id="13241485" author="jmhsieh" created="Thu, 29 Mar 2012 18:28:01 +0000"  >&lt;p&gt;meant to say &quot;ideally it does not go up&quot;.  I think stack&apos;s action (he didn&apos;t lower findbugs number on normal patch) captured the same idea.&lt;/p&gt;</comment>
                            <comment id="13242065" author="hudson" created="Fri, 30 Mar 2012 05:05:35 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #154 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/154/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/154/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records (Revision 1306907)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13242189" author="lakshman" created="Fri, 30 Mar 2012 09:30:07 +0000"  >&lt;p&gt;Thanks for the commit stack.&lt;/p&gt;</comment>
                            <comment id="13242477" author="hudson" created="Fri, 30 Mar 2012 15:53:52 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2698 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2698/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2698/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records (Revision 1306907)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13242768" author="zhihyu@ebaysf.com" created="Fri, 30 Mar 2012 21:34:09 +0000"  >&lt;p&gt;By reverting the patch applied to trunk, TestImportTsv#testMROnTableWithCustomMapper passes.&lt;/p&gt;</comment>
                            <comment id="13242785" author="stack" created="Fri, 30 Mar 2012 21:45:06 +0000"  >&lt;p&gt;Thanks Ted.  I reverted the patch for now.  Laxman, mind taking a looksee at the failures Ted found in TestImportTsv#testMROnTableWithCustomMapper?&lt;/p&gt;</comment>
                            <comment id="13242825" author="hudson" created="Fri, 30 Mar 2012 22:46:18 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2701 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2701/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2701/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records (Revision 1307629)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13243043" author="hudson" created="Sat, 31 Mar 2012 05:54:11 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #155 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/155/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/155/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records (Revision 1307629)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13245999" author="lakshman" created="Wed, 4 Apr 2012 03:52:15 +0000"  >&lt;p&gt;Yes Stack. I will take a look. Changes in this patch are in Default Mapper. IMO these changes shouldn&apos;t cause failures in custom mapper.&lt;/p&gt;</comment>
                            <comment id="13260282" author="stack" created="Tue, 24 Apr 2012 06:31:23 +0000"  >&lt;p&gt;@Laxman Any luck?&lt;/p&gt;</comment>
                            <comment id="13292746" author="ram_krish" created="Mon, 11 Jun 2012 11:02:28 +0000"  >&lt;p&gt;We got the problem.  It was because there was a space created in the latest patch in the testcase&lt;br/&gt;
&apos;&quot; = org.apache.hadoop.hbase.mapreduce.TsvImporterCustomTestMapper&quot;,&apos;.  There should not be any space before and after &apos;=&apos;.&lt;/p&gt;

&lt;p&gt;Will rebase the patch so that it can be recommitted.&lt;/p&gt;</comment>
                            <comment id="13292931" author="ram_krish" created="Mon, 11 Jun 2012 18:03:51 +0000"  >&lt;p&gt;New patch for trunk.  This time the testcases should run.  Pls review and provide your comments.&lt;/p&gt;</comment>
                            <comment id="13293238" author="hadoopqa" created="Tue, 12 Jun 2012 00:59:21 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531698/HBASE-5564.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531698/HBASE-5564.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2136//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13293367" author="ram_krish" created="Tue, 12 Jun 2012 05:36:55 +0000"  >&lt;p&gt;All the tests are passing.. Will integrate tomorrow if there are no objections.&lt;/p&gt;</comment>
                            <comment id="13293375" author="zhihyu@ebaysf.com" created="Tue, 12 Jun 2012 05:50:10 +0000"  >&lt;p&gt;Minor comment:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BadTsvLineException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Invalid timestamp&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can the timestamp string be included ?&lt;/p&gt;</comment>
                            <comment id="13293469" author="ram_krish" created="Tue, 12 Jun 2012 09:24:16 +0000"  >&lt;p&gt;Ok.. I will make that change and reupload the patch..Thanks Ted.&lt;/p&gt;</comment>
                            <comment id="13293790" author="ram_krish" created="Tue, 12 Jun 2012 17:28:03 +0000"  >&lt;p&gt;Updated patch addressing Ted&apos;s comments.  This what am planning to commit if there is no objection.&lt;/p&gt;</comment>
                            <comment id="13293815" author="hadoopqa" created="Tue, 12 Jun 2012 18:17:41 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531854/HBASE-5564_1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531854/HBASE-5564_1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestClassLoading&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2153//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13295345" author="stack" created="Thu, 14 Jun 2012 22:00:50 +0000"  >&lt;p&gt;+1 on commit.&lt;/p&gt;</comment>
                            <comment id="13295760" author="ram_krish" created="Fri, 15 Jun 2012 16:53:08 +0000"  >&lt;p&gt;Committed to trunk.&lt;br/&gt;
Thanks for the patch Laxman.&lt;br/&gt;
Thanks for the review Stack, Ted, Lars, Todd, Jesse and Anoop.&lt;/p&gt;</comment>
                            <comment id="13295775" author="hudson" created="Fri, 15 Jun 2012 17:11:43 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3030 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3030/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3030/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records&lt;/p&gt;

&lt;p&gt;Submitted by:Laxman	&lt;br/&gt;
Reviewed by:iStack, Ted, Ram (Revision 1350691)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
ramkrishna : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13296053" author="hudson" created="Sat, 16 Jun 2012 00:48:59 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #55 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/55/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/55/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records&lt;/p&gt;

&lt;p&gt;Submitted by:Laxman	&lt;br/&gt;
Reviewed by:iStack, Ted, Ram (Revision 1350691)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
ramkrishna : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13574279" author="hudson" created="Fri, 8 Feb 2013 05:50:33 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #834 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/834/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/834/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7793&quot; title=&quot;Port HBASE-5564 Bulkload is discarding duplicate records to 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7793&quot;&gt;&lt;del&gt;HBASE-7793&lt;/del&gt;&lt;/a&gt; Port &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records to 0.94 (Ted Yu) (Revision 1443842)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13574291" author="hudson" created="Fri, 8 Feb 2013 06:17:59 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #109 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/109/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/109/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7793&quot; title=&quot;Port HBASE-5564 Bulkload is discarding duplicate records to 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7793&quot;&gt;&lt;del&gt;HBASE-7793&lt;/del&gt;&lt;/a&gt; Port &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records to 0.94 (Ted Yu) (Revision 1443842)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13574295" author="hudson" created="Fri, 8 Feb 2013 06:35:51 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #835 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/835/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/835/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7793&quot; title=&quot;Port HBASE-5564 Bulkload is discarding duplicate records to 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7793&quot;&gt;&lt;del&gt;HBASE-7793&lt;/del&gt;&lt;/a&gt; Port &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records to 0.94 (Ted Yu) (Revision 1443842)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13593192" author="hudson" created="Tue, 5 Mar 2013 07:52:17 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #12 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/12/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/12/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7793&quot; title=&quot;Port HBASE-5564 Bulkload is discarding duplicate records to 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7793&quot;&gt;&lt;del&gt;HBASE-7793&lt;/del&gt;&lt;/a&gt; Port &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5564&quot; title=&quot;Bulkload is discarding duplicate records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5564&quot;&gt;&lt;del&gt;HBASE-5564&lt;/del&gt;&lt;/a&gt; Bulkload is discarding duplicate records to 0.94 (Ted Yu) (Revision 1443842)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/TsvImporterMapper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13775041" author="stack" created="Mon, 23 Sep 2013 18:30:37 +0000"  >&lt;p&gt;Marking closed.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12519254" name="5564.lint" size="9780" author="zhihyu@ebaysf.com" created="Wed, 21 Mar 2012 16:05:08 +0000"/>
                            <attachment id="12520371" name="5564v5.txt" size="19026" author="stack" created="Thu, 29 Mar 2012 05:47:18 +0000"/>
                            <attachment id="12531698" name="HBASE-5564.patch" size="16425" author="ram_krish" created="Mon, 11 Jun 2012 18:03:50 +0000"/>
                            <attachment id="12531854" name="HBASE-5564_1.patch" size="16482" author="ram_krish" created="Tue, 12 Jun 2012 17:28:03 +0000"/>
                            <attachment id="12519054" name="HBASE-5564_trunk.1.patch" size="14449" author="lakshman" created="Tue, 20 Mar 2012 09:30:55 +0000"/>
                            <attachment id="12519028" name="HBASE-5564_trunk.1.patch" size="14449" author="lakshman" created="Tue, 20 Mar 2012 06:06:32 +0000"/>
                            <attachment id="12519960" name="HBASE-5564_trunk.2.patch" size="13709" author="lakshman" created="Mon, 26 Mar 2012 14:55:30 +0000"/>
                            <attachment id="12520096" name="HBASE-5564_trunk.3.patch" size="14742" author="lakshman" created="Tue, 27 Mar 2012 11:00:13 +0000"/>
                            <attachment id="12520255" name="HBASE-5564_trunk.4_final.patch" size="18627" author="lakshman" created="Wed, 28 Mar 2012 09:40:09 +0000"/>
                            <attachment id="12519017" name="HBASE-5564_trunk.patch" size="14692" author="lakshman" created="Tue, 20 Mar 2012 03:54:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 12 Mar 2012 17:15:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>231266</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 12 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0694v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34411</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1) Provision for using the existing timestamp (HBASE_TS_KEY)&lt;br/&gt;
2) Bug fix to use same timestamp across mappers.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>bulkload, mapreduce, importtsv</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>