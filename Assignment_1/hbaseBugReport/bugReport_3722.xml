<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:12:32 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3722/HBASE-3722.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3722]  A lot of data is lost when name node crashed</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3722</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I&apos;m not sure exactly what arose it. there is some split failed logs .&lt;br/&gt;
the master should shutdown itself when the HDFS is crashed.&lt;/p&gt;

&lt;p&gt; The logs is :&lt;br/&gt;
 2011-03-22 13:21:55,056 WARN &lt;br/&gt;
 org.apache.hadoop.hbase.master.LogCleaner: Error while cleaning the &lt;br/&gt;
 logs&lt;br/&gt;
 java.net.ConnectException: Call to C4C1/157.5.100.1:9000 failed on connection exception: java.net.ConnectException: Connection refused&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.wrapException(Client.java:844)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.call(Client.java:820)&lt;br/&gt;
         at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:221)&lt;br/&gt;
         at $Proxy5.getListing(Unknown Source)&lt;br/&gt;
         at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)&lt;br/&gt;
         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
         at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
         at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)&lt;br/&gt;
         at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)&lt;br/&gt;
         at $Proxy5.getListing(Unknown Source)&lt;br/&gt;
         at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:614)&lt;br/&gt;
         at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:252)&lt;br/&gt;
         at org.apache.hadoop.hbase.master.LogCleaner.chore(LogCleaner.java:121)&lt;br/&gt;
         at org.apache.hadoop.hbase.Chore.run(Chore.java:66)&lt;br/&gt;
         at &lt;br/&gt;
 org.apache.hadoop.hbase.master.LogCleaner.run(LogCleaner.java:154)&lt;br/&gt;
 Caused by: java.net.ConnectException: Connection refused&lt;br/&gt;
         at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)&lt;br/&gt;
         at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)&lt;br/&gt;
         at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)&lt;br/&gt;
         at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:408)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:332)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:202)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.getConnection(Client.java:943)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.call(Client.java:788)&lt;br/&gt;
         ... 13 more&lt;br/&gt;
 2011-03-22 13:21:56,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 0 time(s).&lt;br/&gt;
 2011-03-22 13:21:57,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 1 time(s).&lt;br/&gt;
 2011-03-22 13:21:58,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 2 time(s).&lt;br/&gt;
 2011-03-22 13:21:59,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 3 time(s).&lt;br/&gt;
 2011-03-22 13:22:00,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 4 time(s).&lt;br/&gt;
 2011-03-22 13:22:01,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 5 time(s).&lt;br/&gt;
 2011-03-22 13:22:02,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 6 time(s).&lt;br/&gt;
 2011-03-22 13:22:03,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 7 time(s).&lt;br/&gt;
 2011-03-22 13:22:04,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 8 time(s).&lt;br/&gt;
 2011-03-22 13:22:05,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 9 time(s).&lt;br/&gt;
 2011-03-22 13:22:05,060 ERROR &lt;br/&gt;
 org.apache.hadoop.hbase.master.MasterFileSystem: Failed splitting &lt;br/&gt;
 hdfs://C4C1:9000/hbase/.logs/C4C9.site,60020,1300767633398&lt;br/&gt;
 java.net.ConnectException: Call to C4C1/157.5.100.1:9000 failed on connection exception: java.net.ConnectException: Connection refused&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.wrapException(Client.java:844)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.call(Client.java:820)&lt;br/&gt;
         at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:221)&lt;br/&gt;
         at $Proxy5.getFileInfo(Unknown Source)&lt;br/&gt;
         at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)&lt;br/&gt;
         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
         at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
         at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)&lt;br/&gt;
         at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)&lt;br/&gt;
         at $Proxy5.getFileInfo(Unknown Source)&lt;br/&gt;
         at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:623)&lt;br/&gt;
         at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:461)&lt;br/&gt;
         at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:690)&lt;br/&gt;
         at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLog(HLogSplitter.java:177)&lt;br/&gt;
         at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:196)&lt;br/&gt;
         at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:95)&lt;br/&gt;
         at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)&lt;br/&gt;
         at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
         at java.lang.Thread.run(Thread.java:662)&lt;br/&gt;
 Caused by: java.net.ConnectException: Connection refused&lt;br/&gt;
         at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)&lt;br/&gt;
         at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)&lt;br/&gt;
         at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)&lt;br/&gt;
         at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:408)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:332)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:202)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.getConnection(Client.java:943)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.call(Client.java:788)&lt;br/&gt;
         ... 18 more&lt;br/&gt;
 2011-03-22 13:22:45,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 0 time(s).&lt;br/&gt;
 2011-03-22 13:22:46,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 1 time(s).&lt;br/&gt;
 2011-03-22 13:22:47,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 2 time(s).&lt;br/&gt;
 2011-03-22 13:22:48,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 3 time(s).&lt;br/&gt;
 2011-03-22 13:22:49,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 4 time(s).&lt;br/&gt;
 2011-03-22 13:22:50,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 5 time(s).&lt;br/&gt;
 2011-03-22 13:22:51,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 6 time(s).&lt;br/&gt;
 2011-03-22 13:22:52,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 7 time(s).&lt;br/&gt;
 2011-03-22 13:22:53,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 8 time(s).&lt;br/&gt;
 2011-03-22 13:22:54,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 9 time(s).&lt;br/&gt;
 2011-03-22 13:22:54,603 WARN &lt;br/&gt;
 org.apache.hadoop.hbase.master.LogCleaner: Error while cleaning the &lt;br/&gt;
 logs&lt;br/&gt;
 java.net.ConnectException: Call to C4C1/157.5.100.1:9000 failed on connection exception: java.net.ConnectException: Connection refused&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.wrapException(Client.java:844)&lt;br/&gt;
         at org.apache.hadoop.ipc.Client.call(Client.java:820)&lt;br/&gt;
         at org.apache.hadoop.ipc.RPC$Invok&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12503083">HBASE-3722</key>
            <summary> A lot of data is lost when name node crashed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sunnygao">gaojinchao</assignee>
                                    <reporter username="sunnygao">gaojinchao</reporter>
                        <labels>
                    </labels>
                <created>Fri, 1 Apr 2011 01:07:52 +0000</created>
                <updated>Fri, 20 Nov 2015 12:40:52 +0000</updated>
                            <resolved>Wed, 13 Apr 2011 04:57:27 +0000</resolved>
                                    <version>0.90.1</version>
                                    <fixVersion>0.90.3</fixVersion>
                                    <component>master</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13016208" author="sunnygao" created="Wed, 6 Apr 2011 01:13:59 +0000"  >&lt;p&gt;Jean-Daniel answers in mail as:&lt;/p&gt;

&lt;p&gt;MasterFileSystem has most of DFS interactions, it seems that checkFileSystem is never called (it should be) and splitLog catches the ERROR when splitting but doesn&apos;t abort.&lt;/p&gt;

&lt;p&gt;Would you mind opening a jira about this issue and perhaps submit a patch?&lt;/p&gt;

&lt;p&gt;when will it submit a patch and I want to test it?&lt;br/&gt;
thanks.&lt;/p&gt;</comment>
                            <comment id="13016350" author="sunnygao" created="Wed, 6 Apr 2011 11:52:14 +0000"  >&lt;p&gt;I try to fix this bug. who do review it?  &lt;br/&gt;
thanks&lt;/p&gt;</comment>
                            <comment id="13016696" author="stack" created="Thu, 7 Apr 2011 05:04:59 +0000"  >&lt;p&gt;That seems like an harmless addtion.  Do you think it would help w/ the issue you saw Gao Jinchao?  If so, I can commit.&lt;/p&gt;</comment>
                            <comment id="13016768" author="sunnygao" created="Thu, 7 Apr 2011 08:45:42 +0000"  >&lt;p&gt;yes, it is important for me. thanks.&lt;br/&gt;
some explains about our application:&lt;br/&gt;
1.I have a babysitter process,  it controls all Hbase process start or stop.&lt;br/&gt;
  when NN crash. Hbase can be self-protection.&lt;br/&gt;
  when NN recover. I hope to Hbase can automatically recover service.&lt;br/&gt;
  if Hmaster don&apos;t shutdown itself, it will skipping splitlog and wait for assign Meta table or root table.&lt;br/&gt;
  when NN recover and region server start up. a lots of data is lost. especially the meta table. &lt;/p&gt;

&lt;p&gt;2. Hbase + hadoop-append should assure all data not to be lost except hadoop is lost data.&lt;br/&gt;
   the reliability is importance for my application. I read the code about Hlog and do some DFX tests.&lt;br/&gt;
   the issue is badly. but NN crashed is lowness probability. &lt;br/&gt;
   I find Region server will also retart when NN crash.&lt;/p&gt;

&lt;p&gt;please review the modification.  I afraid to make a mistake. &lt;/p&gt;</comment>
                            <comment id="13018791" author="sunnygao" created="Tue, 12 Apr 2011 10:52:05 +0000"  >&lt;p&gt;In my cluster :&lt;br/&gt;
1.HDFS cluster is HA namenode( ANN and BNN)&lt;br/&gt;
2.HBASE Version 0.90.1:&lt;br/&gt;
  Active Hmaster: C4C1 &lt;br/&gt;
  Backup Hmaster: C4C2&lt;br/&gt;
  Region server: C4C3,C4C4,C4C5,...&lt;/p&gt;

&lt;p&gt;operation:&lt;br/&gt;
1.ANN crashed and BNN becomed Active(that needs some time)&lt;br/&gt;
2.Some region server crashed(eg:C4C3 has meta table) that Hbase client is putting into data and some Region server is ok.&lt;br/&gt;
3.Hmaster split hlog failed and skip it.&lt;br/&gt;
4.BNN had been active and Hmaster had finished processed shutdown event.&lt;br/&gt;
5.A lots of data is lost that region server had crashed.&lt;/p&gt;


&lt;p&gt;log as:&lt;br/&gt;
14:57:58 C4C3 shutdow itself  because of ANN crashed.&lt;br/&gt;
skip splitlog and ressigned Meta table.  &lt;/p&gt;

&lt;p&gt;2011-04-12 14:57:58,782 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Splitting logs for C4C3.site,60020,1302590910433&lt;br/&gt;
2011-04-12 14:57:59,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 0 time(s).&lt;br/&gt;
....&lt;br/&gt;
2011-04-12 14:58:08,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 9 time(s).&lt;br/&gt;
2011-04-12 14:58:08,795 ERROR org.apache.hadoop.hbase.master.MasterFileSystem: Failed splitting hdfs://C4C1:9000/hbase/.logs/C4C3.site,60020,1302590910433&lt;br/&gt;
java.net.ConnectException: Call to C4C1/157.5.100.1:9000 failed on connection exception: java.net.ConnectException: Connection refused&lt;br/&gt;
2011-04-12 14:58:08,805 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper&lt;br/&gt;
2011-04-12 14:58:08,880 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Failed verification of .META.,,1 at address=C4C3.site:60020; java.net.ConnectException: Connection refused&lt;br/&gt;
2011-04-12 14:58:08,880 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Current cached META location is not valid, resetting&lt;/p&gt;

&lt;p&gt;Hmaster finished process shutdown event when BNN becomes active and meta table ressigned &lt;/p&gt;

&lt;p&gt;2011-04-12 15:00:31,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 0 time(s).&lt;br/&gt;
2011-04-12 15:00:32,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: C4C1/157.5.100.1:9000. Already tried 1 time(s).&lt;br/&gt;
2011-04-12 15:00:40,698 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,,1.1028785192 state=OPENING, ts=1302591600701&lt;br/&gt;
2011-04-12 15:00:40,699 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OPENING for too long, reassigning region=.META.,,1.1028785192&lt;br/&gt;
2011-04-12 15:00:40,709 INFO org.apache.hadoop.hbase.master.AssignmentManager: Successfully transitioned region=.META.,,1.1028785192 into OFFLINE and forcing a new assignment&lt;br/&gt;
2011-04-12 15:00:40,712 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  &lt;del&gt;ROOT&lt;/del&gt;,,0.70236052 state=OPENING, ts=1302591600718&lt;br/&gt;
2011-04-12 15:00:40,712 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OPENING for too long, reassigning region=&lt;del&gt;ROOT&lt;/del&gt;,,0.70236052&lt;br/&gt;
2011-04-12 15:00:40,725 INFO org.apache.hadoop.hbase.master.AssignmentManager: Successfully transitioned region=&lt;del&gt;ROOT&lt;/del&gt;,,0.70236052 into OFFLINE and forcing a new assignment&lt;br/&gt;
2011-04-12 15:00:40,892 INFO org.apache.hadoop.hbase.zookeeper.MetaNodeTracker: Detected completed assignment of META, notifying catalog tracker&lt;br/&gt;
2011-04-12 15:00:45,870 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Reassigning 0 region(s) that C4C3.site,60020,1302590910433 was carrying (skipping 0 regions(s) that are already in transition)&lt;br/&gt;
2011-04-12 15:00:45,870 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Finished processing of shutdown of C4C3.site,60020,1302590910433&lt;/p&gt;



&lt;p&gt;It has been lost that the Hlog is skipped if Hmaster don&apos;t restart when NN recovered.&lt;br/&gt;
so I think Hmaster should shutdown itslef when NN crashed.&lt;br/&gt;
like as region server roll Hlog shutdowns itself when it catchs any IO exception.&lt;/p&gt;</comment>
                            <comment id="13019206" author="stack" created="Wed, 13 Apr 2011 04:57:27 +0000"  >&lt;p&gt;Applied to branch and trunk.  Makes sense.  Thanks for patch and substantiating evidence gaojinchao.&lt;/p&gt;</comment>
                            <comment id="13019520" author="hudson" created="Wed, 13 Apr 2011 19:54:02 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #1850 (See &lt;a href=&quot;https://hudson.apache.org/hudson/job/HBase-TRUNK/1850/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hudson.apache.org/hudson/job/HBase-TRUNK/1850/&lt;/a&gt;)&lt;/p&gt;
</comment>
                            <comment id="15016818" author="lars_francke" created="Fri, 20 Nov 2015 12:40:52 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12475581" name="HmasterFilesystem_PatchV1.patch" size="595" author="sunnygao" created="Wed, 6 Apr 2011 11:49:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 7 Apr 2011 05:04:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26995</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hnjr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101077</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>