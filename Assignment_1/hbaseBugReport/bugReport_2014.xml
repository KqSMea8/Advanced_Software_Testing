<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:58:15 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2014/HBASE-2014.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2014] [DAC] Audit</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2014</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Audit: Important actions taken by subjects should be logged for accountability, a chronological record which enables the full reconstruction and examination of a sequence of events, e.g. schema changes or data mutations. Logging activity should be protected from all subjects except for a restricted set with administrative privilege, perhaps to only a single super-user.&lt;/p&gt;

&lt;p&gt;Support dynamic scaling transparently and support multi-tenant. Acquire enough detail and support streamline auditing in time. Should be configurable on a per-table basis to avoid this overhead where it is not wanted.&lt;/p&gt;

&lt;p&gt;Consider logging audit trails to an HBase table (bigtable type schemas are natural for this) and also external options with Java library support - syslog, etc., or maybe commons-logging is sufficient and punt to administrator to set up appropriate commons-logging/log4j configurations for their needs.&lt;/p&gt;

&lt;p&gt;Consider integration with Scribe (&lt;a href=&quot;http://developers.facebook.com/scribe/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://developers.facebook.com/scribe/&lt;/a&gt;) or Chukwa (&lt;a href=&quot;http://wiki.apache.org/hadoop/Chukwa&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Chukwa&lt;/a&gt;).&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Session information (Required)
	&lt;ul&gt;
		&lt;li&gt;Client, server, When, How, Where.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Command information (Required)
	&lt;ul&gt;
		&lt;li&gt;Command detail and intent&lt;/li&gt;
		&lt;li&gt;Command result and why&lt;/li&gt;
		&lt;li&gt;Data event (input and output interested data, depends on predefined policy)
		&lt;ul&gt;
			&lt;li&gt;Metadata, data detail, session identity and command identity, data direction, etc.&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;Command Counts (optional)
		&lt;ul&gt;
			&lt;li&gt;Execution duration&lt;/li&gt;
			&lt;li&gt;Response/request data amount&lt;/li&gt;
			&lt;li&gt;Resource usage&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Node status
	&lt;ul&gt;
		&lt;li&gt;Node resource counts&lt;/li&gt;
		&lt;li&gt;Session status&lt;/li&gt;
		&lt;li&gt;Abnormal events (Required)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12441792">HBASE-2014</key>
            <summary>[DAC] Audit</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12431322">HBASE-1697</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Nov 2009 19:20:55 +0000</created>
                <updated>Wed, 19 Sep 2012 19:57:21 +0000</updated>
                                                                            <component>security</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="12782980" author="ryanobjc" created="Thu, 26 Nov 2009 21:31:02 +0000"  >&lt;p&gt;Beware the lessons of the historian, storing data like this in an actual table may cause problems when the systems are offline. I would vote for straight up normal logging and let people put together a log aggregation infrastructure as needed. &lt;/p&gt;</comment>
                            <comment id="12785232" author="linden lin" created="Thu, 3 Dec 2009 08:57:11 +0000"  >&lt;p&gt;Audit is always for regulatory needs. How to secure auditing data as evidence and if there is enough detail to trace the source and problem is the key point I think. If the auditing data can deliver to target in time, it will better.&lt;/p&gt;

&lt;p&gt;From regulatory compliant needs, it not only needs to acquire all events on the table, but also needs to collect the necessary events from the cluster, such as server offline information, and some necessary information (metadata and status at that time) to analyze the event. Thus, third-part software can get the detailed event in time for monitoring, content inspection or policy enforcement in the company.&lt;/p&gt;
</comment>
                            <comment id="12785745" author="apurtell" created="Fri, 4 Dec 2009 04:38:12 +0000"  >&lt;p&gt;@ryan: Thanks for the reminder about the historian. Agree.&lt;/p&gt;</comment>
                            <comment id="12785769" author="stack" created="Fri, 4 Dec 2009 05:19:41 +0000"  >&lt;p&gt;I like the idea of audit logs going out via commons logging so you could hook up a sink of your choosing (and yes, sink could be an hbase table.. we could write a logger plugin for log4j or some such to do this).&lt;/p&gt;</comment>
                            <comment id="12785771" author="apurtell" created="Fri, 4 Dec 2009 05:29:22 +0000"  >&lt;p&gt;So I think participants on this issue are in basic agreement we can start with commons logging, presumed into a log aggregation framework. Should put support in package o.a.h.h.log.audit or similar to facilitate routing and filtering in log4j properties.&lt;/p&gt;
</comment>
                            <comment id="12786768" author="linden lin" created="Mon, 7 Dec 2009 03:12:58 +0000"  >&lt;p&gt;There is afraid of security issue about storing auditing log on the same Hbase. Audit&apos;s motivation includes the observation of the administrator&apos;s behavior.&lt;/p&gt;</comment>
                            <comment id="12786777" author="stack" created="Mon, 7 Dec 2009 04:48:35 +0000"  >&lt;p&gt;@Linden That makes sense.  So, if writing to hbase, write to a different hbase instance?  Emitting audit logs using apache commons or so or sfl4j make sense to you and then hooking up the logging system to different kind of sinks writing any necessary plugins if needed make sense to you?&lt;/p&gt;</comment>
                            <comment id="12786849" author="linden lin" created="Mon, 7 Dec 2009 10:16:51 +0000"  >&lt;p&gt;@stack, User should have a another hbase instance for audit isn&apos;t a reasonable solution from my view. Acquiring the enough detail, log4j or other logging solution is ok (leverage the efforts in implementation). But my consideration is how to transfer the log to different kind of sinks with efficient method.&lt;br/&gt;
My draft idea, I recommend using the distributional subscriber &amp;amp; receiver model for Hbase audit. One Hbase server (or HRegion) is a subscriber (many subscribers) for the distributional framework and receiver is the any sink which receives the interested content from distributional framework. The key point is receiver can divide the subscriber&apos;s log for load balance (for example, by topic name, topic name is IP address, table name, key range and so on). &lt;br/&gt;
Thus, Hbase only needs to add a client plug-in for the distributional framework (message bus, etc) and define the log title for router (it is static from design).&lt;/p&gt;

&lt;p&gt;Normally, the auditing feature is disabled. When user want to enable this feature, he should install the specific third-party router cluster (distributional, scalable framework), then add the cluster address to Hbase configuration. Thus, Hbase cluster can be the subscribers for the router cluster. The next things I think they are all customers&apos; task. (Add receiver, operate the log and so on)&lt;/p&gt;

&lt;p&gt;Meanwhile, should we need to support dynamic subscriber and subscriber content in this version?&lt;/p&gt;</comment>
                            <comment id="12786850" author="ryanobjc" created="Mon, 7 Dec 2009 10:26:47 +0000"  >&lt;p&gt;Instead of building a complex audit data management system, I suggest making a log tap that sends audit trace to syslog, either local or remote. Using syslog to audit machines is fairly common and there are a lot of good syslog systems for a variety of levels of paranoia.&lt;/p&gt;</comment>
                            <comment id="12787018" author="apurtell" created="Mon, 7 Dec 2009 18:05:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;Instead of building a complex audit data management system, I suggest making a log tap that sends audit trace to syslog, either local or remote.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. Via log4j preferably, as we already bundle it. I had a log4j setup once which aggregated into a mysql db via a rsyslog hierarchy. Not that such a thing is necessarily ideal, point is log4j affords a lot of flexibility to the user and is clean and simple to use in the HBase code. &lt;/p&gt;

&lt;p&gt;I suggest defining a format for audit logging to conveniently support message routing by regexp.&lt;/p&gt;
</comment>
                            <comment id="12787936" author="linden lin" created="Wed, 9 Dec 2009 06:15:04 +0000"  >&lt;p&gt;I give my thoughts for reference.&lt;br/&gt;
Routing string is hierarchical and easily matched by order. &lt;/p&gt;

&lt;p&gt;The routing string is as follows:&lt;/p&gt;

{Event Type}.{Candidate Router Key}.{Sub Event Item}.{Other items}&lt;br/&gt;
{Event Type}
&lt;p&gt; indicates the main event type; &lt;/p&gt;
{Candidate Router Key} is the consideration for scalability and performance; and {Sub Event Item} will be the more accurate type for filtering and routing; {Other items} is reserved for future.&lt;br/&gt;

{Event Type}:&lt;br/&gt;
1.	Session&lt;br/&gt;
2.	Command&lt;br/&gt;
3.	Data in Command&lt;br/&gt;
4.	Counts in Command&lt;br/&gt;
5.	Node Status: necessary status and abnormal events.&lt;br/&gt;
&lt;br/&gt;
Relation (A-&amp;gt;B: A depends on B):&lt;br/&gt;
Counts in Command-&amp;gt;Data In Command-&amp;gt;Command-&amp;gt;Session;&lt;br/&gt;
Counts in Command-&amp;gt;Command-&amp;gt;Session;&lt;br/&gt;
Node Status;&lt;br/&gt;
{Candidate Router Key}
&lt;p&gt; (Only choose one):&lt;br/&gt;
1.	Object Name (Recommended, it is table name for Hbase, if there isn&apos;t table in the event, Object name is null. If client query metadata from Zookeeper, use hardcode table name to replace. Such as &quot;Hbase Metadata&quot;.)&lt;br/&gt;
2.	HRegion Identity&lt;br/&gt;
3.	RegionServer IP&lt;br/&gt;
4.	Others.....&lt;/p&gt;

{Sub Event Item}
&lt;p&gt;: It depends on the &lt;/p&gt;
{Event Type}
&lt;p&gt;.&lt;br/&gt;
1.	Session (in current Hbase version, it is the connection, establish connection and close connection)&lt;br/&gt;
       Session Login In : &lt;br/&gt;
       Session Login Off:&lt;br/&gt;
2.	Command&lt;br/&gt;
       Command Request&lt;br/&gt;
       Command Response&lt;br/&gt;
3.	Data in Command (interested data from input and output command)&lt;br/&gt;
       Data metadata and content (only)&lt;br/&gt;
4.	Counts In Command&lt;br/&gt;
      Counts Set (only)&lt;br/&gt;
5.	Node Status&lt;br/&gt;
      Performance counts (Resource usage, Session amount, and other performance related counts)&lt;br/&gt;
      Abnormal events (defined by user, normally, it includes error event, huge request in a short time and &lt;br/&gt;
      so on).&lt;/p&gt;


&lt;p&gt;BTW, I suggest try to shorten the routing string and keep the capability of dynamic routing. Fox example:&lt;/p&gt;

&lt;p&gt;2.ObjectName.2.Others  =&amp;gt; it means Command.ObjectName.CommandResponse.Others (string to number is only for predefined type).&lt;/p&gt;</comment>
                            <comment id="12787937" author="linden lin" created="Wed, 9 Dec 2009 06:18:43 +0000"  >&lt;p&gt;I give my thoughts for reference.&lt;br/&gt;
Routing string is hierarchical and easily matched by order. &lt;/p&gt;

&lt;p&gt;The routing string is as follows:&lt;/p&gt;

{Event Type}.{Candidate Router Key}.{Sub Event Item}.{Other items}&lt;br/&gt;
{Event Type}
&lt;p&gt; indicates the main event type; &lt;/p&gt;
{Candidate Router Key} is the consideration for scalability and performance; and {Sub Event Item} will be the more accurate type for filtering and routing; {Other items} is reserved for future.&lt;br/&gt;

{Event Type}:&lt;br/&gt;
1.	Session&lt;br/&gt;
2.	Command&lt;br/&gt;
3.	Data in Command&lt;br/&gt;
4.	Counts in Command&lt;br/&gt;
5.	Node Status: necessary status and abnormal events.&lt;br/&gt;
&lt;br/&gt;
Relation (A-&amp;gt;B: A depends on B):&lt;br/&gt;
Counts in Command-&amp;gt;Data In Command-&amp;gt;Command-&amp;gt;Session;&lt;br/&gt;
Counts in Command-&amp;gt;Command-&amp;gt;Session;&lt;br/&gt;
Node Status;&lt;br/&gt;
{Candidate Router Key}
&lt;p&gt; (Only choose one):&lt;br/&gt;
1.	Object Name (Recommended, it is table name for Hbase, if there isn&apos;t table in the event, Object name is null. If client query metadata from Zookeeper, use hardcode table name to replace. Such as &quot;Hbase Metadata&quot;.)&lt;br/&gt;
2.	HRegion Identity&lt;br/&gt;
3.	RegionServer IP&lt;br/&gt;
4.	Others.....&lt;/p&gt;

{Sub Event Item}
&lt;p&gt;: It depends on the &lt;/p&gt;
{Event Type}
&lt;p&gt;.&lt;br/&gt;
1.	Session (in current Hbase version, it is the connection, establish connection and close connection)&lt;br/&gt;
       Session Login In : &lt;br/&gt;
       Session Login Off:&lt;br/&gt;
2.	Command&lt;br/&gt;
       Command Request&lt;br/&gt;
       Command Response&lt;br/&gt;
3.	Data in Command (interested data from input and output command)&lt;br/&gt;
       Data metadata and content (only)&lt;br/&gt;
4.	Counts In Command&lt;br/&gt;
      Counts Set (only)&lt;br/&gt;
5.	Node Status&lt;br/&gt;
      Performance counts (Resource usage, Session amount, and other performance related counts)&lt;br/&gt;
      Abnormal events (defined by user, normally, it includes error event, huge request in a short time and &lt;br/&gt;
      so on).&lt;/p&gt;


&lt;p&gt;BTW, I suggest try to shorten the routing string and keep the capability of dynamic routing. Fox example:&lt;/p&gt;

&lt;p&gt;2.ObjectName.2.Others  =&amp;gt; it means Command.ObjectName.CommandResponse.Others (string to number is only for predefined type).&lt;/p&gt;</comment>
                            <comment id="13047620" author="stack" created="Fri, 10 Jun 2011 22:46:07 +0000"  >&lt;p&gt;Moving out of 0.92.0. Pull it back in if you think different.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 26 Nov 2009 21:31:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32368</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 27 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hg7j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99888</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>