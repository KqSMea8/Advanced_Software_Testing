<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:46:58 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-728/HBASE-728.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-728] Supporting for HLog appends</title>
                <link>https://issues.apache.org/jira/browse/HBASE-728</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I thank we should open a ticket to track what needs changed to support appends when the coding is done on &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1700&quot; title=&quot;Append to files in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1700&quot;&gt;&lt;del&gt;HADOOP-1700&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12399780">HBASE-728</key>
            <summary>Supporting for HLog appends</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jimk">Jim Kellerman</assignee>
                                    <reporter username="viper799">Billy Pearson</reporter>
                        <labels>
                    </labels>
                <created>Tue, 8 Jul 2008 06:16:14 +0000</created>
                <updated>Sun, 13 Sep 2009 22:26:25 +0000</updated>
                            <resolved>Tue, 28 Oct 2008 01:07:35 +0000</resolved>
                                                    <fixVersion>0.19.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>3</watches>
                                                                                                            <comments>
                            <comment id="12611469" author="viper799" created="Tue, 8 Jul 2008 06:34:42 +0000"  >&lt;p&gt;The Major item needing appends in HBase is HLog so we can handle crashed regional servers with out data loss. Currently we could lose up to 30K updates if a server fails.&lt;/p&gt;

&lt;p&gt;I was thanking we should maybe thank of something like mysql does with innodb database&lt;br/&gt;
innodb_flush_log_at_trx_commit&lt;/p&gt;

&lt;p&gt;Options:&lt;br/&gt;
1 = HLog buffer is flushed to disk with each update.&lt;br/&gt;
2 = HLog buffer is flushed to disk once per second or every x secs.&lt;br/&gt;
3 = HLog buffer is flushed to disk when reached x size.&lt;/p&gt;

&lt;p&gt;Clearly option 1 would be slower per update as we would have to append to the file with each change but that would allow us an option to have zero data loss and options 2-3 would give users option to chose how much data lose would be acceptable for a performance increase.&lt;/p&gt;</comment>
                            <comment id="12617114" author="viper799" created="Sat, 26 Jul 2008 01:51:58 +0000"  >&lt;p&gt;Upgraded to a blocker now that append is supported in hadoop 0.18.0&lt;br/&gt;
I thank this is a #1 for 0.3.0 to make it where we can run with out data loss from hlogs on failed region servers.&lt;/p&gt;</comment>
                            <comment id="12617126" author="stack" created="Sat, 26 Jul 2008 05:16:07 +0000"  >&lt;p&gt;You think we should target hbase 0.3.0 for hadoop 0.19.0 altogether (since 0.2.0 seems to run on hadoop 0.18 &amp;#8211; though we haven&apos;t tested it much).  0.3.0 would be performance + implement appends?&lt;/p&gt;</comment>
                            <comment id="12617179" author="jdcryans" created="Sat, 26 Jul 2008 14:30:45 +0000"  >&lt;p&gt;Maybe we should add appends in the 0.2 branch since it is the one that is supposed to provide more reliability. Once 0.2.0 is out, this should be a priority.&lt;/p&gt;</comment>
                            <comment id="12617193" author="viper799" created="Sat, 26 Jul 2008 16:29:00 +0000"  >&lt;p&gt;I thank they added append to 0.18.0 and we only support 0.17.1 with 0.2.0 we could bump 0.2.0 to 0.18.0&lt;br/&gt;
Might be something to thank about sense we have not release 0.2.0&lt;/p&gt;</comment>
                            <comment id="12617198" author="stack" created="Sat, 26 Jul 2008 17:39:35 +0000"  >&lt;p&gt;J-D: &lt;/p&gt;

&lt;p&gt;hbase can&apos;t fall too far behind hadoop releases.  We need to always have an offering for current hadoops.  If 0.2.0 hbase works on both 0.17 and 0.18 hadoop &amp;#8211; we need to test a little more to be sure &amp;#8211; then we can leapfrog 0.3.0 hbase back on to the hadoop TRUNK.  More work on 0.2.0 I&apos;m afraid will just have us falling further behind.  Also, will exploiting the append additions to hadoop 0.18 in hbase 0.2.0 make it so it we&apos;re not API compatible with hadoop 0.17 (I may be wrong on the latter but I seem to recall rework of flush API).&lt;/p&gt;

&lt;p&gt;Billy:&lt;/p&gt;

&lt;p&gt;Though 0.17 hadoop seems to be slower than 0.16, IMO, we should have an hbase for all hadoop versions.&lt;/p&gt;</comment>
                            <comment id="12617202" author="jdcryans" created="Sat, 26 Jul 2008 18:10:12 +0000"  >&lt;p&gt;stack, I totally agree. In fact, by saying 0.2 branch and not 0.2.0, I meant to release the append feature for a minor version. I also totally agree that there should be an HBase for all hadoop versions; I think we should even release as often as them even if it&apos;s for a small set of features. A strong argument for this is current migration to 0.2.0 which speaks for itself.&lt;/p&gt;</comment>
                            <comment id="12617232" author="viper799" created="Sun, 27 Jul 2008 02:57:33 +0000"  >&lt;p&gt;If we plan on releasing for each version then we need to be looking to do a feature freeze on 0.3.0 soon so we can roll it out fast and start work on 0.4.0 that will tagged for 0.19.0&lt;/p&gt;</comment>
                            <comment id="12624459" author="viper799" created="Thu, 21 Aug 2008 19:47:27 +0000"  >&lt;p&gt;Re reading bigtable paper found this&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
To protect mutations from GFS latency spikes,
each tablet server actually has two log writing threads,
each writing to its own log le; only one of these two
threads is actively in use at a time. If writes to the active
log le are performing poorly, the log le writing is
switched to the other thread, and mutations that are in
the commit log queue are written by the newly active log
writing thread. Log entries contain sequence numbers
to allow the recovery process to elide duplicated entries
resulting from &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; log switching process.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12624473" author="jimk" created="Thu, 21 Aug 2008 20:49:46 +0000"  >&lt;p&gt;It is unlikely that we will implement dual log writing threads for the first release that uses hadoop append.&lt;/p&gt;

&lt;p&gt;We don&apos;t know anything about the performance of append at this point, and writing the HLog is not a bottleneck at this time.&lt;/p&gt;</comment>
                            <comment id="12624537" author="viper799" created="Fri, 22 Aug 2008 02:48:01 +0000"  >&lt;p&gt;I know just adding ideas on this so when we start adding this option we have thing we cna thank on and test if we run in to bottlenecks in the append feature&lt;/p&gt;</comment>
                            <comment id="12624872" author="jimk" created="Fri, 22 Aug 2008 15:35:54 +0000"  >&lt;p&gt;Good point, Billy, thanks for writing this down so we don&apos;t lose it.&lt;/p&gt;

&lt;p&gt;Later on, we may want to make this a separate issue.&lt;/p&gt;</comment>
                            <comment id="12642039" author="jimk" created="Thu, 23 Oct 2008 02:37:06 +0000"  >&lt;p&gt;Before resolving this issue, I will investigate &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-888&quot; title=&quot;NPE in HLog.append -&amp;gt; DroppedSnapshotException causes hosed regionserver&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-888&quot;&gt;&lt;del&gt;HBASE-888&lt;/del&gt;&lt;/a&gt;. It may no longer be an issue.&lt;/p&gt;

&lt;p&gt;In the mean time, if you are on trunk, enjoy reliable and faster HBase.&lt;/p&gt;</comment>
                            <comment id="12642045" author="stack" created="Thu, 23 Oct 2008 03:53:31 +0000"  >&lt;p&gt;I made comments against the hbase-dev mail message.&lt;/p&gt;</comment>
                            <comment id="12642046" author="stack" created="Thu, 23 Oct 2008 03:54:02 +0000"  >&lt;p&gt;Oh, ain&apos;t the fact that we now have appends a reason to go drinking?&lt;/p&gt;</comment>
                            <comment id="12642525" author="jimk" created="Fri, 24 Oct 2008 19:35:36 +0000"  >&lt;p&gt;&amp;gt; From: Michael Stack &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;mailto:stack@duboce.net&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;stack@duboce.net&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/mail_small.gif&quot; height=&quot;12&quot; width=&quot;13&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;
&amp;gt; Sent: Wednesday, October 22, 2008 8:53 PM&lt;br/&gt;
&amp;gt; To: hbase-dev@hadoop.apache.org&lt;br/&gt;
&amp;gt; Subject: Re: svn commit: r707247 - in /hadoop/hbase/trunk: ./ conf/ &lt;br/&gt;
&amp;gt; src/java/org/apache/hadoop/hbase/regionserver/&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; How does new feature effect hbase throughput?  Does it make it slower?&lt;br/&gt;
&amp;gt; Faster?  Any measurement done?&lt;/p&gt;

&lt;p&gt;I measured PerformanceEvaluation random write 1 with one region server&lt;br/&gt;
before and after the appends patch.&lt;/p&gt;

&lt;p&gt;I would say that throughput is either the same or a little faster.&lt;/p&gt;

&lt;p&gt;I only ran one run on the code before appends, and this test completed&lt;br/&gt;
in 2 minutes 31 seconds&lt;/p&gt;

&lt;p&gt;In fixing up a couple of bugs in appends, I have run this test 5 times.&lt;br/&gt;
The slowest was 2 minutes 33 seconds, but the other times were all faster:&lt;br/&gt;
2:24, 2:20, 2:21 and 2:21.&lt;/p&gt;

&lt;p&gt;&amp;gt;  Do appends work for hbase?  Did you try crashing an hbase server and&lt;br/&gt;
&amp;gt; see if it comes back up with only a few edits lost?&lt;/p&gt;

&lt;p&gt;Yes, after fixing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-952&quot; title=&quot;Deadlock in HRegion.batchUpdate&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-952&quot;&gt;&lt;del&gt;HBASE-952&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-954&quot; title=&quot;Don&amp;#39;t reassign root region until ProcessServerShutdown has split the former region server&amp;#39;s log&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-954&quot;&gt;&lt;del&gt;HBASE-954&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; I was thinking that the size of the log file is a better measure of &lt;br/&gt;
&amp;gt; when to rotate given that there can be a wide divergence in WAL log &lt;br/&gt;
&amp;gt; file size but maybe not given that flush sequenceids are pegged &lt;br/&gt;
&amp;gt; against a particular edit.&lt;/p&gt;

&lt;p&gt;This could be done either way and I have no preference. With the default&lt;br/&gt;
settings, running PerformanceEvaluation random write 1 with one region&lt;br/&gt;
server, the HLogs were about 160MB. It might be nice to use the file size&lt;br/&gt;
so we can get closer to a multiple of HDFS block size. Doing so, might&lt;br/&gt;
be better in the general case, which is any application except&lt;br/&gt;
PerformanceEvaluation. In some cases, we might put more updates into a&lt;br/&gt;
log (if keys and values are small), and in others we might put fewer&lt;br/&gt;
(when keys and values are large). Being close to a multiple of HDFS block&lt;br/&gt;
size is probably a good thing, so I am kind of leaning toward log size&lt;br/&gt;
instead of number of updates. What do others think?&lt;/p&gt;

&lt;p&gt;&amp;gt; I like how Flusher has had a bunch of code purged.&lt;/p&gt;

&lt;p&gt;Without the time based cache flush and the time based log roll, yes things&lt;br/&gt;
have gotten simpler and we don&apos;t end up creating small MapFiles or small&lt;br/&gt;
log files.&lt;/p&gt;

&lt;p&gt;&amp;gt; We have convention naming threads.  Its name of server &amp;#8211; &lt;br/&gt;
&amp;gt; master/regionserver host and port &amp;#8211; followed by the what thread does &lt;br/&gt;
&amp;gt; (This used to be hlog?  Or log?).  Makes it easy sorting them out in &lt;br/&gt;
&amp;gt; thread dump.&lt;/p&gt;

&lt;p&gt;Currently the thread is named HLog. Would it be preferable to name it&lt;br/&gt;
&amp;lt;servername&amp;gt;.Hlog ? Log entries only appear in one region server&apos;s log.&lt;br/&gt;
Does it matter?&lt;/p&gt;

&lt;p&gt;&amp;gt; Should this Log thread inherit from Chore?&lt;/p&gt;

&lt;p&gt;Currently only the root, meta scanners and CleanOldTransactions (in&lt;br/&gt;
regionserver.transactional) extend chore. This change was made a while&lt;br/&gt;
back, but I can&apos;t remember why. Should all the threads in HRS and HMaster&lt;br/&gt;
extend Chore? We would need to add the &quot;interrupt politely&quot; method,&lt;br/&gt;
but I can&apos;t think of a reason we shouldn&apos;t do this (as a separate Jira).&lt;/p&gt;

&lt;p&gt;&amp;gt; There is a place in HRS where all service threads are started.   Now&lt;br/&gt;
&amp;gt; HLog is a Thread, should it be moved in there? Into startServiceThreads?&lt;/p&gt;

&lt;p&gt;Currently, the HLog thread is started by HRS.setupHLog. Since it is called&lt;br/&gt;
from multiple locations, moving the thread start to startServiceThreads,&lt;br/&gt;
would involve extra synchronization. &lt;/p&gt;

&lt;p&gt;However I note that the HLog thread is not set to be a daemon thread, which&lt;br/&gt;
should probably be fixed.&lt;/p&gt;

</comment>
                            <comment id="12642554" author="jdcryans" created="Fri, 24 Oct 2008 22:15:41 +0000"  >&lt;p&gt;Testing with  hbase.regionserver.flushlogentries=1 on 1 client and one HRS doesn&apos;t give bigger or smaller numbers. Would need to be tested on a cluster.&lt;/p&gt;</comment>
                            <comment id="12643066" author="jimk" created="Mon, 27 Oct 2008 21:22:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-956&quot; title=&quot;Master and region server threads should extend Chore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-956&quot;&gt;&lt;del&gt;HBASE-956&lt;/del&gt;&lt;/a&gt; Master and region server threads should extend Chore&lt;/p&gt;

&lt;p&gt;Chore: Note that chores are repetitive tasks that do not wake up when there is work to be done.&lt;/p&gt;

&lt;p&gt;Leases: are not Chores, because they wait on a DelayQueue rather than doing the same thing.&lt;/p&gt;

&lt;p&gt;HMaster: is not a Chore because the run loop waits for an entry on the toDoQueue or delayedToDoQueue&lt;/p&gt;

&lt;p&gt;CompactSplitThred: is not a Chore because it waits for compaction requests&lt;/p&gt;

&lt;p&gt;HLog: neither a Thread nor a Chore. It is now just an object which manages the HLog&lt;/p&gt;

&lt;p&gt;LogRoller is a Thread and not a Chore because it waits for log roll requests.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-955&quot; title=&quot;Stop HLog thread before starting a new one&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-955&quot;&gt;&lt;del&gt;HBASE-955&lt;/del&gt;&lt;/a&gt; Stop HLog thread before starting a new one&lt;/p&gt;

&lt;p&gt;No longer applies as HLog is neither a Thread nor a Chore. HLog has new method HLog.optionalSync.&lt;/p&gt;

&lt;p&gt;HRegionServer:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;starts new Chore which is LogFlusher. Thread is named consistantly with other threads, region server tells the LogFlusher whenever the HLog object changes.&lt;/li&gt;
	&lt;li&gt;renamed Flusher to MemcacheFlusher so it would not be confused with LogFlusher&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Rename Flusher to MemcacheFlusher&lt;/p&gt;

&lt;p&gt;New Chore LogFlusher. Allows client (HRegionServer) to change the HLog instance being used, calls HLog.optionalSync() every threadWakeInterval.&lt;/p&gt;</comment>
                            <comment id="12643111" author="jimk" created="Tue, 28 Oct 2008 01:06:06 +0000"  >&lt;p&gt;Moved &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-888&quot; title=&quot;NPE in HLog.append -&amp;gt; DroppedSnapshotException causes hosed regionserver&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-888&quot;&gt;&lt;del&gt;HBASE-888&lt;/del&gt;&lt;/a&gt; out to separate issue as it is not clear it still is applicable.&lt;/p&gt;</comment>
                            <comment id="12643112" author="jimk" created="Tue, 28 Oct 2008 01:07:35 +0000"  >&lt;p&gt;Resolving issue as all sub-issues have been resolved. If &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-888&quot; title=&quot;NPE in HLog.append -&amp;gt; DroppedSnapshotException causes hosed regionserver&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-888&quot;&gt;&lt;del&gt;HBASE-888&lt;/del&gt;&lt;/a&gt; is still an issue, it will be dealt with separately.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12398550">HBASE-698</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12401197">HBASE-784</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="12407111">HBASE-952</subtask>
                            <subtask id="12407188">HBASE-954</subtask>
                            <subtask id="12407206">HBASE-955</subtask>
                            <subtask id="12407208">HBASE-956</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 26 Jul 2008 05:16:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>31826</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 8 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h933:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98734</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>