<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:45:23 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-554/HBASE-554.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-554] filters generate StackOverflowException</title>
                <link>https://issues.apache.org/jira/browse/HBASE-554</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Below is from list.&lt;/p&gt;

&lt;p&gt;You&apos;re doing nothing wrong.&lt;/p&gt;

&lt;p&gt;The filters as written recurse until they find a match.  If long stretches between matching rows, then you will get a StackOverflowError.  Filters need to be changed.  Thanks for pointing this out.  Can you do without them for the moment until we get a chance to fix it?&lt;/p&gt;

&lt;p&gt;St.Ack&lt;/p&gt;

&lt;p&gt;David Alves wrote:&lt;br/&gt;
&amp;gt; Hi St.Ack and all&lt;br/&gt;
&amp;gt; 	&lt;br/&gt;
&amp;gt; 	The error always occurs when trying to see if there are more rows to&lt;br/&gt;
&amp;gt; process.&lt;br/&gt;
&amp;gt; 	Yes I&apos;m using a filter(RegExpRowFilter) to select only the rows (any&lt;br/&gt;
&amp;gt; row key) that match a specific value in one of the columns.&lt;br/&gt;
&amp;gt; 	Then I obtain the scanner just test the hasNext method, close the&lt;br/&gt;
&amp;gt; scanner and return.&lt;br/&gt;
&amp;gt; 	Am I doing something wrong?&lt;br/&gt;
&amp;gt; 	Still StackOverflowError is not supposed to happen right?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Regards&lt;br/&gt;
&amp;gt; David Alves&lt;br/&gt;
&amp;gt; On Thu, 2008-03-27 at 12:36 -0700, stack wrote:&lt;br/&gt;
&amp;gt;&amp;gt; You are using a filter?  If so, tell us more about it.&lt;br/&gt;
&amp;gt;&amp;gt; St.Ack&lt;br/&gt;
&amp;gt;&amp;gt;&lt;br/&gt;
&amp;gt;&amp;gt; David Alves wrote:&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; Hi guys &lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; 	I &apos;m using HBase to keep data that is later indexed.&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; 	The data is indexed in chunks so the cycle is get XXXX records index&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; them check for more records etc...&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; 	When I tryed the candidate-2 instead of the old 0.16.0 (which I&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; switched to do to the regionservers becoming unresponsive) I got the&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; error in the end of this email well into an indexing job.&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; 	So you have any idea why? Am I doing something wrong?&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; David Alves&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException:&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; java.io.IOException: java.lang.StackOverflowError&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at java.io.DataInputStream.readFully(DataInputStream.java:178)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at java.io.DataInputStream.readLong(DataInputStream.java:399)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.dfs.DFSClient&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $BlockReader.readChunk(DFSClient.java:735)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:234)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:176)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:193)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:157)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.dfs.DFSClient&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $BlockReader.read(DFSClient.java:658)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.dfs.DFSClient&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $DFSInputStream.readBuffer(DFSClient.java:1130)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.dfs.DFSClient&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $DFSInputStream.read(DFSClient.java:1166)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at java.io.DataInputStream.readFully(DataInputStream.java:178)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.io.DataOutputBuffer&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $Buffer.write(DataOutputBuffer.java:56)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:90)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.io.SequenceFile&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $Reader.next(SequenceFile.java:1829)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.io.SequenceFile&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $Reader.next(SequenceFile.java:1729)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.io.SequenceFile&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $Reader.next(SequenceFile.java:1775)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:461)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HStore&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $StoreFileScanner.getNext(HStore.java:2350)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; org.apache.hadoop.hbase.HAbstractScanner.next(HAbstractScanner.java:256)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HStore&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HStoreScanner.next(HStore.java:2561)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1807)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;         at org.apache.hadoop.hbase.HRegion&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; $HScanner.next(HRegion.java:1843)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; ...&lt;/p&gt;</description>
                <environment></environment>
        <key id="12392679">HBASE-554</key>
            <summary>filters generate StackOverflowException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jimk">Jim Kellerman</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Sun, 30 Mar 2008 20:36:43 +0000</created>
                <updated>Sat, 12 Apr 2008 16:12:05 +0000</updated>
                            <resolved>Tue, 8 Apr 2008 18:58:24 +0000</resolved>
                                    <version>0.16.0</version>
                    <version>0.1.0</version>
                    <version>0.2.0</version>
                                    <fixVersion>0.1.1</fixVersion>
                    <fixVersion>0.2.0</fixVersion>
                                    <component>Filters</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12583935" author="clint.morgan" created="Mon, 31 Mar 2008 23:41:01 +0000"  >&lt;p&gt;The culprit is in the last patch I submitted. Upon filtering an assembled row, it recursively calls next. Technically this is a tail-rec call, but I guess not all compilers will recognize this.&lt;/p&gt;

&lt;p&gt;This patch uses explicit iteration instead. Let me know if it works for you...&lt;/p&gt;</comment>
                            <comment id="12583940" author="stack" created="Mon, 31 Mar 2008 23:47:29 +0000"  >&lt;p&gt;Clint: Want to write the list in case Dave Alves is not watching this issue telling him you made a possible fix?  (Thanks for the patch).&lt;/p&gt;</comment>
                            <comment id="12585666" author="clint.morgan" created="Fri, 4 Apr 2008 17:54:59 +0000"  >&lt;p&gt;My last patch was missing part of the header, and so eclipse would not apply it. This fixes it.&lt;/p&gt;</comment>
                            <comment id="12586929" author="jimk" created="Tue, 8 Apr 2008 18:58:24 +0000"  >&lt;p&gt;Committed to 0.1 branch and trunk&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12379415" name="hbase-554-v2.patch" size="5262" author="clint.morgan" created="Fri, 4 Apr 2008 17:54:59 +0000"/>
                            <attachment id="12378988" name="hbase-554.patch" size="5103" author="clint.morgan" created="Mon, 31 Mar 2008 23:41:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 31 Mar 2008 23:41:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25262</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 37 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h80f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98560</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>