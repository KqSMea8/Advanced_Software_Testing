<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:20:56 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-4662/HBASE-4662.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-4662] Replay the required hlog edits to make the backup preserve row atomicity.</title>
                <link>https://issues.apache.org/jira/browse/HBASE-4662</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The algorithm is as follows:&lt;/p&gt;

&lt;p&gt;A. For HFiles:&lt;br/&gt;
1. Need to track t1,t2 for each backup (start and end times of the backup)&lt;br/&gt;
2. For point in time restore to time t, pick a HFile snapshot which has t2 &amp;lt; t&lt;br/&gt;
3. Copy HFile snapshot to a temp location - HTABLE_RESTORE_t&lt;/p&gt;

&lt;p&gt;B. For HLogs:&lt;br/&gt;
for each regionserver do&lt;br/&gt;
  for .logs and .oldlogs do&lt;br/&gt;
1. log file is hlog.TIME&lt;br/&gt;
2. if (t &amp;gt; TIME and hlog.TIME is open for write) fail restore for t&lt;br/&gt;
3. Pick the latest HLog whose create time is &amp;lt; t1&lt;br/&gt;
4. Pick all HLogs whose create time is &amp;gt; t1 and &amp;lt;= t2&lt;br/&gt;
5. Copy hlogs to the right structures inside HTABLE_RESTORE_t&lt;/p&gt;

&lt;p&gt;C. Split logs&lt;br/&gt;
1. Enhance HLog.splitLog to take timestamp t&lt;br/&gt;
2. Enhance distributed log split tool to pass HTABLE_RESTORE_t, so that log split is picked up and put in the right location&lt;br/&gt;
3. Enhance distributed log split tool to pass t so that all edits till t are included and others ignored&lt;/p&gt;

&lt;p&gt;D. Import the directory into the running HBase with META entries, etc (this already exists)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12528615">HBASE-4662</key>
            <summary>Replay the required hlog edits to make the backup preserve row atomicity.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12527765">HBASE-4618</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="4">Incomplete</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="karthik.ranga">Karthik Ranganathan</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Oct 2011 04:50:38 +0000</created>
                <updated>Wed, 22 Apr 2015 00:44:43 +0000</updated>
                            <resolved>Wed, 22 Apr 2015 00:44:43 +0000</resolved>
                                                                    <component>documentation</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13166670" author="lhofhansl" created="Fri, 9 Dec 2011 23:36:52 +0000"  >&lt;p&gt;Thanks for writing this up!&lt;/p&gt;

&lt;p&gt;I had a few questions:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;How do you currently back up your HLogs? Do you have a process that watches .&lt;span class=&quot;error&quot;&gt;&amp;#91;old&amp;#93;&lt;/span&gt;logs and copies/archives every new file appearing there?&lt;/li&gt;
	&lt;li&gt;How do you back up the HFiles? Do you issue a flush before you do this?&lt;/li&gt;
	&lt;li&gt;That tool you mention in D. Is not completebulkload, right? Will that tool deal with replaying the logs you placed in B.5.?&lt;/li&gt;
	&lt;li&gt;I found that distributed log splitting relies on region names in the HLog in order to do the splitting. If any region splits happened after the HLog was written, or this is a new table, the replay will fail for regions that do no longer exist. Do you plan to change the distributed log splitter to deal with this? (It would need to map the rowkeys back to the now-current set of regions.)&lt;/li&gt;
	&lt;li&gt;HLogs have entries of many tables. In the approach above whatever replays the log would need to only replay those entries pertaining to the HFiles copied over, right?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thanks again...&lt;/p&gt;</comment>
                            <comment id="13217682" author="karthik.ranga" created="Mon, 27 Feb 2012 23:20:41 +0000"  >&lt;p&gt;Missed this one:&lt;/p&gt;


&lt;p&gt;&amp;lt;&amp;lt; How do you currently back up your HLogs? Do you have a process that watches .&lt;span class=&quot;error&quot;&gt;&amp;#91;old&amp;#93;&lt;/span&gt;logs and copies/archives every new file appearing there? &amp;gt;&amp;gt;&lt;br/&gt;
We have written a taskframework (code name &apos;cassini&apos;). The framework is logically the equivalent of a distributed-threadpool. It manages N worker threads (one per regionserver) across M machines (destination backup machines for example) using ZK as the persistent store for the queue of tasks. It can run plugins that are coded to some requirements to do arbitrary work. That framework has a plugin which we have implemented to tail and play logs. Will put that one out soon.&lt;/p&gt;

&lt;p&gt;&amp;lt;&amp;lt; How do you back up the HFiles? Do you issue a flush before you do this?&lt;br/&gt;
That tool you mention in D. Is not completebulkload, right? Will that tool deal with replaying the logs you placed in B.5.? &amp;gt;&amp;gt;&lt;br/&gt;
The above 2 are in the diff. Yes, we issue a flush, and there is a custom tool. HLog replays are not done yet, we have an initial diff which we have not yet productized.&lt;/p&gt;

&lt;p&gt;&amp;lt;&amp;lt; I found that distributed log splitting relies on region names in the HLog in order to do the splitting. If any region splits happened after the HLog was written, or this is a new table, the replay will fail for regions that do no longer exist. Do you plan to change the distributed log splitter to deal with this? (It would need to map the rowkeys back to the now-current set of regions.) &amp;gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;&amp;lt; HLogs have entries of many tables. In the approach above whatever replays the log would need to only replay those entries pertaining to the HFiles copied over, right? &amp;gt;&amp;gt;&lt;br/&gt;
Yes, and potentially take care of changed table names (export from table A, import as table B).&lt;/p&gt;</comment>
                            <comment id="13217709" author="zhihyu@ebaysf.com" created="Mon, 27 Feb 2012 23:55:46 +0000"  >&lt;p&gt;The taskframework (&apos;cassini&apos;) is interesting and maybe useful to implement region deletion - see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4991&quot; title=&quot;Provide capability to delete named region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4991&quot;&gt;&lt;del&gt;HBASE-4991&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;How does cassini handle failure scenarios ?&lt;/p&gt;</comment>
                            <comment id="13217926" author="karthik.ranga" created="Tue, 28 Feb 2012 05:49:04 +0000"  >&lt;p&gt;Lots of discussion on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4991&quot; title=&quot;Provide capability to delete named region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4991&quot;&gt;&lt;del&gt;HBASE-4991&lt;/del&gt;&lt;/a&gt;... could someone update the description of the JIRA to more accurately reflect the intent? (Didnt read through all the discussion, but the following questions come to mind: Is it just &quot;delete regions in HBase&quot;? Is that similar to merge - then why not use merge? etc so not sure how this can be used there)&lt;/p&gt;

&lt;p&gt;&amp;lt;&amp;lt; How does cassini handle failure scenarios ? &amp;gt;&amp;gt;&lt;br/&gt;
The various processes leader elect among themselves - one of them is the master. It moves tasks that are assigned to failed processes to unassigned state after a timeout.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 9 Dec 2011 23:36:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>214475</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 42 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hrpr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101752</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>