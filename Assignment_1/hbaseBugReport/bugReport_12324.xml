<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:31:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12324/HBASE-12324.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12324] Improve compaction speed and process for immutable short lived datasets</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12324</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We have seen multiple cases where HBase is used to store immutable data and the data lives for short period of time (few days)&lt;br/&gt;
On very high volume systems, major compactions become very costly and slowdown ingestion rates.&lt;br/&gt;
In all such use cases (immutable data, high write rate and moderate read rates and shorter ttl), avoiding any compactions and just deleting old data brings lot of performance benefits.&lt;/p&gt;

&lt;p&gt;We should have a compaction policy that can only delete/archive files older than TTL and not compact any files.&lt;/p&gt;

&lt;p&gt;Also attaching a patch that can do so.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12749883">HBASE-12324</key>
            <summary>Improve compaction speed and process for immutable short lived datasets</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sheetal_dolas">Sheetal Dolas</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Oct 2014 21:02:42 +0000</created>
                <updated>Wed, 29 Oct 2014 16:25:59 +0000</updated>
                                            <version>0.98.0</version>
                    <version>0.96.0</version>
                                                    <component>Compaction</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                <comments>
                            <comment id="14180539" author="vrodionov" created="Wed, 22 Oct 2014 21:10:18 +0000"  >&lt;p&gt;FIFO compaction? Purge oldest files? &lt;/p&gt;</comment>
                            <comment id="14181317" author="busbey" created="Thu, 23 Oct 2014 13:23:33 +0000"  >&lt;p&gt;In the case where we have  table-wide TTL, is there any reason not to just do a delete-only optimization in the general compaction policy?&lt;/p&gt;

&lt;p&gt;We could add to the fixed trailer the newest timestamp of all the cells in the HFile.&lt;/p&gt;</comment>
                            <comment id="14183131" author="vrodionov" created="Fri, 24 Oct 2014 17:52:34 +0000"  >&lt;p&gt;Sean,&lt;/p&gt;

&lt;p&gt;You can effectively disable compaction by setting the following config:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    conf.setLong(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hregion.max.filesize&quot;&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.MAX_VALUE);
    conf.setLong(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hregion.memstore.flush.size&quot;&lt;/span&gt;, FLUSH_SIZE);
    conf.setInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hstore.compactionThreshold&quot;&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE);
    conf.setInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hstore.blockingStoreFiles&quot;&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE); 
    conf.setInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hstore.compaction.min&quot;&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE);
    conf.setInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.hstore.compaction.max&quot;&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;If you do not need compaction , you can have only few (even one) regions per server&lt;/li&gt;
	&lt;li&gt;Make sure pre-split your table&lt;/li&gt;
	&lt;li&gt;Run periodically utility which purge/archive the oldest HFiles&lt;/li&gt;
	&lt;li&gt;FLUSH_SIZE should be large enough but not that extreme. Because you can afford hosting very few regions per RS , your flush size can be quite large.&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="14183188" author="busbey" created="Fri, 24 Oct 2014 18:13:26 +0000"  >&lt;p&gt;Sure, but I&apos;d rather we have an optimization in place that can improve this workload without requiring niche tuning and special operational handling. Especially if these datasets need to live in an hbase cluster with others that don&apos;t share the same properties.&lt;/p&gt;</comment>
                            <comment id="14183287" author="sheetal_dolas" created="Fri, 24 Oct 2014 19:01:42 +0000"  >&lt;p&gt;Sean, Vlad,&lt;/p&gt;

&lt;p&gt;Thanks for your inputs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;, in our case already had all those params tuned , however the expired data must get deleted. Which utility are you referring to ? Can one run that while tables are active and data being ingested?&lt;br/&gt;
IMO Adding external utilities is error prone and operational overhead. So it would be nice if it is inside HBase. Also as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt; pointed out, tuning these parameter needs careful evaluation and need for niche expertise.&lt;/p&gt;

&lt;p&gt;It would be nice if HBase itself can take care of complexities and make it easy for users/operators. I can see multiple use cases including Open TSDB which need this to be handled elegantly.&lt;/p&gt;

&lt;p&gt;Let me add some more details to the use case and proposed solution.&lt;br/&gt;
Use case:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Very high ingest rate.&lt;/li&gt;
	&lt;li&gt;Immutable data&lt;/li&gt;
	&lt;li&gt;Data life is short (few days)&lt;/li&gt;
	&lt;li&gt;Read rates are low to moderate (in comparison to ingest rates)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Issues with default major compaction (even when compactions are done rarely)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Lot of data IO just to get out expired data out&lt;/li&gt;
	&lt;li&gt;No other significant benefits then expired data deletion&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Proposed solution&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;During major (or even minor) compactions, do not compact any data&lt;/li&gt;
	&lt;li&gt;Just delete files whose timestamp is older than TTL&lt;/li&gt;
	&lt;li&gt;Add a new compaction policy class say &quot;OnlyDeleteExpiredFilesCompactionPolicy&quot; and set these configurations while creating the table.&lt;br/&gt;
&apos;hbase.hstore.defaultengine.compactionpolicy.class&apos; =&amp;gt; &apos;org.apache.hadoop.hbase.regionserver.compactions.OnlyDeleteExpiredFilesCompactionPolicy&apos;, &apos;hbase.store.delete.expired.storefile&apos; =&amp;gt; &apos;true&apos; &lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Benefits&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Significant reduction in IO during compaction&lt;/li&gt;
	&lt;li&gt;Automatically get rid of expired data&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Assumptions and applicability&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;TTL is defined at table level or for all CFs in table&lt;/li&gt;
	&lt;li&gt;Cells use system timestamp for versioning or if overwritten, the overwritten timestamp is closer to system timestamp&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Attached proposed compaction policy. It appears trivially simple. Thoughts?&lt;/p&gt;</comment>
                            <comment id="14183311" author="busbey" created="Fri, 24 Oct 2014 19:08:33 +0000"  >&lt;p&gt;Relying on the file timestamp seems problematic.&lt;/p&gt;

&lt;p&gt;Do you have a specific concern with adding the optional trailer item about cell timestamps present? It would allow us to generalize that part of the optimization to other policies.&lt;/p&gt;</comment>
                            <comment id="14183337" author="sheetal_dolas" created="Fri, 24 Oct 2014 19:21:15 +0000"  >&lt;p&gt;The only issue I see with TS is if old data come late. But in those cases, the data will get deleted later which seems same as running major compaction late.&lt;/p&gt;

&lt;p&gt;Do you mean to say that every file will have latest timestamp of any cell in it. And we could use that TS to identify files to delete instead of looking at file timestamp ? That sounds interesting.&lt;/p&gt;</comment>
                            <comment id="14183342" author="busbey" created="Fri, 24 Oct 2014 19:26:08 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The only issue I see with TS is if old data come late. But in those cases, the data will get deleted later which seems same as running major compaction late.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s actually worse than that, because the clock could adjust and we could have a file timestamp that is older than the cell timestamps within it. That would result in deleting data that isn&apos;t yet expired. (presuming the timestamp will be set based on when the server calls close())&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Do you mean to say that every file will have latest timestamp of any cell in it. And we could use that TS to identify files to delete instead of looking at file timestamp ? That sounds interesting.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes exactly, we use protobufs and  have a bunch of padded space in the fixed trailer so that we can make optimizations without having to increment the file version. We already track some other cell stats as we make a file, seems like adding the info about the timestamps inside the file should be straight forward.&lt;/p&gt;</comment>
                            <comment id="14183343" author="sheetal_dolas" created="Fri, 24 Oct 2014 19:26:23 +0000"  >&lt;p&gt;So probably removeUnneededFiles method of HStore can be modified to check for the trailer ts and use it to decide files to be deleted. If not present rely back on file TS.&lt;br/&gt;
This way it will be compatible with older data as well.&lt;/p&gt;</comment>
                            <comment id="14183355" author="ndimiduk" created="Fri, 24 Oct 2014 19:33:30 +0000"  >&lt;p&gt;I believe OpenTSDB is commonly used as a metrics archival tool as well, so retaining data for months or years will quickly accumulate small HFIles using this scheme. I believe its data is otherwise consistent with your assumptions. You need to be very careful with your flush sizes to avoid a small file problem. As Sean says, I&apos;d prefer to see less operational overhead push to users, not more. It would be interesting to see an &quot;ImmutableRealtimeTimeSeriesCompactionPolicy&quot; that will compact small files when some threshold is exceeded but otherwise defer to simply expiring files as you do here.&lt;/p&gt;

&lt;p&gt;Another question: in this schema, does the rowkey contain the data&apos;s timestamp? Are you just using HBase cell version for storing your temporal attribute? StripeCompactionPolicy is explicitly addressing the former case (because stripe boundaries are identified by rowkey ranges.&lt;/p&gt;</comment>
                            <comment id="14183370" author="sheetal_dolas" created="Fri, 24 Oct 2014 19:51:16 +0000"  >&lt;p&gt;Makes sense to me. Some cases may still need some sort of compaction (though ours did not as we already had other params tuned as we could not afford frequent minor compactions to support million ingests per second)&lt;br/&gt;
So more informed decision based on number of files at hand (and possibly configurations for advanced user to delay or totally turn compactions off but enable only deletes) can make it usable for multiple situations.&lt;/p&gt;

&lt;p&gt;In our case we did not have TS in key. TS was only in cell version.&lt;/p&gt;</comment>
                            <comment id="14183477" author="vrodionov" created="Fri, 24 Oct 2014 21:00:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;IMO Adding external utilities is error prone and operational overhead.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;May be ( it will take a couple hours to write and debug such utils), I just described how would I approach this use case without changing a single line of code in HBase.  But, in general, I agree that immutable data (tables, CFs) must be treated as separate class citizen in HBase.&lt;/p&gt;</comment>
                            <comment id="14183485" author="vrodionov" created="Fri, 24 Oct 2014 21:03:17 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The only issue I see with TS is if old data come late&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There is no issue here. You will never read this stale data back unles you have MIN_VERSIONS &amp;gt; 0 for that CF.&lt;/p&gt;</comment>
                            <comment id="14183494" author="ndimiduk" created="Fri, 24 Oct 2014 21:10:30 +0000"  >&lt;p&gt;What I&apos;m hearing is that it could be interesting to be able to flag a table or column family as &quot;immutable&quot;. This combined with a TTL setting can allow for significant compaction optimizations. Next steps would be to enable such a configuration and write an integration test that demonstrates the benefit of this configuration.&lt;/p&gt;</comment>
                            <comment id="14183518" author="vrodionov" created="Fri, 24 Oct 2014 21:20:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What I&apos;m hearing is that it could be interesting to be able to flag a table or column family as &quot;immutable&quot;. This combined with a TTL setting can allow for significant compaction optimizations. Next steps would be to enable such a configuration and write an integration test that demonstrates the benefit of this configuration.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Benefits:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Constant sustained write rate which does not decreases over time. All DB systems that do not update data in - place and relies on a compaction to merge delete/updates suffer badly when data set size becomes larger and larger. Sustained write rate decreases significantly over time (anti -logarithmically)&lt;/li&gt;
	&lt;li&gt;A lot of optimizations can be done on a read path as well (no need to keep track for deleted cell, for example)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14183520" author="enis" created="Fri, 24 Oct 2014 21:21:06 +0000"  >&lt;p&gt;This compaction policy makes sense with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10141&quot; title=&quot;instead of putting expired store files thru compaction, just archive them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10141&quot;&gt;&lt;del&gt;HBASE-10141&lt;/del&gt;&lt;/a&gt; I think. Given the use case, it disables compactions effectively, but still lets TTL do the job. The problem with disable compactions using regular configuration is that, only compaction will get rid of hfiles, so disabling compactions will not expire any files. With this compaction policy, we trigger compactions, but the compaction selection will not select any files. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Run periodically utility which purge/archive the oldest HFiles&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;BTW, you cannot delete a file under the region using an external tool if the region is being served (table enabled, hbase cluster running).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It&apos;s actually worse than that, because the clock could adjust and we could have a file timestamp that is older than the cell timestamps within it. That would result in deleting data that isn&apos;t yet expired. (presuming the timestamp will be set based on when the server calls close())&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is how TTL&apos;s work in HBase. The RS compares the max TS of the file / cell with the current timestamp. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;You will never read this stale data back unles you have MIN_VERSIONS &amp;gt; 0 for that CF.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10141&quot; title=&quot;instead of putting expired store files thru compaction, just archive them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10141&quot;&gt;&lt;del&gt;HBASE-10141&lt;/del&gt;&lt;/a&gt; and MIN_VERSIONS &amp;gt; 0 is incompatible. We may need to address / document that. &lt;/p&gt;</comment>
                            <comment id="14183542" author="vrodionov" created="Fri, 24 Oct 2014 21:28:43 +0000"  >&lt;blockquote&gt;
&lt;p&gt;BTW, you cannot delete a file under the region using an external tool if the region is being served (table enabled, hbase cluster running).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am pretty sure that the system will remain in operable state. Some HFileReaders will fail, of course.&lt;/p&gt;</comment>
                            <comment id="14188518" author="sheetal_dolas" created="Wed, 29 Oct 2014 16:25:59 +0000"  >&lt;p&gt;So to consolidate all inputs and comments, here is what I see&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;All compactions (including striped compactions) already have logic to delete TTL expired files  when &apos;hbase.store.delete.expired.storefile&apos; is set to &apos;true&apos; (Reference: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5199&quot; title=&quot;Delete out of TTL store files before compaction selection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5199&quot;&gt;&lt;del&gt;HBASE-5199&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10141&quot; title=&quot;instead of putting expired store files thru compaction, just archive them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10141&quot;&gt;&lt;del&gt;HBASE-10141&lt;/del&gt;&lt;/a&gt; )&lt;/li&gt;
	&lt;li&gt;Archiving old files is based comparison between file timestamp and server time stamp. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5199&quot; title=&quot;Delete out of TTL store files before compaction selection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5199&quot;&gt;&lt;del&gt;HBASE-5199&lt;/del&gt;&lt;/a&gt; can be further improved to store and check latest TTL of any field in the file trailer and use that for comparison instead of file timestamp. This could be independent improvement from this thread.&lt;/li&gt;
	&lt;li&gt;Proposed OnlyDeleteExpiredFilesCompactionFiles has its own use case where use does not want to compact at all and just delete old data.&lt;/li&gt;
	&lt;li&gt;Cases where some compassion is needed (to avoid too many HFiles) can be addressed by striped compaction policy (as it already has smarter logic for deciding which files to compact as well as at already deletes TTL expired files before compaction.)&lt;/li&gt;
	&lt;li&gt;Declaring table/cf &quot;immutable&quot; - to make smarter decisions: This probably needs more exploration.&lt;/li&gt;
	&lt;li&gt;New question now aires is shall there be multiple compaction policies (only delete expired files, striped, immutable etc ) or should is all be consolidated under striped compaction with configuration parameters to enable/disable certain behavior.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12676973" name="OnlyDeleteExpiredFilesCompactionPolicy.java" size="2069" author="sheetal_dolas" created="Fri, 24 Oct 2014 19:02:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Oct 2014 21:10:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 7 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i21grz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>