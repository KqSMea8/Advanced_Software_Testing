<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:27:57 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5458/HBASE-5458.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5458] Thread safety issues with Compression.Algorithm.GZ and CompressionTest</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5458</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I&apos;ve seen some occasional NullPointerExceptions in ZlibFactory.isNativeZlibLoaded(conf) during region server startups and the completebulkload process.  This is being caused by a null configuration getting passed to the isNativeZlibLoaded method.  I think this happens when 2 or more threads call the CompressionTest.testCompression method at once.  If the GZ algorithm has not been tested yet both threads could continue on and attempt to load the compressor.  For GZ the getCodec method is not thread safe which could lead to one thread getting a reference to a GzipCodec that has a null configuration.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
current:
      DefaultCodec getCodec(Configuration conf) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (codec == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          codec = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; GzipCodec();
          codec.setConf(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(conf));
        }

        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; codec;
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;one possible fix would be something like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      DefaultCodec getCodec(Configuration conf) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (codec == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          GzipCodec gzip = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; GzipCodec();
          gzip.setConf(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(conf));
          codec = gzip;
        }

        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; codec;
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;But that may not be totally safe without some synchronization.  An upstream fix in CompressionTest could also prevent multi thread access to GZ.getCodec(conf)&lt;/p&gt;

&lt;p&gt;exceptions:&lt;br/&gt;
12/02/21 16:11:56 ERROR handler.OpenRegionHandler: Failed open of region=all-monthly,,1326263896983.bf574519a95263ec23a2bad9f5b8cbf4.&lt;br/&gt;
java.io.IOException: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.util.CompressionTest.testCompression(CompressionTest.java:89)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.checkCompressionCodecs(HRegion.java:2670)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:2659)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:2647)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:312)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:99)&lt;br/&gt;
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:158)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;br/&gt;
Caused by: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:63)&lt;br/&gt;
        at org.apache.hadoop.io.compress.GzipCodec.getCompressorType(GzipCodec.java:166)&lt;br/&gt;
        at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:100)&lt;br/&gt;
        at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:112)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.Compression$Algorithm.getCompressor(Compression.java:236)&lt;br/&gt;
        at org.apache.hadoop.hbase.util.CompressionTest.testCompression(CompressionTest.java:84)&lt;br/&gt;
        ... 9 more&lt;/p&gt;

&lt;p&gt;Caused by: java.io.IOException: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.util.CompressionTest.testCompression(CompressionTest.java:89)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readTrailer(HFile.java:890)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.loadFileInfo(HFile.java:819)&lt;br/&gt;
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.groupOrSplit(LoadIncrementalHFiles.java:405)&lt;br/&gt;
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:323)&lt;br/&gt;
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:321)&lt;br/&gt;
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)&lt;br/&gt;
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;br/&gt;
Caused by: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:63)&lt;br/&gt;
        at org.apache.hadoop.io.compress.GzipCodec.getCompressorType(GzipCodec.java:166)&lt;br/&gt;
        at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:100)&lt;br/&gt;
        at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:112)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.Compression$Algorithm.getCompressor(Compression.java:236)&lt;br/&gt;
        at org.apache.hadoop.hbase.util.CompressionTest.testCompression(CompressionTest.java:84)&lt;br/&gt;
        ... 10 more&lt;/p&gt;</description>
                <environment></environment>
        <key id="12543750">HBASE-5458</key>
            <summary>Thread safety issues with Compression.Algorithm.GZ and CompressionTest</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="eclark">Elliott Clark</assignee>
                                    <reporter username="dmcintosh">David McIntosh</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Feb 2012 22:11:28 +0000</created>
                <updated>Tue, 26 Feb 2013 08:27:18 +0000</updated>
                            <resolved>Fri, 18 Jan 2013 19:37:57 +0000</resolved>
                                    <version>0.90.5</version>
                    <version>0.92.2</version>
                    <version>0.94.4</version>
                    <version>0.95.2</version>
                                    <fixVersion>0.94.5</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>io</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13214068" author="zhihyu@ebaysf.com" created="Wed, 22 Feb 2012 22:37:45 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      Compressor c = algo.getCompressor();
      algo.returnCompressor(c);
      compressionTestResults[algo.ordinal()] = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// passes
&lt;/span&gt;    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Throwable t) {
      compressionTestResults[algo.ordinal()] = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// failure
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(t);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;How about catching NPE in the above code and call algo.getCompressor() again ?&lt;br/&gt;
We set compressionTestResults to false after the retry fails.&lt;/p&gt;</comment>
                            <comment id="13556068" author="jmhsieh" created="Thu, 17 Jan 2013 11:10:11 +0000"  >&lt;p&gt;I didn&apos;t look at all the context, but why is lock transient?&lt;/p&gt;

&lt;p&gt;Do we really need double-checked locking (how often is this called and is it in the critical path)?  simpler to just do the normal locking pattern (I&apos;d prefer this)?&lt;/p&gt;

&lt;p&gt;If we do double-checked locking, let&apos;s do it correctly &amp;#8211; I believe the lzoCodec and snappyCodec need to be volatile instead of transient.  See &lt;a href=&quot;http://en.wikipedia.org/wiki/Double-checked_locking&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Double-checked_locking&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13556312" author="eclark" created="Thu, 17 Jan 2013 15:35:30 +0000"  >&lt;p&gt;The lock&apos;s transient so that if someone tries to serialize an HFile that&apos;s been compressed there&apos;s no lock object that&apos;s serialized.  It&apos;s only there as a helper, and has no real state to serialize.&lt;/p&gt;

&lt;p&gt;This method is called on every open of HFiles.  So it&apos;s in a pretty critical path; which is why I went with double checked locking.  Though there aren&apos;t a lot of these calls made so it could be ok.&lt;/p&gt;

&lt;p&gt;I&apos;ll make the codecs volatile as well as transient.&lt;/p&gt;</comment>
                            <comment id="13556335" author="jmhsieh" created="Thu, 17 Jan 2013 16:00:45 +0000"  >&lt;p&gt;I&apos;m fine with the double checked locking.  &lt;/p&gt;

&lt;p&gt;Hm.. I thought transient was used only for java serialization &amp;#8211; we&apos;re actually using that for the Compression class?  That seems funny since I thought we always did writables/pbufs.  (if we aren&apos;t using java serialization file a follow on to remove the transients?)&lt;/p&gt;
</comment>
                            <comment id="13556342" author="dmcintosh" created="Thu, 17 Jan 2013 16:11:36 +0000"  >&lt;p&gt;This patch prevents instantiating the same codec multiple times but it doesn&apos;t look like it addresses the race condition I originally ran into.  The problematic sequence is like this:&lt;/p&gt;

&lt;p&gt;Thread 1 calls GZ.getCodec for the first time.  It sees that codec is null and makes it into the buildCodec method.  It executes codec = new GzipCodec() but before it can set the configuration thread 2 also calls GZ.getCodec.  Thread 2 sees that codec is not null and returns it resulting in an exception if it is used before Thread 1 has set the configuration on it.&lt;/p&gt;

&lt;p&gt;The GzipCodec is the only one affected since the other codecs are able to set the configuration in the constructor.&lt;/p&gt;</comment>
                            <comment id="13556364" author="eclark" created="Thu, 17 Jan 2013 16:43:37 +0000"  >&lt;p&gt;Adds volatile.&lt;br/&gt;
Makes the builder function return a codec rather than setting it.&lt;/p&gt;</comment>
                            <comment id="13556399" author="yuzhihong@gmail.com" created="Thu, 17 Jan 2013 17:41:49 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+              &lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.getSystemClassLoader().loadClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.io.compress.SnappyCodec&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Mind wrapping long line ?&lt;/p&gt;</comment>
                            <comment id="13556488" author="eclark" created="Thu, 17 Jan 2013 19:12:43 +0000"  >&lt;p&gt;Wrap the long line that Ted saw.&lt;/p&gt;</comment>
                            <comment id="13556506" author="yuzhihong@gmail.com" created="Thu, 17 Jan 2013 19:30:38 +0000"  >&lt;p&gt;Latest patch looks good.&lt;/p&gt;

&lt;p&gt;Can you prepare patch for trunk ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13556537" author="jmhsieh" created="Thu, 17 Jan 2013 20:01:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; lgtm +1.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dmcintosh&quot; class=&quot;user-hover&quot; rel=&quot;dmcintosh&quot;&gt;David McIntosh&lt;/a&gt; it looks good to me &amp;#8211; this idiom is called double-checked locking and is an optimization for lazy initializers.  In your example let&apos;s say thread 1 is already in buildCodec.  This means it has the lock.   thread 2 could see null, and would get blocked by the lock.  thread 1 would finish initialization, set the variable, and then release the lock.  thread 2 enters, sees that the variable is not null and falls through.  I don&apos;t see where the conf object gets passed elsewhere.  Am I missing something?&lt;/p&gt;</comment>
                            <comment id="13556545" author="eclark" created="Thu, 17 Jan 2013 20:11:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;Ted Yu&lt;/a&gt; Sure I&apos;ll post a version for all the versions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt; The order was wrong on version 0, and it would be possible (not easy but still possible) for a thread to get a partially initialized Gzip algorithm. Fixed since then.&lt;/p&gt;</comment>
                            <comment id="13556610" author="jmhsieh" created="Thu, 17 Jan 2013 21:24:00 +0000"  >&lt;p&gt;Got it, thanks for the clarification (I was looking at the later versions).&lt;/p&gt;</comment>
                            <comment id="13556716" author="eclark" created="Thu, 17 Jan 2013 23:08:24 +0000"  >&lt;p&gt;The non-trunk patches.  Trunk patch coming in a few.&lt;/p&gt;</comment>
                            <comment id="13556718" author="eclark" created="Thu, 17 Jan 2013 23:10:58 +0000"  >&lt;p&gt;Trunk patch&lt;/p&gt;</comment>
                            <comment id="13556739" author="hadoopqa" created="Thu, 17 Jan 2013 23:28:29 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12565392/HBASE-5458-trunk-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12565392/HBASE-5458-trunk-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestScanWithBloomError&lt;br/&gt;
                  org.apache.hadoop.hbase.io.hfile.TestHFile&lt;br/&gt;
                  org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility&lt;br/&gt;
                  org.apache.hadoop.hbase.io.hfile.TestChecksum&lt;br/&gt;
                  org.apache.hadoop.hbase.io.hfile.TestHFileWriterV2&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4077//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13556758" author="hadoopqa" created="Thu, 17 Jan 2013 23:43:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12565390/HBASE-5458-092-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12565390/HBASE-5458-092-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4078//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4078//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13556761" author="eclark" created="Thu, 17 Jan 2013 23:44:29 +0000"  >&lt;p&gt;0.94 and trunk used a new ReusableStreamGzipCodec which I missed when doing the port.  Posting new patch.&lt;/p&gt;</comment>
                            <comment id="13556824" author="hadoopqa" created="Fri, 18 Jan 2013 00:47:19 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12565398/HBASE-5458-trunk-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12565398/HBASE-5458-trunk-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestLocalHBaseCluster&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): &lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4079//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13556828" author="yuzhihong@gmail.com" created="Fri, 18 Jan 2013 00:50:52 +0000"  >&lt;p&gt;+1 on latest patch.&lt;/p&gt;</comment>
                            <comment id="13556858" author="eclark" created="Fri, 18 Jan 2013 01:22:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Thoughts on this in 0.94 ?&lt;/p&gt;</comment>
                            <comment id="13556872" author="lhofhansl" created="Fri, 18 Jan 2013 01:43:18 +0000"  >&lt;p&gt;Looks good to me.&lt;br/&gt;
This is not on a hot code path, right? The hottest I found was AbstractFSReader.decompress.&lt;/p&gt;

&lt;p&gt;Even volatiles create memory barriers in many cases, so we have to be careful.&lt;/p&gt;</comment>
                            <comment id="13557451" author="eclark" created="Fri, 18 Jan 2013 18:32:00 +0000"  >&lt;p&gt;This is called on every hfile reader open (assuming compressed hfiles), so pretty low volume, but not never.&lt;/p&gt;

&lt;p&gt;Edit: if compressed.&lt;/p&gt;</comment>
                            <comment id="13557458" author="lhofhansl" created="Fri, 18 Jan 2013 18:38:28 +0000"  >&lt;p&gt;AbstractFSReader.decompress is called for each block read, no? Anyway, still not super high volume.&lt;/p&gt;</comment>
                            <comment id="13557478" author="eclark" created="Fri, 18 Jan 2013 18:58:57 +0000"  >&lt;p&gt;Yeah you&apos;re correct. every block not every file.&lt;/p&gt;</comment>
                            <comment id="13557485" author="eclark" created="Fri, 18 Jan 2013 19:03:40 +0000"  >&lt;p&gt;going ahead to commit then.&lt;/p&gt;</comment>
                            <comment id="13557488" author="lhofhansl" created="Fri, 18 Jan 2013 19:04:53 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13557529" author="eclark" created="Fri, 18 Jan 2013 19:37:57 +0000"  >&lt;p&gt;Trunk: Committed revision 1435316.&lt;br/&gt;
94: Committed revision 1435317.&lt;br/&gt;
92: Committed revision 1435318.&lt;br/&gt;
90: Committed revision 1435319.&lt;/p&gt;</comment>
                            <comment id="13557559" author="hudson" created="Fri, 18 Jan 2013 20:17:09 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3766 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3766/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3766/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435316)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/compress/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13557599" author="hudson" created="Fri, 18 Jan 2013 21:02:05 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #746 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/746/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/746/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435317)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13557741" author="hudson" created="Fri, 18 Jan 2013 23:22:36 +0000"  >&lt;p&gt;Integrated in HBase-0.92 #611 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92/611/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92/611/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435318)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/io/hfile/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13557799" author="hudson" created="Sat, 19 Jan 2013 00:33:30 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #360 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/360/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/360/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435316)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/compress/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13561705" author="hudson" created="Thu, 24 Jan 2013 16:04:45 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #96 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/96/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/96/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435317)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13570938" author="hudson" created="Tue, 5 Feb 2013 03:58:15 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #11 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/11/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/11/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435317)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13571099" author="hudson" created="Tue, 5 Feb 2013 07:06:38 +0000"  >&lt;p&gt;Integrated in HBase-0.92-security #148 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92-security/148/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92-security/148/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5458&quot; title=&quot;Thread safety issues with Compression.Algorithm.GZ and CompressionTest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5458&quot;&gt;&lt;del&gt;HBASE-5458&lt;/del&gt;&lt;/a&gt; Thread safety issues with Compression.Algorithm.GZ and CompressionTest (Revision 1435318)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/io/hfile/Compression.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12565227" name="HBASE-5458-090-0.patch" size="4138" author="eclark" created="Thu, 17 Jan 2013 00:47:16 +0000"/>
                            <attachment id="12565345" name="HBASE-5458-090-1.patch" size="4446" author="eclark" created="Thu, 17 Jan 2013 16:43:37 +0000"/>
                            <attachment id="12565353" name="HBASE-5458-090-2.patch" size="4500" author="eclark" created="Thu, 17 Jan 2013 19:12:43 +0000"/>
                            <attachment id="12565390" name="HBASE-5458-092-2.patch" size="4624" author="eclark" created="Thu, 17 Jan 2013 23:08:24 +0000"/>
                            <attachment id="12565396" name="HBASE-5458-094-2.patch" size="6048" author="eclark" created="Thu, 17 Jan 2013 23:44:29 +0000"/>
                            <attachment id="12565398" name="HBASE-5458-trunk-2.patch" size="6027" author="eclark" created="Thu, 17 Jan 2013 23:45:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Feb 2012 22:37:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>228989</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 45 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02bqn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11503</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>