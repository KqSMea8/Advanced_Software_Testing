<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:15:52 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-4095/HBASE-4095.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-4095] Hlog may not be rolled in a long time if checkLowReplication&apos;s request of LogRoll is blocked</title>
                <link>https://issues.apache.org/jira/browse/HBASE-4095</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Some large Hlog files(Larger than 10G) appeared in our environment, and I got the reason why they got so huge:&lt;/p&gt;

&lt;p&gt;1. The replicas is less than the expect number. So the method of checkLowReplication will be called each sync.&lt;/p&gt;

&lt;p&gt;2. The method checkLowReplication request log-roll first, and set logRollRequested as true: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;private void checkLowReplication() {
// if the number of replicas in HDFS has fallen below the initial
// value, then roll logs.
try {
  int numCurrentReplicas = getLogReplication();
  if (numCurrentReplicas != 0 &amp;amp;&amp;amp;
	  numCurrentReplicas &amp;lt; this.initialReplication) {
	LOG.warn(&quot;HDFS pipeline error detected. &quot; +
		&quot;Found &quot; + numCurrentReplicas + &quot; replicas but expecting &quot; +
		this.initialReplication + &quot; replicas. &quot; +
		&quot; Requesting close of hlog.&quot;);
	requestLogRoll();
	logRollRequested = true;
  }
} catch (Exception e) {
  LOG.warn(&quot;Unable to invoke DFSOutputStream.getNumCurrentReplicas&quot; + e +
	  &quot; still proceeding ahead...&quot;);
}
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3.requestLogRoll() just commit the roll request. It may not execute in time, for it must got the un-fair lock of cacheFlushLock.&lt;br/&gt;
But the lock may be carried by the cacheflush threads.&lt;/p&gt;

&lt;p&gt;4.logRollRequested was true until the log-roll executed. So during the time, each request of log-roll in sync() was skipped.&lt;/p&gt;

&lt;p&gt;Here&apos;s the logs while the problem happened(Please notice the file size of hlog &quot;193-195-5-111%3A20020.1309937386639&quot; in the last row):&lt;/p&gt;

&lt;p&gt;2011-07-06 15:28:59,284 WARN org.apache.hadoop.hbase.regionserver.wal.HLog: HDFS pipeline error detected. Found 2 replicas but expecting 3 replicas.  Requesting close of hlog.&lt;br/&gt;
2011-07-06 15:29:46,714 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309937339119, entries=32434, filesize=239589754. New hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309937386639&lt;br/&gt;
2011-07-06 15:29:56,929 WARN org.apache.hadoop.hbase.regionserver.wal.HLog: HDFS pipeline error detected. Found 2 replicas but expecting 3 replicas.  Requesting close of hlog.&lt;br/&gt;
2011-07-06 15:29:56,933 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://193.195.5.112:9000/hbase/Htable_UFDR_034/a3780cf0c909d8cf8f8ed618b290cc95/.tmp/4656903854447026847 to hdfs://193.195.5.112:9000/hbase/Htable_UFDR_034/a3780cf0c909d8cf8f8ed618b290cc95/value/8603005630220380983&lt;br/&gt;
2011-07-06 15:29:57,391 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://193.195.5.112:9000/hbase/Htable_UFDR_034/a3780cf0c909d8cf8f8ed618b290cc95/value/8603005630220380983, entries=445880, sequenceid=248900, memsize=207.5m, filesize=130.1m&lt;br/&gt;
2011-07-06 15:29:57,478 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~207.5m for region Htable_UFDR_034,07664,1309936974158.a3780cf0c909d8cf8f8ed618b290cc95. in 10839ms, sequenceid=248900, compaction requested=false&lt;br/&gt;
2011-07-06 15:28:59,236 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309926531955, entries=216459, filesize=2370387468. New hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309937339119&lt;br/&gt;
2011-07-06 15:29:46,714 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309937339119, entries=32434, filesize=239589754. New hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309937386639&lt;br/&gt;
2011-07-06 16:29:58,775 DEBUG org.apache.hadoop.hbase.regionserver.LogRoller: Hlog roll period 3600000ms elapsed&lt;br/&gt;
2011-07-06 16:29:58,775 DEBUG org.apache.hadoop.hbase.regionserver.LogRoller: Hlog roll period 3600000ms elapsed&lt;br/&gt;
2011-07-06 16:30:01,978 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309937386639, entries=1135576, filesize=19220372830. New hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3A20020.1309940998890&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12514051">HBASE-4095</key>
            <summary>Hlog may not be rolled in a long time if checkLowReplication&apos;s request of LogRoll is blocked</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jeason">Jieshan Bean</assignee>
                                    <reporter username="jeason">Jieshan Bean</reporter>
                        <labels>
                    </labels>
                <created>Thu, 14 Jul 2011 11:55:02 +0000</created>
                <updated>Fri, 20 Nov 2015 11:55:06 +0000</updated>
                            <resolved>Fri, 19 Aug 2011 04:00:46 +0000</resolved>
                                    <version>0.90.3</version>
                                    <fixVersion>0.90.5</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13065757" author="jeason" created="Fri, 15 Jul 2011 08:10:15 +0000"  >&lt;p&gt;The modifications in the patch:&lt;br/&gt;
1. Move &quot;logRollRequested = true;&quot; out of &quot;HLog#checkLowReplication()&quot;. But added in &quot;HLog#rollWriter&quot; after got the lock of cacheFlushLock.&lt;br/&gt;
2. Change the &quot;this.cacheFlushLock.lock()&quot; to &quot;this.cacheFlushLock.tryLock&quot; in the method of &quot;HLog#rollWriter()&quot; If it was blocked a long time, just skip the operations. &lt;br/&gt;
I think this&apos;s reasonable.&lt;br/&gt;
3. &quot;fs.getFileStatus(newPath).getReplication();&quot; is get the expect replicas but not the actual one. &quot;HLog.initialReplication&quot; was changed in each calling of rollWriter. &lt;br/&gt;
So I think its value should be the current replicas but not the expect value.&lt;/p&gt;

&lt;p&gt;I have taken many tests about the patch. It behaves very well. During each test, I killed one of the datanode who carried one replicas of the HLog, a new HLog file is recreated&lt;br/&gt;
successfully. &lt;/p&gt;</comment>
                            <comment id="13067436" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 01:37:47 +0000"  >&lt;p&gt;I think the following parameter:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.tryLockWaitingTime = 
+        conf.getLong(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.regionserver.logroll.trylock.waitingtime&quot;&lt;/span&gt;, 5000);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;can be named &apos;hbase.regionserver.cacheFlushLock.waittime&apos;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.logRollRequested = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
+        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (closed) {
+            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; regionsToFlush;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should this.logRollRequested = true be moved after the return ?&lt;/p&gt;</comment>
                            <comment id="13067447" author="jeason" created="Tue, 19 Jul 2011 02:03:07 +0000"  >&lt;p&gt;Thanks, Ted.&lt;br/&gt;
I have made the change of the patches according to your suggestions.&lt;/p&gt;</comment>
                            <comment id="13067466" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 03:01:50 +0000"  >&lt;p&gt;Running tests for TRUNK patch.&lt;/p&gt;</comment>
                            <comment id="13067499" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 05:06:30 +0000"  >&lt;p&gt;@Jieshan:&lt;br/&gt;
I saw the following test failures using patch TRUNK:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Running org.apache.hadoop.hbase.regionserver.wal.TestLogRolling
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 108.675 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.master.TestDistributedLogSplitting
Tests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 162.863 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Running the tests manually passed.&lt;/p&gt;</comment>
                            <comment id="13067504" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 05:15:45 +0000"  >&lt;p&gt;Integrated to branch and TRUNK.&lt;/p&gt;

&lt;p&gt;Thanks for the patch Jieshan.&lt;/p&gt;</comment>
                            <comment id="13067506" author="jeason" created="Tue, 19 Jul 2011 05:17:41 +0000"  >&lt;p&gt;About the failure in trunk(Sorry, I just tested the branch patch), is it a problem?&lt;br/&gt;
Thanks, Ted.&lt;/p&gt;</comment>
                            <comment id="13067508" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 05:25:56 +0000"  >&lt;p&gt;I ran TestLogRolling manually twice and TestDistributedLogSplitting once.&lt;br/&gt;
They passed.&lt;/p&gt;

&lt;p&gt;@Jieshan:&lt;br/&gt;
Running related unit tests before submission is always a good idea.&lt;/p&gt;</comment>
                            <comment id="13067509" author="jeason" created="Tue, 19 Jul 2011 05:28:51 +0000"  >&lt;p&gt;Sorry, about the trunk patch, I didn&apos;t have the env for it(Though I have taken enough tests for the branch). But I&apos;ll remember to do the unit tests for trunk the next time.&lt;/p&gt;</comment>
                            <comment id="13067511" author="jeason" created="Tue, 19 Jul 2011 05:29:38 +0000"  >&lt;p&gt;So I can resolve this issue??&lt;/p&gt;</comment>
                            <comment id="13067514" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 05:37:43 +0000"  >&lt;p&gt;@Jieshan:&lt;br/&gt;
I use the following command to run test suite on Linux:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
nohup mvn &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt; &amp;gt; 4095.results
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I normally wait for TRUNK build to pass before resolving an issue.&lt;/p&gt;</comment>
                            <comment id="13067571" author="hudson" created="Tue, 19 Jul 2011 08:21:10 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2039 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2039/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2039/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; title=&quot;Hlog may not be rolled in a long time if checkLowReplication&amp;#39;s request of LogRoll is blocked&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4095&quot;&gt;&lt;del&gt;HBASE-4095&lt;/del&gt;&lt;/a&gt;  Hlog may not be rolled in a long time if checkLowReplication&apos;s&lt;br/&gt;
               request of LogRoll is blocked (Jieshan via Ted Yu)&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13067737" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 14:12:57 +0000"  >&lt;p&gt;TestLogRolling failed in build 2040.&lt;/p&gt;</comment>
                            <comment id="13067903" author="yuzhihong@gmail.com" created="Tue, 19 Jul 2011 19:30:15 +0000"  >&lt;p&gt;Although build 2041 passed, we should investigate why TestLogRolling failed intermittently.&lt;/p&gt;</comment>
                            <comment id="13068175" author="jeason" created="Wed, 20 Jul 2011 06:41:07 +0000"  >
&lt;p&gt;assertTrue(&quot;Missing datanode should&apos;ve triggered a log roll&quot;,&lt;br/&gt;
        newFilenum &amp;gt; oldFilenum &amp;amp;&amp;amp; newFilenum &amp;gt; curTime);&lt;/p&gt;

&lt;p&gt;I&apos;ve got the reasons why the TestLogRolling failed intermittently.&lt;/p&gt;

&lt;p&gt;1. Before the patch of this issue, if one datanode was killed, it will trigger a log-roll. For it will get the lock of cacheFlushLock finally.&lt;/p&gt;

&lt;p&gt;2. But after the modification, if the log-roll didn&apos;t get the lock in 5 second, it will skip the operations.&lt;br/&gt;
So it may not get the lock of cacheFlushLock in 5 second , so it failed.&lt;/p&gt;</comment>
                            <comment id="13068183" author="yuzhihong@gmail.com" created="Wed, 20 Jul 2011 06:59:21 +0000"  >&lt;p&gt;I wonder if there is other reason.&lt;br/&gt;
I added else block for cacheFlushLock.tryLock() call and placed a breakpoint inside else block.&lt;/p&gt;

&lt;p&gt;testLogRollOnDatanodeDeath failed but the breakpoint wasn&apos;t hit.&lt;/p&gt;</comment>
                            <comment id="13068184" author="stack" created="Wed, 20 Jul 2011 07:01:29 +0000"  >&lt;p&gt;It failed for me just now on local machine.&lt;/p&gt;</comment>
                            <comment id="13068185" author="jeason" created="Wed, 20 Jul 2011 07:06:07 +0000"  >&lt;p&gt;Only two places was changed in HLog$rollWriter():&lt;/p&gt;

&lt;p&gt;1. lock -&amp;gt; tryLock&lt;br/&gt;
2. Change the value of &quot;this.initialReplication&quot;:&lt;br/&gt;
      //This method get expect but not the actual replicas of the Hlog file&lt;br/&gt;
        int nextExpectReplicas = fs.getFileStatus(newPath).getReplication();&lt;/p&gt;

&lt;p&gt;      //Get the current replicas of the Hlog file&lt;br/&gt;
        int nextActualReplicas = -1;&lt;br/&gt;
        try&lt;br/&gt;
        &lt;/p&gt;
{
            nextActualReplicas = getLogReplication();
        }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
            LOG.warn(&quot;Unable to invoke DFSOutputStream.getNumCurrentReplicas&quot; + e +
                &quot; still proceeding ahead...&quot;);
        }

&lt;p&gt;       this.initialReplication = nextActualReplicas == -1 ? &lt;br/&gt;
              nextExpectReplicas : nextActualReplicas;&lt;/p&gt;
</comment>
                            <comment id="13068191" author="jeason" created="Wed, 20 Jul 2011 07:24:14 +0000"  >&lt;p&gt;Here&apos;s the logs from a failure-test:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;---------------Rolling from the first test-------------------------------
2011-07-20 12:35:59,121 INFO  [main] wal.HLog(529): Roll /user/root/.logs/C4C2.site,42700,1311136499029/C4C2.site%3A42700.1311136501182, entries=296, filesize=307097. New hlog /user/root/.logs/C4C2.site,42700,1311136499029/C4C2.site%3A42700.1311136559078
2011-07-20 12:35:59,121 DEBUG [main] wal.HLog(541): Last sequenceid written is empty. Deleting all old hlogs
2011-07-20 12:35:59,136 INFO  [main] wal.TestLogRolling(206): after flushing all regions and rolling logs there are 0 log files

---------------Rolling from the second test ()testLogRollOnDatanodeDeath----------------
2011-07-20 12:35:59,141 INFO  [main] wal.TestLogRolling(264): Replication=2
2011-07-20 12:37:02,434 WARN  [RegionServer:1;C4C2.site,42700,1311136499029.logSyncer] wal.HLog(1035): HDFS pipeline error detected. Found 1 replicas but expecting 2 replicas.  Requesting close of hlog.
2011-07-20 12:37:02,497 INFO  [RegionServer:1;C4C2.site,42700,1311136499029.logRoller] wal.HLog(529): Roll /user/root/.logs/C4C2.site,42700,1311136499029/C4C2.site%3A42700.1311136559078, entries=3, filesize=1043. New hlog /user/root/.logs/C4C2.site,42700,1311136499029/C4C2.site%3A42700.1311136622435
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From the logs, we can see that, the Hlog was indeed rolled.&lt;/p&gt;</comment>
                            <comment id="13068285" author="hudson" created="Wed, 20 Jul 2011 11:23:55 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2043 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2043/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2043/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; title=&quot;Hlog may not be rolled in a long time if checkLowReplication&amp;#39;s request of LogRoll is blocked&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4095&quot;&gt;&lt;del&gt;HBASE-4095&lt;/del&gt;&lt;/a&gt; make cacheFlushLock.waittime longer&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13068314" author="hudson" created="Wed, 20 Jul 2011 12:18:19 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2044 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2044/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2044/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; title=&quot;Hlog may not be rolled in a long time if checkLowReplication&amp;#39;s request of LogRoll is blocked&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4095&quot;&gt;&lt;del&gt;HBASE-4095&lt;/del&gt;&lt;/a&gt; revert, wait for further investigation&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; title=&quot;Hlog may not be rolled in a long time if checkLowReplication&amp;#39;s request of LogRoll is blocked&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4095&quot;&gt;&lt;del&gt;HBASE-4095&lt;/del&gt;&lt;/a&gt; revert to previous way of initializing initialReplication&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13068407" author="yuzhihong@gmail.com" created="Wed, 20 Jul 2011 14:36:30 +0000"  >&lt;p&gt;Rolled back in branch and TRUNK.&lt;/p&gt;

&lt;p&gt;Waiting for better solution.&lt;/p&gt;</comment>
                            <comment id="13068747" author="sunnygao" created="Thu, 21 Jul 2011 00:57:37 +0000"  >&lt;p&gt;I added some log  and found that the initialReplication is zero. &lt;br/&gt;
when we create a file in hdfs , If I don&apos;t write data , the replication should be zero.&lt;br/&gt;
So the solution has some issue.&lt;/p&gt;

&lt;p&gt;2011-07-20 19:38:20,517 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:1;C4C3.site,41763,1311161899551&amp;#93;&lt;/span&gt; wal.HLog(478): gjc:rollWriter start1311161900517&lt;br/&gt;
2011-07-20 19:38:20,650 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:0;C4C3.site,35697,1311161899494&amp;#93;&lt;/span&gt; wal.HLog(478): gjc:rollWriter start1311161900650&lt;br/&gt;
2011-07-20 19:38:20,707 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:1;C4C3.site,41763,1311161899551&amp;#93;&lt;/span&gt; wal.HLog(518): gjc:updateLock start1311161900707&lt;br/&gt;
2011-07-20 19:38:20,707 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:1;C4C3.site,41763,1311161899551&amp;#93;&lt;/span&gt; wal.HLog(532): gjc:initialReplication start0&lt;br/&gt;
2011-07-20 19:38:21,238 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:0;C4C3.site,35697,1311161899494&amp;#93;&lt;/span&gt; wal.HLog(518): gjc:updateLock start1311161901238&lt;br/&gt;
2011-07-20 19:38:21,239 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:0;C4C3.site,35697,1311161899494&amp;#93;&lt;/span&gt; wal.HLog(532): gjc:initialReplication start0&lt;br/&gt;
2011-07-20 19:38:41,726 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 37616&amp;#93;&lt;/span&gt; wal.HLog(478): gjc:rollWriter start1311161921726&lt;br/&gt;
2011-07-20 19:38:41,769 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 37616&amp;#93;&lt;/span&gt; wal.HLog(518): gjc:updateLock start1311161921769&lt;br/&gt;
2011-07-20 19:38:41,769 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 37616&amp;#93;&lt;/span&gt; wal.HLog(532): gjc:initialReplication start0&lt;/p&gt;</comment>
                            <comment id="13069325" author="jeason" created="Fri, 22 Jul 2011 00:51:48 +0000"  >&lt;p&gt;I misunderstood the method of HLog#getLogReplication, this method is also get the default replicas value of a new created block(Not for the old one).&lt;br/&gt;
I just changed the place of &quot;this.logRollRequested = true&quot;.&lt;/p&gt;

&lt;p&gt;I have taken tests on the branch patch, but the trunk one, I didn&apos;t build up the env for it.&lt;/p&gt;

&lt;p&gt;Though the patch has little modification, But problem of the large HLog can be well resolved.&lt;/p&gt;</comment>
                            <comment id="13069390" author="stack" created="Fri, 22 Jul 2011 05:26:45 +0000"  >&lt;p&gt;Jieshan.  Is there something messed up in the logs you report way up at the top of this issue?  Time starts to go backwards if I look at the log timestamps.  We go:&lt;/p&gt;

&lt;p&gt;2011-07-06 15:29:57,478&lt;br/&gt;
2011-07-06 15:28:59,236&lt;br/&gt;
2011-07-06 15:29:46,714&lt;/p&gt;

&lt;p&gt;Your patch seems a little odd in that we do this.logRollRequested = true; inside in a method named rollWriter.  That doesn&apos;t seem right; i.e. at the start of log rolling, we set a flag to say we have requested a log roll.&lt;/p&gt;

&lt;p&gt;Is the issue that this.logRollRequested is being set to true but its not being cleared appropriately?  Once set, we&apos;ll never roll the logs again though the replicas are &amp;lt; 3?&lt;/p&gt;
</comment>
                            <comment id="13069393" author="jeason" created="Fri, 22 Jul 2011 05:38:30 +0000"  >&lt;p&gt;About the report, I mixed up several tests.&lt;br/&gt;
For the first time, I ran all the tests, but several got error(It&apos;s the hostName problems)..So I changed some code ,and run the failed test again. All the tests passed.&lt;/p&gt;

&lt;p&gt;Before the patch, this.logRollRequested = true was placed in the method of checkLowReplication(). But if rollWriter is blocked, all the following roll will be skippted. That&apos;s why I made the modification and change the place of this.logRollRequested = true.&lt;/p&gt;

&lt;p&gt;Though the name of this.logRollRequested seems misleading. But if don&apos;t change its place, the rollWriter may not run a for long time, and the HLog could becomes very large.&lt;/p&gt;</comment>
                            <comment id="13069396" author="jeason" created="Fri, 22 Jul 2011 05:44:56 +0000"  >&lt;p&gt;Sorry for misunderstood your comments about the logs:&lt;/p&gt;

&lt;p&gt;Yes, I copied the logs together, but make up them with the wrong order. Sorry.&lt;/p&gt;</comment>
                            <comment id="13069397" author="stack" created="Fri, 22 Jul 2011 05:45:50 +0000"  >&lt;p&gt;&quot;But if rollWriter is blocked, all the following roll will be skippted.&quot;&lt;/p&gt;

&lt;p&gt;When is the above so?&lt;/p&gt;</comment>
                            <comment id="13069399" author="stack" created="Fri, 22 Jul 2011 05:47:20 +0000"  >&lt;p&gt;Oh, ok.  I was unable to follow what was going on.  Mixing up their order threw me off (I&apos;m still not sure what is going on here.  Maybe if you can answer my above question that would help &amp;#8211; thanks).&lt;/p&gt;</comment>
                            <comment id="13069401" author="jeason" created="Fri, 22 Jul 2011 05:59:48 +0000"  >
&lt;p&gt;I attached the full logs of the regionserver.&lt;br/&gt;
&quot;hbase-root-regionserver-193-195-5-111.rar&quot;:&lt;br/&gt;
1. One datanode was down, it tricker the rollWriter.&lt;br/&gt;
2. Before the patch:&lt;br/&gt;
  private void checkLowReplication() {&lt;br/&gt;
    // if the number of replicas in HDFS has fallen below the initial&lt;br/&gt;
    // value, then roll logs.&lt;br/&gt;
    try {&lt;br/&gt;
      int numCurrentReplicas = getLogReplication();&lt;br/&gt;
      if (numCurrentReplicas != 0 &amp;amp;&amp;amp;&lt;br/&gt;
          numCurrentReplicas &amp;lt; this.initialReplication) &lt;/p&gt;
{
        LOG.warn(&quot;HDFS pipeline error detected. &quot; +
            &quot;Found &quot; + numCurrentReplicas + &quot; replicas but expecting &quot; +
            this.initialReplication + &quot; replicas. &quot; +
            &quot; Requesting close of hlog.&quot;);
        requestLogRoll();
        logRollRequested = true;
      }
&lt;p&gt;    } catch (Exception e) &lt;/p&gt;
{
      LOG.warn(&quot;Unable to invoke DFSOutputStream.getNumCurrentReplicas&quot; + e +
          &quot; still proceeding ahead...&quot;);
    }
&lt;p&gt;  }&lt;/p&gt;

&lt;p&gt;  It requested to rollWriter, and set logRollRequested as true.&lt;br/&gt;
  But the rollWriter may be blocked this time. So the logRollRequested is always true until the next success rollWriter finished.&lt;br/&gt;
  During the time , client was writing the data into this RegionServer. If Hlog was larger than 256M(Suppose it is), it should tricker a new rollWriter, &lt;br/&gt;
  but each time will skip the request, for logRollRequested was still true:  &lt;br/&gt;
	public void sync() throws IOException {&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;       if (!logRollRequested) {&lt;br/&gt;
          checkLowReplication();&lt;br/&gt;
          if (this.writer.getLength() &amp;gt; this.logrollsize) &lt;/p&gt;
{
            requestLogRoll();
          }
&lt;p&gt;       }&lt;br/&gt;
    }&lt;/p&gt;</comment>
                            <comment id="13069403" author="stack" created="Fri, 22 Jul 2011 06:04:39 +0000"  >&lt;p&gt;You say &quot;But the rollWriter may be blocked this time&quot;  Why is it blocked?   And does it just stay blocked for ever? (Thanks for the help making me understand Jieshan).&lt;/p&gt;</comment>
                            <comment id="13069404" author="jeason" created="Fri, 22 Jul 2011 06:14:14 +0000"  >&lt;p&gt;I don&apos;t know why it got blocked for a long time. The rollWriter must get the lock of this.cacheFlushLock, if the RS&apos;s flushing now, the rollWriter can&apos;t be executed in time(The lock is carried by CacheFlush threads).&lt;/p&gt;

&lt;p&gt;I think use tryLock is better(If it can&apos;t get the lock in several second, we just skip it this time).&lt;/p&gt;


&lt;p&gt;  public long startCacheFlush() &lt;/p&gt;
{
    this.cacheFlushLock.lock();
    return obtainSeqNum();
  }
&lt;p&gt; &lt;/p&gt;</comment>
                            <comment id="13069470" author="jeason" created="Fri, 22 Jul 2011 09:52:05 +0000"  >&lt;p&gt;stack, you can ignore this patch.&lt;br/&gt;
I&apos;ll give out a more considerate patch.&lt;/p&gt;</comment>
                            <comment id="13072267" author="jeason" created="Thu, 28 Jul 2011 09:24:38 +0000"  >&lt;p&gt;After I&apos;ve taken more tests about this issue. I found the cause of &quot;RollWriter blocked for a long time&quot; is just a illusion.&lt;br/&gt;
(In order to tracing what happened, I add some new logs, please check the attached file &quot;RelatedLogs2011-07-28&quot;)&lt;br/&gt;
Here&apos;s the analysis:&lt;br/&gt;
(Suppose there&apos;s only 3 nodes in the cluster)&lt;/p&gt;

&lt;p&gt;1. HLog-rolling was requested after one datanode was killed.&lt;br/&gt;
2. Set HLog#logRollRequested as true after the request.&lt;br/&gt;
3. HLog#rollWriter was executed some time later. &lt;br/&gt;
4. A new rollWriter was requested nearby the prev one. And there&apos;s no new entries during the time.&lt;br/&gt;
   HLog#rollWriter() was returned at the beginning, for the numEntries.get() == 0:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  public byte [][] rollWriter() throws FailedLogCloseException, IOException {
    // Return if nothing to flush.
    long stamp = System.currentTimeMillis();
    if (this.writer != null &amp;amp;&amp;amp; this.numEntries.get() &amp;lt;= 0) {
      return null;
    }
    byte [][] regionsToFlush = null;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It happens with a high probabities if one datanode was down in such mini-cluster(3 nodes):&lt;/p&gt;

&lt;p&gt;1.HLog#initialReplication is reset in each HLog#rollWriter.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  int nextInitialReplication = fs.getFileStatus(newPath).getReplication();
  this.initialReplication = nextInitialReplication;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The method of &quot;fs.getFileStatus(newPath).getReplication()&quot; could only get the default/expect replicas value(3).&lt;br/&gt;
So HLog#initialReplication is always 3.&lt;/p&gt;

&lt;p&gt;2.HLog could only has 2 replicas for there&apos;s only 2 datanodes.&lt;br/&gt;
  So rollWriter was requested in each HLog#sync().&lt;/p&gt;

&lt;p&gt;That&apos;s why it happens easily if one datanode was down.&lt;/p&gt;

&lt;p&gt;I&apos;m thinking about two solutions to this issue:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Solution A&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Consider the actual live datanode count while reset the value of HLog#initialReplication.&lt;br/&gt;
If the live datanode count is less than the default replicas, its value should be the actual datanode count. Otherwise, set it to the default value.&lt;br/&gt;
But I&apos;ve no idea about how to get the live datanode count. &lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Solution B&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Add a new configurable parameter to set the minimum tolerable number. It&apos;s default value is the default replicas.&lt;br/&gt;
If one datanode was killed which carried one replicas of HLog, but the actual replicas value is still larger than/equal with the configurable parameter value. We should not tricker a new RollWriter.&lt;br/&gt;
Something likes:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;   private OutputStream hdfs_out;     // OutputStream associated with the current SequenceFile.writer
-  private int initialReplication;    // initial replication factor of SequenceFile.writer
+  
+  //Minimum tolerable replicas, if the actual value is less than that, the rollWriter would be trickered
+  private int minTolerableReplication; 
+  
   private Method getNumCurrentReplicas; // refers to DFSOutputStream.getNumCurrentReplicas
   final static Object [] NO_ARGS = new Object []{};
 
@@ -358,6 +361,9 @@
       }
     }
     this.maxLogs = conf.getInt(&quot;hbase.regionserver.maxlogs&quot;, 32);
+    
+    this.minTolerableReplication = 
+      conf.getInt(&quot;hbase.regionserver.hlog.mintolerablereplicas&quot;, 3);
     this.enabled = conf.getBoolean(&quot;hbase.regionserver.hlog.enabled&quot;, true);
     LOG.info(&quot;HLog configuration: blocksize=&quot; +
       StringUtils.byteDesc(this.blocksize) +
@@ -480,7 +486,6 @@
       this.filenum = System.currentTimeMillis();
       Path newPath = computeFilename();
       HLog.Writer nextWriter = this.createWriterInstance(fs, newPath, conf);
-      int nextInitialReplication = fs.getFileStatus(newPath).getReplication();
       // Can we get at the dfsclient outputstream?  If an instance of
       // SFLW, it&apos;ll have done the necessary reflection to get at the
       // protected field name.
@@ -500,7 +505,6 @@
         // Clean up current writer.
         Path oldFile = cleanupCurrentWriter(currentFilenum);
         this.writer = nextWriter;
-        this.initialReplication = nextInitialReplication;
         this.hdfs_out = nextHdfsOut;
 
         LOG.info((oldFile != null?
@@ -1003,10 +1007,10 @@
     try {
       int numCurrentReplicas = getLogReplication();
       if (numCurrentReplicas != 0 &amp;amp;&amp;amp;
-          numCurrentReplicas &amp;lt; this.initialReplication) {
+          numCurrentReplicas &amp;lt; this.minTolerableReplication) {
         LOG.warn(&quot;HDFS pipeline error detected. &quot; +
-            &quot;Found &quot; + numCurrentReplicas + &quot; replicas but expecting &quot; +
-            this.initialReplication + &quot; replicas. &quot; +
+            &quot;Found &quot; + numCurrentReplicas + &quot; replicas but expecting no less than &quot; +
+            this.minTolerableReplication + &quot; replicas. &quot; +
             &quot; Requesting close of hlog.&quot;);
         requestLogRoll();
         logRollRequested = true;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13079855" author="jeason" created="Fri, 5 Aug 2011 08:51:30 +0000"  >&lt;p&gt;The analysis before this has told why did the large-Hlog file occur.&lt;br/&gt;
Be brief, it&apos;s because the variable of &quot;HLog#logRollRequested&quot;. Once the rollWriter was requested, it&apos;s value was set as true. But the rollWriter was able to executed in time. So the following roll-requests were skippted. &lt;/p&gt;

&lt;p&gt;In the original code, it using the following code to try to get the initial Hlog replicas:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; int nextInitialReplication = fs.getFileStatus(newPath).getReplication(); 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;But it&apos;s value always equals with the default replicas number.Once the actual datanode count is less than default replicas value. rollWriter will be requested in each sync.&lt;br/&gt;
So rollWriter was executed one by one with a high frequency.&lt;/p&gt;

&lt;p&gt;The patch of V4 is trying to solve both the &quot;large-file&quot; problem and the &quot;high-frequency roll request&quot; problem.&lt;/p&gt;

&lt;p&gt;1. Replace the variable of &quot;HLog#logRollRequested&quot; as &quot;HLog#logRollRunning&quot;. A new request will be skippted while another rollWriter was running.&lt;br/&gt;
2. Add a new variable named &quot;minTolerableReplication&quot;. Once the actual replicas is less than it, send a rollWriter request.&lt;br/&gt;
3. Once a sequence of unreasonable rollWriter executed, disable roll-request from checkLowReplication(). Enable it while replicas return to normal.&lt;/p&gt;

&lt;p&gt;I&apos;ve take many tests on the patch. Please check them from the attachment of &quot;TestResultForPatch-V4.rar&quot;.&lt;/p&gt;</comment>
                            <comment id="13079976" author="yuzhihong@gmail.com" created="Fri, 5 Aug 2011 13:49:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;But the rollWriter was able to executed in time. So the following roll-requests were skippted.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think you meant:&lt;br/&gt;
But the rollWriter wasn&apos;t able to execute in time. And the following roll-requests were skipped.&lt;/p&gt;</comment>
                            <comment id="13079996" author="ram_krish" created="Fri, 5 Aug 2011 14:44:18 +0000"  >&lt;p&gt;@Jieshan,&lt;br/&gt;
I was analysing the initial logs attached.  As you said the Rolling of hLog has not happened due to some reason. I hope the cacheFlushLock was not allowed to be held by the HLog Roller.  If the rolling of logs has not happened due to this reason then the current soln will it take care of it ? &lt;br/&gt;
One more point is, if the number of replicas doesnt for the Logroll to happen then we stop the log rolling as per the current patch. Correct me if am wrong.  &lt;br/&gt;
Is this behaviour ok? &lt;br/&gt;
Should we expose the new properties in the hbase-default.xml?&lt;br/&gt;
Pls correct me if my analysis/query is wrong.  &lt;/p&gt;</comment>
                            <comment id="13080724" author="jeason" created="Mon, 8 Aug 2011 03:40:44 +0000"  >&lt;p&gt;@Ted,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;But the rollWriter was able to executed in time. So the following roll-requests were skippted.

I think you meant:
But the rollWriter wasn&apos;t able to execute in time. And the following roll-requests were skipped.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Yes, you&apos;re right. Sorry&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;@ramkrishna,&lt;br/&gt;
There&apos;s several possibilities of &quot;why did rollWriter not executed in time&quot;. It may not get the lock of &quot;cacheFlushLock&quot;. The patch has taken care of it. &lt;br/&gt;
If one request of rollWriter got blocked(was not allowed to hold cacheFlushLock), it will not effect the following requests.&lt;br/&gt;
There&apos;s 3 scenarios of request rollWriter:&lt;br/&gt;
1. Periodic execution.&lt;br/&gt;
2. Current Hlog writer has larger than 256M(It&apos;s a configurable parameter).&lt;br/&gt;
3. Current Hlog replicas is less than the initial replicas.&lt;/p&gt;

&lt;p&gt;The patch of &quot;disable the rolling-request&quot; is just disable the request from scenario 3.&lt;br/&gt;
We needn&apos;t expose the new properties in hbase-default.xml, for they have the default value.&lt;/p&gt;</comment>
                            <comment id="13081027" author="yuzhihong@gmail.com" created="Mon, 8 Aug 2011 16:19:19 +0000"  >&lt;p&gt;Ran through unit tests.&lt;br/&gt;
+1 on patch.&lt;/p&gt;</comment>
                            <comment id="13081369" author="jeason" created="Tue, 9 Aug 2011 02:05:33 +0000"  >&lt;p&gt;Just modified the code comments for the patches of V6.&lt;/p&gt;</comment>
                            <comment id="13081423" author="jeason" created="Tue, 9 Aug 2011 04:21:15 +0000"  >&lt;p&gt;Review Board related address: &lt;a href=&quot;https://reviews.apache.org/r/1354/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1354/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13081424" author="jiraposter@reviews.apache.org" created="Tue, 9 Aug 2011 04:22:27 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/1354/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1354/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-08-09 04:20:46.103510)&lt;/p&gt;


&lt;p&gt;Review request for hbase.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Issue: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-4095&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some large Hlog files(Larger than 10G) appeared in our environment, and I got the reason why they got so huge:&lt;/p&gt;

&lt;p&gt;1. The replicas is less than the expect number. So the method of checkLowReplication will be called each sync.&lt;br/&gt;
2. The method checkLowReplication request log-roll first, and set logRollRequested as true: &lt;br/&gt;
3. requestLogRoll() just commit the roll request. It may not execute in time, like the following scenario(It returns at the beginning, for the numEntries.get() == 0):&lt;br/&gt;
    public byte [][] rollWriter() throws FailedLogCloseException, IOException {&lt;br/&gt;
    // Return if nothing to flush.&lt;br/&gt;
    if (this.writer != null &amp;amp;&amp;amp; this.numEntries.get() &amp;lt;= 0) &lt;/p&gt;
{
      return null;
    }
&lt;p&gt;4.logRollRequested was true until the log-roll executed. So during the time, each request of log-roll in sync() was skipped.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; title=&quot;Hlog may not be rolled in a long time if checkLowReplication&amp;#39;s request of LogRoll is blocked&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4095&quot;&gt;&lt;del&gt;HBASE-4095&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-4095&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  /src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java 1155186 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/1354/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1354/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Please find the test result from the attachment of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-4095&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Jieshan&lt;/p&gt;
</comment>
                            <comment id="13081438" author="ram_krish" created="Tue, 9 Aug 2011 04:47:21 +0000"  >&lt;p&gt;Patch looks good. &lt;/p&gt;
</comment>
                            <comment id="13081440" author="stack" created="Tue, 9 Aug 2011 04:58:36 +0000"  >&lt;p&gt;I&apos;d clean up the extra spaces the patch adds before commit.  It adds a bunch.&lt;/p&gt;

&lt;p&gt;Reviewing I kept scratching my head.  This seems to be a slightly odd case in that it happens on a cluster of three nodes or less yet we&apos;re changing the way a pretty important piece of code works.  Any chance of a unit test Jieshan?  The HLog has a bunch of tests that do various mock ups.  Shouldn&apos;t be too hard studying what goes on there to figure how to get a little test in.  If you think this too much, that&apos;s fine, we can commit since you got two +1s but I thought I&apos;d ask anyways.&lt;/p&gt;</comment>
                            <comment id="13081447" author="jeason" created="Tue, 9 Aug 2011 05:30:15 +0000"  >&lt;p&gt;Yes, this problem happens in a special scenario. Though I&apos;ve taken many times of unit tests on it, I&apos;m running more. The result will be attached later.&lt;br/&gt;
I also took several days tests on the patch in our real environment(During the time, I killed some datanodes and restarted them, and repeated the steps again and again),I paid special attention to the HLog paths, it&apos; indeed a good solution to this problem.&lt;/p&gt;</comment>
                            <comment id="13082260" author="jeason" created="Wed, 10 Aug 2011 09:57:56 +0000"  >&lt;p&gt;I repeated the LLT test for several times. All the tests past except one--TestHFileReaderV1. And I found it had got failure before this patch(I have no time to dig in. But the failure has no relationship with this patch).&lt;br/&gt;
Please find the results from the attached file &quot;LatestLLTResults-20110810.rar&quot;&lt;/p&gt;</comment>
                            <comment id="13082403" author="stack" created="Wed, 10 Aug 2011 15:34:11 +0000"  >&lt;p&gt;Moving out of 0.90.4&lt;/p&gt;</comment>
                            <comment id="13082644" author="stack" created="Wed, 10 Aug 2011 20:13:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Though I&apos;ve taken many times of unit tests on it, I&apos;m running more&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;When I say unit test, I&apos;m talking of adding some code to TestHLog under src/test that &quot;proves&quot; your patch fixes this issue.  Would that be possible?&lt;/p&gt;

&lt;p&gt;(Whats LLT test?)&lt;/p&gt;</comment>
                            <comment id="13082810" author="jeason" created="Thu, 11 Aug 2011 00:30:13 +0000"  >&lt;p&gt;I will do it immediately. Thanks stack&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
(LLT means the unit tests based on the exist test code. I&apos;ll try to write one case.)&lt;/p&gt;</comment>
                            <comment id="13085458" author="jdcryans" created="Tue, 16 Aug 2011 00:39:24 +0000"  >&lt;p&gt;mintolerablereplicas and fewerreplicasrolllimit should be made more readable.&lt;/p&gt;

&lt;p&gt;The log message &quot;it&apos;s a sign of the live datanodes count is less than the minimum tolerable replicas&quot; should be rewritten.&lt;/p&gt;

&lt;p&gt;Fix spelling:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;+    // Force roll writer. The new log file will have the defalt replication,&lt;br/&gt;
+    // and the lowerReplcas roller will be enabled.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not how we do brackets:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isFewerReplicasRollEnabled()
+  {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; fewerReplicasRollEnabled;
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;About the test, there&apos;s a &lt;em&gt;lot&lt;/em&gt; of sleeping in there which makes the test suite run even slower than it is. Any chance of making it not really on time (which is usually flaky) by using tools like mockito?&lt;/p&gt;</comment>
                            <comment id="13085558" author="stack" created="Tue, 16 Aug 2011 06:15:24 +0000"  >&lt;p&gt;Thanks for doing the new test.  That helps.  I&apos;m w/ J-D though that there are lots of timeouts.  Is that necessary?  The trouble with depending on timeouts is that they are not determinate and in different environments may behave differently.  If there is no other way, then so be it... &lt;/p&gt;

&lt;p&gt;There is:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    &lt;span class=&quot;code-comment&quot;&gt;// write some more log data (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; should use a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; hdfs_out)
&lt;/span&gt;-    writeData(table, 3);
-    assertTrue(&lt;span class=&quot;code-quote&quot;&gt;&quot;The log should not roll again.&quot;&lt;/span&gt;, log.getFilenum() == newFilenum);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where you remove an assertion.  Can you leave that in?&lt;/p&gt;

&lt;p&gt;What difference between batchWriteData and writeData?  The pause?  Is the pause needed?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13085569" author="jeason" created="Tue, 16 Aug 2011 06:50:42 +0000"  >&lt;p&gt;I used timeout to wait the logRoll request. Otherwise, we can&apos;t get the correct value by the calling of &quot;log.isFewerReplicasRollEnabled()&quot;. A lot of sleeping indeed seems un-reasonable. I&apos;m thinking about J-d&apos;s suggestion by using the tool of mockito(Though I don&apos;t know whether it could help). &lt;br/&gt;
About the assertion, I&apos;ll put it back.&lt;br/&gt;
batchWriterData is used to write a list of value, but writeData could only put one record. The problem in this issue happens under the scenario of a lot of data were written into the table. So I used batchWriterData instead of writeData. &lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="13085648" author="jeason" created="Tue, 16 Aug 2011 12:04:44 +0000"  >&lt;p&gt;I fixed some spellings and sentences acording to J-d&apos;s suggestion. About the sleepings, I have made some changes. Added a timeout mechanism to decrease the sleeping time.&lt;br/&gt;
But some sleepings is also required. Like the following:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; assertTrue(dfsCluster.stopDataNode(pipeline[1].getName()) != null);
 Thread.sleep(10000);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Maybe there&apos;s some differece according to different env. But some code like this is already there. 10000 maybe a empirical value.&lt;br/&gt;
I tried to use mockito. But it makes things more difficult in this scenario.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is not how we do brackets:&lt;br/&gt;
+  public boolean isFewerReplicasRollEnabled()&lt;br/&gt;
+  &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {
+    return fewerReplicasRollEnabled;
+  }&lt;/span&gt; &lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;I just got the Eclipse-based Apache Formatter xml and applied it in my editor. Before this, I format the code mannually&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. So this problem will not happen again.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Where you remove an assertion. Can you leave that in?&lt;/p&gt;&lt;/blockquote&gt; 
&lt;p&gt;I&apos;ve putted them back.&lt;/p&gt;

&lt;p&gt;stack, J-d, expecting your review again. Thanks a lot.&lt;/p&gt;</comment>
                            <comment id="13085701" author="yuzhihong@gmail.com" created="Tue, 16 Aug 2011 13:49:11 +0000"  >&lt;p&gt;Config parameters are renamed in HLog but not in the test, please make them consistent.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.regionserver.hlog.lowreplication.tolerable&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A better name would be hbase.regionserver.hlog.tolerable.lowreplication&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.regionserver.hlog.lowreplication.rolls&quot;&lt;/span&gt;, 5);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Would hbase.regionserver.hlog.lowreplication.rolllimit be more informative ?&lt;/p&gt;

&lt;p&gt;In batchWriteAndWait() remaining always decrements by 200. This can be made more accurate through calling System.currentTimeMillis()&lt;/p&gt;</comment>
                            <comment id="13086066" author="jeason" created="Wed, 17 Aug 2011 00:40:56 +0000"  >&lt;p&gt;Thanks, Ted. I&apos;ve changed them.&lt;/p&gt;</comment>
                            <comment id="13086792" author="yuzhihong@gmail.com" created="Thu, 18 Aug 2011 04:35:34 +0000"  >&lt;p&gt;+1 on patch version 9.&lt;br/&gt;
Minor comment, timeout parameter should be long:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  void batchWriteAndWait(HTable table, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; start, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; expect, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; timeout)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13086887" author="jeason" created="Thu, 18 Aug 2011 08:34:40 +0000"  >&lt;p&gt;I increased the timeout value to 1000. It&apos;s enough. Thanks, Ted.&lt;/p&gt;</comment>
                            <comment id="13086890" author="jeason" created="Thu, 18 Aug 2011 08:44:03 +0000"  >&lt;p&gt;Sorry, it&apos;s 10000 not 1000.&lt;/p&gt;</comment>
                            <comment id="13087254" author="stack" created="Thu, 18 Aug 2011 20:23:27 +0000"  >&lt;p&gt;Thank you for your persistence Jieshan on trying to get this patch in.  I&apos;m basically +1 on v9.  Below is a small question.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.logRollRequested = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
+        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.logRollRunning = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Should the setting of this.logRollRunning be set instead in a finally block in here in rollWriter?  If an exception thrown after we set the logRollRunning, it looks like logRollRunning could stay set.   My guess is that not doing this would probably not be noticed in that we probably crash out the regionserver if a rollWriter fails but having the flag stuck set might make for some unexpected state?&lt;/p&gt;

&lt;p&gt;So, it looks like we&apos;ll roll 5 times by default before we&apos;ll turn off the low replication log rolling facility &amp;#8211; which is better than a log per sync, right?&lt;/p&gt;

&lt;p&gt;You seem to lose some &apos;liveness&apos; regards file replication setting.  In code before this patch, when rollwriter ran, it&apos;d ask the FS what the replication on the new writer is and that going forward would be the replication to use.  See here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; nextInitialReplication = fs.getFileStatus(newPath).getReplication();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Instead you set the replication once on instantiation of HLog.  See here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.minTolerableReplication = conf.getInt(
+        &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.regionserver.hlog.tolerable.lowreplication&quot;&lt;/span&gt;,
+        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.fs.getDefaultReplication());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;.. and rather than ask the files replication you use the filesystem default value.&lt;/p&gt;

&lt;p&gt;Do you have a good reason for changing this behavior?&lt;/p&gt;

&lt;p&gt;Thanks Jieshan.&lt;/p&gt;



</comment>
                            <comment id="13087448" author="jeason" created="Fri, 19 Aug 2011 01:20:27 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Should the setting of this.logRollRunning be set instead in a finally block in here in rollWriter? If an exception thrown after we set the logRollRunning, it looks like logRollRunning could stay set. My guess is that not doing this would probably not be noticed in that we probably crash out the regionserver if a rollWriter fails but having the flag stuck set might make for some unexpected state?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, it&apos;s good suggestion. It should be put in the finally block. And I&apos;ve changed it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So, it looks like we&apos;ll roll 5 times by default before we&apos;ll turn off the low replication log rolling facility - which is better than a log per sync, right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do you have a good reason for changing this behavior?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Maybe we misunderstood the method of :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; int nextInitialReplication = fs.getFileStatus(newPath).getReplication();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It always returns the default replications value(I&apos;ve taken some tests to prove it. And I affirmed it from some hdfs experts). No matter how many live datanodes there and what&apos;s the actual replications.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;this.minTolerableReplication = conf.getInt(
+        &quot;hbase.regionserver.hlog.tolerable.lowreplication&quot;,
+        this.fs.getDefaultReplication());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So I added a new parameter &quot;hbase.regionserver.hlog.tolerable.lowreplication&quot;. Suppose the default replication value is 3. Before the patch, once the replications decreased, rollWriter should be triggered. To some extend, it&apos;s unreasonable. Because the rest 2 replication is also tolerable sometime. So I made it configurable. &lt;br/&gt;
That&apos;s why I changed the behavior.&lt;/p&gt;</comment>
                            <comment id="13087504" author="stack" created="Fri, 19 Aug 2011 04:00:46 +0000"  >&lt;p&gt;Committed branch and trunk.  Thank you for your perserverance Jieshan.&lt;/p&gt;</comment>
                            <comment id="13087560" author="hudson" created="Fri, 19 Aug 2011 06:09:35 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2125 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2125/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2125/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4095&quot; title=&quot;Hlog may not be rolled in a long time if checkLowReplication&amp;#39;s request of LogRoll is blocked&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4095&quot;&gt;&lt;del&gt;HBASE-4095&lt;/del&gt;&lt;/a&gt; Hlog may not be rolled in a long time if checkLowReplication&apos;s request of LogRoll is blocked&lt;/p&gt;

&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15016397" author="lars_francke" created="Fri, 20 Nov 2015 11:55:06 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12486959" name="HBASE-4095-90-v2.patch" size="7997" author="jeason" created="Tue, 19 Jul 2011 02:03:07 +0000"/>
                            <attachment id="12486560" name="HBASE-4095-90.patch" size="7987" author="jeason" created="Fri, 15 Jul 2011 07:53:15 +0000"/>
                            <attachment id="12486960" name="HBASE-4095-trunk-v2.patch" size="7934" author="jeason" created="Tue, 19 Jul 2011 02:03:07 +0000"/>
                            <attachment id="12486561" name="HBASE-4095-trunk.patch" size="7924" author="jeason" created="Fri, 15 Jul 2011 07:53:15 +0000"/>
                            <attachment id="12489450" name="HBase-4095-V4-Branch.patch" size="7266" author="jeason" created="Fri, 5 Aug 2011 08:51:30 +0000"/>
                            <attachment id="12489651" name="HBase-4095-V5-Branch.patch" size="7303" author="jeason" created="Mon, 8 Aug 2011 03:40:44 +0000"/>
                            <attachment id="12489669" name="HBase-4095-V5-trunk.patch" size="6548" author="jeason" created="Mon, 8 Aug 2011 10:13:40 +0000"/>
                            <attachment id="12489796" name="HBase-4095-V6-branch.patch" size="7312" author="jeason" created="Tue, 9 Aug 2011 02:05:33 +0000"/>
                            <attachment id="12489797" name="HBase-4095-V6-trunk.patch" size="6752" author="jeason" created="Tue, 9 Aug 2011 02:05:33 +0000"/>
                            <attachment id="12490423" name="HBase-4095-V7-branch.patch" size="9871" author="jeason" created="Mon, 15 Aug 2011 11:38:01 +0000"/>
                            <attachment id="12490424" name="HBase-4095-V7-trunk.patch" size="9829" author="jeason" created="Mon, 15 Aug 2011 11:38:01 +0000"/>
                            <attachment id="12490522" name="HBase-4095-V8-branch.patch" size="12633" author="jeason" created="Tue, 16 Aug 2011 12:04:44 +0000"/>
                            <attachment id="12490523" name="HBase-4095-V8-trunk.patch" size="12907" author="jeason" created="Tue, 16 Aug 2011 12:04:44 +0000"/>
                            <attachment id="12490905" name="HBase-4095-V9-branch.patch" size="12830" author="jeason" created="Fri, 19 Aug 2011 01:20:27 +0000"/>
                            <attachment id="12490906" name="HBase-4095-V9-trunk.patch" size="13103" author="jeason" created="Fri, 19 Aug 2011 01:20:27 +0000"/>
                            <attachment id="12486562" name="HlogFileIsVeryLarge.gif" size="76208" author="jeason" created="Fri, 15 Jul 2011 07:57:01 +0000"/>
                            <attachment id="12489960" name="LatestLLTResults-20110810.rar" size="62404" author="jeason" created="Wed, 10 Aug 2011 09:57:56 +0000"/>
                            <attachment id="12488077" name="RelatedLogs2011-07-28.txt" size="7315" author="jeason" created="Thu, 28 Jul 2011 09:24:38 +0000"/>
                            <attachment id="12489449" name="TestResultForPatch-V4.rar" size="565716" author="jeason" created="Fri, 5 Aug 2011 08:51:30 +0000"/>
                            <attachment id="12490586" name="flowChart-IntroductionToThePatch.gif" size="20755" author="jeason" created="Wed, 17 Aug 2011 00:40:56 +0000"/>
                            <attachment id="12487396" name="hbase-root-regionserver-193-195-5-111.rar" size="310264" author="jeason" created="Fri, 22 Jul 2011 05:59:48 +0000"/>
                            <attachment id="12489670" name="surefire-report-V5-trunk.html" size="231678" author="jeason" created="Mon, 8 Aug 2011 10:13:40 +0000"/>
                            <attachment id="12487387" name="surefire-report-branch.html" size="179377" author="jeason" created="Fri, 22 Jul 2011 00:51:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 19 Jul 2011 01:37:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>27170</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hpcv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101370</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>