<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:53:53 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8299/HBASE-8299.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8299] ExploringCompactionPolicy can get stuck in rare cases.</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8299</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;If the files are very oddly sized then it&apos;s possible that ExploringCompactionPolicy can get stuck.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12641492">HBASE-8299</key>
            <summary>ExploringCompactionPolicy can get stuck in rare cases.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="eclark">Elliott Clark</assignee>
                                    <reporter username="eclark">Elliott Clark</reporter>
                        <labels>
                    </labels>
                <created>Tue, 9 Apr 2013 00:00:10 +0000</created>
                <updated>Tue, 15 Oct 2013 04:46:29 +0000</updated>
                            <resolved>Thu, 25 Apr 2013 21:24:58 +0000</resolved>
                                    <version>0.95.1</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.95.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13626007" author="eclark" created="Tue, 9 Apr 2013 00:06:58 +0000"  >&lt;p&gt;If there are no files that are in ratio the ExploringCompactionPolicy can get stuck.&lt;/p&gt;

&lt;p&gt;[ 10 1 100 5000 1 ]&lt;/p&gt;</comment>
                            <comment id="13626020" author="eclark" created="Tue, 9 Apr 2013 00:26:19 +0000"  >&lt;p&gt;Should keep us from getting stuck.&lt;/p&gt;</comment>
                            <comment id="13626107" author="sershe" created="Tue, 9 Apr 2013 01:57:44 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;potentialMatchFiles.size() &amp;gt; bestSelection.size()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; is always true initially and true for any larger potential match after that.&lt;br/&gt;
If no compaction is in ratio (which can be true in normal case), it would always do the maximum possible compaction, wouldn&apos;t it?&lt;br/&gt;
50 1 1, minfiles 3 would major compact as far as I see, which seems wrong, it should wait for more small files to appear.&lt;/p&gt;</comment>
                            <comment id="13626147" author="eclark" created="Tue, 9 Apr 2013 02:41:39 +0000"  >&lt;p&gt;We are only requested to compact when there is an issue (user requested, or the number of files is getting close).  The compaction should do as requested.  If we don&apos;t do something then there&apos;s the chance of getting stuck in a loop.&lt;/p&gt;

&lt;p&gt;If in your same example the max storefiles is 3 there will be an infinite loop if we don&apos;t choose something.&lt;/p&gt;

&lt;p&gt;Maybe if we don&apos;t pass the ratio test it should take the smallest set of files ?&lt;/p&gt;</comment>
                            <comment id="13626913" author="sershe" created="Tue, 9 Apr 2013 18:23:12 +0000"  >&lt;p&gt;There will only be infinite loop (I assume you mean no compaction ever selected?) if there are no more files added.&lt;br/&gt;
I think this is by design, compaction in this case doesn&apos;t make sense... if it doesn&apos;t make sense as minor compaction at one time, it still doesn&apos;t make sense later.&lt;br/&gt;
For the above case getting stuck:&lt;br/&gt;
1) Why isn&apos;t major compaction enough to resolve it?&lt;br/&gt;
2) Another thing is that the above described pattern looks very uncommon. Imho we should optimize for common pattern... if we introduce something that can hurt normal use case by making unnecessary compactions at least it should be configurable and off by default.&lt;/p&gt;

&lt;p&gt;Btw, smallest allowed set of files in the 500 1 1 case is also 500 1 1.&lt;/p&gt;</comment>
                            <comment id="13626914" author="sershe" created="Tue, 9 Apr 2013 18:25:37 +0000"  >&lt;p&gt;The intuitive reason to compact 10 1 100 (for example) from [ 10 1 100 5000 1 ] is relative size to the 5000 file. Maybe that could be encoded in a heuristic.&lt;/p&gt;</comment>
                            <comment id="13627041" author="eclark" created="Tue, 9 Apr 2013 20:18:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;(I assume you mean no compaction ever selected?)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Nope.  I mean an infinite loop of compaction selection.  If the number of store files doesn&apos;t change and you are over the high water mark then after a compaction is done another selection will be queued.&lt;/p&gt;

&lt;p&gt;So there have been problems in the real world with previous compaction selection algorithms not choosing files to compact.  It is a bug if there are no files chosen when a compaction is queued.  It&apos;s not as rare as you seem to think.  Ask Stack about the half size file problem.&lt;/p&gt;

&lt;p&gt;This change only affects the algorith when it can&apos;t find any files sets in ratio and have need of a compaction.  Just ignoring the need for a compaction is not an option.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The intuitive reason to compact 10 1 100 (for example) from [ 10 1 100 5000 1 ] is relative size to the 5000 file. Maybe that could be encoded in a heuristic.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s a completely different algorithm.  If you want to write that then I would feel better doing that in a different issue.  Right now we need to fix the policy that&apos;s currently there.&lt;/p&gt;</comment>
                            <comment id="13627133" author="sershe" created="Tue, 9 Apr 2013 21:25:40 +0000"  >&lt;p&gt;The compaction is not only requested when it&apos;s necessary. There&apos;s periodic compaction checker, and there&apos;s compaction when region is opened. needsCompaction also doesn&apos;t check ratio iirc, so number of files would be enough to call compaction selection. It doesn&apos;t mean there must be selection. In such cases with one large file and a few new memstore flush files that are not yet by themselves within the ratio, there must be no compaction.&lt;br/&gt;
If something calls selection non-stop when there&apos;s no reasonable selection to be made it&apos;s a different problem.&lt;/p&gt;</comment>
                            <comment id="13627137" author="sershe" created="Tue, 9 Apr 2013 21:28:25 +0000"  >&lt;p&gt;if it&apos;s above blockingFileCount (you mean that by high watermark?) should the force flag be passed for this case? Then it can do no-ratio compaction.&lt;/p&gt;</comment>
                            <comment id="13627145" author="eclark" created="Tue, 9 Apr 2013 21:31:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;If something calls selection non-stop when there&apos;s no reasonable selection to be made it&apos;s a different problem.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Exactly that&apos;s the odd thing not the normal.  We shouldn&apos;t change the algorithm to protect a user from that.  We should make sure the normal case is fine.  The normal case is that compaction is needed because store says needsCompaction() = true.  If there&apos;s some times that compactions are requested when not needed then we should fix that not patch around it here.&lt;/p&gt;</comment>
                            <comment id="13627150" author="sershe" created="Tue, 9 Apr 2013 21:43:24 +0000"  >&lt;p&gt;Current case definitely doesn&apos;t work like that, see needsComaction implementation. Its semantics is more like mayNeedCompaction, a cheap check, and request actually does the heavy lifting. &lt;br/&gt;
And code expects request to not request anything - that can happen both due to logic of the policy, and due to coprocessor overrides, or concurrent compaction requests from coprocessors.&lt;br/&gt;
That seems like reasonable logic for me, making it possible to call the method speculatively when region opens/memstore flushes/compaction finishes (for schemes that may require multiple compactions like level or stripe).&lt;br/&gt;
Force flag (or method) can solve the forcing compaction issue here.&lt;br/&gt;
Otherwise needsCompaction basically needs to be true to requestCompaction implementation (at least).&lt;/p&gt;</comment>
                            <comment id="13627151" author="sershe" created="Tue, 9 Apr 2013 21:43:59 +0000"  >&lt;p&gt;*concurrent compaction requests, including from coprocessors&lt;/p&gt;</comment>
                            <comment id="13627158" author="eclark" created="Tue, 9 Apr 2013 21:49:16 +0000"  >&lt;p&gt;I don&apos;t understand what you&apos;re looking for.  You&apos;re asking to change the whole algorithm without specific requests.  If you want to propose another algorithm for compaction selection then another issue would be best.&lt;/p&gt;

&lt;p&gt;As it stands now ExploringCompactionPolicy is broken and either needs to be changed so that it can&apos;t get stuck (done in this patch) or ExploringCompactionPolicy needs to be removed (breaking bulk loads again).&lt;/p&gt;</comment>
                            <comment id="13627177" author="sershe" created="Tue, 9 Apr 2013 22:01:22 +0000"  >&lt;p&gt;I get that it needs to be fixed, but this fix affects the cases beyond the ones it&apos;s looking to solve, so I am looking for another, or modified, fix.&lt;/p&gt;

&lt;p&gt;This fix changes the logic of requestCompaction to force compaction   every time it&apos;s called when needsCompaction is true, which is different from current behavior (and that for old default policy) where needsCompaction is an inaccurate pre-check and real decision is done in requestCompaction, which is called speculatively form many place. Changing semantics of requestCompaction like that will cause bad compactions in normal cases where compaction is not needed. &lt;br/&gt;
Including bad consequences with many compactions (see compaction checker - how it runs compactions).&lt;br/&gt;
I am looking to avoid that.&lt;/p&gt;

&lt;p&gt;The ways to avoid it that can be used are:&lt;br/&gt;
1) Keep this patch but add force flag/method which will trigger this  behavior of &quot;select compaction regardless of ratio&quot;.&lt;br/&gt;
2) Change semantics of needsCompaction and requestCompaction across the code so that the assumption this patch makes is actually true.&lt;br/&gt;
3) Change the heuristic to not get stuck in such case via other means.&lt;/p&gt;

&lt;p&gt;It seems that (1) is the simplest. &lt;/p&gt;</comment>
                            <comment id="13635918" author="eclark" created="Fri, 19 Apr 2013 01:17:41 +0000"  >&lt;p&gt;I&apos;ve done a good amount of research into what fixing this will mean.&lt;/p&gt;

&lt;p&gt;Here&apos;s a patch with all of the different selection policies that I have come up with to test this.&lt;/p&gt;</comment>
                            <comment id="13635925" author="eclark" created="Fri, 19 Apr 2013 01:31:04 +0000"  >&lt;p&gt;Then running the perf tests gets this result:&lt;/p&gt;
&lt;h2&gt;&lt;a name=&quot;Data&quot;&gt;&lt;/a&gt;Data&lt;/h2&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Name&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Max Files&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Min Files&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Ratio&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;IO&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;File Diff&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;IO Per File&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;EverythingPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;566916287&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-113090&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5012.97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;RandomPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;457296661&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-109033&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4194.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NoStuckLargestPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30827212&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-111271&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;277.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NoStuckBestRatioPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25519685&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-111439&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;229.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;RatioBasedCompactionPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25242372&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-111622&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;226.14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NoStuckSmallestPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24200357&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-111339&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;217.36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;ExploringCompactionPolicy&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23526926&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-110921&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;212.11&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;h2&gt;&lt;a name=&quot;Explanations&quot;&gt;&lt;/a&gt;Explanations&lt;/h2&gt;
&lt;ul&gt;
	&lt;li&gt;Random Policy just illustrates what the worst case is&lt;/li&gt;
	&lt;li&gt;Everything policy compacts all files all the time.&lt;/li&gt;
	&lt;li&gt;The No Stuck Smallest policy seems like the best all around pick for this.  It won&apos;t get stuck because when it hits the storefile blocking limit it ignores the ratio.  It then picks the smallest set of files to compact.&lt;/li&gt;
	&lt;li&gt;The No Stuck Best Ratio does similar except instead of trying to pick the smallest set of files it chooses a set of files that are close to being in ratio.  This works really well on spiky load but really badly on sinusoidal work loads.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;&lt;a name=&quot;Testing&quot;&gt;&lt;/a&gt;Testing&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt; put this patch up on a 0.94 cluster.  He then started a random gets, while looping a bulk load job.  For the old compaction algorithm we ended up with max average latency of 136ms. For the new algorithm that doesn&apos;t get stuck we ended up with a max average latency of 20ms.  Lots of compactions were skipped.  The compactions that were chosen all were what I would have expected.  No major compactions were needed or triggered.&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Plan&quot;&gt;&lt;/a&gt;Plan&lt;/h2&gt;
&lt;p&gt;So I&apos;ll clean up the code and make the NoStuckSmallestPolicy default.&lt;/p&gt;</comment>
                            <comment id="13635967" author="hadoopqa" created="Fri, 19 Apr 2013 02:27:07 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12579464/HBASE-8299-1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12579464/HBASE-8299-1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5353//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13636070" author="yuzhihong@gmail.com" created="Fri, 19 Apr 2013 04:58:27 +0000"  >&lt;p&gt;NoStuckSmallestPolicy needs license header.&lt;br/&gt;
For NoStuckSmallestPolicy#applyCompactionPolicy():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (bestSelection.size() == 0 &amp;amp;&amp;amp; mightBeStuck) {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;StoreFile&amp;gt;(smallest);
+    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When bestSelection.size() == 0 &amp;amp;&amp;amp; !mightBeStuck, we return bestSelection. Would smallest be empty in this case ?&lt;/p&gt;
</comment>
                            <comment id="13636119" author="eclark" created="Fri, 19 Apr 2013 06:19:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would smallest be empty in this case ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Probably not, assuming that there is some set of files that can satisfy the other conditions on a compaction.  See the previous discussion on why we want to skip some compactions.&lt;/p&gt;</comment>
                            <comment id="13636882" author="sershe" created="Fri, 19 Apr 2013 21:03:25 +0000"  >&lt;p&gt;Thanks, great testing.&lt;/p&gt;

&lt;p&gt;Do you intend to commit all the policies e.g. EverythingPolicy?&lt;br/&gt;
Didn&apos;t review them yet assuming you would only commit the best one.&lt;br/&gt;
Ok, I actually reviewed one accidentally.&lt;/p&gt;

&lt;p&gt;For NoStuckBestRatio, if it gets committed:&lt;br/&gt;
When not stuck, the compactions are only judged based on selection size and file size, foundRatio and bestRatio are never compared.&lt;br/&gt;
When stuck, the reverse is true, it chooses best ratio without regard to selection size or file size. Is it intended?&lt;/p&gt;

&lt;p&gt;For both this and the NoStuckSmallest one:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (files.size() &amp;lt; 2) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The min size sanity check should ensure it&apos;s 2 or more. Should it do precondition check?&lt;br/&gt;
Also nit^2 in this function - total size computed inside and outside in the caller, could just pass it in. Too bad Java doesn&apos;t have out/pointer parameters &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Nit^3 - the loop could actually just find the biggest file (it could be done in the previous loop too), by definition it would have the biggest ratio. Doesn&apos;t really matter.&lt;br/&gt;
There are some blank lines.&lt;/p&gt;


&lt;p&gt;One test set was removed but nothing was added; need a couple new tests to ensure it doesn&apos;t get broken?&lt;/p&gt;</comment>
                            <comment id="13637002" author="eclark" created="Fri, 19 Apr 2013 23:18:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Do you intend to commit all the policies e.g. EverythingPolicy?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think so.  They are great to get a sense of what compactions could be like.  But they aren&apos;t really useful for any read users.  So if anyone wanted to use them as a benchmark then I would move those algorithms into the test folders.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When not stuck, the compactions are only judged based on selection size and file size, foundRatio and bestRatio are never compared.&lt;br/&gt;
When stuck, the reverse is true, it chooses best ratio without regard to selection size or file size. Is it intended?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes this is intended.  The thought was to keep the policy as close to ExploringCompactionPolicy as possible.  So if not stuck take the same set of files that Exploring Compaction Policy would.  If we are stuck take the set of files that are the closest to being in ratio.  This policy works really well if there are giant spikes (see the last set of files created in the perf test).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The min size sanity check should ensure it&apos;s 2 or more. Should it do precondition check?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;d much rather protect against a bug then try and prematurely optimize.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also nit^2 in this function - total size computed inside and outside in the caller, could just pass it in. Too bad Java doesn&apos;t have out/pointer parameters &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You brought this up last time.  Without some profiling I&apos;m not up for optimizing this code.  I don&apos;t think that it&apos;s needed at all.  Readability is worth a lot, especially in something that is as complex as our compactions have become.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Nit^3 - the loop could actually just find the biggest file&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m not convinced that removing a division is worth the loss of clarity.&lt;/p&gt;</comment>
                            <comment id="13637016" author="sershe" created="Fri, 19 Apr 2013 23:37:11 +0000"  >&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;The min size sanity check should ensure it&apos;s 2 or more. Should it do precondition check? &lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I&apos;d much rather protect against a bug then try and prematurely optimize.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It&apos;s not optimization, just correctness, we never should be attempting to compact one file here.&lt;/p&gt;

&lt;p&gt;With other stuff in my mind less lines generally means more clarity.&lt;/p&gt;

&lt;p&gt;+1 assuming the all of the policies will be removed except the good one.&lt;/p&gt;</comment>
                            <comment id="13637067" author="jmspaggi" created="Sat, 20 Apr 2013 01:34:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;So if anyone wanted to use them as a benchmark then I would move those algorithms into the test folders.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 with the idea of moving the algorithms into the test folders. Might be good to keep them for later uses.&lt;/p&gt;</comment>
                            <comment id="13637071" author="sershe" created="Sat, 20 Apr 2013 01:42:57 +0000"  >&lt;p&gt;yeah that also works&lt;/p&gt;</comment>
                            <comment id="13638707" author="eclark" created="Tue, 23 Apr 2013 01:53:31 +0000"  >&lt;ul&gt;
	&lt;li&gt;Added in Max Compact size to Exploring compaction selection.&lt;/li&gt;
	&lt;li&gt;Made sure that no RatioBasedCompactionPolicy can get stuck.  Turns out that in extreme cases even the old compaction policy can get stuck.&lt;/li&gt;
	&lt;li&gt;deleted the un-used policies (Smallest ratio)&lt;/li&gt;
	&lt;li&gt;Tweaked the perf test so that it is more pluggable&lt;/li&gt;
	&lt;li&gt;Added new use cases to the testing&lt;/li&gt;
	&lt;li&gt;Changed the test output format.&lt;/li&gt;
	&lt;li&gt;Added in comments with more details&lt;/li&gt;
	&lt;li&gt;Fixed some style issues.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13638722" author="hadoopqa" created="Tue, 23 Apr 2013 02:22:13 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12579959/HBASE-8299-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12579959/HBASE-8299-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 35 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5389//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13639279" author="sershe" created="Tue, 23 Apr 2013 17:35:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;This class will search all possibilities for different &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;unfinished&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;.subList(0, Math.max(0,candidateSelection.size() - 1 - comConf.getMinFilesToCompact()))&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;subList&apos;s 2nd argument is exclusive, so -1 is not needed as far as I see. E.g. 5 files, 3 min files, will now remove [0, 1), leaving 4 files not 3.&lt;br/&gt;
I think test is needed for this path.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;//To change body of implemented methods use File | Settings | File Templates.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Leftovers.&lt;/p&gt;

&lt;p&gt;There are long lines.&lt;/p&gt;</comment>
                            <comment id="13639312" author="jdcryans" created="Tue, 23 Apr 2013 17:54:48 +0000"  >&lt;p&gt;One important thing that was changed in the latest patch that you haven&apos;t mentioned Elliott is that getMinCompactSize() is now compared against the whole selection&apos;s size. This is important because before that, any small files could easily trigger major compactions. I&apos;ve been running with a patched 0.94 over the weekend while inserting tiny bulk loaded files every ~10 minutes and the only times it major compacted was when the sum of all the bulk loaded files was within ratio of the main big file. I&apos;m really happy about this patch.&lt;/p&gt;

&lt;p&gt;+1 for commit once the patch is cleaned up.&lt;/p&gt;</comment>
                            <comment id="13639442" author="eclark" created="Tue, 23 Apr 2013 19:20:05 +0000"  >&lt;p&gt;Formatting.&lt;br/&gt;
Cleaned up the sublist call&lt;br/&gt;
Changed random number generation so that every class gets a different set of random numbers.&lt;/p&gt;</comment>
                            <comment id="13639582" author="hadoopqa" created="Tue, 23 Apr 2013 20:25:44 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12580106/HBASE-8299-3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12580106/HBASE-8299-3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 35 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestAdmin&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestTableLockManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5407//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13640758" author="sershe" created="Wed, 24 Apr 2013 18:28:37 +0000"  >&lt;p&gt;+1... I assume the tests above are unrelated?&lt;/p&gt;</comment>
                            <comment id="13640955" author="eclark" created="Wed, 24 Apr 2013 21:11:52 +0000"  >&lt;p&gt;yeah there was a trunk build break.  Everything&apos;s back to normal.  I&apos;ll check this in later today.&lt;/p&gt;


&lt;p&gt;Thanks for the review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13642237" author="eclark" created="Thu, 25 Apr 2013 21:24:58 +0000"  >&lt;p&gt;Committed.&lt;/p&gt;

&lt;p&gt;Thanks for the indepth reviews and testing guys.&lt;/p&gt;</comment>
                            <comment id="13642581" author="hudson" created="Fri, 26 Apr 2013 04:28:13 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #4080 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4080/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4080/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8299&quot; title=&quot;ExploringCompactionPolicy can get stuck in rare cases.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8299&quot;&gt;&lt;del&gt;HBASE-8299&lt;/del&gt;&lt;/a&gt; ExploringCompactionPolicy can get stuck in rare cases. (Revision 1475966)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreEngine.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreConfigInformation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/ExploringCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/RatioBasedCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultCompactSelection.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/EverythingPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ExplicitFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/GaussianFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/MockStoreFileGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/PerfTestCompactionPolicies.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SemiConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SinusoidalFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SpikyFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/StoreFileListGenerator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13642682" author="hudson" created="Fri, 26 Apr 2013 08:34:35 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #163 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/163/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/163/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8299&quot; title=&quot;ExploringCompactionPolicy can get stuck in rare cases.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8299&quot;&gt;&lt;del&gt;HBASE-8299&lt;/del&gt;&lt;/a&gt; ExploringCompactionPolicy can get stuck in rare cases. (Revision 1475965)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreEngine.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreConfigInformation.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/ExploringCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/RatioBasedCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultCompactSelection.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/EverythingPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ExplicitFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/GaussianFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/MockStoreFileGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/PerfTestCompactionPolicies.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SemiConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SinusoidalFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SpikyFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/StoreFileListGenerator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13642796" author="hudson" created="Fri, 26 Apr 2013 12:35:51 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #81 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/81/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/81/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8299&quot; title=&quot;ExploringCompactionPolicy can get stuck in rare cases.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8299&quot;&gt;&lt;del&gt;HBASE-8299&lt;/del&gt;&lt;/a&gt; ExploringCompactionPolicy can get stuck in rare cases. (Revision 1475965)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreEngine.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreConfigInformation.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/ExploringCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/RatioBasedCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultCompactSelection.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/EverythingPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ExplicitFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/GaussianFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/MockStoreFileGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/PerfTestCompactionPolicies.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SemiConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SinusoidalFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SpikyFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/StoreFileListGenerator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13642831" author="hudson" created="Fri, 26 Apr 2013 13:22:13 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #511 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/511/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/511/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8299&quot; title=&quot;ExploringCompactionPolicy can get stuck in rare cases.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8299&quot;&gt;&lt;del&gt;HBASE-8299&lt;/del&gt;&lt;/a&gt; ExploringCompactionPolicy can get stuck in rare cases. (Revision 1475966)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreEngine.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreConfigInformation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/ExploringCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/RatioBasedCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultCompactSelection.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/EverythingPolicy.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/ExplicitFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/GaussianFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/MockStoreFileGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/PerfTestCompactionPolicies.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SemiConstantSizeFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SinusoidalFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/SpikyFileListGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/StoreFileListGenerator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12644945">HBASE-8448</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12577663" name="HBASE-8299-0.patch" size="2638" author="eclark" created="Tue, 9 Apr 2013 00:26:19 +0000"/>
                            <attachment id="12579464" name="HBASE-8299-1.patch" size="28106" author="eclark" created="Fri, 19 Apr 2013 01:17:41 +0000"/>
                            <attachment id="12579959" name="HBASE-8299-2.patch" size="45580" author="eclark" created="Tue, 23 Apr 2013 01:53:31 +0000"/>
                            <attachment id="12580106" name="HBASE-8299-3.patch" size="48800" author="eclark" created="Tue, 23 Apr 2013 19:20:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 9 Apr 2013 01:57:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>321908</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1jjhr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>322253</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.96notable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>