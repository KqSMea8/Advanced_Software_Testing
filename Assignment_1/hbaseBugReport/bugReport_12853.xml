<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:37:05 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12853/HBASE-12853.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12853] distributed write pattern to replace ad hoc &apos;salting&apos;</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12853</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;In reviewing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11682&quot; title=&quot;Explain hotspotting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11682&quot;&gt;&lt;del&gt;HBASE-11682&lt;/del&gt;&lt;/a&gt; (Description of Hot Spotting), one of the issues is that while &apos;salting&apos; alleviated  regional hot spotting, it increased the complexity required to utilize the data.  &lt;/p&gt;

&lt;p&gt;Through the use of coprocessors, it should be possible to offer a method which distributes the data on write across the cluster and then manages reading the data returning a sort ordered result set, abstracting the underlying process. &lt;/p&gt;

&lt;p&gt;On table creation, a flag is set to indicate that this is a parallel table. &lt;/p&gt;

&lt;p&gt;On insert in to the table, if the flag is set to true then a prefix is added to the key.  e.g. &amp;lt;region server#&amp;gt;- or &amp;lt;region server #|| where the region server # is an integer between 1 and the number of region servers defined.  &lt;/p&gt;

&lt;p&gt;On read (scan) for each region server defined, a separate scan is created adding the prefix. Since each scan will be in sort order, its possible to strip the prefix and return the lowest value key from each of the subsets. &lt;/p&gt;
</description>
                <environment></environment>
        <key id="12767426">HBASE-12853</key>
            <summary>distributed write pattern to replace ad hoc &apos;salting&apos;</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="msegel">Michael Segel </reporter>
                        <labels>
                    </labels>
                <created>Wed, 14 Jan 2015 13:16:02 +0000</created>
                <updated>Sun, 2 Aug 2015 21:12:44 +0000</updated>
                            <resolved>Sun, 2 Aug 2015 21:12:17 +0000</resolved>
                                                                        <due></due>
                            <votes>1</votes>
                                    <watches>13</watches>
                                                                <comments>
                            <comment id="14276897" author="msegel" created="Wed, 14 Jan 2015 13:20:43 +0000"  >&lt;p&gt;On second thought rather than try to automate the number of regions to be used in the prefix, it may just be easier to define a parameter that contains the number of parallel buckets. (Apologies for using a very loose terminology.) We could say buckets or parallelization factor.  &lt;/p&gt;

&lt;p&gt;We may have 100 RS but only want to use a parallel factor of 10 which could be enough to alleviate the hot spotting. It also makes it easier if the size of the cluster is relatively dynamic with the adding and subtracting of RS. &lt;/p&gt;

&lt;p&gt;Also apologies if this concept has been already raised. &lt;/p&gt;</comment>
                            <comment id="14277024" author="msegel" created="Wed, 14 Jan 2015 15:11:19 +0000"  >&lt;p&gt;Note that some of this may actually be in Phoenix so it could be redundant...&lt;br/&gt;
&lt;a href=&quot;http://phoenix.apache.org/salted.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://phoenix.apache.org/salted.html&lt;/a&gt;&lt;br/&gt;
Implies some of this... but does not go in to detail...&lt;/p&gt;</comment>
                            <comment id="14277341" author="lhofhansl" created="Wed, 14 Jan 2015 18:03:21 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=msegel&quot; class=&quot;user-hover&quot; rel=&quot;msegel&quot;&gt;Michael Segel &lt;/a&gt;. It would most be client side code, right? I.e. prefixing keys before issuing the writes and performing the right fanning out upon scanning. I don&apos;t think that would need any server-side logic (a.k.a. coprocessors), but I might be wrong.&lt;/p&gt;</comment>
                            <comment id="14277413" author="msegel" created="Wed, 14 Jan 2015 18:40:18 +0000"  >&lt;p&gt;Lars, &lt;br/&gt;
No it will be all server side. &lt;br/&gt;
That&apos;s the beauty of it. The client won&apos;t know anything about the underlying differences. &lt;/p&gt;

&lt;p&gt;Today, you can easily do this client side and then you have the responsibility for managing the N scanners and merging the result set(s). The idea is to do this server side so that clients won&apos;t need to know any of the details. &lt;/p&gt;

&lt;p&gt;Again, Phoenix implies that it does something like this. However, having a tighter coupling to HBase would mean that there is no client side changes.  Clients would have one API to get data from a regular table or one that used buckets. The only difference would be in the table definition and parameters for the table. &lt;/p&gt;

&lt;p&gt;Does that make sense? &lt;/p&gt;</comment>
                            <comment id="14277488" author="lhofhansl" created="Wed, 14 Jan 2015 19:14:57 +0000"  >&lt;p&gt;The coprocessors are per region, and you want the &quot;salting&quot; for spreading across regions. So you mean to have some region server contact other region server in order to execute a portion of a scan there?&lt;/p&gt;

&lt;p&gt;Phoenix does the parallelization on the client and then farms out the work to the various region servers, which then execute the requests with the help of per region coprocessors.&lt;/p&gt;

&lt;p&gt;Would be nice to completely hide this. We might have to invent something new for that.&lt;/p&gt;</comment>
                            <comment id="14277990" author="Apache9" created="Thu, 15 Jan 2015 00:40:50 +0000"  >&lt;p&gt;I think a client side library is enough.&lt;/p&gt;

&lt;p&gt;You can not hide everything. At least user should specify that he wants to use this feature, right? Then use a client side library is not much different with a server side solution I think, you can hide all the logic in the library(Maybe a different Table implementation?).&lt;/p&gt;

&lt;p&gt;We should be very careful when making a regionserver contact other regionservers. It will easily reduce the availability of the whole cluster.&lt;/p&gt;</comment>
                            <comment id="14278320" author="liushaohui" created="Thu, 15 Jan 2015 06:23:05 +0000"  >&lt;p&gt;Intel hadoop team has opensourced a salted table implement at &lt;a href=&quot;https://github.com/intel-hadoop/SaltedHTable&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/intel-hadoop/SaltedHTable&lt;/a&gt;.&lt;br/&gt;
It is also a client-slide library and the code is very clean.&lt;/p&gt;

&lt;p&gt;Personally, a client-slide library is simple enough for salted table.&lt;/p&gt;</comment>
                            <comment id="14280440" author="msegel" created="Fri, 16 Jan 2015 15:59:45 +0000"  >
&lt;p&gt;First, lets get away from using the term salted. &lt;br/&gt;
Salts do have a specific meaning and its associated with cryptography. While we&apos;re clearly not talking about cryptography, it implies that the prefix is orthogonal to the data set and the number of salted values is bound by the width of the prefix. &lt;/p&gt;

&lt;p&gt;Using the term bucketing the table would be more appropriate because in this example, you&apos;re assigning a prefix from a round robin approach. &lt;/p&gt;

&lt;p&gt;I have to apologize, I don&apos;t play with HBase that much these days... my work is client driven.&lt;br/&gt;
With respect to client/server it seems that the delineation between client and server appears to be a bit different from what I would expect from other databases.   In HBase, the client creates a scan, and then has the hmaster will manage the scan and return a pointer to the result set? &lt;/p&gt;

&lt;p&gt;With respect to the client side code... you&apos;re missing the point. You want to abstract the bucketing from the client. So that the same scan will run against a bucketed table and an un-bucketed table. The only exposed difference is that the metadata for the table will specify the number of buckets which defaults to 1 (no bucketing) &lt;/p&gt;
</comment>
                            <comment id="14280461" author="msegel" created="Fri, 16 Jan 2015 16:21:46 +0000"  >&lt;p&gt;&quot;An implemented one is OneBytePrefixKeySalter, where the prefix is hash(RowKey)%buckets&quot; &lt;/p&gt;

&lt;p&gt;That&apos;s fine. But now if I have another client, I have to know that the table is bucketed. (Yes, I am refusing to use the term salt when talking about this... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;And not only do you need to know that the table is bucketed, you need to know the number of buckets.  You are also assuming that the individual is using a java application to query the data.  What happens if they are not? &lt;br/&gt;
And that they&apos;ve got the Intel library. &lt;/p&gt;

&lt;p&gt;If its done server side all of that goes away.&lt;/p&gt;</comment>
                            <comment id="14281074" author="lhofhansl" created="Sat, 17 Jan 2015 00:56:51 +0000"  >&lt;p&gt;Let&apos;s see a design &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14282337" author="msegel" created="Mon, 19 Jan 2015 10:09:07 +0000"  >&lt;p&gt;Sure... &lt;/p&gt;

&lt;p&gt;Just a couple of things... &lt;br/&gt;
1) I would like to make sure I understand the split between client/server in HBase works the way I think it does. &lt;/p&gt;

&lt;p&gt;2) I get some free time. (Day Job, conference talks, R&amp;amp;D, ...) &lt;/p&gt;

&lt;p&gt;This is one issue that is specific to HBase and doesn&apos;t conflict with any prior work I may have done. &lt;/p&gt;</comment>
                            <comment id="14291765" author="msegel" created="Mon, 26 Jan 2015 12:24:39 +0000"  >&lt;p&gt;Before we go in to a design, I need to get a bit more information. &lt;br/&gt;
As a practice, I don&apos;t review HBase source code and work from the exposed APIs. &lt;br/&gt;
Of course looking at the HBase API these days is a bit of a CF since most of the APIs are deprecated referring to other deprecated classes / interfaces etc ... not to mention there a couple of different releases...&lt;/p&gt;

&lt;p&gt;So we start with a Connection instance which we get a instance of class Table for the given table. &lt;br/&gt;
Ignoring put() for a moment,  we have get() and getScanner() methods. &lt;/p&gt;

&lt;p&gt;What happens on the server side of the connection when the client calls getScanner() or get() ? &lt;/p&gt;

&lt;p&gt;Part of the issue is that a simple scanner won&apos;t work right unless you end up preprocessing it and treating it as a scanner but with a default (blank) set of filters. &lt;/p&gt;

&lt;p&gt;So while I can walk you through the logic and give you a resulting diagram, I need a committer who&apos;s familiar with the server side workings.  Then it should be a pretty straight forward thing to implement. &lt;/p&gt;

&lt;p&gt;-Mike&lt;/p&gt;</comment>
                            <comment id="14329574" author="msegel" created="Fri, 20 Feb 2015 21:21:53 +0000"  >&lt;p&gt;The design seems straight forward, at least as to a starting point. (YMMV) &lt;/p&gt;

&lt;p&gt;The client will create a reference to a table and then instantiate a scanner object along with any associated filters. &lt;br/&gt;
The client then passes this object to the server expecting a result set to be returned. &lt;/p&gt;

&lt;p&gt;On the server side, it seems that the HBase Master (active) gets the scan request and then starts to do the heavy lifting. &lt;/p&gt;

&lt;p&gt;By providing more intelligence to this process, its possible to do more than just allow for bucketed tables to abstract the buckets and act as if its a regular table. &lt;br/&gt;
The key question is how to best redesign this initial entry point to allow for such extensibility.&lt;/p&gt;
</comment>
                            <comment id="14329576" author="msegel" created="Fri, 20 Feb 2015 21:23:00 +0000"  >&lt;p&gt;I should also add that this is one area that one must take caution in the design because if not done properly or cleanly, it will kill performance. &lt;/p&gt;</comment>
                            <comment id="14363448" author="anoop.hbase" created="Mon, 16 Mar 2015 16:36:46 +0000"  >&lt;p&gt;Pls note that in reads HBase Master wont do any co-ordination or so.  The client talks directly with RS where its intended region resides.  &lt;/p&gt;</comment>
                            <comment id="14384102" author="msegel" created="Fri, 27 Mar 2015 16:32:36 +0000"  >&lt;p&gt;Ok, &lt;br/&gt;
So then when a scanner object is passed from the client to the server the client will ask the HMaster for the region(s) that satisfy the scan, or just the first region? &lt;/p&gt;

&lt;p&gt;This would imply that when running a m/r that the m/r program will ask the HMaster for the regions and then will create a split for each region in the list and then each mapper task will initiate its own scan over a specific region? &lt;/p&gt;

&lt;p&gt;Ok... on one level for m/r that makes sense because you wouldn&apos;t want 1000 mappers trying to coordinate queries with the HMaster at the same time because it could become a bottleneck. &lt;/p&gt;

&lt;p&gt;On the other side, if you&apos;re using HBase as a database outside of Map/Reduce, you&apos;d want to have a query engine that would abstract the underlying workings of a scan from the client. &lt;/p&gt;
</comment>
                            <comment id="14384111" author="msegel" created="Fri, 27 Mar 2015 16:41:03 +0000"  >&lt;p&gt;To add to my comment in response to Anoop, &lt;/p&gt;

&lt;p&gt;I wanted to abstract the concept of a scan from the application.  Normally you&apos;d do this on the server side of the client/server split, however... w.r.t HBase, this becomes a bit more difficult. &lt;/p&gt;

&lt;p&gt;Ok... &lt;br/&gt;
So if I understand this.&lt;br/&gt;
Client passes scanner object to instance of table in the table.scan(scanner) call. &lt;br/&gt;
So still on the client side, the  client&apos;s table object will then connect with the HMaster and determine which region and region server is required to start the table scan, and then the client connects directly to the region and starts the scan? &lt;/p&gt;

&lt;p&gt;What do you call the scanner object that&apos;s running on the region? &lt;/p&gt;</comment>
                            <comment id="14385112" author="anoop.hbase" created="Sat, 28 Mar 2015 04:14:52 +0000"  >&lt;p&gt;Just one correction..  The client side has to contact the META (single) region to determine the regions and their location for the scan. So not HM.  (If HM is acting as another RS and holding META region, then yes it goes to HM.)  So where is META region sits matters. Hope am making it clear now.&lt;/p&gt;</comment>
                            <comment id="14392726" author="msegel" created="Thu, 2 Apr 2015 13:58:05 +0000"  >&lt;p&gt;Sorry, I thought that the HM had the META table cached in memory. Didn&apos;t think that the META was too large....&lt;/p&gt;

&lt;p&gt;Ok, so then it looks like what I want to do is all client side then. &lt;/p&gt;

&lt;p&gt;The design is pretty straight forward. &lt;/p&gt;

&lt;p&gt;The number of buckets is fixed at the time of table creation. &lt;br/&gt;
The row key is a composite key of  bucket_id | rowkey  and the bucket_id is derived from taking the modulus N of the first byte of the row key. (Giving you 0xFF(255) max buckets. ) Then when you want to fetch a single row given the rowkey, you can find the bucket and fetch the single row. If you need to do a scan, given the start row, you can then create N parallel threads and within each thread, start the scan by prepending the bucket_id |  to the start rowkey.&lt;/p&gt;

&lt;p&gt;When returning the result set, you can then strip off the bucket_id | and take the MIN(value&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) value&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; is the next row from each scanner, popping it off the stack. This will give you a single result that is guaranteed to still be within sort order. &lt;/p&gt;

&lt;p&gt;Its all client side and it abstracts the bucketing from the user/client code so that the same code will run against either table without any changes.&lt;/p&gt;
</comment>
                            <comment id="14392727" author="msegel" created="Thu, 2 Apr 2015 13:59:14 +0000"  >&lt;p&gt;Sorry, the value &apos;(&apos; n &apos;)&apos; gets translated in to a downvote &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                            <comment id="14633793" author="msegel" created="Mon, 20 Jul 2015 16:35:16 +0000"  >&lt;p&gt;Nothing new? &lt;/p&gt;

&lt;p&gt;Seriously?&lt;/p&gt;

&lt;p&gt;This is a trivial feature.&lt;/p&gt;</comment>
                            <comment id="14633854" author="busbey" created="Mon, 20 Jul 2015 17:19:34 +0000"  >&lt;p&gt;This issue has been unassigned, had no fix versipn targetted, and was listed at Minor priority. I do&apos;t find it surprising that there were no updates.&lt;/p&gt;

&lt;p&gt;Personally  i think this will make a great feature addition that will help us tackle more workloads. Accordingly, ive chaned it to major and set a goal of 2.0.&lt;/p&gt;

&lt;p&gt;Please do not downplay the effort needed by whomever ends up implementing it by claiming it is trivial. The ASF is a &lt;a href=&quot;http://www.apache.org/foundation/how-it-works.html#decision-making&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;do-ocracy&lt;/a&gt;; while all contributions are valuable please don&apos;t criticize the prioritization of othrr volunteers when you yourself have not prioritized the feature yourself.&lt;/p&gt;</comment>
                            <comment id="14646347" author="msegel" created="Wed, 29 Jul 2015 16:21:52 +0000"  >&lt;p&gt;@Sean, &lt;/p&gt;

&lt;p&gt;As I have said before... Apache doesn&apos;t indemnify committers (actually its the reverse) and there is no upside for me to offset the risk. &lt;/p&gt;

&lt;p&gt;In a nutshell it would be pointless in having a discussion on why I used the term trivial and why I rated this as a low priority. &lt;/p&gt;

&lt;p&gt;BTW, there are 11 watchers... why don&apos;t you ask those watchers who are also committers and leaders of the HBase project, why they didn&apos;t raise the priority? &lt;/p&gt;

&lt;p&gt;I don&apos;t wish to seem rude, but if you&apos;re going to lecture someone, you had better realize that some will ignore you, others will mock you... &lt;/p&gt;

&lt;p&gt;To your point, this was the first JIRA that I raised.  I assumed that those who volunteer their time would also take the time to assess the value of the suggestion.  Clearly not.  That was my mistake. &lt;/p&gt;

&lt;p&gt;To be honest, I lack the patience to suffer fools...  &lt;/p&gt;

</comment>
                            <comment id="14646411" author="anoop.hbase" created="Wed, 29 Jul 2015 16:59:30 +0000"  >&lt;p&gt;As per the discussion in the Jira comments, we can not do this as a server side feature. This will be a client side thing.  Priority can be marked minor or major that is not the main thing IMHO.  What matters is a small doc abt the approach and patch. Many of us will be happy to review that when it comes. As far as a feature is value added for the team,we all are open for those.   Are you going to work on this and give patch?   If not there is no point in keeping jira open.  We can see any one else willing to take this up. If none better close it as later/wont implement.  &lt;/p&gt;</comment>
                            <comment id="14646617" author="msegel" created="Wed, 29 Jul 2015 19:11:41 +0000"  >&lt;p&gt;@Anoop,&lt;/p&gt;

&lt;p&gt;Yes, that is correct. &lt;br/&gt;
It was my misunderstanding on the client/server break. &lt;br/&gt;
(I program to the APISs and don&apos;t look at the source code.) &lt;/p&gt;

&lt;p&gt;I believe I did mention this after your last post correcting my mistake.&lt;/p&gt;

&lt;p&gt;Again, this is pretty simple... you&apos;re overloading the scan() so that it first does a check to see if the underlying table is bucketed or not.  A simple way to do this is to check the number of buckets. If its 0, then its not bucketed and you just run the scan like normal.  If it is a non-negative, non-zero integer, you would then parallelize the scan.&lt;/p&gt;

&lt;p&gt;You would then need to wait until all of the result sets return before you can funnel the data in to a single result set to be returned to the user. &lt;/p&gt;

&lt;p&gt;Of course I&apos;m assuming that each result set will start to send back results prior to completion of the ensuing scan. &lt;br/&gt;
Note too that these will be range scans. &lt;/p&gt;

&lt;p&gt;One other side effect is that if the scan is a full table scan... things will get a bit messy. (We&apos;ll maybe not... )&lt;/p&gt;</comment>
                            <comment id="14647980" author="lhofhansl" created="Thu, 30 Jul 2015 17:20:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;As I have stated repeatedly, I am unable to contribute to certain Apache projects unless Apache is willing to indemnify me. (Which they are not.) &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Don&apos;t be ridiculous. It is always your task to clear with all possible IP owners before you contribute anything under any license.&lt;br/&gt;
If you have something to contribute show us the code or even just a spec, otherwise it&apos;s just useless noise; if not just leave it instead of now blaming the committers with specious excuses why you can&apos;t do it.&lt;/p&gt;

&lt;p&gt;I&apos;m going to close this.&lt;/p&gt;</comment>
                            <comment id="14648174" author="apurtell" created="Thu, 30 Jul 2015 19:31:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;Either you find value to the suggestion or not. That is your call. But please note that Andrew P. worked on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13044&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-13044&lt;/a&gt;. (Also relatively trivial)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not sure I understand the relevance. For the record, I filed that issue after a brief encounter with Jim Scott of MapR over on the OpenTSDB list. He spoke of customers implementing coprocessors that exist solely to prevent loading of any other coprocessors, so I thought we could do something simple to make that unnecessary and volunteered time to do it. Strictly speaking, I didn&apos;t have to but the conversation was respectful and interesting and I felt like volunteering some of my evening that evening rather than spend it with family.&lt;/p&gt;

&lt;p&gt;The committer role at Apache is not about requiring individuals to implement unfunded mandates from random folks. On the other hand, we are expected to try and assess all contributions in the form of a patch in the most impartial manner possible. If for whatever reason you are not in a position to provide a patch, that&apos;s fine, but understand you are speaking to a community of volunteers who have work and personal lives and are already being super generous just for showing up here from time to time. You&apos;ll have to find a way to convince them they should volunteer their time to help you. Sometimes under the best of circumstances that just won&apos;t happen. An abrasive communication style - for example, repeated comments about &quot;lack&lt;span class=&quot;error&quot;&gt;&amp;#91;ing&amp;#93;&lt;/span&gt; the patience to suffer fools&quot; - dooms you to failure out of the gate. Don&apos;t be surprised at your lack of results.&lt;/p&gt;</comment>
                            <comment id="14649304" author="msegel" created="Fri, 31 Jul 2015 15:00:24 +0000"  >&lt;p&gt;Lars, &lt;/p&gt;

&lt;p&gt;If I respond, I&apos;ll be called argumentative. If I don&apos;t respond, it will leave readers with the incorrect perception. &lt;/p&gt;

&lt;p&gt;Again, Apache does not indemnify the contributor, leaving you with risk.  You need to balance that risk against the benefits of contributing. &lt;/p&gt;

&lt;p&gt;Its a lot simpler to say &quot;Apache won&apos;t indemnify me...&quot; than to continually having to write out long paragraphs as to why and what that really means. Either you get it or you don&apos;t.  Most of the committers here don&apos;t run their own shop or have to deal with the business side of software. &lt;/p&gt;

</comment>
                            <comment id="14649455" author="lhofhansl" created="Fri, 31 Jul 2015 16:46:37 +0000"  >&lt;p&gt;Most committers have well paying jobs and won&apos;t risk leaving them either. The employer also would be exposed to the very same risk (amplified, because there&apos;s more money to make).&lt;br/&gt;
I have personally many discussions with our legal team(s) about this. So I do know what I am talking about. &lt;/p&gt;

&lt;p&gt;Most people fail to calculate the cost of legal risk and assume it to be infinite.&lt;/p&gt;

&lt;p&gt;I get consulting gigs offered all the time &lt;em&gt;because&lt;/em&gt; I commit to open source (since I am employed I cannot accept such gigs, but that&apos;s not the point here). It&apos;s all about how you set it up with your customers. &lt;/p&gt;

&lt;p&gt;Sorry you feel this way. Contributing is what makes open source work. If everybody would think like you there would be no open source.&lt;/p&gt;

&lt;p&gt;In any case this is not the right place to discuss this.&lt;/p&gt;</comment>
                            <comment id="14649476" author="msegel" created="Fri, 31 Jul 2015 17:00:28 +0000"  >
&lt;p&gt;Andrew, &lt;/p&gt;

&lt;p&gt;As you point out, it was a trivial solution and that was the point I was trying to make, that you took the time to work on it. &lt;/p&gt;


&lt;p&gt;As I&apos;ve said repeatedly, I can&apos;t provide patches because the risks outweigh the benefits. (Lets leave it at that.) &lt;/p&gt;


&lt;p&gt;I guess at the time I wrote this enhancement request, I could have raised this issue with a certain vendor&apos;s support team, then suggested that a certain person call a certain person to ask that this get done... but that would have been a waste of calling in a favor. &lt;/p&gt;

&lt;p&gt;Again, either the committers or community  sees the benefits and merits in doing this... or you don&apos;t. It was a five minute thought that wasn&apos;t worth the effort of diagramming out on a white board that solved a problem. &lt;/p&gt;</comment>
                            <comment id="14650544" author="gumby" created="Sat, 1 Aug 2015 21:34:02 +0000"  >&lt;p&gt;Wow, &lt;/p&gt;

&lt;p&gt;Rather than try to stay focused on the issue of the Jira, you talk about contributing to open source. &lt;/p&gt;

&lt;p&gt;I can tell you the answer, I can even explain it to you, but you still wouldn&apos;t get it. &lt;/p&gt;
</comment>
                            <comment id="14651186" author="lhofhansl" created="Sun, 2 Aug 2015 21:12:17 +0000"  >&lt;p&gt;The discussion has been off topic. We can open a new jira if/when we have something concrete.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 14 Jan 2015 18:03:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 19 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i24cxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>