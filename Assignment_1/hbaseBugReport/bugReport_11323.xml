<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:22:06 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-11323/HBASE-11323.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-11323] BucketCache all the time!</title>
                <link>https://issues.apache.org/jira/browse/HBASE-11323</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;One way to realize the parent issue is to just enable bucket cache all the time; i.e. always have offheap enabled.  Would have to do some work to make it drop-dead simple on initial setup (I think it doable).&lt;/p&gt;

&lt;p&gt;So, upside would be the offheap upsides (less GC, less likely to go away and never come back because of full GC when heap is large, etc.).&lt;/p&gt;

&lt;p&gt;Downside is higher latency.   In Nick&apos;s BlockCache 101 there is little to no difference between onheap and offheap.  In a basic compare doing scans and gets &amp;#8211; details to follow &amp;#8211; I have BucketCache deploy about 20% less ops than LRUBC when all incache and maybe 10% less ops when falling out of cache.   I can&apos;t tell difference in means and 95th and 99th are roughly same (more stable with BucketCache).  GC profile is much better with BucketCache &amp;#8211; way less.  BucketCache uses about 7% more user CPU.&lt;/p&gt;

&lt;p&gt;More detail on comparison to follow.&lt;/p&gt;

&lt;p&gt;I think the numbers disagree enough we should probably do the &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; suggestion, that we allow you to have a table sit in LRUBC, something the current bucket cache layout does not do.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12720480">HBASE-11323</key>
            <summary>BucketCache all the time!</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12690435">HBASE-10403</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Jun 2014 23:51:50 +0000</created>
                <updated>Sat, 23 Aug 2014 06:26:12 +0000</updated>
                            <resolved>Fri, 8 Aug 2014 05:06:43 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>io</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>16</watches>
                                                                <comments>
                            <comment id="14027349" author="lhofhansl" created="Wed, 11 Jun 2014 02:19:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think the numbers disagree enough we should probably do the Lars Hofhansl suggestion, that we allow you to have a table sit in LRUBC, something the current bucket cache layout does not do.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How is that to do after you spent some time with it. When I looked last (didn&apos;t spend a lot of time, though), it did not look entirely trivial.&lt;/p&gt;</comment>
                            <comment id="14027372" author="ndimiduk" created="Wed, 11 Jun 2014 03:36:08 +0000"  >&lt;p&gt;+1 for this. I think moving offheap by default is a sound approach, barring any new revelations re: CMS and/or G1 (cough &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;). We&apos;ll enjoy more stability and have a less complicated story for folks with gobs of ram.&lt;/p&gt;

&lt;p&gt;In this new world, the default RS configuration looks something like 4-6G heap (how many memstores do you need?) + XXX direct memory. Leave the heap for memstore and protobuf garbage; only 512m - 1g for index blocks in LruBlockCache that only evicts from compactions. It could even be simplified to remove the 3 different block priorities.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we allow you to have a table sit in LRUBC&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this becomes pretty easy if we&apos;re assuming a CombinedBlockCache is always present. It&apos;s managing the block placement strategy already, so it can check the flag and do the right thing.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I have BucketCache deploy about 20% less ops than LRUBC when all incache and maybe 10% less ops when falling out of cache.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Must be smallish heap. What are your memory allocations here? Have you tried with 24+G heap? I think you&apos;ll see very different numbers.&lt;/p&gt;

&lt;p&gt;One improvement for BucketCache is to have HFileBlock&apos;s buf refer directly to the memory in BucketCache instead of copying it over. Might help, if we can ensure a block isn&apos;t evicted out from under us.&lt;/p&gt;</comment>
                            <comment id="14027385" author="apurtell" created="Wed, 11 Jun 2014 04:04:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;We&apos;ll enjoy more stability and have a less complicated story for folks with gobs of ram.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that&apos;s what all our (early) experience bears out.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the default RS configuration looks something like 4-6G heap (how many memstores do you need?) &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We can get that down further with off heap memstores, if that pans out ... longer term work.&lt;/p&gt;</comment>
                            <comment id="14027397" author="stack" created="Wed, 11 Jun 2014 04:22:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;When I looked last (didn&apos;t spend a lot of time, though), it did not look entirely trivial.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not sure &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; CombinedBlockCache has special casing currently.  Hopefully can pass a flag from CF down.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Leave the heap for memstore and protobuf garbage; only 512m - 1g for index blocks in LruBlockCache that only evicts from compactions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I like your suggestion of simplified LruBlockCache &amp;#8211; no tiers.  LruBlockCache is resizable now because of &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; ergonomics work.  We could have it so the LruBlockCache starts out big then sizes down to the size of blooms and indices only.&lt;/p&gt;

&lt;p&gt;It is 8G heap w/ 4G to LruBC and then when BucketCache test, it is 8G heap and 4G offheap.  I can do another run w/ bigger BC just to see.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One improvement for BucketCache is to have HFileBlock&apos;s buf refer directly to the memory in BucketCache instead of copying it over. Might help, if we can ensure a block isn&apos;t evicted out from under us.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds good to me.  Try and get this one in first then we can work on saving copies.&lt;/p&gt;</comment>
                            <comment id="14027412" author="stack" created="Wed, 11 Jun 2014 04:53:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hopefully can pass a flag from CF down.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm.  That ain&apos;t going to work, not w/o messing up HFiles and below w/ CF mess.  Going back to comparing LruBlockCache to BucketCache for a while.  See how far they are apart really.&lt;/p&gt;</comment>
                            <comment id="14028978" author="anoop.hbase" created="Thu, 12 Jun 2014 09:53:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;One improvement for BucketCache is to have HFileBlock&apos;s buf refer directly to the memory in BucketCache instead of copying it over. Might help, if we can ensure a block isn&apos;t evicted out from under us.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;block buf refer the offheap memory? So in the read path, the Cells will refer to this memory?&lt;/p&gt;</comment>
                            <comment id="14029279" author="ndimiduk" created="Thu, 12 Jun 2014 15:45:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;block buf refer the offheap memory? So in the read path, the Cells will refer to this memory?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that&apos;s what I&apos;m suggesting.&lt;/p&gt;</comment>
                            <comment id="14029465" author="apurtell" created="Thu, 12 Jun 2014 17:28:12 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;block buf refer the offheap memory? So in the read path, the Cells will refer to this memory?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, that&apos;s what I&apos;m suggesting.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s a route to one of the objectives of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10191&quot; title=&quot;Move large arena storage off heap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10191&quot;&gt;HBASE-10191&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14029959" author="stack" created="Thu, 12 Jun 2014 22:50:18 +0000"  >&lt;p&gt;Small report.  Constant row sizes so its going to give an odd view comparing the block cache deploys; lrublockcache to bucketcache offheap and bucketcache onheap. Mostly just pictures.  Here is high-level takeaway:&lt;/p&gt;

&lt;p&gt;&quot;LruBucketCache has lower latency and uses less CPU in all cases (all-in-cache ~20% better, mostly-in-cache ~7% better, mostly-out-of-cache about the same). Bucket cache does almost half the GC and has slightly better 95th and 99th percentiles when cache misses.  Offheap performs slightly better than onheap bucket cache.&lt;/p&gt;

&lt;p&gt;Need to redo with different sized rows.&quot;&lt;/p&gt;</comment>
                            <comment id="14031270" author="lhofhansl" created="Fri, 13 Jun 2014 22:23:07 +0000"  >&lt;p&gt;I&apos;d say before we default this to on we need to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;make it configurable per table (my pet peeve &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/li&gt;
	&lt;li&gt;avoid deserialization of the blocks during scanning (where possible)&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14031283" author="stack" created="Fri, 13 Jun 2014 22:35:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;make it configurable per table (my pet peeve  )&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think we can do this one without an ugly hack.  Would mean schema carried down into hfile.  Yuck.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;avoid deserialization of the blocks during scanning (where possible)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was gong to look at this one next...  will report back.&lt;/p&gt;</comment>
                            <comment id="14031285" author="stack" created="Fri, 13 Jun 2014 22:37:09 +0000"  >&lt;p&gt;Working on new version of report comparing lrubc and bucketcache but with Cells/blocks or non-uniform size.&lt;/p&gt;</comment>
                            <comment id="14031288" author="apurtell" created="Fri, 13 Jun 2014 22:40:07 +0000"  >&lt;p&gt;Just related to the schema tangent... We do have HFileContext envisioned as a way to encapsulate state to carry down from Store into HFile. &lt;/p&gt;</comment>
                            <comment id="14031295" author="enis" created="Fri, 13 Jun 2014 22:49:43 +0000"  >&lt;p&gt;We do not need the whole schema right. Just the store would know which cache to use and send it to the hfile readers? &lt;/p&gt;</comment>
                            <comment id="14031303" author="stack" created="Fri, 13 Jun 2014 22:57:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; Thanks Andy.  Looking at it, it is all about write time, right?  Maybe I could add a &apos;hot&apos; flag to HStoreFileInfo or something.  But on creation, it only has Path context... nought else.&lt;/p&gt;</comment>
                            <comment id="14031305" author="stack" created="Fri, 13 Jun 2014 22:59:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; That is correct sir&lt;/p&gt;</comment>
                            <comment id="14031609" author="anoop.hbase" created="Sat, 14 Jun 2014 15:56:25 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;block buf refer the offheap memory? So in the read path, the Cells will refer to this memory?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that&apos;s what I&apos;m suggesting.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So we have to make sure the read path having Cell flowing through. (I think this is mostly done) &lt;br/&gt;
And the Cell should be supported being backed by BB. (offheap) We will need new comparators. &lt;br/&gt;
The Cell interface is having get***Array() APIs which return byte[]. We use them for the compare.  When the Cells are backed by BB, calling these APIs will need us to create temp byte[] objects and copying.  Need ways to solve this.&lt;/p&gt;</comment>
                            <comment id="14031612" author="apurtell" created="Sat, 14 Jun 2014 16:29:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;But on creation, it only has Path context... nought else.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah when opening a reader we only have the metadata in the HFile, we are disconnected from schema at the HFile level. If you look at the patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9857&quot; title=&quot;Blockcache prefetch option&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9857&quot;&gt;&lt;del&gt;HBASE-9857&lt;/del&gt;&lt;/a&gt;, there are some TODOs where we have regex constants down in HFile for what should be Store level detail (path and dir layout conventions). We should hook up read side to Store. Possibly we could do that by adding a method HFileContext Store#getFileContext(Path) ? Would set up a context with schema and flags based on the Store level knowledge of what the Path encodes.&lt;/p&gt;</comment>
                            <comment id="14031616" author="apurtell" created="Sat, 14 Jun 2014 16:40:50 +0000"  >&lt;p&gt;We have various results that all indicate &lt;em&gt;some&lt;/em&gt; penalty for using the bucket cache, with commensurate improvement in GC related metrics. It can be a trade off well worth making but should not be a global decision. I think we should make combined LRU cache + bucket cache the default, but only if we can have the default placement for data blocks still be on heap and plumb down schema level selection of block placement off heap. Then you can have, on a per CF basis, such strategies as large warm data off heap with block encoding (trade scanning CPU for serde/copying costs) and smaller hot data on heap with no encoding. At a future time we could have a few caching strategies like this automatically managed by ergonomics.&lt;/p&gt;</comment>
                            <comment id="14031716" author="stack" created="Sat, 14 Jun 2014 21:54:14 +0000"  >&lt;p&gt;Hm.  Maybe I am making this harder than it needs to be (the Lars and now Andrew ask that it be possible to have tables keep their DATA blocks in LruBlockCache):&lt;/p&gt;

&lt;p&gt;The HCD#setInMemory javadoc says:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;@param inMemory True if we are to keep all values in the HRegionServer cache&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, if I am allowed extrapolate, if a CF has IN_MEMORY set and we are using CombinedBlockCache &amp;#8211; i.e. LruBC and BucketCache &amp;#8211; then lets just cache the CF DATA blocks in LruBC too?&lt;/p&gt;

&lt;p&gt;This small change is all that is needed:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java
index 7564cc2..23cdf83 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java
@@ -56,7 +56,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class CombinedBlockCache &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; BlockCache, HeapSize {
   @Override
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void cacheBlock(BlockCacheKey cacheKey, Cacheable buf, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; inMemory) {
     &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isMetaBlock = buf.getBlockType().getCategory() != BlockCategory.DATA;
-    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isMetaBlock) {
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isMetaBlock || inMemory) {
       lruCache.cacheBlock(cacheKey, buf, inMemory);
     } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
       bucketCache.cacheBlock(cacheKey, buf, inMemory);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running with it, I was able to check it was actually working by looking at the block cache dump by files.  It reports counts of blocks and whether DATA blocks.  Creating a table which is IN_MEMORY has its data blocks got into LruBC.&lt;/p&gt;

&lt;p&gt;Of note, hbase:meta and other system tables now will have their DATA blocks up in LruBC too since they are marked as IN_MEMORY.&lt;/p&gt;

&lt;p&gt;If the above is allowed, I&apos;ll go through and amend all references to IN_MEMORY to make note of this expanded definition of its meaning.&lt;/p&gt;</comment>
                            <comment id="14031717" author="stack" created="Sat, 14 Jun 2014 21:54:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; I&apos;ll take a look sir.&lt;/p&gt;</comment>
                            <comment id="14031720" author="apurtell" created="Sat, 14 Jun 2014 22:06:06 +0000"  >&lt;p&gt;Do we want IN_MEMORY to be synonymous with on heap? I would not want my largish but able to fit collectively in RAM table to require big heaps when I have all this off heap memory available I could take advantage of without risk of long stop the world pauses. &lt;/p&gt;</comment>
                            <comment id="14031721" author="apurtell" created="Sat, 14 Jun 2014 22:09:13 +0000"  >&lt;p&gt;On the other hand it&apos;s an easy change and we could have IN_MEMORY mean this now as long as we can get to more precise specification of per CF placement at a later time when someone actually needs it. &lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14031767" author="lhofhansl" created="Sun, 15 Jun 2014 03:17:20 +0000"  >&lt;p&gt;That can work. InMemory also implies a different &quot;arena&quot; in the block cache, though.&lt;br/&gt;
If we can pass inMemory down to where it matters, why can&apos;t we pass another flag down this way?&lt;/p&gt;</comment>
                            <comment id="14031778" author="stack" created="Sun, 15 Jun 2014 03:58:40 +0000"  >&lt;p&gt;Thanks for the feedback lads.  I&apos;ll add new config on CacheConfig and will use it figuring whether to DATA blocks are L1 or L2 (Turns out BucketCache gives blocks marked IN_MEMORY higher priority trying to mimic roughly what is happening in LruBlockCache).&lt;/p&gt;</comment>
                            <comment id="14033045" author="stack" created="Mon, 16 Jun 2014 21:47:49 +0000"  >&lt;p&gt;I did the work to add new flag over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11364&quot; title=&quot;[BlockCache] Add a flag to cache data blocks in L1 if multi-tier cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11364&quot;&gt;&lt;del&gt;HBASE-11364&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14033046" author="stack" created="Mon, 16 Jun 2014 21:48:30 +0000"  >&lt;p&gt;Link to prerequisite&lt;/p&gt;</comment>
                            <comment id="14037749" author="stack" created="Thu, 19 Jun 2014 19:42:51 +0000"  >&lt;p&gt;Options are shaping up as follows (copied from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11364&quot; title=&quot;[BlockCache] Add a flag to cache data blocks in L1 if multi-tier cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11364&quot;&gt;&lt;del&gt;HBASE-11364&lt;/del&gt;&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;1. Do NOT enable offheap by default. Just talk it up as the way to go underlining it will make pure in-memory access slower (but you can make it so some of your tables are pegged in memory if you want because of the flag here). Upside: No surprise. Downside: Folks don&apos;t read manuals nor change defaults.&lt;br/&gt;
2. Enable offheap BucketCache using CombinedBucketCache. When folks upgrade, latency to user-level DATA blocks will go up. Upsides: less GC, more cached. Downside: those who notice added latency might get upset. Changing schema will require alter table.&lt;br/&gt;
3. Enable offheap BucketCache but in additive mode where we just add in an L2 under the L1 LruBlockCache. Upside: Additive. Downside: Could make for more GC.&lt;br/&gt;
Of the above, maybe 1. is the way to go? 2. may surprise in that perf and GC gets better of a sudden (this would be ok) but others may be surprised that their latencies have gone up for some key tables. 3. may actually make GC worse (at least that is case in the SlabCache case which is similar and the L1/L2 layout doesn&apos;t get good review to date going by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8894&quot; title=&quot;Forward port compressed l2 cache from 0.89fb&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8894&quot;&gt;&lt;del&gt;HBASE-8894&lt;/del&gt;&lt;/a&gt;).&lt;br/&gt;
Will test 3.&lt;/p&gt;</comment>
                            <comment id="14037985" author="stack" created="Thu, 19 Jun 2014 22:08:17 +0000"  >&lt;p&gt;Two votes for #1 over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11364&quot; title=&quot;[BlockCache] Add a flag to cache data blocks in L1 if multi-tier cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11364&quot;&gt;&lt;del&gt;HBASE-11364&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;BlockCache&amp;#93;&lt;/span&gt; Add a flag to cache data blocks in L1 if multi-tier cache&lt;/p&gt;</comment>
                            <comment id="14061635" author="stack" created="Tue, 15 Jul 2014 04:15:11 +0000"  >&lt;p&gt;Setting as target 2.0.0. Turn on BucketCache after 1.0 goes out.  Will raise it on list.  Discussion over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11364&quot; title=&quot;[BlockCache] Add a flag to cache data blocks in L1 if multi-tier cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11364&quot;&gt;&lt;del&gt;HBASE-11364&lt;/del&gt;&lt;/a&gt; has two votes against enabling BucketCache in 1.0 HBase.&lt;/p&gt;</comment>
                            <comment id="14072102" author="stack" created="Wed, 23 Jul 2014 18:36:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;Need to redo with different sized rows.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Attached is a new report that has zipfian sized cells from 1-256k bytes. Concludes that offheap CombinedBlockCache is generaly best for all cases except the one where we are serving all requests from cache; in this latter case near twice the throughput and half the GC&apos;ing if LruBlockCache.  Otherwise offheap CBC is better.&lt;/p&gt;</comment>
                            <comment id="14107881" author="hudson" created="Sat, 23 Aug 2014 06:03:21 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.94-security #514 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/514/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/514/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11323&quot; title=&quot;BucketCache all the time!&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11323&quot;&gt;&lt;del&gt;HBASE-11323&lt;/del&gt;&lt;/a&gt; Add MultiRowMutation tests. (Liu Shaohui) (larsh: rev 44492624d4b8a6cf1ce1c7ba595f3a3447f9f536)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;src/test/java/org/apache/hadoop/hbase/coprocessor/TestMultiRowMutationProtocol.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14107886" author="hudson" created="Sat, 23 Aug 2014 06:23:28 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.94-JDK7 #173 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-JDK7/173/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-JDK7/173/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11323&quot; title=&quot;BucketCache all the time!&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11323&quot;&gt;&lt;del&gt;HBASE-11323&lt;/del&gt;&lt;/a&gt; Add MultiRowMutation tests. (Liu Shaohui) (larsh: rev 44492624d4b8a6cf1ce1c7ba595f3a3447f9f536)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;src/test/java/org/apache/hadoop/hbase/coprocessor/TestMultiRowMutationProtocol.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14107888" author="hudson" created="Sat, 23 Aug 2014 06:26:12 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-0.94 #1404 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/1404/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/1404/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11323&quot; title=&quot;BucketCache all the time!&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11323&quot;&gt;&lt;del&gt;HBASE-11323&lt;/del&gt;&lt;/a&gt; Add MultiRowMutation tests. (Liu Shaohui) (larsh: rev 44492624d4b8a6cf1ce1c7ba595f3a3447f9f536)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;src/test/java/org/apache/hadoop/hbase/coprocessor/TestMultiRowMutationProtocol.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12732083">HBASE-11678</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12721519">HBASE-11364</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12657407" name="BlockCacheReportLruBlockCachevsOffHeapCombinedBlockCacheSmall4G (1).pdf" size="372390" author="stack" created="Wed, 23 Jul 2014 18:36:39 +0000"/>
                            <attachment id="12650161" name="ReportBlockCache.pdf" size="1312780" author="stack" created="Thu, 12 Jun 2014 22:50:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 11 Jun 2014 02:19:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>398679</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 16 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1wmy7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>398803</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Use the LruBlockCache default if your data fits the blockcache.  If block cache churn or you want a block cache that is immune to the vagaries of BC, deploy the offheap bucketcache.  See &lt;a href=&quot;http://people.apache.org/~stack/bc/&quot;&gt;http://people.apache.org/~stack/bc/&lt;/a&gt;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>