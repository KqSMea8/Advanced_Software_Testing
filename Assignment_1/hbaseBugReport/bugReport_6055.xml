<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:33:22 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6055/HBASE-6055.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6055] Offline Snapshots in HBase 0.96</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6055</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Continuation of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt; for the current trunk. Since the implementation has drastically changed, opening as a new ticket.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12556488">HBASE-6055</key>
            <summary>Offline Snapshots in HBase 0.96</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jmhsieh">Jonathan Hsieh</assignee>
                                    <reporter username="jesse_yates">Jesse Yates</reporter>
                        <labels>
                    </labels>
                <created>Fri, 18 May 2012 23:16:47 +0000</created>
                <updated>Tue, 15 Oct 2013 04:46:32 +0000</updated>
                            <resolved>Thu, 21 Feb 2013 04:26:46 +0000</resolved>
                                                    <fixVersion>0.95.0</fixVersion>
                                    <component>Client</component>
                    <component>master</component>
                    <component>regionserver</component>
                    <component>snapshots</component>
                    <component>Zookeeper</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>43</watches>
                                                                                                            <comments>
                            <comment id="13279340" author="jesse_yates" created="Fri, 18 May 2012 23:40:01 +0000"  >&lt;p&gt;Initial, very rough draft of the code is up on github: &lt;a href=&quot;https://github.com/jyates/hbase/tree/snapshots&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jyates/hbase/tree/snapshots&lt;/a&gt;. Latest commit message has the following description (which is a pretty good summary of the current status):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is based on the backup-hfile work in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;, and is very different&lt;br/&gt;
from the actual proposal (and code samples) in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt;. The overall layout is&lt;br/&gt;
more or less the same as the proposal, but they actual implementation has changed&lt;br/&gt;
due to changes in the actual code as well as the current conventions.&lt;/p&gt;

&lt;p&gt;Currently, only 1 test is written and has not been tested (99% sure its not&lt;br/&gt;
going to pass). However, the meat of the implementation is complete. There is&lt;br/&gt;
still some work around listing and deleting of online snapshots and taking of&lt;br/&gt;
snapshots for offlined tables, but this is trivial compared&lt;br/&gt;
to the taking of snapshots for an online table and naturally falls out of the&lt;br/&gt;
current implementation.&lt;/p&gt;

&lt;p&gt;Further, the export/import functionality for snapshots has not been completed, but will&lt;br/&gt;
probably (again) be very similar to the work in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt;. Currently Matteo Bertozzi is&lt;br/&gt;
interested in working on this functionality, so I&apos;m leaving that to him for the moment.&lt;/p&gt;

&lt;p&gt;NOTES:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I&apos;m not very happy with the monitoring infrastructure I&apos;ve put in place around&lt;br/&gt;
keeping track of the different tasks and propagating errors from snapshots failing&lt;br/&gt;
locally (from any of the various async threads) back to the rest of the nodes running&lt;br/&gt;
the snapshot and vice-versa. Its feels overly complex and seems to be refactored repeatedly.&lt;br/&gt;
Its on the list, but seemed not worth the effort of cleanup versus having something up.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Planning on doing a writeup this weekend so people can actually have a chance at splunking through the changeset (which is non-trivial in size).&lt;/p&gt;</comment>
                            <comment id="13280349" author="jesse_yates" created="Mon, 21 May 2012 18:39:35 +0000"  >&lt;p&gt;Attaching longer document detailing snapshots. It has both a general overview and a walkthrough of implementation. Its complementary to the docs on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt; and the code on github.&lt;/p&gt;

&lt;p&gt;In short, its distributed two-phase commit, where the prepare phase blocks all writes to all, enabled via a barrier node in zookeeper.&lt;/p&gt;</comment>
                            <comment id="13280706" author="zhihyu@ebaysf.com" created="Tue, 22 May 2012 04:24:52 +0000"  >&lt;p&gt;The design document is very good.&lt;br/&gt;
Will get back to reviewing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt; first.&lt;/p&gt;</comment>
                            <comment id="13281416" author="jesse_yates" created="Wed, 23 May 2012 06:02:36 +0000"  >&lt;p&gt;Adding updated documentation - realized it fudged a couple things when doing the testing (thanks for the hints Matteo!)&lt;/p&gt;</comment>
                            <comment id="13281715" author="jxiang" created="Wed, 23 May 2012 16:40:38 +0000"  >&lt;p&gt;I have a concern.  Why should we do two phases?  I think the prepare phase is not needed.  We have row level atomicity.  We don&apos;t need every region server to be on the same page.  Since it is distributed, it is arguable about the meaning of point-in-time. That means it is hard to say it is consistent/inconsistent point-in-time.&lt;/p&gt;

&lt;p&gt;I think we each region server can try to create the snapshot at first.  If anyone fails, partial snapshot can be just deleted.&lt;/p&gt;</comment>
                            <comment id="13282047" author="zhihyu@ebaysf.com" created="Wed, 23 May 2012 23:45:30 +0000"  >&lt;p&gt;I checked out project from github:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
# On branch snapshots
nothing to commit (working directory clean)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I got some compilation errors:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[ERROR] /Users/zhihyu/snapshots/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java:[102,0] org.apache.hadoop.hbase.master.MockRegionServer is not &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; and does not override &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; method getRootDir() in org.apache.hadoop.hbase.regionserver.RegionServerServices
[ERROR] 
[ERROR] /Users/zhihyu/snapshots/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionHFileArchiving.java:[340,12] cannot find symbol
[ERROR] symbol  : method waitForFlushesAndCompactions()
[ERROR] location: class org.apache.hadoop.hbase.regionserver.HRegion
[ERROR] 
[ERROR] /Users/zhihyu/snapshots/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionHFileArchiving.java:[426,12] cannot find symbol
[ERROR] symbol  : method waitForFlushesAndCompactions()
[ERROR] location: class org.apache.hadoop.hbase.regionserver.HRegion
[ERROR] 
[ERROR] /Users/zhihyu/snapshots/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionHFileArchiving.java:[507,12] cannot find symbol
[ERROR] symbol  : method waitForFlushesAndCompactions()
[ERROR] location: class org.apache.hadoop.hbase.regionserver.HRegion
[ERROR] 
[ERROR] /Users/zhihyu/snapshots/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java:[45,7] org.apache.hadoop.hbase.util.MockRegionServerServices is not &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; and does not override &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; method getRootDir() in org.apache.hadoop.hbase.regionserver.RegionServerServices
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13282067" author="zhihyu@ebaysf.com" created="Thu, 24 May 2012 00:16:09 +0000"  >&lt;p&gt;Some files, such as RegionSnapshotPool, don&apos;t have license.&lt;/p&gt;

&lt;p&gt;For RegionSnapshotOperation.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void setStatusMonitor(RegionSnapshotOperationStatus monitor) {
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.setStatus(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RegionSnapshotStatus(monitor));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the method name doesn&apos;t seem to match its parameter.&lt;/p&gt;

&lt;p&gt;Will post more comments later.&lt;/p&gt;</comment>
                            <comment id="13282221" author="jesse_yates" created="Thu, 24 May 2012 06:08:48 +0000"  >&lt;p&gt;sorry, forgot to mention that the new &quot;correct&quot; branch is snapshots-r0. It compiles locally for me and gets most of the way through the test (TestSnapshotFromClient).Should solve most of the current issues &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; That&apos;ll teach me to be overzealous with posting patches.&lt;/p&gt;</comment>
                            <comment id="13283894" author="sunnygao" created="Sat, 26 May 2012 03:01:23 +0000"  >&lt;p&gt;This is a very useful feature. :0&lt;/p&gt;</comment>
                            <comment id="13284366" author="sunnygao" created="Mon, 28 May 2012 10:57:26 +0000"  >&lt;p&gt;Hi Jesse, Are you working this feature? I am interested in it.  I will study your code.&lt;br/&gt;
one question, When we are creating snapshots,  Do we need stop the balance?&lt;/p&gt;</comment>
                            <comment id="13284373" author="ram_krish" created="Mon, 28 May 2012 11:35:26 +0000"  >&lt;p&gt;Nice doc Jesse.&lt;/p&gt;</comment>
                            <comment id="13284532" author="jmhsieh" created="Mon, 28 May 2012 19:39:10 +0000"  >&lt;p&gt;Jesse,&lt;/p&gt;

&lt;p&gt;Thanks for the writeup, I find having a single doc with the design summary really helpful and ideally something we do for all major new features. I&apos;ve read through the document carefully, let it steep for a few days, and had some design-level questions.  I&apos;ve skimmed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt; and will read more of the history more carefully later this evening.  &lt;/p&gt;

&lt;p&gt;What is the read mechanism for snapshots like?  Does the snapshot act like a read-only table or is there some special external mechanism needed to read the data from a snapshot?  You mention having to rebuild in-memory state by replaying wals &amp;#8211; is this a recovery situation or needed in normal reads?&lt;/p&gt;

&lt;p&gt;What is a representation of a snapshot look like in terms of META and file system contents?  At some point we may get called upon to repair these, I want to make sure there are enough breadcrumbs for this to be possible.&lt;/p&gt;

&lt;p&gt;I&apos;m still thinking about the two-phase part &amp;#8211; I think it is necessary for marking success or initiating failure recovery, but I&apos;m skeptical at the moment about why the barriering writes is necessary.  How does this buy your more consistency?  Aren&apos;t we still inconsistent at the prepare point now instead?   Can we just write the special snapshotting hlog entry at initiation of prepare, allowing writes to continue, then adding data elsewhere (META) to mark success in commit?  We could then have some compaction/flush time logic cleanup failed atttempt markers?&lt;/p&gt;


</comment>
                            <comment id="13285017" author="jesse_yates" created="Tue, 29 May 2012 19:07:39 +0000"  >&lt;p&gt;@gaojinchao: I&apos;m definitely still working on it - its just been a busy week, what with hbasecon, the hackathon and the rebase, this has been on the back burner. This week I&apos;m planning to have a working first cut. Keep in mind that the code on github is a rough preview - definitely not the finished version, so no guarantees on polish or even correctness. That said, any feedback is appreciated.&lt;/p&gt;

&lt;p&gt;@Jon - I&apos;m working on a thorough response, thanks for the questions.&lt;/p&gt;</comment>
                            <comment id="13286429" author="jmhsieh" created="Thu, 31 May 2012 09:31:46 +0000"  >&lt;p&gt;Thanks Jesse,&lt;/p&gt;

&lt;p&gt;I haven&apos;t looked at code yet but I got a chance to read through the writeup in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt;.  One thing I like about it is that it breaks out the operations, pretty clearly describes the zk and hdfs layouts so that an admin, a tool, or someone with info at this particular level could use the feature and inspect the exposed zk and hdfs state for debugging. &lt;/p&gt;

&lt;p&gt;From the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt; doc (haven&apos;t looked at code yet), Li seems to have chosen or more clearly stated these design decisions:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;hlog roll (which I believe does not trigger a flush) instead of special meta hlog marker (this might avoid write unavailability, seems simpler that the mechanism I suggested)&lt;/li&gt;
	&lt;li&gt;admin initiated snapshot and admin initiated restore operations as opposed to acting like a read only table.  (not sure what happens to &quot;newer&quot; data after a restore, need to reread to see if it is in there, not sure about the cost to restore a snapshot)&lt;/li&gt;
	&lt;li&gt;I believe it also has an ability to read files directly from an MR job without having to go through HBase&apos;s get/put interface.   Is that in scope for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt;?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Jon.&lt;/p&gt;</comment>
                            <comment id="13286861" author="jesse_yates" created="Thu, 31 May 2012 19:29:13 +0000"  >&lt;p&gt;I&apos;ve recently had an existential crisis, of sorts, over snapshots. Triggered by both Jon&apos;s questions and some from Ian Varley, I&apos;ve started to rethink the goal of snapshot. Initially, it was to take a globally consistent view of a single table. The question that Ian raised is, &quot;Why are we enforcing stricter guarantees for a snapshot than for a scan?&quot; In fact, a globally consistent view is something HBase explicitly doesn&apos;t support (if you do a put to two different tables, you have no real, system level guarantees of consistency). &lt;/p&gt;

&lt;p&gt;So does it really matter if we have an actual point in time? Everything in HBase is timestamped, which is considered the source of truth for a given Mutation. If we are doing a scan for the state of the table as of 12:15:05, we don&apos;t know if RS1 is 2 seconds before RS2 - as far as we care, its just the state at 12:15:05. &lt;/p&gt;

&lt;p&gt;This starts to break down a little bit when doing a Get for the latest version on a table. If RS1 is two seconds behind RS2 and we snapshot at 12:15:05, then we actually might not see all the change to RS1 in the snapshot. However, this doesn&apos;t really matter because you still wouldn&apos;t see that edit when looking at that &quot;time&quot;. Things are happening so fast in HBase that the best we really need is just a &quot;fuzzy&quot; view of the state of the table.&lt;/p&gt;

&lt;p&gt;The upside to this is we can do the snapshot &lt;em&gt;without taking any downtime&lt;/em&gt; on the table being snapshotted. I already discussed how to do this generally in the document, but it will have to be rewritten from the perspective of timestamped based snapshots (I&apos;ll move it to a google doc until we get a more finalized version).&lt;/p&gt;

&lt;p&gt;The only problem that has jumped out in multiple discussions of the timestamp based approach is that if you are using the timestamp for something other than the time (ala Facebook Messages) you might not be able to make use of snapshots. At Salesforce, I was planning on abusing timestamps as well, so that consideration will be made in the implementation (I&apos;ll go over how in another post).&lt;/p&gt;

&lt;p&gt;TL;DR global consistency doesn&apos;t matter for HBase since the timestamp is the source of truth - the only question is whether you believe the timestamp or not. I would posit that based on the design of HBase it has to be considered a source of truth.&lt;/p&gt;

&lt;p&gt;I&apos;ll respond in a bit with a more detailed design of how timestamp based snapshots differ from the point-in-time design, but in everything except how to deal with the memstore and WAL, it &lt;em&gt;exactly the same&lt;/em&gt;. The way to handle the memstore was suggested by Ian Varley in that we basically use the memstore snapshot stuff with some rejiggering to wait a certain amount of time; for the WAL we can just use the meta edits that Jon recommends and that I&apos;ve at least talked about IRL (if not in text).&lt;/p&gt;</comment>
                            <comment id="13286862" author="jesse_yates" created="Thu, 31 May 2012 19:31:26 +0000"  >&lt;p&gt;&lt;em&gt;(jon: I made a minor formatting tweak to make this easier to read the dir structure)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;But before a detailed description of how timestamp-based snapshots work internally, lets answer some comments!&lt;/p&gt;

&lt;p&gt;@Jon: I&apos;ll add more info to the document to cover this stuff, but for the moment, lets just get it out there.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What is the read mechanism for snapshots like? Does the snapshot act like a read-only table or is there some special external mechanism needed to read the data from a snapshot? You mention having to rebuild in-memory state by replaying wals &#8211; is this a recovery situation or needed in normal reads?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its almost, but not quite like a table. Read of a snapshot is going to require an external tool but after hooking up the snapshot via the external tool, it should act just like a real table. &lt;/p&gt;

&lt;p&gt;Snapshots are intended to happen as fast as possible, to minimize downtime for the table. To enable that, we are just creating reference files in the snapshot directory. My vision is that once you take a snapshot, at some point (maybe weekly), you export the snapshot to a backup area. In the export you actually do the copy of the referenced files - you do a direct scan of the HFile (avoiding the top-level interface and going right to HDFS) and the WAL files. Then when you want to read the snapshot, you can just bulk-import the HFIles and replay the WAL files (with the WALPlayer this is relatively easy) to rebuild the state of the table at the time of the snapshot. Its not an exact copy (META isn&apos;t preserved), but all the actual data is there.&lt;/p&gt;

&lt;p&gt;The caveat here is since everything is references, one of the WAL files you reference may not actually have been closed (and therefore not readable). In the common case this won&apos;t happen, but if you snap and immediately export, its possible. In that case, you need to roll the WAL for the RS that haven&apos;t rolled them yet. However, this is in the export process, so a little latency there is tolerable, whereas avoiding this means adding latency to taking a snapshot  - bad news bears.&lt;/p&gt;

&lt;p&gt;Keep in mind that the log files and hfiles will get regularly cleaned up. The former will be moved to the .oldlogs directory and periodically cleaned up and the latter get moved to the .archive directory (again with a parallel file hierarchy, as per &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;). If the snapshot goes to read the reference file, which tracks down to the original file and it doesn&apos;t find it, then it will need to lookup the same file in its respective archive directory. If its not there, then you are really hosed (except for the case mentioned in the doc about the WALs getting cleaned up by an aggressive log cleaner, which it is shown, is not a problem).&lt;/p&gt;

&lt;p&gt;Haven&apos;t gotten around to implementing this yet, but it seems reasonable to finish up (and I think Matteo was interested in working on that part).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What is a representation of a snapshot look like in terms of META and file system contents?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The way I see the implementation in the end is just a bunch of files in the /hbase/.snapshot directory. Like I mentioned above, the layout is very similar to the layout of a table. &lt;/p&gt;

&lt;p&gt;Lets look at an example of a table named &quot;stuff&quot; (snapshot names need to be valid directory names - same as a table or CF) and has column &quot;column&quot; which is hosted on servers rs-1 and rs-2. Originally, the file system will look something like (with license taken on file names - its not exact, I know, this is just an example) :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/hbase/
	.logs/
		rs-1/
			WAL-rs1-1
			WAL-rs1-2
		rs-2/
			WAL-rs2-1
			WAL-rs2-2
	stuff/
		.tableinfo
		region1
			column
				region1-hfile-1
		region2
			column
				region2-hfile-1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The snapshot named &quot;tuesday-at-nine&quot;, when completed, then just adds the following to the directory structure (or close enough):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
	.snapshot/
		tuesday-at-nine/
			.tableinfo
			.snapshotinfo
			.logs
				rs-1/
				WAL-rs1-1.reference
				WAL-rs1-2.reference
			rs-2/
				WAL-rs2-1.reference
				WAL-rs2-2.reference
			stuff/
				.tableinfo
				region1
					column
						region1-hfile-1.reference
				region2
					column
						region2-hfile-1.reference
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The only file here that isn&apos;t a reference here is the tableinfo since it is a pretty small file (generally), so a copy seemed more prudent over doing archiving on changes to the table info.&lt;/p&gt;

&lt;p&gt;The original implementation updated META with file references to do hbase-level hard links for the HFiles. AFter getting the original implementation working, I&apos;m going to be ripping this piece out in favor of just doing an HFile cleaner and cleaner delegates (similar to logs) and then have a snapshot cleaner that reads of the FS for file references. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;At some point we may get called upon to repair these, I want to make sure there are enough breadcrumbs for this to be possible.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How could that happen - hbase never has problems! (sarcasm)&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;hlog roll (which I believe does not trigger a flush) instead of special meta hlog marker (this might avoid write unavailability, seems simpler that the mechanism I suggested)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;The hlog marker is what I&apos;m planning on doing for the timestamped based snapshot, which is going to be far safer than doing an HLog roll and provide less latency. With the roll, you need to not take any writes to the memstore between the roll and the end of the snapshot (otherwise you will lose edits). Doing meta edits into the HLog allows you to keep edits and not worry about it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;admin initiated snapshot and admin initiated restore operations as opposed to acting like a read only table. (not sure what happens to &quot;newer&quot; data after a restore, need to reread to see if it is in there, not sure about the cost to restore a snapshot)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yup, right now its all handled from HBaseAdmin. Matteo was interested in working on the restore stuff, but depending on timing, I may end up picking up that work when I get the taking of a snapshot working.  I think part of &quot;snapshots&quot; definitely includes getting back the state.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I believe it also has an ability to read files directly from an MR job without having to go through HBase&apos;s get/put interface. Is that in scope for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Absolutely in scope. It just didn&apos;t come up because I considered that part of the restore (which Matteo expressed interest). If you had to go through the high-level interface, then you would just use the procedure Lars talks about in his blog: &lt;a href=&quot;http://hadoop-hbase.blogspot.com/2012/04/timestamp-consistent-backups-in-hbase.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop-hbase.blogspot.com/2012/04/timestamp-consistent-backups-in-hbase.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The other notable change is that I&apos;m building to support multiple snapshots concurrently. Its really a trivial change, so I don&apos;t think its too much feature creep, just a matter of using lists rather than a single item. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;How does this buy your more consistency? Aren&apos;t we still inconsistent at the prepare point now instead? Can we just write the special snapshotting hlog entry at initiation of prepare, allowing writes to continue, then adding data elsewhere (META) to mark success in commit? We could then have some compaction/flush time logic cleanup failed atttempt markers?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;See the above comment about timestamp based vs. point in time and the former being all that&apos;s necessary for HBase. This means we don&apos;t take downtime and end up with a &apos;fuzzy&apos; snapshot in terms of global consistency, but is exact in terms of HBase delivered timestamps.&lt;/p&gt;

&lt;p&gt;The problem point-in-time snapshots overcomes is reaching distributed consensus while still trying to maintain availability and the ability to cross partitions. Since no one has figured out CAP and we are looking for consistency, we have to remove some availability to reach consensus. In this case, the agreement is over the state &lt;em&gt;of the entire table&lt;/em&gt;, rather than per region server. &lt;/p&gt;

&lt;p&gt;Yes, this is strictly against the contract that we have on a Scan, but it is also in line with expectations people have on what a snapshot means. Any writes that are pending before the snapshot are allowed to commit, but any writes that reach the RS after the snapshot time cannot be included in the snapshot. I got a little overzealous in my reading of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-50&quot; title=&quot;Snapshot of table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-50&quot;&gt;&lt;del&gt;HBASE-50&lt;/del&gt;&lt;/a&gt; and took it to mean global state, but after review the only way it would work within the constraints (no downtime) is to make it timestamp based.&lt;/p&gt;

&lt;p&gt;But why can&apos;t we get global consistency without taking downtime?&lt;/p&gt;

&lt;p&gt;Let&apos;s take your example of using an HLog edit to mark the start (and for ease, lets say the end as well - as long as its durable and recoverable, it doesn&apos;t matter if its WAL or META). &lt;/p&gt;

&lt;p&gt;Say we start a snapshot and send a message to all the RS (lets ignore ZK for the moment, to simplify things) that they should take a snapshot. So they write a marker into the HLog marking the start, create references as mentioned above, and then report to the master that they are done. When everyone is done, we then message each RS to commit the snapshot, which is just another entry into the WAL. Then in rebuilding the snapshot, they would just replay the WAL up to the start (assuming the end is found).&lt;/p&gt;

&lt;p&gt;How do we know though which writes arrived first on each RS if we just dump a write into the WAL? Ok, so then we need to wait for the MVCC read number to roll forward to when we got the snapshot notification &lt;em&gt;before&lt;/em&gt; we can write an edit to the log - totally reasonable.&lt;/p&gt;

&lt;p&gt;However, the problem arises in attempting to get a global state of the table in a high-volume write environment. We have no guarantee that the &quot;snapshot commit&quot; notification reached each of the RS at the same time. And even if it did reach them at the same time, maybe there was some latency in getting the write number. Or the switch was a little wonky, or it just finishing up a GC (I could go on). &lt;/p&gt;

&lt;p&gt;Then we have a case where we don&apos;t actually have the snapshot as of the commit, but rather &quot;at commit, plus or minus a bit&quot; - not a clean snapshot (if we don&apos;t care about being exact then we can do a much faster, lower potential latency solution, the discussion of which is still coming, I promise). In a system that can take millions of writes a second, that is still a non-trivial amount of data that can change in a few milliseconds, no longer a true &apos;point in time&apos;.&lt;/p&gt;

&lt;p&gt;The only way to get that global, consistent view is to remove the availability of the table for a short time so we know that the state is the same across all tables.&lt;/p&gt;

&lt;p&gt;Say we start a snapshot and the start indication doesn&apos;t reach the servers and get started at &lt;em&gt;exactly the same time on all the servers&lt;/em&gt;, which, as explained above, is very likely. Then we let the servers commit any outstanding writes,but they don&apos;t get to take any new writes or a short time. In this time while they are waiting for writes to commit, we can then do all the snapshot preparation (referencing, table info copying). Once we are ready for the snapshot, we report back to the master and wait for the commit step. In this time we are still not taking writes. The key here is that for that short time, none of the servers are taking writes and that allows us to get a single point in time that no writes are committing (but they do get buffered on the server, they just can&apos;t change the system state).&lt;/p&gt;

&lt;p&gt;If we let writes commit, then how do we reach a state that we can agree on across all the servers? If you let the writes commit, you again don&apos;t have any assurances that the prepare or the commit message time is agreed to by all the servers. The table-level consistent state is somewhere between the prepare and commit, but it&apos;s not clear how one would find that point - I&apos;m pretty sure we can&apos;t do this unless we have perfectly synchronized clocks, which is not really possible without a better understanding of quantum mechanics &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Block writes is a perhaps a bad phrase in this situation. In the current implementation, it buffers the writes as threads into the server, blocking on the updateLock. However, we can go with a &quot;semi-blocking&quot; version: writes still complete, but they aren&apos;t going to be visible until we roll forward to the snapshot MVCC number. This lets the writers complete (not affecting latency), but is going to affect read-modify-write and reader-to-writer comparison latency. However, as soon as we roll forward the MVCC, all those writes become visible, essentially catching back up to the current state. A slight modification to the WAL edits will need to be made to write the MVCC number so we can keep track of which writes are in/out of a snapshot, but that &lt;em&gt;shouldn&apos;t&lt;/em&gt; be too hard (famous last words). You don&apos;t even need to modify all the WAL edits, just those made during the snapshot window, so the over the wire cost is still kept essentially the same, when amortized over the life of a table (for the standard use case).&lt;/p&gt;

&lt;p&gt;I&apos;m looking at doing this once I get the simple version working - one step at a time. Moving to the timestamp based approach lets us keep taking writes but does so at the cost of global consistency in favor of local consistency and still uses the &lt;em&gt;exact same infrastructure&lt;/em&gt;. The first patch I&apos;ll actually put on RB will be the timestamp based, but let me get the stop the world version going before going down a rabbit hole.&lt;/p&gt;

&lt;p&gt;The only thing we don&apos;t capture is if a writer makes a request to the RS before the snapshot is taken (by another client), but the write doesn&apos;t reach the server until after the RS hits the start barrier. From the global client perspective, this write should be in the snapshot, but that requires a single client or client-side write coordination (via a timestamp oracle). However, this is even worse coordination and creates even more constraints on the system where we currently have no coordination between clients (and I&apos;m against adding any). So yes, we miss that edit, but that would be the case in a single-server database anyways without an external timestamp manager (to again distributed coordination between the client and server, though it can be done in a non-blocking manner). I&apos;ll mention some of this external coordination in the timestamp explanation.&lt;/p&gt;</comment>
                            <comment id="13288238" author="jmhsieh" created="Sun, 3 Jun 2012 19:04:45 +0000"  >&lt;p&gt;Jesse,&lt;/p&gt;

&lt;p&gt;Thanks for answering the questions.  A strong +1 for doing the simplest hbase timestamp-based approach first, and then looking into the more complicated version as an option afterwards.  Maybe start a sub issue with the point-in-time approach to move discussion there? (I still have questions there, might be better to ask there)&lt;/p&gt;

&lt;p&gt;The main use case I care about is ability to quickly &quot;snapshot&quot; without downtime and quickly recover it (ideally with no downtime, but possibly with a short downtime window).  Although it is a &quot;sloppy snapshot&quot; conceptually it is pretty simple to define and I think the caveats are fairly well undestood.  I don&apos;t expect something with stronger consistency guarantees than what hbase currently offers but do expect something better (cheaper/faster) than the current closest thing which is a CopyTable.  &lt;/p&gt;

&lt;p&gt;I have a bunch of new questions - some just asking for precision and some for clarification.  It might be helpful to define terms in the beginning of the doc so it stays consistent? &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Hm.. how do you restore a snapshot from references files if it hasn&apos;t been scan/copied yet?  Require scan/copy &quot;materialization&quot; of the snapshot first?  (which means slower restore, but probably would likely be simplest for a first cut)&lt;/li&gt;
	&lt;li&gt;Snapshot restore needs to be &quot;transactional&quot; like snapshotting right?&lt;/li&gt;
	&lt;li&gt;what is &quot;export&quot;? is this taking a snapshot or the materialization or the snapshot restore or something else?&lt;/li&gt;
	&lt;li&gt;If we restore snapshots to the same hbase instance, in dir structure, you probably need .regioninfo files as well. (contains region startkey/endkey info necessary to reconsistute META later).&lt;/li&gt;
	&lt;li&gt;Is restoring to a separate instance in scope?  If so bulk loads can be expensive &amp;#8211; if regions don&apos;t line up there will be a bunch of spliting that happens.  Again, keeping the regionsinfos and the snapshot&apos;s splits may be worthwhile.&lt;/li&gt;
	&lt;li&gt;Where do the materialized versions of the snapshot reference files end up?  in the snapshot dirs? elsewhere?
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;This potentially gets a little trickier with markers as opposed to log rolls.&lt;/li&gt;
		&lt;li&gt;The HLog will have edits from regions not relevant to the table&apos;s regions.  Not a huge problem but maybe an optmization would be that the materialization step will do an &quot;offline hlogsplit/flush&quot; to just keep the data relevent to this table/region?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="13288279" author="jmhsieh" created="Sun, 3 Jun 2012 23:10:01 +0000"  >&lt;p&gt;One other place where bulk import can be expensive &amp;#8211; if we bulk import all into a single region, it would likely incur a compaction/split storm...&lt;/p&gt;</comment>
                            <comment id="13288414" author="lhofhansl" created="Mon, 4 Jun 2012 08:29:19 +0000"  >&lt;p&gt;Now that I started to get a bit more familiar with HDFS I am wondering whether HDFS hardlinks (&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3370&quot; title=&quot;HDFS hardlink&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3370&quot;&gt;HDFS-3370&lt;/a&gt;) or even HDFS snapshots (&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-233&quot; title=&quot;Support for snapshots&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-233&quot;&gt;&lt;del&gt;HDFS-233&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2802&quot; title=&quot;Support for RW/RO snapshots in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2802&quot;&gt;&lt;del&gt;HDFS-2802&lt;/del&gt;&lt;/a&gt;) are not a better avenue. We are looking for data consistency here, which would be better tackled at the data layer.&lt;br/&gt;
Now... Both features are some ways off in HDFS (although we can probably push these forward), so doing something in HBase first is probably needed, but IMHO it should be something quick.&lt;br/&gt;
Lastly if we are considering this for backups &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt; should be a better (simpler) solution.&lt;/p&gt;

&lt;p&gt;Not trying to derail anything here, just making sure we do not invest a lot of time in vain.&lt;/p&gt;</comment>
                            <comment id="13288429" author="jmhsieh" created="Mon, 4 Jun 2012 08:45:04 +0000"  >&lt;p&gt;I agreee that &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3370&quot; title=&quot;HDFS hardlink&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3370&quot;&gt;HDFS-3370&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-233&quot; title=&quot;Support for snapshots&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-233&quot;&gt;&lt;del&gt;HDFS-233&lt;/del&gt;&lt;/a&gt; are likely a ways off.  Hardlinks would probably obviate the need for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;.  We could probably take advantage of HDFS symlinks &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-245&quot; title=&quot;Create symbolic links in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-245&quot;&gt;&lt;del&gt;HDFS-245&lt;/del&gt;&lt;/a&gt; which is in Hadoop 2.x.x hdfs but may not be in Hadoop 1.x.x hdfs.&lt;/p&gt;

&lt;p&gt;I think that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt; is a prereq for either consistency approach (even if we use symlinks) until we have hdfs hardlinks.  I&apos;ll take a closer look into &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13288696" author="jesse_yates" created="Mon, 4 Jun 2012 17:13:33 +0000"  >&lt;p&gt;@Lars even with the HDFS patches, we should have a way to logically group/backup/restore snapshots. &lt;/p&gt;

&lt;p&gt;IMO hardlinks with HBase snapshots is the way to go, since we can do it with zero downtime, whereas HDFS snapshots require some (though admittedly small) downtime. HBSE-5547 is basically just a hack around hardlinks.&lt;/p&gt;</comment>
                            <comment id="13288700" author="lhofhansl" created="Mon, 4 Jun 2012 17:17:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;IMO hardlinks with HBase snapshots is the way to go... HBSE-5547 is basically just a hack around hardlinks&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep.&lt;/p&gt;</comment>
                            <comment id="13288715" author="jesse_yates" created="Mon, 4 Jun 2012 17:33:51 +0000"  >&lt;p&gt;A couple of definitions going forward:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;materialization: the end result of taking a single snapshot, on the same cluster. It ends up in in the .snapshot/&lt;span class=&quot;error&quot;&gt;&amp;#91;snapshot_name&amp;#93;&lt;/span&gt; directory&lt;/li&gt;
	&lt;li&gt;export: sending the snapshot to another cluster or another part of the same cluster&lt;/li&gt;
	&lt;li&gt;restore: taking an exported snapshot and converting the snapshot into an active table.&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;Hm.. how do you restore a snapshot from references files if it hasn&apos;t been scan/copied yet? Require scan/copy &quot;materialization&quot; of the snapshot first? (which means slower restore, but probably would likely be simplest for a first cut)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right now, you would do a M/R job to distcp over the files to another cluster or a backup part of your cluster. Since we are just storing references, the actual file copying will be necessary. This will be helped by using the actual &quot;Reference&quot; class for the HFiles (and currently being (mis)used for the WALs, but I don&apos;t think we actually need to keep the WALs  - I&apos;ll comment in the timestamp ticket). Since they are just reference files, you could just use the regular HFile reader to load them into another table.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;	Snapshot restore needs to be &quot;transactional&quot; like snapshotting right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, I guess. I don&apos;t really see this as a problem - just keep it to one restore at a time. But it would be all or nothing to get a table online.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;what is &quot;export&quot;? is this taking a snapshot or the materialization or the snapshot restore or something else?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Export is taking a snapshot from the .snapshot/ directory and possibly having a special snapshot distcp to somewhere. I would consider materialization as taking the exported snapshot and then &apos;hooking it back up&apos; to another cluster (or the same) as a new table. You could throw materialization of the exported snapshot, but they are in fact distinct.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If we restore snapshots to the same hbase instance, in dir structure, you probably need .regioninfo files as well. (contains region startkey/endkey info necessary to reconsistute META later).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 I&apos;ll make sure that gets in&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Is restoring to a separate instance in scope? If so bulk loads can be expensive &#8211; if regions don&apos;t line up there will be a bunch of spliting that happens. Again, keeping the regionsinfos and the snapshot&apos;s splits may be worthwhile.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;d say restore is part of this. Should be solved by having the region info. -1 for split/compact storms.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Where do the materialized versions of the snapshot reference files end up? in the snapshot dirs? elsewhere?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What do you mean materialized? After taking  snapshot, where do the snapshot files end up? In the .snapshot directory. See my earlier comments on the structure.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This potentially gets a little trickier with markers as opposed to log rolls.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If we do a log roll, its probably going to take a bit longer. Also, its not going to be applicable to the timestamp approach, since log rolling will necessitate doing some kind of locking, which we should avoid, where the markers will be much faster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The HLog will have edits from regions not relevant to the table&apos;s regions. Not a huge problem but maybe an optmization would be that the materialization step will do an &quot;offline hlogsplit/flush&quot; to just keep the data relevent to this table/region?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1, assuming we need the HLogs. I think there is a minimally impactful way to avoid this altogether.&lt;/p&gt;
</comment>
                            <comment id="13288733" author="zhihyu@ebaysf.com" created="Mon, 4 Jun 2012 17:47:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;The HLog will have edits from regions not relevant to the table&apos;s regions.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5699&quot; title=&quot;Run with &amp;gt; 1 WAL in HRegionServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5699&quot;&gt;&lt;del&gt;HBASE-5699&lt;/del&gt;&lt;/a&gt;, each one of the multiple WALs can be devised to receive edits from single table.&lt;/p&gt;</comment>
                            <comment id="13289900" author="sunnygao" created="Wed, 6 Jun 2012 02:12:11 +0000"  >&lt;p&gt;Hi Jesse&lt;br/&gt;
I am considering the solution which don&apos;t use Hlog.   The way is only handling the memstore and asynchronous flush the memstore to Hfile. when the region server is down, we can finish flushing Hfile by replay editLog. Do  you think whether it is feasible or not?&lt;br/&gt;
If we can do, there are several relatively large benefits:&lt;br/&gt;
1. restore the snapshot is easier&lt;br/&gt;
2. We can achieve an incremental backup by HFile &lt;/p&gt;</comment>
                            <comment id="13289907" author="jesse_yates" created="Wed, 6 Jun 2012 02:23:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sunnygao&quot; class=&quot;user-hover&quot; rel=&quot;sunnygao&quot;&gt;gaojinchao&lt;/a&gt; In the &quot;stop the world&quot; impementation, flushing the HFile is going to take too long. However, in the timestamp based approach time doesn&apos;t play as big a role (oh the irony!), so we can actually flush the HFiles and do what you are talking about. I&apos;m most of the way through a writeup for how this would work, but have been a bit busy the last few days to post it - planning to have it up tomorrow in a sub-ticket (as Jon suggests). &lt;/p&gt;</comment>
                            <comment id="13290027" author="sunnygao" created="Wed, 6 Jun 2012 08:51:31 +0000"  >&lt;p&gt;Fine, Thanks, I will take some time for this feature.&lt;/p&gt;</comment>
                            <comment id="13292852" author="jmhsieh" created="Mon, 11 Jun 2012 15:57:51 +0000"  >&lt;p&gt;I still a bit confused &amp;#8211; still at the basic admin level.  I think it would help if we give the &quot;restoring&quot;/&quot;export&quot; parts some more attention and talk about usage as opposed to mechanism first.  I&apos;m going to pose some use case/examples/scenarios which hopefully will be easier to discuss.  &lt;/p&gt;

&lt;p&gt;Let&apos;s say I am an admin, and we are pre hdfs hardlinks.  &lt;/p&gt;

&lt;p&gt;I issue a &quot;snapshot&quot; command at the shell/master.  &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;HBase creates a new .snapshot subdir, and it contains references to HLogs and HFiles.  This is a &quot;snapshot&quot;
	&lt;ul&gt;
		&lt;li&gt;This step is called: snapshotting, &quot;taking a snapshot&quot;, and also materializing right?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I currently have a snapshot.  I want read-only access its contents to compare with the current table.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Does HBase know how to interpret the stuff in a .snapshot dir such that it act like a read-only table?&lt;/li&gt;
	&lt;li&gt;Do I, as an admin, need to execute some step to make it appear in HBase as a read-only table? (if so what is this called?)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I currently have a snapshot.  Oops! I accidentally truncated the table I had snapshotted.  I don&apos;t want the truncated version of the table anymore and I want to replace the table with the snapshot so I have read write access.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;This is called &quot;restoring&quot; the snapshot right? (and I do this by issuing a something like &quot;restore&quot; command at the shell?)&lt;/li&gt;
	&lt;li&gt;Does HBase copy or move the data referred to in the snapshot?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I currently have a snapshot.  I want the current version but I&apos;d like to clone of the snapshotted table that provides read/write access to the clone.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is/should this be supported?&lt;/li&gt;
	&lt;li&gt;Is this called &quot;restoring&quot; or &quot;exporting&quot; the snapshot (to a new name)?&lt;/li&gt;
	&lt;li&gt;For this to work I need to convert all references into actual copies of the HFiles and HLogs right?  Is this conversion called exporting? (FYI, this is what I meant materializing to mean, but let&apos;s just stick to your definitions)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I currently have a snapshot.  I want to send a copy of the snapshot to a remote cluster so that it can provide read/write access to the data.  &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is/should this be supported?&lt;/li&gt;
	&lt;li&gt;Do both HBase instances need to be up at the same time?
	&lt;ul&gt;
		&lt;li&gt;This process would need to dereference the snapshot&apos;s references and copy them.  What is it called?  exporting?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;



&lt;hr /&gt;
&lt;p&gt;Source of confusion&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Export is taking a snapshot from the .snapshot/ directory and possibly having a special snapshot distcp to somewhere. I would consider materialization as taking the exported snapshot and then &apos;hooking it back up&apos; to another cluster (or the same) as a new table. You could throw materialization of the exported snapshot, but they are in fact distinct.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the first &quot;materialization&quot; is supposed to be &quot;restoration&quot; yeah?  I don&apos;t quite get the last sentence.&lt;/p&gt;</comment>
                            <comment id="13292952" author="mbertozzi" created="Mon, 11 Jun 2012 18:32:54 +0000"  >&lt;p&gt;@Jon inline replies&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I issue a &quot;snapshot&quot; command at the shell/master.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;HBase creates a new .snapshot subdir, and it contains references to HLogs and HFiles. This is a &quot;snapshot&quot;
	&lt;ul&gt;
		&lt;li&gt;This step is called: snapshotting, &quot;taking a snapshot&quot;, and also materializing right?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Yes, When you issue a &quot;snapshot&quot; command, hbase create a new .snapshot subdir containing references to hlog and hfile.&lt;br/&gt;
This is &quot;taking a snapshot&quot; or snapshotting... &lt;br/&gt;
but not materialization, I think &quot;materialization&quot; is when you copy the hfiles/hlogs somewhere else...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I currently have a snapshot. I want read-only access its contents to compare with the current table.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Does HBase know how to interpret the stuff in a .snapshot dir such that it act like a read-only table?&lt;/li&gt;
	&lt;li&gt;Do I, as an admin, need to execute some step to make it appear in HBase as a read-only table? (if so what is this called?)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think that the first point is more like a snapshot-scan... that scan the hfiles + hlog in the snapshot directory and show you the result...&lt;br/&gt;
The second point seems more like a &quot;Restore on different table&quot; and marking the table as readonly&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I currently have a snapshot. Oops! I accidentally truncated the table I had snapshotted. I don&apos;t want the truncated version of the table anymore and I want to replace the table with the snapshot so I have read write access.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;This is called &quot;restoring&quot; the snapshot right? (and I do this by issuing a something like &quot;restore&quot; command at the shell?)&lt;/li&gt;
	&lt;li&gt;Does HBase copy or move the data referred to in the snapshot?&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&quot;Restore&quot; is when you replace your current table with the snapshot version, and you do it by &quot;restore snapshot-name&quot;&lt;br/&gt;
Yeah you need to copy the &quot;old hfiles&quot; to restore the snapshot (but maybe not every hfiles are removed from the current table)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I currently have a snapshot. I want the current version but I&apos;d like to clone of the snapshotted table that provides read/write access to the clone.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is/should this be supported?&lt;/li&gt;
	&lt;li&gt;Is this called &quot;restoring&quot; or &quot;exporting&quot; the snapshot (to a new name)?&lt;/li&gt;
	&lt;li&gt;For this to work I need to convert all references into actual copies of the HFiles and HLogs right? Is this conversion called exporting? (FYI, this is what I meant materializing to mean, but let&apos;s just stick to your definitions)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yeah this is really easy with HardLink... some more work is needed to keep track of references files&lt;br/&gt;
This is &quot;Restore on a different table&quot;, &quot;export&quot; is when you&apos;re copying the .snapshot/name folder to another cluster...&lt;br/&gt;
If you think in term of HardLink you don&apos;t need to copy the hfiles but just doing an HardLink... more code is needed to use Reference Files but you can avoid the copy. (Note that HLog need to be replayed, so this is the only one that need to be copied.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I currently have a snapshot. I want to send a copy of the snapshot to a remote cluster so that it can provide read/write access to the data.&lt;br/&gt;
Is/should this be supported?&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Do both HBase instances need to be up at the same time?&lt;/li&gt;
	&lt;li&gt;This process would need to dereference the snapshot&apos;s references and copy them. What is it called? exporting?&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes this is &quot;Import/Export&quot; that besically is a distcp of the .snapshot/name folder&lt;br/&gt;
I Think that is enough having both hdfs up at the same time.&lt;br/&gt;
Yeah in this case you need to physically copy the hfiles.&lt;/p&gt;</comment>
                            <comment id="13293482" author="lhofhansl" created="Tue, 12 Jun 2012 09:51:50 +0000"  >&lt;p&gt;Let&apos;s try to avoid going overboard here.&lt;br/&gt;
In principle snapshot and backup/restore are different and independent.&lt;/p&gt;

&lt;p&gt;A snapshot generates a consistent snapshot of the data that can subsequently be copied conveniently somewhere else - thus creating a backup.&lt;/p&gt;

&lt;p&gt;Ideally we would not even prescribe the backup/restore semantics here, but just provide missing building blocks.&lt;/p&gt;

&lt;p&gt;Just my $0.02.&lt;/p&gt;

&lt;p&gt;Another thought here is: In principle an HFile resulting from a major compaction could be considered a baseline copy and additional HFiles would be incremental changes on top of that baseline. It might be worth considering if we can make use of this ability of HBase to overlay changes from many sources into a single view of the data (would probably be tricky as regions are flushed in sync, etc, just waving hands here).&lt;/p&gt;</comment>
                            <comment id="13293657" author="jmhsieh" created="Tue, 12 Jun 2012 14:24:24 +0000"  >&lt;p&gt;Hey Lars,&lt;/p&gt;

&lt;p&gt;Sorry if it seems like I&apos;m going overboard &amp;#8211; I&apos;m trying to tease out consistent common definitions, and get an explicit high-level understanding of how the feature is supposed to be used from an user/admin point of view.  &lt;/p&gt;

&lt;p&gt;I&apos;m also trying to understand what is in scope and not (ex: making the snapshot act like a read-only table could be in scope,  restoring/replacing the original table should be, but restoring to another name could be deferred until hardlinks, the import/export stuff could be done using existing means.)&lt;/p&gt;</comment>
                            <comment id="13395990" author="jesse_yates" created="Mon, 18 Jun 2012 16:08:01 +0000"  >&lt;p&gt;Adding link to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6230&quot; title=&quot;[brainstorm] &amp;quot;Restore&amp;quot; snapshots for HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6230&quot;&gt;&lt;del&gt;HBASE-6230&lt;/del&gt;&lt;/a&gt; for further discussion around snapshot restore.&lt;/p&gt;</comment>
                            <comment id="13408390" author="jesse_yates" created="Fri, 6 Jul 2012 22:07:13 +0000"  >&lt;p&gt;Pushed up initial review (based on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;) on review board: &lt;a href=&quot;https://reviews.apache.org/r/5817/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/5817/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13408512" author="zhihyu@ebaysf.com" created="Sat, 7 Jul 2012 01:14:25 +0000"  >&lt;p&gt;Can you rebase to current trunk ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
|--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HMasterInterface.java
|+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HMasterInterface.java
--------------------------
File to patch: ^C
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13408528" author="jesse_yates" created="Sat, 7 Jul 2012 01:45:56 +0000"  >&lt;p&gt;Looks like I&apos;m just missing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6341&quot; title=&quot;Publicly expose HConnectionKey&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6341&quot;&gt;&lt;del&gt;HBASE-6341&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6283&quot; title=&quot;[region_mover.rb] Add option to exclude list of hosts on unload instead of just assuming the source node.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6283&quot;&gt;&lt;del&gt;HBASE-6283&lt;/del&gt;&lt;/a&gt;, both of which don&apos;t really change the patch. Keep in mind you will need to apply the latest patch from &lt;a href=&quot;https://reviews.apache.org/r/4633/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/4633/&lt;/a&gt; (RB of latest for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;, that code on trunk) before applying the patch - RB isn&apos;t obvious about having a parent diff.&lt;/p&gt;

&lt;p&gt;Unless something has been committed to the svn that is significantly different and hasn&apos;t propagated to the git repo yet...&lt;/p&gt;</comment>
                            <comment id="13408646" author="mbertozzi" created="Sat, 7 Jul 2012 12:06:56 +0000"  >&lt;p&gt;@Jesse working on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6353&quot; title=&quot;Snapshots shell&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6353&quot;&gt;&lt;del&gt;HBASE-6353&lt;/del&gt;&lt;/a&gt;, I&apos;ve also switched to use protobuf (HMasterInterface was removed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6039&quot; title=&quot;Remove HMasterInterface and replace with something similar to RegionServerStatusProtocol&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6039&quot;&gt;&lt;del&gt;HBASE-6039&lt;/del&gt;&lt;/a&gt;).&lt;br/&gt;
Maybe you can use when rebasing on trunk (HBaseAdmin, MasterAdminProtocol, ...)&lt;/p&gt;</comment>
                            <comment id="13408713" author="jesse_yates" created="Sat, 7 Jul 2012 16:40:51 +0000"  >&lt;p&gt;@Matteo I&apos;ve done that already, looks like my diff-ing got messed up :/ Working on pushing up a new patch...&lt;/p&gt;</comment>
                            <comment id="13414689" author="zhihyu@ebaysf.com" created="Sun, 15 Jul 2012 16:14:49 +0000"  >&lt;p&gt;Flipping through 5 pages on review board is slow. So I am putting down some notes here.&lt;/p&gt;

&lt;p&gt;For HStore.java:&lt;br/&gt;
The license header doesn&apos;t look like the standard format.&lt;br/&gt;
Please add audience and stability annotations to this new interface.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  FileStatus[] getStoreFiles() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
+
+  List&amp;lt;StoreFile&amp;gt; getStorefiles();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why do we need two methods which are spelled almost the same, yet returning different types ? When refactoring, we should make the code cleaner.&lt;br/&gt;
There&apos;re many methods which don&apos;t have javadoc. Please add javadoc for them.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; HStore getDelgate() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Correct spelling for the above method.&lt;/p&gt;</comment>
                            <comment id="13414766" author="jmhsieh" created="Sun, 15 Jul 2012 20:19:33 +0000"  >&lt;p&gt;@Ted &amp;#8211; FYI, I keep 5 screens open each on a different one.  Then I can flip between them quick and comment on each.&lt;/p&gt;</comment>
                            <comment id="13415410" author="zhihyu@ebaysf.com" created="Mon, 16 Jul 2012 17:22:17 +0000"  >&lt;p&gt;Thanks for the hint, Jon.&lt;br/&gt;
I thought of that approach.&lt;/p&gt;

&lt;p&gt;I recently looked up related classes in the patch using vi directly.&lt;br/&gt;
It would be nice if we can reduce the number of classes: controller, monitor, manager, sentinel, etc. It is hard to follow &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I have gone through about 2.5 pages of diff.&lt;br/&gt;
I can see there is more work to be done for Global snapshot.&lt;/p&gt;</comment>
                            <comment id="13432220" author="jesse_yates" created="Thu, 9 Aug 2012 22:13:50 +0000"  >&lt;p&gt;I&apos;ve working on a new version that abstracts out a lot of the different pieces in the snapshot that can be reused (both here and in general in HBase) and then reimplementing everything based on those abstractions. Each of these abstractions/standalone pieces is going to moved to another jira and given their own RB review. Hopefully this is going to makes reviewer&apos;s lives easier.&lt;/p&gt;

&lt;p&gt;I currently have tests passing and hopefully, I&apos;ll have a new version (and child tickets) up on RB tomorrow.&lt;/p&gt;</comment>
                            <comment id="13432228" author="apurtell" created="Thu, 9 Aug 2012 22:23:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Each of these abstractions/standalone pieces is going to moved to another jira and given their own RB review.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jesse_yates&quot; class=&quot;user-hover&quot; rel=&quot;jesse_yates&quot;&gt;Jesse Yates&lt;/a&gt; So maybe we can use this JIRA as an umbrella for subtasks?&lt;/p&gt;</comment>
                            <comment id="13433602" author="jesse_yates" created="Mon, 13 Aug 2012 21:50:02 +0000"  >&lt;p&gt;Created sub-tasks &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6568&quot; title=&quot;Extract daemon thread factory from HTable into its own class&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6568&quot;&gt;&lt;del&gt;HBASE-6568&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6569&quot; title=&quot;Extract HStore interface from Store&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6569&quot;&gt;&lt;del&gt;HBASE-6569&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6570&quot; title=&quot;Fix hfile/log cleaning delegate method naming&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6570&quot;&gt;&lt;del&gt;HBASE-6570&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6571&quot; title=&quot;Generic multi-thread/cross-process error handling framework&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6571&quot;&gt;&lt;del&gt;HBASE-6571&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6573&quot; title=&quot;Distributed Three-Phase Commit framework.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6573&quot;&gt;&lt;del&gt;HBASE-6573&lt;/del&gt;&lt;/a&gt; for each of the pieces for snapshots. Posting a new snapshots patch (based on all these patches - to apply the coming patch you will need to apply all the others first) to RB soon.&lt;/p&gt;</comment>
                            <comment id="13436380" author="jesse_yates" created="Thu, 16 Aug 2012 22:42:52 +0000"  >&lt;p&gt;Current patch is up on RB, but is missing (1) validation of the snapshot on the master, (2) concurrent flushes during a timestamp-consistent snapshot and (3) concurrent compactions during a timestamp-consistent snapshot. That being said, these are relatively minor elements that can be rolled in after a majority of reviews.&lt;/p&gt;

&lt;p&gt;I&apos;ve currently got (2) working with unit tests and am hoping to push up a new version early next week with all 3 elements (so a complete implementation).&lt;/p&gt;</comment>
                            <comment id="13436382" author="jesse_yates" created="Thu, 16 Aug 2012 22:43:32 +0000"  >&lt;p&gt;Looking at implementing concurrent compactions, there is an issue around allowing compactions and how to get a consistent view of the directory for each store. If a compaction is taking place and we &apos;ls&apos; the directory for a store, the following may occur (or some semantically correct subset of the following):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;get the first set of HFiles in the directory&lt;/li&gt;
	&lt;li&gt;compaction removes all the files&lt;/li&gt;
	&lt;li&gt;compaction moves in its own files&lt;/li&gt;
	&lt;li&gt;we get the next batch of files from the namenode for the original &apos;ls&apos;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This leads to a munged (not necessarily incorrect) view of the hfiles that will require another compaction on restore to get a reasonable performance. There are a couple considerations here. &lt;/p&gt;

&lt;p&gt;(1) the above situation occurs only when we have &lt;em&gt;more files in a store that the ls limit on the namenode&lt;/em&gt;, which is 1000 by default - the unit of atomicity. As long as a single store doesn&apos;t have more than 1000 files, then we can just ignore compactions entirely and snap away. However, once we breach 1000 files, this becomes a different, potentially far more complex to reason about, problem. &lt;/p&gt;

&lt;p&gt;(2) We can block for the currently running compactions to finish and then get a quick &apos;ls&apos; between compactions starting. This is a bit more intrustive and will potentialy hold up the compaction queue for a little bit. Also as we have more files and a more active system it becomes increasingly likely to get a compaction and cause your snapshot to fail as it waits on the compaction to finish (since we time-bound snapshots to minimize impact on the system).&lt;/p&gt;

&lt;p&gt;Personally, it seems unlikely that we are going to get more than 1000 files in a single store. However, if its unlikely, that means its probably going to happen &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Option (2) is far more intrusive and code intensive, potentially causing some lag in the system, but is sure to be safe once we get it right. &lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="13437209" author="hudson" created="Sat, 18 Aug 2012 01:42:49 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3237 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3237/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3237/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt; Fix hfile/log cleaning delegate method naming (Revision 1374478)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/backup/example/LongTermArchivingHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseLogCleanerDelegate.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/FileCleanerDelegate.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/TimeToLiveHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/CheckedArchivingHFileCleaner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13437254" author="jmhsieh" created="Sat, 18 Aug 2012 05:46:32 +0000"  >&lt;p&gt;Hm.. previous should have been labeled &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6570&quot; title=&quot;Fix hfile/log cleaning delegate method naming&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6570&quot;&gt;&lt;del&gt;HBASE-6570&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13441953" author="mbertozzi" created="Sat, 25 Aug 2012 20:13:13 +0000"  >&lt;p&gt;Can we have a snapshot branch to speedup the development?&lt;/p&gt;

&lt;p&gt;currently to test snapshot you need to apply patches from different jiras, &lt;br/&gt;
and after a while they cannot be applied cleanly, &lt;br/&gt;
and it require some time to been able to run it...&lt;/p&gt;

&lt;p&gt;since neither me or Jesse has rights to commit, do you have any idea how to do that? someone volunteer to merge the patches in the branch? any other suggestions?&lt;/p&gt;</comment>
                            <comment id="13441975" author="lhofhansl" created="Sat, 25 Aug 2012 22:03:11 +0000"  >&lt;p&gt;I think that makes sense at this point.&lt;/p&gt;

&lt;p&gt;I&apos;ve also been thinking that a synchronous flush of all regions of a table (or cluster) would already get us far along a backup solution (with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt;). So maybe we should start with that and do the rest in a branch.&lt;/p&gt;</comment>
                            <comment id="13454168" author="jesse_yates" created="Wed, 12 Sep 2012 17:47:46 +0000"  >&lt;p&gt;Just setup my github repo for a snapshots development branch: &lt;a href=&quot;https://github.com/jyates/hbase/tree/snapshots&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jyates/hbase/tree/snapshots&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We can make it such that any of the future patches for snapshots (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6765&quot; title=&quot;&amp;#39;Take a snapshot&amp;#39; interface&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6765&quot;&gt;&lt;del&gt;HBASE-6765&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6353&quot; title=&quot;Snapshots shell&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6353&quot;&gt;&lt;del&gt;HBASE-6353&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6571&quot; title=&quot;Generic multi-thread/cross-process error handling framework&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6571&quot;&gt;&lt;del&gt;HBASE-6571&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6573&quot; title=&quot;Distributed Three-Phase Commit framework.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6573&quot;&gt;&lt;del&gt;HBASE-6573&lt;/del&gt;&lt;/a&gt;) all go into this branch and then we just merge the branch into svn with 3 +1&apos;s from committers when its ready (as per the discussion here: &lt;a href=&quot;http://search-hadoop.com/m/asM982C5FkS1/hbase+branch+git&amp;amp;subj=Thoughts+about+large+feature+dev+branches&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search-hadoop.com/m/asM982C5FkS1/hbase+branch+git&amp;amp;subj=Thoughts+about+large+feature+dev+branches&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;All reviews still go through reviewboard and will receive the same scrutiny, but get committed over on github until we want to roll it into trunk.&lt;/p&gt;

&lt;p&gt;Thoughts? &lt;/p&gt;</comment>
                            <comment id="13454169" author="jmhsieh" created="Wed, 12 Sep 2012 17:50:42 +0000"  >&lt;p&gt;+1 Sounds good to me.  We might have to do the incremental reviews(generating a parent patch and then the main patch) to send up to review board but this should work.&lt;/p&gt;</comment>
                            <comment id="13454173" author="jesse_yates" created="Wed, 12 Sep 2012 17:54:31 +0000"  >&lt;p&gt;@Jon yeah, that&apos;s the pain of RB, but you can just do &apos;git checkout HEAD~1; git diff trunk&apos; to generate that parent patch - not too much overhead.&lt;/p&gt;</comment>
                            <comment id="13463433" author="jesse_yates" created="Wed, 26 Sep 2012 01:11:40 +0000"  >&lt;p&gt;I was going through the offline snapshot code (&lt;a href=&quot;https://github.com/jyates/hbase/tree/offline-snapshots&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jyates/hbase/tree/offline-snapshots&lt;/a&gt;) and noticed that apparently I wrote the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Path editsdir = HLog.getRegionDirRecoveredEditsDir(HRegion.getRegionDir(tdir,regionInfo.getEncodedName()));
WALReferenceTask op = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WALReferenceTask(snapshot, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.monitor, editsdir, conf, fs, &lt;span class=&quot;code-quote&quot;&gt;&quot;disabledTableSnapshot&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For referencing the current hfiles for a disabled table, this makes no sense. However, it got me thinking about dealing with recovered edits for a table. Even if a table is disabled, it may have recovered edits that haven&apos;t been applied to the table (a RS comes up, splits the logs, but then dies again before replaying the split log). &lt;/p&gt;

&lt;p&gt;If I&apos;m reading the log-splitting code correctly, I think it archives the original HLog after splitting, but not before the edits are applied to the region. This would mean we also need to reference the recovered.edits directory under each region, if we keep the current implementation...right?&lt;/p&gt;

&lt;p&gt;I was thinking that instead we can keep the hfiles around in the .logs directory until the recovered.edits files for that log file have been replayed. This way we can avoid another task for snapshotting (referencing all the recovered edits) and keep everything simple fairly simple. There would need to be some extra work to keep track of the source hlog - either an &apos;info&apos; file for the source hlog that lists the written recovered.edits files or special naming of the recovered.edits files that point back to the source file. &lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="13463700" author="mbertozzi" created="Wed, 26 Sep 2012 10:44:04 +0000"  >&lt;p&gt;When you&apos;re talking about hfiles, you are referring to the log files right? I&apos;ve a bit a of confusion reading your comment, bacause the log files are sequence files. anyway...&lt;/p&gt;

&lt;p&gt;The logs in /hbase/.logs are splitted (new files are created in region/recover.edits) and if you look at HRegion.replayRecoveredEditsIfAny(), the content of recover.edits is removed as soon as the edits are applied. Removed, not archived. And this means that as soon as the table goes online, the snapshot doesn&apos;t have a way to read those files.&lt;/p&gt;

&lt;p&gt;but as you&apos;ve said, the original (full) log is still available during split, but moved to the archive (.oldlogs) as soon as the split is done. &lt;/p&gt;

&lt;p&gt;This means that if you see files in recover.edits, you should have the full logs in /hbase/.logs folder. And you can keep a reference to them, as you do for the online snapshot.&lt;/p&gt;

&lt;p&gt;Another semi-unrelated note... currently we keep full logs files, and the restore needs to split them (see the restore code SnapshotLogSplitter, &lt;a href=&quot;https://github.com/matteobertozzi/hbase/blob/snapshot-dev/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/restore/RestoreSnapshotHelper.java#L398&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/matteobertozzi/hbase/blob/snapshot-dev/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/restore/RestoreSnapshotHelper.java#L398&lt;/a&gt;)&lt;br/&gt;
Can we move this logic at the end of the take snapshot operation and split the logs in .snapshot/region/recover.edits?&lt;/p&gt;</comment>
                            <comment id="13464276" author="jesse_yates" created="Wed, 26 Sep 2012 23:21:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;When you&apos;re talking about hfiles, you are referring to the log files right? I&apos;ve a bit a of confusion reading your comment, bacause the log files are sequence files. anyway...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops, typing tired. Yeah, I mean hlogs the entire time.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The logs in /hbase/.logs are splitted (new files are created in region/recover.edits) and if you look at HRegion.replayRecoveredEditsIfAny(), the content of recover.edits is removed as soon as the edits are applied. Removed, not archived. And this means that as soon as the table goes online, the snapshot doesn&apos;t have a way to read those files.&lt;/p&gt;

&lt;p&gt;but as you&apos;ve said, the original (full) log is still available during split, but moved to the archive (.oldlogs) as soon as the split is done.&lt;/p&gt;

&lt;p&gt;This means that if you see files in recover.edits, you should have the full logs in /hbase/.logs folder. And you can keep a reference to them, as you do for the online snapshot&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Keeping all the logs in .oldlogs as well as .logs will cover a LOT more hlogs than are necessary to restore the table. Better would be just just reference all the files in the recovered.edits directory, but I worry that there will probably be some race conditions (especially in cases where a server is brought up and down multiple times). Easier just seems to be to remove the log file when when all the recovered.edits are finished. For instance, we could use the FileLink stuff Matteo is working on to ref-count that hlog and only delete it when the last &apos;reference&apos; (or file derived from that hlog) is gone from the recovered.edits directory&lt;/p&gt;</comment>
                            <comment id="13464283" author="jesse_yates" created="Wed, 26 Sep 2012 23:26:40 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Another semi-unrelated note... currently we keep full logs files, and the restore needs to split them (see the restore code SnapshotLogSplitter, &lt;a href=&quot;https://github.com/matteobertozzi/hbase/blob/snapshot-dev/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/restore/RestoreSnapshotHelper.java#L398&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/matteobertozzi/hbase/blob/snapshot-dev/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/restore/RestoreSnapshotHelper.java#L398&lt;/a&gt;)&lt;br/&gt;
Can we move this logic at the end of the take snapshot operation and split the logs in .snapshot/region/recover.edits?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If we move it into the snapshot operation, then that will slow down the overall operation and make it more difficult to reason about how long a snapshot &apos;should&apos; take. In particular, this becomes difficult because we want to give the client firm time bounds, but the log splitting is not time bounded (AFAIK).  &lt;/p&gt;

&lt;p&gt;An alternative would be to have a background snapshot-log-splitter task that just goes through and splits logs for snapshots. It would basically comb though the snapshot directory, looking for snapshots. If it finds one it hasn&apos;t seen, it starts doing the current log splitting on that snapshot (which looks basically like the root directory of hbase - less the ROOT and META tables - so it should be almost, if not entirely, drop-in useable). When the logs are split, we would have to do a little extra checking to make sure that we don&apos;t restore a snapshot mid-split, or that if we do that it handles it properly. &lt;/p&gt;</comment>
                            <comment id="13496573" author="mbertozzi" created="Tue, 13 Nov 2012 21:39:56 +0000"  >&lt;p&gt;Current offline snapshot status: &lt;br/&gt;
the code was up for review for a while now, and everything is at least +1&lt;br/&gt;
we&apos;re missing a couple of reviews to merge it in the snapshot branch.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Jira &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Description &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Status &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Review Link &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5547&quot; title=&quot;Don&amp;#39;t delete HFiles when in &amp;quot;backup mode&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5547&quot;&gt;&lt;del&gt;HBASE-5547&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; HFile Archiver &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; trunk &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6610&quot; title=&quot;HFileLink: Hardlink alternative for snapshot restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6610&quot;&gt;&lt;del&gt;HBASE-6610&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; HFileLink hardlink alternative &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; trunk &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6571&quot; title=&quot;Generic multi-thread/cross-process error handling framework&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6571&quot;&gt;&lt;del&gt;HBASE-6571&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Error handling framework &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; snapshot branch &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/6589/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6765&quot; title=&quot;&amp;#39;Take a snapshot&amp;#39; interface&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6765&quot;&gt;&lt;del&gt;HBASE-6765&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Take a Snapshot Interface &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; snapshot branch &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7072/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6230&quot; title=&quot;[brainstorm] &amp;quot;Restore&amp;quot; snapshots for HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6230&quot;&gt;&lt;del&gt;HBASE-6230&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Snapshot Reference Utils &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; snapshot branch &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7788/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6353&quot; title=&quot;Snapshots shell&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6353&quot;&gt;&lt;del&gt;HBASE-6353&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Snapshot Shell &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; snapshot-branch &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7583/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6863&quot; title=&quot;Offline snapshots&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6863&quot;&gt;&lt;del&gt;HBASE-6863&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Offline Snapshot &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; review +2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7608/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6865&quot; title=&quot;Snapshot File Cleaners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6865&quot;&gt;&lt;del&gt;HBASE-6865&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Snapshot cleaner &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; review +2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7627&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6777&quot; title=&quot;Snapshot Restore interface&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6777&quot;&gt;&lt;del&gt;HBASE-6777&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Restore Interface &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; review +1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7096&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6230&quot; title=&quot;[brainstorm] &amp;quot;Restore&amp;quot; snapshots for HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6230&quot;&gt;&lt;del&gt;HBASE-6230&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Restore Snapshot &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; review +1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/5963/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6802&quot; title=&quot;Export Snapshot&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6802&quot;&gt;&lt;del&gt;HBASE-6802&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Export Snapshot &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; review +1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://reviews.apache.org/r/7137/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;The &lt;b&gt;reference snapshot branch&lt;/b&gt; is: &lt;a href=&quot;https://github.com/jyates/hbase/tree/snapshots&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jyates/hbase/tree/snapshots&lt;/a&gt;&lt;br/&gt;
The &quot;complete&quot; dev branch with all commit above is: &lt;a href=&quot;https://github.com/matteobertozzi/hbase/commits/offline-snapshot-review-v3&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/matteobertozzi/hbase/commits/offline-snapshot-review-v3&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13496582" author="jmhsieh" created="Tue, 13 Nov 2012 21:47:01 +0000"  >&lt;p&gt;I think we need to get all those committed to the branch, and then put up a doc about the features, what it provides, how it works, and why we chose particular semantics.  We also need to document its current caveats. &lt;/p&gt;

&lt;p&gt;We&apos;ll do some testing and probably need to do a little rebasing before we can consider a trunk merge.&lt;/p&gt;

&lt;p&gt;We&apos;ll put a flag up here when we are ready but as a heads up, we&apos;d like 1-2 more committers to review.  (Currently it is Me, Jesse, and Ted in some places).&lt;/p&gt;</comment>
                            <comment id="13496795" author="jesse_yates" created="Wed, 14 Nov 2012 03:09:00 +0000"  >&lt;p&gt;+1 on Jon&apos;s comments. I think most of this is almost there&lt;/p&gt;</comment>
                            <comment id="13500491" author="jmhsieh" created="Mon, 19 Nov 2012 18:44:49 +0000"  >&lt;p&gt;I&apos;ve reached a pretty decent point on this branch now refactoring and simplifying the online snapshot code.  Most of the work is in the plumbing, and most of the complexity remains in the plumbing.   Here is a link&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jmhsieh/hbase/commits/snapshot-dev?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jmhsieh/hbase/commits/snapshot-dev?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It isn&apos;t worth looking at the individual patches &amp;#8211; if interested take a look at the code generally one package at a time.  I&apos;d suggest starting from errorhandling, then procedures since this work is fairly isolated and stable now.  The will likely affect existing code, and online may change significantly during the merge process.&lt;/p&gt;

&lt;p&gt;Error handling:  o.a.h.h.errorhandling.*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Added concept of ExternalException (an exception from an separate thread or process).&lt;/li&gt;
	&lt;li&gt;Removing generics by funneling everything through an ExternalException&lt;/li&gt;
	&lt;li&gt;Simplified Exception Propagation by only having a Dispatcher, Listener, and Checker. (No Visitors, Orchestrators, some Factories)&lt;/li&gt;
	&lt;li&gt;Made Exception Serialization static so that instances don&apos;t need to be passed around.&lt;/li&gt;
	&lt;li&gt;Added more meaningful usage and motivation documentation.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Procedure framework: o.a.h.h.procedure.*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Separated Coordinator side from Member side&lt;/li&gt;
	&lt;li&gt;Reduced the number of constructors (and fewer objects threaded throughout).&lt;/li&gt;
	&lt;li&gt;Added concept of Procedure and Subprocedure &amp;#8211; these maintain state on each host. (this replaces just using strings everywhere).&lt;/li&gt;
	&lt;li&gt;Folded several threads that used latch ping-pong into single threads.&lt;/li&gt;
	&lt;li&gt;Renamed methods from 2pc nomenclature to barrier nomenclature.&lt;/li&gt;
	&lt;li&gt;Added more meaningful usage and motivation documentation.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Online Snapshots: o.a.h.h.snapshot.*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Converted per regionserver only Procedures to simpler Callable/Future fork join implementation.&lt;/li&gt;
	&lt;li&gt;Removed different *ErrorHandlers and moved into Subprocedures. (this may be further eliminated)&lt;/li&gt;
	&lt;li&gt;Each Procedure contains an ExternalExceptionDispatcher&lt;/li&gt;
	&lt;li&gt;ExternalExceptions go to the SnapshotManager to abort the Procedure.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m in process of merging code into the offline snapshot branch.  It isn&apos;t clean but I&apos;ll be working on that for the next few days. (Clashes with updates in offline snapshot).   Once I get the snapshot branch compiling again, I&apos;ll start posting the External Exception and Procedure stuff as a series of patches.&lt;/p&gt;

&lt;p&gt;My suggestion for the overall effort is to get the main offline snapshot branch code committed to the branch and then start looking into merging with trunk and 0.94.  The online work I feel should remain a branch until its pieces are fleshed out.&lt;/p&gt;</comment>
                            <comment id="13500532" author="jmhsieh" created="Mon, 19 Nov 2012 19:27:55 +0000"  >&lt;p&gt;Branch to a squashed version. &lt;br/&gt;
&lt;a href=&quot;https://github.com/jmhsieh/hbase/tree/snapshot-dev-squash&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jmhsieh/hbase/tree/snapshot-dev-squash&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13500557" author="jesse_yates" created="Mon, 19 Nov 2012 19:41:44 +0000"  >&lt;p&gt;I just +1&apos;ed Matteo&apos;s restore changes, so I hope to roll that into the snapshot branch (&lt;a href=&quot;https://github.com/jyates/hbase/tree/snapshots&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jyates/hbase/tree/snapshots&lt;/a&gt;) in the next day or two, which would mean we have everything for offline snapshots.&lt;/p&gt;

&lt;p&gt;The offline snapshots themselves are a self contained bit of code and sizable enough to make it worthwhile to roll it into trunk on its own. &lt;/p&gt;

&lt;p&gt;Let&apos;s keep the online keep on a branch until its wrapped up - I&apos;ll start taking a look at the online when I have a chance, and look forward to code posted on RB. The progress sounds real sweet Jon!&lt;/p&gt;


&lt;p&gt;TL;DR lets do what Jon suggests above, especially as offline snapshots are basically done and ready to merge into trunk&lt;/p&gt;</comment>
                            <comment id="13500578" author="jmhsieh" created="Mon, 19 Nov 2012 19:49:56 +0000"  >&lt;p&gt;Just force pushed the snapshot-dev-squash branch &amp;#8211; it didn&apos;t delete files that were supposed to be gone.&lt;/p&gt;</comment>
                            <comment id="13501387" author="jmhsieh" created="Tue, 20 Nov 2012 19:13:44 +0000"  >&lt;p&gt;Here&apos;s a repo with the online branch merged to the snapshot branch with snapshot unit tests passing now.  &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jmhsieh/hbase/tree/snapshots-online-merge&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jmhsieh/hbase/tree/snapshots-online-merge&lt;/a&gt;&lt;br/&gt;
hash  d1299347c0c1afcc0264b14ee12beee170efc4c2&lt;/p&gt;

&lt;p&gt;mvn clean&lt;br/&gt;
mvn test -Dtest=errorhandling/* -PlocalTests&lt;br/&gt;
mvn test -Dtest=Test*Procedure* -PlocalTests&lt;br/&gt;
mvn test -Dtest=Test*Snapshot*,snapshot/*,TestFSUtils -PlocalTests&lt;/p&gt;

&lt;p&gt;It needs some cleanup (cleanup duplicate/commented code from merge) but patches of pieces will be coming out later today / tommorrow.&lt;/p&gt;

&lt;p&gt;Likely pieces:  ( might break a few more of these down if they are excessive)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;External Exceptions + snapshot manager refactor&lt;/li&gt;
	&lt;li&gt;Barrier Procedure&lt;/li&gt;
	&lt;li&gt;online Timestamp snapshots tasks&lt;/li&gt;
	&lt;li&gt;online timestampe snapshots + snapshot manager&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13502554" author="jmhsieh" created="Thu, 22 Nov 2012 02:44:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jesse_yates&quot; class=&quot;user-hover&quot; rel=&quot;jesse_yates&quot;&gt;Jesse Yates&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; What do you guys about closing this issue when offline makes it into trunk and having a separate umbrella issue for online-snapshots and variants?  If we&apos;d do this we&apos;d move some of the remaining subtasks to the new issue.&lt;/p&gt;

&lt;p&gt;I&apos;m also considering closing some of the existing subtasks and creating new issues with the simplified versions &amp;#8211; while they have similar purposes the design and implementation details are somewhat different.  comments concerns?&lt;/p&gt;
</comment>
                            <comment id="13502563" author="yuzhihong@gmail.com" created="Thu, 22 Nov 2012 03:21:37 +0000"  >&lt;p&gt;In that case the title of this JIRA should signify offline snapshots, right ?&lt;/p&gt;</comment>
                            <comment id="13502896" author="jmhsieh" created="Thu, 22 Nov 2012 18:54:38 +0000"  >&lt;p&gt;If I get some +1&apos;s or no comments after Monday,  I&apos;ll update it.&lt;/p&gt;</comment>
                            <comment id="13502910" author="mbertozzi" created="Thu, 22 Nov 2012 19:19:03 +0000"  >&lt;p&gt;+1 on separate offline and online, but maybe we can keep a root jira to keep track of all the dependencies, and a general design doc&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 + Snapshot in HBase
 |-- HFile Archiver
 |-- Offline Snapshot
 |----- Offline Snapshot
 |----- Cleaner
 |----- Restore/Clone
 |----- Shell
 |----- ...
 |-- Online Snapshot
 |----- Procedure
 |----- Exception Framework
 |----- Timestamp Snapshot
 |----- ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13503315" author="jesse_yates" created="Sat, 24 Nov 2012 00:56:24 +0000"  >&lt;p&gt;I agree with Matteo wrt Jon&apos;s comments. I expect the &apos;online scaffolding&apos; will have to dramatically change too, though it depends on what Jon comes up with.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt; feel free to close out the old jiras for things that you are replacing (e.g. the Three-Phase Commit Framework), if you feel up to it.&lt;/p&gt;</comment>
                            <comment id="13508972" author="jesse_yates" created="Mon, 3 Dec 2012 19:40:28 +0000"  >&lt;p&gt;Attaching doc that covers a range of information on how offline snapshots and recovery work. It starts out talking a bit about the high-level of each feature, and then does a walk-through of offline snapshots, restore, clone and export.&lt;/p&gt;

&lt;p&gt;This doc describes out general FS layouts, ordering of events, process ownership, and pending concerns.&lt;/p&gt;</comment>
                            <comment id="13582902" author="jmhsieh" created="Thu, 21 Feb 2013 04:26:46 +0000"  >&lt;p&gt;Committed as part of the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7290&quot; title=&quot;Online snapshots &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7290&quot;&gt;&lt;del&gt;HBASE-7290&lt;/del&gt;&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt; snapshot branch merge.&lt;/p&gt;</comment>
                            <comment id="13582977" author="hudson" created="Thu, 21 Feb 2013 07:18:30 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3888 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3888/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3888/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7290&quot; title=&quot;Online snapshots &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7290&quot;&gt;&lt;del&gt;HBASE-7290&lt;/del&gt;&lt;/a&gt; / &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt; Online and Offline table snapshots.  Merged to trunk. (Jesse Yates, Matteo Bertozzi, Jonathan Hsieh, Ted Yu) (Revision 1448506)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
jmhsieh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ErrorHandlingProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/MasterAdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/ErrorHandling.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/MasterAdmin.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/hbase.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/avro&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/Chore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/MasterAdminProtocol.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/backup/HFileArchiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseMasterObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/MasterObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignExceptionDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignExceptionListener.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignExceptionSnare.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/TimeoutException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/TimeoutExceptionInjector.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HLogLink.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/SnapshotSentinel.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DeleteTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/TableEventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/CloneSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/EnabledTableSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/MasterSnapshotVerifier.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/RestoreSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotLogCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/TakeSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/Procedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinatorRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMemberRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/Subprocedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/SubprocedureFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureCoordinatorRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/FlushSnapshotSubprocedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/CopyRecoveredEditsTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/CorruptedSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/HBaseSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ReferenceRegionHFilesTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ReferenceServerWALsTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotCreationException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDoesNotExistException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotExistsException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TableInfoCopyTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TablePartiallyOpenException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TakeSnapshotUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/UnknownSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileArchiveUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ModifyRegionUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/snapshot.jsp&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/hbase/admin.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/hbase/table.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/clone_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/delete_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/list.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/list_snapshots.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/rename_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/restore_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/TestHFileArchiving.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRestoreSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotCloneIndependence.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotMetadata.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestMasterObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionSerialization.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestTimeoutExceptionInjector.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileLinkCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotLogCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/migration&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestProcedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestProcedureCoordinator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestProcedureMember.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestZKProcedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestZKProcedureControllers.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestCopyRecoveredEditsTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestExportSnapshot.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestReferenceRegionHFilesTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotDescriptionUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestWALReferenceTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSVisitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHFileArchiveUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13583168" author="hudson" created="Thu, 21 Feb 2013 13:16:01 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #414 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/414/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/414/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7290&quot; title=&quot;Online snapshots &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7290&quot;&gt;&lt;del&gt;HBASE-7290&lt;/del&gt;&lt;/a&gt; / &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt; Online and Offline table snapshots.  Merged to trunk. (Jesse Yates, Matteo Bertozzi, Jonathan Hsieh, Ted Yu) (Revision 1448506)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
jmhsieh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ErrorHandlingProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/MasterAdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/ErrorHandling.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/MasterAdmin.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/hbase.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/avro&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/Chore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/MasterAdminProtocol.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/backup/HFileArchiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseMasterObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/MasterObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignExceptionDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignExceptionListener.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/ForeignExceptionSnare.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/TimeoutException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/errorhandling/TimeoutExceptionInjector.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HLogLink.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/SnapshotSentinel.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DeleteTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/TableEventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/CloneSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/EnabledTableSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/MasterSnapshotVerifier.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/RestoreSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotLogCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/TakeSnapshotHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/Procedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinatorRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMemberRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/Subprocedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/SubprocedureFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureCoordinatorRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/FlushSnapshotSubprocedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/CopyRecoveredEditsTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/CorruptedSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/HBaseSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ReferenceRegionHFilesTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ReferenceServerWALsTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotCreationException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDoesNotExistException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotExistsException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TableInfoCopyTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TablePartiallyOpenException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TakeSnapshotUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/UnknownSnapshotException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileArchiveUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ModifyRegionUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/snapshot.jsp&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/hbase/admin.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/hbase/table.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/clone_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/delete_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/list.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/list_snapshots.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/rename_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/restore_snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/ruby/shell/commands/snapshot.rb&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/TestHFileArchiving.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRestoreSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotCloneIndependence.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotMetadata.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestMasterObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionSerialization.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestTimeoutExceptionInjector.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileLinkCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotLogCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/migration&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestProcedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestProcedureCoordinator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestProcedureMember.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestZKProcedure.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestZKProcedureControllers.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/metrics&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestCopyRecoveredEditsTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestExportSnapshot.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestReferenceRegionHFilesTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotDescriptionUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestWALReferenceTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSVisitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHFileArchiveUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13775238" author="stack" created="Mon, 23 Sep 2013 18:31:03 +0000"  >&lt;p&gt;Marking closed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12545774">HBASE-5547</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12528561">HBASE-4655</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12594958">HBASE-6230</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12597899">HBASE-6353</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12545774">HBASE-5547</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12538675">HDFS-2802</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12594981">HBASE-6233</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12385270">HBASE-50</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12607169">HBASE-6765</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12559616">HBASE-6180</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12623876">HBASE-7353</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12619005">HBASE-7290</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12555812" name="Offline Snapshots.docx" size="1000256" author="jesse_yates" created="Mon, 3 Dec 2012 19:40:28 +0000"/>
                            <attachment id="12528703" name="Snapshots in HBase.docx" size="464713" author="jesse_yates" created="Wed, 23 May 2012 06:02:36 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12603327">HBASE-6568</subtask>
                            <subtask id="12603328">HBASE-6569</subtask>
                            <subtask id="12603330">HBASE-6570</subtask>
                            <subtask id="12603331">HBASE-6571</subtask>
                            <subtask id="12603334">HBASE-6573</subtask>
                            <subtask id="12607169">HBASE-6765</subtask>
                            <subtask id="12607526">HBASE-6777</subtask>
                            <subtask id="12607965">HBASE-6802</subtask>
                            <subtask id="12608715">HBASE-6863</subtask>
                            <subtask id="12608717">HBASE-6865</subtask>
                            <subtask id="12597899">HBASE-6353</subtask>
                            <subtask id="12613391">HBASE-7047</subtask>
                            <subtask id="12615037">HBASE-7107</subtask>
                            <subtask id="12616348">HBASE-7174</subtask>
                            <subtask id="12617261">HBASE-7206</subtask>
                            <subtask id="12617266">HBASE-7207</subtask>
                            <subtask id="12617267">HBASE-7208</subtask>
                            <subtask id="12603981">HBASE-6610</subtask>
                            <subtask id="12594958">HBASE-6230</subtask>
                            <subtask id="12618232">HBASE-7240</subtask>
                            <subtask id="12618978">HBASE-7288</subtask>
                            <subtask id="12622833">HBASE-7294</subtask>
                            <subtask id="12623081">HBASE-7311</subtask>
                            <subtask id="12623615">HBASE-7339</subtask>
                            <subtask id="12623872">HBASE-7352</subtask>
                            <subtask id="12623950">HBASE-7354</subtask>
                            <subtask id="12624310">HBASE-7367</subtask>
                            <subtask id="12624587">HBASE-7388</subtask>
                            <subtask id="12624642">HBASE-7389</subtask>
                            <subtask id="12624759">HBASE-7400</subtask>
                            <subtask id="12625014">HBASE-7419</subtask>
                            <subtask id="12625019">HBASE-7420</subtask>
                            <subtask id="12625156">HBASE-7430</subtask>
                            <subtask id="12625214">HBASE-7436</subtask>
                            <subtask id="12625295">HBASE-7439</subtask>
                            <subtask id="12625435">HBASE-7452</subtask>
                            <subtask id="12625436">HBASE-7453</subtask>
                            <subtask id="12625464">HBASE-7454</subtask>
                            <subtask id="12625583">HBASE-7471</subtask>
                            <subtask id="12625742">HBASE-7480</subtask>
                            <subtask id="12625803">HBASE-7484</subtask>
                            <subtask id="12627040">HBASE-7535</subtask>
                            <subtask id="12627317">HBASE-7547</subtask>
                            <subtask id="12627879">HBASE-7583</subtask>
                            <subtask id="12628067">HBASE-7604</subtask>
                            <subtask id="12628248">HBASE-7622</subtask>
                            <subtask id="12628291">HBASE-7625</subtask>
                            <subtask id="12629467">HBASE-7689</subtask>
                            <subtask id="12631460">HBASE-7795</subtask>
                            <subtask id="12624210">HBASE-7365</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 22 May 2012 04:24:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>250485</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 12 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ayuf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>61918</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.96notable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>