<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:12:01 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-10254/HBASE-10254.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-10254] Optionally return null when attempting to Increment KeyValue that doesn&apos;t exist</title>
                <link>https://issues.apache.org/jira/browse/HBASE-10254</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Instead of creating a new KeyValue starting from 0 when an Increment is done on a row that doesn&apos;t exist, we should optionally return null. A Get is already being done, so it&apos;s easy to detect this case. This can be done in a backward compatible manner if the behavior is done optionally. In addition, Increment does not allow me to specify the timestamp to use for the KeyValue. This should be added as well.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686662">HBASE-10254</key>
            <summary>Optionally return null when attempting to Increment KeyValue that doesn&apos;t exist</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jamestaylor">James Taylor</reporter>
                        <labels>
                    </labels>
                <created>Sun, 29 Dec 2013 08:34:26 +0000</created>
                <updated>Mon, 30 Dec 2013 20:42:42 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13858386" author="stack" created="Sun, 29 Dec 2013 18:16:24 +0000"  >&lt;p&gt;Sounds good.  Should not be an optional return.  Rather define null return as the result when the increment row does not exist.&lt;/p&gt;</comment>
                            <comment id="13858405" author="jamestaylor" created="Sun, 29 Dec 2013 19:30:33 +0000"  >&lt;p&gt;Fine by me, but might be a b/w compat issue then. Not sure if folks are counting on the existing behavior.&lt;/p&gt;</comment>
                            <comment id="13858571" author="anoop.hbase" created="Mon, 30 Dec 2013 05:37:07 +0000"  >&lt;p&gt;So when the cell does not exist, u dont want to create a new one with 0 value right?  Yes this will be a BC issue if changing the current way. We can do it in optional way.&lt;/p&gt;</comment>
                            <comment id="13858662" author="jamestaylor" created="Mon, 30 Dec 2013 08:45:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; - yes, that&apos;s right, don&apos;t create a new one if the cell doesn&apos;t already exist. In addition, I need to be able to control the timestamp of the cell which the API doesn&apos;t let me do either - I&apos;ll add that to the description.&lt;/p&gt;</comment>
                            <comment id="13858689" author="anoop.hbase" created="Mon, 30 Dec 2013 10:06:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;I need to be able to control the timestamp of the cell which the API doesn&apos;t let me do either &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can&apos;t Increment#add(Cell cell) help here?&lt;/p&gt;</comment>
                            <comment id="13858967" author="jamestaylor" created="Mon, 30 Dec 2013 18:14:00 +0000"  >&lt;p&gt;I don&apos;t see this (or its KeyValue equivalent) in 0.94. Also, I&apos;m using the Phoenix serialized form for the increment amount, so if HBase uses Bytes.toLong(byte[]) to get the increment, it won&apos;t work. I could manufacture another Cell, but what I&apos;d rather have is an API like this:&lt;/p&gt;

&lt;p&gt;public Increment addColumn(byte[] family, byte[] qualifier, long amount, long timestamp)&lt;/p&gt;</comment>
                            <comment id="13859046" author="jamestaylor" created="Mon, 30 Dec 2013 20:08:27 +0000"  >&lt;p&gt;As an experiment, I copy/pasted the HRegion.increment() code, adding a incrementTimestamp argument and returning null if the KeyValue doesn&apos;t exist (see below). Here&apos;s what I learned:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;you can&apos;t get at the HRegion.updatesLock, so this is likely problematic&lt;/li&gt;
	&lt;li&gt;you can&apos;t do a HRegion.requestFlush()&lt;/li&gt;
	&lt;li&gt;too much of the guts of the implementation leaks out to coprocessors IMO&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m thinking to just have my own coprocessor that locks the row and does a Get followed by a Put through the HRegion methods. It&apos;ll be a lot less code.&lt;/p&gt;

&lt;p&gt;package com.salesforce.phoenix.coprocessor;&lt;/p&gt;

&lt;p&gt;import java.io.IOException;&lt;br/&gt;
import java.io.InterruptedIOException;&lt;br/&gt;
import java.util.Collections;&lt;br/&gt;
import java.util.concurrent.TimeUnit;&lt;br/&gt;
import java.util.concurrent.locks.Lock;&lt;br/&gt;
import java.util.concurrent.locks.ReentrantReadWriteLock;&lt;/p&gt;

&lt;p&gt;import org.apache.hadoop.conf.Configuration;&lt;br/&gt;
import org.apache.hadoop.hbase.CoprocessorEnvironment;&lt;br/&gt;
import org.apache.hadoop.hbase.DoNotRetryIOException;&lt;br/&gt;
import org.apache.hadoop.hbase.HConstants;&lt;br/&gt;
import org.apache.hadoop.hbase.HTableDescriptor;&lt;br/&gt;
import org.apache.hadoop.hbase.KeyValue;&lt;br/&gt;
import org.apache.hadoop.hbase.RegionTooBusyException;&lt;br/&gt;
import org.apache.hadoop.hbase.client.Get;&lt;br/&gt;
import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
import org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor;&lt;br/&gt;
import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;&lt;br/&gt;
import org.apache.hadoop.hbase.io.TimeRange;&lt;br/&gt;
import org.apache.hadoop.hbase.regionserver.HRegion;&lt;br/&gt;
import org.apache.hadoop.hbase.regionserver.Store;&lt;br/&gt;
import org.apache.hadoop.hbase.regionserver.WrongRegionException;&lt;br/&gt;
import org.apache.hadoop.hbase.regionserver.wal.WALEdit;&lt;br/&gt;
import org.apache.hadoop.hbase.util.Bytes;&lt;br/&gt;
import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;&lt;br/&gt;
import org.slf4j.Logger;&lt;br/&gt;
import org.slf4j.LoggerFactory;&lt;/p&gt;

&lt;p&gt;public class SequenceEndpointImpl extends BaseEndpointCoprocessor {&lt;br/&gt;
    private static final Logger LOG = LoggerFactory.getLogger(GroupedAggregateRegionObserver.class);&lt;br/&gt;
    private static final long DEFAULT_BUSY_WAIT_DURATION = HConstants.DEFAULT_HBASE_RPC_TIMEOUT;&lt;/p&gt;

&lt;p&gt;    // If updating multiple rows in one call, wait longer,&lt;br/&gt;
    // i.e. waiting for busyWaitDuration * # of rows. However,&lt;br/&gt;
    // we can limit the max multiplier.&lt;br/&gt;
    private int maxBusyWaitMultiplier;&lt;/p&gt;

&lt;p&gt;    // Max busy wait duration. There is no point to wait longer than the RPC&lt;br/&gt;
    // purge timeout, when a RPC call will be terminated by the RPC engine.&lt;br/&gt;
    private long maxBusyWaitDuration;&lt;br/&gt;
    // The internal wait duration to acquire a lock before read/update&lt;br/&gt;
    // from the region. It is not per row. The purpose of this wait time&lt;br/&gt;
    // is to avoid waiting a long time while the region is busy, so that&lt;br/&gt;
    // we can release the IPC handler soon enough to improve the&lt;br/&gt;
    // availability of the region server. It can be adjusted by&lt;br/&gt;
    // tuning configuration &quot;hbase.busy.wait.duration&quot;.&lt;br/&gt;
    private long busyWaitDuration;&lt;br/&gt;
    private long memstoreFlushSize;&lt;br/&gt;
    private boolean deferredLogSyncDisabled;&lt;/p&gt;

&lt;p&gt;    // Stop updates lock&lt;br/&gt;
    private final ReentrantReadWriteLock updatesLock = new ReentrantReadWriteLock();&lt;/p&gt;

&lt;p&gt;    @Override&lt;br/&gt;
    public void start(CoprocessorEnvironment e) {&lt;br/&gt;
        Configuration conf = e.getConfiguration();&lt;br/&gt;
        this.busyWaitDuration = conf.getLong(&quot;hbase.busy.wait.duration&quot;, DEFAULT_BUSY_WAIT_DURATION);&lt;br/&gt;
        this.maxBusyWaitMultiplier = conf.getInt(&quot;hbase.busy.wait.multiplier.max&quot;, 2);&lt;br/&gt;
        if (busyWaitDuration * maxBusyWaitMultiplier &amp;lt;= 0L) &lt;/p&gt;
{ throw new IllegalArgumentException(
                &quot;Invalid hbase.busy.wait.duration (&quot; + busyWaitDuration + &quot;) or hbase.busy.wait.multiplier.max (&quot;
                        + maxBusyWaitMultiplier + &quot;). Their product should be positive&quot;); }
&lt;p&gt;        this.maxBusyWaitDuration = conf.getLong(&quot;ipc.client.call.purge.timeout&quot;,&lt;br/&gt;
                2 * HConstants.DEFAULT_HBASE_RPC_TIMEOUT);&lt;br/&gt;
        RegionCoprocessorEnvironment env = (RegionCoprocessorEnvironment)e;&lt;br/&gt;
        HRegion region = env.getRegion();&lt;br/&gt;
        long flushSize = region.getTableDesc().getMemStoreFlushSize();&lt;/p&gt;

&lt;p&gt;        if (flushSize &amp;lt;= 0) &lt;/p&gt;
{
            flushSize = conf.getLong(HConstants.HREGION_MEMSTORE_FLUSH_SIZE,
                    HTableDescriptor.DEFAULT_MEMSTORE_FLUSH_SIZE);
        }
&lt;p&gt;        this.memstoreFlushSize = flushSize;&lt;br/&gt;
        // When hbase.regionserver.optionallogflushinterval &amp;lt;= 0 , deferred log sync is disabled.&lt;br/&gt;
        this.deferredLogSyncDisabled = conf.getLong(&quot;hbase.regionserver.optionallogflushinterval&quot;, 1 * 1000) &amp;lt;= 0;&lt;/p&gt;

&lt;p&gt;    }&lt;/p&gt;

&lt;p&gt;    public static boolean rowIsInRange(HRegion info, final byte[] row) &lt;/p&gt;
{
        return ((info.getStartKey().length == 0) || (Bytes.compareTo(info.getStartKey(), row) &amp;lt;= 0))
                &amp;amp;&amp;amp; ((info.getEndKey().length == 0) || (Bytes.compareTo(info.getEndKey(), row) &amp;gt; 0));
    }

&lt;p&gt;    /** Make sure this is a valid row for the HRegion */&lt;br/&gt;
    void checkRow(final byte[] row, String op, HRegion region) throws IOException {&lt;br/&gt;
        if (!rowIsInRange(region, row)) &lt;/p&gt;
{ throw new WrongRegionException(&quot;Requested row out of range for &quot; + op
                + &quot; on HRegion &quot; + this + &quot;, startKey=&apos;&quot; + Bytes.toStringBinary(region.getStartKey())
                + &quot;&apos;, getEndKey()=&apos;&quot; + Bytes.toStringBinary(region.getEndKey()) + &quot;&apos;, row=&apos;&quot;
                + Bytes.toStringBinary(row) + &quot;&apos;&quot;); }
&lt;p&gt;    }&lt;/p&gt;

&lt;p&gt;    private void lock(final Lock lock) throws RegionTooBusyException, InterruptedIOException &lt;/p&gt;
{
        lock(lock, 1);
    }

&lt;p&gt;    /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Try to acquire a lock. Throw RegionTooBusyException if failed to get the lock in time. Throw&lt;/li&gt;
	&lt;li&gt;InterruptedIOException if interrupted while waiting for the lock.&lt;br/&gt;
     */&lt;br/&gt;
    private void lock(final Lock lock, final int multiplier) throws RegionTooBusyException, InterruptedIOException {&lt;br/&gt;
        try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {            final long waitTime = Math.min(maxBusyWaitDuration,                    busyWaitDuration * Math.min(multiplier, maxBusyWaitMultiplier));            if (!lock.tryLock(waitTime, TimeUnit.MILLISECONDS)) { throw new RegionTooBusyException(
                    &quot;failed to get a lock in &quot; + waitTime + &quot;ms&quot;); }        }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; catch (InterruptedException ie) &lt;/p&gt;
{
            LOG.info(&quot;Interrupted while waiting for a lock&quot;);
            InterruptedIOException iie = new InterruptedIOException();
            iie.initCause(ie);
            throw iie;
        }
&lt;p&gt;    }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    @Override&lt;br/&gt;
    public RegionCoprocessorEnvironment getEnvironment() &lt;/p&gt;
{
        return (RegionCoprocessorEnvironment)super.getEnvironment();
    }

&lt;p&gt;    /*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@param size&lt;/li&gt;
	&lt;li&gt;@return True if size is over the flush threshold&lt;br/&gt;
     */&lt;br/&gt;
    private boolean isFlushSize(final long size) 
{
        return size &amp;gt; memstoreFlushSize;
    }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;check if current region is deferred sync enabled.&lt;br/&gt;
     */&lt;br/&gt;
    private boolean isDeferredLogSyncEnabled(HRegion region) 
{
        return (region.getTableDesc().isDeferredLogFlush() &amp;amp;&amp;amp; !this.deferredLogSyncDisabled);
    }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    public Long incrementColumnValue(byte[] row, byte[] family, byte[] qualifier, long amount, TimeRange tr,&lt;br/&gt;
            long incrementTimestamp, boolean writeToWAL) throws IOException {&lt;br/&gt;
        RegionCoprocessorEnvironment env = this.getEnvironment();&lt;br/&gt;
        HRegion region = env.getRegion();&lt;br/&gt;
        HTableDescriptor htableDescriptor = region.getTableDesc();&lt;br/&gt;
        checkRow(row, &quot;increment&quot;, region);&lt;br/&gt;
        boolean flush = false;&lt;br/&gt;
        long txid = 0;&lt;br/&gt;
        // Lock row&lt;br/&gt;
        region.startRegionOperation();&lt;br/&gt;
        try {&lt;br/&gt;
            Integer lid = region.getLock(null, row, true);&lt;br/&gt;
            lock(this.updatesLock.readLock());&lt;br/&gt;
            try {&lt;br/&gt;
                Store store = region.getStore(family);&lt;/p&gt;

&lt;p&gt;                // Get the old value:&lt;br/&gt;
                Get get = new Get(row);&lt;br/&gt;
                get.setTimeRange(tr.getMin(), tr.getMax());&lt;br/&gt;
                get.addColumn(family, qualifier);&lt;/p&gt;

&lt;p&gt;                Result result = region.get(get);&lt;br/&gt;
                if (result.isEmpty()) &lt;/p&gt;
{ return null; }

&lt;p&gt;                KeyValue kv = result.raw()&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
                if (kv.getValueLength() == Bytes.SIZEOF_LONG) &lt;/p&gt;
{
                    byte[] buffer = kv.getBuffer();
                    int valueOffset = kv.getValueOffset();
                    amount += Bytes.toLong(buffer, valueOffset, Bytes.SIZEOF_LONG);
                }
&lt;p&gt; else &lt;/p&gt;
{
                    throw new DoNotRetryIOException(&quot;Attempted to increment field that isn&apos;t 64 bits wide&quot;);
                }
&lt;p&gt;                // build the KeyValue now:&lt;br/&gt;
                KeyValue newKv = new KeyValue(row, family, qualifier, incrementTimestamp, Bytes.toBytes(amount));&lt;/p&gt;

&lt;p&gt;                // now log it:&lt;br/&gt;
                if (writeToWAL) &lt;/p&gt;
{
                    long now = EnvironmentEdgeManager.currentTimeMillis();
                    WALEdit walEdit = new WALEdit();
                    walEdit.add(newKv);
                    // Using default cluster id, as this can only happen in the
                    // orginating cluster. A slave cluster receives the final value (not
                    // the delta) as a Put.
                    txid = region.getLog().appendNoSync(region.getRegionInfo(), htableDescriptor.getName(), walEdit,
                            HConstants.DEFAULT_CLUSTER_ID, now, htableDescriptor);
                }

&lt;p&gt;                long size = store.upsert(Collections.singletonList(newKv));&lt;br/&gt;
                size = region.addAndGetGlobalMemstoreSize(size);&lt;br/&gt;
                flush = isFlushSize(size);&lt;br/&gt;
            } finally &lt;/p&gt;
{
                this.updatesLock.readLock().unlock();
                region.releaseRowLock(lid);
            }
&lt;p&gt;            if (writeToWAL) {&lt;br/&gt;
                // sync the transaction log outside the rowlock&lt;br/&gt;
                if (!isDeferredLogSyncEnabled(region)) &lt;/p&gt;
{
                    region.getLog().sync(txid);
                }
&lt;p&gt;            }&lt;br/&gt;
        } finally &lt;/p&gt;
{
            region.closeRegionOperation();
        }

&lt;p&gt;        if (flush) &lt;/p&gt;
{
            // Request a cache flush. Do it outside update lock.
            // This method isn&apos;t exposed on HRegion, so we can&apos;t do this
            // requestFlush();
        }
&lt;p&gt;        return amount;&lt;br/&gt;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;</comment>
                            <comment id="13859064" author="jamestaylor" created="Mon, 30 Dec 2013 20:42:42 +0000"  >&lt;p&gt;Here&apos;s the simplified version of Increment. How will this perform relative to HRegion.increment() ? If all increments are done through my new coprocessor, are there edge cases that aren&apos;t covered&lt;/p&gt;

&lt;p&gt;package com.salesforce.phoenix.coprocessor;&lt;/p&gt;

&lt;p&gt;import java.io.IOException;&lt;/p&gt;

&lt;p&gt;import org.apache.hadoop.hbase.KeyValue;&lt;br/&gt;
import org.apache.hadoop.hbase.client.Get;&lt;br/&gt;
import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
import org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor;&lt;br/&gt;
import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;&lt;br/&gt;
import org.apache.hadoop.hbase.io.TimeRange;&lt;br/&gt;
import org.apache.hadoop.hbase.regionserver.HRegion;&lt;/p&gt;

&lt;p&gt;import com.salesforce.phoenix.schema.PDataType;&lt;br/&gt;
import com.salesforce.phoenix.util.KeyValueUtil;&lt;/p&gt;

&lt;p&gt;public class SequenceEndpointImpl extends BaseEndpointCoprocessor {&lt;/p&gt;

&lt;p&gt;    @Override&lt;br/&gt;
    public RegionCoprocessorEnvironment getEnvironment() &lt;/p&gt;
{
        return (RegionCoprocessorEnvironment)super.getEnvironment();
    }

&lt;p&gt;    public Long incrementColumnValue(byte[] row, byte[] family, byte[] qualifier, &lt;br/&gt;
            long amount, TimeRange tr, long incrementTimestamp, boolean writeToWAL) throws IOException {&lt;br/&gt;
        RegionCoprocessorEnvironment env = this.getEnvironment();&lt;br/&gt;
        HRegion region = env.getRegion();&lt;/p&gt;

&lt;p&gt;        region.startRegionOperation();&lt;br/&gt;
        try {&lt;br/&gt;
            Integer lid = region.getLock(null, row, true);&lt;br/&gt;
            try {&lt;br/&gt;
                Get get = new Get(row);&lt;br/&gt;
                get.setTimeRange(tr.getMin(), tr.getMax());&lt;br/&gt;
                get.addColumn(family, qualifier);&lt;br/&gt;
                Result result = region.get(get);&lt;br/&gt;
                if (result.isEmpty()) &lt;/p&gt;
{
                    return null;
                }
&lt;p&gt;                KeyValue existingKV = result.raw()&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
                long value = PDataType.LONG.getCodec().decodeLong(existingKV.getBuffer(), existingKV.getValueOffset(), null);&lt;br/&gt;
                value += amount;&lt;br/&gt;
                byte[] valueBuffer = new byte&lt;span class=&quot;error&quot;&gt;&amp;#91;PDataType.LONG.getByteSize()&amp;#93;&lt;/span&gt;;&lt;br/&gt;
                PDataType.LONG.getCodec().encodeLong(value, valueBuffer, 0);&lt;br/&gt;
                Put put = new Put(row);&lt;br/&gt;
                KeyValue newKV = KeyValueUtil.newKeyValue(row, family, qualifier, incrementTimestamp, valueBuffer);&lt;br/&gt;
                put.add(newKV);&lt;br/&gt;
                region.put(put, writeToWAL);&lt;br/&gt;
                return value;&lt;br/&gt;
            } finally &lt;/p&gt;
{
                region.releaseRowLock(lid);
            }
&lt;p&gt;        } finally &lt;/p&gt;
{
            region.closeRegionOperation();
        }
&lt;p&gt;    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 29 Dec 2013 18:16:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365655</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 50 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1r12v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365962</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Phoenix</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>