<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:09:39 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3373/HBASE-3373.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3373] Allow regions to be load-balanced by table</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3373</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;From our experience, cluster can be well balanced and yet, one table&apos;s regions may be badly concentrated on few region servers.&lt;br/&gt;
For example, one table has 839 regions (380 regions at time of table creation) out of which 202 are on one server.&lt;/p&gt;

&lt;p&gt;It would be desirable for load balancer to distribute regions for specified tables evenly across the cluster. Each of such tables has number of regions many times the cluster size.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12493577">HBASE-3373</key>
            <summary>Allow regions to be load-balanced by table</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zhihyu@ebaysf.com">Ted Yu</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Sat, 18 Dec 2010 08:29:38 +0000</created>
                <updated>Tue, 4 Dec 2012 19:11:15 +0000</updated>
                            <resolved>Wed, 18 Jan 2012 18:10:48 +0000</resolved>
                                    <version>0.20.6</version>
                                    <fixVersion>0.94.0</fixVersion>
                                    <component>master</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>19</watches>
                                                                <comments>
                            <comment id="12972870" author="streamy" created="Sat, 18 Dec 2010 21:21:00 +0000"  >&lt;p&gt;On cluster startup in 0.90, regions are assigned in one of two ways.  By default, it will attempt to retain the previous assignment of the cluster.  The other option which I&apos;ve also used is round-robin.  This will evenly distribute each table.&lt;/p&gt;

&lt;p&gt;That plus the change to do round-robin on table create should probably cover per-table distribution fairly well.&lt;/p&gt;

&lt;p&gt;I think the next step in the load balancer is a major effort to switch to something with more of a cost-based approach.  I think ideally you don&apos;t need even distribution of each table, you want even distribution of load.  If one hot table, it will get evenly balanced anyways.&lt;/p&gt;

&lt;p&gt;One thing we could do is get rid of all random assignments and always try to do some kind of quick load balance or round-robin.  It does seem like randomness always leads to one guy who gets an unfair share &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12972908" author="yuzhihong@gmail.com" created="Sun, 19 Dec 2010 04:00:00 +0000"  >&lt;p&gt;If a table is heavily written to, its regions split over relatively long period of time.&lt;br/&gt;
The new daughter regions may not have good distribution.&lt;/p&gt;

&lt;p&gt;E.g. after a region server comes back online from crash, it takes time for balancer to assign regions from other servers. The new regions from above tend to get assigned to this region server.&lt;/p&gt;
</comment>
                            <comment id="12973437" author="yuzhihong@gmail.com" created="Tue, 21 Dec 2010 00:59:30 +0000"  >&lt;p&gt;List of regions for the table can be given to AssignmentManager so that the regions can be evenly distributed.&lt;br/&gt;
We need to consider the regions in the table that are actively splitting. These regions and their daughters would lead to imbalance after the above round-robin assignment.&lt;/p&gt;</comment>
                            <comment id="12975845" author="yuzhihong@gmail.com" created="Wed, 29 Dec 2010 17:52:04 +0000"  >&lt;p&gt;For environment where a lot of tables are created, client can specify a list of tables to hbase whose regions would be load balanced. Time-to-live is specified along with table names after which load balancer gets to balance all tables.&lt;/p&gt;</comment>
                            <comment id="12976431" author="yuzhihong@gmail.com" created="Sat, 1 Jan 2011 19:11:52 +0000"  >&lt;p&gt;Currently, regions offloaded from the most overloaded server would be assigned to most underloaded server first. When some regions are actively splitting on the most overloaded server, this arrangement is sub-optimal.&lt;br/&gt;
A better way is to round-robin assign regionsToMove over underloaded servers.&lt;/p&gt;</comment>
                            <comment id="12984877" author="stack" created="Fri, 21 Jan 2011 19:12:16 +0000"  >&lt;p&gt;Moving &apos;feature&apos; out of bug-fix only release.&lt;/p&gt;</comment>
                            <comment id="12988214" author="mcorgan" created="Fri, 28 Jan 2011 20:19:45 +0000"  >&lt;p&gt;Have you guys considered using a consistent hashing method to choose which server a region belongs to?  You would create ~50 buckets for each server by hashing serverName_port_bucketNum, and then hash the start key of each region into the buckets.&lt;/p&gt;

&lt;p&gt;There are a few benefits:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;when you add a server it takes an equal load from all existing servers&lt;/li&gt;
	&lt;li&gt;if you remove a server it distributes its regions equally to the remaining servers&lt;/li&gt;
	&lt;li&gt;adding a server does not cause all regions to shuffle like round robin assignment would&lt;/li&gt;
	&lt;li&gt;assignment is nearly random, but repeatable, so no hot spots&lt;/li&gt;
	&lt;li&gt;when a region splits the front half will stay on the same server, but the back half will usually be sent to another server&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And a few drawbacks:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;each server wouldn&apos;t end up with exactly the same number of regions, but they would be close&lt;/li&gt;
	&lt;li&gt;if a hot spot does end up developing, you can&apos;t do anything about it, at least not unless it supported a list of manual overrides&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12988221" author="streamy" created="Fri, 28 Jan 2011 20:43:14 +0000"  >&lt;p&gt;I think consistent hashing would be a major step backwards for us and unnecessary because there is no cost of moving bits around in HBase.  The primary benefit of consistent hashing is that it reduces the amount of data you have to physically move around.  Because of our use of HDFS, we never have to move physical data around.&lt;/p&gt;

&lt;p&gt;In your benefit list, we are already implementing almost all of these features, or if not, it is possible in the current architecture.  In addition, our architecture is extremely flexible and we can do all kinds of interesting load balancing techniques related to actual load profiles not just #s of shards/buckets as we do today or as would be done with consistent hashing.&lt;/p&gt;</comment>
                            <comment id="12988229" author="mcorgan" created="Fri, 28 Jan 2011 21:01:21 +0000"  >&lt;p&gt;Gotcha.  I guess I was thinking of it more as a quick upgrade to the current load balancer which only looks at region count.  We store a lot of time series data, and regions that split were left on the same server while it moved cold regions off.  I wrote a little client side consistent hashing balancer that solved the problem in our case, but there are definitely better ways.  Consistent hashing also binds regions to severs across cluster restarts which helps keep regions near their last major compacted hdfs file.&lt;/p&gt;

&lt;p&gt;Whatever balancing scheme you do use, don&apos;t you need some starting point for randomly distributing the regions?  If no other data is available or you need a tie breaker, maybe consistent hashing is better than round robin or purely random placement.&lt;/p&gt;</comment>
                            <comment id="12988249" author="yuzhihong@gmail.com" created="Fri, 28 Jan 2011 21:41:28 +0000"  >&lt;p&gt;This is what I added in HMaster:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  /**
   * Evenly distributes the regions of the tables (assuming the number of regions is much bigger
   *  than the number of region servers)
   * @param tableNames tables to load balance
   * @param ttl Time-to-live &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; load balance request. If negative, request is withdrawn
   * @&lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException e
   */
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void loadBalanceTable(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [][] tableNames, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; ttl) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Our production environment has 150 to 300 tables. We run flow sequentially. Each flow creates about 10 new tables.&lt;br/&gt;
The above API would allow load balancer to distribute hot (recently split) regions off certain region server(s).&lt;/p&gt;</comment>
                            <comment id="12988269" author="streamy" created="Fri, 28 Jan 2011 22:04:54 +0000"  >&lt;p&gt;Both of your solutions are rather specialized and I&apos;m not sure generally applicable.  I would much prefer spending effort on improving our current load balancer and it seems to me that it would be possible to implement similar behaviors in a more generalized way.&lt;/p&gt;

&lt;p&gt;Also, the addition of an HBaseAdmin region move API makes it so you don&apos;t need to muck with HBase server code to do specialized balancing logic.  With the current APIs, it&apos;s possible to basically push the balancer out into your own client.&lt;/p&gt;

&lt;p&gt;@Matt, I don&apos;t think I&apos;m really understanding how you upgrade our load balancer w/ consistent hashing?&lt;/p&gt;

&lt;p&gt;The fact that split regions open back up on the same server is actually an optimization in many cases because it reduces the amount of time the regions are offline and when they come back online and do a compaction to drop references, all the files are more likely to be on the local DataNode rather than remote.  In some cases, like time-series, you may want the splits to move to different servers.  I could imagine some configurable logic in there to ensure the bottom half goes to a different server (or maybe the top half would actually be more efficient to move away since most the time you&apos;ll write more to the bottom half and thus want the data locality / quick turnaround).  There&apos;s likely going to be a bit of split rework in 0.92 to make it more like the ZK-based regions-in-transition.&lt;/p&gt;

&lt;p&gt;As far as binding regions to servers between cluster restarts, this is already implemented and on by default in 0.90.&lt;/p&gt;

&lt;p&gt;Consistent hashing also requires a fixed keyspace (right?) and that&apos;s a mismatch for HBase&apos;s flexibility in this regard.&lt;/p&gt;

&lt;p&gt;Do you have any code for this client-side consistent hashing balancer?  I&apos;m confused about how that could be implemented without knowing a lot about your data, the regions, the servers available, etc.&lt;/p&gt;</comment>
                            <comment id="12988290" author="yuzhihong@gmail.com" created="Fri, 28 Jan 2011 22:35:20 +0000"  >&lt;p&gt;Hive, for instance, may create new (intermediate) tables for its map/reduce jobs.&lt;br/&gt;
The add-on I propose would be beneficial for that scenario.&lt;/p&gt;

&lt;p&gt;Also, in LoadBalancer.balanceCluster(), line 210:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt;(numTaken &amp;lt; numToTake &amp;amp;&amp;amp; regionidx &amp;lt; regionsToMove.size()) {
        regionsToMove.get(regionidx).setDestination(server.getKey());
        numTaken++;
        regionidx++;
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above code would offload regions from most loaded server to most underloaded server.&lt;br/&gt;
It is more desirable to round-robin the regions from loaded server(s) to underloaded server(s) so that the new daughter regions don&apos;t stay on the same server.&lt;/p&gt;</comment>
                            <comment id="12988294" author="streamy" created="Fri, 28 Jan 2011 22:43:38 +0000"  >&lt;p&gt;Round-robin assignment at table creation is fine.  Bypassing the load balancer and doing your own thing is fine.  Adding intelligence into the balancer to get good balance of load is great.&lt;/p&gt;

&lt;p&gt;I&apos;m -1 on adding these kinds of specialized hooks into HBase proper.  They should either be an external component (seems that they can be) or we should make the balancer pluggable and you could provide alternative/configurable balancer implementations.&lt;/p&gt;

&lt;p&gt;Assigning overloaded regions in a round-robin way to underloaded does make sense.  Would be happy to take a contribution to do that.  I&apos;m not sure there&apos;s a very strong correlation with that and splitting up of daughter regions.  It certainly could be the case, but selection of which regions to move off an overloaded server is rather dumb so no guarantees that recently split regions get reassigned.&lt;/p&gt;</comment>
                            <comment id="12988329" author="mcorgan" created="Sat, 29 Jan 2011 00:36:37 +0000"  >&lt;p&gt;I can&apos;t really post my client code since it&apos;s intertwined with a bunch of other stuff, but I extracted the important parts into a junit test that i attached to this issue.  We run java (tomcat) so it&apos;s fairly easy to talk directly to hbase and integrate a few features into our admin console.  Printing friendly record names rather than escaped bytes, triggering backups, moving regions, etc...  Don&apos;t think it requires knowing the keyspace ahead of time, just that you hash into a known output range, a 63 bit long in my example.&lt;/p&gt;

&lt;p&gt;I think the consistent hashing scheme may be a good out-of-the-box methodology.  Even with something smarter, I&apos;d worry about the underlying algorithms getting off course and starting a death spiral as bad outputs are fed back in creating even worse outputs.  Something like consistent hashing could be a good beacon to always be steering towards so things don&apos;t get too far off course.&lt;/p&gt;

&lt;p&gt;I have about 20 tables with many different access patterns and I can&apos;t envision an algorithm that balances them truly well.  Everything could be going fine until I kick off a MR job that randomly digs up 100 very cold regions and find that they&apos;re all on the same server.&lt;/p&gt;

&lt;p&gt;I&apos;m thinking of a system where each region is either at home  (its consistent hash destination) or visiting another server because the balancer decided its home was too hot.  Each regionserver could identify it&apos;s hotter regions, and the balancer could move these around in an effort to smooth out the load.  In the mean time, colder regions would stay well distributed based on how good the hashing mechanism is.  If a regionserver cools down, the master brings home it&apos;s vacationing regions first, and if it&apos;s still cool, then it borrows someone else&apos;s hotter home regions.  Without an underlying scheme, I can envision things getting extremely chaotic, especially with regards to cold regions of a single table getting bundled up since they&apos;re being overlooked.  With this method, you&apos;re never too far from safely hitting the reset button.&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;Regarding your comment about moving the top or bottom child off the parent server after a split, I tend to prefer moving the bottom one.  With time series data it will keep writing to the bottom child, so if you don&apos;t move the bottom child then a single server will end up doing the appending forever.  I prefer to rotate the server that&apos;s doing the work even though it&apos;s not quite as efficient and may cause a longer split pause.... makes for a more balanced cluster.&lt;/p&gt;</comment>
                            <comment id="12988331" author="mcorgan" created="Sat, 29 Jan 2011 00:37:37 +0000"  >&lt;p&gt;Sample consistent hashing balancing&lt;/p&gt;</comment>
                            <comment id="12988333" author="mcorgan" created="Sat, 29 Jan 2011 00:41:00 +0000"  >&lt;p&gt;removed dependency&lt;/p&gt;</comment>
                            <comment id="12988340" author="yuzhihong@gmail.com" created="Sat, 29 Jan 2011 00:53:00 +0000"  >&lt;p&gt;We should sort regionsToMove by the creation time of regions. The rationale is that new regions tend to be the hot ones and should be round-robin assigned to underloaded servers.&lt;/p&gt;</comment>
                            <comment id="12988396" author="yuzhihong@gmail.com" created="Sat, 29 Jan 2011 06:00:23 +0000"  >&lt;p&gt;@Matt:&lt;br/&gt;
The following code can be improved through randomization in case of empty tail to avoid clustering at consistentHashRing.firstKey()&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
regionHash = tail.isEmpty() ? consistentHashRing.firstKey() : tail.firstKey();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12991720" author="yuzhihong@gmail.com" created="Mon, 7 Feb 2011 23:51:06 +0000"  >&lt;p&gt;The loop in balanceCluster(Map&amp;lt;HServerInfo, List&amp;lt;HRegionInfo&amp;gt;&amp;gt;) which fills out destination servers for regionsToMove currently iterates underloadedServers in the same direction (from index 0 up).&lt;br/&gt;
This works for load metric being number of regions.&lt;br/&gt;
If we use number of requests as load metric, we should iterate from index 0 up, then back down to index 0, so forth. This would give us better load distribution.&lt;/p&gt;</comment>
                            <comment id="13005261" author="yuzhihong@gmail.com" created="Thu, 10 Mar 2011 19:12:30 +0000"  >&lt;p&gt;In preparation for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3616&quot; title=&quot;Add per region request information to HServerLoad&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3616&quot;&gt;&lt;del&gt;HBASE-3616&lt;/del&gt;&lt;/a&gt;, I think we need to enhance this method in SplitTransaction:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  HRegion createDaughterRegion(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; HRegionInfo hri,
      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; FlushRequester flusher)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;requestsCount is initially 0 for daughter regions which doesn&apos;t reflect the fact that parent region has been heavily accessed.&lt;br/&gt;
Maybe we can assign half of requestsCount of parent region to each daughter region ?&lt;/p&gt;</comment>
                            <comment id="13014906" author="sunnygao" created="Sat, 2 Apr 2011 01:07:39 +0000"  >&lt;p&gt;In hbase version 0.20.6, If contiguous regions, do not assign adjacent &lt;br/&gt;
regions in same region server. So it can break daughters of splits in same &lt;br/&gt;
region server and avoid hot spot. The performance can improve.&lt;/p&gt;

&lt;p&gt;In version 0.90.1, daughter is opened in region server that his parent is opened.&lt;br/&gt;
In the case A region server has thousands of regions. the contiguous region is difficult to&lt;br/&gt;
Choose by random. So the region server always is hot spot. &lt;/p&gt;

&lt;p&gt;Should the balance method be choose the contiguous region and then random or &lt;br/&gt;
other way avoid hot spot? (eg: add configue parameter choose balance method base on applications ?)&lt;/p&gt;</comment>
                            <comment id="13014927" author="zhoushuaifeng" created="Sat, 2 Apr 2011 01:31:01 +0000"  >&lt;p&gt;Agree with Gao&apos;s comments. When the region are splitting, it usually gets more write operations. It&apos;s better to assign the daughters to different regionservers to avoid hot spot.&lt;/p&gt;</comment>
                            <comment id="13019635" author="yuzhihong@gmail.com" created="Thu, 14 Apr 2011 00:38:46 +0000"  >&lt;p&gt;Suggestion from Stan Barton:&lt;br/&gt;
This JIRA can be generalized as a new policy for load balancer. That is, to have balanced number of&lt;br/&gt;
regions per RS per table and not in total number of regions from all tables.&lt;/p&gt;</comment>
                            <comment id="13041395" author="stack" created="Tue, 31 May 2011 03:17:02 +0000"  >&lt;p&gt;The need for this issue keeps coming up.  I&apos;m not sure if it the requesters are post 0.90.2 (and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3586&quot; title=&quot;Improve the selection of regions to balance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3586&quot;&gt;&lt;del&gt;HBASE-3586&lt;/del&gt;&lt;/a&gt;).  I&apos;d think the latter should have made our story better but maybe not (We should get folks to note if they are complaining post 0.90.2 or not).&lt;/p&gt;</comment>
                            <comment id="13047599" author="stack" created="Fri, 10 Jun 2011 22:46:01 +0000"  >&lt;p&gt;Moving out of 0.92.0. Pull it back in if you think different.&lt;/p&gt;</comment>
                            <comment id="13160177" author="xodarap" created="Wed, 30 Nov 2011 17:48:44 +0000"  >&lt;p&gt;We&apos;re running 0.94 and ran into this. With 4 region servers, we had one table with ~1800 regions, evenly balanced. We then used importtsv to import ~300 regions of a new table. We ended up with virtually all regions on one server; when I look at the master&apos;s log it looks like there were 159 rebalances (which makes sense); 123 were moving regions from the old table, and 26 moved new table regions. The result is that about 90% of the regions of the new table are on one server.&lt;/p&gt;

&lt;p&gt;When I look at DefaultLoadBalancer.balanceCluster, it has:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-comment&quot;&gt;// fetch in alternate order &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there is &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; region server
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (emptyRegionServerPresent) {
          fetchFromTail = !fetchFromTail;
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so we&apos;re only doing the randomization stuff in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3609&quot; title=&quot;Improve the selection of regions to balance; part 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3609&quot;&gt;&lt;del&gt;HBASE-3609&lt;/del&gt;&lt;/a&gt; if there&apos;s a new region server? Is there a reason we don&apos;t do this all the time?&lt;/p&gt;</comment>
                            <comment id="13160233" author="yuzhihong@gmail.com" created="Wed, 30 Nov 2011 18:56:35 +0000"  >&lt;p&gt;@Ben:&lt;br/&gt;
Thanks for trying out 0.94&lt;/p&gt;

&lt;p&gt;The code snippet above deals with region server which recently joined the cluster. Its goal is to avoid hot region server which receives above average load.&lt;br/&gt;
This is part of the changes from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3609&quot; title=&quot;Improve the selection of regions to balance; part 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3609&quot;&gt;&lt;del&gt;HBASE-3609&lt;/del&gt;&lt;/a&gt;. The randomization is done on this line:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    Collections.shuffle(sns, RANDOM);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where we schedule regions to region servers which are shuffled randomly.&lt;/p&gt;

&lt;p&gt;Your observation about unbalanced table(s) in the cluster is valid. This is due to master not passing per-table region distribution to balanceCluster().&lt;br/&gt;
I have a patch which is in internal repository where master calls balanceCluster() for each table.&lt;br/&gt;
Once we test it in production cluster, I should be able to contribute back.&lt;/p&gt;</comment>
                            <comment id="13160277" author="xodarap" created="Wed, 30 Nov 2011 19:47:33 +0000"  >&lt;p&gt;@Ted: Thanks! I think I was looking at trunk instead of .94, I see that in .94 it should be random:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
List&amp;lt;HRegionInfo&amp;gt; regions = randomize(server.getValue());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Your per-table balance will be very useful for this case. Look forward to seeing it!&lt;/p&gt;</comment>
                            <comment id="13160283" author="jdcryans" created="Wed, 30 Nov 2011 19:54:50 +0000"  >&lt;p&gt;Just to clear up some confusion, trunk is going to be 0.94 so what you&apos;re playing with is probably 0.90.4&lt;/p&gt;</comment>
                            <comment id="13178588" author="zhihyu@ebaysf.com" created="Tue, 3 Jan 2012 01:17:51 +0000"  >&lt;p&gt;The following data structure is introduced:&lt;br/&gt;
Map&amp;lt;String, Map&amp;lt;ServerName, List&amp;lt;HRegionInfo&amp;gt;&amp;gt;&amp;gt; tableRegionDistribution&lt;br/&gt;
The String key is the name of table. The list holds the regions for the table on ServerName.&lt;/p&gt;

&lt;p&gt;In HMaster.balance(), before calling balancer.balanceCluster(assignments), we translate (regroup) Map&amp;lt;ServerName, List&amp;lt;HRegionInfo&amp;gt;&amp;gt; returned by assignmentManager.getAssignments() into Map&amp;lt;String, Map&amp;lt;ServerName, List&amp;lt;HRegionInfo&amp;gt;&amp;gt;&amp;gt;. Then we iterate over the tables and call balancer.balanceCluster(assignments) for each table.&lt;/p&gt;

&lt;p&gt;Additionally, new HBaseAdmin method can be added to filter tables which don&apos;t need to be balanced.&lt;/p&gt;

&lt;p&gt;The ultimate goal is to distribute table regions evenly&lt;/p&gt;</comment>
                            <comment id="13178606" author="lhofhansl" created="Tue, 3 Jan 2012 03:10:02 +0000"  >&lt;p&gt;Looks good to me (as far as I understand the balancing code).&lt;br/&gt;
Minor nits:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Should &quot;ensemble&quot; be &quot;dummytable&quot; (or something) and be defined as constant?&lt;/li&gt;
	&lt;li&gt;Why:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!svrToRegions.containsKey(e.getKey())) {
  regions = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;HRegionInfo&amp;gt;();
  svrToRegions.put(e.getKey(), regions);
} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
  regions = svrToRegions.get(e.getKey());
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;instead of:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
regions = svrToRegions.get(e.getKey());
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (regions == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
  regions = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;HRegionInfo&amp;gt;();
  svrToRegions.put(e.getKey(), regions);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;serverName can&apos;t be null here, correct?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13178611" author="zhihyu@ebaysf.com" created="Tue, 3 Jan 2012 03:39:40 +0000"  >&lt;p&gt;Since the table name in the outer map is only used for grouping purposes, I think &quot;ensemble&quot; is a better name than &quot;dummytable&quot;.&lt;br/&gt;
The code snippets in second comment are equivalent. I may keep my code since this is patch 1 in a series of at least 3 patches.&lt;br/&gt;
The other two are: block location affinity utilization and better load balancing heuristics for tables with presplit regions.&lt;/p&gt;</comment>
                            <comment id="13178628" author="zhihyu@ebaysf.com" created="Tue, 3 Jan 2012 04:55:32 +0000"  >&lt;p&gt;Patch which Hadoop QA can use.&lt;/p&gt;</comment>
                            <comment id="13178641" author="hadoopqa" created="Tue, 3 Jan 2012 06:00:48 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12509174/3373.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12509174/3373.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -151 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 77 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/652//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/652//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/652//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/652//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/652//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/652//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13179712" author="zhihyu@ebaysf.com" created="Wed, 4 Jan 2012 18:11:27 +0000"  >&lt;p&gt;@Ben, @Jonathan Gray:&lt;br/&gt;
What do you think of my patch ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13179767" author="lhofhansl" created="Wed, 4 Jan 2012 19:11:13 +0000"  >&lt;p&gt;I forgot to +1 it above.&lt;/p&gt;</comment>
                            <comment id="13180557" author="zhihyu@ebaysf.com" created="Thu, 5 Jan 2012 17:21:00 +0000"  >&lt;p&gt;This issue was opened more than a year ago.&lt;br/&gt;
If there is no objection, I will get it in TRUNK.&lt;/p&gt;</comment>
                            <comment id="13180633" author="xodarap" created="Thu, 5 Jan 2012 17:57:33 +0000"  >&lt;p&gt;@Zhihong: Thank you for looking into this issue.&lt;/p&gt;

&lt;p&gt;Just to verify (since I&apos;m not too familiar with the code): with this change, the balancing will be done at the per-table level, right?&lt;/p&gt;

&lt;p&gt;So if I have one big table, this may not address the issue (since a randomly chosen region from the table is unlikely to be the newly split one) but with lots of small tables the issue will be addressed. Correct?&lt;/p&gt;</comment>
                            <comment id="13180641" author="zhihyu@ebaysf.com" created="Thu, 5 Jan 2012 18:07:20 +0000"  >&lt;p&gt;@Ben:&lt;br/&gt;
Your observation is correct.&lt;br/&gt;
If you have a big table which has newly split regions, load balancer in 0.92 (and TRUNK) is already able to pick newly split ones and balance them.&lt;br/&gt;
If the big table has presplit regions only, I have another feature (to be open sourced) which utilizes region load information for balancing decisions.&lt;/p&gt;</comment>
                            <comment id="13180675" author="xodarap" created="Thu, 5 Jan 2012 18:41:01 +0000"  >&lt;p&gt;OK, thanks Zhihong, I was confusing which JIRA this was. &lt;/p&gt;

&lt;p&gt;+1 from me.&lt;/p&gt;</comment>
                            <comment id="13180893" author="zhihyu@ebaysf.com" created="Thu, 5 Jan 2012 22:23:13 +0000"  >&lt;p&gt;Integrated to TRUNK.&lt;/p&gt;

&lt;p&gt;Thanks for the review, Lars and Ben.&lt;/p&gt;

&lt;p&gt;More enhancements for load balancer to come.&lt;/p&gt;</comment>
                            <comment id="13180916" author="hudson" created="Thu, 5 Jan 2012 22:57:22 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2613 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2613/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2613/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3373&quot; title=&quot;Allow regions to be load-balanced by table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3373&quot;&gt;&lt;del&gt;HBASE-3373&lt;/del&gt;&lt;/a&gt; Allow regions to be load-balanced by table&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13181169" author="hudson" created="Fri, 6 Jan 2012 06:57:57 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #65 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/65/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/65/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3373&quot; title=&quot;Allow regions to be load-balanced by table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3373&quot;&gt;&lt;del&gt;HBASE-3373&lt;/del&gt;&lt;/a&gt; Allow regions to be load-balanced by table&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13191364" author="hudson" created="Mon, 23 Jan 2012 19:12:32 +0000"  >&lt;p&gt;Integrated in HBase-0.92 #257 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92/257/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92/257/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5231&quot; title=&quot;Backport HBASE-3373 (per-table load balancing) to 0.92&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5231&quot;&gt;&lt;del&gt;HBASE-5231&lt;/del&gt;&lt;/a&gt;  Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3373&quot; title=&quot;Allow regions to be load-balanced by table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3373&quot;&gt;&lt;del&gt;HBASE-3373&lt;/del&gt;&lt;/a&gt; (per-table load balancing) to 0.92&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13191991" author="hudson" created="Tue, 24 Jan 2012 07:50:19 +0000"  >&lt;p&gt;Integrated in HBase-0.92-security #88 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92-security/88/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92-security/88/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5231&quot; title=&quot;Backport HBASE-3373 (per-table load balancing) to 0.92&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5231&quot;&gt;&lt;del&gt;HBASE-5231&lt;/del&gt;&lt;/a&gt;  Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3373&quot; title=&quot;Allow regions to be load-balanced by table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3373&quot;&gt;&lt;del&gt;HBASE-3373&lt;/del&gt;&lt;/a&gt; (per-table load balancing) to 0.92&lt;/p&gt;

&lt;p&gt;tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12503142">HBASE-3724</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12462821">HBASE-2480</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12509174" name="3373.txt" size="5743" author="zhihyu@ebaysf.com" created="Tue, 3 Jan 2012 05:11:03 +0000"/>
                            <attachment id="12469717" name="HbaseBalancerTest2.java" size="3243" author="mcorgan" created="Sat, 29 Jan 2011 00:41:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 18 Dec 2010 21:21:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33005</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 47 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02h07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12356</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>There is a parameter, hbase.regions.slop, with default value of 0.2&lt;br/&gt;
This parameter allows actual region count to deviate by this percentage from (ideal) average region count.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>