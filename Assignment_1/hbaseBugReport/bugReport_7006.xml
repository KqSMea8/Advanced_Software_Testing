<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:41:49 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7006/HBASE-7006.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7006] [MTTR] Improve Region Server Recovery Time - Distributed Log Replay</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7006</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Just saw interesting issue where a cluster went down  hard and 30 nodes had 1700 WALs to replay.  Replay took almost an hour.  It looks like it could run faster that much of the time is spent zk&apos;ing and nn&apos;ing.&lt;/p&gt;

&lt;p&gt;Putting in 0.96 so it gets a look at least.  Can always punt.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12612336">HBASE-7006</key>
            <summary>[MTTR] Improve Region Server Recovery Time - Distributed Log Replay</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jeffreyz">Jeffrey Zhong</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Wed, 17 Oct 2012 23:47:31 +0000</created>
                <updated>Wed, 23 Mar 2016 02:04:56 +0000</updated>
                            <resolved>Wed, 15 May 2013 04:28:39 +0000</resolved>
                                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.95.1</fixVersion>
                                    <component>MTTR</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>30</watches>
                                                                                                            <comments>
                            <comment id="13478770" author="nkeywal" created="Thu, 18 Oct 2012 08:06:32 +0000"  >&lt;p&gt;Nothing related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6738&quot; title=&quot;Too aggressive task resubmission from the distributed log manager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6738&quot;&gt;&lt;del&gt;HBASE-6738&lt;/del&gt;&lt;/a&gt;?&lt;br/&gt;
There is not a limit of 32 WALs per node (hence 900 wals)? Or have you lost more nodes?&lt;/p&gt;</comment>
                            <comment id="13479513" author="stack" created="Fri, 19 Oct 2012 00:09:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; No sir.  Limit was 8 WALs but write rate overran the limit so almost 40 WALs each.&lt;/p&gt;</comment>
                            <comment id="13543490" author="jeffreyz" created="Fri, 4 Jan 2013 01:11:39 +0000"  >
&lt;p&gt;Hey,&lt;/p&gt;

&lt;p&gt;I&apos;ve came up a proposal to improve current log splitting process. Feedbacks are welcome! &lt;/p&gt;

&lt;p&gt;I temporarily assign the JIRA to me so that I can implement the proposal once it gets green light.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;
</comment>
                            <comment id="13550662" author="stack" created="Fri, 11 Jan 2013 01:11:01 +0000"  >&lt;p&gt;Excellent write up Jeffrey.&lt;/p&gt;

&lt;p&gt;Was thinking myself that we might do what Nicolas suggests on the end.&lt;/p&gt;

&lt;p&gt;It looks like you handle failures properly.&lt;/p&gt;

&lt;p&gt;Savings will be large I&apos;d think.&lt;/p&gt;

&lt;p&gt;Actually simplifies the log splitting process I&apos;d say.&lt;/p&gt;

&lt;p&gt;What if we do multiple WALs per regionserver?  That shouldn&apos;t change your processing model far as I can see.&lt;/p&gt;</comment>
                            <comment id="13550665" author="stack" created="Fri, 11 Jan 2013 01:11:39 +0000"  >&lt;p&gt;Making major rather than critical.  If done in time, that&apos;d be excellent but won&apos;t hold up 0.96 for it.&lt;/p&gt;</comment>
                            <comment id="13550705" author="jeffreyz" created="Fri, 11 Jan 2013 02:17:35 +0000"  >&lt;p&gt;Thanks Stack for reviewing the proposal! &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What if we do multiple WALs per regionserver? That shouldn&apos;t change your processing model far as I can see.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeah, you&apos;re right. multiples WALs per RS won&apos;t affect the proposal.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;</comment>
                            <comment id="13576177" author="jeffreyz" created="Mon, 11 Feb 2013 22:25:43 +0000"  >
&lt;p&gt;The new implementation increases performance about 2 times and become much better when more regions to be recovered.&lt;/p&gt;

&lt;p&gt;The new implementation allows writes in recovery so we won&apos;t have data loss for &quot;time series data&quot; usage pattern. The down time for writes normally is about one or two seconds.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;</comment>
                            <comment id="13576178" author="yuzhihong@gmail.com" created="Mon, 11 Feb 2013 22:33:07 +0000"  >&lt;p&gt;This is encouraging.&lt;/p&gt;

&lt;p&gt;Looking forward to your patch.&lt;/p&gt;</comment>
                            <comment id="13576225" author="enis" created="Mon, 11 Feb 2013 23:47:11 +0000"  >&lt;p&gt;These are excellent results, especially with large # of regions. Also we will benefit from other improvements on connection management, region discovery, etc, which means that those numbers can go even lower. Let&apos;s try to get this in with the current set of changes, then as we debug more and learn more, we can do follow ups. &lt;/p&gt;

&lt;p&gt;One thing we did not test is to not write a file per region per WAL file, but do the bigtable approach. Namely, for each WAL file, read up until DFS block size (128MB), sort the edits per region in memory, and write a file per block. The files have a simple index per region. Not sure how we can test that easily though. &lt;/p&gt;</comment>
                            <comment id="13576244" author="jeffreyz" created="Tue, 12 Feb 2013 00:21:14 +0000"  >
&lt;p&gt;The big table approach is kind of middle ground approach between the existing implementation and the proposal in the JIRA. The file block implementation seems need more work though. Each region server has to read all those newly created block files to replay edits but cut writes significantly so it should have improvements over existing approach(not the new proposal as it still read recovery data twice: one is in log splitting and the other is in replay phase and incur some extra writes).&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;

</comment>
                            <comment id="13576304" author="enis" created="Tue, 12 Feb 2013 02:27:38 +0000"  >&lt;p&gt;Agreed that it is the middle ground. On region open, RS has to do a read on the index, and seek, and sequential read for each region. However, in your approach as you reported off-list, we are paying for re-locating the regions, and the rpc overhead instead of just streaming sequential writes to hdfs. I was just curious, given the current implementation, which one would be faster. I am not suggesting that we should prototype that as well, especially given that we can open the regions for writes in 1-2 secs with this. &lt;/p&gt;</comment>
                            <comment id="13576339" author="yuzhihong@gmail.com" created="Tue, 12 Feb 2013 03:18:30 +0000"  >&lt;p&gt;@Jeff:&lt;br/&gt;
Do you plan to publish your patch in sub-task of this JIRA ?&lt;/p&gt;</comment>
                            <comment id="13576821" author="jeffreyz" created="Tue, 12 Feb 2013 17:47:25 +0000"  >&lt;p&gt;@Ted,&lt;/p&gt;

&lt;p&gt;Yes, my first patch will include major logic for this JIRA and will be attached to a sub task JIRA(to be created) and be submitted within these two days. There will be two more sub JIRAs: one is to create a replay command and the other is to add metrics for better reporting purpose.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey &lt;/p&gt;</comment>
                            <comment id="13583653" author="jeffreyz" created="Thu, 21 Feb 2013 23:13:37 +0000"  >&lt;p&gt;Mark it critical so that we can ship this into 0.96.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;</comment>
                            <comment id="13631981" author="jxiang" created="Mon, 15 Apr 2013 18:26:05 +0000"  >&lt;p&gt;I read the proposal and have some questions. At first, it sounds we trade disk io to network io, which should have better performance.  As to the memstore flush write saving after recovered.edits have been replayed, the proposal needs to do the same, right?  You just write them to another WAL file, isn&apos;t it true?&lt;/p&gt;

&lt;p&gt;Suppose a region server failed again in the middle, does a split worker need to split the WAL again? This means a WAL may be read/split multiple times?&lt;/p&gt;

&lt;p&gt;In the attached performance testing, do we have a breakdown on how many time it spends on reading the log file, writing to the recovered edits file?  How did you measure the log splitting time?&lt;/p&gt;</comment>
                            <comment id="13632172" author="jeffreyz" created="Mon, 15 Apr 2013 20:49:46 +0000"  >&lt;blockquote&gt;
&lt;p&gt; it sounds we trade disk io to network io&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No, we cut both disk io and network ios relating to recovered.edits files creations &amp;amp; deletions.&lt;/p&gt;

&lt;p&gt;Currently we replay the wal to the destination region server while in old way the destination RS reads recovered edits from underlying hdfs. In terms of network io, they&apos;re same because the old way still need read recovered edits file across wire. The difference is that in distributed replay wal edits are pushed to the destination RS while the old way is pulling edits from recovered edits(which are intermediate files). &lt;/p&gt;

&lt;p&gt;In summary, the IOs related to recovered.edits files are all gone without any extra IOs. I think this question is common and I&apos;ll include this in the write up.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Suppose a region server failed again in the middle, does a split worker need to split the WAL again? This means a WAL may be read/split multiple times&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We handle sequential RS failures like a new RS failure and replay its WALs left behind.  We may read a WAL multiple times in sequential failures but not replay multiple times if edits are flushed.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the attached performance testing, do we have a breakdown on how many time it spends on reading the log file, writing to the recovered edits file? How did you measure the log splitting time?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t have the break down since reading and writing happen at the same time. In normal cases, writing finish several secs after reading is done. We have metrics in splitlogmanager which measures the total splitting time and that&apos;s what I used in the testing. &lt;/p&gt;

&lt;p&gt;The latest combined patch is attached in 7837.&lt;/p&gt;</comment>
                            <comment id="13632198" author="jxiang" created="Mon, 15 Apr 2013 21:12:49 +0000"  >&lt;p&gt;Cool, that&apos;s great!&lt;/p&gt;</comment>
                            <comment id="13632359" author="jxiang" created="Mon, 15 Apr 2013 23:27:11 +0000"  >&lt;p&gt;You mentioned that this patch depends on some assumption.  Have you verified it? If so, which patch should be reviewed and committed at first? Or you want them all be reviewed and committed together?&lt;/p&gt;</comment>
                            <comment id="13632441" author="jeffreyz" created="Tue, 16 Apr 2013 00:39:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; Thanks in advance for reviewing. The assumption documented in the write-up is verified and relies on idempotence of hbase. I think it makes sense to review the combined patch to reduce reviewing effort but I fully relies on each reviewer&apos;s preferences.&lt;/p&gt;
</comment>
                            <comment id="13634456" author="jxiang" created="Wed, 17 Apr 2013 21:22:14 +0000"  >&lt;p&gt;I prefer small patches, otherwise, it is hard to review.&lt;/p&gt;</comment>
                            <comment id="13634748" author="jeffreyz" created="Thu, 18 Apr 2013 01:40:32 +0000"  >&lt;p&gt;Update the write-up to reflect the implementations.&lt;/p&gt;</comment>
                            <comment id="13636110" author="jeffreyz" created="Fri, 19 Apr 2013 06:10:17 +0000"  >&lt;p&gt;Rebase combined patch&lt;/p&gt;</comment>
                            <comment id="13636134" author="hadoopqa" created="Fri, 19 Apr 2013 06:32:03 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12579488/hbase-7006-combined.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12579488/hbase-7006-combined.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 15 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.TestHeapSize&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5356//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13636138" author="anoop.hbase" created="Fri, 19 Apr 2013 06:44:48 +0000"  >&lt;p&gt;Will start reviewing the patch by tomorrow Jeffrey Zhong. This will be an interesting stuff in MTTR.&lt;/p&gt;</comment>
                            <comment id="13636151" author="hadoopqa" created="Fri, 19 Apr 2013 07:13:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12579497/hbase-7006-combined.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12579497/hbase-7006-combined.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 15 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.TestHeapSize&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5360//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13636983" author="jmhsieh" created="Fri, 19 Apr 2013 22:50:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Do we have any numbers of how this improves our recovery time?&lt;/p&gt;</comment>
                            <comment id="13636984" author="jeffreyz" created="Fri, 19 Apr 2013 22:53:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt; The initial performance number is in the attachment &apos;LogSplitting Comparison.pdf&apos;. Thanks. &lt;/p&gt;</comment>
                            <comment id="13637011" author="jmhsieh" created="Fri, 19 Apr 2013 23:27:32 +0000"  >&lt;p&gt;Lovely.  Thanks!&lt;/p&gt;</comment>
                            <comment id="13637026" author="yuzhihong@gmail.com" created="Fri, 19 Apr 2013 23:56:04 +0000"  >&lt;p&gt;For ReplicationZookeeper.java :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] toByteArray(
+      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Considering lockToByteArray() method that follows above, maybe rename above as positionToByteArray()&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; REGION_ASSIGNMENT_TIME_OUT = &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.master.region.assignment.time.out&quot;&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;How about &quot;hbase.master.region.assignment.timeout&quot; ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; REPLAY_BATCH_SIZE_DESC = &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of changes of each replay batch.&quot;&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&quot;&quot;Number of changes of each&quot; -&amp;gt; &quot;&quot;Number of changes in each&quot;&lt;/p&gt;

&lt;p&gt;For AssignmentManager.java :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; end = (timeOut &amp;lt;= 0) ? &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.MAX_VALUE : &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis() + timeOut;
...
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis() &amp;gt; end) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please use EnvironmentEdge.&lt;/p&gt;</comment>
                            <comment id="13638831" author="stack" created="Tue, 23 Apr 2013 06:24:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Nice numbers in posted doc.&lt;/p&gt;

&lt;p&gt;What does below mean sir?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-comment&quot;&gt;// make current mutation as a distributed log replay change
&lt;/span&gt;+  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isReplay = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Why we have this isReplay in a Mutation?  Because these edits get treated differently over on serverside?&lt;/p&gt;

&lt;p&gt;Suggest calling the data member replay or logReplay or walReplay and then the accessor is isLogReply or isWALReplay.  isReplay is the name of a method that returns whether the data member replay is true or not.&lt;/p&gt;

&lt;p&gt;Does this define belong in this patch?&lt;/p&gt;

&lt;p&gt;+  /** Conf key that specifies region assignment timeout value */&lt;br/&gt;
+  public static final String REGION_ASSIGNMENT_TIME_OUT = &quot;hbase.master.region.assignment.time.out&quot;;&lt;/p&gt;

&lt;p&gt;Why we timing out assignments in this patch?&lt;/p&gt;

&lt;p&gt;Is this log splitting that is referred to in the metric name below?&lt;/p&gt;

&lt;p&gt;+  void updateMetaSplitTime(long time);&lt;/p&gt;

&lt;p&gt;If so, should it be updateMetaWALSplitTime?  And given what this patch is about, should it be WALReplay?&lt;/p&gt;

&lt;p&gt;Ditto for updateMetaSplitSize&lt;/p&gt;

&lt;p&gt;Excuse me if I am not following what is going on w/ the above (because I see later that you have replay metrics going on....)&lt;/p&gt;

&lt;p&gt;Default is false?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    distributedLogReplay = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.conf.getBoolean(HConstants.DISTRIBUTED_LOG_REPLAY_KEY, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Should we turn it on in trunk and off in 0.95?  (Should we turn it on in 0.95 so it gets a bit of testing?)&lt;/p&gt;

&lt;p&gt;Something wrong w/ license in WALEditsReplaySink&lt;/p&gt;

&lt;p&gt;Skimmed the patch.  Let me come back w/ a decent review.  Looks good J.&lt;/p&gt;</comment>
                            <comment id="13638964" author="anoop.hbase" created="Tue, 23 Apr 2013 11:25:14 +0000"  >&lt;p&gt;The comparison numbers looks promising! So now we make the region available for writes immediately. Have you run the test with clients doing the writes to region soon after it is opened for write? (Impact on total recovery time) Going through the patch..&lt;/p&gt;</comment>
                            <comment id="13639707" author="jeffreyz" created="Tue, 23 Apr 2013 22:14:22 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopsamjohn&quot; class=&quot;user-hover&quot; rel=&quot;anoopsamjohn&quot;&gt;Anoop Sam John&lt;/a&gt; for reviewing! &lt;/p&gt;

&lt;p&gt;I included the following changes in the v1 patch:&lt;br/&gt;
1) Support for recovering wal edits of regions in disabling/disabled table(Theoretically  there is no need to recover wal edits of regions on a disabled table but I keep it to be compatible with before). &lt;br/&gt;
2) Review feedbacks from Ted and Stack.&lt;/p&gt;

&lt;p&gt;From this point, I&apos;ll write more unit tests and start run integration tests. &lt;/p&gt;

&lt;p&gt;Below are answers to the latest feedbacks:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Why we have this isReplay in a Mutation&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is used inside HRegionServer#batchMutate for special handling of a reply mutation. For example, skip &quot;readonly&quot; check and coprocessor in the normal write path. I&apos;ll change this to &quot;logReplay&quot; per your suggestion. The other option is to add an addition &quot;logReplay&quot; argument for all functions in the write path, which isn&apos;t as clean as current way IMHO. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Does this define belong in this patch?&lt;br/&gt;
+ /** Conf key that specifies region assignment timeout value */&lt;br/&gt;
+ public static final String REGION_ASSIGNMENT_TIME_OUT = &quot;hbase.master.region.assignment.time.out&quot;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think the name is confusing and I changed it to &quot;hbase.master.log.replay.wait.region.timeout&quot;. It&apos;s used by logReplay to wait for a region ready before we can replay wal edits against the region.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If so, should it be updateMetaWALSplitTime? And given what this patch is about, should it be WALReplay?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Good point. Fixed.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Should we turn it on in trunk and off in 0.95?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;A good suggestion to bake it in trunk a little bit.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Something wrong w/ license in WALEditsReplaySink&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Fixed. Good catch!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Have you run the test with clients doing the writes to region soon after it is opened for write?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No, I haven&apos;t yet. The performance test I run is against a cluster without load to easily compare results. I&apos;ll conduct more performance tests when the feature is fully ready. &lt;/p&gt;
</comment>
                            <comment id="13639871" author="hadoopqa" created="Wed, 24 Apr 2013 00:06:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12580153/hbase-7006-combined-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12580153/hbase-7006-combined-v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 21 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5417//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13641338" author="ram_krish" created="Thu, 25 Apr 2013 02:57:33 +0000"  >&lt;p&gt;Patch looks good on a high level.  Will go through the patch&lt;/p&gt;</comment>
                            <comment id="13641431" author="anoop.hbase" created="Thu, 25 Apr 2013 05:13:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Do we need the metric like req count to be affected by the replay requests?&lt;/p&gt;</comment>
                            <comment id="13641977" author="ram_krish" created="Thu, 25 Apr 2013 17:30:12 +0000"  >&lt;p&gt;It is more dependent on ZK now. will these exceptions cause any problem if it happens always&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (KeeperException e) {
+        LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Cannot get lastFlushedSequenceId from ZooKeeper &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server=&quot;&lt;/span&gt; + regionServerName
+            + &lt;span class=&quot;code-quote&quot;&gt;&quot;; region=&quot;&lt;/span&gt; + encodedRegionName, e);
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (KeeperException e) {
+      LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Cannot remove recovering regions from ZooKeeper&quot;&lt;/span&gt;, e);
+    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13641981" author="jeffreyz" created="Thu, 25 Apr 2013 17:31:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; Are you suggesting to add a req counter at the receiving RS to see how many replays is happening? I think it&apos;s a good idea. In addition, I don&apos;t see there is such counter for each individual command such as put, get, scan etc. I can add new counters for all client commands in RS. Thanks.  &lt;/p&gt;</comment>
                            <comment id="13642027" author="jeffreyz" created="Thu, 25 Apr 2013 18:10:14 +0000"  >&lt;p&gt;Hey Ram,&lt;br/&gt;
Thanks for the good questions. Below are the answers:&lt;br/&gt;
1) &lt;/p&gt;







&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (KeeperException e) {
+        LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Cannot get lastFlushedSequenceId from ZooKeeper &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server=&quot;&lt;/span&gt; + regionServerName
+            + &lt;span class=&quot;code-quote&quot;&gt;&quot;; region=&quot;&lt;/span&gt; + encodedRegionName, e);
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In this scenario, we can&apos;t get last flushed sequence Id so we&apos;ll replay all edits in the wal. There will be some duplicated replay while it won&apos;t affect correctness.&lt;/p&gt;








&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (KeeperException e) {
+      LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Cannot remove recovering regions from ZooKeeper&quot;&lt;/span&gt;, e);
+    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We have other place to do stale data GC. Therefore, after a little bit, the recovering ZK node should be removed:&lt;br/&gt;
In SplitLogManager, we have following code:&lt;/p&gt;















&lt;p&gt;      // Garbage collect left-over /hbase/recovering-regions/... znode&lt;br/&gt;
      if (tot == 0 &amp;amp;&amp;amp; inflightWorkItems.size() == 0 &amp;amp;&amp;amp; tasks.size() == 0) &lt;/p&gt;
{
        removeRecoveringRegionsFromZK(null);
      }
&lt;p&gt;-Jeffrey&lt;/p&gt;
</comment>
                            <comment id="13642364" author="jeffreyz" created="Thu, 25 Apr 2013 23:17:20 +0000"  >&lt;p&gt;In the v2 patch:&lt;/p&gt;

&lt;p&gt;1) Incorporate &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; feedbacks by adding updateReplay histogram&lt;br/&gt;
2) Add a new test case for disabling table&lt;br/&gt;
3) Bug fixes relating to sequential RS failures scenario&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;</comment>
                            <comment id="13642429" author="hadoopqa" created="Fri, 26 Apr 2013 00:26:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12580612/hbase-7006-combined-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12580612/hbase-7006-combined-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 21 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessController&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5459//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13643420" author="v.himanshu" created="Sat, 27 Apr 2013 00:28:09 +0000"  >&lt;p&gt;This has really bloated now. Can you please rb it. Thanks.&lt;/p&gt;</comment>
                            <comment id="13643485" author="stack" created="Sat, 27 Apr 2013 02:49:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Yeah, rb it please sir (A few of us were talking about it today... we are all fired up for reviewing more!).   Thanks J.&lt;/p&gt;</comment>
                            <comment id="13643549" author="jeffreyz" created="Sat, 27 Apr 2013 05:56:24 +0000"  >&lt;p&gt;Sure, I&apos;ll put the latest combined patch in the review board this weekend. &lt;/p&gt;</comment>
                            <comment id="13644313" author="jeffreyz" created="Mon, 29 Apr 2013 07:01:13 +0000"  >&lt;p&gt;I posted the latest patch(v3) to review board at &lt;a href=&quot;https://reviews.apache.org/r/10832&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10832&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the v3 patch, it has following changes:&lt;br/&gt;
1) Enable distributedLogReplay by default&lt;br/&gt;
2) Bug fixes of some tricky issues from recent tests&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Jeffrey&lt;/p&gt;</comment>
                            <comment id="13644339" author="hadoopqa" created="Mon, 29 Apr 2013 08:06:05 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12580940/hbase-7006-combined-v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12580940/hbase-7006-combined-v3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 21 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 4 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplicationQueueFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaReaderEditor&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5482//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13644703" author="stack" created="Mon, 29 Apr 2013 18:11:29 +0000"  >&lt;p&gt;Are some of the above failures because of your patch J? (Reviewing now...)&lt;/p&gt;</comment>
                            <comment id="13644851" author="jeffreyz" created="Mon, 29 Apr 2013 20:49:40 +0000"  >&lt;p&gt;TestMetaReaderEditor is related and the other three passed locally. I&apos;ll include fixes in the next patch. Thanks.&lt;/p&gt;</comment>
                            <comment id="13645431" author="anoop.hbase" created="Tue, 30 Apr 2013 10:07:23 +0000"  >&lt;p&gt;Added some comments in RB. Not yet completed the review..&lt;br/&gt;
Mutation.replay -&amp;gt; This new state varianle is needed really? For the replay we call replay interface addded in HRS from another HRS. So all the Mutations in that call are replay mutations.&lt;/p&gt;</comment>
                            <comment id="13645705" author="jeffreyz" created="Tue, 30 Apr 2013 16:38:56 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; for the reviewing!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the replay we call replay interface addded in HRS from another HRS. So all the Mutations in that call are replay mutations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agree. In fact, current implementation is this way. The replay flag is NOT added into MutationProto protobuf message but in the Mutation class. So client doesn&apos;t need to specify the flag while the receiving region server set the flag so that write path code can do special logic for the replay otherwise I have to add a new &apos;replay&apos; flag input argument to all functions along the write path.&lt;/p&gt;</comment>
                            <comment id="13646864" author="stack" created="Wed, 1 May 2013 19:44:48 +0000"  >&lt;p&gt;Some comments on the design doc:&lt;/p&gt;

&lt;p&gt;+ Nit: Add author, date, and add issue number so can go back to the hosting issue should I trip over the doc w/o any other context.&lt;br/&gt;
+ Is your assumption about out-of-order replay of edits new to this feature?  I suppose in the old/current way of log splitting, we do stuff in sequenceid order because we wrote the recovered.edits files named by sequenceid... so they were ordered when the regionserver read them in? We should highlight your assumption more.  I think if we move to multiple-WALs we&apos;ll want to also take on this assumption doing recovery.&lt;br/&gt;
+ Given the assumption, we should list the problematic scenarios (or point to where we list them already &amp;#8211; I think the &apos;Current Limitations&apos; section here &lt;a href=&quot;http://hbase.apache.org/book.html#version.delete&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/book.html#version.delete&lt;/a&gt; should have the list we currently know).&lt;br/&gt;
+ &quot;...check if all WALs of a failed region server have been successfully replayed.&quot;  How is this done?&lt;br/&gt;
+ How will a crashed regionserver &quot;...... and appending itself into the list of...&quot;: i.e. append itself to list of crashed servers (am I reading this wrong)?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;For each region per failed region server, we stores the last flushed sequence Id from the region server before it failed.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is the mechanism that has the regionserver telling the master its current sequenceid everytime it flushes to an hfile?  So when server crashes, master writes a znode under the recovering-regions with the last reported seq id?    if a new regionserver hosting a recovery of regions then crashes, it gets a new znode w/ its current sequenceid?  Now we have two crashed servers with (probably) two different sequenceids whose logs we are recovering.  The two sequenceids are never related right?  They are only applied to the logs of the server who passed the particular sequenceid to the master?&lt;/p&gt;


&lt;p&gt;Question:  So it looks like we replay the WALs of a crashed regionserver by playing them into the new region host servers.  There does not seem to be a flush when the replay of the old crashed servers WALs is done.  Is your thinking that it is not needed since the old edits are now in the new servers WAL?  Would there be any advantage NOT writing the WAL on replay and only when done, then flush (I suppose not, thinking about it, and in fact, it would probably make replay more complicated since we&apos;d have to have this new operation to do; a flush-when-all-WALS-recovered).&lt;/p&gt;

&lt;p&gt;Good stuff.&lt;/p&gt;</comment>
                            <comment id="13647004" author="jeffreyz" created="Wed, 1 May 2013 22:20:41 +0000"  >&lt;p&gt;The v4 patch includes following changes:&lt;/p&gt;

&lt;p&gt;1) fixes for test failures from last QA run&lt;br/&gt;
2) incorporate &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; feedbacks&lt;/p&gt;

&lt;p&gt;The remaining item is to see if need support &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2231&quot; title=&quot;Compaction events should be written to HLog&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2231&quot;&gt;&lt;del&gt;HBASE-2231&lt;/del&gt;&lt;/a&gt; where I raised some questions there. &lt;/p&gt;</comment>
                            <comment id="13647069" author="hadoopqa" created="Wed, 1 May 2013 23:30:43 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12581430/hbase-7006-combined-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12581430/hbase-7006-combined-v4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 21 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestOpenedRegionHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5527//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13647084" author="jeffreyz" created="Wed, 1 May 2013 23:42:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; Good comments! Please see my responses in reverse order of your feedbacks:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Would there be any advantage NOT writing the WAL on replay and only when done, then flush&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is very good question. Actually I was thinking to evaluate this after this feature is in as a possible optimization. Currently receiving RS does a WAL sync for each replay batch. In the optimization scenario, we could replay mutaions with SKIP_WAL durability and flush at the end. The gain mostly depends on the &quot;sequential&quot; write performance of wal syncs. I think it&apos;s worth a try here.   &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt; The two sequenceids are never related right? They are only applied to the logs of the server who passed the particular sequenceid to the master?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No, sequenceIds from different RSs are totally un-related. Yes. Currently we use the up-to-date flushed sequence id when we open the region by looking all the store files as we do today. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;+ &quot;...check if all WALs of a failed region server have been successfully replayed.&quot; How is this done?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We rely on the fact that when log split for a failed RS is done then all its wal files are recovered so we don&apos;t really does the check.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;+ How will a crashed regionserver &quot;...... and appending itself into the list of...&quot;: i.e. append itself to list of crashed servers (am I reading this wrong)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Master SSH does the work not the dead RS.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;+ Is your assumption about out-of-order replay of edits new to this feature? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. I&apos;ll amend the design doc based on your other comments. Thanks.&lt;/p&gt;


</comment>
                            <comment id="13647252" author="anoop.hbase" created="Thu, 2 May 2013 03:53:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; I also had the same question as from Stack regarding the WAL. This might be very important.  Also now we will allow the writes on the recovering region when this replay is happening. These other writes + replays might be doing flushes in btw.. Any way replays alone also might be doing flushes in between(because of memstore sizes)..  When this replays are in progress for some regions opened in a RS, now the replay requests from other RS taking some handlers.  Whether this will affect the normal functioning of the RS?  May be we can test this also IMO. The cluster is normal functioning with read,writes and then this RS down happens. So whether/how it will impact the normal read write throughput.&lt;/p&gt;</comment>
                            <comment id="13647273" author="anoop.hbase" created="Thu, 2 May 2013 04:11:06 +0000"  >&lt;p&gt;Do we need a cleaner abstraction layer for RS-&amp;gt;RS communication?  May be later when we can do a HLog to region opening RS collocation (RS where the region is newly assigned only doing the HLog split) we can do stuff in this layer so as to avoid the RS connection based calls but just get the Region ref from RS and do direct writes)&lt;/p&gt;

&lt;p&gt;As I mentioned in some above comment when we can do the multi WAL and if we go with fixed regions for a WAL (we are infact doing virtula groups of regions in RS), we can try(max try) assigning all regions in one group to a RS and give the log splitting work for those WAL to this RS then it will be 100% locality wrt the replay commands. Sounds sensible? May be in such a case the replay can create the HFiles directly avoiding the memstore write and then flushes? (Like the bulk loading way)  Some thoughts coming.. Pls correct me if I am going wrong.&lt;/p&gt;</comment>
                            <comment id="13647278" author="yuzhihong@gmail.com" created="Thu, 2 May 2013 04:19:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;we can do a HLog to region opening RS collocation&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Without multi WAL, the above implies that all regions from one failed region server be assigned to one active region server. This negates the performance benefit of distributed log splitting.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;assigning all regions in one group to a RS&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I guess the underlying assumption above is that there are several region groups in multi WAL such that we gain parallelism across multiple active region servers.&lt;/p&gt;</comment>
                            <comment id="13647280" author="anoop.hbase" created="Thu, 2 May 2013 04:24:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;Ted Yu&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Without multi WAL, the above implies that all regions from one failed region server be assigned to one active region server. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes with multi WAL only.. I was just saying it for future consideration &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I guess the underlying assumption above is that there are several region groups in multi WAL &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes that is the assumption I have made. &lt;/p&gt;</comment>
                            <comment id="13647325" author="jeffreyz" created="Thu, 2 May 2013 05:48:01 +0000"  >&lt;blockquote&gt;
&lt;p&gt;This might be very important. Also now we will allow the writes on the recovering region when this replay is happening. These other writes + replays might be doing flushes in btw.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is valid concern. Let&apos;s compare the new way with old way. old log splitting appends each WAL edit into a recovered.edits file while the new way flush disk only when memstore reaching certain size. Therefore, even with allowing writes during recovery, new distributed log replay still has better disk writing characteristics(assuming normal situations). &lt;br/&gt;
While your concern is more relevant when a system close to its disk IO or other capacity. Allowing writes could deteriorate whole system even more. I think a system operator should rate limiting in a higher level not using recovery logic to reject traffic because nodes are expected to be down at anytime and we don&apos;t want our users get affected even a system is in recovery. Being said that, we could provide a config flag to disallow writes during recovery.  &lt;/p&gt;</comment>
                            <comment id="13647328" author="stack" created="Thu, 2 May 2013 05:56:01 +0000"  >&lt;p&gt;Thinking on it, flushing after all logs recovered is a bad idea because it a special case.  Replay mutations, as is, are treated like any other inbound edit.  I think this good. &lt;/p&gt;

&lt;p&gt;Turning off WALs and flushing on the end and trying to figure what we failed to write or writing hfiles directly &amp;#8211; if you could, and I don&apos;t think you can since edits need to be sorted in an hfile &amp;#8211; and by-passing memstore and then telling the Region to pick up the new hfile when done all introduce new states that we will have to manage complicating critical recovery.&lt;/p&gt;</comment>
                            <comment id="13648947" author="jeffreyz" created="Sat, 4 May 2013 00:28:21 +0000"  >&lt;p&gt;v4 patch incorporating Stack&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13649070" author="hadoopqa" created="Sat, 4 May 2013 11:23:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12581779/hbase-7006-combined-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12581779/hbase-7006-combined-v4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 24 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5554//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13650365" author="hadoopqa" created="Tue, 7 May 2013 02:05:22 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12581779/hbase-7006-combined-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12581779/hbase-7006-combined-v4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 24 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5563//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13651661" author="jeffreyz" created="Wed, 8 May 2013 06:38:57 +0000"  >&lt;p&gt;Including following changes:&lt;br/&gt;
1) Incorporated Stack&apos;s comments&lt;br/&gt;
2) Set replayed WAL edits replication scope to null so that WAL edits created by replay command won&apos;t be double replicated.&lt;br/&gt;
3) Add support for non-existence table and column family during replay&lt;/p&gt;</comment>
                            <comment id="13651704" author="hadoopqa" created="Wed, 8 May 2013 08:27:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12582262/hbase-7006-combined-v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12582262/hbase-7006-combined-v5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 27 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessController&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5589//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13652060" author="stack" created="Wed, 8 May 2013 17:05:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;2) Set replayed WAL edits replication scope to null so that WAL edits created by replay command won&apos;t be double replicated.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How can you be sure all edits in WALs from crashed server were replicated already? &lt;/p&gt;</comment>
                            <comment id="13652074" author="jeffreyz" created="Wed, 8 May 2013 17:19:10 +0000"  >&lt;blockquote&gt;
&lt;p&gt;How can you be sure all edits in WALs from crashed server were replicated already?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is guaranteed by the replication fail over logic. Replication waits for log splitting finish and then resume replication on those wal files from failed RS. The above change just make sure we don&apos;t replicate WAL edits created by replay command again because those edits will be replicated from the original wal file.&lt;/p&gt;</comment>
                            <comment id="13652094" author="stack" created="Wed, 8 May 2013 17:31:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Nice.  Good one.&lt;/p&gt;

&lt;p&gt;Up on rb, you may have missed another set of reviews of mine.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13652106" author="jeffreyz" created="Wed, 8 May 2013 17:40:43 +0000"  >&lt;p&gt;It seems that I forgot to publish it. You should have it now. Thanks. &lt;/p&gt;</comment>
                            <comment id="13652253" author="stack" created="Wed, 8 May 2013 19:31:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Thanks.&lt;/p&gt;

&lt;p&gt;I asked about zxid.&lt;/p&gt;

&lt;p&gt;&quot;I think you mean the zxid? That&apos;s a 64bit number where the lower&lt;br/&gt;
32bits are the xid and the upper 32 bits are the epoch. The xid&lt;br/&gt;
increases for each write, the epoch increases when there is a leader&lt;br/&gt;
change. The zxid should always only increase. There was a bug where&lt;br/&gt;
the lower 32bits could roll over, however that resulted in the epoch&lt;br/&gt;
number increasing as well (64bits++) - so the constraint was&lt;br/&gt;
maintained (but the cluster would fail/lockup for another issue, I&lt;br/&gt;
fixed that in recent releases though...... Now&lt;br/&gt;
when that is about to happen it forces a new leader election).&quot;&lt;/p&gt;

&lt;p&gt;Above is from our Patrick Hunt.  Says fix is in Apache ZK (3.3.5, 3.4.4).&lt;/p&gt;

&lt;p&gt;If you look at tail of the below issue, you will see an hbase favorite user running into rollover issue:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1277&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/ZOOKEEPER-1277&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let me make sure we add to notes that folks should upgrade to these versions of zk.&lt;/p&gt;</comment>
                            <comment id="13652258" author="stack" created="Wed, 8 May 2013 19:43:17 +0000"  >&lt;p&gt;I added note to refguide that folks should run w/ newer zks and point to &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1277&quot; title=&quot;servers stop serving when lower 32bits of zxid roll over&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1277&quot;&gt;&lt;del&gt;ZOOKEEPER-1277&lt;/del&gt;&lt;/a&gt; as a justification.&lt;/p&gt;</comment>
                            <comment id="13653456" author="jeffreyz" created="Fri, 10 May 2013 01:13:05 +0000"  >&lt;p&gt;The v6 patch comes with the following changes:&lt;br/&gt;
1) Incorporated Ted&apos;s comments&lt;br/&gt;
2) Add support to remove stale recovering region znodes from previous run during master initialization&lt;br/&gt;
3) retry znode deletion&lt;br/&gt;
4) bug fixes&lt;/p&gt;</comment>
                            <comment id="13653495" author="hadoopqa" created="Fri, 10 May 2013 02:26:03 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12582559/hbase-7006-combined-v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12582559/hbase-7006-combined-v6.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 31 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.util.TestHBaseFsck&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5620//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13654707" author="jeffreyz" created="Fri, 10 May 2013 18:41:22 +0000"  >&lt;p&gt;Incorporated Ted&apos;s latest comments.&lt;/p&gt;</comment>
                            <comment id="13654782" author="hadoopqa" created="Fri, 10 May 2013 20:00:29 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12582663/hbase-7006-combined-v7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12582663/hbase-7006-combined-v7.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 31 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestHCM&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5625//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13654874" author="stack" created="Fri, 10 May 2013 21:37:30 +0000"  >&lt;p&gt;Where are we w/ this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;?  What is your sense?  Can you summarize.  Are all the reviews up in rb addressed in this v7?&lt;/p&gt;</comment>
                            <comment id="13655041" author="jeffreyz" created="Fri, 10 May 2013 23:53:04 +0000"  >&lt;p&gt;V8 patch: Rebased and one line change add &quot;checkOpen()&quot; into replay command(I found &quot;multi, mutate and multiGet&quot; all missing checkOpen call. I&apos;ll file a separate JIRA on this). &lt;/p&gt;

&lt;p&gt;Summary on the JIRA:&lt;/p&gt;

&lt;p&gt;All review comments are addressed. Unit tests passed and no issue is found so far from integration test IntegrationTestDataIngestWithChaosMonkey(will keeping running for a while). &lt;/p&gt;

&lt;p&gt;I think we can check it in now.&lt;/p&gt;

&lt;p&gt;Next steps are:&lt;/p&gt;

&lt;p&gt;1) Re-run performance tests to avoid any performance degradation from recent changes.&lt;br/&gt;
2) Add configuration to &quot;disallow writes during recovery&quot;, which I intentionally leave it out from the combined patch.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13655100" author="hadoopqa" created="Sat, 11 May 2013 01:40:22 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12582743/hbase-7006-combined-v8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12582743/hbase-7006-combined-v8.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 31 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5635//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13656133" author="yuzhihong@gmail.com" created="Mon, 13 May 2013 17:18:12 +0000"  >&lt;p&gt;I ran test suite through patch v6 twice, through v8 once.&lt;br/&gt;
Result was good.&lt;/p&gt;

&lt;p&gt;TestHBaseFsck failed once in v8 run but wasn&apos;t reproduced.&lt;/p&gt;</comment>
                            <comment id="13657680" author="stack" created="Tue, 14 May 2013 23:30:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; The &apos;next steps&apos; are to be done in other issues, not on this one?  Have you run the IntegrationTestBigLinkedList with this in place killing servers as it runs?  I am game for checking it in.  It has a good bit of review and if we have not found egregious error by now, then we get what we deserve.  Nice one.&lt;/p&gt;</comment>
                            <comment id="13657812" author="jeffreyz" created="Wed, 15 May 2013 02:20:24 +0000"  >&lt;p&gt;v9 patch is a rebase patch. I&apos;ve run the integration test IntegrationTestDataIngestWithChaosMonkey which does data ingestion with verification and randomly kill a region server/master periodically.&lt;/p&gt;

&lt;p&gt;I think we can check the v9 patch in. Meanwhile I&apos;ll run more integration tests.&lt;/p&gt;</comment>
                            <comment id="13657848" author="hadoopqa" created="Wed, 15 May 2013 03:25:10 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12583262/hbase-7006-combined-v9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12583262/hbase-7006-combined-v9.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 34 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5693//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13657863" author="yuzhihong@gmail.com" created="Wed, 15 May 2013 03:37:58 +0000"  >&lt;p&gt;+1 on patch v9.&lt;/p&gt;</comment>
                            <comment id="13657893" author="stack" created="Wed, 15 May 2013 04:28:39 +0000"  >&lt;p&gt;Committed to 0.95 and trunk.  Thanks for the nice feature Jeffrey.  Nice work.&lt;/p&gt;

&lt;p&gt;Please add a fat release note on what this facility adds and do some cleanup of the old issues outstanding.&lt;/p&gt;</comment>
                            <comment id="13658089" author="jeffreyz" created="Wed, 15 May 2013 06:00:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; Thanks! I&apos;ll keep working on the follow up items and add a release note accordingly.&lt;/p&gt;</comment>
                            <comment id="13658159" author="hudson" created="Wed, 15 May 2013 08:06:12 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #194 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/194/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/194/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay (Revision 1482676)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/exceptions/RegionInRecoveryException.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySource.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/protobuf/Admin.proto&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/protobuf/hbase.proto&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/MetaServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LastSequenceId.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsWALEditsReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEditsReplaySink.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoveringRegionWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorExceptionWithAbort.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13658188" author="hudson" created="Wed, 15 May 2013 09:18:25 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #4119 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4119/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4119/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay (Revision 1482675)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/exceptions/RegionInRecoveryException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Admin.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/hbase.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/MetaServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LastSequenceId.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsWALEditsReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEditsReplaySink.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoveringRegionWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorExceptionWithAbort.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13658383" author="hudson" created="Wed, 15 May 2013 14:09:48 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #100 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/100/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/100/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay (Revision 1482676)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/exceptions/RegionInRecoveryException.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySource.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/protobuf/Admin.proto&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-protocol/src/main/protobuf/hbase.proto&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/MetaServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LastSequenceId.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsWALEditsReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEditsReplaySink.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoveringRegionWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorExceptionWithAbort.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13658423" author="hudson" created="Wed, 15 May 2013 15:03:47 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #531 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/531/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/531/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay (Revision 1482675)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/exceptions/RegionInRecoveryException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsEditsReplaySourceImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Admin.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/hbase.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/MetaServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LastSequenceId.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/MetricsWALEditsReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEditsReplaySink.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoveringRegionWatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorExceptionWithAbort.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13658644" author="jeffreyz" created="Wed, 15 May 2013 18:36:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;tedyu@apache.org&quot;&gt;Ted Yu&lt;/a&gt; Attached a NPE fix for the issue that Ted found an intermittent failure &lt;a href=&quot;http://54.241.6.143/job/HBase-0.95/org.apache.hbase$hbase-server/269/testReport/org.apache.hadoop.hbase.master/TestDistributedLogSplitting/testWorkerAbort/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-0.95/org.apache.hbase$hbase-server/269/testReport/org.apache.hadoop.hbase.master/TestDistributedLogSplitting/testWorkerAbort/&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13658673" author="stack" created="Wed, 15 May 2013 19:02:23 +0000"  >&lt;p&gt;I applied the addendum to trunk and 0.95.  Thanks lads.&lt;/p&gt;</comment>
                            <comment id="13658964" author="hudson" created="Wed, 15 May 2013 22:57:42 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #196 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/196/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/196/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay; ADDENDUM (Revision 1483009)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13659154" author="hudson" created="Thu, 16 May 2013 02:35:38 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #4122 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4122/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4122/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay; ADDENDUM (Revision 1483011)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13659234" author="hudson" created="Thu, 16 May 2013 05:19:49 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #532 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/532/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/532/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay; ADDENDUM (Revision 1483011)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13659268" author="hudson" created="Thu, 16 May 2013 06:13:05 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #101 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/101/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/101/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay; ADDENDUM (Revision 1483009)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13659710" author="rajesh23" created="Thu, 16 May 2013 17:04:02 +0000"  >&lt;p&gt;HMaster changes broken TestMasterShutdown.testMasterShutdownBeforeStartingAnyRegionServer&lt;/p&gt;</comment>
                            <comment id="13659719" author="rajesh23" created="Thu, 16 May 2013 17:11:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;&lt;br/&gt;
Is it fine to continue master initialization even .META. region not assigned?&lt;/p&gt;</comment>
                            <comment id="13659748" author="jeffreyz" created="Thu, 16 May 2013 17:36:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt; After I reset my build to the point right after 7006 check in using &quot;git reset --hard a3e0004e26a68cf58031330a477344b225aaf901&quot;, I see the test pass. I guess some checkins after my patch caused the test failure. I&apos;ll debug a little bit more to see what caused the issue. &lt;/p&gt;</comment>
                            <comment id="13659789" author="rajesh23" created="Thu, 16 May 2013 18:16:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;&lt;br/&gt;
Earlier If META assignment failed then we will return from initialization&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!assignMeta(status)) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In side assignMeta&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       &lt;span class=&quot;code-comment&quot;&gt;// Make sure a .META. location is set.
&lt;/span&gt;-      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!isMetaLocation()) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
-      &lt;span class=&quot;code-comment&quot;&gt;// This guarantees that the transition assigning .META. has completed
&lt;/span&gt;-      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.assignmentManager.waitForAssignment(HRegionInfo.FIRST_META_REGIONINFO);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But now in this patch the logic got changed and even if META not assigned also initialization getting continued and hanging at .META. migration while locating meta from zk.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Make sure meta assigned before proceeding.
&lt;/span&gt;    status.setStatus(&lt;span class=&quot;code-quote&quot;&gt;&quot;Assigning Meta Region&quot;&lt;/span&gt;);
    assignMeta(status);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13659801" author="jeffreyz" created="Thu, 16 May 2013 18:28:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt; That&apos;s a bug before. Though we return false to break the initialization but there is no return from caller finishInitialization so we continue even master isn&apos;t initialized fully. The change is expecting assignMeta to throw exception to stop master starts up. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        finishInitialization(startupStatus, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
        loop();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13659817" author="rajesh23" created="Thu, 16 May 2013 18:43:55 +0000"  >&lt;p&gt;if any failures during .META. assignment other than master shutdown/stop we are infinitely waiting until .META. is assigned.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    enableServerShutdownHandler();
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.catalogTracker.waitForMeta();
    &lt;span class=&quot;code-comment&quot;&gt;// Above check waits &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; general meta availability but &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; does not
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// guarantee that the transition has completed
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.assignmentManager.waitForAssignment(HRegionInfo.FIRST_META_REGIONINFO);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Only chance we will come out from initialization before assigning META is master shutdown/stop.&lt;br/&gt;
then any way we will not block in loop as well.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void loop() {
    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; lastMsgTs = 0l;
    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; now = 0l;
    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (!&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.stopped) {
      now = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((now - lastMsgTs) &amp;gt;= &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.msgInterval) {
        doMetrics();
        lastMsgTs = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
      }
      stopSleeper.sleep();
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13659820" author="stack" created="Thu, 16 May 2013 18:46:42 +0000"  >&lt;p&gt;I&apos;m looking at TestMasterShutdown too... lets do it over in new issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8560&quot; title=&quot;TestMasterShutdown failing in trunk 0.95/trunk -- &amp;quot;Unable to get data of znode /hbase/meta-region-server because node does not exist (not an error)&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8560&quot;&gt;&lt;del&gt;HBASE-8560&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13659831" author="rajesh23" created="Thu, 16 May 2013 19:00:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;&lt;br/&gt;
Throwing exception also fine too..its not a problem...&lt;/p&gt;</comment>
                            <comment id="13659880" author="jeffreyz" created="Thu, 16 May 2013 19:38:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt; Thanks for the good catch. It turns out my refactoring missed to handle the master shutting down case. I submitted a patch under hbase-8560. &lt;/p&gt;</comment>
                            <comment id="13660428" author="zjushch" created="Fri, 17 May 2013 07:24:48 +0000"  >&lt;p&gt;Great work!&lt;/p&gt;

&lt;p&gt;One question:&lt;br/&gt;
From the doc, I see &quot;last flushed sequence id of the region is stored in ZK&quot;&lt;br/&gt;
I think we should store the last flushed sequence id for each store of region, otherwise would cause the problem of data correctness when replaying logs.&lt;/p&gt;</comment>
                            <comment id="13660436" author="jeffreyz" created="Fri, 17 May 2013 07:34:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjushch&quot; class=&quot;user-hover&quot; rel=&quot;zjushch&quot;&gt;chunhui shen&lt;/a&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I think we should store the last flushed sequence id for each store of region, otherwise would cause the problem of data correctness when replaying logs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You&apos;re right. Actually yesterday &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; showed me &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6059&quot; title=&quot;Replaying recovered edits would make deleted data exist again&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6059&quot;&gt;&lt;del&gt;HBASE-6059&lt;/del&gt;&lt;/a&gt;, I realized that we need to do the above as you suggested. I considered that before and thought storing one id per region is enough which turns out not true. I&apos;ll fix that as a follow up issue. Thanks for mentioning this!&lt;/p&gt;</comment>
                            <comment id="13660444" author="ram_krish" created="Fri, 17 May 2013 07:43:47 +0000"  >&lt;p&gt;Good one Chunhui.&lt;/p&gt;</comment>
                            <comment id="13660851" author="yuzhihong@gmail.com" created="Fri, 17 May 2013 16:53:32 +0000"  >&lt;p&gt;I created &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8573&quot; title=&quot;Store last flushed sequence id for each store of region for Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8573&quot;&gt;&lt;del&gt;HBASE-8573&lt;/del&gt;&lt;/a&gt; for storing last flushed sequence id for each store of region in zookeeper.&lt;/p&gt;</comment>
                            <comment id="13660897" author="yuzhihong@gmail.com" created="Fri, 17 May 2013 17:41:22 +0000"  >&lt;p&gt;Before &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8573&quot; title=&quot;Store last flushed sequence id for each store of region for Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8573&quot;&gt;&lt;del&gt;HBASE-8573&lt;/del&gt;&lt;/a&gt; is resolved, I think we should change the following to false:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; DEFAULT_DISTRIBUTED_LOG_REPLAY_CONFIG = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13660916" author="yuzhihong@gmail.com" created="Fri, 17 May 2013 18:02:18 +0000"  >&lt;p&gt;Addendum 2 turns off distributed log replay by default.&lt;/p&gt;</comment>
                            <comment id="13661047" author="stack" created="Fri, 17 May 2013 21:02:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjushch&quot; class=&quot;user-hover&quot; rel=&quot;zjushch&quot;&gt;chunhui shen&lt;/a&gt; Thanks for keeping an eye out.&lt;/p&gt;

&lt;p&gt;+1 on addendum for now (adjust release note to say this is off for now)&lt;/p&gt;</comment>
                            <comment id="13661081" author="jeffreyz" created="Fri, 17 May 2013 21:59:24 +0000"  >&lt;p&gt;Looks good to me(+1). Thanks.&lt;/p&gt;</comment>
                            <comment id="13661094" author="yuzhihong@gmail.com" created="Fri, 17 May 2013 22:18:25 +0000"  >&lt;p&gt;I got the following test failure:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testHBaseFsck(org.apache.hadoop.hbase.util.TestHBaseFsck)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;[]&amp;gt; but was:&amp;lt;[EXPIRED_TABLE_LOCK]&amp;gt;
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.failNotEquals(Assert.java:743)
        at org.junit.Assert.assertEquals(Assert.java:118)
        at org.junit.Assert.assertEquals(Assert.java:144)
        at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.assertNoErrors(HbckTestingUtil.java:85)
        at org.apache.hadoop.hbase.util.TestHBaseFsck.testHBaseFsck(TestHBaseFsck.java:146)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the above was not related to addendum.&lt;/p&gt;</comment>
                            <comment id="13661118" author="yuzhihong@gmail.com" created="Fri, 17 May 2013 22:49:48 +0000"  >&lt;p&gt;Addendum integrated to 0.95 and trunk.&lt;/p&gt;

&lt;p&gt;Thanks for the reviews, Stack and Jeff.&lt;/p&gt;</comment>
                            <comment id="13661190" author="hudson" created="Sat, 18 May 2013 01:00:04 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #202 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/202/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/202/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay, Addendum disables the feature by default (Revision 1484021)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13661193" author="hudson" created="Sat, 18 May 2013 01:03:46 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #4128 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4128/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4128/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay, Addendum disables the feature by default (Revision 1484022)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13661219" author="hudson" created="Sat, 18 May 2013 01:58:18 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #103 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/103/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/103/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay, Addendum disables the feature by default (Revision 1484021)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13661241" author="hudson" created="Sat, 18 May 2013 03:17:08 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #534 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/534/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/534/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7006&quot; title=&quot;[MTTR] Improve Region Server Recovery Time - Distributed Log Replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7006&quot;&gt;&lt;del&gt;HBASE-7006&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;MTTR&amp;#93;&lt;/span&gt; Improve Region Server Recovery Time - Distributed Log Replay, Addendum disables the feature by default (Revision 1484022)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13673878" author="jeffreyz" created="Tue, 4 Jun 2013 00:42:41 +0000"  >
&lt;p&gt;I conducted a performance test against trunk code + hbase-8680 and hbase-8666. The goal is to verify there is no unexpected performance regression. In the tests, 44 WAL files are recovered in about total 274M size on a 5 EC2 m1.large nodes environment(1 master, 4 region servers).&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Arecapofthetworecoveringmodeincomparison%3A&quot;&gt;&lt;/a&gt;A recap of the two recovering mode in comparison:&lt;/h5&gt;
&lt;p&gt;1) recovered edits files creation recovery includes following steps: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;creating recovered edits files per wal per region&lt;/li&gt;
	&lt;li&gt;re-assign failed regions&lt;/li&gt;
	&lt;li&gt;replay recovered edits files during post region open task&lt;/li&gt;
	&lt;li&gt;region are opened for writes &amp;amp; reads&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2) logReplay contains following steps:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;re-assign failed regions&lt;/li&gt;
	&lt;li&gt;regions are opened for writes&lt;/li&gt;
	&lt;li&gt;replay wal edits directly to assigned regions&lt;/li&gt;
	&lt;li&gt;regions are opened for reads&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;&lt;a name=&quot;LogSplittingwithcreationofrecoverededitsfiles&quot;&gt;&lt;/a&gt;Log Splitting with creation of recovered edits files&lt;/h5&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Number of Regions in each WAL file&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Log Splitting Elapsed Time(ms)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Recovered Edits Replay Elapsed Time(ms)*&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Recovery Time For Reads(ms)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Recovery Time For Writes(ms)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;80&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;201263&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100631&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;301894&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;301894&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;160&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;256325&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;128160&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;384485&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;384485&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;320&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;283514&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;141757&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;425271&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;425271&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;ul&gt;
	&lt;li&gt;During tests I didn&apos;t capture the recovered edits file replay(need to use bulk assign sync mode) accurately so I based on previous runs and used 0.5 * splitting time as an estimate&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;&lt;a name=&quot;DistributedLogReplay&quot;&gt;&lt;/a&gt;Distributed Log Replay&lt;/h5&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Number of Regions in each WAL file&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Log Splitting Elapsed Time(ms)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Recovered Edits Replay Elapsed Time(ms)*&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Recovery Time For Reads(ms)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Recovery Time For Writes*(ms)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;80&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;80953&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;n/a&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;80953&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;lt; 5000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;160&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;91656&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;n/a&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;91656&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;lt; 5000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;320&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95053&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;n/a&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95053&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;lt; 5000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;ul&gt;
	&lt;li&gt;Due to the same above reason that I didn&apos;t use bulk assign sync mode so I didn&apos;t get the accurate numbers. Opening region normally takes about several secs when there is no recovered edits file replay.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The cluster I used seems have slow disk throughput while it&apos;s good enough to make sure that distributedLogReplay has better performance than recovered edits creation mode after checked into trunk.&lt;/p&gt;</comment>
                            <comment id="13675513" author="eclark" created="Wed, 5 Jun 2013 01:18:58 +0000"  >&lt;p&gt;So talking about this patch with Himanshu and I had a few concerns.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;ConcernOne&quot;&gt;&lt;/a&gt;Concern One&lt;/h3&gt;

&lt;p&gt;I&apos;m pretty sure there is an issue with opening a region for edits before all logs are finished replaying.  To illustrate:&lt;/p&gt;

&lt;p&gt;Say there&apos;s a table with cf that has VERSIONS = 2.&lt;br/&gt;
For all edits the rowkey is the same.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;There&apos;s a log with: [ A (ts = 0), B (ts = 0) ]&lt;/li&gt;
	&lt;li&gt;Replay the first half of the log.&lt;/li&gt;
	&lt;li&gt;A user puts in C (ts = 0)&lt;/li&gt;
	&lt;li&gt;Memstore has to flush&lt;/li&gt;
	&lt;li&gt;A new Hfile will be created with [ C, A ] and MaxSequenceId = C&apos;s seqid.&lt;/li&gt;
	&lt;li&gt;Replay the rest of the Log.&lt;/li&gt;
	&lt;li&gt;Flush&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;You&apos;ll get either C, A when a get is issued.&lt;/p&gt;

&lt;p&gt;C, B is the expected result.&lt;/p&gt;

&lt;p&gt;We have promised that edits will be ordered by timestamp, then sequence id.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;ConcernTwo&quot;&gt;&lt;/a&gt;Concern Two&lt;/h3&gt;

&lt;p&gt;I think there&apos;s an issue with duplicating edits if there is a failure while replaying.  To illustrate:&lt;/p&gt;

&lt;p&gt;Say there&apos;s a table with a column family with Versions = 3&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;There&apos;s a log with edits who&apos;s timestamps are [ 10, 11, 12 ]&lt;/li&gt;
	&lt;li&gt;assign the region for replay&lt;/li&gt;
	&lt;li&gt;Start replaying&lt;/li&gt;
	&lt;li&gt;Fail after [ 10, 11 ]&lt;/li&gt;
	&lt;li&gt;Now there are two logs [ 10, 11, 12] [ 10, 11 ]&lt;/li&gt;
	&lt;li&gt;Master sees that replaying failed and that the rs hosting the region failed.&lt;/li&gt;
	&lt;li&gt;it will replay both logs.&lt;/li&gt;
	&lt;li&gt;You will now have [ 12, 11, 11 ]&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Any get to that table will get [ 12, 11, 11]&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;12, 11, 10&amp;#93;&lt;/span&gt; is expected.&lt;/p&gt;


&lt;p&gt;This is fixable if we:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Don&apos;t replay wal edits with isReaply = true&lt;/li&gt;
	&lt;li&gt;and only remove old logs after all the memstores that the log got replayed into have fully flushed.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This is hard since the memstores are all over and hard to keep track of.&lt;/p&gt;

&lt;p&gt;or:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Don&apos;t append the replayed edits to the wal&lt;/li&gt;
	&lt;li&gt;while replaying if the memstore needs to flush, flush the hfiles out to a temp location.&lt;/li&gt;
	&lt;li&gt;Move the Hfiles in after all the edits are recovered.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This is hard as we&apos;ll have to meddle with how we flush the memstore.&lt;/p&gt;</comment>
                            <comment id="13675530" author="yuzhihong@gmail.com" created="Wed, 5 Jun 2013 01:56:42 +0000"  >&lt;p&gt;for concern #1, step 2 (log replay) implies the crash of original region server.&lt;br/&gt;
In step 3, how would C carry timestamp 0 which is the same as A and B ?&lt;/p&gt;</comment>
                            <comment id="13675535" author="jeffreyz" created="Wed, 5 Jun 2013 02:23:48 +0000"  >&lt;p&gt;Thanks for the concerns!&lt;/p&gt;

&lt;p&gt;Since a row is keyed by row, column family, column qualifier and timestamp. If we send the same put like the following repeatedly&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
put &apos;t3&apos;, &apos;row1&apos;, &apos;test_cf:c1&apos;,&apos;1&apos;, 11
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;scan will only return one row. I tested with the following raw scan &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scan &apos;t3&apos;, {RAW=&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, VERSIONS=&amp;gt;100}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The test steps I&apos;m using are:&lt;br/&gt;
1) &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;create &apos;t3&apos;, {NAME =&amp;gt; &apos;test_cf&apos;, VERSIONS =&amp;gt; 5}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;2) &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;put &apos;t3&apos;, &apos;row1&apos;, &apos;test_cf:c1&apos;,&apos;1&apos;, 10&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3) &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;put &apos;t3&apos;, &apos;row1&apos;, &apos;test_cf:c1&apos;,&apos;1&apos;, 11 (10 times)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;4) &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scan &apos;t3&apos;, {RAW=&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, VERSIONS=&amp;gt;100}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I only got:&lt;br/&gt;
 row1                                          column=test_cf:c1, timestamp=11, value=1&lt;br/&gt;
 row1                                          column=test_cf:c1, timestamp=10, value=1&lt;/p&gt;

&lt;p&gt;For your first concern, I think the result should be either B or C. &lt;/p&gt;</comment>
                            <comment id="13675646" author="eclark" created="Wed, 5 Jun 2013 06:54:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;In step 3, how would C carry timestamp 0 which is the same as A and B ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You can specify the timestamp on put&apos;s.  0 isn&apos;t special here.  It could be any timestamp that&apos;s the same.&lt;/p&gt;

&lt;p&gt;So I bring up the seqId as a concern because of:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://archive.apache.org/dist/hbase/docs/versions.html#d397e2960&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://archive.apache.org/dist/hbase/docs/versions.html#d397e2960&lt;/a&gt;
	&lt;ul&gt;
		&lt;li&gt;&quot;To overwrite an existing value, do a put at exactly the same row, column, and version as that of the cell you would overshadow.&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7763?focusedCommentId=13572592&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13572592&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-7763?focusedCommentId=13572592&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13572592&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/KeyValueHeap.html#176&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/KeyValueHeap.html#176&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Things in the memstore may be upserted (Probably a bug that should be doc&apos;d or addressed).  But sequence Id sorting is the reason that compaction must always choose contiguous files.  If that changes then the compaction algorithm can be very different from what it currently is.&lt;/p&gt;</comment>
                            <comment id="13676308" author="stack" created="Wed, 5 Jun 2013 20:27:27 +0000"  >&lt;p&gt;On &apos;Concern One&apos;, we would get back B.  The B would be in memstore when region was flipped readable.  memstore gets precedence over hfiles.  We should get back C though.  Even if we held up flushes until the region were flipped to readable, we&apos;d have a problem (because B coming in later would overwrite C).  But Jeffrey, don&apos;t you have replayed edits go into a different memstore?  Or if you don&apos;t, maybe they should... and this other memstore should sort after the first memstore?  You could flush the memstore of replayed edits but not the memstore of new edits, not until the region had flipped readable?&lt;/p&gt;

&lt;p&gt;(Good find E and H).&lt;/p&gt;

&lt;p&gt;On concern two, what Jeffrey says above, we suppress versions of same timestamp so only the latest version of a timestamp returned so we&apos;d get 12, 11, 10.&lt;/p&gt;</comment>
                            <comment id="13676458" author="jeffreyz" created="Wed, 5 Jun 2013 23:12:04 +0000"  >&lt;p&gt;I think about the issue whole morning. Also I discussed this with other folks. Basically the root issue is to maintain the receiving order during recovery for puts with exact same key + version(timestamp). Since log recovery process could work on multiple wal files at same time, the order of replay isn&apos;t guaranteed to be in the receiving order. I&apos;m listing several options below to see how others think.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Optionone%28thesimplestone%29&quot;&gt;&lt;/a&gt;Option one(the simplest one) &lt;/h5&gt;
&lt;p&gt;Document this limitation in the release note. Assuming the same version update is a rare usage pattern.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Optiontwo%28stillsimplebuthacky%29&quot;&gt;&lt;/a&gt;Option two(still simple but hacky)&lt;/h5&gt;
&lt;p&gt;a) disallow writes during recovery&lt;br/&gt;
b) hold flush till all wals of a recovering region are replayed. Memstore should hold because we only recover unflushed wal edits.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Optionthree%28multiplememstores%29&quot;&gt;&lt;/a&gt;Option three(multiple memstores)&lt;/h5&gt;
&lt;p&gt;a) Let splitlogworker pick wals of a failed RS in order instead of random. Say a failed RS has WAL1, WAL2, WAL3,... WALk. a worker will only pick WAL2 if WAL1 is done(or errored) etc.&lt;br/&gt;
b) During replay, we pass original wal sequence ids of edits to the receiving RS&lt;br/&gt;
c) In receiving RS, we bucket WAL files to a different memstore during replaying and use the original sequence Ids. Say wal1-wal4 to memstore1, wal5-wal10 to memstore2 etc. We only flush the bucket memstore when all wals inside the bucket are replayed. all wals can be replayed concurrently.&lt;br/&gt;
d) writes from normal traffic(allow writes during recovery) are put in a different memstore as of today and flush normally with new sequenceIds.  &lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Optionfour&quot;&gt;&lt;/a&gt;Option four&lt;/h5&gt;
&lt;p&gt;a) During replay, we pass original wal sequence ids&lt;br/&gt;
b) for each wal edit, we store each edit&apos;s sequence id along with its key. &lt;br/&gt;
c) during scanning, we use the original sequence id if it&apos;s present otherwise its store file sequence Id&lt;br/&gt;
d) compaction can just leave put with max sequence id&lt;/p&gt;





</comment>
                            <comment id="13676479" author="jeffreyz" created="Wed, 5 Jun 2013 23:24:40 +0000"  >&lt;p&gt;A small correction for option three: &lt;blockquote&gt;&lt;p&gt;a worker will only pick WAL2 if WAL1 is done(or errored) etc.&lt;/p&gt;&lt;/blockquote&gt; should be &lt;blockquote&gt;&lt;p&gt;a worker will only pick WAL2 if WAL1 is taken by another worker&lt;/p&gt;&lt;/blockquote&gt;&lt;/p&gt;</comment>
                            <comment id="13676513" author="stack" created="Wed, 5 Jun 2013 23:51:21 +0000"  >&lt;p&gt;On option two, if WALs are being replayed without order, couldn&apos;t an edit from WAL 1 (an old WAL) overwrite an edit from WAL 3 (a newer WAL) because memstore does not consider sequenceid?&lt;/p&gt;

&lt;p&gt;I do not think option three will work.  We want to be able to put in place multiple WALs per server in the near future and in this case the sequenceids will be spread about amongst a few logs (probably two is enough).  Since the sequenceids will be spread across N WALs, splitlogworker will not be able to deduce WAL order since some WALs will be contemporaneous having been written to in // (In other words, replay is bringing on sooner a problem we are going to need to solve anyways).&lt;/p&gt;

&lt;p&gt;In Option three, how will you bucket WALs?  You will need to pass in the the WAL file name when you do the Put?  How will you signal the regionserver the WAL is done?  A special edit?&lt;/p&gt;

&lt;p&gt;On replay, do you need a memstore that considers sequenceid such that when two edits w/ same coordinate, the one w/ the latest sequenceid is retained rather than the last written?&lt;/p&gt;

&lt;p&gt;What is the worst case if we could not flush until all WALs replayed?&lt;/p&gt;

&lt;p&gt;Lets say 2k regions on two servers?  That means one server will need to take all edits from 1k regions?   Lets say there were 256k WALs?  At 128M per WAL that is 32G of edits we&apos;d have to keep in memory w/o flushing?  If were also taking writes for all 2k regions, that would be extra memory pressure.  We&apos;d fall over in this case.&lt;/p&gt;

&lt;p&gt;Could the replay tell the RS it was replaying a single WAL and when it was done?  For WAL it could pass the sequence ids and a hash of the WAL path.  Not sure how it would flag the replay is done since in distributed split, a RS could be taking on multiple WAL edits at a time... (so can not treat the arrival of a new WAL file hash as meaning we are done w/ the old file).  Region server could take on the edits into a special single-WAL memstore.  Region server could keep taking on edits from WALs and keep them in memory until it hit memory barrier.  We could then flush these per WAL memstores as hfiles w/ their sequence ids.  If the flush didn&apos;t get all of a WAL, that should be fine.  Would be lots of hfiles possibly but having to flush would be rare I&apos;d say (RS w/ 1k regions and 256 WALs would be rare).&lt;/p&gt;
</comment>
                            <comment id="13676549" author="jeffreyz" created="Thu, 6 Jun 2013 00:53:41 +0000"  >&lt;blockquote&gt;
&lt;p&gt;On option two, if WALs are being replayed without order, couldn&apos;t an edit from WAL 1 (an old WAL) overwrite an edit from WAL 3 (a newer WAL) because memstore does not consider sequenceid?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You&apos;re right. Option2 has to consider original wal sequenceId as well.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In Option three, how will you bucket WALs? You will need to pass in the the WAL file name when you do the Put? How will you signal the regionserver the WAL is done? A special edit?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I need to pass WAL file name(or its hash) inside each replay batch. Receiving RS can put watcher on the split log file deletion/done ZK events and flush a bucket memstore when all log files of the bucket are recovered. Bucket logic is controlled by receiving RS and configuration. Since all the info are in ZK so receiving RS can determine which files belong to which bucket.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Lets say 2k regions on two servers? That means one server will need to take all edits from 1k regions? Lets say there were 256k WALs? At 128M per WAL that is 32G of edits we&apos;d have to keep in memory w/o flushing? If were also taking writes for all 2k regions, that would be extra memory pressure. We&apos;d fall over in this case.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I guess the 2k regions on two servers is a long term goal for us. We could add a memory limit for all memstore opened for replay. If the limit is exceeded, the receiving RS rejects replays. In addition it could also pick a memstore and resign work items for the store and tell the playing RS to reassign the work item(wal file).&lt;/p&gt;

&lt;p&gt;I like your single-WAL memstore flush approach(a special case with number of wal per bucket=1). This way keeps memory management &amp;amp; flush simpler while at cost of more IOs. We could implement this at the beginning. Possibly group more log files for flush depending on how multiple WAL implementation goes.&lt;/p&gt;

&lt;p&gt;Thanks! &lt;/p&gt;





</comment>
                            <comment id="13677402" author="v.himanshu" created="Thu, 6 Jun 2013 19:22:10 +0000"  >&lt;p&gt;Thanks for the above discussion. I have some follow up questions on Option 2/3:&lt;/p&gt;

&lt;p&gt;1. If I am reading it correct, Option 2/3 are preserving the sequenceId of the old wal file? Does that mean the WAL edit created at the new RS for this entry would have old sequenceId? Or something else?&lt;br/&gt;
When a region is opened, it reads the max sequence Ids from its StoreFiles and sets the FSHlog counter to it (if the counter is at some lower value). If we are keeping the original sequence IDs, a WAL file could have a random distribution of sequenceIds (would not be tightly ascending as we have it now). Could there be any gotcha here? Such as handling chain fail-over.&lt;/p&gt;

&lt;p&gt;2. Another question is, initially we had one recovered.edits file per WAL; now we planning one HFile per WAL.&lt;br/&gt;
Looking at this, saving on number of I/O (and NN ops) is not that much IMHO as it is the same number of files as such? With larger number of small files, it could lead to more compaction. Though stripe compaction could help, but that&apos;s a different thing (and I haven&apos;t looked at the compaction code).  Bucketing WALs is definitely better.&lt;/p&gt;</comment>
                            <comment id="13677449" author="jeffreyz" created="Thu, 6 Jun 2013 20:15:27 +0000"  >&lt;p&gt;I created &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8701&quot; title=&quot;distributedLogReplay need to apply wal edits in the receiving order of those edits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8701&quot;&gt;&lt;del&gt;HBASE-8701&lt;/del&gt;&lt;/a&gt; and linked it to this JIRA to address the concerns from Elliot and Himanshu.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When a region is opened, it reads the max sequence Ids from its StoreFiles and sets the FSHlog counter to it (if the counter is at some lower value). If we are keeping the original sequence IDs, a WAL file could have a random distribution of sequenceIds (would not be tightly ascending as we have it now). Could there be any gotcha here? Such as handling chain fail-over.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We have to use skip wal option here.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Another question is, initially we had one recovered.edits file per WAL; now we planning one HFile per WAL&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is a good question. The benefits are still no recovered.edits related IOs and allow writes during recovery. Currently we already created many hfiles because we flush after each recovered edits replay. I&apos;m planning to use a config to control the new behavior because the issue we&apos;re trying to address isn&apos;t a common usage scenario. Later we can introduce bucketing for optimization this part.&lt;/p&gt;</comment>
                            <comment id="13677469" author="devaraj" created="Thu, 6 Jun 2013 20:29:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m planning to use a config to control the new behavior because the issue we&apos;re trying to address isn&apos;t a common usage scenario.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Don&apos;t think this is a good idea since if this config is disabled, and we have a scenario where the problem surfaces, it&apos;d lead to data consistency issues. If we want to have a config for having some control, I&apos;d vote we instead have a config that would disallow writes during recovery, or disallow operations (with timestamps?) that would lead to this unpredictability of ordering. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13677473" author="yuzhihong@gmail.com" created="Thu, 6 Jun 2013 20:32:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;have a config that would disallow writes during recovery, or disallow operations (with timestamps?)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Both are fine with me.&lt;/p&gt;</comment>
                            <comment id="13677582" author="stack" created="Thu, 6 Jun 2013 22:10:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;We have to use skip wal option here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was hoping to avoid our doing skip-wal for reasons argued above, that replaying edits w/ skip WAL enabled introduces more states and will complicate replay but old edits coming into the new server getting new seqids will itself make for some new interesting states (If the server we are playing into crashes before all is flushed, it will have in its WALs edits where the sequenceid for &apos;B&apos;, is &amp;gt; that for &apos;C&apos;, so on its recovery, &apos;B&apos;, will come out when we want &apos;C&apos;, the last edit inserted at a particular coordinate).&lt;/p&gt;

&lt;p&gt;So, if no WAL, what happens when we need to flush a memstore or a background replay memstore (the one-memstore-per-region we discuss above)?  What seqid will we write out into the hfile if we have to flush memory?  I suppose if this replay backing memstore had the old WAL seqid, it would be legit to use these.  The flushed file would sort properly with an old seqid (but then this would be a different kind of flush, one where you dictate the seqid file rather than take what is current in the server &amp;#8211; that will be intrusive to change).&lt;/p&gt;

&lt;p&gt;We&apos;d have to use the old ids in case we had to flush midway through a WAL (I suppose we say this already above)&lt;/p&gt;

&lt;p&gt;But thinking more on the per-WAL replay memstore, there are kinks to figure (apart from the one above where we want to have a flush w/ a seqid that is not the servers current max seqid).  As hfiles contain sorted kvs but the edits in the old WAL not in sort order, if we sort the edits so we can flush the hfile, then we&apos;ll have seqids not-in-order.  Do we take the highest seqid in the hfile as the hfiles&apos; seqid?  This would be different to how we usually write hfiles.  There could be issues in here.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Another question is, initially we had one recovered.edits file per WAL; now we planning one HFile per WAL.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would be only if we had to flush.  We&apos;d keep per-WAL replay memstore so if we have to flush, the file written out  &amp;#8211; this would be at an extreme.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;I&apos;m planning to use a config to control the new behavior because the issue we&apos;re trying to address isn&apos;t a common usage scenario.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I&apos;d vote we instead have a config that would disallow writes during recovery&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 on disabling writes during recovery for now.  It is this that is adding the complication.  If we disable writes during recovery, we can turn on distributed log replay now as the default and enjoy the speedup it brings over current log splitting.  We can work on being able to take on writes during recovery for later and over in the new issue.&lt;/p&gt;</comment>
                            <comment id="13677759" author="jeffreyz" created="Fri, 7 Jun 2013 02:15:46 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Do we take the highest seqid in the hfile as the hfiles&apos; seqid? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. We use highest seqid as hfile seqid and no need to sort by seqids internally.&lt;/p&gt;

&lt;p&gt;&quot;disable writes during recovery&quot; won&apos;t solve the issue totally because we could have put(row1,t) in wal1 and put(row1,t) in wal2. Since we replay wal files concurrently, we could replay wal2 before wal1. The issue will come after we replay wal2, region flush and then we replay wal1. I do agree that handling this edge case makes the implementation much more complicated.&lt;/p&gt;
</comment>
                            <comment id="13678382" author="enis" created="Fri, 7 Jun 2013 20:12:48 +0000"  >&lt;p&gt;Here is a proposed scheme that can solve this problem:&lt;/p&gt;

&lt;p&gt;The region will be opened for replaying as in previous. The normal writes go to the memstore, and the memstore is flushed as usual. The region servers who are reading the WAL and sending to the replaying RS will still be the same, except for the fact that the edits are sent with their seq_ids. &lt;/p&gt;

&lt;p&gt;On the replaying RS, for all regions that are in replaying state, there is a single buffer. All edits are appended to this buffer without any sorting. This buffer can be accounted as a memstore, and it will have the memstore flush size as max size. Once this is reached, or due to global memstore pressure, we are asked to flush, we do spill this to disk after sorting. This buffer keeps &amp;lt;kv,seq&amp;gt; pairs, and sorts according to &amp;lt;kv,seq&amp;gt;. If there is not memory pressure, and buffer does not fill up, we don&apos;t need to spill to disk. &lt;/p&gt;

&lt;p&gt;Once the replaying is finished, and master asks the region server to open the region for reading, then we do a final merge sort for the in-memory sorted buffer, and all on-disk spilled buffers and create an hfile, discarding kv&apos;s that have the same kv, but smaller seq_id. This file will be a single hfile that corresponds to a flush. This hfile will have a seq_id that is obtained from the wal edits. Then we add this hfile to the store, and open the region as usual. This kind of keeping an unsorted buffer, and sorting it with qsort with spills and final on-disk merge sort might even be faster, since otherwise, we would be doing an insertion to the memstore, which becomes an insertion sort. &lt;/p&gt;

&lt;p&gt;The other thing we need to change is that replayed edits will not go into the wal again, so we keep track of recovering state for the region server, and re-do the work if there is a subsequent failure. &lt;/p&gt;

&lt;p&gt;In sort, this will be close to the BigTable&apos;s in-memory sort for each WAL file approach, but instead we gather the edits for the region from all WAL files by doing the replay RPC, and do the sort per region. End result, we create a flushed hfile, as if the region just flushed before the crash. &lt;/p&gt;</comment>
                            <comment id="15207733" author="allan163" created="Wed, 23 Mar 2016 02:04:56 +0000"  >&lt;p&gt;I may find a bug in this implementation.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@@ -283,6 +319,9 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class SplitLogManager &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; ZooKeeperListener {
       }
     }
     waitForSplittingCompletion(batch, status);
+    &lt;span class=&quot;code-comment&quot;&gt;// remove recovering regions from ZK
&lt;/span&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.removeRecoveringRegionsFromZK(serverNames);
+
     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (batch.done != batch.installed) {
       batch.isDead = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
       SplitLogCounters.tot_mgr_log_split_batch_err.incrementAndGet();
@@ -409,6 +448,171 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class SplitLogManager &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; ZooKeeperListener {
     &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; count;
   }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In your logic, you wait for the completion of the split batch task. And before you check if all job is done without error, you removed the recovering regions from ZK. After that, you check if the batch is done without error and resubmit the task in LogReplayHandler.&lt;br/&gt;
That is a big problem, you remove the region&apos;s recovering status in ZK before the split&amp;amp;replay log task is actually done.Though the split task will be resubmit again, but it will skip the regions that aren&apos;t in recovering state. That means some replays haven&apos;t done before the region can be read again, and that means data lose.&lt;br/&gt;
Can you look this problem for me? &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12717842">HBASE-11280</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12651415">HBASE-8701</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12652164">HBASE-8729</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12648123">HBASE-8568</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12648209">HBASE-8573</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12649422">HBASE-8617</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12648263">HBASE-8575</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12648021">HBASE-8560</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12648097">HBASE-8567</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12631857">HBASE-7825</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12551766">HBASE-5843</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12611460">HBASE-6984</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12843020">HBASE-14028</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12583690" name="7006-addendum-3.txt" size="2026" author="yuzhihong@gmail.com" created="Fri, 17 May 2013 21:17:48 +0000"/>
                            <attachment id="12568897" name="LogSplitting Comparison.pdf" size="51372" author="jeffreyz" created="Mon, 11 Feb 2013 22:25:43 +0000"/>
                            <attachment id="12579260" name="ProposaltoimprovelogsplittingprocessregardingtoHBASE-7006-v2.pdf" size="133072" author="jeffreyz" created="Thu, 18 Apr 2013 01:40:32 +0000"/>
                            <attachment id="12583350" name="hbase-7006-addendum.patch" size="1009" author="jeffreyz" created="Wed, 15 May 2013 18:36:50 +0000"/>
                            <attachment id="12580153" name="hbase-7006-combined-v1.patch" size="251902" author="jeffreyz" created="Tue, 23 Apr 2013 22:14:22 +0000"/>
                            <attachment id="12581779" name="hbase-7006-combined-v4.patch" size="305127" author="jeffreyz" created="Sat, 4 May 2013 00:28:21 +0000"/>
                            <attachment id="12582262" name="hbase-7006-combined-v5.patch" size="314162" author="jeffreyz" created="Wed, 8 May 2013 06:38:57 +0000"/>
                            <attachment id="12582559" name="hbase-7006-combined-v6.patch" size="322351" author="jeffreyz" created="Fri, 10 May 2013 01:13:05 +0000"/>
                            <attachment id="12582663" name="hbase-7006-combined-v7.patch" size="323054" author="jeffreyz" created="Fri, 10 May 2013 18:41:22 +0000"/>
                            <attachment id="12582743" name="hbase-7006-combined-v8.patch" size="318971" author="jeffreyz" created="Fri, 10 May 2013 23:53:04 +0000"/>
                            <attachment id="12583262" name="hbase-7006-combined-v9.patch" size="319991" author="jeffreyz" created="Wed, 15 May 2013 02:20:24 +0000"/>
                            <attachment id="12579497" name="hbase-7006-combined.patch" size="239395" author="jeffreyz" created="Fri, 19 Apr 2013 06:48:50 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12625880">HBASE-7487</subtask>
                            <subtask id="12632135">HBASE-7835</subtask>
                            <subtask id="12632138">HBASE-7836</subtask>
                            <subtask id="12632139">HBASE-7837</subtask>
                            <subtask id="12640036">HBASE-8234</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 18 Oct 2012 08:06:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>249432</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            38 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0a88v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>57609</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Distributed Log Replay Description:&lt;br/&gt;
&lt;br/&gt;
After a region server fails, we firstly assign a failed region to another region server with recovering state marked in ZooKeeper. Then a SplitLogWorker directly replays edits from WAL(Write-Ahead-Log)s of the failed region server to the region after it&amp;#39;s re-opened in the new location. When a region is in recovering state, it can also accept writes but no reads(including Append and Increment), region split or merge. &lt;br/&gt;
&lt;br/&gt;
The feature piggybacks on existing distributed log splitting framework and directly replay WAL edits to another region server instead of creating recovered.edits files.&lt;br/&gt;
&lt;br/&gt;
The advantages over existing log splitting recovered edits implementation:&lt;br/&gt;
1) Eliminate the steps to write and read recovered.edits files. There could be thousands of recovered.edits files are created and written concurrently during a region server recovery. Many small random writes could degrade the overall system performance.&lt;br/&gt;
2) Allow writes even when a region is in recovering state. It only takes seconds for a failed over region to accept writes again. &lt;br/&gt;
&lt;br/&gt;
The feature can be enabled by setting hbase.master.distributed.log.replay to true (by default is false)&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>