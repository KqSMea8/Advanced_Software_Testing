<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:00:16 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2248/HBASE-2248.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2248] Provide new non-copy mechanism to assure atomic reads in get and scan</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2248</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2037&quot; title=&quot;Alternate indexed hbase implementation; speeds scans by adding indexes to regions rather secondary tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2037&quot;&gt;&lt;del&gt;HBASE-2037&lt;/del&gt;&lt;/a&gt; introduced a new MemStoreScanner which triggers a ConcurrentSkipListMap.buildFromSorted clone of the memstore and snapshot when starting a scan.&lt;/p&gt;

&lt;p&gt;After upgrading to 0.20.3, we noticed a big slowdown in our use of short scans.  Some of our data repesent a time series.   The data is stored in time series order, MR jobs often insert/update new data at the end of the series, and queries usually have to pick up some or all of the series.  These are often scans of 0-100 rows at a time.  To load one page, we&apos;ll observe about 20 such scans being triggered concurrently, and they take 2 seconds to complete.  Doing a thread dump of a region server shows many threads in ConcurrentSkipListMap.biuldFromSorted which traverses the entire map of key values to copy it.  &lt;/p&gt;</description>
                <environment></environment>
        <key id="12457095">HBASE-2248</key>
            <summary>Provide new non-copy mechanism to assure atomic reads in get and scan</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ryanobjc">ryan rawson</assignee>
                                    <reporter username="davelatham">Dave Latham</reporter>
                        <labels>
                    </labels>
                <created>Mon, 22 Feb 2010 23:35:19 +0000</created>
                <updated>Fri, 12 Oct 2012 06:14:59 +0000</updated>
                            <resolved>Wed, 14 Apr 2010 21:57:26 +0000</resolved>
                                    <version>0.20.3</version>
                                    <fixVersion>0.20.4</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="12836990" author="davelatham" created="Mon, 22 Feb 2010 23:35:47 +0000"  >&lt;p&gt;Here&apos;s some example threads from a dump.&lt;/p&gt;</comment>
                            <comment id="12836994" author="davelatham" created="Mon, 22 Feb 2010 23:42:28 +0000"  >&lt;p&gt;After doing a flush on the table, the scans are about 100x faster.&lt;/p&gt;</comment>
                            <comment id="12837002" author="dan.washusen" created="Tue, 23 Feb 2010 00:02:30 +0000"  >&lt;p&gt;I notice the performance evaluation flushes the table after each test completes, as a result none of the read tests take the memstore into account.  Maybe the PerformanceEvaluation class could be changed to make the flush optional?&lt;/p&gt;</comment>
                            <comment id="12837015" author="dan.washusen" created="Tue, 23 Feb 2010 00:48:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2249&quot; title=&quot;The PerformanceEvaluation read tests don&amp;#39;t take the MemStore into account.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2249&quot;&gt;&lt;del&gt;HBASE-2249&lt;/del&gt;&lt;/a&gt; will allow changes to the MemStore to be performance tested.&lt;/p&gt;</comment>
                            <comment id="12837067" author="dan.washusen" created="Tue, 23 Feb 2010 03:58:42 +0000"  >&lt;p&gt;K, with PerformanceEvaluation updates running &quot;hbase org.apache.hadoop.hbase.PerformanceEvaluation --rows=1000 scanRange100 10&quot; each scan takes on average 9ms to return a max of 100 rows (random data means they don&apos;t usually return 100 rows, average seemed to be around 70 rows).&lt;/p&gt;

&lt;p&gt;The setup for that tests is as follows;&lt;br/&gt;
1 master&lt;br/&gt;
4 region servers (12GB heap)&lt;/p&gt;

&lt;p&gt;1 million rows set up using:&lt;br/&gt;
hbase org.apache.hadoop.hbase.PerformanceEvaluation randomWrite 1&lt;/p&gt;

&lt;p&gt;There were four regions all on one host.  Each region had roughly 40MB in the MemStore...&lt;/p&gt;</comment>
                            <comment id="12837069" author="jdcryans" created="Tue, 23 Feb 2010 04:03:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;1 million rows set up using:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;With randomWrite you don&apos;t write 1M rows (more like ~700,000 IIRC) so that explains why your scans aren&apos;t always of 100 rows.&lt;/p&gt;</comment>
                            <comment id="12837074" author="dan.washusen" created="Tue, 23 Feb 2010 04:13:04 +0000"  >&lt;p&gt;@JD: that would explain it...&lt;/p&gt;

&lt;p&gt;With --nomapred (10 client threads in a single VM) each scan took 120-140ms...  &lt;/p&gt;

&lt;p&gt;Also, the randomSeekScan test each scan seems VERY slow.  Each scan takes about 15 seconds...?  The scanRange100 uses a startRow and stopRow to get 100 rows back (well 70 rows).  The randomSeekScan using a &quot;scan.setFilter(new WhileMatchFilter(new PageFilter(120)));&quot;.  What&apos;s up with that?&lt;/p&gt;

&lt;p&gt;Oh, also, those tests are on the latest 0.20 branch (not on the 0.20.3 release)... &lt;/p&gt;</comment>
                            <comment id="12837105" author="dan.washusen" created="Tue, 23 Feb 2010 06:46:55 +0000"  >&lt;p&gt;Cloning the MemStore based on the scan.startRow and scan.stopRow drops the scan times from ~9ms per scan to ~3ms per scan on the above hardware...&lt;/p&gt;</comment>
                            <comment id="12837126" author="tlipcon" created="Tue, 23 Feb 2010 07:40:22 +0000"  >&lt;p&gt;Can anyone shed light on why &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2037&quot; title=&quot;Alternate indexed hbase implementation; speeds scans by adding indexes to regions rather secondary tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2037&quot;&gt;&lt;del&gt;HBASE-2037&lt;/del&gt;&lt;/a&gt; introduced this clone in the first place? Seems like a totally braindead thing for performance.&lt;/p&gt;</comment>
                            <comment id="12837127" author="ryanobjc" created="Tue, 23 Feb 2010 07:55:39 +0000"  >&lt;p&gt;I had a look at the implementation of clone, and it is really not appropriate for what we are doing.&lt;/p&gt;

&lt;p&gt;I would like to open up discussions to revert the original patch.  I would argue there has been too many lurking issues, and the additional functionality, while useful, doesnt justify crippling performance.&lt;/p&gt;</comment>
                            <comment id="12837141" author="dan.washusen" created="Tue, 23 Feb 2010 08:41:16 +0000"  >&lt;p&gt;@Todd: I didn&apos;t author the change but it relates to the &lt;a href=&quot;http://svn.apache.org/viewvc/hadoop/hbase/branches/0.20/src/test/org/apache/hadoop/hbase/regionserver/TestHRegion.java?p2=/hadoop/hbase/branches/0.20/src/test/org/apache/hadoop/hbase/regionserver/TestHRegion.java&amp;amp;p1=/hadoop/hbase/branches/0.20/src/test/org/apache/hadoop/hbase/regionserver/TestHRegion.java&amp;amp;r1=896138&amp;amp;r2=896137&amp;amp;view=diff&amp;amp;pathrev=896138&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;tests&lt;/a&gt; added with the change.&lt;/p&gt;

&lt;p&gt;@Ryan: The tests added to PE as a result of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2249&quot; title=&quot;The PerformanceEvaluation read tests don&amp;#39;t take the MemStore into account.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2249&quot;&gt;&lt;del&gt;HBASE-2249&lt;/del&gt;&lt;/a&gt; seem to indicate that even with a fully loaded MemStore it takes 9ms to complete a scan for ~100 rows with 10 concurrent client VMs hitting a single region server.  That seems to contradict the 1-2 seconds seen by Dave.   The thread dump does seems to indicate the clone but maybe something else is coming into play as well?  Maybe the additional 4KB memory allocation is bringing GC into it?&lt;/p&gt;</comment>
                            <comment id="12837146" author="ryanobjc" created="Tue, 23 Feb 2010 08:48:53 +0000"  >&lt;p&gt;could you please tell me where your 4k of memory quote is coming from?&lt;/p&gt;

&lt;p&gt;the clone() is a deep/shallow clone.  The KeyValues arent being cloned, but in ever other way the clone is a deep clone - it copies all the nodes!  That could be literally a million nodes!  The number of nodes is dependent on your data size... 64MB memstore can accomodate 1.3m values if your KeyValue size is ~ 50 bytes.  Or even larger if you start kicking in the memstore multiplier during a pending snapshot, you could have 4m+ nodes in a snapshot and a oversized kvset.  Clone is not really viable, it needs to be rolled back.  Furthermore it doesnt provide atomic protection anyways.&lt;/p&gt;</comment>
                            <comment id="12837202" author="dan.washusen" created="Tue, 23 Feb 2010 11:35:23 +0000"  >&lt;p&gt;Very good point...  &lt;/p&gt;

&lt;p&gt;Even if the clone took the scan start and stop rows into account, there is still the possibility that only one or neither of them has been provided provided... &lt;/p&gt;</comment>
                            <comment id="12837281" author="ykulbak" created="Tue, 23 Feb 2010 15:39:15 +0000"  >&lt;p&gt;Ryan:&lt;br/&gt;
The 4K quote is my mistake, based on a non-typical HBASE usage (small memstore, large KVs).&lt;br/&gt;
Cloning is definitely bad. It&apos;s only benefit is that it allows the scan to be isolated from on-going writes; HRegion#newScannerLock takes care of writes not coming in while the scanner is created, so 0.20.3 unlike 0.20.2 does provide protection from &apos;partial puts&apos; if this was what you&apos;re implying by &apos;atomic protection&apos;. There is also a test added to TestHRegion which verifies that. &lt;/p&gt;

&lt;p&gt;I&apos;m not sure that rollback is a viable option:  &lt;br/&gt;
The 0.20.2 Memstore was using the ConcurrentSkipListMap#tailMap for every row. tailMap incurs an O(log&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) overhead when called on a ConcurrentSkipListMap so the total overhead of scanning the whole memstore in some cases, may be very close to the overhead of a complete sort of the KVs in memstore.&lt;br/&gt;
The 0.20.2 MemStore and MemStoreScanner are also functionally incorrect since  &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The scanner may observe a &apos;partial put&apos; (not atomically protected)&lt;/li&gt;
	&lt;li&gt;The scanner scans incorrectly when a snapshot exists&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;since we observed a considerable &apos;single scan&apos; performance improvement using the new MemStore implementation could the performance hit stem from increased GC overhead on multiple concurrent scans?   &lt;br/&gt;
Note that with 0.20.2 we observed that MemStoreScanner is running slower than StoreFileScanner..  &lt;/p&gt;

&lt;p&gt;Is it possible to avoid both &apos;partial puts&apos; and cloning by &apos;timestamping&apos; memstore records? e.g. each new KV in memstore gets a &apos;memstore timestamp&apos; and when a scanner is created it grabs the current timestamp so that it knows to ignore KVs which entered the store after its creation?  Should probably use a counter and not currentTimeMillis to ensure a clear-cut. &lt;/p&gt;

&lt;p&gt;------------&lt;br/&gt;
About those ~50 byte KVs, according to my calcs:&lt;br/&gt;
KeyLength: 4 bytes&lt;br/&gt;
ValueLength: 4 bytes&lt;br/&gt;
rowLength: 2 bytes&lt;br/&gt;
FamilyLength: 1 byte&lt;br/&gt;
TimeStamp: 8 bytes&lt;br/&gt;
Type: 1 byte&lt;/p&gt;

&lt;p&gt;There are 20 bytes of overhead to start with.&lt;br/&gt;
Adding an average of 10 bytes for the column and qualifier brings it to 40 bytes. &lt;br/&gt;
This leaves 10 bytes (out of 50) for the row + value. Meaning 80% of the storage is overhead.&lt;br/&gt;
My point is that if ~50b KVs are the common use-case  some optimization needs to be made to the way things are stored.&lt;br/&gt;
Perhaps you meant 50b for row+value?&lt;/p&gt;
</comment>
                            <comment id="12837326" author="davelatham" created="Tue, 23 Feb 2010 17:20:37 +0000"  >&lt;p&gt;Thanks, Dan, and others for looking into this issue.  The table where we were seeing these slow scans was definitely a tall, narrow table.  Each row has one cell, the column family and qualifier are each one byte.  The row varies, but is typically 8-20 bytes, and the value is usually 4 bytes or less.  Most common is probably row - 12 bytes, col fam - 1 byte, qualifier 1 byte, value - 3 bytes, giving 17 bytes plus overhead.&lt;/p&gt;

&lt;p&gt;As I was trying to understand the discrepancy between the PE results you mentioned and what I&apos;ve observed, I looked in to PerformanceEvaluation.  It looks like the timer only starts after the scanner is constructed which means that the MemStore clone isn&apos;t being timed as part of the test, so that would probably explain why the test seems fast.  Just reasoning, it seems hard to believe that ConcurrentSkipListMap.buildFromSorted could complete a million iterations that fast.&lt;/p&gt;</comment>
                            <comment id="12837343" author="stack" created="Tue, 23 Feb 2010 17:52:43 +0000"  >&lt;p&gt;.bq Can anyone shed light on why &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2037&quot; title=&quot;Alternate indexed hbase implementation; speeds scans by adding indexes to regions rather secondary tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2037&quot;&gt;&lt;del&gt;HBASE-2037&lt;/del&gt;&lt;/a&gt; introduced this clone in the first place? Seems like a totally braindead thing for performance. &lt;/p&gt;

&lt;p&gt;Mea Culpa. I should have caught this in review, the non-scalable, expensive full-copy.  Dumb.&lt;/p&gt;

&lt;p&gt;I also should have run PE to catch degradation in performance before release though in this case, according to Dan, as PE is now, we&apos;d not have caught the slowed-down memstore since we flush after each PE run and since the short-scan test is new with no history (Long time ago I wrote up a how-to-release: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hbase/HowToRelease&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hbase/HowToRelease&lt;/a&gt;.  It says PE required but I think I&apos;ve not followed this receipe in a good while now).&lt;/p&gt;

&lt;p&gt;.bq The 0.20.2 Memstore was using the ConcurrentSkipListMap#tailMap for every row. tailMap incurs an O(log) overhead when called on a ConcurrentSkipListMap so the total overhead of scanning the whole memstore in some cases, may be very close to the overhead of a complete sort of the KVs in memstore.&lt;/p&gt;

&lt;p&gt;In the old implementation, we used to also make a copy of a row, everytime we called a next, to protect against the case where snapshot was removed out from under us.&lt;/p&gt;

&lt;p&gt;.bq The scanner scans incorrectly when a snapshot exists&lt;/p&gt;

&lt;p&gt;Why was this again?&lt;/p&gt;

&lt;p&gt;.bq ... increased GC overhead on multiple concurrent scans&lt;/p&gt;

&lt;p&gt;Dave, can you enable GC logging?  Even if this is the case, it needs to be addressed.&lt;/p&gt;

&lt;p&gt;.bq Is it possible to avoid both &apos;partial puts&apos; and cloning by &apos;timestamping&apos; memstore records? e.g. each new KV in memstore gets a &apos;memstore timestamp&apos; and when a scanner is created it grabs the current timestamp so that it knows to ignore KVs which entered the store after its creation? Should probably use a counter and not currentTimeMillis to ensure a clear-cut.&lt;/p&gt;

&lt;p&gt;How would we snapshot such a thing?&lt;/p&gt;

&lt;p&gt;We could add another ts/counter to KV.  We could do an AND on the type setting a bit if extra ts is present.  We then write out the KV as old style, dropping extra ts when we flush to hfile, or we just dump it all out.  System would need to be able to work with old-style KVs.  Comparator would be adjusted to accomodate new KV.   We&apos;d do a tailset each time we made a scanner?  This would be a big change.  We should probably bump rpc version and require a restart of hbase cluster on upgrade.&lt;/p&gt;</comment>
                            <comment id="12837352" author="davelatham" created="Tue, 23 Feb 2010 18:09:30 +0000"  >&lt;p&gt;I&apos;ve got gc logging enabled.  Here&apos;s a snapshot of the regionserver for a few minutes during which I ran this test 5 or 6 times and generated 360 short scans.  Let me know if there&apos;s any other GC info that would be useful.&lt;/p&gt;
</comment>
                            <comment id="12837372" author="stack" created="Tue, 23 Feb 2010 18:39:51 +0000"  >&lt;p&gt;There is a bunch of YG GC&apos;ing going on... Might slow things some but not by much.  I&apos;ve attached a screen shot.&lt;/p&gt;</comment>
                            <comment id="12837497" author="dan.washusen" created="Tue, 23 Feb 2010 23:03:29 +0000"  >&lt;p&gt;@Dave: Could you have at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2249&quot; title=&quot;The PerformanceEvaluation read tests don&amp;#39;t take the MemStore into account.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2249&quot;&gt;&lt;del&gt;HBASE-2249&lt;/del&gt;&lt;/a&gt; and confirm that the call to HTable.getScanner(...) is now being timed?&lt;/p&gt;</comment>
                            <comment id="12837519" author="davelatham" created="Tue, 23 Feb 2010 23:40:26 +0000"  >&lt;p&gt;@Dan: Took a read over the patch, though it seemed to be based in a different dir and didn&apos;t want to apply nicely.  From what I can see the ScanTest still does getScanner in testSetup before the timer is begun.  This may be fine, if the point of this test is to measure scan performance per-row and not setup/teardown time.  It just explains why the ScanTest doesn&apos;t exhibit this issue.  It does look like other tests, such as the RandomSeekScanTest and the new RandomScanWithRangeTest do test setup/teardown time as part of each &quot;testRow&quot; and should exhibit this issue, if run.&lt;/p&gt;</comment>
                            <comment id="12837523" author="ryanobjc" created="Tue, 23 Feb 2010 23:44:15 +0000"  >&lt;p&gt;done properly, a timestamp oriented fix to version memstore should not require any RPC version bump, its all internal. &lt;/p&gt;</comment>
                            <comment id="12837562" author="dan.washusen" created="Wed, 24 Feb 2010 01:28:04 +0000"  >&lt;p&gt;@Dave: &lt;/p&gt;

&lt;p&gt;Correct you are.  I&apos;ve added comments on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2249&quot; title=&quot;The PerformanceEvaluation read tests don&amp;#39;t take the MemStore into account.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2249&quot;&gt;&lt;del&gt;HBASE-2249&lt;/del&gt;&lt;/a&gt; as a result of your comments here...&lt;/p&gt;

&lt;p&gt;It&apos;s worth noting that in the case of ScanTest the cost of setting up the ResultScanner is almost non-existent compared to the cost of scanning over the majority of table.  The ScanTest takes 23 seconds in total according to the log output (including opening the scanner etc).&lt;/p&gt;

&lt;p&gt;Dave, the numbers I posted above (9ms) were from the RandomScanWithRangeTest.  As you mention, these tests include the cost of opening the scanner.  I was under the impression that this was closer to your use case (e.g. specify both a scan.startRow and scan.stopRow which returns a small number of rows)...?&lt;/p&gt;</comment>
                            <comment id="12837591" author="ykulbak" created="Wed, 24 Feb 2010 03:06:18 +0000"  >&lt;p&gt;I did the following sanity check: I rolled back memstore to just before &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2037&quot; title=&quot;Alternate indexed hbase implementation; speeds scans by adding indexes to regions rather secondary tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2037&quot;&gt;&lt;del&gt;HBASE-2037&lt;/del&gt;&lt;/a&gt; was applied &lt;span class=&quot;error&quot;&gt;&amp;#91;last commit on 21 Oct 2009&amp;#93;&lt;/span&gt;. &lt;br/&gt;
[ To get things going I had to put back the MemStore#numKeyValues method and change the  MemStore#clearSnapshot   argument to SortedSet ]&lt;/p&gt;

&lt;p&gt;I then ran TestHRegion and two tests failed:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;testFlushCacheWhileScanning - demonstrates the incorrect scans while a snapshot exists issue&lt;/li&gt;
	&lt;li&gt;testWritesWhileScanning - demonstrates &apos;partial puts&apos; being visible to the scanner&lt;br/&gt;
I also tried running TestMemStore but all the tests there have passed. I didn&apos;t try running the whole suite.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It took me a while to figure out what exactly goes wrong when a snapshot exists, the short (and vague) explanation is that the scanner may return keys in a &apos;non ordered&apos; manner, meaning a KV with a higher row  may be returned before a KV with a lower row because the result list which aggregates results from both snapshot and kvset doesn&apos;t guarantee the KVs are added in a sorted order. I think there&apos;s a way to add a simple test to TestMemStore which will demonstrate that..   &lt;/p&gt;
</comment>
                            <comment id="12837908" author="stack" created="Wed, 24 Feb 2010 17:48:46 +0000"  >&lt;p&gt;Patch that restores memstore to how it was.  With this in place run memstore unit tests to see how old implementation was broke.&lt;/p&gt;</comment>
                            <comment id="12838750" author="ryanobjc" created="Fri, 26 Feb 2010 08:23:47 +0000"  >&lt;p&gt;i have a prototype implementation of how to fix the atomic read without using locking or copying.  I&apos;ll put up a patch within a few days.  It&apos;s a little subtle, but put simply it uses sequential &quot;Timestamps&quot; to internally version the memstore so people know to ignore half written rows.&lt;/p&gt;</comment>
                            <comment id="12838853" author="stack" created="Fri, 26 Feb 2010 12:55:11 +0000"  >&lt;p&gt;Here is an attempt.  Tests pass.  Posting for review.  Need to do load tests yet.&lt;/p&gt;

&lt;p&gt;&quot;- Added a (transient) int updateId to KeyValue&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Memstore populates it on Adds and Deletes&lt;/li&gt;
	&lt;li&gt;When a MemstoreScanner is created it grabs the current id (actually increments  it to make sure no KV has that same id) and ignores records from kvset having an id greater than the one grabbed. Snapshots are scanned in full since they&apos;re not updated during the scanner&apos;s lifetime hence there&apos;s no risk of partial updates being visible.  There may be an issue with delete&apos;s becoming partly visible in this scheme, I&apos;ll check that later.&quot;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12838919" author="tlipcon" created="Fri, 26 Feb 2010 16:33:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;There may be an issue with delete&apos;s becoming partly visible in this scheme&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would think so - deletes in the memstore don&apos;t use tombstones, do they? Similarly for updates - if you update a row, its internal ts will update and the scanner will no longer see the old version either.&lt;/p&gt;</comment>
                            <comment id="12839050" author="ryanobjc" created="Fri, 26 Feb 2010 22:37:39 +0000"  >&lt;p&gt;deletes use tombstones, but the current GET code might need... adjustment to make it work. I&apos;m working on a base fix which I will post soon and I&apos;ll also check the get implementation. &lt;/p&gt;</comment>
                            <comment id="12839248" author="stack" created="Sat, 27 Feb 2010 12:52:42 +0000"  >&lt;p&gt;Yeah, if client adds new edit w/ exact same ts and the comparator used by memstore does not take sequenceid into consideration, we&apos;ll have issues Todd identifies.  Perhaps change the Comparator used by MemStore to consider sequenceid?   Also missing from patch is enforcement of the fact that on flush, the flush file has deletes that apply to older files only &amp;#8211; not to current flush file content.&lt;/p&gt;</comment>
                            <comment id="12839964" author="ryanobjc" created="Tue, 2 Mar 2010 01:58:51 +0000"  >&lt;p&gt;I&apos;m working on this, there is a general approach hammered out and code to be written.&lt;/p&gt;

&lt;p&gt;The approach is like so:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;on read from memstore, for each row, we grab the &apos;read number&apos; and ignore any keyvalues in the structure newer (ie: &amp;gt; value)&lt;/li&gt;
	&lt;li&gt;on put to hregion/memstore, we start a write &apos;tx&apos; and get a write-number, and put keyvalues with said write-number.  when we are finished, that write-number is &apos;commited&apos; which causes the read number to be advanced most of the time.  under concurrent writes we have a little queue and slower puts may slightly hold up puts that come before it.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;this will need to be extensively tested to see how the performance profile changes. it will allow us to remove the newScannerLock.&lt;/p&gt;</comment>
                            <comment id="12841165" author="ryanobjc" created="Thu, 4 Mar 2010 10:23:11 +0000"  >&lt;p&gt;Ok here is my proposal to fix this, hopefully once and for all.&lt;/p&gt;

&lt;p&gt;The only thing that isn&apos;t covered is deletes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;removing keyvalues wont ever be atomic&lt;/li&gt;
	&lt;li&gt;we could stop deleting key values, but the get code would have to be checked
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;the flush would also need to prune out deleted key values to keep the delete invariant of &apos;get&apos; going on.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12841169" author="ryanobjc" created="Thu, 4 Mar 2010 10:28:08 +0000"  >&lt;p&gt;my patch passes all the new tests added by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2037&quot; title=&quot;Alternate indexed hbase implementation; speeds scans by adding indexes to regions rather secondary tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2037&quot;&gt;&lt;del&gt;HBASE-2037&lt;/del&gt;&lt;/a&gt; which focus on parallelism while doing scans.  &lt;/p&gt;</comment>
                            <comment id="12841488" author="streamy" created="Thu, 4 Mar 2010 20:14:29 +0000"  >&lt;p&gt;Might be time to turn gets into scans so we don&apos;t have a second read code path.&lt;/p&gt;</comment>
                            <comment id="12841579" author="ykulbak" created="Thu, 4 Mar 2010 22:46:54 +0000"  >&lt;p&gt;Turning gets into scans will cause some minor functional changes. See for example the differences between gets and scans exposed in TestClient#testDeletes. IMHO eliminating the functional differences between gets and scans will be a change for the better but perhaps there are existing users which rely those subtle differences.&lt;/p&gt;</comment>
                            <comment id="12841585" author="tlipcon" created="Thu, 4 Mar 2010 22:56:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;IMHO eliminating the functional differences between gets and scans will be a change for the better but perhaps there are existing users which rely those subtle differences&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 for eliminating the differences. If people are relying on broken behavior, they should fix their applications &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; HBase is not 1.0; let&apos;s pick sanity over compatibility.&lt;/p&gt;</comment>
                            <comment id="12841669" author="tlipcon" created="Fri, 5 Mar 2010 02:46:00 +0000"  >&lt;p&gt;Hey Ryan&lt;/p&gt;

&lt;p&gt;I looked over this patch a bit this afternoon. It&apos;s clever but I think it can result in loss of read-your-own-writes consistency for a single client. Consider this scenario:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Action &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Read # &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Write # &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; memstoreRead &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; memstoreWrite &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client A begins a put on row R   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client B begins a put on row S   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client B finishes a put on row S &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client B initiates a get on row S &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 0 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;So, since client A&apos;s put #1 is still ongoing on a separate row, client B is unable to read version #2 of its row.&lt;/p&gt;

&lt;p&gt;I think dropping consistency below read-your-own-writes is bad, even though it&apos;s rare that the above situation would occur. Under high throughput I think it&apos;s possible to occur, and it could be very very bad if people are relying on this level of consistency to implement transactions, etc.&lt;/p&gt;

&lt;p&gt;One possible solution is that completeMemstoreInsert can spin until memstoreRead &amp;gt;= e.getWriteNumber(). Given that it only has to wait for other concurrent writers to finish, a spin on memstoreRead.get() should only go a few cycles and actually be reasonably efficient.&lt;/p&gt;

&lt;p&gt;I&apos;ll think a bit about whether there are other possible solutions.&lt;/p&gt;</comment>
                            <comment id="12841675" author="tlipcon" created="Fri, 5 Mar 2010 03:14:18 +0000"  >&lt;p&gt;Here&apos;s a test case patch (on top of yours) which should illustrate the issue. It fails every time for me on a dual core box:&lt;/p&gt;

&lt;p&gt;Didnt read own writes expected:&amp;lt;395&amp;gt; but was:&amp;lt;394&amp;gt;&lt;br/&gt;
junit.framework.AssertionFailedError: Didnt read own writes expected:&amp;lt;395&amp;gt; but was:&amp;lt;394&amp;gt;&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.TestMemStore$ReadOwnWritesTester.internalRun(TestMemStore.java:293)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.TestMemStore$ReadOwnWritesTester.run(TestMemStore.java:268)&lt;/p&gt;</comment>
                            <comment id="12841680" author="tlipcon" created="Fri, 5 Mar 2010 03:25:44 +0000"  >&lt;p&gt;Here&apos;s a slightly better test patch, much more sure to fail.&lt;/p&gt;

&lt;p&gt;(this test could easily be written without multiple threads, but as an illustration of the client&apos;s view of the consistency, the threads are useful)&lt;/p&gt;</comment>
                            <comment id="12841687" author="ryanobjc" created="Fri, 5 Mar 2010 03:44:28 +0000"  >&lt;p&gt;I think your suggestion is a good one, the race condition is really small, and holding up a client for just a few more microseconds should be reasonable.  Once we restructure to not put logs appends between memstore puts, we are literally talking about the speed of adding a few dozen entries in an array.  There is no data copy involved, since KeyValue was already read in during RPC time, and we are talking inserting small objects into a data structure.&lt;/p&gt;

&lt;p&gt;I originally thought of being speedy about returning, but read your own writes does make this be an issue.  I&apos;ll add in your suggestions and put this test in as well.&lt;/p&gt;

&lt;p&gt;Thanks for the great test!&lt;/p&gt;</comment>
                            <comment id="12841691" author="tlipcon" created="Fri, 5 Mar 2010 03:53:28 +0000"  >&lt;p&gt;Here&apos;s a patch on top of Ryan&apos;s which implements the spin-wait. The concurrency test for read-own-writes now passes.&lt;/p&gt;</comment>
                            <comment id="12844367" author="stack" created="Fri, 12 Mar 2010 05:24:46 +0000"  >&lt;p&gt;@Ryan, your next patch picks up Todds spin-wait I believe?&lt;/p&gt;</comment>
                            <comment id="12844371" author="stack" created="Fri, 12 Mar 2010 05:31:57 +0000"  >&lt;p&gt;Here is a different take for review and input on how to solve this issue.  &lt;/p&gt;

&lt;p&gt;Get is now implemented using Scan. I deleted lots of get-related classes/code including the QueryMatcher. Deletes are no longer removing KV&apos;s from memstore.  The change so on flush we filter deleted KVs is not done in this patch &amp;#8211; can be done in another issue.  Maybe we don&apos;t want to filter deleted KVs on flush but rather on minor compactions, for instance (The axiom that a file hold only deletes that pertain to values held in storefiles that follow may not be necessary when gets are implemented using scan?).&lt;/p&gt;



&lt;p&gt;Things left to do:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Performance test&lt;/li&gt;
	&lt;li&gt;More accurate heap size calculation for HRegion&lt;/li&gt;
	&lt;li&gt;Discuss where/when deletes should be partially applied&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Here is more detail on what this change includes:&lt;/p&gt;

&lt;p&gt;M       src/contrib/indexed/src/java/org/apache/hadoop/hbase/regionserver/IdxRegion.java&lt;br/&gt;
 minor tweak due to Memstore#getScanners signature change&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
 Appended EMPTY_KEY_VALUE_UPDATE_ID to stand for an unset update id&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/KeyValue.java&lt;br/&gt;
 Added a transient int updateId + accessors + heap size adjustment&lt;br/&gt;
 Added a createLastOnRow method (similar to create first on row) and&lt;br/&gt;
made sure the comparator treats this case symmetrically&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/client/Scan.java&lt;br/&gt;
 Added a constructor which accepts a Get and creates a matching scan +&lt;br/&gt;
a convenience method isGetScan&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/ColumnTracker.java&lt;br/&gt;
 Modified references to QueryMatcher to refer to ScanQueryMatcher&lt;/p&gt;

&lt;p&gt;D       src/java/org/apache/hadoop/hbase/regionserver/DeleteCompare.java&lt;br/&gt;
M       src/java/org/apache/hadoop/hbase/regionserver/ExplicitColumnTracker.java&lt;br/&gt;
 QueryMatcher -&amp;gt; ScanQueryMatcher&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/GetClosestRowBeforeTracker.java&lt;br/&gt;
 QueryMatcher -&amp;gt; ScanQueryMatcher&lt;/p&gt;

&lt;p&gt;D       src/java/org/apache/hadoop/hbase/regionserver/GetDeleteTracker.java&lt;br/&gt;
M       src/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
 Added a member of type RegionUpdateTracker which is intialized both&lt;br/&gt;
in the constructor and every flush + heap size adjustment&lt;br/&gt;
 Scans are now paused while flushers prepare (e.g. snapshots are taken)&lt;br/&gt;
 Old gets replaced with new get implementation (which uses scans)&lt;br/&gt;
 #getClosestRowBefore is now using HRegion#get instead of Store#get&lt;br/&gt;
 #delete(Delete,Integer,boolean) no longer aquires a newScannerLock&lt;br/&gt;
and also tracks update ids using the update tracker&lt;br/&gt;
 #delete(byte[],List,boolean) protected changed to package since it&apos;s&lt;br/&gt;
used as an internal HRegion subroutine and accessed a few times by&lt;br/&gt;
tests. It&apos;s also no longer aquires the update lock&lt;br/&gt;
 #put no longer aquires newScannerLock also modified to track update ids&lt;br/&gt;
 RegionScanner stop-row logic was adjusted to support get scans. Also,&lt;br/&gt;
RegionUpdateTracker#UpdateIdValidator is now aquired and passed down&lt;br/&gt;
to store scanners&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/KeyValueSkipListSet.java&lt;br/&gt;
 no longer Cloneable&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;br/&gt;
 deleted lots of unneeded logic, mainly around deletes (very much&lt;br/&gt;
simplifed) and gets (no longer needed)&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/MemStoreScanner.java&lt;br/&gt;
 Modified to consider UpdateIdValidator for kvset KeyValues. snapshot&lt;br/&gt;
kv&apos;s are reset to undefined update if for Store#updateColumnValue to&lt;br/&gt;
remain backward compatible&lt;/p&gt;

&lt;p&gt;D       src/java/org/apache/hadoop/hbase/regionserver/QueryMatcher.java&lt;br/&gt;
A       src/java/org/apache/hadoop/hbase/regionserver/RegionUpdateTracker.java&lt;br/&gt;
 Trackes updates to HRegions. See javadoc.&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/ScanDeleteTracker.java&lt;br/&gt;
 Fixed to throw an exception as comment suggests&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;br/&gt;
 Merged with the deleted QueryMatcher. Added a slight variant for get&lt;br/&gt;
scans to use &apos;lastInRows&apos;&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/ScanWildcardColumnTracker.java&lt;br/&gt;
 QueryMatcher -&amp;gt; ScanQueryMatcher&lt;/p&gt;

&lt;p&gt;M       src/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
 #getScanner now accepts an UpdateIdValidator&lt;/p&gt;

&lt;p&gt; #get deleted&lt;br/&gt;
 #updateColumnValue modified to use scans and not memstore#getWithCode&lt;br/&gt;
(which was deleted)&lt;br/&gt;
D       src/java/org/apache/hadoop/hbase/regionserver/StoreFileGetScan.java&lt;br/&gt;
M       src/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;br/&gt;
 QueryMatcher.MatchCode -&amp;gt; ScanQueryMatcher.MatchCode&lt;br/&gt;
 passing around of the UpdateIdValidator&lt;/p&gt;

&lt;p&gt;D       src/java/org/apache/hadoop/hbase/regionserver/WildcardColumnTracker.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/TestKeyValue.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/client/TestClient.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;br/&gt;
D       src/test/org/apache/hadoop/hbase/regionserver/TestDeleteCompare.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/regionserver/TestExplicitColumnTracker.java&lt;br/&gt;
D       src/test/org/apache/hadoop/hbase/regionserver/TestGetDeleteTracker.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/regionserver/TestMemStore.java&lt;br/&gt;
D       src/test/org/apache/hadoop/hbase/regionserver/TestQueryMatcher.java&lt;br/&gt;
A       src/test/org/apache/hadoop/hbase/regionserver/TestRegionUpdateTracker.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/regionserver/TestScanWildcardColumnTracker.java&lt;br/&gt;
M       src/test/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
D       src/test/org/apache/hadoop/hbase/regionserver/TestWildcardColumnTracker.java&lt;/p&gt;</comment>
                            <comment id="12844378" author="ryanobjc" created="Fri, 12 Mar 2010 05:46:33 +0000"  >&lt;p&gt;Yes I have asked Todd and rolled up his patch. I have identified a small&lt;br/&gt;
race condition in scanning today and ill fix it soon and likely post on&lt;br/&gt;
Monday.&lt;/p&gt;

&lt;p&gt;On Mar 12, 2010 12:25 AM, &quot;stack (JIRA)&quot; &amp;lt;jira@apache.org&amp;gt; wrote:&lt;/p&gt;


&lt;p&gt;   [&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=12844367#action_12844367&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-2248?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=12844367#action_12844367&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;stack commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
------------------------------&lt;/p&gt;

&lt;p&gt;@Ryan, your next patch picks up Todds spin-wait I believe?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;-ryan.patch, hbase-2248.gc, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;.patch, hbase-2248.txt,&lt;br/&gt;
readownwrites-lost.2.patch, readownwrites-lost.patch, Screen shot 2010-02-23&lt;br/&gt;
at 10.33.38 AM.png, threads.txt&lt;br/&gt;
ConcurrentSkipListMap.buildFromSorted clone of the memstore and snapshot&lt;br/&gt;
when starting a scan.&lt;br/&gt;
scans.  Some of our data repesent a time series.   The data is stored in&lt;br/&gt;
time series order, MR jobs often insert/update new data at the end of the&lt;br/&gt;
series, and queries usually have to pick up some or all of the series.&lt;br/&gt;
 These are often scans of 0-100 rows at a time.  To load one page, we&apos;ll&lt;br/&gt;
observe about 20 such scans being triggered concurrently, and they take 2&lt;br/&gt;
seconds to complete.  Doing a thread dump of a region server shows many&lt;br/&gt;
threads in ConcurrentSkipListMap.biuldFromSorted which traverses the entire&lt;br/&gt;
map of key values to copy it.&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message is automatically generated by JIRA.&lt;br/&gt;
-&lt;br/&gt;
You can reply to this email to add a comment to the issue online.&lt;/p&gt;</comment>
                            <comment id="12845204" author="tlipcon" created="Mon, 15 Mar 2010 06:56:09 +0000"  >&lt;p&gt;I&apos;m upgrading this to blocker - this patch fixes a ton of deadlock scenarios (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2322&quot; title=&quot;deadlock between put and cacheflusher in 0.20 branch&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2322&quot;&gt;&lt;del&gt;HBASE-2322&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="12845537" author="tlipcon" created="Mon, 15 Mar 2010 21:30:21 +0000"  >&lt;p&gt;Has this JIRA outgrown its scope? Should the reasonably small fix that Ryan and I did go in first, and then we can do the get-&amp;gt;scan conversion separately?&lt;/p&gt;</comment>
                            <comment id="12845543" author="ryanobjc" created="Mon, 15 Mar 2010 21:39:16 +0000"  >&lt;p&gt;Here is my patch to address the issue.&lt;br/&gt;
Some notes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;we use a single forward pushing read point to accomplish atomicity.  Right now with appends and memstore puts mixed in, this causes writes to appear to be serialized. There is no sync block which prevents multiple puts from being done at the same time though.  When we restructure WAL append to happen in one go, and memstore put to happen after, this issue will go away.&lt;/li&gt;
	&lt;li&gt;this patch does atomicity at a multi-family level. This means that if a write is going across multiple families, and we do a concurrent scan (AND if a concurrent flush also happens) we will only read the previously completely written row. No partial multi-family row reads.&lt;/li&gt;
	&lt;li&gt;Deletes are also atomic. By no longer removing KeyValues from memstore we make it so. Also adjusted Gets to use 1 row Scans, and put in a TODO for a bloomfilter hook.&lt;/li&gt;
	&lt;li&gt;During a scan, we will ride over a snapshot and see the new data. We will also reset the read point between every row, so a scan will see new values as they are inserted &lt;em&gt;after&lt;/em&gt; it&apos;s current read point.  If a row is updated after a scan has already seen it, it will of course not see that value.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some thanks:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Todd for pointing out a case where read-your-own-writes might not happen&lt;/li&gt;
	&lt;li&gt;Hints from the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;-GetsAsScans patch for doing single row scans.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12845554" author="tlipcon" created="Mon, 15 Mar 2010 22:01:42 +0000"  >&lt;p&gt;Hey Ryan.&lt;/p&gt;

&lt;p&gt;Will try to take a look at your patch early this week. Regarding the new atomicity properties, can you please comment in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2294&quot; title=&quot;Enumerate ACID properties of HBase in a well defined spec&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2294&quot;&gt;&lt;del&gt;HBASE-2294&lt;/del&gt;&lt;/a&gt;? I want to make sure that, if we add these properties, that (a) they are really user requirements and (b) we have documented them somewhere. If (a) isn&apos;t true, we should document that, in case we find efficiency improvements we can make by dropping some of them.&lt;/p&gt;</comment>
                            <comment id="12845615" author="ryanobjc" created="Tue, 16 Mar 2010 00:15:05 +0000"  >&lt;p&gt;My patch doesn&apos;t add any new properties, it just makes the existing ones efficient and removes locks.  I already enumerated a number of properties we have and would like to have in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2294&quot; title=&quot;Enumerate ACID properties of HBase in a well defined spec&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2294&quot;&gt;&lt;del&gt;HBASE-2294&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;</comment>
                            <comment id="12845666" author="apurtell" created="Tue, 16 Mar 2010 02:40:06 +0000"  >&lt;p&gt;Some feedback based on initial tests:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Heap sizes need to be adjusted for KeyValue (add a long), HRegion (add a reference), and MemStore (add a reference).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Indexed contrib is unhappy:
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;o.a.h.h.TestIdxHBaseCluster fails.&lt;/li&gt;
		&lt;li&gt;o.a.h.h.regionserver.TestHRegionWithIdxRegion OOMEs after 376 put iterations.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The OOME is concerning as might be catching a memory leak introduced in the change set. &lt;/p&gt;

&lt;p&gt;I&apos;m going to put it up on EC2 and throw PE at it tomorrow. &lt;/p&gt;




</comment>
                            <comment id="12845709" author="ykulbak" created="Tue, 16 Mar 2010 05:00:41 +0000"  >&lt;p&gt;.bq &apos;m going to put it up on EC2 and throw PE at it tomorrow.&lt;/p&gt;

&lt;p&gt;What are you going to compare it against?&lt;br/&gt;
May I suggest comparing against both the branch without the patch and the branch with GetsAsScans3 applied?&lt;/p&gt;</comment>
                            <comment id="12845724" author="stack" created="Tue, 16 Mar 2010 05:54:04 +0000"  >&lt;p&gt;Yeah, I just tried to run test suite and ran into at least the TestHeapSize failures.&lt;/p&gt;

&lt;p&gt;On a test up on cluster, something is up.  Its not deadlocked but its only making slow progress.  Regionservers are all waiting for something to do.  Will look in morning.&lt;/p&gt;

&lt;p&gt;On the patch:&lt;/p&gt;

&lt;p&gt;+ &quot;aka DNC&quot; ... whats DNC? (Democratic National Committee?)&lt;br/&gt;
+ In KV, it has &quot;+   * @deprecated&quot;  Usually deprecated points helpfully to what should be used instead.  What should folks use instead of createFirstOnRow override?&lt;br/&gt;
+ &lt;ins&gt;1 on this comment of yours &quot;&lt;/ins&gt;      // TODO the family and qualifier should be compared separately&quot;&lt;br/&gt;
+ So, on flush of the MemStore, we don&apos;t need to clean out items that MemStore Deletes effect?  We now let go of the old axiom that Deletes in storefiles only apply to storefiles that follow and not to the current storefile?&lt;br/&gt;
+ I love all the stuff removed.&lt;/p&gt;

&lt;p&gt;More review later.&lt;/p&gt;

&lt;p&gt;What do we see as implications of removal of the special Get-code path?&lt;/p&gt;

&lt;p&gt;+ Is it true that now, you can do inserts where timestamps are out of order? (If no deletes?)  If so, don&apos;t we need unit tests to prove this assertion?&lt;br/&gt;
+ What about performance?  Though the new Get-Scan does storefile accesses in parallel, if &amp;gt; N storefiles, if looking for latest version only, we&apos;ll be slower (at least until we add BFs?).&lt;/p&gt;</comment>
                            <comment id="12845739" author="ryanobjc" created="Tue, 16 Mar 2010 06:37:23 +0000"  >&lt;p&gt;There is some profiling to be done to figure out what the problems might be.  I think running some Unit tests under a profiler will be illuminating.&lt;/p&gt;

&lt;p&gt;DNC = do not care, it&apos;s a hardware engineering thing &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The problem with Get vs Scan, is the old code was not correct, so favoring a faster incorrect code is something I thought we agreed we would not do. But yes, we no longer get that assumed performance improvement.&lt;/p&gt;</comment>
                            <comment id="12845740" author="tlipcon" created="Tue, 16 Mar 2010 06:39:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2265&quot; title=&quot;HFile and Memstore should maintain minimum and maximum timestamps&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2265&quot;&gt;&lt;del&gt;HBASE-2265&lt;/del&gt;&lt;/a&gt; should really help with culling access to older regions (without the more complicated bloom filter solution)&lt;/p&gt;</comment>
                            <comment id="12847529" author="apurtell" created="Fri, 19 Mar 2010 19:26:41 +0000"  >&lt;p&gt;Commit of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt; invalidates the patch on this issue.&lt;/p&gt;</comment>
                            <comment id="12847539" author="ryanobjc" created="Fri, 19 Mar 2010 19:41:48 +0000"  >&lt;p&gt;ill update my patch to accomodate this commit.&lt;/p&gt;

&lt;p&gt;it doesn&apos;t &quot;invalidate&quot; the patch - there is still a window of opportunity to see partial row updates.&lt;/p&gt;</comment>
                            <comment id="12847542" author="apurtell" created="Fri, 19 Mar 2010 19:44:00 +0000"  >&lt;p&gt;Yeah, ok, imprecise word choice. Thanks for rebasing. &lt;/p&gt;</comment>
                            <comment id="12847553" author="ryanobjc" created="Fri, 19 Mar 2010 20:05:35 +0000"  >&lt;p&gt;ill try to update this today or this weekend!&lt;/p&gt;</comment>
                            <comment id="12847821" author="stack" created="Sat, 20 Mar 2010 20:54:10 +0000"  >&lt;p&gt;+1 on updating the patch.  I just tried to do it and its a little involved so left it to the expert.&lt;/p&gt;

&lt;p&gt;I&apos;ve been doing a rough benchmarking of 0.20.2 hbase so I can measure roughly how this patch effects coarse performance (I didn&apos;t bother measuring 0.20.3.  It must be slower than 0.20.2).&lt;/p&gt;</comment>
                            <comment id="12853624" author="ryanobjc" created="Tue, 6 Apr 2010 00:51:24 +0000"  >&lt;p&gt;Here is my update to my patch, this time I am using iterators to scan the memstore and snapshot.  There are a number of fixes to all sorts of fun race conditions, etc.&lt;/p&gt;

&lt;p&gt;The best news: this is the fastest memstore scanner HBase has seen.  It is about 15x faster than the 0.20.3 version based on the microbenchmark included in the patch.  The old code takes about 400-500ms to scan 250k KeyValues in memstore, and this new patch takes 25-30ms.&lt;/p&gt;

&lt;p&gt;I haven&apos;t run all the tests yet, but it passes the core TestMemStore and TestHRegion which contain all the hard tests that have concurrency.&lt;/p&gt;</comment>
                            <comment id="12853683" author="ryanobjc" created="Tue, 6 Apr 2010 01:39:08 +0000"  >&lt;p&gt;a version that compiles and passes TestHeapSize&lt;/p&gt;</comment>
                            <comment id="12854828" author="stack" created="Thu, 8 Apr 2010 06:29:33 +0000"  >&lt;p&gt;Can we have a version for 0.20_pre_durability branch Ryan?  There are a bunch of failures all in HRegion.  Some I can sort of make sense of but others would take me a while to figure.  You know the code so would probably take you short amount of time?&lt;/p&gt;</comment>
                            <comment id="12855098" author="stack" created="Thu, 8 Apr 2010 19:10:01 +0000"  >&lt;p&gt;This is a big patch.  Can we have a bit more detail than what is given above on what it does to help w/ review?&lt;/p&gt;

&lt;p&gt;Here&apos;s some comments so far:&lt;/p&gt;

&lt;p&gt;In KV, this looks like a fix to the comparator:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (rcolumnlength == 0 &amp;amp;&amp;amp; rtype == Type.Minimum.getCode()) {
+        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -1;
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If we had a getScan datamember flag &amp;#8211; true if this scan is a Get scan &amp;#8211; we could set it if the constructor that takes a Get is invoked and avoid comparing start and end rows.  If flag is not set, go ahead and do the compare.&lt;/p&gt;

&lt;p&gt;Want to remove this?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+&lt;span class=&quot;code-comment&quot;&gt;//    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (LOG.isDebugEnabled()) {
&lt;/span&gt;+&lt;span class=&quot;code-comment&quot;&gt;//      LOG.debug(&lt;span class=&quot;code-quote&quot;&gt;&quot;compareResult=&quot;&lt;/span&gt; + compareResult + &lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt; + Bytes.toString(data, offset, length));
&lt;/span&gt;+&lt;span class=&quot;code-comment&quot;&gt;//    }&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This has to be public?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; ReadWriteConsistencyControl getRWCC() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is this unused?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  @SuppressWarnings({&lt;span class=&quot;code-quote&quot;&gt;&quot;UnusedDeclaration&quot;&lt;/span&gt;})
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] REGIONINFO_FILE_BYTES =
     Bytes.toBytes(REGIONINFO_FILE);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Remove it then?&lt;/p&gt;

&lt;p&gt;Same here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  @SuppressWarnings({&lt;span class=&quot;code-quote&quot;&gt;&quot;UnusedDeclaration&quot;&lt;/span&gt;})
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getRegionId() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are a bunch of them.&lt;/p&gt;

&lt;p&gt;I&apos;m about 1/5th done.  So far patch looks great.&lt;/p&gt;</comment>
                            <comment id="12855130" author="apurtell" created="Thu, 8 Apr 2010 20:22:38 +0000"  >&lt;p&gt;When I run alpha3 on top of 0.20 head I see delete test failures in :&lt;/p&gt;

&lt;p&gt;Testcase: testWeirdCacheBehaviour took 81.599 sec&lt;br/&gt;
Testcase: testFilterAcrossMutlipleRegions took 47.8 sec&lt;br/&gt;
Testcase: testSuperSimple took 18.15 sec&lt;br/&gt;
Testcase: testFilters took 15.781 sec&lt;br/&gt;
Testcase: testSimpleMissing took 16.448 sec&lt;br/&gt;
Testcase: testSingleRowMultipleFamily took 16.686 sec&lt;br/&gt;
Testcase: testNull took 21.443 sec&lt;br/&gt;
Testcase: testVersions took 18.169 sec&lt;br/&gt;
Testcase: testVersionLimits took 15.861 sec&lt;br/&gt;
Testcase: testDeletes took 15.837 sec&lt;br/&gt;
        Caused an ERROR&lt;br/&gt;
null&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.client.TestClient.testDeletes(TestClient.java&lt;br/&gt;
:1608)&lt;/p&gt;

&lt;p&gt;Testcase: testJIRAs took 46.161 sec&lt;/p&gt;

&lt;p&gt;Need more detail? &lt;/p&gt;



</comment>
                            <comment id="12855160" author="stack" created="Thu, 8 Apr 2010 21:21:09 +0000"  >&lt;p&gt;Why do this?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      List&amp;lt;KeyValue&amp;gt; results = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;KeyValue&amp;gt;();
-      store.get(get, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, results);
-      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Result(results);
+      get.addFamily(family);
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; get(get, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is it because of this....up in HRegion:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-comment&quot;&gt;// The reason why we set it up high is so that each HRegionScanner only
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// has a single read point &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all its sub-StoreScanners.
&lt;/span&gt;+      ReadWriteConsistencyControl.resetThreadReadPoint(rwcc);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This bit of the patch looks like its breaking the accumulation of qualifiers:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-            List&amp;lt;KeyValue&amp;gt; result = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;KeyValue&amp;gt;(1);
-            Get g = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Get(kv.getRow());
-            g.setMaxVersions(count);
-            NavigableSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; []&amp;gt; qualifiers =
-              &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; []&amp;gt;(Bytes.BYTES_COMPARATOR);
-            qualifiers.add(qual);
-            get(store, g, qualifiers, result);
+            Get get = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Get(kv.getRow());
+            get.setMaxVersions(count);
+            get.addColumn(family, qual);
+
+            List&amp;lt;KeyValue&amp;gt; result = get(get);
+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Or is this no longer needed because we go back into Region.get rather than do a Store.get?&lt;/p&gt;

&lt;p&gt;I don&apos;t like this if clause style:&lt;/p&gt;

&lt;p&gt;+      if (w != null)&lt;br/&gt;
+      rwcc.completeMemstoreInsert(w);&lt;/p&gt;

&lt;p&gt;I&apos;d suggest you either wrap it in params or put it all on the one line. &lt;/p&gt;

&lt;p&gt;For example, undo changes like this I&apos;d say:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(lockid == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) releaseRowLock(lid);
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(lockid == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
+        releaseRowLock(lid);

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think this needs a comment:&lt;/p&gt;

&lt;p&gt;+    private int isScan;&lt;/p&gt;

&lt;p&gt;or maybe where its assigned so its clear why it can&apos;t be a boolean though its named as though it were one... maybe change its name?&lt;/p&gt;

&lt;p&gt;I don&apos;t get this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-comment&quot;&gt;// TODO call the proper GET API
&lt;/span&gt;       &lt;span class=&quot;code-comment&quot;&gt;// Get the old value:
&lt;/span&gt;       Get get = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Get(row);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;//noinspection SuspiciousMethodCalls&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Why this change Ryan?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-class KeyValueSkipListSet &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; NavigableSet&amp;lt;KeyValue&amp;gt;, &lt;span class=&quot;code-object&quot;&gt;Cloneable&lt;/span&gt; {
+class KeyValueSkipListSet &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; NavigableSet&amp;lt;KeyValue&amp;gt; {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Its crazy how much code you&apos;ve removed from MemStore around #195.&lt;/p&gt;

&lt;p&gt;Ok, thats enough for now&lt;/p&gt;</comment>
                            <comment id="12855188" author="ryanobjc" created="Thu, 8 Apr 2010 22:28:46 +0000"  >&lt;p&gt;this patch fixes the testDelete failure that people have been seeing. it should apply on both 0.20 and 0.20_pre_durability patches&lt;/p&gt;</comment>
                            <comment id="12855279" author="stack" created="Fri, 9 Apr 2010 05:48:02 +0000"  >&lt;p&gt;Running unit tests, at least this one is failing for me:&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.hadoop.hbase.TestRegionRebalancing FAILED (timeout)&lt;/p&gt;
</comment>
                            <comment id="12855282" author="stack" created="Fri, 9 Apr 2010 05:52:21 +0000"  >&lt;p&gt;I&apos;m trying to run on cluster but its all hanging on me.  Its probably a config. messup on my part. Trying to figure it.&lt;/p&gt;

&lt;p&gt;Meantime, this seems to run about 3-4 times slower than release against a standalone hbase:&lt;/p&gt;

&lt;p&gt;$ ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation sequentialWrite 1&lt;/p&gt;</comment>
                            <comment id="12855291" author="apurtell" created="Fri, 9 Apr 2010 06:08:40 +0000"  >&lt;p&gt;0.20_pre_durability branch plus &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;-rr-pre-durability2.txt passes rebalancing for me but fails TestIdxHBaseCluster consistently.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Testcase: testConcurrentReadWrite took 93.349 sec
	FAILED
nextCount=0, count=2, finalCount=2000
junit.framework.AssertionFailedError: nextCount=0, count=2, finalCount=2000
	at org.apache.hadoop.hbase.TestIdxHBaseCluster.testConcurrentReadWrite(TestIdxHBaseCluster.java:123)

Testcase: testHBaseCluster took 41.074 sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before the patch the indexed contrib tests pass on 0.20_pre_durability. &lt;/p&gt;</comment>
                            <comment id="12855292" author="stack" created="Fri, 9 Apr 2010 06:09:49 +0000"  >&lt;p&gt;In the above I&apos;m trying to test branch of branch.   All core tests but above noted rebalancing passed.&lt;/p&gt;</comment>
                            <comment id="12855308" author="ryanobjc" created="Fri, 9 Apr 2010 07:40:31 +0000"  >&lt;p&gt;unfortunately the way the branch and the branch-of-branch does things have diverged a lot.  specifically the locations of the update lock and the flush request. I rearranged things a bunch and have this new patch.  This might help with the PE slowness and other things as well.&lt;/p&gt;</comment>
                            <comment id="12855477" author="apurtell" created="Fri, 9 Apr 2010 17:09:23 +0000"  >&lt;p&gt;On head of 0.20_pre_durability and patch rr-pre_durability3.txt I see this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Testcase: testWritesWhileScanning took 0.155 sec
          FAILED
i=36 expected&amp;lt;1000&amp;gt; but was: &amp;lt;0&amp;gt;
junit.framework.AssertionFailedError: i=36 expected:&amp;lt;1000&amp;gt; but was: &amp;lt;0&amp;gt;
          at org.apache.hadoop.hbase.regionserver.TestHRegion.testWritesWhileScanning(TestHRegion.java:2014)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="12855504" author="stack" created="Fri, 9 Apr 2010 18:09:49 +0000"  >&lt;p&gt;I&apos;m about 50% through &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;-rr-alpha3.txt:&lt;/p&gt;

&lt;p&gt;ReadWriteConsistencyControl is missing a license (I like thename of this class and its nice and clean looking).&lt;/p&gt;

&lt;p&gt;This could be final:&lt;/p&gt;

&lt;p&gt;+    private long writeNumber;&lt;/p&gt;

&lt;p&gt;This class doesn&apos;t have to be public: &lt;/p&gt;

&lt;p&gt;+  public static class WriteEntry {&lt;/p&gt;

&lt;p&gt;Can you explain the below better please?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    &lt;span class=&quot;code-comment&quot;&gt;// The Get returns the latest value but then does not &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the
&lt;/span&gt;-    &lt;span class=&quot;code-comment&quot;&gt;// oldest, which was never deleted, ts[1]. 
&lt;/span&gt;-    
+
+    &lt;span class=&quot;code-comment&quot;&gt;// It used to be due to the internal implementation of Get, that
&lt;/span&gt;+    &lt;span class=&quot;code-comment&quot;&gt;// the Get() call would &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ts[4] UNLIKE the Scan below. With
&lt;/span&gt;+    &lt;span class=&quot;code-comment&quot;&gt;// the &lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt; to using Scan &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Get &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is no longer the &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;.
&lt;/span&gt;     get = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Get(ROW);
     get.addFamily(FAMILIES[0]);
     get.setMaxVersions(&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE);
     result = ht.get(get);
     assertNResult(result, ROW, FAMILIES[0], QUALIFIER, 
-        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; [] {ts[2], ts[3], ts[4]},
-        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[][] {VALUES[2], VALUES[3], VALUES[4]},
+        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; [] {ts[1], ts[2], ts[3]},
+        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[][] {VALUES[1], VALUES[2], VALUES[3]},
         0, 2);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Reading it, it would seem that we should be getting ts&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt; because we just added it previous?&lt;/p&gt;

&lt;p&gt;Why do this?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    Scan scan = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Scan();
-    scan.setFilter(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RowFilter(CompareFilter.CompareOp.EQUAL,
-      &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BinaryComparator(Bytes.toBytes(&lt;span class=&quot;code-quote&quot;&gt;&quot;row0&quot;&lt;/span&gt;))));
+    Scan scan = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Scan(Bytes.toBytes(&lt;span class=&quot;code-quote&quot;&gt;&quot;row0&quot;&lt;/span&gt;), Bytes.toBytes(&lt;span class=&quot;code-quote&quot;&gt;&quot;row1&quot;&lt;/span&gt;));
+&lt;span class=&quot;code-comment&quot;&gt;//    scan.setFilter(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RowFilter(CompareFilter.CompareOp.EQUAL,
&lt;/span&gt;+&lt;span class=&quot;code-comment&quot;&gt;//      &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BinaryComparator(Bytes.toBytes(&lt;span class=&quot;code-quote&quot;&gt;&quot;row0&quot;&lt;/span&gt;))));&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Otherwise, patch looks great.&lt;/p&gt;

&lt;p&gt;This patch needs to be release noted describing how it changes how Get works.&lt;/p&gt;
</comment>
                            <comment id="12855636" author="stack" created="Sat, 10 Apr 2010 19:59:25 +0000"  >&lt;p&gt;Testing I&apos;m hanging when lots of concurrency at HLog.append at the synchronization on the updateLock inside the append method.  Its strange.  A bunch of threads are BLOCKED at this explicit line.  All but one say &quot;waiting to lock&quot;.  A single thread is BLOCKED but it has &apos;locked&apos; successfully, as though it should have moved on but it shows same location in stack trace (same line number) and there doesn&apos;t seem to be anything in the block that threads could contend over.  &lt;/p&gt;

&lt;p&gt;Trying w/ different JVMs to see if I can get move info.&lt;/p&gt;</comment>
                            <comment id="12855648" author="stack" created="Sat, 10 Apr 2010 21:33:19 +0000"  >&lt;p&gt;So, its not a lockup, rather, stuff is working but really, really slow.  It seems to be this patch because going back to a clean hadoop 0.20.2 and the current state of pre_durability branch, all runs fine again (until we do an actual deadlock, i.e. the known deadlock issue).  I&apos;ll spend more time trying to figure it but here is how it looks when you thread dump:&lt;/p&gt;

&lt;p&gt;Most threads are &apos;WAITING&apos;, etc. and then a good few are like the below BLOCKED:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;IPC Server handler 36 on 60020&quot;&lt;/span&gt; daemon prio=10 tid=0x273e4400 nid=0x2888 waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; monitor entry [0x257ad000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.regionserver.HLog.append(HLog.java:646)
        - waiting to lock &amp;lt;0x3d5ec6a0&amp;gt; (a java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Invariabley, there is one &apos;abnormal&apos; BLOCKED that is the same as above &amp;#8211; excepting thread names etc. &amp;#8211; in all except &apos;waiting to lock&apos; is instead &apos;locked&apos; &amp;#8211; same line number and everything.&lt;/p&gt;

&lt;p&gt;I&apos;ll keep digging.&lt;/p&gt;</comment>
                            <comment id="12855799" author="apurtell" created="Mon, 12 Apr 2010 00:44:02 +0000"  >&lt;p&gt;I see the same results as Stack testing up on EC2, with 1.6.0_14 (64 bit). First thing I do is warm the cluster with PE --nomapred randomWrite N (usually N=10 or 15). Not a deadlock, but writes get really slow fast. Without the high write concurrency (N=1 or 3) it&apos;s better. &lt;/p&gt;</comment>
                            <comment id="12856015" author="apurtell" created="Mon, 12 Apr 2010 15:26:42 +0000"  >&lt;p&gt;We spend 76% of CPU time in ReadWriteConsistencyControl.completeMemstoreInsert. See attached &apos;profile.png&apos;. Draining the write queue (for 42,175 puts?) explodes 42,166 calls to ReadWriteConsistencyControl.completeMemstoreInsert into 121,118,233 calls to AtomicLong.get and 121,143,574 calls to $WriteEntry.getWriteNumber, each arc represents 50% of the cumulative time there. See attached &apos;put_call_graph.png&apos;.&lt;/p&gt;</comment>
                            <comment id="12856018" author="apurtell" created="Mon, 12 Apr 2010 15:28:30 +0000"  >&lt;p&gt;From Ryan via email:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is a busy wait loop which attempts to ensure a write completes only when it is visible to others. With the log append as part of the &quot;transaction&quot; this is breaking down. The solution is to either forgo the busy wait loop (probably not a great idea) or restructure the code to do hlog appends first then memstore updates.&lt;/p&gt;

&lt;p&gt;I&apos;ll talk to stack tomorrow and we can figure which route is better... Although I&apos;d guess option #2&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="12856105" author="stack" created="Mon, 12 Apr 2010 18:23:49 +0000"  >&lt;p&gt;The release note for this issue needs to include note of how versioning and delete changes (I was going to say we should add new issue to add more extensive unit testing of our claim that versions will come out in right order now regardless of how they are put in, but we already have an issue for that &amp;#8211; the ACID spec tests issue).&lt;/p&gt;</comment>
                            <comment id="12856752" author="ryanobjc" created="Wed, 14 Apr 2010 04:47:49 +0000"  >&lt;p&gt;ok here is a patch that addresses all the above issues:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;spin fixed by restructuring hlog append&lt;/li&gt;
	&lt;li&gt;index test pass failure fixed&lt;/li&gt;
	&lt;li&gt;test failures due to compaction&lt;/li&gt;
	&lt;li&gt;all comments addressed&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;To accomplish the index hbase fix, I had to introduce a new notion of optional scanner creation atomicity along with pre-flush-commit work, so a sub-class can create an atomic section whereby some work is done (eg: switching out an index) and the flush commit (where the snapshot is removed and the hfile is introduced to open scanners) and this atomic section will be atomic relative to new scanner creation.  This was required to fix race conditions in indexed hbase, which also means that indexed hbase is not as fast as it can be, since it cannot create new scanners during this one critical phase of flush (which includes re-reading scanner blocks btw).&lt;/p&gt;
</comment>
                            <comment id="12856759" author="stack" created="Wed, 14 Apr 2010 05:31:55 +0000"  >&lt;p&gt;This last patch is looking good.  The spin lock slowing writes is gone it looks like and most of the tests are passing.  Will report more in morning.  Will let tests run overnight.&lt;/p&gt;</comment>
                            <comment id="12857007" author="stack" created="Wed, 14 Apr 2010 18:24:03 +0000"  >&lt;p&gt;All tests but this in &apos;indexed&apos; pass:&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.hadoop.hbase.regionserver.TestIdxRegionIndexManager FAILED&lt;/p&gt;

&lt;p&gt;My cluster test failed but for reasons other than would be attributable to this patch.  I did not deadlock.&lt;/p&gt;</comment>
                            <comment id="12857109" author="stack" created="Wed, 14 Apr 2010 21:41:23 +0000"  >&lt;p&gt;I&apos;m going to commit this.  All tests pass if I remove &apos;indexed&apos;.  Patch looks good.  I have cluster issues but unrelated to this patch.  Logs for regionservers look good.&lt;/p&gt;</comment>
                            <comment id="12857117" author="stack" created="Wed, 14 Apr 2010 21:57:26 +0000"  >&lt;p&gt;Thanks all who contributed to this issue: Todd, Dan, Yoram and in particular Ryan.&lt;/p&gt;</comment>
                            <comment id="12857174" author="ryanobjc" created="Thu, 15 Apr 2010 01:39:50 +0000"  >&lt;p&gt;here is the updated version with fixes taken from the work on the 0.20_pre_durability but on plain old 0.20.&lt;/p&gt;</comment>
                            <comment id="12857560" author="ryanobjc" created="Thu, 15 Apr 2010 21:49:07 +0000"  >&lt;p&gt;this removes row locks which are no longer necessary to ensure atomic reads&lt;/p&gt;</comment>
                            <comment id="12857567" author="streamy" created="Thu, 15 Apr 2010 22:10:36 +0000"  >&lt;p&gt;ryan, can you explain more about removal of row locks?  seems like your patch just touches the simple get case that takes a row lock.  Are client-exposed row locks completely gone now?&lt;/p&gt;</comment>
                            <comment id="12857569" author="stack" created="Thu, 15 Apr 2010 22:15:45 +0000"  >&lt;p&gt;@Jon No.. just the row lock around the Get.  The client-side row lock still in place.&lt;/p&gt;

&lt;p&gt;I just tested it up on cluster and seems to run fine.  Going to commit.&lt;/p&gt;</comment>
                            <comment id="12858520" author="ryanobjc" created="Mon, 19 Apr 2010 14:46:14 +0000"  >
&lt;p&gt;   [[ Old comment, sent by email on Wed, 14 Apr 2010 14:43:49 -0700 ]]&lt;/p&gt;

&lt;p&gt;the previous idx test break was a simple heap check break, so easy to&lt;br/&gt;
fix in the eventual destination. the core of the indexed stuff seemed&lt;br/&gt;
to work.&lt;/p&gt;

</comment>
                            <comment id="12858527" author="apurtell" created="Mon, 19 Apr 2010 14:47:30 +0000"  >
&lt;p&gt;   [[ Old comment, sent by email on Wed, 14 Apr 2010 04:52:37 +0000 ]]&lt;/p&gt;

&lt;p&gt;Thanks Ryan! Testing now.&lt;/p&gt;

</comment>
                            <comment id="12858593" author="stack" created="Mon, 19 Apr 2010 17:00:13 +0000"  >&lt;p&gt;Hey Ryan, commit this to branch and TRUNK.  Testing over in branch-of-branch says its good.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12459045">HBASE-2322</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12457101">HBASE-2249</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12457384">HBASE-2265</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12473267">HBASE-2959</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12458312">HBASE-2294</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12441881" name="ASF.LICENSE.NOT.GRANTED--HBASE-2248-no-row-locks.txt" size="3587" author="ryanobjc" created="Thu, 15 Apr 2010 21:49:07 +0000"/>
                            <attachment id="12441785" name="ASF.LICENSE.NOT.GRANTED--HBASE-2248-rr-final1.txt" size="108115" author="ryanobjc" created="Thu, 15 Apr 2010 01:39:50 +0000"/>
                            <attachment id="12441688" name="ASF.LICENSE.NOT.GRANTED--HBASE-2248-rr-pre-durability4.txt" size="129240" author="ryanobjc" created="Wed, 14 Apr 2010 04:47:49 +0000"/>
                            <attachment id="12441500" name="ASF.LICENSE.NOT.GRANTED--profile.png" size="187541" author="apurtell" created="Mon, 12 Apr 2010 15:26:42 +0000"/>
                            <attachment id="12441501" name="ASF.LICENSE.NOT.GRANTED--put_call_graph.png" size="130410" author="apurtell" created="Mon, 12 Apr 2010 15:26:42 +0000"/>
                            <attachment id="12438577" name="HBASE-2248-GetsAsScans3.patch" size="194399" author="stack" created="Fri, 12 Mar 2010 05:31:57 +0000"/>
                            <attachment id="12436876" name="HBASE-2248-demonstrate-previous-impl-bugs.patch" size="14297" author="stack" created="Wed, 24 Feb 2010 17:48:46 +0000"/>
                            <attachment id="12437174" name="HBASE-2248.patch" size="10966" author="stack" created="Fri, 26 Feb 2010 12:55:11 +0000"/>
                            <attachment id="12436737" name="Screen shot 2010-02-23 at 10.33.38 AM.png" size="71664" author="stack" created="Tue, 23 Feb 2010 18:39:51 +0000"/>
                            <attachment id="12436730" name="hbase-2248.gc" size="68252" author="davelatham" created="Tue, 23 Feb 2010 18:09:30 +0000"/>
                            <attachment id="12437967" name="hbase-2248.txt" size="5452" author="tlipcon" created="Fri, 5 Mar 2010 03:53:28 +0000"/>
                            <attachment id="12437964" name="readownwrites-lost.2.patch" size="3109" author="tlipcon" created="Fri, 5 Mar 2010 03:25:44 +0000"/>
                            <attachment id="12437963" name="readownwrites-lost.patch" size="2634" author="tlipcon" created="Fri, 5 Mar 2010 03:14:16 +0000"/>
                            <attachment id="12436646" name="threads.txt" size="12061" author="davelatham" created="Mon, 22 Feb 2010 23:35:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 23 Feb 2010 00:02:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26223</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 35 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08srz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>49262</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This patch changes the Get code path to instead be a Scan of one row.  This means than inserting cells out of timestamp order should work now (tests to verify to follow part of hbase-2294) but also that a delete at an explicit timestamp now overshadows EVEN if the effected cell is put after the delete (The old Get code path did early-out so a subsequent puts would not see the delete).</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>