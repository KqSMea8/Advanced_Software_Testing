<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:10:20 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3451/HBASE-3451.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3451] Cluster migration best practices</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3451</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Mozilla is currently in the process of trying to migrate our HBase cluster to a new datacenter.&lt;/p&gt;

&lt;p&gt;We have our existing 25 node cluster in our SJC datacenter.  It is serving production traffic 24/7.  While we can take downtimes, it is very costly and difficult to take them for more than a few hours in the evening.&lt;/p&gt;

&lt;p&gt;We have two new 30 node clusters in our PHX datacenter.  We are wanting to cut production over to one of these this week.&lt;/p&gt;

&lt;p&gt;The old cluster is running 0.20.6.  The new clusters are running CDH3b3 with HBase 0.89.&lt;/p&gt;

&lt;p&gt;We have tried running a pull distcp using hftp URLs.  If HBase is running, this causes SAX XML Parsing exceptions when a directory is removed during the scan.&lt;br/&gt;
If HBase is stopped, it takes hours for the directory compare to finish before it even begins copying data.&lt;/p&gt;

&lt;p&gt;We have tried a custom backup MR job.  This job uses the map phase to evaluate and copy changed files. It can run while HBase is live, but that results in a dirty copy of the data.&lt;/p&gt;

&lt;p&gt;We have tried running the custom backup job while HBase is shut down as well.  When we do this, even on two back to back runs, it still copies over some data and seems to not be an entirely clean copy.&lt;/p&gt;

&lt;p&gt;When we have gotten what we thought was an entire copy onto the new cluster, we ran add_table on it, but the resulting hbase table had holes.  Investigating the holes revealed there were directories that were not transfered.&lt;/p&gt;

&lt;p&gt;We had a meeting to brainstorm ideas and two further suggestions that came up were:&lt;br/&gt;
1. Build a file list of files to transfer on the SJC side, transfer that file list to PHX and then run distcp on it.&lt;br/&gt;
2. Try a full copy instead of incremental, skipping the expensive file compare step&lt;br/&gt;
3. Evaluate copying from SJC to S3 then from S3 to PHX.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12495911">HBASE-3451</key>
            <summary>Cluster migration best practices</summary>
                <type id="13" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Brainstorming</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="deinspanjer">Daniel Einspanjer</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Jan 2011 17:04:50 +0000</created>
                <updated>Tue, 12 Aug 2014 19:22:30 +0000</updated>
                            <resolved>Tue, 12 Aug 2014 19:22:30 +0000</resolved>
                                    <version>0.20.6</version>
                    <version>0.89.20100924</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="12983296" author="stack" created="Tue, 18 Jan 2011 18:11:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;We have tried running a pull distcp using hftp URLs. If HBase is running, this causes SAX XML Parsing exceptions when a directory is removed during the scan.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can I see the stack trace?  Maybe we need to hack on distcp so it runs over a moved dir?  Or change it so it snapshots dirs up front and doesn&apos;t do a compare?&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;We have tried a custom backup MR job. This job uses the map phase to evaluate and copy changed files. It can run while HBase is live, but that results in a dirty copy of the data.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This seems right.  Then have another job which goes through and does reconciliation after the fact.  Run it a few times.  Finally run it when HBase is down so true copy.  Is this even possible?&lt;/p&gt;

&lt;p&gt;As Gary asks in IRC, whats the intra-DC bandwidth like?&lt;/p&gt;
</comment>
                            <comment id="12983310" author="deinspanjer" created="Tue, 18 Jan 2011 18:29:43 +0000"  >&lt;p&gt;30TB full data set.  iperf tested at 272 Mbps&lt;/p&gt;

&lt;p&gt;Will get you the stack trace later today.&lt;/p&gt;

&lt;p&gt;The problem with the custom backup job is that it didn&apos;t deliver a clean result set even though we ran two back to back with HBase down.  We don&apos;t understand exactly why this didn&apos;t work.&lt;/p&gt;</comment>
                            <comment id="12983371" author="deinspanjer" created="Tue, 18 Jan 2011 20:50:55 +0000"  >&lt;p&gt;Tonight we are going to be trying a modified invocation of distcp:&lt;br/&gt;
1. dfs -lsr /hbase on SJC cluster&lt;br/&gt;
2. dfs -lsr /hbase on PHX cluster&lt;br/&gt;
3. Python script that diffs those two file lists looking for missing, orphaned, or changed files.&lt;br/&gt;
4. Save diff results into a file list on PHX&lt;br/&gt;
5. Invoke distcp with overwrite flag using that file list.&lt;/p&gt;

&lt;p&gt;Anyone see potential gotchas with that?&lt;/p&gt;</comment>
                            <comment id="12983372" author="deinspanjer" created="Tue, 18 Jan 2011 20:51:49 +0000"  >&lt;p&gt;Diffing python script:&lt;br/&gt;
&lt;a href=&quot;http://xstevens.pastebin.mozilla.org/956095&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://xstevens.pastebin.mozilla.org/956095&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12983527" author="stack" created="Wed, 19 Jan 2011 03:51:41 +0000"  >&lt;p&gt;@Daniel You can run the above multiple times in case SJC changes during copy to PHX?  Regards script, apart from what looks like code dup reading the files, it seems fine.  You tried it?&lt;/p&gt;</comment>
                            <comment id="12983544" author="deinspanjer" created="Wed, 19 Jan 2011 06:10:46 +0000"  >&lt;p&gt;Anyone ever try to distcp hbase data using a file list?&lt;/p&gt;

&lt;p&gt;We got this error:&lt;br/&gt;
11/01/18 21:21:50 INFO tools.DistCp: destPath=hdfs://hp-node70.phx1.mozilla.com:8020/hbase&lt;br/&gt;
org.apache.hadoop.tools.DistCp$DuplicationException: Invalid input, there are duplicated files in the sources: hftp://cm-hadoop-adm03.mozilla.org:50070/hbase/archive/683263177/.regioninfo, hftp://cm-hadoop-adm03.mozilla.org:50070/hbase/crash_counts/2038233953/.regioninfo&lt;br/&gt;
	at org.apache.hadoop.tools.DistCp.checkDuplication(DistCp.java:1383)&lt;br/&gt;
	at org.apache.hadoop.tools.DistCp.setup(DistCp.java:1186)&lt;br/&gt;
	at org.apache.hadoop.tools.DistCp.copy(DistCp.java:666)&lt;br/&gt;
	at org.apache.hadoop.tools.DistCp.run(DistCp.java:881)&lt;br/&gt;
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)&lt;br/&gt;
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)&lt;br/&gt;
	at org.apache.hadoop.tools.DistCp.main(DistCp.java:908)&lt;/p&gt;

&lt;p&gt;It seems that checkDuplication doesn&apos;t evaluate the full path and hence will choke the first time it evaluates two .regioninfo files.&lt;/p&gt;</comment>
                            <comment id="14094547" author="apurtell" created="Tue, 12 Aug 2014 19:22:30 +0000"  >&lt;p&gt;Stale brainstorming issue, closing&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 18 Jan 2011 18:11:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33029</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 18 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02b9j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11426</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>