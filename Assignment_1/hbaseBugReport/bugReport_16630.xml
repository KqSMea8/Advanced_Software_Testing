<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:16:06 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-16630/HBASE-16630.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-16630] Fragmentation in long running Bucket Cache</title>
                <link>https://issues.apache.org/jira/browse/HBASE-16630</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;As we are running bucket cache for a long time in our system, we are observing cases where some nodes after some time does not fully utilize the bucket cache, in some cases it is even worse in the sense they get stuck at a value &amp;lt; 0.25 % of the bucket cache (DEFAULT_MEMORY_FACTOR as all our tables are configured in-memory for simplicity sake).&lt;/p&gt;

&lt;p&gt;We took a heap dump and analyzed what is happening and saw that is classic case of fragmentation, current implementation of BucketCache (mainly BucketAllocator) relies on the logic that fullyFreeBuckets are available for switching/adjusting cache usage between different bucketSizes . But once a compaction / bulkload happens and the blocks are evicted from a bucket size , these are usually evicted from random places of the buckets of a bucketSize and thus locking the number of buckets associated with a bucketSize and in the worst case of the fragmentation we have seen some bucketSizes with occupancy ratio of &amp;lt;  10 % But they dont have any completelyFreeBuckets to share with the other bucketSize. &lt;/p&gt;

&lt;p&gt;Currently the existing eviction logic helps in the cases where cache used is more the MEMORY_FACTOR or MULTI_FACTOR and once those evictions are also done, the eviction (freeSpace function) will not evict anything and the cache utilization will be stuck at that value without any allocations for other required sizes.&lt;/p&gt;

&lt;p&gt;The fix for this we came up with is simple that we do deFragmentation ( compaction) of the bucketSize and thus increasing the occupancy ratio and also freeing up the buckets to be fullyFree, this logic itself is not complicated as the bucketAllocator takes care of packing the blocks in the buckets, we need evict and re-allocate the blocks for all the BucketSizes that dont fit the criteria.&lt;/p&gt;

&lt;p&gt;I am attaching an initial patch just to give an idea of what we are thinking and I&apos;ll improve it based on the comments from the community.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13004762">HBASE-16630</key>
            <summary>Fragmentation in long running Bucket Cache</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="dvdreddy">deepankar</assignee>
                                    <reporter username="dvdreddy">deepankar</reporter>
                        <labels>
                    </labels>
                <created>Wed, 14 Sep 2016 00:59:32 +0000</created>
                <updated>Thu, 1 Dec 2016 13:57:50 +0000</updated>
                                            <version>2.0.0</version>
                    <version>1.1.6</version>
                    <version>1.3.1</version>
                    <version>1.2.3</version>
                                                    <component>BucketCache</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="15488995" author="dvdreddy" created="Wed, 14 Sep 2016 01:06:26 +0000"  >&lt;p&gt;ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;, any suggestions ?&lt;/p&gt;</comment>
                            <comment id="15489130" author="aoxiang" created="Wed, 14 Sep 2016 02:24:47 +0000"  >&lt;p&gt;Nice finding&#65281;&lt;/p&gt;</comment>
                            <comment id="15489149" author="yuzhihong@gmail.com" created="Wed, 14 Sep 2016 02:34:06 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt; nonZeroUsedCount = 0.0f, nonZeroFreeCount = 0.0f;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above don&apos;t have to be float, right ? nonZeroUsedCount / (nonZeroFreeCount + nonZeroUsedCount) can be calculated in float.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (BlockCacheKey key : backingMap.keySet()) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Use entrySet to iterate the Map.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-comment&quot;&gt;// Skip the relocation &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; somebody is using it
&lt;/span&gt;+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (bucketEntry.refCount.get() &amp;gt; 0 || bucketEntry.markedForEvict) {
+        &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Consider moving the above ahead of bucketSizesForFragmentation.contains() check since the above check is cheaper.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
+        lock.readLock().unlock();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why unlocking read lock when write lock is obtained at the beginning of try block ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-comment&quot;&gt;// We can not read here even &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; backingMap does contain the given key because its offset&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Typo: read&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException ioex) {
+        LOG.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;Failed reading block &quot;&lt;/span&gt; + key + &lt;span class=&quot;code-quote&quot;&gt;&quot; from bucket cache&quot;&lt;/span&gt;, ioex);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Do all IOE correspond to read error ?&lt;/p&gt;

&lt;p&gt;Is it possible to add a unit test ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15489206" author="aoxiang" created="Wed, 14 Sep 2016 03:03:50 +0000"  >&lt;p&gt;Looks like there is extra copy in deFragment, it is possible to reduce it?&lt;/p&gt;</comment>
                            <comment id="15489225" author="vrodionov" created="Wed, 14 Sep 2016 03:14:27 +0000"  >&lt;p&gt;Defragmentation is hard. (Full GC is an example). Any estimate on a running time for 500GB cache with compressed blocks 10Kb in average (50M total) ?&lt;/p&gt;

&lt;p&gt;I think it should be done in a background and incrementally.&lt;/p&gt;</comment>
                            <comment id="15489234" author="aoxiang" created="Wed, 14 Sep 2016 03:19:52 +0000"  >&lt;p&gt;If i am not wrong, the Defragmentation is done by WriterThread, which is a background thread.&lt;/p&gt;</comment>
                            <comment id="15489235" author="vrodionov" created="Wed, 14 Sep 2016 03:20:25 +0000"  >&lt;p&gt;How about offheap read support? Does it include reading directly from off heap cache? If, yes, then defragmentation will result  in SIGSEGV.&lt;/p&gt;</comment>
                            <comment id="15489238" author="vrodionov" created="Wed, 14 Sep 2016 03:21:36 +0000"  >&lt;p&gt;It requires full cache lock?&lt;/p&gt;</comment>
                            <comment id="15489240" author="aoxiang" created="Wed, 14 Sep 2016 03:22:30 +0000"  >&lt;p&gt;So it will affect flushing the RAM cache to IOEngine.&lt;/p&gt;</comment>
                            <comment id="15489253" author="vrodionov" created="Wed, 14 Sep 2016 03:27:52 +0000"  >&lt;p&gt;How about block reads during defragmentation? I think, they will be affected too. So, full lock for a long time? Still does not answer question how to to avoid SIGSEGV for clients (HFileBlock) who reads directly from off heap cache (it is coming in 2.0)&lt;/p&gt;</comment>
                            <comment id="15489282" author="dvdreddy" created="Wed, 14 Sep 2016 03:40:04 +0000"  >&lt;p&gt;I&apos;ll remove the full lock, essentially the lock is to make sure only one write is happening, reads are unaffected as we skip the blocks that are currently being used in the read by checking their refCount. SIGSEV will also not an issue as this Defragmentation is the software one, underneath everything is backed by a large array of byteBuffers we are not allocating / deallocating anything we are just overwriting / releasing from the java level meta data&lt;/p&gt;</comment>
                            <comment id="15489287" author="dvdreddy" created="Wed, 14 Sep 2016 03:41:23 +0000"  >&lt;p&gt;This is correct, Defragmentation does not affect anything in the RPC response path, it happens in the said background WriterThread.&lt;/p&gt;</comment>
                            <comment id="15489291" author="dvdreddy" created="Wed, 14 Sep 2016 03:43:26 +0000"  >&lt;p&gt;The only problem is currently some IOEngines (Ex:- ByteBufferIOEngine) has a hard requirement that the bytebuffer passed to them for writing needs to be backed by an array, this is the sole reason for this copy, if we can remove that we can skip the copy. I think the main reason for this I think ByteBuff does not have the api methods I think for copying from a ByteBuffer I will take a look and see if this can be avoided.&lt;/p&gt;</comment>
                            <comment id="15489296" author="dvdreddy" created="Wed, 14 Sep 2016 03:44:54 +0000"  >&lt;p&gt;Commented on the comment above, SIGSEV should not be an issue as we are not actually deallocating memory and also we don&apos;t relocate the blocks for which there is an existing read that is going on (we use the check on the refCount).&lt;/p&gt;</comment>
                            <comment id="15489459" author="vrodionov" created="Wed, 14 Sep 2016 05:21:07 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Defragmentation is the software one, underneath everything is backed by a large array of byteBuffers we are not allocating / deallocating anything we are just overwriting / releasing from the java level meta data&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Interesting. I have always thought that defragmentation == moving data. May be I was wrong?&lt;/p&gt;</comment>
                            <comment id="15489482" author="dvdreddy" created="Wed, 14 Sep 2016 05:33:11 +0000"  >&lt;p&gt;It is moving data, but the storage of the data (i.e byte buffers ) are pre-allocted at the beginning of the HRegionServer so it is more like a copy of the data from one to another location with out any new allocation. The old allocation will go on to a free list to be reused for another block of data. &lt;/p&gt;</comment>
                            <comment id="15489646" author="ram_krish" created="Wed, 14 Sep 2016 07:07:59 +0000"  >&lt;p&gt;Nice find. Some simiilar issue was reported with file mode also I believe where it was said that it is not used efficiently. Need to check that JIRA too. I don&apos;t have that ID now.&lt;br/&gt;
On the patch&lt;br/&gt;
-&amp;gt; The read lock is tried to be released when you get write lock.&lt;br/&gt;
-&amp;gt; relocatedCount++; - better to increment after the task is done.&lt;br/&gt;
-&amp;gt; &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
backingMap.put(key, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BucketEntry(newOffset, len, bucketEntry.accessCounter,
697	                  bucketEntry.getPriority()));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should the key be removed once we get the write lock or is it ok to overwrite the key with the new value? Am asking in terms of some other request asking for this key at the same time when the deFragmentation happens.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void setTo(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; free, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; used, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; itemSize,
557	            &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt; nonZeroOccupancyRatio) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When does this exact update happen?&lt;/p&gt;

&lt;p&gt;Overall is it better if we improve the way the buckets are allocated - will that improve things?  &lt;br/&gt;
Also what is the impact of this deFragmentation in real read load. Because we iterate thro every key. Is it better if do this in a seperate thread where we hold on to the highest fragmented bucked in a queue and keep defragmenting that? But  may be it won&apos;t work because eviction is random and not in our hands?&lt;/p&gt;</comment>
                            <comment id="15490281" author="anoop.hbase" created="Wed, 14 Sep 2016 12:13:21 +0000"  >&lt;p&gt;Ya that assert was just added as we always passed HBB at that time.  Now we can add functions to write a ByteBuff directly onto BBArray..  &lt;/p&gt;</comment>
                            <comment id="15500060" author="zjushch" created="Sun, 18 Sep 2016 02:11:15 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
BucketCache#freeSpace
       &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (needFreeForExtra) {
         bucketQueue.clear();
-        remainingBuckets = 2;
+        remainingBuckets = 3;
 
         bucketQueue.add(bucketSingle);
         bucketQueue.add(bucketMulti);
+        bucketQueue.add(bucketMemory);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Seems this issue mentioned in description could be solved  by above code.&lt;br/&gt;
Just FYI&lt;/p&gt;</comment>
                            <comment id="15500076" author="zjushch" created="Sun, 18 Sep 2016 02:25:16 +0000"  >&lt;p&gt;Another thing to do : &lt;br/&gt;
In one BucketCache#FreeSpace round, make sure all BucketSizeInfos have free count. &lt;/p&gt;</comment>
                            <comment id="15504518" author="dvdreddy" created="Mon, 19 Sep 2016 20:02:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; BucketCache#freeSpace
       &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (needFreeForExtra) {
         bucketQueue.clear();
-        remainingBuckets = 2;
+        remainingBuckets = 3;
 
         bucketQueue.add(bucketSingle);
         bucketQueue.add(bucketMulti);
+        bucketQueue.add(bucketMemory);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Seems this issue mentioned in description could be solved by above code. &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Just FYI&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ha, nice point, I missed this, but this would still not guarantee, that we would freeup the buckets needed for the given BucketSize in a single run, it might need several runs free-up a completely free bucket and that would transfer into the our hot BucketSize. One other reason it might be slow is that bytesToFreeWithExtra will depend on the size of the currently hot BucketSize (for which there are no free blocks) and that is usually small and the transition might be slow. Another problem is that due to sparsely occupied buckets we might encounter keep ending up in the freeSpace method again and again. &lt;/p&gt;</comment>
                            <comment id="15504536" author="dvdreddy" created="Mon, 19 Sep 2016 20:05:09 +0000"  >&lt;p&gt;This is very good idea to make sure all the buckets have freeCount, since there are no free counts, one way to enforce this would be force the eviction from that BucketSizeInfo which would lead to eviction of hot blocks also if the current buckets of that BucketSize is small and also it would also lockup the unused and fragmented space from the other bucketSizes until a compaction or something else frees them up.&lt;/p&gt;</comment>
                            <comment id="15505090" author="vrodionov" created="Tue, 20 Sep 2016 00:02:40 +0000"  >&lt;p&gt;Google &quot;slab calcification problem&quot;. This is exactly BucketCache &quot;fragmentation issue&quot;. &lt;/p&gt;</comment>
                            <comment id="15505115" author="dvdreddy" created="Tue, 20 Sep 2016 00:14:43 +0000"  >&lt;p&gt;Yup looks like this is exactly what we want, the idea is to pick a random slab and evict all elements from it, but we can be a little bit more clever here and pick the slabs that would have least number of elements with in them so that we will do least number of reads to re-cache the elements from them. This idea is simple and could be done easily with current code structure also I think with small amount of code. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; what do you think about this heuristic ? I think this will also address the concerns &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjushch&quot; class=&quot;user-hover&quot; rel=&quot;zjushch&quot;&gt;chunhui shen&lt;/a&gt; raised&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;Thanks for the idea&lt;/p&gt;</comment>
                            <comment id="15505542" author="zjushch" created="Tue, 20 Sep 2016 04:34:06 +0000"  >&lt;p&gt;1.Fix the issue that FreeSpace doesn&apos;t free anything (Required)&lt;br/&gt;
2.Defragmentation  (Optional):&lt;br/&gt;
 a. Would increment cache usage ratio in short time. Otherwise will take relative long time without defragmentation. &lt;br/&gt;
 b. Resource overhead (Byte Copy). Should limit the rate. For example, only trigger one time per hour.&lt;br/&gt;
 c. Add unit test to ensure the correctness with defragmentation.&lt;/p&gt;


&lt;p&gt;Just my thought.&lt;/p&gt;</comment>
                            <comment id="15508254" author="dvdreddy" created="Wed, 21 Sep 2016 00:34:28 +0000"  >&lt;p&gt;Attached v2, this patch changes the logic of defragmentation to the one suggested &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; and the one used by MemCached where they just choose some slabs and evict them completely the code turned out to be much cleaner and smaller. The only heuristic is that we avoid the buckets that are the only buckets for a BucketSizeInfo and the ones that have blocks that are currently in use and order them by their occupancy ratio.&lt;/p&gt;

&lt;p&gt;Also added the change suggested &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjushch&quot; class=&quot;user-hover&quot; rel=&quot;zjushch&quot;&gt;chunhui shen&lt;/a&gt; to add the memory type to the eviction. &lt;/p&gt;

&lt;p&gt;If this logic looks fine to the community I will go ahead and add a unit test to the freeEntireBlocks method&lt;/p&gt;</comment>
                            <comment id="15508425" author="yuzhihong@gmail.com" created="Wed, 21 Sep 2016 02:03:07 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    Set&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; result = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashSet&amp;lt;&amp;gt;(bucketCount);
+    result.addAll(queue);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Result is a Set which doesn&apos;t preserve the order of items in queue.&lt;br/&gt;
Why is the MinMaxPriorityQueue needed ?&lt;/p&gt;</comment>
                            <comment id="15508469" author="dvdreddy" created="Wed, 21 Sep 2016 02:24:30 +0000"  >&lt;p&gt;I used it predominently for limiting the number of buckets we needed, if use a treeset we might still need to do the copy.&lt;/p&gt;</comment>
                            <comment id="15508568" author="yuzhihong@gmail.com" created="Wed, 21 Sep 2016 03:09:50 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// Add buckets with blocks currently in use
&lt;/span&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; offset : excludedOffsets) {
+      excludedBuckets.add(getBucketIndex(offset));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Looks like you can construct excludedBuckets in freeEntireBuckets() directly.&lt;br/&gt;
This way Set excludedOffsets is not needed.&lt;/p&gt;</comment>
                            <comment id="15510294" author="yuzhihong@gmail.com" created="Wed, 21 Sep 2016 15:29:48 +0000"  >&lt;p&gt;If you have time, do you mind trying patch v2 on a (test) cluster ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15510385" author="vrodionov" created="Wed, 21 Sep 2016 16:03:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dvdreddy&quot; class=&quot;user-hover&quot; rel=&quot;dvdreddy&quot;&gt;deepankar&lt;/a&gt;,  memory requirements is very high. You efficiently add one more backingMap during defragmentation (majority of blocks will have zero refCount). backingMap itself takes 200+ bytes per block. For reasonably large caches, with 10M blocks, that is 2GB+ more heap to run defragmentation. Seems quite a high overhead.&lt;/p&gt;</comment>
                            <comment id="15513348" author="anoop.hbase" created="Thu, 22 Sep 2016 13:51:23 +0000"  >&lt;p&gt;Is there a way we can get the possible candidates of buckets for freeing in one go rather than 1st find the non 0 ref counted and pass that offset as excluded and find buckets from that and for every bucket do a contains check in excluded?  Which new Map u refer &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; which is having 200+ bytes per entry?&lt;/p&gt;</comment>
                            <comment id="15513542" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 15:15:58 +0000"  >&lt;p&gt;Suggested patch based on v2 which removes Set creation in getLeastFilledBuckets()&lt;/p&gt;</comment>
                            <comment id="15514293" author="dvdreddy" created="Thu, 22 Sep 2016 19:43:34 +0000"  >&lt;p&gt;Sorry for delay in adding the suggestion &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;, I attached a patch now which in addition to your suggestions contains a couple of import fixes. Also I tested the patch on couple of machines, every thing looked fine. we are doing a cluster wide deploy today, will report on that results&lt;/p&gt;</comment>
                            <comment id="15514299" author="dvdreddy" created="Thu, 22 Sep 2016 19:45:11 +0000"  >&lt;p&gt;Which map are you referring to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; , I am constructing a couple of sets which are atmost 0(bucket  count).&lt;/p&gt;</comment>
                            <comment id="15514407" author="vrodionov" created="Thu, 22 Sep 2016 20:33:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dvdreddy&quot; class=&quot;user-hover&quot; rel=&quot;dvdreddy&quot;&gt;deepankar&lt;/a&gt;&lt;br/&gt;
OK, I was not right - do not see any significant memory overhead, but I have another concern&lt;/p&gt;

&lt;p&gt;You collect all buckets that have active blocks (refCount != 0), then clear them up. This is counterintuitive. You evict Most Recently Used blocks?&lt;/p&gt;</comment>
                            <comment id="15514424" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 20:39:30 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      Set&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; candidateBuckets = bucketAllocator.getLeastFilledBuckets(
+          inUseBuckets, completelyFreeBucketsNeeded);
...
+   * @param excludedBuckets the buckets that need to be excluded due to
+   *                        currently being in used
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In use buckets are excluded from freeing.&lt;/p&gt;</comment>
                            <comment id="15514645" author="vrodionov" created="Thu, 22 Sep 2016 22:20:47 +0000"  >&lt;p&gt;Yes, my bad. Somehow missed ! &lt;/p&gt;
</comment>
                            <comment id="15515026" author="yuzhihong@gmail.com" created="Fri, 23 Sep 2016 01:21:12 +0000"  >&lt;p&gt;Patch with DEBUG log at the end of freeEntireBuckets().&lt;/p&gt;</comment>
                            <comment id="15561095" author="yuzhihong@gmail.com" created="Mon, 10 Oct 2016 02:50:36 +0000"  >&lt;p&gt;Deepankar:&lt;br/&gt;
How was the patched version running in your cluster ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15580415" author="dvdreddy" created="Sun, 16 Oct 2016 19:24:28 +0000"  >&lt;p&gt;Sorry for the delayed reply, the bucket cache is not stuck as before atleast it is evicting blocks and adding on new blocks, but we are occasionally facing a different issues especially under peak load that this heuristic we have is repeatedly eviciting the same blocks again and again and that is leading very high load average some times. We are trying to come up with some tweaks by getting into consideration the total blocks allocated for a bucket also. if you have any other suggestions we can try them out too.&lt;/p&gt;</comment>
                            <comment id="15626001" author="yuzhihong@gmail.com" created="Tue, 1 Nov 2016 16:59:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;repeatedly eviciting the same blocks again &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How about keeping last N evicted blocks and trying not to re-evict them ?&lt;/p&gt;</comment>
                            <comment id="15626247" author="stack" created="Tue, 1 Nov 2016 18:25:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dvdreddy&quot; class=&quot;user-hover&quot; rel=&quot;dvdreddy&quot;&gt;deepankar&lt;/a&gt; Could you use the &apos;smarter&apos; algo from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15560&quot; title=&quot;TinyLFU-based BlockCache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15560&quot;&gt;HBASE-15560&lt;/a&gt; TinyLFU-based BlockCache&lt;/p&gt;</comment>
                            <comment id="15635307" author="anoop.hbase" created="Fri, 4 Nov 2016 05:28:59 +0000"  >&lt;p&gt;We would like to enable BucketCache On by default for the data blocks in 2.0.  So can we up the priority to be critical? &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dvdreddy&quot; class=&quot;user-hover&quot; rel=&quot;dvdreddy&quot;&gt;deepankar&lt;/a&gt; u still working on this?&lt;/p&gt;</comment>
                            <comment id="15635468" author="dvdreddy" created="Fri, 4 Nov 2016 06:49:41 +0000"  >&lt;p&gt;Yeah I am looking into stacks suggestion to counter the problem I have previously mentioned about re-eviction just cached blocks&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="13024377">HBASE-17204</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12829871" name="16630-v2-suggest.patch" size="8194" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 15:15:58 +0000"/>
                            <attachment id="12829969" name="16630-v3-suggest.patch" size="8528" author="yuzhihong@gmail.com" created="Fri, 23 Sep 2016 01:21:12 +0000"/>
                            <attachment id="12829475" name="HBASE-16630-v2.patch" size="9704" author="dvdreddy" created="Wed, 21 Sep 2016 00:34:28 +0000"/>
                            <attachment id="12829922" name="HBASE-16630-v3.patch" size="9652" author="dvdreddy" created="Thu, 22 Sep 2016 19:43:34 +0000"/>
                            <attachment id="12828369" name="HBASE-16630.patch" size="15688" author="dvdreddy" created="Wed, 14 Sep 2016 01:04:08 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 14 Sep 2016 02:24:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33ljr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>