<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:55:37 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8477/HBASE-8477.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8477] [hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8477</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;In the test we see the following log messages which indicate an authentication problem and then some sort of recovery problem.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-04-16 23:27:04,469 ERROR [IPC Server handler 0 on 45600] security.UserGroupInformation(1370): PriviledgedActionException as:ec2-user.hfs.2 (auth:SIMPLE) cause:org.apache.hadoop.security.AccessControlException: Can&apos;t &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo
2013-04-16 23:27:04,501 WARN  [PRI IPC Server handler 4 on 33892] hdfs.DFSInputStream(489): Failed to connect to /127.0.0.1:55547 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block, add to deadNodes and &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;. org.apache.hadoop.security.AccessControlException: Can&apos;t &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1016)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1026)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:5104)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688)

org.apache.hadoop.security.AccessControlException: Can&apos;t &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1016)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1026)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:5104)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:790)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:888)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:645)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:689)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorModtime(FSTableDescriptors.java:429)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorModtime(FSTableDescriptors.java:414)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:169)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:132)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:3350)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine$Server.call(ProtobufRpcServerEngine.java:174)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1871)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Can&apos;t &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1016)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1026)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:5104)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688)

	at org.apache.hadoop.ipc.Client.call(Client.java:1164)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:202)
	at com.sun.proxy.$Proxy20.getBlockLocalPathInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolTranslatorPB.java:199)
	at org.apache.hadoop.hdfs.BlockReaderLocal.getBlockPathInfo(BlockReaderLocal.java:254)
	at org.apache.hadoop.hdfs.BlockReaderLocal.newBlockReader(BlockReaderLocal.java:167)
	at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:786)
	... 17 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This seems similar to the other short-circuit-read hadoop2 related failures&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645743">HBASE-8477</key>
            <summary>[hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12609485">HBASE-6891</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jmhsieh">Jonathan Hsieh</assignee>
                                    <reporter username="jmhsieh">Jonathan Hsieh</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 02:50:47 +0000</created>
                <updated>Mon, 23 Sep 2013 19:08:24 +0000</updated>
                            <resolved>Thu, 2 May 2013 06:30:03 +0000</resolved>
                                    <version>0.98.0</version>
                    <version>0.95.1</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.95.1</fixVersion>
                                    <component>hadoop2</component>
                    <component>mapreduce</component>
                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13647296" author="jmhsieh" created="Thu, 2 May 2013 05:06:25 +0000"  >&lt;p&gt;patch disables short circuit read for these table input format scan tests.  I haven&apos;t been able to reliably duplicate the problem so this is speculative.  I&apos;d say it is worth committing and we&apos;ll see if the jenkins builds stop failing.&lt;/p&gt;</comment>
                            <comment id="13647316" author="stack" created="Thu, 2 May 2013 05:38:23 +0000"  >&lt;p&gt;+1 on trying it.&lt;/p&gt;</comment>
                            <comment id="13647337" author="hadoopqa" created="Thu, 2 May 2013 06:20:56 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12581480/hbase-8477.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12581480/hbase-8477.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5535//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13647341" author="jmhsieh" created="Thu, 2 May 2013 06:29:51 +0000"  >&lt;p&gt;Thanks stack.  I&apos;ve committed to trunk and 0.95.  I&apos;ll close it for now but if the errors keep showing up I&apos;ll revert and reopen.&lt;/p&gt;</comment>
                            <comment id="13647388" author="hudson" created="Thu, 2 May 2013 08:59:59 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #4093 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4093/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4093/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8477&quot; title=&quot;[hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8477&quot;&gt;&lt;del&gt;HBASE-8477&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;hadoop2&amp;#93;&lt;/span&gt; TestTableInputFormatScan* fails intermittently with PriviledgeActionException (Revision 1478281)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
jmhsieh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13647394" author="hudson" created="Thu, 2 May 2013 09:20:39 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #175 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/175/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/175/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8477&quot; title=&quot;[hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8477&quot;&gt;&lt;del&gt;HBASE-8477&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;hadoop2&amp;#93;&lt;/span&gt; TestTableInputFormatScan* fails intermittently with PriviledgeActionException (Revision 1478280)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
jmhsieh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13647486" author="hudson" created="Thu, 2 May 2013 12:54:48 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #88 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/88/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/88/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8477&quot; title=&quot;[hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8477&quot;&gt;&lt;del&gt;HBASE-8477&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;hadoop2&amp;#93;&lt;/span&gt; TestTableInputFormatScan* fails intermittently with PriviledgeActionException (Revision 1478280)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
jmhsieh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13647513" author="jmhsieh" created="Thu, 2 May 2013 13:30:12 +0000"  >&lt;p&gt;A few runs later we still have some failures on these tests but they are due to different reasons:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/206/testReport/org.apache.hadoop.hbase.mapreduce/TestTableInputFormatScan1/testScanEmptyToEmpty/?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/206/testReport/org.apache.hadoop.hbase.mapreduce/TestTableInputFormatScan1/testScanEmptyToEmpty/?&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-05-02 09:34:46,344 WARN  [AsyncDispatcher event handler] resourcemanager.RMAuditLogger(255): USER=ec2-user	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1367487107266_0005 failed 1 times due to AM Container &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; appattempt_1367487107266_0005_000001 exited with  exitCode: -1000 due to: RemoteTrace: 
org.apache.hadoop.util.Shell$ExitCodeException: chmod: cannot access `/home/ec2-user/jenkins/workspace/HBase-TRUNK-Hadoop-2/hbase-server/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-localDir-nm-0_2/usercache/ec2-user/filecache/-8553343706879310630_tmp&apos;: No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:202)
	at org.apache.hadoop.util.Shell.run(Shell.java:129)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:322)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:411)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:394)
	at org.apache.hadoop.fs.RawLocalFileSystem.execCommand(RawLocalFileSystem.java:604)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:595)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:394)
	at org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:1007)
	at org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:145)
	at org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:187)
	at org.apache.hadoop.fs.FileContext$4.next(FileContext.java:712)
	at org.apache.hadoop.fs.FileContext$4.next(FileContext.java:708)
	at org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2361)
	at org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:708)
	at org.apache.hadoop.yarn.util.FSDownload.createDir(FSDownload.java:87)
	at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:189)
	at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:50)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:662)
 at LocalTrace: 
	org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: chmod: cannot access `/home/ec2-user/jenkins/workspace/HBase-TRUNK-Hadoop-2/hbase-server/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-localDir-nm-0_2/usercache/ec2-user/filecache/-8553343706879310630_tmp&apos;: No such file or directory

	at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.convertFromProtoFormat(LocalResourceStatusPBImpl.java:217)
	at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.getException(LocalResourceStatusPBImpl.java:147)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(ResourceLocalizationService.java:824)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.processHeartbeat(ResourceLocalizationService.java:493)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.heartbeat(ResourceLocalizationService.java:222)
	at org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.service.LocalizationProtocolPBServiceImpl.heartbeat(LocalizationProtocolPBServiceImpl.java:46)
	at org.apache.hadoop.yarn.proto.LocalizationProtocol$LocalizationProtocolService$2.callBlockingMethod(LocalizationProtocol.java:57)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688)

.Failing &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; attempt.. Failing the application.	APPID=application_1367487107266_0005
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13650908" author="hudson" created="Tue, 7 May 2013 14:54:43 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #518 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/518/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/518/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8477&quot; title=&quot;[hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8477&quot;&gt;&lt;del&gt;HBASE-8477&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;hadoop2&amp;#93;&lt;/span&gt; TestTableInputFormatScan* fails intermittently with PriviledgeActionException (Revision 1478281)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
jmhsieh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581480" name="hbase-8477.patch" size="983" author="jmhsieh" created="Thu, 2 May 2013 05:06:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 2 May 2013 05:38:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326102</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 32 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k9cn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326447</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>