<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:58:05 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1996/HBASE-1996.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1996] Configure scanner buffer in bytes instead of number of rows</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1996</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently, the default scanner fetches a single row at a time.  This makes for very slow scans on tables where the rows are not large.  You can change the setting for an HTable instance or for each Scan.&lt;/p&gt;

&lt;p&gt;It would be better to have a default that performs reasonably well so that people stop running into slow scans because they are evaluating HBase, aren&apos;t familiar with the setting, or simply forgot.  Unfortunately, if we increase the value of the current setting, then we run the risk of running OOM for tables with large rows.  Let&apos;s change the setting so that it works with a size in bytes, rather than in rows.  This will allow us to set a reasonable default so that tables with small rows will scan performantly and tables with large rows will not run OOM.&lt;/p&gt;

&lt;p&gt;Note that the case is very similar to table writes as well.  When disabling auto flush, we buffer a list of Put&apos;s to commit at once.  That buffer is measured in bytes, so that a small number of large Puts or a lot of small Puts can each fit in a single flush.  If that buffer were measured in number of Put&apos;s it would have the same problem that we have for the scan buffer, and we wouldn&apos;t be able to set a good default value for tables with different size rows.  Changing the scan buffer to be configured like the write buffer will make it more consistent.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12441347">HBASE-1996</key>
            <summary>Configure scanner buffer in bytes instead of number of rows</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davelatham">Dave Latham</assignee>
                                    <reporter username="davelatham">Dave Latham</reporter>
                        <labels>
                    </labels>
                <created>Sat, 21 Nov 2009 00:10:39 +0000</created>
                <updated>Tue, 1 Nov 2016 19:19:03 +0000</updated>
                            <resolved>Mon, 4 Jan 2010 23:05:58 +0000</resolved>
                                                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="12780842" author="davelatham" created="Sat, 21 Nov 2009 00:11:41 +0000"  >&lt;p&gt;Here&apos;s a first shot at making this change.&lt;/p&gt;</comment>
                            <comment id="12780856" author="davelatham" created="Sat, 21 Nov 2009 00:51:11 +0000"  >&lt;p&gt;One thing to note in this patch.  The buffer behaves similar to the write case where it always includes at least one row, and doesn&apos;t return until it&apos;s at least full.  So the value is more a minimum to attempt to fill (as long as more rows are available) rather than a maximum.  Hence, setting it to 0 is equivalent to setting the number of rows to 1.&lt;/p&gt;</comment>
                            <comment id="12780883" author="davelatham" created="Sat, 21 Nov 2009 02:05:56 +0000"  >&lt;p&gt;Ryan made a good point that the scanner caching is set to 1 not just for memory concerns, but because if a client takes a long time processing rows, then the scanner might timeout before getting the next batch of rows.&lt;/p&gt;</comment>
                            <comment id="12784724" author="dlrozendaal" created="Wed, 2 Dec 2009 09:08:29 +0000"  >&lt;p&gt;This feature would be really useful to us. We have a table where the number of columns per row varies greatly. Most of them have less than 100 columns, but some have more than a million. With the current scanner we&apos;re pretty much limited to specifying 1-3 rows of caching, which hurts performance in many cases. So being able to specify the size in bytes (with the minimum of one row returned) would be very useful.&lt;/p&gt;

&lt;p&gt;I&apos;ll try to see if this patch can be applied to our version of HBase (0.20.2) and see how that works.&lt;/p&gt;

&lt;p&gt;PS We&apos;re also working to reduce the variance of row sizes... &amp;gt;1 million columns is a pain w.r.t. memory usage.&lt;/p&gt;</comment>
                            <comment id="12794822" author="dlrozendaal" created="Mon, 28 Dec 2009 14:58:39 +0000"  >&lt;p&gt;I&apos;ve tested this against hbase 0.20.2 (some manual patching was required). As expected, performance with this patch is much more stable when having rows of widely varying sizes. Also, no more out-of-memory errors in the hbase region server or on the client side.&lt;/p&gt;

&lt;p&gt;Being able to set caching parameters based on memory usage (bytes) is much nicer than trying to predict row or KeyValue sizes (as used by the new 0.21 scanning API).&lt;/p&gt;

&lt;p&gt;It would be really nice if this patch (maybe adjusted to preserve backwards compatibility with the setCaching API) could be included for 0.20.3 and 0.21.&lt;/p&gt;</comment>
                            <comment id="12794863" author="davelatham" created="Mon, 28 Dec 2009 18:42:14 +0000"  >&lt;p&gt;Perhaps if we supported both settings i.e. buffer at least X rows and at least Y bytes.  Too much complexity?  We could still default to min 1 row and 0 bytes to minimize the chance of a scanner timeout if needed.&lt;/p&gt;</comment>
                            <comment id="12794961" author="stack" created="Mon, 28 Dec 2009 23:21:44 +0000"  >&lt;p&gt;It looks like this patch as is can&apos;t go into 0.20.3 because it changes the interfaces making it so we won&apos;t be able to do rolling upgrade?  (HRI#next parameter changed from int to long for size of buffer instead of number of rows).  I think adding a new method, one that takes a size also breaks rolling updates (I&apos;m not sure about this one).&lt;/p&gt;

&lt;p&gt;.bq ...at least X rows and at least Y bytes&lt;/p&gt;

&lt;p&gt;This could work if it was done cleanly, IMO.&lt;/p&gt;

&lt;p&gt;If I had to choose, looking at the patch, size of result rather than number of rows seems the better idea.&lt;/p&gt;

&lt;p&gt;How should we proceed.   Seems like a clean addition can be made for 0.21 but what to do for 0.20.3 timeframe?&lt;/p&gt;</comment>
                            <comment id="12795026" author="dlrozendaal" created="Tue, 29 Dec 2009 08:25:31 +0000"  >&lt;p&gt;For 0.20.3 we could have a configuration parameter for HRegionServer for the scan buffer size. The client will not be able to override this value. It is not optimal, but will work for us and will prevent the current worst-case scan behavior when caching is set to 1 and rows are very small. The scan buffer size could default to 0 (100% backwards compatible) or a more useful value like 128-512 kB or so.&lt;/p&gt;

&lt;p&gt;W.r.t. &quot;at least N rows and M bytes&quot; &lt;/p&gt;

&lt;p&gt;I don&apos;t think this is very useful (yet). I think it is more useful to be able to specify:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;scan buffer size (for performance)&lt;/li&gt;
	&lt;li&gt;allow/disallow partial rows (to prevent OOMs with large rows)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Adding minimum number of rows and/or batch size in number of key values (0.21?) will make the API harder to use and test.&lt;/p&gt;</comment>
                            <comment id="12795061" author="dlrozendaal" created="Tue, 29 Dec 2009 14:25:16 +0000"  >&lt;p&gt;This patch limits the result from a single call to a scanner&apos;s next method to one MB. I couldn&apos;t get &quot;minimum N rows, minimum M bytes&quot; to work without needing changes in the protocol. So now it is &quot;maximum N rows, maximum M bytes&quot; where M is hardcoded to 1 MB.&lt;/p&gt;

&lt;p&gt;This allows me to set a scanner&apos;s caching to Integer.MAX_VALUE and not get any OOMs on the region server. Obviously only ~1 MB of data is returned.&lt;/p&gt;

&lt;p&gt;Scanning performance is very high (I get 20+ MB/second on my Core2Duo 2.4 GHz laptop going to HBase through a web server... so more like 40+ MB/second on the HBase side).&lt;/p&gt;
</comment>
                            <comment id="12795086" author="apurtell" created="Tue, 29 Dec 2009 17:11:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think it is more useful to be able to specify &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt; allow/disallow partial rows (to prevent OOMs with large rows)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Does &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1537&quot; title=&quot;Intra-row scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1537&quot;&gt;&lt;del&gt;HBASE-1537&lt;/del&gt;&lt;/a&gt; cover this? &lt;/p&gt;</comment>
                            <comment id="12795163" author="stack" created="Tue, 29 Dec 2009 21:45:55 +0000"  >&lt;p&gt;@Erik I took a look at the patch.  Could you make it so the 1MB upper bound was not a hard-coding, instead read it from HBaseConfiguration (You don&apos;t have to add the value to hbase-default.xml).  I&apos;d default to 10MBs rather than 1MB.  Also, I&apos;m not sure what the changes in HTable do?  The client stops the scan when it hits the hard-coded upper-bound?  Thanks. &lt;/p&gt;</comment>
                            <comment id="12795578" author="dlrozendaal" created="Thu, 31 Dec 2009 10:14:14 +0000"  >&lt;p&gt;Second version of patch for 0.20.3 branch. This makes the maximum result size configurable.&lt;/p&gt;

&lt;p&gt;However: the client and the server &lt;b&gt;must&lt;/b&gt; use the same maximum result size, otherwise rows in regions may be skipped. This is because of the way the results of a region scan are reported to the client:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null: scanning filter stopped processing&lt;/li&gt;
	&lt;li&gt;fewer rows returned than requested: end-of-region reached, move on.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The second point is why the HTable modifications are necessary. It is now normal that a region scan will return fewer rows than requested even when the end of the region has not been reached yet. So the client needs to duplicate the region server logic to keep in sync.&lt;/p&gt;

&lt;p&gt;I think for 0.21 the result communication to the client should be made more explicit, eg. make a ScannerCallableResult class that contains a status field (MORE_AVAILABLE, SKIP_TO_NEXT_REGION, FILTER_SAID_STOP) as well as the actual rows returned.&lt;/p&gt;

&lt;p&gt;I also left the default max result size value at 1 megabyte. In my (admittedly limited) testing using just my laptop without a real network a size of 256-1024 kB seems to be optimal.&lt;/p&gt;

&lt;p&gt;Here are my test results:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;max scanner result size (bytes)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MB/s scanned with rows avg 750 bytes&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MB/s scanned with rows avg 175 bytes&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1024&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.23&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2048&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5.14&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4096&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.34&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8192&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.95&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16384&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16.15&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8.30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;32768&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.96&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;65536&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.42&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;131072&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.93&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;262144&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.48&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;524288&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.34&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1048576&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8.91&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2097152&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.91&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8.03&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4194304&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.86&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8388608&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17.89&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16777216&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17.63&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.98&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Scanner caching was set to Integer.MAX_VALUE (unlimited number of rows). MB/s are measured going through a web server, so raw HBase speed is probably double or higher. Obviously a real cluster test should be done to measure real performance and otherwise tune the max result size.&lt;/p&gt;</comment>
                            <comment id="12795579" author="dlrozendaal" created="Thu, 31 Dec 2009 10:17:40 +0000"  >&lt;p&gt;@Andrew: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1537&quot; title=&quot;Intra-row scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1537&quot;&gt;&lt;del&gt;HBASE-1537&lt;/del&gt;&lt;/a&gt; will work pretty well when KeyValues are of similar/predictable size. However, I prefer to be able to set a limit in bytes. This should use give more predictable performance, especially when you have widely varying row/KeyValue sizes.&lt;/p&gt;</comment>
                            <comment id="12796054" author="stack" created="Mon, 4 Jan 2010 00:43:12 +0000"  >&lt;p&gt;Erik: Thanks for making the size configurable.  Thanks for explaining why client needs to match server.&lt;/p&gt;

&lt;p&gt;Can you make it so that unless an explicit size has been set, the behavior is that things work as they do now?  So that this sizing of data only cuts in if you set an explicit value in hbase.client.scanner.max.result.size?  So the behavior is as it is now, pre-patch, unless you change hbase.client.scanner.max.result.size from its default of -1?&lt;/p&gt;

&lt;p&gt;Once committed, we should file the issue you suggest for 0.21 where we do better communication of state between client and server during scans.&lt;/p&gt;</comment>
                            <comment id="12796184" author="dlrozendaal" created="Mon, 4 Jan 2010 14:20:50 +0000"  >&lt;p&gt;The 1996-0.20.3-v3.patch sets the default limit to &quot;unlimited&quot;, so 0.20.3 should have the same scanning behavior as 0.20.2 unless the configuration parameter is set explicitly.&lt;/p&gt;

&lt;p&gt;PS The fix-version of this issue is 0.21 and is marked as incompatible change. Maybe the 0.20.3 patch should be moved to a new issue or this issue changed?&lt;/p&gt;</comment>
                            <comment id="12796376" author="stack" created="Mon, 4 Jan 2010 21:58:22 +0000"  >&lt;p&gt;Patch looks good.  Testing now...&lt;/p&gt;</comment>
                            <comment id="12796419" author="stack" created="Mon, 4 Jan 2010 23:05:58 +0000"  >&lt;p&gt;Committed branch and trunk.  Thanks for the patch lads (Dave and Erik.. in particular Erik, thanks for persisting).&lt;/p&gt;</comment>
                            <comment id="12832653" author="stack" created="Thu, 11 Feb 2010 19:27:21 +0000"  >&lt;p&gt;I made hbase-2214 to do this better in 0.21.&lt;/p&gt;</comment>
                            <comment id="13266815" author="hudson" created="Wed, 2 May 2012 18:57:22 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2837 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2837/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2837/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2214&quot; title=&quot;Do HBASE-1996 -- setting size to return in scan rather than count of rows -- properly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2214&quot;&gt;&lt;del&gt;HBASE-2214&lt;/del&gt;&lt;/a&gt; Do &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1996&quot; title=&quot;Configure scanner buffer in bytes instead of number of rows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1996&quot;&gt;&lt;del&gt;HBASE-1996&lt;/del&gt;&lt;/a&gt; &amp;#8211; setting size to return in scan rather than count of rows &amp;#8211; properly (Ferdy Galema) (Revision 1333122)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ZooKeeperProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13266870" author="hudson" created="Wed, 2 May 2012 20:09:23 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #170 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/170/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/170/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2214&quot; title=&quot;Do HBASE-1996 -- setting size to return in scan rather than count of rows -- properly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2214&quot;&gt;&lt;del&gt;HBASE-2214&lt;/del&gt;&lt;/a&gt; Do &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1996&quot; title=&quot;Configure scanner buffer in bytes instead of number of rows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1996&quot;&gt;&lt;del&gt;HBASE-1996&lt;/del&gt;&lt;/a&gt; &amp;#8211; setting size to return in scan rather than count of rows &amp;#8211; properly (Ferdy Galema) (Revision 1333157)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13267220" author="hudson" created="Thu, 3 May 2012 06:03:30 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #190 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/190/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/190/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2214&quot; title=&quot;Do HBASE-1996 -- setting size to return in scan rather than count of rows -- properly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2214&quot;&gt;&lt;del&gt;HBASE-2214&lt;/del&gt;&lt;/a&gt; Do &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1996&quot; title=&quot;Configure scanner buffer in bytes instead of number of rows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1996&quot;&gt;&lt;del&gt;HBASE-1996&lt;/del&gt;&lt;/a&gt; &amp;#8211; setting size to return in scan rather than count of rows &amp;#8211; properly (Ferdy Galema) (Revision 1333122)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HBaseProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ZooKeeperProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13268831" author="hudson" created="Sat, 5 May 2012 00:58:51 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #26 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/26/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/26/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2214&quot; title=&quot;Do HBASE-1996 -- setting size to return in scan rather than count of rows -- properly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2214&quot;&gt;&lt;del&gt;HBASE-2214&lt;/del&gt;&lt;/a&gt; Do &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1996&quot; title=&quot;Configure scanner buffer in bytes instead of number of rows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1996&quot;&gt;&lt;del&gt;HBASE-1996&lt;/del&gt;&lt;/a&gt; &amp;#8211; setting size to return in scan rather than count of rows &amp;#8211; properly (Ferdy Galema) (Revision 1333157)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15017862" author="lars_francke" created="Fri, 20 Nov 2015 13:01:40 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12456059">HBASE-2214</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13016963">HBASE-16987</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12425688" name="1966.patch" size="19921" author="davelatham" created="Sat, 21 Nov 2009 00:11:41 +0000"/>
                            <attachment id="12429203" name="1996-0.20.3-v2.patch" size="4299" author="dlrozendaal" created="Thu, 31 Dec 2009 10:14:14 +0000"/>
                            <attachment id="12429341" name="1996-0.20.3-v3.patch" size="4347" author="dlrozendaal" created="Mon, 4 Jan 2010 14:20:50 +0000"/>
                            <attachment id="12429061" name="1996-0.20.3.patch" size="2895" author="dlrozendaal" created="Tue, 29 Dec 2009 14:25:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 2 Dec 2009 09:08:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32355</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hg53:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99877</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>