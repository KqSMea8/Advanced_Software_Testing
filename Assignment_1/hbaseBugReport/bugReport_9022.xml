<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:00:41 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9022/HBASE-9022.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9022] TestHLogSplit.testIOEOnOutputThread fails</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9022</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6428//testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6428//testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12659239">HBASE-9022</key>
            <summary>TestHLogSplit.testIOEOnOutputThread fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 23 Jul 2013 01:00:57 +0000</created>
                <updated>Wed, 22 Apr 2015 00:36:01 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13715948" author="stack" created="Tue, 23 Jul 2013 01:03:10 +0000"  >&lt;p&gt;Trying against hadoopqa since it failed there.  Added logging to testhlogsplit.&lt;/p&gt;</comment>
                            <comment id="13716005" author="hadoopqa" created="Tue, 23 Jul 2013 03:09:35 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12593624/9022.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12593624/9022.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6433//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13716009" author="stack" created="Tue, 23 Jul 2013 03:19:28 +0000"  >&lt;p&gt;Retry&lt;/p&gt;</comment>
                            <comment id="13716038" author="hadoopqa" created="Tue, 23 Jul 2013 04:29:19 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12593635/9022.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12593635/9022.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6434//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13716066" author="stack" created="Tue, 23 Jul 2013 05:34:18 +0000"  >&lt;p&gt;Retry to see if get a fail&lt;/p&gt;</comment>
                            <comment id="13716166" author="hadoopqa" created="Tue, 23 Jul 2013 06:49:45 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12593645/9022.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12593645/9022.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6435//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13716443" author="stack" created="Tue, 23 Jul 2013 14:50:19 +0000"  >&lt;p&gt;It timed out in this build: &lt;a href=&quot;http://54.241.6.143/job/HBase-0.95/org.apache.hbase$hbase-server/676/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-0.95/org.apache.hbase$hbase-server/676/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Adding timeouts seems to have helped moving fail type from &apos;invisible&apos; to flakey fail.&lt;/p&gt;</comment>
                            <comment id="13718992" author="stack" created="Wed, 24 Jul 2013 23:05:43 +0000"  >&lt;p&gt;This tests still fails.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://54.241.6.143/job/HBase-0.95-Hadoop-2/687/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-0.95-Hadoop-2/687/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/420/testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/420/testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/418/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/418/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/418/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/418/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;... and its compressed version here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/view/H-L/view/HBase/job/hbase-0.95-on-hadoop2/191/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testSplitWillFailIfWritingToRegionFails/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/view/H-L/view/HBase/job/hbase-0.95-on-hadoop2/191/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testSplitWillFailIfWritingToRegionFails/&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Usually the test completes in a couple of seconds.&lt;/p&gt;

&lt;p&gt;When it goes &amp;gt; 300seconds, we are not closing one of our writers.  It is sticking around.  It is not a daemon thread I suppose because we want to make sure our edits all go in.  So, it is stuck somewhere.  I can&apos;t see it at momemnt.  Looking....&lt;/p&gt;</comment>
                            <comment id="13719022" author="stack" created="Wed, 24 Jul 2013 23:39:41 +0000"  >&lt;p&gt;So here is a local run where testIOEOnOutputThread completes a couple of seconds:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-07-24 15:32:10,936 INFO  [main] wal.HLogSplitter(334): Finishing writing output logs and closing down.
2013-07-24 15:32:10,936 INFO  [main] wal.HLogSplitter$OutputSink(925): Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; split writer threads to finish
2013-07-24 15:32:10,962 INFO  [IPC Server handler 8 on 65470] namenode.FSNamesystem(169): ugi=stack	ip=/127.0.0.1	cmd=mkdirs	src=/hbase/t1/bbb/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=stack:supergroup:rwxr-xr-x
2013-07-24 15:32:10,963 INFO  [IPC Server handler 6 on 65470] namenode.FSNamesystem(169): ugi=stack	ip=/127.0.0.1	cmd=mkdirs	src=/hbase/t1/ccc/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=stack:supergroup:rwxr-xr-x
2013-07-24 15:32:11,078 DEBUG [WriterThread-1] wal.HLogSplitter$LogRecoveredEditsOutputSink(1200): Creating writer path=/hbase/t1/bbb/recovered.edits/0000000000000000001.temp region=bbb
2013-07-24 15:32:11,078 DEBUG [WriterThread-2] wal.HLogSplitter$LogRecoveredEditsOutputSink(1200): Creating writer path=/hbase/t1/ccc/recovered.edits/0000000000000000002.temp region=ccc
2013-07-24 15:32:11,082 FATAL [WriterThread-2] wal.HLogSplitter$LogRecoveredEditsOutputSink(1234):  Got &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; writing log entry to log
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 15:32:11,082 FATAL [WriterThread-1] wal.HLogSplitter$LogRecoveredEditsOutputSink(1234):  Got &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; writing log entry to log
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 15:32:11,082 ERROR [WriterThread-1] wal.HLogSplitter$WriterThread(793): Error in log splitting write thread
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 15:32:11,082 ERROR [WriterThread-2] wal.HLogSplitter$WriterThread(793): Error in log splitting write thread
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 15:32:11,087 INFO  [split-log-closeStream-2] wal.HLogSplitter$LogRecoveredEditsOutputSink$2(1042): Closed path /hbase/t1/ccc/recovered.edits/0000000000000000002.temp (wrote 0 edits in 0ms)
2013-07-24 15:32:11,087 INFO  [split-log-closeStream-1] wal.HLogSplitter$LogRecoveredEditsOutputSink$2(1042): Closed path /hbase/t1/bbb/recovered.edits/0000000000000000001.temp (wrote 0 edits in 0ms)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is not easy to read but notice how we do the &apos;Creating writer&apos; lines one after the other.&lt;/p&gt;

&lt;p&gt;Here is an example fail.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-07-24 20:52:06,520 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-297] wal.HLogSplitter(334): Finishing writing output logs and closing down.
2013-07-24 20:52:06,520 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-297] wal.HLogSplitter$OutputSink(925): Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; split writer threads to finish
2013-07-24 20:52:06,529 DEBUG [WriterThread-2] wal.HLogSplitter$WriterThread(799): Writer thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[WriterThread-2,5,main]: starting
2013-07-24 20:52:06,542 INFO  [IPC Server handler 9 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/bbb	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,543 INFO  [IPC Server handler 1 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/ccc	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,544 INFO  [IPC Server handler 3 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/bbb/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,546 INFO  [IPC Server handler 4 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/bbb/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,546 INFO  [IPC Server handler 2 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/ccc/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,548 INFO  [IPC Server handler 5 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hbase/t1/bbb/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=ec2-user:supergroup:rwxr-xr-x
2013-07-24 20:52:06,549 INFO  [IPC Server handler 8 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/ccc/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,550 INFO  [IPC Server handler 6 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/bbb/recovered.edits/0000000000000000001.temp	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,552 INFO  [IPC Server handler 0 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hbase/t1/ccc/recovered.edits	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=ec2-user:supergroup:rwxr-xr-x
2013-07-24 20:52:06,552 DEBUG [WriterThread-1] wal.HLogSplitter$LogRecoveredEditsOutputSink(1200): Creating writer path=/hbase/t1/bbb/recovered.edits/0000000000000000001.temp region=bbb
2013-07-24 20:52:06,553 FATAL [WriterThread-1] wal.HLogSplitter$LogRecoveredEditsOutputSink(1234):  Got &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; writing log entry to log
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 20:52:06,553 INFO  [IPC Server handler 7 on 50391] namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/ccc/recovered.edits/0000000000000000002.temp	dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;	perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2013-07-24 20:52:06,553 ERROR [WriterThread-1] wal.HLogSplitter$WriterThread(793): Error in log splitting write thread
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 20:52:06,554 DEBUG [WriterThread-2] wal.HLogSplitter$LogRecoveredEditsOutputSink(1200): Creating writer path=/hbase/t1/ccc/recovered.edits/0000000000000000002.temp region=ccc
2013-07-24 20:52:06,555 FATAL [WriterThread-2] wal.HLogSplitter$LogRecoveredEditsOutputSink(1234):  Got &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; writing log entry to log
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 20:52:06,555 ERROR [WriterThread-2] wal.HLogSplitter$WriterThread(793): Error in log splitting write thread
java.io.IOException: Injected
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1225)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)
2013-07-24 20:52:06,557 INFO  [split-log-closeStream-1] wal.HLogSplitter$LogRecoveredEditsOutputSink$2(1042): Closed path /hbase/t1/bbb/recovered.edits/0000000000000000001.temp (wrote 0 edits in 0ms)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is a bit of extra ipc logging going on but you can see that the &apos;Creating writers&apos; is staggered and that we fail writing the first writer before we open the second.  Failed write is FATAL so we are shutting down and on our way out.&lt;/p&gt;

&lt;p&gt;We are leaving the just-opened writer around on our exit.&lt;/p&gt;

&lt;p&gt;Let me try and get a thread dump in here.  It is tough figuring out what we are blocked on.&lt;/p&gt;</comment>
                            <comment id="13719042" author="stack" created="Wed, 24 Jul 2013 23:52:12 +0000"  >&lt;p&gt;Will thread dump every minute if stuck.&lt;/p&gt;</comment>
                            <comment id="13719049" author="stack" created="Wed, 24 Jul 2013 23:55:07 +0000"  >&lt;p&gt;Adds thread dumping and wraps an IOE in another so we can where the &apos;fatal&apos; is being thrown from.  I think the fix is waiting on writer threads to all complete before throwing the fatal exception (they have all been signalled) but let me get some evidence first.&lt;/p&gt;

&lt;p&gt;This looks to be a bug in the log splitter that the unit test is exposing sometimes when scheduling is a little jittery rather than your usual nice and smooth on laptop.&lt;/p&gt;
</comment>
                            <comment id="13719052" author="stack" created="Wed, 24 Jul 2013 23:56:30 +0000"  >&lt;p&gt;I committed the thread dumping patch to 0.95 and trunk.  Lets see how tonights builds do.&lt;/p&gt;</comment>
                            <comment id="13719091" author="hadoopqa" created="Thu, 25 Jul 2013 00:23:11 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594062/9022.addthreaddumping.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594062/9022.addthreaddumping.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6458//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6458//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13719230" author="stack" created="Thu, 25 Jul 2013 04:59:27 +0000"  >&lt;p&gt;Addendum for debugging.  My first patch was a disaster.  Broke builds as all we did was thread dump.&lt;/p&gt;</comment>
                            <comment id="13719231" author="stack" created="Thu, 25 Jul 2013 04:59:49 +0000"  >&lt;p&gt;Applied debug addendum to 0.95 and trunk.&lt;/p&gt;</comment>
                            <comment id="13719233" author="hadoopqa" created="Thu, 25 Jul 2013 05:02:36 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594098/9022.addthreaddumping-part2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594098/9022.addthreaddumping-part2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6459//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6459//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13719980" author="stack" created="Thu, 25 Jul 2013 19:50:57 +0000"  >&lt;p&gt;Failed here: &lt;a href=&quot;http://54.241.6.143/job/HBase-0.95-Hadoop-2/org.apache.hbase$hbase-server/693/testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-0.95-Hadoop-2/org.apache.hbase$hbase-server/693/testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Blocked trying to take:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 408 (&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-298):
  State: WAITING
  Blocked count: 481
  Waited count: 495
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@438b1699
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
    java.util.concurrent.ExecutorCompletionService.take(ExecutorCompletionService.java:164)
    org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.close(HLogSplitter.java:1089)
    org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.finishWritingAndClose(HLogSplitter.java:999)
    org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:336)
    org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.testIOEOnOutputThread(TestHLogSplit.java:837)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    java.lang.reflect.Method.invoke(Method.java:597)
    org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
    org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
    org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
    org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;More logging.  I do not understand whe we are blocked doing a take from the blocking queue when we use ExecutorCompletionService  We are counting wrong when one file is closed first but I do not see how (I see only one thread in the pool of threads passed to ECS though we have two files to close).&lt;/p&gt;</comment>
                            <comment id="13719990" author="stack" created="Thu, 25 Jul 2013 20:03:56 +0000"  >&lt;p&gt;Here is what I applied.&lt;/p&gt;</comment>
                            <comment id="13719992" author="hadoopqa" created="Thu, 25 Jul 2013 20:09:54 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594252/9022.yet-more-logging2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594252/9022.yet-more-logging2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6465//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6465//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13719995" author="hadoopqa" created="Thu, 25 Jul 2013 20:12:34 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594252/9022.yet-more-logging2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594252/9022.yet-more-logging2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6466//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6466//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13721081" author="stack" created="Fri, 26 Jul 2013 19:06:06 +0000"  >&lt;p&gt;It failed a few times over night including here &lt;a href=&quot;http://54.241.6.143/job/HBase-0.95-Hadoop-2/696/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testIOEOnOutputThread/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-0.95-Hadoop-2/696/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplitCompressed/testIOEOnOutputThread/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The debugging shows that we open a writer AFTER the clean up has run (probably because loaded cluster and the thread gets scheduled later):&lt;/p&gt;

&lt;p&gt;Here is section for the above logs:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;monospaced&lt;/tt&gt;&lt;br/&gt;
...&lt;br/&gt;
2013-07-26 05:02:48,439 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;WriterThread-1&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink(1202): Creating writer path=/hbase/t1/ccc/recovered.edits/0000000000000000002.temp region=ccc&lt;br/&gt;
2013-07-26 05:02:48,440 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;WriterThread-1&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink(1236):  Got while writing log entry to log&lt;br/&gt;
java.io.IOException: Injected&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1227)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)&lt;br/&gt;
2013-07-26 05:02:48,440 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;WriterThread-1&amp;#93;&lt;/span&gt; wal.HLogSplitter$WriterThread(793): Exiting thread&lt;br/&gt;
java.io.IOException: Injected&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1227)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)&lt;br/&gt;
2013-07-26 05:02:48,441 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-298&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink(1032): &lt;font color=&quot;red&quot;&gt;Submitting close of /hbase/t1/ccc/recovered.edits/0000000000000000002.temp&lt;/font&gt;&lt;br/&gt;
2013-07-26 05:02:48,443 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 6 on 60581&amp;#93;&lt;/span&gt; namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=true	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hbase/t1/bbb/recovered.edits	dst=null	perm=ec2-user:supergroup:rwxr-xr-x&lt;br/&gt;
2013-07-26 05:02:48,445 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 9 on 60581&amp;#93;&lt;/span&gt; namenode.FSNamesystem$DefaultAuditLogger(5567): allowed=true	ugi=ec2-user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/hbase/t1/bbb/recovered.edits/0000000000000000001.temp	dst=null	perm=null&lt;br/&gt;
2013-07-26 05:02:48,447 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;WriterThread-2&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink(1202): Creating writer path=/hbase/t1/bbb/recovered.edits/0000000000000000001.temp region=bbb&lt;br/&gt;
2013-07-26 05:02:48,447 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;WriterThread-2&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink(1236):  Got while writing log entry to log&lt;br/&gt;
java.io.IOException: Injected&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1227)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)&lt;br/&gt;
2013-07-26 05:02:48,447 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;WriterThread-2&amp;#93;&lt;/span&gt; wal.HLogSplitter$WriterThread(793): Exiting thread&lt;br/&gt;
java.io.IOException: Injected&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink.append(HLogSplitter.java:1227)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:829)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:821)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:791)&lt;br/&gt;
2013-07-26 05:02:48,456 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;split-log-closeStream-1&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink$2(1036): Closing /hbase/t1/ccc/recovered.edits/0000000000000000002.temp&lt;br/&gt;
2013-07-26 05:02:48,458 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;split-log-closeStream-1&amp;#93;&lt;/span&gt; wal.HLogSplitter$LogRecoveredEditsOutputSink$2(1044): Closed wap /hbase/t1/ccc/recovered.edits/0000000000000000002.temp (wrote 0 edits in 0ms)&lt;br/&gt;
...&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;monospaced&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;So we schedule a writer thread.  It opens a recovered.edits writer per region encountered.  The close happens after first region recovered.edits writer is opened but before the second region is encountered.&lt;/p&gt;</comment>
                            <comment id="13721089" author="stack" created="Fri, 26 Jul 2013 19:10:45 +0000"  >&lt;p&gt;Attempted fix.  Applied to trunk and 0.95.  Lets see how it does.&lt;/p&gt;

&lt;p&gt;Wait on thread joins.  We will have set the stop so the writer threads should finish soon enough.&lt;/p&gt;</comment>
                            <comment id="13721094" author="hadoopqa" created="Fri, 26 Jul 2013 19:12:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594436/9022.fix.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594436/9022.fix.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6483//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6483//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13721114" author="stack" created="Fri, 26 Jul 2013 19:25:15 +0000"  >&lt;p&gt;Committed attempted fix to trunk and 0.95.  Will leave issue open to see how it does.&lt;/p&gt;</comment>
                            <comment id="14506110" author="apurtell" created="Wed, 22 Apr 2015 00:35:51 +0000"  >&lt;p&gt;We can close this now?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12594098" name="9022.addthreaddumping-part2.txt" size="3101" author="stack" created="Thu, 25 Jul 2013 04:59:27 +0000"/>
                            <attachment id="12594062" name="9022.addthreaddumping.txt" size="1693" author="stack" created="Wed, 24 Jul 2013 23:52:12 +0000"/>
                            <attachment id="12594436" name="9022.fix.txt" size="657" author="stack" created="Fri, 26 Jul 2013 19:10:45 +0000"/>
                            <attachment id="12593645" name="9022.txt" size="1719" author="stack" created="Tue, 23 Jul 2013 05:34:18 +0000"/>
                            <attachment id="12593635" name="9022.txt" size="1719" author="stack" created="Tue, 23 Jul 2013 03:19:28 +0000"/>
                            <attachment id="12593624" name="9022.txt" size="1719" author="stack" created="Tue, 23 Jul 2013 01:02:02 +0000"/>
                            <attachment id="12594251" name="9022.yet-more-logging.txt" size="7505" author="stack" created="Thu, 25 Jul 2013 19:50:57 +0000"/>
                            <attachment id="12594252" name="9022.yet-more-logging2.txt" size="6553" author="stack" created="Thu, 25 Jul 2013 20:03:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 23 Jul 2013 03:09:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>339432</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 34 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1mjm7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>339752</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>