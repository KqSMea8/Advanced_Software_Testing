<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:57:29 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1923/HBASE-1923.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1923] Bulk incremental load into an existing table</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1923</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;hbase-48 is about bulk load of a new table,maybe it&apos;s more practicable to bulk load aganist a existing table.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12438532">HBASE-1923</key>
            <summary>Bulk incremental load into an existing table</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="anty">anty.rao</reporter>
                        <labels>
                    </labels>
                <created>Tue, 20 Oct 2009 07:01:00 +0000</created>
                <updated>Fri, 20 Nov 2015 13:02:07 +0000</updated>
                            <resolved>Wed, 2 Jun 2010 00:41:59 +0000</resolved>
                                    <version>0.90.0</version>
                                    <fixVersion>0.90.0</fixVersion>
                                    <component>Client</component>
                    <component>regionserver</component>
                    <component>scripts</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="12767754" author="anty" created="Tue, 20 Oct 2009 08:57:38 +0000"  >&lt;p&gt;Flush the table so there is nothing in memstore,then make it read-only so it didn&apos;t split and make new regions.&lt;br/&gt;
Then we should parittion the dataset according to the regions of the table.But when generating HFiles,we should get the latest sequenceId from hbase.&lt;br/&gt;
we need a new version of loadtable.rb that move the HFiles to the right region&lt;br/&gt;
Thanks very much for the comment from stack.&lt;/p&gt;
</comment>
                            <comment id="12869709" author="tlipcon" created="Thu, 20 May 2010 18:27:37 +0000"  >&lt;p&gt;This has become high priority for us, so I&apos;ll be looking into this in the short term.&lt;/p&gt;</comment>
                            <comment id="12869724" author="tlipcon" created="Thu, 20 May 2010 19:02:09 +0000"  >&lt;h1&gt;&lt;a name=&quot;BasicDesign%3A&quot;&gt;&lt;/a&gt;Basic Design:&lt;/h1&gt;

&lt;h2&gt;&lt;a name=&quot;ChangestoHFileOutputFormat%3A&quot;&gt;&lt;/a&gt;Changes to HFileOutputFormat:&lt;/h2&gt;

&lt;p&gt;Should only need changes during job initialization:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;scan all regions of table from .META.&lt;/li&gt;
	&lt;li&gt;configure TotalOrderPartitioner based on existing region key boundaries&lt;/li&gt;
	&lt;li&gt;If the number of reducers &amp;gt; number of regions, we could&lt;br/&gt;
  (a) recursively split table until this is not true (degenerate case: incremental load into table with one row?)&lt;br/&gt;
  (b) simply split keyspace by taking the lexical &quot;halfway&quot; of the region (two HFiles go into one region in load stage)&lt;br/&gt;
  (c) add API to regionserver to get estimate of region midpoint (assuming that new data has similar distribution to old data)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I plan to do either (a) or (b) initially.&lt;/p&gt;

&lt;p&gt;We should provide at least some sample code, if not good utility classes/methods to do this task.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;JobRunning&quot;&gt;&lt;/a&gt;Job Running&lt;/h3&gt;

&lt;p&gt;Should be unaffected&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;DataLoader&quot;&gt;&lt;/a&gt;Data Loader&lt;/h3&gt;

&lt;p&gt;Note that the partitions output by the MR job no longer necessarily correspond to the region boundaries (regions could have split or merged). I think the algorithm looks like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; each reducer output:
  inspect hfile to find lowest key and highest key
  look up region name/startkey/endkey corresponding to first key in hfile
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; HFile&apos;s low&amp;lt;-&amp;gt;high is entirely contained within regions low&amp;lt;-&amp;gt;high:
    send RPC to RS: loadIncremental(region name, &lt;span class=&quot;code-quote&quot;&gt;&quot;/path/to/hfile&quot;&lt;/span&gt;)
  &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
    # &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the inefficient path, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the region split during the MR job
    On the loading side, manually split the HFile into two physical HFiles
      in a tmp directory
    recurse on the split files
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &quot;inefficient&quot; path should occur in a minority of cases. In the future we can implement this path using reference files that would be cleaned at next compaction. I don&apos;t plan to do this in the first pass.&lt;/p&gt;


&lt;p&gt;The above functionality would be implemented in a client side script/program (currently a ruby script, though I will probably just write in Java)&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;RegionServerSide&quot;&gt;&lt;/a&gt;RegionServer Side&lt;/h3&gt;

&lt;p&gt;Need to implement the &quot;loadIncremental&quot; RPC. This function needs to do the following reasonably simple steps:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;ensure that the region being accessed is the same one being hosted (including timestamp, etc)&lt;/li&gt;
	&lt;li&gt;move the HFile into the correct store directory&lt;/li&gt;
	&lt;li&gt;briefly lock the storefile list and add the HFile&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Probably need some other interaction with concurrent scanners, etc - will look at this carefully during implementation.&lt;/p&gt;</comment>
                            <comment id="12869727" author="tlipcon" created="Thu, 20 May 2010 19:05:46 +0000"  >&lt;p&gt;oops, forgot to write about case where number of reducers is less than the number of regions. We could either (a) disallow it, or (b) configure the reducer to simply roll to a new HFile at each region boundary that it crosses. The load algorithm runs per-hfile, not per-reducer, so should work fine.&lt;/p&gt;

&lt;p&gt;I will probably choose option (a) initially &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12869729" author="vidhyash" created="Thu, 20 May 2010 19:10:23 +0000"  >&lt;p&gt;Can you also include support for delete operations along with this bulk-update feature?&lt;/p&gt;

&lt;p&gt;Thank you&lt;br/&gt;
Vidhya&lt;/p&gt;</comment>
                            <comment id="12869733" author="tlipcon" created="Thu, 20 May 2010 19:16:54 +0000"  >&lt;p&gt;Since the HFileOutputFormat just writes KeyValues, delete support should fall out &quot;for free&quot;. However, the APIs to construct the delete tombstones aren&apos;t that obvious, so I think it will be an advanced feature. We should follow up this JIRA with (a) much better documentation on HFileOutputFormat (b) some better wrapper APIs for using it, as KeyValue is pretty low level.&lt;/p&gt;</comment>
                            <comment id="12869735" author="streamy" created="Thu, 20 May 2010 19:20:17 +0000"  >&lt;p&gt;KeyValues are &quot;low level&quot; but there are some pretty user-accessible API calls in it that look just like Puts.  Shouldn&apos;t be too hard to support Put and Delete though since their underlying structure is a bunch of KeyValues anyways.&lt;/p&gt;

&lt;p&gt;Could make HFOF the same API/similar API as TOF.  Would make sense once u can load to an existing table.&lt;/p&gt;</comment>
                            <comment id="12869736" author="streamy" created="Thu, 20 May 2010 19:21:45 +0000"  >&lt;p&gt;Basic design looks good Todd.&lt;/p&gt;</comment>
                            <comment id="12869775" author="stack" created="Thu, 20 May 2010 21:22:09 +0000"  >&lt;p&gt;Looks good to me.  Hows the sampling the TotalOrderPartitioner needs going to work going against hbase?  This is one CF only still, right?&lt;/p&gt;</comment>
                            <comment id="12869776" author="tlipcon" created="Thu, 20 May 2010 21:27:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hows the sampling the TotalOrderPartitioner needs going to work going against hbase?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;TotalOrderPartitioner just needs split points, so I&apos;m manually writing out the necessary SequenceFile, instead of using the Sampler interface.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This is one CF only still, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For now, yes. Unless along the way it becomes easy to fix that while I&apos;m in the vicinity. But I think the two things are pretty much orthogonal.&lt;/p&gt;</comment>
                            <comment id="12869908" author="tlipcon" created="Fri, 21 May 2010 08:06:51 +0000"  >&lt;p&gt;Attaching a work-in-progress patch in case anyone wants to start looking at this (a number of people sounded interested, figured early review would be best)&lt;/p&gt;

&lt;p&gt;Quick tutorial:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
# Generate some data
perl -e &apos;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (1..10000) { print &lt;span class=&quot;code-quote&quot;&gt;&quot;$_\t$_\n&quot;&lt;/span&gt;; }&apos; | hadoop fs -put - mytsv.txt
perl -e &apos;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (1..10000) { print &lt;span class=&quot;code-quote&quot;&gt;&quot;$_\t&quot;&lt;/span&gt; . ($_*3) . &lt;span class=&quot;code-quote&quot;&gt;&quot;\n&quot;&lt;/span&gt;; }&apos; | hadoop fs -put - mytsv2.txt

# Create table to hold it
./bin/hbase shell
create &apos;myfile&apos;, &apos;f1&apos;

# Do a normal MR load
HADOOP_CLASSPATH=$(cat /tmp/hbase-core-test-classpath.txt) hadoop jar target/hbase-0.21.0-SNAPSHOT.jar importtsv -Dcolumns=f1:blah  myfile mytsv.txt

# scan in the shell &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you like
# Potentially split table &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you like
# Generate incremental from the other file
HADOOP_CLASSPATH=$(cat /tmp/hbase-core-test-classpath.txt) hadoop jar target/hbase-0.21.0-SNAPSHOT.jar importtsv -Dcolumns=f1:blah  -Duse.hfile=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; myfile mytsv2.txt

# Load incremental
HBASE_CLASSPATH=$HADOOP_CONF_DIR  ./bin/hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles hfof myfile

# scan in the shell and see that the data has changed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A fair amount of work remains - have to take care of regions that split, or the case when there are fewer reducers than regions.&lt;/p&gt;</comment>
                            <comment id="12870008" author="stack" created="Fri, 21 May 2010 15:02:23 +0000"  >&lt;p&gt;I was going to suggest you add this to the hbase mapreduce driver but you have done so already.&lt;/p&gt;</comment>
                            <comment id="12871364" author="hbasereviewboard" created="Tue, 25 May 2010 21:23:32 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hbase, stack and Jonathan Gray.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Here&apos;s a first patch that implements bulk import into existing tables. This applies on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2586&quot; title=&quot;Move hbase webapps to an hbase-webapps dir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2586&quot;&gt;&lt;del&gt;HBASE-2586&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2588&quot; title=&quot;Add easier way to ship hbase dependencies to MR cluster with job&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2588&quot;&gt;&lt;del&gt;HBASE-2588&lt;/del&gt;&lt;/a&gt; - I&apos;ve pushed the series of the three to my github: &lt;a href=&quot;http://github.com/toddlipcon/hbase/tree/hfof-review&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/toddlipcon/hbase/tree/hfof-review&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have some TODOs left that I want to take care of before this gets committed, but since it&apos;s a pretty large patch, I figured I&apos;d get it out for review ASAP.&lt;/p&gt;

&lt;p&gt;The stuff in the hadoopbackport package is essentially copypaste from Hadoop trunk, so you can ignore that in the review.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1923&quot; title=&quot;Bulk incremental load into an existing table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1923&quot;&gt;&lt;del&gt;HBASE-1923&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HBASE-1923&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HBASE-1923&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  pom.xml 0a009cf &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HRegionInfo.java 29b0cd6 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/ImmutableBytesWritable.java 0a9ec4b &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java cf4768f &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java 4cbe52a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/Driver.java 3d40695 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java 9c8e53e &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/SimpleTotalOrderPartitioner.java af3d588 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java 287cd48 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java fb65ed1 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java 7de766d &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/Bytes.java a53dafe &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java ed8709f &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/NMapInputFormat.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java d04ced2 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionInfo.java fcb22fb &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.hbase.org/r/87/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Primary unit/functional testing, a bit of pseudo-distributed testing. Plan on doing full system tests before commit as well.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Todd&lt;/p&gt;

</comment>
                            <comment id="12871537" author="hbasereviewboard" created="Wed, 26 May 2010 06:54:32 +0000"  >&lt;p&gt;Message from: &quot;Ryan Rawson&quot; &amp;lt;ryanobjc@gmail.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review76&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review76&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment396&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment396&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    this cant go here, HFile cannot know about KeyValues. It will go into StoreFile&lt;/p&gt;




&lt;p&gt;src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment397&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment397&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    you might also say the last key in the HFile means the last &quot;KeyValue&quot;&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment398&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment398&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    this won&apos;t work for an existing table - if the current time millis &amp;gt; the current sequence id in the live server, we could end up losing edits during a log recovery&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ryan&lt;/li&gt;
&lt;/ul&gt;




</comment>
                            <comment id="12871542" author="ryanobjc" created="Wed, 26 May 2010 07:25:55 +0000"  >&lt;p&gt;an extensive discussion outlined why the sequence id thing is critical and is a major blocker:&lt;/p&gt;

&lt;p&gt;23:43 &amp;lt; dj_ryan&amp;gt; before this can go in&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; the sequence # stuff is... tricky&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; so here&apos;s the thing&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; if you use any static sequence id you will end up with problems&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; if you use System.currentTimeMilli()&lt;br/&gt;
23:44 &amp;lt; tlipcon&amp;gt; yea it needs to be unique&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; it isnt that easy&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; it has to be smaller than the current largest sequence ID&lt;br/&gt;
23:44 &amp;lt; tlipcon&amp;gt; and less than the lowest unflushed&lt;br/&gt;
23:44 &amp;lt; tlipcon&amp;gt; right&lt;br/&gt;
23:44 &amp;lt; dj_ryan&amp;gt; because otherwise you might bump the sequence id up a bunch&lt;br/&gt;
23:45 &amp;lt; dj_ryan&amp;gt; and if we ever hit a log recovery we&apos;d skip a ton of edits&lt;br/&gt;
23:45 &amp;lt; tlipcon&amp;gt; yea, perhaps unique negative numbers&lt;br/&gt;
23:45 &amp;lt; dj_ryan&amp;gt; well it will go away after a compaction&lt;br/&gt;
23:45 &amp;lt; dj_ryan&amp;gt; so if we use &apos;0&apos;&lt;br/&gt;
23:45 &amp;lt; dj_ryan&amp;gt; that might workish&lt;br/&gt;
23:45 &amp;lt; dj_ryan&amp;gt; you will have to compact between imports&lt;br/&gt;
23:45 &amp;lt; tlipcon&amp;gt; or potentially change the storefile holder to be a &lt;br/&gt;
                 List&amp;lt;Storefile&amp;gt; rather than a map&lt;br/&gt;
23:45 &amp;lt; tlipcon&amp;gt; we&apos;re sort of abusing a map there&lt;br/&gt;
23:45 &amp;lt; dj_ryan&amp;gt; there was a really good reason for doing what we did&lt;br/&gt;
23:46 &amp;lt; tlipcon&amp;gt; yea i think it used to make more sense&lt;br/&gt;
23:46 &amp;lt; tlipcon&amp;gt; when we &quot;early out&quot;ed gets&lt;br/&gt;
23:46 &amp;lt; dj_ryan&amp;gt; so until we know exactly why that is so i&apos;d be hesistant at &lt;br/&gt;
                 removing it&lt;br/&gt;
23:46 &amp;lt; dj_ryan&amp;gt; so we had that before that&lt;br/&gt;
23:46 &amp;lt; tlipcon&amp;gt; now with gets as scans I don&apos;t htink it&apos;s so important&lt;br/&gt;
23:46 &amp;lt; dj_ryan&amp;gt; didnt we stack?&lt;br/&gt;
23:46 &amp;lt; dj_ryan&amp;gt; but we still need it&lt;br/&gt;
23:46 &amp;lt; dj_ryan&amp;gt; because META has custom logic to do rowAtOrBefore()&lt;br/&gt;
23:46 &amp;lt; tlipcon&amp;gt; we need to be able to find oldest/newest, but we&apos;re talking &lt;br/&gt;
                 about a min/max over like 10s of elements, hardly slow&lt;br/&gt;
23:46 &amp;lt; dj_ryan&amp;gt; which still does a similar behaviour like the old get, only &lt;br/&gt;
                 with its own unique code path&lt;br/&gt;
23:48 &amp;lt; dj_ryan&amp;gt; we dont want to go back to the ye olde days of &apos;you cant drop &lt;br/&gt;
                 a table then recreate it without flushing and major compacting &lt;br/&gt;
                 between the drop and the create&apos;&lt;br/&gt;
23:48 &amp;lt; dj_ryan&amp;gt; that was no good&lt;br/&gt;
23:48 &amp;lt; dj_ryan&amp;gt; yeah we arent creating sequence ids for these HFiles are we&lt;br/&gt;
23:48 &amp;lt; dj_ryan&amp;gt; they wont load&lt;br/&gt;
23:49 &amp;lt; dj_ryan&amp;gt; oh isee&lt;br/&gt;
23:49 &amp;lt; dj_ryan&amp;gt; it uses currentTimMillis&lt;br/&gt;
23:49 &amp;lt; dj_ryan&amp;gt; you cant do that for this code&lt;br/&gt;
23:50 &amp;lt; dj_ryan&amp;gt; because we&apos;d end up potentially creating a HFile that has a &lt;br/&gt;
                 seq id &amp;gt; the live seq ID&lt;br/&gt;
23:50 &amp;lt; dj_ryan&amp;gt; which would be i trouble&lt;br/&gt;
23:50 &amp;lt; tlipcon&amp;gt; yep&lt;br/&gt;
23:51 &amp;lt; tlipcon&amp;gt; I think unique negative numbers are probably the best bet&lt;br/&gt;
23:51 &amp;lt; tlipcon&amp;gt; though it&apos;s a hack&lt;br/&gt;
23:51 &amp;lt; dj_ryan&amp;gt; well 0 is probably one of the best choices&lt;br/&gt;
23:51 &amp;lt; tlipcon&amp;gt; or better, changing the container to not be a map&lt;br/&gt;
23:51 &amp;lt; dj_ryan&amp;gt; actually&lt;br/&gt;
23:51 &amp;lt; dj_ryan&amp;gt; we cant do that&lt;br/&gt;
23:51 &amp;lt; tlipcon&amp;gt; 0 doesn&apos;t let you do multiple incrementals w/o major compact, &lt;br/&gt;
                 like you said&lt;br/&gt;
23:51 &amp;lt; dj_ryan&amp;gt; yeah&lt;br/&gt;
23:51 &amp;lt; dj_ryan&amp;gt; but we cant get rid of the ordering&lt;br/&gt;
23:51 &amp;lt; dj_ryan&amp;gt; i think the compaction code also depends on using that as well&lt;br/&gt;
23:52 &amp;lt; St^Ack&amp;gt; we saying that there is no ordering any more?&lt;br/&gt;
23:52 &amp;lt; St^Ack&amp;gt; we can&apos;t be saying that, right?&lt;br/&gt;
23:52 &amp;lt; tlipcon&amp;gt; St^Ack: I dunno&lt;br/&gt;
23:52 &amp;lt; St^Ack&amp;gt; no order to sequence files&lt;br/&gt;
23:52 &amp;lt; tlipcon&amp;gt; it would be an enticing thing to say&lt;br/&gt;
23:52 &amp;lt; tlipcon&amp;gt; but we never quite figured out if we can say it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
23:52 &amp;lt; tlipcon&amp;gt; i think the delete semantics question actually factors in here&lt;br/&gt;
23:52 &amp;lt; St^Ack&amp;gt; you need sequenceid replaying logs&lt;br/&gt;
23:53 &amp;lt; St^Ack&amp;gt; and for letting go of hlogs&lt;br/&gt;
23:53 &amp;lt; St^Ack&amp;gt; each edit gets a seqid &lt;br/&gt;
23:53 &amp;lt; St^Ack&amp;gt; they are ever increasing inside HRS&lt;br/&gt;
23:54 &amp;lt; St^Ack&amp;gt; hfile gets written w/ last seqid&lt;br/&gt;
23:54 &amp;lt; St^Ack&amp;gt; in old days for get&lt;br/&gt;
23:54 &amp;lt; St^Ack&amp;gt; we&apos;d order them by seqid&lt;br/&gt;
23:54 &amp;lt; tlipcon&amp;gt; yea, I don&apos;t think we&apos;re debating whether we need seqid&lt;br/&gt;
23:54 &amp;lt; tlipcon&amp;gt; just whether seqid has to be entirely unique&lt;br/&gt;
23:54 &amp;lt; St^Ack&amp;gt; it does have to be unique&lt;br/&gt;
23:55 &amp;lt; St^Ack&amp;gt; at least currenlty it does&lt;br/&gt;
23:55 &amp;lt; St^Ack&amp;gt; when we open them, we key them by seqid&lt;br/&gt;
23:55 &amp;lt; tlipcon&amp;gt; yea currently cuz of the Map&amp;lt;Long, StoreFile&amp;gt; or whatever we do&lt;br/&gt;
23:55 &amp;lt; tlipcon&amp;gt; but we could change that to a List&amp;lt;Pair&amp;lt;Long, StoreFile&amp;gt;&amp;gt;&lt;br/&gt;
23:56 &amp;lt; St^Ack&amp;gt; compacting code currently addresses them in order&lt;br/&gt;
23:56 &amp;lt; St^Ack&amp;gt; which version to let go &lt;br/&gt;
23:56 &amp;lt; St^Ack&amp;gt; we let go of the oldest&lt;br/&gt;
23:56 &amp;lt; St^Ack&amp;gt; first&lt;br/&gt;
23:57 &amp;lt; jgray&amp;gt; St^Ack: compacting code has notion of storefile ordering?&lt;br/&gt;
23:57 &amp;lt; St^Ack&amp;gt; todd, you are inserting into quiescent table?&lt;br/&gt;
23:57 &amp;lt; St^Ack&amp;gt; jgray: yes&lt;br/&gt;
23:58 &amp;lt; tlipcon&amp;gt; St^Ack: nope, inserting a new storefile into a live table&lt;br/&gt;
23:58 &amp;lt; St^Ack&amp;gt; tlipcon: if you asked RS for a seqid&lt;br/&gt;
23:58 &amp;lt; tlipcon&amp;gt; that&apos;s the fun of this patch&lt;br/&gt;
23:58 &amp;lt; St^Ack&amp;gt; that might help&lt;br/&gt;
23:58 &amp;lt; tlipcon&amp;gt; it all happens inside the RS&lt;br/&gt;
23:58 &amp;lt; St^Ack&amp;gt; hmmm....&lt;br/&gt;
23:58 &amp;lt; St^Ack&amp;gt; that won&apos;t help&lt;br/&gt;
23:58 &amp;lt; tlipcon&amp;gt; we don&apos;t want a new seqid though&lt;br/&gt;
23:59 &amp;lt; tlipcon&amp;gt; we explicitly want an old seqid&lt;br/&gt;
23:59 &amp;lt; St^Ack&amp;gt; because then you could have memsotre flush that had edits &lt;br/&gt;
                either side of your new file&lt;br/&gt;
23:59 &amp;lt; jgray&amp;gt; St^Ack: where does it look at storefile order?&lt;br/&gt;
23:59 &amp;lt; St^Ack&amp;gt; jgray: files are ordered in the Store&lt;br/&gt;
23:59 &amp;lt; St^Ack&amp;gt; by seqid&lt;br/&gt;
23:59 &amp;lt; St^Ack&amp;gt; newest to oldest&lt;br/&gt;
00:00 &amp;lt; jgray&amp;gt; yeah, i thought u meant when it does the merge?&lt;br/&gt;
00:00 &amp;lt; jgray&amp;gt; u mean in picking which files to compact?&lt;br/&gt;
00:00 &amp;lt; St^Ack&amp;gt; yeah.... keesp order&lt;br/&gt;
00:00 &amp;lt; jgray&amp;gt; yeah ok&lt;br/&gt;
00:00 &amp;lt; jgray&amp;gt; sorry thought u meant something else&lt;br/&gt;
00:00 &amp;lt; St^Ack&amp;gt; but you saying that because it uses mergesort it dont&apos; matter&lt;br/&gt;
00:00 &amp;lt; St^Ack&amp;gt; tlipcon: thats hard.&lt;br/&gt;
00:00 &amp;lt; jgray&amp;gt; once it picks the files to merge, from then on it doesn&apos;t look &lt;br/&gt;
               at seqid&lt;br/&gt;
00:01 &amp;lt; jgray&amp;gt; but we do look at them in seqid order when picking files to &lt;br/&gt;
               compact&lt;br/&gt;
00:01 &amp;lt; dj_ryan&amp;gt; during the process of compaction yes we dont use the sequence &lt;br/&gt;
                 ordering&lt;br/&gt;
00:01 &amp;lt; St^Ack&amp;gt; so, if 10 versions and we&apos;re to keep 3, we could be keping any &lt;br/&gt;
                3?&lt;br/&gt;
00:01 &amp;lt; tlipcon&amp;gt; yea, but I think we all agree current compaction heuristic is &lt;br/&gt;
                 kind of silly&lt;br/&gt;
00:01 &amp;lt; dj_ryan&amp;gt; well&lt;br/&gt;
00:02 &amp;lt; dj_ryan&amp;gt; so the thing is picking which store files uses the sequence&lt;br/&gt;
00:02 &amp;lt; dj_ryan&amp;gt; because when we do minor compaction its important that we &lt;br/&gt;
                 compact adjacent files &lt;br/&gt;
00:02 &amp;lt; dj_ryan&amp;gt; and it will be important for future patches&lt;br/&gt;
00:02 &amp;lt; jgray&amp;gt; St^Ack: 10 columns w/ same timestamp?&lt;br/&gt;
00:02 &amp;lt; jgray&amp;gt; the same 10 cols&lt;br/&gt;
00:02 &amp;lt; St^Ack&amp;gt; thats diff topic (smile)&lt;br/&gt;
00:02 &amp;lt; dj_ryan&amp;gt; heh&lt;br/&gt;
00:03 &amp;lt; dj_ryan&amp;gt; i mean how often do we want to actually do do loadFile&lt;br/&gt;
00:03 &amp;lt; tlipcon&amp;gt; dj_ryan: the particular customer that has requested this &lt;br/&gt;
                 essentially wants to &lt;b&gt;only&lt;/b&gt; do loadfile&lt;br/&gt;
00:03 &amp;lt; dj_ryan&amp;gt; well&lt;br/&gt;
00:03 &amp;lt; dj_ryan&amp;gt; you could pick the current sequence id then increment it&lt;br/&gt;
00:03 &amp;lt; jgray&amp;gt; St^Ack: if the columns have unique versions/stamps, then we do &lt;br/&gt;
               it right... we merge them in KV order... the issue there is more &lt;br/&gt;
               about when they have the same stamp, we would want to know &lt;br/&gt;
               storefile stamps to use that to determine order&lt;br/&gt;
00:03 &amp;lt; dj_ryan&amp;gt; thus creating a 1 edit hole in the hlog&lt;br/&gt;
00:04 &amp;lt; dj_ryan&amp;gt; in fact you could even log it&lt;br/&gt;
00:04 &amp;lt; tlipcon&amp;gt; dj_ryan: isn&apos;t it the opposite? we want to pick the latest &lt;br/&gt;
                 flushed store file, and go one less?&lt;br/&gt;
00:04 &amp;lt; dj_ryan&amp;gt; but then the metadata in the HFile wouldnt match &lt;br/&gt;
00:04 &amp;lt; dj_ryan&amp;gt; unless we re-wrote the HFile during load (Doh)&lt;br/&gt;
00:04 &amp;lt; St^Ack&amp;gt; jgray: makes sense&lt;br/&gt;
00:04 &amp;lt; tlipcon&amp;gt; yea that&apos;s another pain in the ass&lt;br/&gt;
00:04 &amp;lt; dj_ryan&amp;gt; hmm&lt;br/&gt;
00:04 &amp;lt; dj_ryan&amp;gt; yeah i guess you&apos;re right&lt;br/&gt;
00:05 &amp;lt; dj_ryan&amp;gt; again the problem would be the sequence id in the HFile&lt;br/&gt;
00:05 &amp;lt; dj_ryan&amp;gt; right now its being baked in at the map reduce time&lt;br/&gt;
00:05 &amp;lt; dj_ryan&amp;gt; no matter what we pick at regionserver time&lt;br/&gt;
00:05 &amp;lt; tlipcon&amp;gt; right, I think our best bet is to either not put one in there, &lt;br/&gt;
                 or put in a special BULKLOAD_HFILE signifier of some sort&lt;br/&gt;
00:05 &amp;lt; tlipcon&amp;gt; either in place of or in addition to the seqid&lt;br/&gt;
00:05 &amp;lt; dj_ryan&amp;gt; you&apos;d potentially have an issue during the next region re-open&lt;br/&gt;
00:09 &amp;lt; dj_ryan&amp;gt; 0 might be the best choice at MR time&lt;br/&gt;
00:09 &amp;lt; tlipcon&amp;gt; I think adding a new metadata entry saying it was a bulk load &lt;br/&gt;
                 is our best bet&lt;br/&gt;
00:09 &amp;lt; tlipcon&amp;gt; then treating them specially where we need to&lt;br/&gt;
00:09 &amp;lt; tlipcon&amp;gt; i hate special casing, but other things seem hackish&lt;br/&gt;
00:09 &amp;lt; St^Ack&amp;gt; can&apos;t be 0 because next time he runs nd if its still around... &lt;br/&gt;
                clash&lt;br/&gt;
00:09 &amp;lt; dj_ryan&amp;gt; St^Ack: right&lt;br/&gt;
00:10 &amp;lt; dj_ryan&amp;gt; can we call seqid 0 special&lt;br/&gt;
00:10 &amp;lt; tlipcon&amp;gt; I&apos;d rather put no seqid at all&lt;br/&gt;
00:10 &amp;lt; dj_ryan&amp;gt; we will never have a seqid 0 in the wild&lt;br/&gt;
00:10 &amp;lt; tlipcon&amp;gt; calling seqid 0 special is easy to miss&lt;br/&gt;
00:10 &amp;lt; dj_ryan&amp;gt; hmm&lt;br/&gt;
00:10 &amp;lt; tlipcon&amp;gt; whereas if we make it null, we&apos;ll get NPEs if we forget to &lt;br/&gt;
                 account for this case&lt;br/&gt;
00:10 &amp;lt; tlipcon&amp;gt; which I think is preferable&lt;br/&gt;
00:10 &amp;lt; tlipcon&amp;gt; otherwise people will forget about it and code stuff that &lt;br/&gt;
                 breaks subtly instead of loudly&lt;br/&gt;
00:10 &amp;lt; dj_ryan&amp;gt; hmm&lt;br/&gt;
00:11 &amp;lt; dj_ryan&amp;gt; without a sequence id you cant compact those files to each &lt;br/&gt;
                 other&lt;br/&gt;
00:11 &amp;lt; dj_ryan&amp;gt; or maybe they can&lt;br/&gt;
00:11 &amp;lt; dj_ryan&amp;gt; so if you grab all the hfiles w/sequence ids&lt;br/&gt;
00:11 &amp;lt; St^Ack&amp;gt; w/o seqid can&apos;t load it&lt;br/&gt;
00:11 &amp;lt; dj_ryan&amp;gt; then fit in the ones without it around it&lt;br/&gt;
00:13 &amp;lt; dj_ryan&amp;gt; so when you compact N files together you pick the largest &lt;br/&gt;
                 sequence id&lt;br/&gt;
00:13 &amp;lt; dj_ryan&amp;gt; then use that as the new sequence id of the file&lt;br/&gt;
00:13 &amp;lt; dj_ryan&amp;gt; (of the output file)&lt;br/&gt;
00:14 &amp;lt; dj_ryan&amp;gt; and that comes from the file&apos;s metadata i think&lt;/p&gt;</comment>
                            <comment id="12872854" author="hbasereviewboard" created="Fri, 28 May 2010 05:27:40 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review90&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review90&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/util/Bytes.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment514&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment514&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Oops, left this in.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Todd&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12872859" author="tlipcon" created="Fri, 28 May 2010 05:42:14 +0000"  >&lt;p&gt;Regarding the logseqid issue, I think I like the following solution:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;we insert no seqid at all in the HFile when we create it&lt;/li&gt;
	&lt;li&gt;instead, we insert a special meta field that specifies that this is a bulk load result file (perhaps give the timestamp or the MR job ID or whatever)&lt;/li&gt;
	&lt;li&gt;change the Map&amp;lt;Long, StoreFile&amp;gt; inside HRegion to be a List&amp;lt;StoreFile&amp;gt;, making necessary changes so that existing functionality still works (maybe need to add logseqid as a member of storefile?)&lt;/li&gt;
	&lt;li&gt;ensure that RS startup handles hfiles correctly when they have no seqid (in terms of log replay)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The hard part is that last bit - where in the StoreFile list do bulk load files end up? Do we always put them &quot;on top&quot;? I think with our new gets-as-scans implementation this will be fine, but we need to think whether it will cause issues with compaction, etc. Does anyone have some thoughts here?&lt;/p&gt;</comment>
                            <comment id="12873193" author="hbasereviewboard" created="Sat, 29 May 2010 00:20:27 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review96&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment554&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment554&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    @Ryan: This shouldn&apos;t block commit of Todd&apos;s patch though, right?  We can move it out after your refactoring?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment555&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment555&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Is this patch for trunk or branch?  If branch, this addition might break RPC.   It might be ok on the end here but we should test.&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/Driver.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment556&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment556&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Is this a good description? Its underneath the Import.class which imports by going against the API.  You might add a work about it going behind the API, writing hfiles?&lt;/p&gt;

&lt;p&gt;    Hmmm... later I see that it can do both, write hfile or write to table&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment557&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment557&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Nice!&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment558&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment558&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Man, we never enable asserts.... throw an exception!&lt;/p&gt;




&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment559&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment559&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Just asking, the comparator for sure is going to do the right thing here?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment560&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment560&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Won&apos;t javadoc mangle your nice formatting here?  Use ul/li or wrap w/ &amp;lt;pre&amp;gt;?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment561&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment561&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Why two types?  Is this legacy?  KV has advantage of being able to carry a Delete&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment562&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment562&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    In KV, there is a parseColumns function that might help here&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment563&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment563&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Is this safe?  Is there escaping you should be handling here?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment564&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment564&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    I suppose in rare circumstances, it could split in here and mess you up.  You need a no-split flag per region out in zk or something?  We&apos;d need such a thing for snapshotting methinks.  But, thats for a later...&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment566&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment566&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    THis is good&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment565&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment565&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Yeah, there is probably other metadata you&apos;d want to bring over beyond blocksize &amp;#8211; like whether its compressed?  For later.&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment567&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment567&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Class comment.  Whats this thing do?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment568&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment568&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    We need this even though you wrote out partition edges earlier when you read region boundaries?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment569&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment569&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This is old cruddy stuff you are asking about.  It looks like I added splitsAndClosesLock to stop either happening during critical periods (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-588&quot; title=&quot;Still a &amp;#39;hole&amp;#39; in scanners, even after HBASE-532&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-588&quot;&gt;&lt;del&gt;HBASE-588&lt;/del&gt;&lt;/a&gt;) and the splits lock looks now like a half measure from way back in 2007 &amp;#8211; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-217&quot; title=&quot;[hbase] Fix critical shutdown problem introduced by HADOOP-2338&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-217&quot;&gt;&lt;del&gt;HBASE-217&lt;/del&gt;&lt;/a&gt;.  Lets make an issue to clean it up.&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment570&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment570&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Nice&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment571&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment571&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    There is FSUtils in hbase util&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment572&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment572&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    What you going to do here?  Get the last key from the map of storefiles in current region and make your file be one less than it?  Your timestamp is current though so edits in here could overshadow those in another storefile.  Thats ok?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/util/Bytes.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment573&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    You were going to remove this&lt;/p&gt;



&lt;p&gt;src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment574&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment574&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Good&lt;/p&gt;



&lt;p&gt;src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment575&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment575&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Ugh... ok.&lt;/p&gt;



&lt;p&gt;src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment576&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment576&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Whats this about?&lt;/p&gt;



&lt;p&gt;src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment577&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment577&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Its not removing it itself?  Its registered to cleanup on exit.&lt;/p&gt;



&lt;p&gt;src/test/java/org/apache/hadoop/hbase/mapreduce/NMapInputFormat.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment578&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment578&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    How?  If nullwritables, don&apos;t I just get nulls?&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12873194" author="hbasereviewboard" created="Sat, 29 May 2010 00:22:36 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review97&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review97&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;p&gt;Looks good to me.  I don&apos;t have any major issues so go ahead and commit addressing any comments of mine you think prompt fixup.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12873486" author="hbasereviewboard" created="Sun, 30 May 2010 21:15:31 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java, line 264&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=610#file610line264&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=610#file610line264&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Is this patch for trunk or branch?  If branch, this addition might break RPC.   It might be ok on the end here but we should test.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I will be backporting to branch for our customer, but as a major new feature I didn&apos;t expect it would be committed to Apache branch. If people want it, though, I&apos;ll put the patch up.&lt;/p&gt;

&lt;p&gt;In general, adding a new RPC doesn&apos;t cause incompatibility - if a client calls it and it&apos;s not there on the server side, the client will just get an exception that the method doesn&apos;t exist. (eg see my backport of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt; to hadoop 20)&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java, line 181&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=612#file612line181&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=612#file612line181&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Man, we never enable asserts.... throw an exception!&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switched to using google Preconditions&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java, line 187&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=612#file612line187&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=612#file612line187&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Just asking, the comparator for sure is going to do the right thing here?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yea, ImmutableBytesWritable implements Comparable&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java, line 213&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=612#file612line213&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=612#file612line213&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Won&apos;t javadoc mangle your nice formatting here?  Use ul/li or wrap w/ &amp;lt;pre&amp;gt;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;good call, fixed to ul/li&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java, line 234&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=612#file612line234&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=612#file612line234&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Why two types?  Is this legacy?  KV has advantage of being able to carry a Delete&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yea, it&apos;s for compatibility with TableOutputFormat which can take either. Kind of a pain, maybe we should just get rid of it and only accept KV?&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java, line 73&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=613#file613line73&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=613#file613line73&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     In KV, there is a parseColumns function that might help here&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;doesn&apos;t seem much more convenient (since I already have String here)&lt;br/&gt;
One question, though: if I want to insert into a family that has no qualifiers, should I be using EMPTY_BYTE_ARRAY when I construct the KV, or passing null?&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java, line 96&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=613#file613line96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=613#file613line96&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Is this safe?  Is there escaping you should be handling here?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Plan to address this in docs for importtsv - it&apos;s not a good TSV parser that supports quoting, etc.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java, line 229&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=614#file614line229&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=614#file614line229&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     I suppose in rare circumstances, it could split in here and mess you up.  You need a no-split flag per region out in zk or something?  We&apos;d need such a thing for snapshotting methinks.  But, thats for a later...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;if there&apos;s been a split, the new daughter region will detect that the HFile doesn&apos;t &quot;fit&quot; and throw WrongRegionException. This then triggers the retry on ServerCallable, which fetches the new region info from meta, and realizes it has to split the hfile before trying again.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java, line 29&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=615#file615line29&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=615#file615line29&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Class comment.  Whats this thing do?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;fixed - copied from KeyValueSortReducer&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java, line 57&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=617#file617line57&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=617#file617line57&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     We need this even though you wrote out partition edges earlier when you read region boundaries?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You&apos;re right that it&apos;s unused, but I figured I&apos;d put it in for convenience - when doing a bulk load into a new table, for example, you may want to use this in order to figure out where to set region splits.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1897&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=619#file619line1897&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=619#file619line1897&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This is old cruddy stuff you are asking about.  It looks like I added splitsAndClosesLock to stop either happening during critical periods (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-588&quot; title=&quot;Still a &amp;#39;hole&amp;#39; in scanners, even after HBASE-532&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-588&quot;&gt;&lt;del&gt;HBASE-588&lt;/del&gt;&lt;/a&gt;) and the splits lock looks now like a half measure from way back in 2007 &amp;#8211; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-217&quot; title=&quot;[hbase] Fix critical shutdown problem introduced by HADOOP-2338&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-217&quot;&gt;&lt;del&gt;HBASE-217&lt;/del&gt;&lt;/a&gt;.  Lets make an issue to clean it up.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Which one should I be taking? Do I need both? Which order?&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/Store.java, line 511&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=621#file621line511&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=621#file621line511&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     There is FSUtils in hbase util&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;On second thought actually this should be somewhat store-specific, so took out the TODO&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/util/Bytes.java, line 1105&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=622#file622line1105&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=622#file622line1105&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     You were going to remove this&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;fixed&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/Store.java, line 535&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=621#file621line535&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=621#file621line535&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     What you going to do here?  Get the last key from the map of storefiles in current region and make your file be one less than it?  Your timestamp is current though so edits in here could overshadow those in another storefile.  Thats ok?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;going to make storefiles be a list instead of map... new review coming in a bit&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java, line 646&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=623#file623line646&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=623#file623line646&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Whats this about?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;added comment - idea is to restore back to local-mode job runner when cluster shuts down&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java, line 784&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=623#file623line784&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=623#file623line784&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Its not removing it itself?  Its registered to cleanup on exit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;was seeing cases where in between different tests in the same test case, it wouldn&apos;t get cleaned up, etc.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/test/java/org/apache/hadoop/hbase/mapreduce/NMapInputFormat.java, line 40&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=624#file624line40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=624#file624line40&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     How?  If nullwritables, don&apos;t I just get nulls?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Changed to:&lt;/p&gt;

&lt;p&gt;/**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Input format that creates as many map tasks as configured in&lt;/li&gt;
	&lt;li&gt;mapred.map.tasks, each provided with a single row of&lt;/li&gt;
	&lt;li&gt;NullWritables. This can be useful when trying to write mappers&lt;/li&gt;
	&lt;li&gt;which don&apos;t have any real input (eg when the mapper is simply&lt;/li&gt;
	&lt;li&gt;producing random data as output)&lt;br/&gt;
 */&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Todd&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review96&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12873509" author="hbasereviewboard" created="Sun, 30 May 2010 23:15:30 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-05-30 16:13:22.509910)&lt;/p&gt;


&lt;p&gt;Review request for hbase, stack and Jonathan Gray.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Here&apos;s an updated diff which includes Stack&apos;s comments, plus does the junk inside Store to get rid of the currentTimeMillis hack. Also augments the test case a bit to force the bulk-loaded regions to reload.&lt;/p&gt;

&lt;p&gt;Still needs further work, and some new unit tests, again just want to get early comments since this has become rather invasive.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Here&apos;s a first patch that implements bulk import into existing tables. This applies on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2586&quot; title=&quot;Move hbase webapps to an hbase-webapps dir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2586&quot;&gt;&lt;del&gt;HBASE-2586&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2588&quot; title=&quot;Add easier way to ship hbase dependencies to MR cluster with job&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2588&quot;&gt;&lt;del&gt;HBASE-2588&lt;/del&gt;&lt;/a&gt; - I&apos;ve pushed the series of the three to my github: &lt;a href=&quot;http://github.com/toddlipcon/hbase/tree/hfof-review&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/toddlipcon/hbase/tree/hfof-review&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have some TODOs left that I want to take care of before this gets committed, but since it&apos;s a pretty large patch, I figured I&apos;d get it out for review ASAP.&lt;/p&gt;

&lt;p&gt;The stuff in the hadoopbackport package is essentially copypaste from Hadoop trunk, so you can ignore that in the review.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1923&quot; title=&quot;Bulk incremental load into an existing table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1923&quot;&gt;&lt;del&gt;HBASE-1923&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HBASE-1923&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HBASE-1923&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  pom.xml 0a009cf &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HRegionInfo.java 29b0cd6 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/ImmutableBytesWritable.java 0a9ec4b &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java b912a85 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java 4cbe52a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/Driver.java 3d40695 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java 9c8e53e &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/SimpleTotalOrderPartitioner.java af3d588 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java 287cd48 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java 78f3223 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java 7de766d &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java 80bf09a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java c8941f1 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/Bytes.java a53dafe &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java ed8709f &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/NMapInputFormat.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java d04ced2 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java f1566d3 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionInfo.java fcb22fb &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java 4595e6e &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.hbase.org/r/87/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Primary unit/functional testing, a bit of pseudo-distributed testing. Plan on doing full system tests before commit as well.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Todd&lt;/p&gt;

</comment>
                            <comment id="12873566" author="hbasereviewboard" created="Mon, 31 May 2010 07:24:40 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-05-31 00:22:24.084089)&lt;/p&gt;


&lt;p&gt;Review request for hbase, stack and Jonathan Gray.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Yet another draft, addresses some of the TODOs, adds some more unit tests, etc.&lt;/p&gt;

&lt;p&gt;I think this is nearing commitability.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Here&apos;s a first patch that implements bulk import into existing tables. This applies on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2586&quot; title=&quot;Move hbase webapps to an hbase-webapps dir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2586&quot;&gt;&lt;del&gt;HBASE-2586&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2588&quot; title=&quot;Add easier way to ship hbase dependencies to MR cluster with job&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2588&quot;&gt;&lt;del&gt;HBASE-2588&lt;/del&gt;&lt;/a&gt; - I&apos;ve pushed the series of the three to my github: &lt;a href=&quot;http://github.com/toddlipcon/hbase/tree/hfof-review&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/toddlipcon/hbase/tree/hfof-review&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have some TODOs left that I want to take care of before this gets committed, but since it&apos;s a pretty large patch, I figured I&apos;d get it out for review ASAP.&lt;/p&gt;

&lt;p&gt;The stuff in the hadoopbackport package is essentially copypaste from Hadoop trunk, so you can ignore that in the review.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1923&quot; title=&quot;Bulk incremental load into an existing table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1923&quot;&gt;&lt;del&gt;HBASE-1923&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HBASE-1923&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HBASE-1923&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  pom.xml 0a009cf &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HRegionInfo.java 29b0cd6 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/ImmutableBytesWritable.java 0a9ec4b &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java b912a85 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java 4cbe52a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/Driver.java 3d40695 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java 9c8e53e &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/SimpleTotalOrderPartitioner.java af3d588 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java b332280 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java 287cd48 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java 78f3223 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java 7de766d &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java 80bf09a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java c8941f1 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/Bytes.java a53dafe &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java ed8709f &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java d76c75e &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/NMapInputFormat.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java d04ced2 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java f1566d3 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionInfo.java fcb22fb &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java 4595e6e &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java 2e4c7df &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestBytes.java c7361cb &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.hbase.org/r/87/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Primary unit/functional testing, a bit of pseudo-distributed testing. Plan on doing full system tests before commit as well.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Todd&lt;/p&gt;

</comment>
                            <comment id="12873569" author="tlipcon" created="Mon, 31 May 2010 07:29:00 +0000"  >&lt;p&gt;Attaching latest patch. This needs to go on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2588&quot; title=&quot;Add easier way to ship hbase dependencies to MR cluster with job&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2588&quot;&gt;&lt;del&gt;HBASE-2588&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12873695" author="hbasereviewboard" created="Mon, 31 May 2010 16:14:50 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java, line 234&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=612#file612line234&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=612#file612line234&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Why two types?  Is this legacy?  KV has advantage of being able to carry a Delete&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;yea, it&apos;s for compatibility with TableOutputFormat which can take either. Kind of a pain, maybe we should just get rid of it and only accept KV?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Doing both is a pain yes.  If Delete and Put had a common ancestor/Interface, we could use that but it ain&apos;t there yet.  File an issue to undo Put option?&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java, line 73&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=613#file613line73&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=613#file613line73&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     In KV, there is a parseColumns function that might help here&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;doesn&apos;t seem much more convenient (since I already have String here)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;One question, though: if I want to insert into a family that has no qualifiers, should I be using EMPTY_BYTE_ARRAY when I construct the KV, or passing null?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It looks like either works.  It looks like nulls are handled properly.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java, line 96&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=613#file613line96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=613#file613line96&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Is this safe?  Is there escaping you should be handling here?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Plan to address this in docs for importtsv - it&apos;s not a good TSV parser that supports quoting, etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ok&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java, line 229&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=614#file614line229&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=614#file614line229&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     I suppose in rare circumstances, it could split in here and mess you up.  You need a no-split flag per region out in zk or something?  We&apos;d need such a thing for snapshotting methinks.  But, thats for a later...&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;if there&apos;s been a split, the new daughter region will detect that the HFile doesn&apos;t &quot;fit&quot; and throw WrongRegionException. This then triggers the retry on ServerCallable, which fetches the new region info from meta, and realizes it has to split the hfile before trying again.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nice.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java, line 57&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=617#file617line57&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=617#file617line57&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     We need this even though you wrote out partition edges earlier when you read region boundaries?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;You&apos;re right that it&apos;s unused, but I figured I&apos;d put it in for convenience - when doing a bulk load into a new table, for example, you may want to use this in order to figure out where to set region splits.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok.  Sounds good.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-05-28 17:19:22, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1897&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/diff/1/?file=619#file619line1897&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff/1/?file=619#file619line1897&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This is old cruddy stuff you are asking about.  It looks like I added splitsAndClosesLock to stop either happening during critical periods (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-588&quot; title=&quot;Still a &amp;#39;hole&amp;#39; in scanners, even after HBASE-532&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-588&quot;&gt;&lt;del&gt;HBASE-588&lt;/del&gt;&lt;/a&gt;) and the splits lock looks now like a half measure from way back in 2007 &amp;#8211; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-217&quot; title=&quot;[hbase] Fix critical shutdown problem introduced by HADOOP-2338&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-217&quot;&gt;&lt;del&gt;HBASE-217&lt;/del&gt;&lt;/a&gt;.  Lets make an issue to clean it up.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Which one should I be taking? Do I need both? Which order?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Seems like it depends on what you need.  I like your issue on rethinking these locks.  Sounds like we might need to do stuff like break apart the splittingAndClose lock into a splitting and closing.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review96&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12873912" author="hbasereviewboard" created="Tue, 1 Jun 2010 07:36:38 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-06-01 00:33:30.030753)&lt;/p&gt;


&lt;p&gt;Review request for hbase, stack and Jonathan Gray.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;One more day of hacking on this, adds some docs, cleans up the command line parameters, fixes a couple bugs identified in cluster testing.&lt;/p&gt;

&lt;p&gt;Calling this one final, I swear &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I don&apos;t know how to build the forrest docs in trunk, but the new xml file does pass xmllint.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Here&apos;s a first patch that implements bulk import into existing tables. This applies on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2586&quot; title=&quot;Move hbase webapps to an hbase-webapps dir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2586&quot;&gt;&lt;del&gt;HBASE-2586&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2588&quot; title=&quot;Add easier way to ship hbase dependencies to MR cluster with job&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2588&quot;&gt;&lt;del&gt;HBASE-2588&lt;/del&gt;&lt;/a&gt; - I&apos;ve pushed the series of the three to my github: &lt;a href=&quot;http://github.com/toddlipcon/hbase/tree/hfof-review&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/toddlipcon/hbase/tree/hfof-review&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have some TODOs left that I want to take care of before this gets committed, but since it&apos;s a pretty large patch, I figured I&apos;d get it out for review ASAP.&lt;/p&gt;

&lt;p&gt;The stuff in the hadoopbackport package is essentially copypaste from Hadoop trunk, so you can ignore that in the review.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1923&quot; title=&quot;Bulk incremental load into an existing table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1923&quot;&gt;&lt;del&gt;HBASE-1923&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HBASE-1923&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HBASE-1923&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  pom.xml 0a009cf &lt;br/&gt;
  src/docs/src/documentation/content/xdocs/bulk-loads.xml PRE-CREATION &lt;br/&gt;
  src/docs/src/documentation/content/xdocs/site.xml 0d644f5 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HRegionInfo.java 29b0cd6 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/ImmutableBytesWritable.java 0a9ec4b &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java b912a85 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java 4cbe52a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/Driver.java 3d40695 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java 9c8e53e &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/SimpleTotalOrderPartitioner.java af3d588 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java 07d7911 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/InputSampler.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.java PRE-CREATION &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java 287cd48 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java 78f3223 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java 7de766d &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java 80bf09a &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java c8941f1 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/Bytes.java a53dafe &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java ed8709f &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/NMapInputFormat.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java d04ced2 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java PRE-CREATION &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java f1566d3 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionInfo.java fcb22fb &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java 4595e6e &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java 2e4c7df &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestBytes.java c7361cb &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.hbase.org/r/87/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Primary unit/functional testing, a bit of pseudo-distributed testing. Plan on doing full system tests before commit as well.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Todd&lt;/p&gt;

</comment>
                            <comment id="12874215" author="hbasereviewboard" created="Tue, 1 Jun 2010 20:21:38 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review108&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review108&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;p&gt;This is a killer feature.  Ship it.  There is one nitpick in the below but can be done on commit (if its legit)&lt;/p&gt;


&lt;p&gt;src/main/java/org/apache/hadoop/hbase/io/ImmutableBytesWritable.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment658&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    duh&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment659&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment659&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Where is the javadoc that the tsv parse doesn&apos;t do escaping?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment660&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment660&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Good&lt;/p&gt;



&lt;p&gt;src/docs/src/documentation/content/xdocs/bulk-loads.xml&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment655&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment655&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This is excellent.  We do have this though already: &lt;a href=&quot;http://hbase.apache.org/docs/r0.20.4/api/org/apache/hadoop/hbase/mapreduce/package-summary.html#bulk&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/docs/r0.20.4/api/org/apache/hadoop/hbase/mapreduce/package-summary.html#bulk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    We should scrap the above if we&apos;re going to go w/ this or update the former to include this.&lt;/p&gt;



&lt;p&gt;src/docs/src/documentation/content/xdocs/bulk-loads.xml&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment656&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment656&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    method_s_&lt;/p&gt;



&lt;p&gt;src/docs/src/documentation/content/xdocs/bulk-loads.xml&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment657&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment657&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This is a killer feature&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12874260" author="hbasereviewboard" created="Tue, 1 Jun 2010 21:53:39 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/87/#review112&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#review112&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;p&gt;Reviewed changes between v2 and v3.  It looks like they were lost &amp;#8211; some failed communication with the server.  The storefile loading stuff is good.  I like the new Comparator.  Oh, one thing is that we have MD5Hash class now.. maybe your md5&apos;ing could go there.&lt;/p&gt;


&lt;p&gt;src/main/java/org/apache/hadoop/hbase/util/Bytes.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/87/#comment666&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/87/#comment666&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Ignore&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12874330" author="tlipcon" created="Wed, 2 Jun 2010 00:19:12 +0000"  >&lt;p&gt;This should be good to go, just blocked on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2588&quot; title=&quot;Add easier way to ship hbase dependencies to MR cluster with job&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2588&quot;&gt;&lt;del&gt;HBASE-2588&lt;/del&gt;&lt;/a&gt; getting committed.&lt;/p&gt;</comment>
                            <comment id="12874342" author="tlipcon" created="Wed, 2 Jun 2010 00:39:23 +0000"  >&lt;p&gt;Attaching final patch, about to commit.&lt;/p&gt;</comment>
                            <comment id="12874345" author="tlipcon" created="Wed, 2 Jun 2010 00:41:59 +0000"  >&lt;p&gt;Spoke to Ryan offline and he&apos;s OK reviewing this later this week post-commit.&lt;/p&gt;

&lt;p&gt;Committed to trunk. There&apos;s some discussion on the dev list about putting this in branch-20, but will hold off on that until there is some consensus.&lt;/p&gt;

&lt;p&gt;Thanks to all who helped review!&lt;/p&gt;</comment>
                            <comment id="12895900" author="lars_francke" created="Fri, 6 Aug 2010 00:54:29 +0000"  >&lt;p&gt;Can loadtable.rb be removed? As far as I understand it your LoadIncrementalHFiles replaces it completely? If this is the case I&apos;d suggest adding some documentation to that effect. The class leads to believe that it only reads incremental imports while the javadoc seems to be more generic.&lt;/p&gt;</comment>
                            <comment id="12895905" author="tlipcon" created="Fri, 6 Aug 2010 01:09:31 +0000"  >&lt;p&gt;Yea, I think it can be removed &amp;#8211; assuming it still works, we should probably keep it around for one release in case anyone has scripting against it. But, we should add a deprecation warning to its out. What do you think?&lt;/p&gt;</comment>
                            <comment id="12895994" author="lars_francke" created="Fri, 6 Aug 2010 08:53:52 +0000"  >&lt;p&gt;I haven&apos;t tried after your patch but it should probably work in non-incremental mode. I guess that might change after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1861&quot; title=&quot;Multi-Family support for bulk upload tools (HFileOutputFormat / loadtable.rb)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1861&quot;&gt;&lt;del&gt;HBASE-1861&lt;/del&gt;&lt;/a&gt;. Thanks for the clarification.&lt;/p&gt;</comment>
                            <comment id="12895998" author="aaa" created="Fri, 6 Aug 2010 09:06:31 +0000"  >&lt;p&gt;I am out of office on vacation and will be slower than usual in&lt;br/&gt;
responding to emails. If this is urgent then please call my cell phone&lt;br/&gt;
(or send an sms), otherwise I will reply to your email when I get&lt;br/&gt;
back.&lt;/p&gt;

&lt;p&gt;Thanks for your patience,&lt;/p&gt;

&lt;p&gt;&amp;#8211; amr&lt;/p&gt;</comment>
                            <comment id="12896085" author="stack" created="Fri, 6 Aug 2010 16:57:35 +0000"  >&lt;p&gt;IMO, remove it now.  The likelihood of anyone scripting against it is low and I&apos;m pretty sure it pales compared to its replacement.&lt;/p&gt;</comment>
                            <comment id="15017984" author="lars_francke" created="Fri, 20 Nov 2015 13:02:07 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12436435">HBASE-1861</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12465924">HIVE-1383</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12494337">HBASE-3404</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12445140" name="hbase-1923-prelim.txt" size="80442" author="tlipcon" created="Fri, 21 May 2010 08:06:51 +0000"/>
                            <attachment id="12446081" name="hbase-1923.txt" size="164938" author="tlipcon" created="Wed, 2 Jun 2010 00:39:23 +0000"/>
                            <attachment id="12445908" name="hbase-1923.txt" size="148707" author="tlipcon" created="Mon, 31 May 2010 07:29:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 20 May 2010 18:27:37 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32314</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hfvr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99835</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>