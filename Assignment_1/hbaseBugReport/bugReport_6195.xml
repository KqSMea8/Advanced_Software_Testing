<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:34:37 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6195/HBASE-6195.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6195] Increment data will be lost when the memstore is flushed</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6195</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;There are two problems in increment() now:&lt;br/&gt;
First:&lt;br/&gt;
I see that the timestamp(the variable now) in HRegion&apos;s Increment() is generated before got the rowLock, so when there are multi-thread increment the same row, although it generate earlier, it may got the lock later. Because increment just store one version, so till now, the result will still be right.&lt;/p&gt;

&lt;p&gt;When the region is flushing, these increment will read the kv from snapshot and memstore with whose timestamp is larger, and write it back to memstore. If the snapshot&apos;s timestamp larger than the memstore, the increment will got the old data and then do the increment, it&apos;s wrong.&lt;/p&gt;

&lt;p&gt;Secondly:&lt;br/&gt;
Also there is a risk in increment. Because it writes the memstore first and then HLog, so if it writes HLog failed, the client will also read the incremented value.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12560111">HBASE-6195</key>
            <summary>Increment data will be lost when the memstore is flushed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xingshi">ShiXing</assignee>
                                    <reporter username="shixing">ShiXing</reporter>
                        <labels>
                    </labels>
                <created>Mon, 11 Jun 2012 03:00:43 +0000</created>
                <updated>Wed, 4 Dec 2013 17:47:31 +0000</updated>
                            <resolved>Fri, 29 Jun 2012 11:14:06 +0000</resolved>
                                                    <fixVersion>0.94.1</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="13292625" author="shixing" created="Mon, 11 Jun 2012 03:13:38 +0000"  >&lt;p&gt;Here is the data:&lt;br/&gt;
I delete the row first, and then use 2000 threads to increment one row, each increment 1000, after all threads done, I read the increment row&apos;s value, do 11 times.&lt;/p&gt;

&lt;p&gt;for i in `seq 0 10`&lt;br/&gt;
do&lt;br/&gt;
    /home/shubao.sx/hadoop-0.20.2-cdh3u3/bin/hadoop --config /home/shubao.sx/0.90-hadoop-config jar /home/shubao.sx/inc-no-delete/inc.jar com.taobao.hbase.MultiThreadsIncrement --threadNum 2000 --inc 1000 &amp;gt;/home/shubao.sx/inc-no-delete/inc.$i.log&lt;br/&gt;
done&lt;/p&gt;

&lt;p&gt;and the results:&lt;/p&gt;

&lt;p&gt;inc.0.log : return 199838                                                                                                                  &lt;br/&gt;
inc.1.log : return 399729&lt;br/&gt;
inc.2.log : return 599579&lt;br/&gt;
inc.3.log : return 799441&lt;br/&gt;
inc.4.log : return 999305&lt;br/&gt;
inc.5.log : return 1199173&lt;br/&gt;
inc.6.log : return 1399037&lt;br/&gt;
inc.7.log : return 1598939&lt;br/&gt;
inc.8.log : return 1798804&lt;br/&gt;
inc.9.log : return 1998708&lt;br/&gt;
inc.10.log : return 2198637&lt;/p&gt;

&lt;p&gt;Because I set the  hlog&apos;s parameter&lt;br/&gt;
  &amp;lt;property&amp;gt;&lt;br/&gt;
    &amp;lt;name&amp;gt;hbase.regionserver.logroll.multiplier&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;0.005&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;/property&amp;gt;&lt;br/&gt;
  &amp;lt;property&amp;gt;&lt;br/&gt;
    &amp;lt;name&amp;gt;hbase.regionserver.maxlogs&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;so the memstore flush occurs often.&lt;/p&gt;</comment>
                            <comment id="13292626" author="shixing" created="Mon, 11 Jun 2012 03:16:18 +0000"  >&lt;p&gt;Oh sorry, there is no delete in my test case.&lt;/p&gt;</comment>
                            <comment id="13292627" author="shixing" created="Mon, 11 Jun 2012 03:17:48 +0000"  >&lt;p&gt;The patch.&lt;/p&gt;</comment>
                            <comment id="13292634" author="shixing" created="Mon, 11 Jun 2012 04:11:31 +0000"  >&lt;p&gt;The previous patch didn&apos;t mv the now variable into the lock, fix it.&lt;/p&gt;</comment>
                            <comment id="13292825" author="shixing" created="Mon, 11 Jun 2012 14:57:02 +0000"  >&lt;p&gt;I just found that the append interface also has thie problem. May be I should open a new JIRA for it?&lt;/p&gt;</comment>
                            <comment id="13292849" author="zhihyu@ebaysf.com" created="Mon, 11 Jun 2012 15:48:44 +0000"  >&lt;p&gt;@Xing:&lt;br/&gt;
Hadoop QA run wasn&apos;t triggered.&lt;br/&gt;
Can you add a unit test showing this problem and present test suite results ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13292862" author="zhihyu@ebaysf.com" created="Mon, 11 Jun 2012 16:24:36 +0000"  >&lt;p&gt;In patch v3:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; now = EnvironmentEdgeManager.currentTimeMillis();
       &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt; lid = getLock(lockid, row, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Variable now isn&apos;t actually referenced. Do we need it ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-comment&quot;&gt;//store the kvs to the tmp memory &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; write hlog first, then write memory&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above should read: &apos;to temporary memstore before writing HLog&apos;&lt;/p&gt;</comment>
                            <comment id="13293268" author="hadoopqa" created="Tue, 12 Jun 2012 01:51:31 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531685/HBASE-6195-trunk-V3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531685/HBASE-6195-trunk-V3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2138//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13293317" author="shixing" created="Tue, 12 Jun 2012 03:41:58 +0000"  >&lt;p&gt;//In patch v3:&lt;br/&gt;
//+      long now = //EnvironmentEdgeManager.currentTimeMillis();&lt;br/&gt;
//       Integer lid = getLock(lockid, row, true);&lt;br/&gt;
//Variable now isn&apos;t actually referenced. Do we need it ?&lt;/p&gt;

&lt;p&gt;Variable now is used for generate the newKV, V3 generate the Variable also before the lock, V4 fix it.&lt;/p&gt;

&lt;p&gt;//+          //store the kvs to the tmp memory for write hlog first, then write memory&lt;br/&gt;
//The above should read: &apos;to temporary memstore before writing HLog&apos;&lt;/p&gt;

&lt;p&gt;Let me think how to show the problem in UintTest.&lt;/p&gt;</comment>
                            <comment id="13293434" author="hadoopqa" created="Tue, 12 Jun 2012 08:13:26 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531767/HBASE-6195-trunk-V4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531767/HBASE-6195-trunk-V4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2144//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13293458" author="shixing" created="Tue, 12 Jun 2012 09:02:57 +0000"  >&lt;p&gt;add UnitTest for increment&lt;/p&gt;</comment>
                            <comment id="13293629" author="hadoopqa" created="Tue, 12 Jun 2012 13:53:26 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531794/HBASE-6195-trunk-V5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531794/HBASE-6195-trunk-V5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    -1 @author.  The patch appears to contain 1 @author tags which the Hadoop community has agreed to not allow in code contributions.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2148//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13293643" author="shixing" created="Tue, 12 Jun 2012 14:06:58 +0000"  >&lt;p&gt;remove the @author&lt;/p&gt;</comment>
                            <comment id="13293677" author="hadoopqa" created="Tue, 12 Jun 2012 14:58:16 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531834/HBASE-6195-trunk-V6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531834/HBASE-6195-trunk-V6.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestSplitLogManager&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2151//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13293708" author="zhihyu@ebaysf.com" created="Tue, 12 Jun 2012 15:49:32 +0000"  >&lt;p&gt;The new test fails without fix in patch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Failed tests:   testParallelIncrementWithMemStoreFlush(org.apache.hadoop.hbase.regionserver.TestHRegion): expected:&amp;lt;2000&amp;gt; but was:&amp;lt;968&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Will integrate this afternoon if there is no objection.&lt;/p&gt;</comment>
                            <comment id="13293713" author="zhihyu@ebaysf.com" created="Tue, 12 Jun 2012 15:52:17 +0000"  >&lt;p&gt;Modified the test slightly.&lt;br/&gt;
Made Incrementer class private, removed unused variable.&lt;/p&gt;</comment>
                            <comment id="13293759" author="hadoopqa" created="Tue, 12 Jun 2012 16:49:28 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531839/6195-trunk-V7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531839/6195-trunk-V7.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2152//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13293828" author="zhihyu@ebaysf.com" created="Tue, 12 Jun 2012 18:32:44 +0000"  >&lt;p&gt;Integrated to trunk.&lt;/p&gt;

&lt;p&gt;Thanks for the patch, Xing.&lt;/p&gt;</comment>
                            <comment id="13293882" author="hudson" created="Tue, 12 Jun 2012 19:57:01 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3016 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3016/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3016/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; Increment data will be lost when the memstore is flushed (Xing Shi) (Revision 1349471)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13294011" author="hudson" created="Wed, 13 Jun 2012 00:07:15 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #51 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/51/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/51/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; Increment data will be lost when the memstore is flushed (Xing Shi) (Revision 1349471)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13294076" author="shixing" created="Wed, 13 Jun 2012 02:40:30 +0000"  >&lt;p&gt;@Ted&lt;/p&gt;

&lt;p&gt;+  public void testParallelIncrementWithMemStoreFlush() throws Exception {&lt;br/&gt;
+    Configuration conf = HBaseConfiguration.create();&lt;br/&gt;
+    String method = &quot;testParallelismIncrementWithMemStoreFlush&quot;;&lt;br/&gt;
////HERE we should also change the method to &quot;testParallelIncrementWithMemStoreFlush&quot;...&lt;/p&gt;

&lt;p&gt;+    byte[] tableName = Bytes.toBytes(method);&lt;br/&gt;
+    .....&lt;/p&gt;</comment>
                            <comment id="13294091" author="zhihyu@ebaysf.com" created="Wed, 13 Jun 2012 02:52:21 +0000"  >&lt;p&gt;Addendum integrated to trunk.&lt;/p&gt;

&lt;p&gt;Thanks for the reminder, Xing.&lt;/p&gt;</comment>
                            <comment id="13294112" author="hadoopqa" created="Wed, 13 Jun 2012 03:28:38 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12531906/6195.addendum&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12531906/6195.addendum&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2157//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2157//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13294115" author="zhihyu@ebaysf.com" created="Wed, 13 Jun 2012 03:30:19 +0000"  >&lt;p&gt;Patch and addendum integrated to 0.94 as well.&lt;/p&gt;</comment>
                            <comment id="13294126" author="hudson" created="Wed, 13 Jun 2012 03:55:16 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3020 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3020/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3020/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; Addednum changes the method variable to be consistent with test name (Xing Shi) (Revision 1349619)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13294151" author="hudson" created="Wed, 13 Jun 2012 05:00:13 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #256 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/256/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/256/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; Increment data will be lost when the memstore is flushed (Xing Shi) (Revision 1349627)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13294395" author="hudson" created="Wed, 13 Jun 2012 12:04:08 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #52 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/52/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/52/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; Addednum changes the method variable to be consistent with test name (Xing Shi) (Revision 1349619)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13295241" author="stack" created="Thu, 14 Jun 2012 19:05:10 +0000"  >&lt;p&gt;Xing Nice work.  When you run MultiThreadsIncrement w/ your patch in place, do the numbers come out better?&lt;/p&gt;

&lt;p&gt;It looks like this increment was originally added by:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
------------------------------------------------------------------------                                                                                                              
r1027681 | jgray | 2010-10-26 11:50:13 -0700 (Tue, 26 Oct 2010) | 1 line                                                                                                              
                                                                                                                                                                                      
HBASE-2946  Increment multiple columns in a row at once  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is some discussion there that there may be danger around flush time.  Might be useful to review.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2946?focusedCommentId=12924737&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-12924737&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-2946?focusedCommentId=12924737&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-12924737&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In original patch, it has our updating MemStore before we append to WAL.  I seem to recall that there was a reason why we had this unorthodoxy but I am unable to find it now.&lt;/p&gt;

&lt;p&gt;Thanks for fixing this Xing.&lt;/p&gt;

&lt;p&gt;We should backport?&lt;/p&gt;</comment>
                            <comment id="13295356" author="stack" created="Thu, 14 Jun 2012 22:24:36 +0000"  >&lt;p&gt;Ted committed this a few days ago.&lt;/p&gt;</comment>
                            <comment id="13396207" author="zhihyu@ebaysf.com" created="Mon, 18 Jun 2012 20:10:10 +0000"  >&lt;p&gt;In 0.94 build 259, the new test failed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Failed tests:   testParallelIncrementWithMemStoreFlush(org.apache.hadoop.hbase.regionserver.TestHRegion): expected:&amp;lt;2000&amp;gt; but was:&amp;lt;1999&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13397406" author="shixing" created="Wed, 20 Jun 2012 10:21:06 +0000"  >&lt;p&gt;@Ted, I find that if there is no flushcache, there could be three increments in one millisecond(depends on the machine).&lt;/p&gt;

&lt;p&gt;I made all the timestamps (variable now) the same value, to simulate that in the same millisecond, it happends lots of increment.&lt;/p&gt;

&lt;p&gt;Also I start the thread to flushcache. And the test failed:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Results :

Failed tests:   testParallelIncrementWithMemStoreFlush(org.apache.hadoop.hbase.regionserver.TestHRegion): expected:&amp;lt;2000&amp;gt; but was:&amp;lt;146&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Follow is my suspect&#65306;&lt;/p&gt;

&lt;p&gt;Maybe it is because the increment read the old value&#65288;v1&#65289; from snapshot, and write the new value&#65288;v1+1&#65289; to memstore, after this if the flush cache is still not completed, another increment read the value also from snapshot(v1), and write the new value(v1+1) to memstore, so the increment operation takes no effect.&lt;/p&gt;

&lt;p&gt;If the above is right, I think we can read the value from memstore fist for the same timestamp(I didn&apos;t know how to), or make the timestamp to nanoTime to decrease the probability?&lt;/p&gt;
</comment>
                            <comment id="13397696" author="zhihyu@ebaysf.com" created="Wed, 20 Jun 2012 17:58:49 +0000"  >&lt;p&gt;nanoTime is used to calculate duration. It wouldn&apos;t fit the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
            KeyValue newKV = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, family.getKey(), column.getKey(),
                now, Bytes.toBytes(amount));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Store doesn&apos;t provide access to its memstore directly.&lt;/p&gt;</comment>
                            <comment id="13398521" author="shixing" created="Thu, 21 Jun 2012 16:16:24 +0000"  >&lt;p&gt;@Ted,    It&apos;s not because of the snapshot, but the store files.&lt;br/&gt;
When there are serveral same timestamp storefiles, the get will get the row of one of the store files&apos; KeyValue. You can  think that the got KeyValue is almost random between the same timestamp storefiles.&lt;/p&gt;

&lt;p&gt;How to improve it:&lt;br/&gt;
   I make all the timestamps (variable now) of the increment the same value to simulate there are high parallelism. Then  the flushcache after 2 increments and 5 increments, the code like this just in one threads:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void runInOneThread() {
      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; count = 0;
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (count &amp;lt; 10) {
        Increment inc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Increment(incRow);
        inc.addColumn(family, qualifier, ONE);
        count++;
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          region.increment(inc, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
          Get get = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Get(Incrementer.incRow);
          get.addColumn(Incrementer.family, Incrementer.qualifier);
          get.setMaxVersions();
          List&amp;lt;KeyValue&amp;gt; kvs = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.region.get(get, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (KeyValue tmpKv : kvs) {
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : &quot;&lt;/span&gt; + Bytes.toLong(tmpKv.getBuffer(), tmpKv.getValueOffset()) + &lt;span class=&quot;code-quote&quot;&gt;&quot; after &quot;&lt;/span&gt; + count + &lt;span class=&quot;code-quote&quot;&gt;&quot; increment&quot;&lt;/span&gt;);
          }
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (count == 2) {
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;We &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; flush when execute &quot;&lt;/span&gt; + count + &lt;span class=&quot;code-quote&quot;&gt;&quot; increments&quot;&lt;/span&gt;);
            region.flushcache();
          } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (count == 5) {
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;We &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; flush when execute &quot;&lt;/span&gt; + count + &lt;span class=&quot;code-quote&quot;&gt;&quot; increments&quot;&lt;/span&gt;);
            region.flushcache();
          }
        } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Exception e) {
          e.printStackTrace();
          &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
        }
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the print out result is :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 1 after 1 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 2 increment
We &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; flush when execute 2 increments
2012-06-21 23:16:32,847 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1367): Started memstore flush &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; testParallelismIncrementWithMemStoreFlush,,1340291792603.b2a89da7ad8457cab8a1c758c32ed418., current region memstore size 176.0
2012-06-21 23:16:32,848 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1415): Finished snapshotting testParallelismIncrementWithMemStoreFlush,,1340291792603.b2a89da7ad8457cab8a1c758c32ed418., commencing wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; mvcc, flushsize=176
2012-06-21 23:16:32,849 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1425): Finished snapshotting, commencing flushing stores
2012-06-21 23:16:32,859 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] util.FSUtils(149): Creating file:/home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/4382d83027cc48b6b9a3f411157d0749with permission:rwxrwxrwx
2012-06-21 23:16:32,871 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] hfile.HFileWriterV2(141): Initialized with CacheConfig:enabled [cacheDataOnRead=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;] [cacheDataOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheIndexesOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheBloomsOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheEvictOnClose=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheCompressed=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;]
2012-06-21 23:16:32,874 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.StoreFile$Writer(995): Delete Family Bloom filter type &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/4382d83027cc48b6b9a3f411157d0749: CompoundBloomFilterWriter
2012-06-21 23:16:32,880 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.StoreFile$Writer(1218): NO General Bloom and NO DeleteFamily was added to HFile (/home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/4382d83027cc48b6b9a3f411157d0749) 
2012-06-21 23:16:32,880 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.Store(753): Flushed , sequenceid=3, memsize=176.0, into tmp file /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/4382d83027cc48b6b9a3f411157d0749
2012-06-21 23:16:32,905 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.Store(778): Renaming flushed file at /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/4382d83027cc48b6b9a3f411157d0749 to /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/family/4382d83027cc48b6b9a3f411157d0749
2012-06-21 23:16:32,909 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.Store(801): Added /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/family/4382d83027cc48b6b9a3f411157d0749, entries=1, sequenceid=3, filesize=788.0
2012-06-21 23:16:32,910 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1499): Finished memstore flush of ~176.0/176, currentsize=0.0/0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region testParallelismIncrementWithMemStoreFlush,,1340291792603.b2a89da7ad8457cab8a1c758c32ed418. in 63ms, sequenceid=3, compaction requested=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 3 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 4 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 5 increment
We &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; flush when execute 5 increments
2012-06-21 23:16:32,922 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1367): Started memstore flush &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; testParallelismIncrementWithMemStoreFlush,,1340291792603.b2a89da7ad8457cab8a1c758c32ed418., current region memstore size 176.0
2012-06-21 23:16:32,923 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1415): Finished snapshotting testParallelismIncrementWithMemStoreFlush,,1340291792603.b2a89da7ad8457cab8a1c758c32ed418., commencing wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; mvcc, flushsize=176
2012-06-21 23:16:32,923 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1425): Finished snapshotting, commencing flushing stores
2012-06-21 23:16:32,923 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] util.FSUtils(149): Creating file:/home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/a1313e3239e840c7ac9fa9f25387b59fwith permission:rwxrwxrwx
2012-06-21 23:16:32,926 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] hfile.HFileWriterV2(141): Initialized with CacheConfig:enabled [cacheDataOnRead=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;] [cacheDataOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheIndexesOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheBloomsOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheEvictOnClose=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheCompressed=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;]
2012-06-21 23:16:32,926 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.StoreFile$Writer(995): Delete Family Bloom filter type &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/a1313e3239e840c7ac9fa9f25387b59f: CompoundBloomFilterWriter
2012-06-21 23:16:32,927 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.StoreFile$Writer(1218): NO General Bloom and NO DeleteFamily was added to HFile (/home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/a1313e3239e840c7ac9fa9f25387b59f) 
2012-06-21 23:16:32,927 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.Store(753): Flushed , sequenceid=7, memsize=176.0, into tmp file /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/a1313e3239e840c7ac9fa9f25387b59f
2012-06-21 23:16:32,929 DEBUG [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.Store(778): Renaming flushed file at /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/.tmp/a1313e3239e840c7ac9fa9f25387b59f to /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/family/a1313e3239e840c7ac9fa9f25387b59f
2012-06-21 23:16:32,932 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.Store(801): Added /home/shixing/project/0.94.0-ali-1.0/target/test-data/19e96a0f-6721-4fe7-8ede-f5ca359739a0/TestHRegiontestParallelismIncrementWithMemStoreFlush/testParallelismIncrementWithMemStoreFlush/b2a89da7ad8457cab8a1c758c32ed418/family/a1313e3239e840c7ac9fa9f25387b59f, entries=1, sequenceid=7, filesize=788.0
2012-06-21 23:16:32,933 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-3] regionserver.HRegion(1499): Finished memstore flush of ~176.0/176, currentsize=0.0/0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region testParallelismIncrementWithMemStoreFlush,,1340291792603.b2a89da7ad8457cab8a1c758c32ed418. in 11ms, sequenceid=7, compaction requested=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 6 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 7 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 8 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 9 increment
get &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; : 2 after 10 increment
result : 2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In memstore, the value is 3, but the Get doesn&apos;t get it.&lt;/p&gt;

&lt;p&gt;I will also don&apos;t know which KeyValue to choose if they have the same timestamp, like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
           /     |     \   
          /      |      \   
         /       |       \   
        /        |        \   
       /         |         \   
 __________ __________ __________
 |r1|t1|v1| |r1|t1|v2| |r1|t1|v3|
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;v1 or v2 or v3?&lt;/p&gt;

&lt;p&gt;In real scene, the memstore flush will not happend so quickly, and there will be almost no same timestamp KeyValue in increment.&lt;/p&gt;

&lt;p&gt;The different between Put and Increment is that the memstoreTS, in Increment the memstoreTS are always 0, and in Put ,the memstoreTS progressively increases.&lt;/p&gt;</comment>
                            <comment id="13398547" author="zhihyu@ebaysf.com" created="Thu, 21 Jun 2012 16:30:47 +0000"  >&lt;p&gt;Thanks for the analysis.&lt;br/&gt;
In reality, we can consider this issue fixed.&lt;/p&gt;

&lt;p&gt;Will resolve again if there is no objection.&lt;/p&gt;</comment>
                            <comment id="13398725" author="ram_krish" created="Thu, 21 Jun 2012 18:37:53 +0000"  >&lt;p&gt;@Xing&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-comment&quot;&gt;// Negate &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; comparison so later edits show up first
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -Longs.compare(left.getMemstoreTS(), right.getMemstoreTS());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You mean this gives 0 as the memStoreTS is zero, right?&lt;/p&gt;</comment>
                            <comment id="13400033" author="hudson" created="Sat, 23 Jun 2012 18:23:14 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #37 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/37/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/37/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; Increment data will be lost when the memstore is flushed (Xing Shi) (Revision 1349627)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13400505" author="shixing" created="Mon, 25 Jun 2012 14:33:45 +0000"  >&lt;p&gt;@Ted and @ram:&lt;br/&gt;
This problem will simply occur when one KeyValue have same row, family, qualifier, timestamp and different memstoreTS.&lt;/p&gt;

&lt;p&gt;There are losts of optimisation for memstoreTS for storage:&lt;/p&gt;

&lt;p&gt;1. The flush will set memstoreTS to 0 not just Increment but Put, code in Store.internalFlushCache():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (kv.getMemstoreTS() &amp;lt;= smallestReadPoint) {
    &lt;span class=&quot;code-comment&quot;&gt;// let us not change the original KV. It could be in the memstore
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// changing its memstoreTS could affect other threads/scanners.
&lt;/span&gt;    kv = kv.shallowCopy();
    kv.setMemstoreTS(0);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If the versions of the same row with same TimeStamp flushed to StoreFiles, the get will choose the latest version by&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Negate &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; comparison so later edits show up first
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -Longs.compare(left.getMemstoreTS(), right.getMemstoreTS());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Because the TimeStamps(in one millionsecond) and memstoreTSs are all the same(0) in StoreFiles, so we didn&apos;t know which one is the newest.&lt;/p&gt;

&lt;p&gt;2. Besides this, in StoreFileScanner, there is an optimisation in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4346&quot; title=&quot;Optimise the storage that we use for storing MVCC information.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4346&quot;&gt;&lt;del&gt;HBASE-4346&lt;/del&gt;&lt;/a&gt;(code through &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2856&quot; title=&quot;TestAcidGuarantee broken on trunk &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2856&quot;&gt;&lt;del&gt;HBASE-2856&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (cur.getMemstoreTS() &amp;lt;= readPoint) {
      cur.setMemstoreTS(0);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, even though we set memstoreTS progressively increases when Increment(memstoreTS will always 0) or Put, if we flushed two records(all the same excepts memstoreTS, sf1.row.memstoreTS &amp;lt; sf2.row.memstoreTS) into two StoreFiles. The memstoreTSs will also be set to 0, and we may got the old record sf1.row&lt;/p&gt;


&lt;p&gt;3. Why I can&apos;t get all the records for different memstoreTS?&lt;br/&gt;
In the Scanner, the ExplicitColumnTracker will be used for tracking. And there are such code in ExplicitColumnTracker.checkColumn():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-comment&quot;&gt;//If column matches, check &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; it is a duplicate timestamp
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (sameAsPreviousTS(timestamp)) {
    &lt;span class=&quot;code-comment&quot;&gt;//If duplicate, skip &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; Key
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ScanQueryMatcher.MatchCode.SKIP;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So the Get returns just one result although they are different for memstoreTS.&lt;/p&gt;

&lt;p&gt;4. How to resolve this?&lt;br/&gt;
There are some optimization through the memstoreTS makes the solution complex, I still don&apos;t find a solution for this problem and still thinking how to, may be remove some optimization.&lt;/p&gt;</comment>
                            <comment id="13401267" author="xingshi" created="Tue, 26 Jun 2012 09:24:05 +0000"  >&lt;p&gt;I find that the problem is introduced by the lazyseek. I have open a jira  for this problem &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6269&quot; title=&quot;Lazyseek should use the maxSequenseId StoreFile&amp;#39;s KeyValue as the latest KeyValue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6269&quot;&gt;&lt;del&gt;HBASE-6269&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13403788" author="anoopsamjohn" created="Fri, 29 Jun 2012 09:04:40 +0000"  >&lt;p&gt;As &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6269&quot; title=&quot;Lazyseek should use the maxSequenseId StoreFile&amp;#39;s KeyValue as the latest KeyValue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6269&quot;&gt;&lt;del&gt;HBASE-6269&lt;/del&gt;&lt;/a&gt; is committed now, we can close this issue right?&lt;/p&gt;</comment>
                            <comment id="13403811" author="xingshi" created="Fri, 29 Jun 2012 10:09:53 +0000"  >&lt;p&gt;yes, I think so.&lt;/p&gt;</comment>
                            <comment id="13403836" author="ram_krish" created="Fri, 29 Jun 2012 11:14:06 +0000"  >&lt;p&gt;Resolving as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6269&quot; title=&quot;Lazyseek should use the maxSequenseId StoreFile&amp;#39;s KeyValue as the latest KeyValue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6269&quot;&gt;&lt;del&gt;HBASE-6269&lt;/del&gt;&lt;/a&gt; got committed.&lt;/p&gt;</comment>
                            <comment id="13405799" author="hudson" created="Tue, 3 Jul 2012 10:55:36 +0000"  >&lt;p&gt;Integrated in HBase-0.92 #465 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92/465/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92/465/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6297&quot; title=&quot;Backport HBASE-6195 to 0.92&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6297&quot;&gt;&lt;del&gt;HBASE-6297&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6195&quot; title=&quot;Increment data will be lost when the memstore is flushed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6195&quot;&gt;&lt;del&gt;HBASE-6195&lt;/del&gt;&lt;/a&gt; to 0.92 (Ram)&lt;/p&gt;

&lt;p&gt;Submitted by:Ram	&lt;br/&gt;
Reviewed by:Stack (Revision 1356381)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
ramkrishna : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13444561" author="jmhsieh" created="Thu, 30 Aug 2012 00:11:12 +0000"  >&lt;p&gt;Oops, accidentally change assingee &amp;#8211; fixed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12560183">HBASE-6197</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12595882">HBASE-6269</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12682715">HBASE-10079</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12531839" name="6195-trunk-V7.patch" size="6769" author="zhihyu@ebaysf.com" created="Tue, 12 Jun 2012 15:52:17 +0000"/>
                            <attachment id="12531906" name="6195.addendum" size="803" author="zhihyu@ebaysf.com" created="Wed, 13 Jun 2012 02:49:36 +0000"/>
                            <attachment id="12531629" name="HBASE-6195-trunk-V2.patch" size="2972" author="shixing" created="Mon, 11 Jun 2012 04:11:31 +0000"/>
                            <attachment id="12531685" name="HBASE-6195-trunk-V3.patch" size="2980" author="shixing" created="Mon, 11 Jun 2012 15:49:14 +0000"/>
                            <attachment id="12531767" name="HBASE-6195-trunk-V4.patch" size="2971" author="shixing" created="Tue, 12 Jun 2012 03:41:58 +0000"/>
                            <attachment id="12531794" name="HBASE-6195-trunk-V5.patch" size="6849" author="shixing" created="Tue, 12 Jun 2012 09:02:57 +0000"/>
                            <attachment id="12531834" name="HBASE-6195-trunk-V6.patch" size="6793" author="shixing" created="Tue, 12 Jun 2012 14:06:58 +0000"/>
                            <attachment id="12531627" name="HBASE-6195-trunk.patch" size="2263" author="shixing" created="Mon, 11 Jun 2012 03:17:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 11 Jun 2012 15:48:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>245377</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 16 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0685b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34251</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>