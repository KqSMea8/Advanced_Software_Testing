<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:06:16 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9644/HBASE-9644.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9644] Regionserver throws java.lang.NoClassDefFoundError: Ljava/lang/InternalError exception while decompressing hfileblock</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9644</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Regionserver threw a &quot;java.lang.NoClassDefFoundError: Ljava/lang/InternalError&quot; Exception when it decompressed a hfileblock. &lt;/p&gt;

&lt;p&gt;The exception detail is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 
2013-09-15 05:44:03,612 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.lang.NoClassDefFoundError: Ljava/lang/InternalError
        at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
        at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:238)
        at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:87)
        at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:83)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:192)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.decompress(HFileBlock.java:1461)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1890)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1703)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:342)
        at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.loadDataBlockWithScanInfo(HFileBlockIndex.java:254)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:484)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:505)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:220)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:140)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.&amp;lt;init&amp;gt;(StoreScanner.java:131)
        at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:2208)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&amp;lt;init&amp;gt;(HRegion.java:3807)
        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1825)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1817)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1794)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4828)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4802)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:2196)
        at sun.reflect.GeneratedMethodAccessor48.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:320)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1426)
Caused by: java.lang.ClassNotFoundException: Ljava.lang.InternalError
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        ... 30 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
&lt;p&gt;There are two problems here:&lt;br/&gt;
1. Why use the class name &apos;Ljava/lang/InternalError&apos; instead of &apos;java/lang/InternalError&apos; in Snappy library?&lt;br/&gt;
This involves the code of snappy lib, maybe there is a bug in it.&lt;/p&gt;

&lt;p&gt;2. When I tried to read the hfileblock using HDFS tools, it told me that the local hfileblock didn&apos;t pass the file checksum and read another replica from remote datanode. Then here is the question, why hbase checksum cannot find this problem while hdfs can?&lt;/p&gt;

&lt;p&gt;This is my hbase-site.xml configure for checksum:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.client.read.shortcircuit&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;

  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.client.read.shortcircuit.skip.checksum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;

  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regionserver.checksum.verify&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; </description>
                <environment>&lt;p&gt;Linux 2.6.32-el5.x86_64&lt;/p&gt;</environment>
        <key id="12670237">HBASE-9644</key>
            <summary>Regionserver throws java.lang.NoClassDefFoundError: Ljava/lang/InternalError exception while decompressing hfileblock</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="victorunique">Victor Xu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Sep 2013 09:50:56 +0000</created>
                <updated>Wed, 25 Sep 2013 02:52:34 +0000</updated>
                                            <version>0.94.10</version>
                                                    <component>HFile</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13776171" author="xieliang007" created="Tue, 24 Sep 2013 10:21:03 +0000"  >&lt;p&gt;The &quot;L&quot; of  &quot;Ljava/lang/InternalError&quot; means &quot;class or interface&quot;, it&apos;s a type signature, not related with snappy&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13776176" author="xieliang007" created="Tue, 24 Sep 2013 10:27:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;&quot;why hbase checksum cannot find this problem while hdfs can?&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;IIRC, it has a fall back mechanism in hbase&apos;s checksum impl, that means if failed in hbase, and will resort to hdfs&apos;s checksum, but it should be able to print some warning log, probably need to double-check the log code. btw, you never saw any weird checksum log in hbase&apos;s logfile, right?&lt;/p&gt;</comment>
                            <comment id="13776182" author="victorunique" created="Tue, 24 Sep 2013 10:35:15 +0000"  >&lt;p&gt;Yes, there&apos;s no other warning in hbase&apos;s log, the hfileblock went directly into the decompress logic.&lt;/p&gt;</comment>
                            <comment id="13776235" author="victorunique" created="Tue, 24 Sep 2013 11:58:13 +0000"  >&lt;p&gt;HBase does have a fall back mechanism to double check the hfileblock&apos;s checksum. However, in this case, it passed the first hbase checksum and then skipped the second hdfs checksum. As a result, exception was thrown in the decompress logic. &lt;br/&gt;
So my temporary solution to this problem is to add try-catch code to deal with the exception, and return null if it happened, in order to trigger the hdfs checksum mechanism.&lt;br/&gt;
It may take too much time to find the real cause of this problem in hbase checksum mechanism.&lt;/p&gt;</comment>
                            <comment id="13777086" author="xieliang007" created="Wed, 25 Sep 2013 02:48:16 +0000"  >&lt;p&gt;If there&apos;re sth wrong with checksum, that definitely you should see log stuff like at least one of following:&lt;br/&gt;
HBase checksum verification failed&lt;br/&gt;
HDFS checksum verification suceeded&lt;/p&gt;</comment>
                            <comment id="13777087" author="xieliang007" created="Wed, 25 Sep 2013 02:48:25 +0000"  >&lt;p&gt;readBlockData failed, possibly due to&lt;/p&gt;</comment>
                            <comment id="13777090" author="xieliang007" created="Wed, 25 Sep 2013 02:52:34 +0000"  >&lt;p&gt;another possible guess is: it&apos;s a &quot;get&quot; request, and only the related data/index block were loaded on-damond, so the bad hdfs block was not be request from hbase side, but using HDFS tools, it&apos;s definitely will be checked&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 24 Sep 2013 10:21:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>350066</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 12 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ocyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>350360</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>