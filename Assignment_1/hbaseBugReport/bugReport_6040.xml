<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:33:14 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6040/HBASE-6040.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6040] Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6040</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;When the data is bulk loaded using HFileOutputFormat, we are not using the block encoding and the HBase handled checksum features..  When the writer is created for making the HFile, I am not seeing any such info passing to the WriterBuilder.&lt;br/&gt;
In HFileOutputFormat.getNewWriter(byte[] family, Configuration conf), we dont have these info and do not pass also to the writer... So those HFiles will not have these optimizations..&lt;/p&gt;

&lt;p&gt;Later in LoadIncrementalHFiles.copyHFileHalf(), where we physically divide one HFile(created by the MR) iff it can not belong to just one region, I can see we pass the datablock encoding details and checksum details to the new HFile writer. But this step wont happen normally I think..&lt;/p&gt;</description>
                <environment></environment>
        <key id="12556287">HBASE-6040</key>
            <summary>Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="anoopsamjohn">Anoop Sam John</assignee>
                                    <reporter username="anoopsamjohn">Anoop Sam John</reporter>
                        <labels>
                    </labels>
                <created>Thu, 17 May 2012 19:44:30 +0000</created>
                <updated>Fri, 12 Oct 2012 05:36:28 +0000</updated>
                            <resolved>Thu, 31 May 2012 04:27:33 +0000</resolved>
                                    <version>0.94.0</version>
                    <version>0.95.2</version>
                                    <fixVersion>0.94.1</fixVersion>
                                    <component>mapreduce</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="13278162" author="anoopsamjohn" created="Thu, 17 May 2012 19:47:29 +0000"  >&lt;p&gt;Will upload a patch tomorrow. Need to test in cluster..&lt;/p&gt;</comment>
                            <comment id="13284190" author="anoopsamjohn" created="Sun, 27 May 2012 17:52:04 +0000"  >&lt;p&gt;Patch prepared for 0.94&lt;/p&gt;</comment>
                            <comment id="13284226" author="zhihyu@ebaysf.com" created="Sun, 27 May 2012 20:39:59 +0000"  >&lt;p&gt;TestHFileOutputFormat passed with the patch.&lt;br/&gt;
+1 from me.&lt;/p&gt;

&lt;p&gt;Running through test suite is desirable.&lt;/p&gt;</comment>
                            <comment id="13286100" author="stack" created="Wed, 30 May 2012 21:48:39 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Make a trunk patch Anoop and submit it to hadoopqa?&lt;/p&gt;</comment>
                            <comment id="13286287" author="anoopsamjohn" created="Thu, 31 May 2012 03:18:42 +0000"  >&lt;p&gt;Patch for trunk&lt;/p&gt;</comment>
                            <comment id="13286300" author="hadoopqa" created="Thu, 31 May 2012 04:13:40 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12530320/HBASE-6040_Trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12530320/HBASE-6040_Trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to cause Findbugs (version 1.3.9) to fail.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2069//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2069//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2069//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2069//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13286308" author="stack" created="Thu, 31 May 2012 04:27:33 +0000"  >&lt;p&gt;Applied to 0.94 branch and to trunk.  Thanks for the patch Anoop.&lt;/p&gt;</comment>
                            <comment id="13286352" author="hudson" created="Thu, 31 May 2012 05:56:11 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #239 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/239/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/239/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6040&quot; title=&quot;Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6040&quot;&gt;&lt;del&gt;HBASE-6040&lt;/del&gt;&lt;/a&gt; Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat (Revision 1344561)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13286374" author="hudson" created="Thu, 31 May 2012 06:51:50 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2962 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2962/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2962/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6040&quot; title=&quot;Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6040&quot;&gt;&lt;del&gt;HBASE-6040&lt;/del&gt;&lt;/a&gt; Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat (Revision 1344560)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13286510" author="hudson" created="Thu, 31 May 2012 11:59:00 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #34 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/34/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/34/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6040&quot; title=&quot;Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6040&quot;&gt;&lt;del&gt;HBASE-6040&lt;/del&gt;&lt;/a&gt; Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat (Revision 1344560)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13287174" author="hudson" created="Fri, 1 Jun 2012 05:42:55 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #33 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/33/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/33/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6040&quot; title=&quot;Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6040&quot;&gt;&lt;del&gt;HBASE-6040&lt;/del&gt;&lt;/a&gt; Use block encoding and HBase handled checksum verification in bulk loading using HFileOutputFormat (Revision 1344561)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13289334" author="gopinathan.av" created="Tue, 5 Jun 2012 11:16:07 +0000"  >&lt;p&gt;Need to take care some more things for block encoding in case bulk load. &lt;/p&gt;

&lt;p&gt;Getting following exception while scanning the table. &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2012-06-05 15:39:24,771 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Failed openScanner
java.lang.AssertionError: Expected on-disk data block encoding NONE, got PREFIX
	at org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.diskToCacheFormat(HFileDataBlockEncoderImpl.java:151)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:329)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.seekTo(HFileReaderV2.java:951)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:229)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.&amp;lt;init&amp;gt;(StoreScanner.java:130)
	at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:2044)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&amp;lt;init&amp;gt;(HRegion.java:3307)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1630)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1622)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1598)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:2317)
	at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also better to support BloomFilter in bulkload.&lt;/p&gt;</comment>
                            <comment id="13289338" author="ram_krish" created="Tue, 5 Jun 2012 11:26:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3776&quot; title=&quot;Add Bloom Filter Support to HFileOutputFormat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3776&quot;&gt;&lt;del&gt;HBASE-3776&lt;/del&gt;&lt;/a&gt; is still open for supporting bloom filter on bulkload.&lt;/p&gt;</comment>
                            <comment id="13289341" author="anoopsamjohn" created="Tue, 5 Jun 2012 11:28:13 +0000"  >&lt;p&gt;Oh sorry.. I missed that part.&lt;br/&gt;
It is regarding the HFileDataBlockEncoder#saveMetadata(StoreFile.Writer storeFileWriter)&lt;br/&gt;
In bulk load we deal with HFileWriter directly , not through StoreFileWriter.&lt;br/&gt;
The above call of saveMetadata() is happening from StoreFile.Writer#close() only.&lt;br/&gt;
This call saveMetadata() only writes the encoder type into fileinfo&lt;/p&gt;


&lt;p&gt;We might need to explicitly write this fileInfo from HFileOutputFormat.&lt;br/&gt;
HFileDataBlockEncoder#saveMetadata(StoreFile.Writer storeFileWriter)not sure why this takes StoreFile.Writer rather than HFile.Writer&lt;br/&gt;
Other methods in this interface deals with HFile or HFile blocks.&lt;/p&gt;

&lt;p&gt;@Stack I will reopen this JIRA?&lt;/p&gt;

&lt;p&gt;Thanks Gopi for noticing this and raising.  Regarding the point abt usage of bloom we will track through other ticket (If ok)&lt;/p&gt;</comment>
                            <comment id="13289346" author="anoopsamjohn" created="Tue, 5 Jun 2012 11:36:19 +0000"  >&lt;p&gt;HFileDataBlockEncoder is a private interface. Can we change the signature?&lt;/p&gt;

&lt;p&gt;HFileDataBlockEncoder#saveMetadata(StoreFile.Writer storeFileWriter)&lt;/p&gt;</comment>
                            <comment id="13289353" author="anoopsamjohn" created="Tue, 5 Jun 2012 11:50:00 +0000"  >&lt;p&gt;HFileDataBlockEncoder interface usage is mainly at the HFile.Writer level.  Why this saveMetadata() we are making from the StoreFile.Writer?&lt;br/&gt;
I feel it is better to be moved to close() in HFile.Writer&lt;br/&gt;
Any way the signature change would be needed here also.&lt;/p&gt;

&lt;p&gt;Note: Handling of bloom we are doing fully at the StoreFile level.&lt;/p&gt;</comment>
                            <comment id="13289625" author="stack" created="Tue, 5 Jun 2012 18:28:31 +0000"  >&lt;p&gt;Make a new one at this stage I&apos;d suggest Anoop; this one has been closed for &amp;gt; a day or so.  Thanks.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I feel it is better to be moved to close() in HFile.Writer&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok.&lt;/p&gt;

&lt;p&gt;StoreFile is a wrapper around hfile to add &apos;hbase&apos; stuff (we have tried to keep hfile &apos;pure&apos;, unpolluted by hbase-isms... I don&apos;t think we succeeded but that was the idea).&lt;/p&gt;</comment>
                            <comment id="13289633" author="anoopsamjohn" created="Tue, 5 Jun 2012 18:38:20 +0000"  >&lt;p&gt;Thanks Stack. &lt;br/&gt;
Created new bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6164&quot; title=&quot;Correct the bug in block encoding usage in bulkload&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6164&quot;&gt;&lt;del&gt;HBASE-6164&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12608728">HBASE-6868</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12559428">HBASE-6164</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12529898" name="HBASE-6040_94.patch" size="2997" author="anoopsamjohn" created="Sun, 27 May 2012 17:52:04 +0000"/>
                            <attachment id="12530320" name="HBASE-6040_Trunk.patch" size="3130" author="anoopsamjohn" created="Thu, 31 May 2012 03:18:42 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 27 May 2012 20:39:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>247878</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 28 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08rw7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>49119</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Added a new config param &amp;quot;hbase.mapreduce.hfileoutputformat.datablock.encoding&amp;quot; using which we can specify which encoding scheme to be used on disk. Data will get written in to HFiles using this encoding scheme while bulk load. The value of this can be NONE, PREFIX, DIFF, FAST_DIFF as these are the DataBlockEncoding types supported now. [When any new types are added later, corresponding names also will become valid]&lt;br/&gt;
The checksum type and number of bytes per checksum can be configured using the config params hbase.hstore.checksum.algorithm, hbase.hstore.bytes.per.checksum respectively&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>bulkload</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>