<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:56:54 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8615/HBASE-8615.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8615] HLog Compression may fail due to Hadoop fs input stream returning partial bytes</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8615</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;In a recent test run, I noticed the following in test output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-05-24 22:01:02,424 DEBUG [RegionServer:0;kiyo.gq1.ygridcore.net,42690,1369432806911.replicationSource,2] fs.HFileSystem$ReorderWALBlocks(327): /user/hortonzy/hbase/.logs/kiyo.gq1.ygridcore.net,42690,1369432806911/kiyo.gq1.ygridcore.net%2C42690%2C1369432806911.1369432840428 is an HLog file, so reordering blocks, last hostname will be:kiyo.gq1.ygridcore.net
2013-05-24 22:01:02,429 DEBUG [RegionServer:0;kiyo.gq1.ygridcore.net,42690,1369432806911.replicationSource,2] wal.ProtobufLogReader(118): After reading the trailer: walEditsStopOffset: 132235, fileLength: 132243, trailerPresent: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
2013-05-24 22:01:02,438 ERROR [RegionServer:0;kiyo.gq1.ygridcore.net,42690,1369432806911.replicationSource,2] wal.ProtobufLogReader(236): Error  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; reading 691 WAL KVs; started reading at 53272 and read up to 65538
2013-05-24 22:01:02,438 WARN  [RegionServer:0;kiyo.gq1.ygridcore.net,42690,1369432806911.replicationSource,2] regionserver.ReplicationSource(324): 2 Got:
java.io.IOException: Error  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; reading 691 WAL KVs; started reading at 53272 and read up to 65538
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:237)
        at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:96)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.readNextAndSetPosition(ReplicationHLogReaderManager.java:89)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.readAllEntriesToReplicateOrNextFile(ReplicationSource.java:404)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:320)
Caused by: java.lang.IndexOutOfBoundsException: index (30062) must be less than size (1)
        at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:305)
        at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:284)
        at org.apache.hadoop.hbase.regionserver.wal.LRUDictionary$BidirectionalLRUMap.get(LRUDictionary.java:124)
        at org.apache.hadoop.hbase.regionserver.wal.LRUDictionary$BidirectionalLRUMap.access$000(LRUDictionary.java:71)
        at org.apache.hadoop.hbase.regionserver.wal.LRUDictionary.getEntry(LRUDictionary.java:42)
        at org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvDecoder.readIntoArray(WALCellCodec.java:210)
        at org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvDecoder.parseCell(WALCellCodec.java:184)
        at org.apache.hadoop.hbase.codec.BaseDecoder.advance(BaseDecoder.java:46)
        at org.apache.hadoop.hbase.regionserver.wal.WALEdit.readFromCells(WALEdit.java:213)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:217)
        ... 4 more
2013-05-24 22:01:02,439 DEBUG [RegionServer:0;kiyo.gq1.ygridcore.net,42690,1369432806911.replicationSource,2] regionserver.ReplicationSource(583): Nothing to replicate, sleeping 100 times 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Will attach test output.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649409">HBASE-8615</key>
            <summary>HLog Compression may fail due to Hadoop fs input stream returning partial bytes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yuzhihong@gmail.com">Ted Yu</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 May 2013 22:23:39 +0000</created>
                <updated>Mon, 23 Sep 2013 19:22:23 +0000</updated>
                            <resolved>Fri, 9 Aug 2013 23:13:27 +0000</resolved>
                                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.95.2</fixVersion>
                                    <component>Replication</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13720035" author="jdcryans" created="Thu, 25 Jul 2013 20:47:03 +0000"  >&lt;p&gt;Assigning to me, it failed again in this build:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/421/testReport/junit/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/org.apache.hbase$hbase-server/421/testReport/junit/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I tried to repro on Hadoop 1 and I&apos;m not successful. Even tho it shouldn&apos;t matter, I&apos;ll give it a shot on Hadoop 2.&lt;/p&gt;

&lt;p&gt;The cause for this issue is that there&apos;s seems to be one case where we clean the compression context in the middle of reading a file.&lt;/p&gt;</comment>
                            <comment id="13720986" author="stack" created="Fri, 26 Jul 2013 17:45:01 +0000"  >&lt;p&gt;In case this is of help &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt;, fail on different jenkins: &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/195/testReport/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/195/testReport/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13721475" author="stack" created="Sat, 27 Jul 2013 01:29:08 +0000"  >&lt;p&gt;More &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/196/testReport/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/196/testReport/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m removing this test for now.  JD is gone for the w/e and I want the tests to pass meantime.&lt;/p&gt;</comment>
                            <comment id="13721477" author="stack" created="Sat, 27 Jul 2013 01:31:37 +0000"  >&lt;p&gt;Ugh.  Let me see if it fails more.  Will remove it then.&lt;/p&gt;</comment>
                            <comment id="13721766" author="stack" created="Sat, 27 Jul 2013 21:29:00 +0000"  >&lt;p&gt;Failed again here &lt;a href=&quot;https://builds.apache.org/view/H-L/view/HBase/job/hbase-0.95-on-hadoop2/199/testReport/junit/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/view/H-L/view/HBase/job/hbase-0.95-on-hadoop2/199/testReport/junit/org.apache.hadoop.hbase.replication/TestReplicationKillMasterRSCompressed/killOneMasterRS/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I removed this suite of tests &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9062&quot; title=&quot;Remove TestReplicationKillRs* tests temporarily&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9062&quot;&gt;&lt;del&gt;HBASE-9062&lt;/del&gt;&lt;/a&gt; till &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt; says he wants to have them in the mix again &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13722807" author="jdcryans" created="Mon, 29 Jul 2013 18:39:55 +0000"  >&lt;p&gt;It&apos;s just the compression test that fails FWIW, so it seems that something is broken in HLog compression or the way we read them.&lt;/p&gt;</comment>
                            <comment id="13724624" author="jdcryans" created="Tue, 30 Jul 2013 23:48:59 +0000"  >&lt;p&gt;Interestingly this doesn&apos;t happen just on Hadoop 2.0, it&apos;s just that it&apos;s much less likely to happen on Hadoop 1. I have a small unit test that can recreate the problem and it requires inserting 3x more data in Hadoop 1 to see it fail consistently.&lt;/p&gt;

&lt;p&gt;Now I gotta dig deeper...&lt;/p&gt;</comment>
                            <comment id="13726711" author="jdcryans" created="Thu, 1 Aug 2013 18:27:15 +0000"  >&lt;p&gt;Here&apos;s what I know about the different problems.&lt;/p&gt;

&lt;p&gt;The first one is that we find data in the compressed HLog that&apos;s unexpected. It happens easily on Hadoop 2 and takes more data to hit on Hadoop 1. It manifests itself as show in the jira&apos;s description or like this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-07-27 15:17:54,789 ERROR [RS:1;vesta:34230.replicationSource,2] wal.ProtobufLogReader(236): Error  while reading 4 WAL KVs; started reading at 65475 and read up to 65541
2013-07-27 15:17:54,790 WARN  [RS:1;vesta:34230.replicationSource,2] regionserver.ReplicationSource(323): 2 Got: 
java.io.IOException: Error  while reading 4 WAL KVs; started reading at 65475 and read up to 65541
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:237)
	at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:96)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.readNextAndSetPosition(ReplicationHLogReaderManager.java:89)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.readAllEntriesToReplicateOrNextFile(ReplicationSource.java:407)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:319)
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:76)
	at org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$StreamUtils.toShort(WALCellCodec.java:353)
	at org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvDecoder.readIntoArray(WALCellCodec.java:237)
	at org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvDecoder.parseCell(WALCellCodec.java:206)
	at org.apache.hadoop.hbase.codec.BaseDecoder.advance(BaseDecoder.java:46)
	at org.apache.hadoop.hbase.regionserver.wal.WALEdit.readFromCells(WALEdit.java:213)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:217)
	... 4 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One thing I saw is that it always happens when we&apos;re close to a multiple of Short.MAX_VALUE. In the stack trace I just pasted you can see it started reading at 65475 and in the jira&apos;s description it was ending at 65538.&lt;/p&gt;

&lt;p&gt;I&apos;m able to recreate the problem with at patch to TestReplicationHLogReaderManager that I&apos;m going to attach later. I also was able to recreate the problem on a single node cluster and was able to grab a &quot;corrupted&quot; HLog that will also be attached.&lt;/p&gt;

&lt;p&gt;The other problem I found is that when appending WALEdits with only 1 KV to a compressed HLog, it hits an invalid PB:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-07-31 11:38:52,156 ERROR [main] wal.ProtobufLogReader(199):
Invalid PB while reading WAL, probably an unexpected EOF, ignoring
com.google.protobuf.InvalidProtocolBufferException: Protocol message
contained an invalid tag (zero).
        at com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:68)
        at com.google.protobuf.CodedInputStream.readTag(CodedInputStream.java:108)
        at org.apache.hadoop.hbase.protobuf.generated.WALProtos$WALKey$Builder.mergeFrom(WALProtos.java:1120)
        at org.apache.hadoop.hbase.protobuf.generated.WALProtos$WALKey$Builder.mergeFrom(WALProtos.java:885)
        at com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:212)
        at com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:746)
        at com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:238)
        at com.google.protobuf.AbstractMessageLite$Builder.mergeDelimitedFrom(AbstractMessageLite.java:282)
        at com.google.protobuf.AbstractMessage$Builder.mergeDelimitedFrom(AbstractMessage.java:760)
        at com.google.protobuf.AbstractMessageLite$Builder.mergeDelimitedFrom(AbstractMessageLite.java:288)
        at com.google.protobuf.AbstractMessage$Builder.mergeDelimitedFrom(AbstractMessage.java:752)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:197)
        at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:96)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Printing the position when it fails I can see it&apos;s still around a multiple of Short.MAX_VALUE, and using the unit test I attached you can reliably get the issue after reading the same number of edits. I wasn&apos;t able to trigger the issue in Hadoop 1 unfortunately, but it seems related.&lt;/p&gt;</comment>
                            <comment id="13727139" author="jdcryans" created="Fri, 2 Aug 2013 00:13:49 +0000"  >&lt;p&gt;Attaching two files.&lt;/p&gt;

&lt;p&gt;The first one is a patch for TestReplicationHLogReaderManager that shows how to trigger the two issues I was talking about in the previous comment. Change a few numbers according to the code comments I left and you&apos;re good to go.&lt;/p&gt;

&lt;p&gt;The second file is a &quot;corrupted&quot; HLog (I&apos;m not sure if it&apos;s really a bad log or it just triggers something bad on the read path). Use the &quot;bin/hbase hlog&quot; tool to read it and don&apos;t forget to set hbase.regionserver.wal.enablecompression to true since it&apos;s a compressed HLog.&lt;/p&gt;</comment>
                            <comment id="13727818" author="jdcryans" created="Fri, 2 Aug 2013 17:15:06 +0000"  >&lt;p&gt;Pushing to 0.96.0, won&apos;t be fixed in time for 0.95.2, so it means that HLog compression is broken and cannot be used.&lt;/p&gt;</comment>
                            <comment id="13732832" author="sershe" created="Wed, 7 Aug 2013 22:17:56 +0000"  >&lt;p&gt;Could it be similar issue to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8498&quot; title=&quot;PB WAL reading is broken due to some partial reads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8498&quot;&gt;&lt;del&gt;HBASE-8498&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The cause for this issue is that there&apos;s seems to be one case where we clean the compression context in the middle of reading a file&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Is this a statement based on observation (then it would invalidate my comment)?&lt;/p&gt;</comment>
                            <comment id="13732839" author="jdcryans" created="Wed, 7 Aug 2013 22:23:30 +0000"  >&lt;p&gt;Sergey, see my later comments.&lt;/p&gt;</comment>
                            <comment id="13732850" author="sershe" created="Wed, 7 Aug 2013 22:31:41 +0000"  >&lt;p&gt;Which one? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Both cases seem to be reading /over/ the 64k boundary, not just close to it. Hadoop fs input stream class reserves (and exercises as the other jira shows) the right to not give you all the bytes you&apos;re asking for, on block boundaries. I wonder if 65535 could be some block boundary, compression code calls read here and there as far as I see. See fix to KeyValue::iscreate, it couldn&apos;t read a pitiful int properly, it got cut by some boundary.&lt;br/&gt;
Are you implying I should supply a patch? I can do that but probably not this week unfortunately.&lt;br/&gt;
Or do you mean my hunch is invalid. Just checking &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13732864" author="jdcryans" created="Wed, 7 Aug 2013 22:39:26 +0000"  >&lt;p&gt;You quoted an earlier comment where I hadn&apos;t done as much investigation as the one where I start with &quot;Here&apos;s what I know about the different problems&quot; where I aimed at dumping my whole understanding of the problem.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Are you implying I should supply a patch? I can do that but probably not this week unfortunately.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nope.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Or do you mean my hunch is invalid. Just checking&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It could very well be related and it could explain why we&apos;re not seeing this problem with an uncompressed log.&lt;/p&gt;</comment>
                            <comment id="13732956" author="yuzhihong@gmail.com" created="Wed, 7 Aug 2013 23:52:08 +0000"  >&lt;p&gt;With help from J-D and Sergey, here is a patch that fixes the problem.&lt;/p&gt;

&lt;p&gt;I looped TestReplicationHLogReaderManager several times based on hadoop 2.1 and the test passed.&lt;/p&gt;

&lt;p&gt;Please comment.&lt;/p&gt;</comment>
                            <comment id="13733022" author="hadoopqa" created="Thu, 8 Aug 2013 01:09:10 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12596744/8615-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12596744/8615-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6643//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13733059" author="sershe" created="Thu, 8 Aug 2013 02:04:59 +0000"  >&lt;p&gt;1) A method like that already exists (IOUtils.readFully), the only reason KV has custom code in one place is because in that case it&apos;s ok to have 0 bytes but not ok to have some other insufficient number of bytes.&lt;br/&gt;
2) Does this cover all cases where compressed input might call read (incl. transitively thru some other call)?&lt;/p&gt;</comment>
                            <comment id="13733070" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 02:18:05 +0000"  >&lt;p&gt;Patch v3 addresses Sergey&apos;s comments.&lt;/p&gt;

&lt;p&gt;I did a search among related classes but didn&apos;t find other calls of in.read() which writes to buffer&lt;/p&gt;</comment>
                            <comment id="13733109" author="hadoopqa" created="Thu, 8 Aug 2013 03:30:10 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12596761/8615-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12596761/8615-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6649//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13733138" author="ram_krish" created="Thu, 8 Aug 2013 04:38:05 +0000"  >&lt;p&gt;Similar issue as in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8498&quot; title=&quot;PB WAL reading is broken due to some partial reads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8498&quot;&gt;&lt;del&gt;HBASE-8498&lt;/del&gt;&lt;/a&gt;.  Patch looks good to me.  &lt;/p&gt;</comment>
                            <comment id="13733207" author="anoop.hbase" created="Thu, 8 Aug 2013 06:47:39 +0000"  >&lt;p&gt;Fix looks reasonable to me. &lt;/p&gt;</comment>
                            <comment id="13733918" author="jdcryans" created="Thu, 8 Aug 2013 20:14:42 +0000"  >&lt;p&gt;Thanks for the patch Ted. To commit we should at least fix the unit test though because what I did was kind of a hack, TestReplicationHLogReaderManager isn&apos;t supposed to run on compressed data. Maybe do a TestReplicationHLogReaderManagerCompressed that just enables it?&lt;/p&gt;

&lt;p&gt;Then we could also test more than just one failure mode in there, easy refactor where you just have to pass the two ints to a method, then get rid of most of the comments. Right now it&apos;s just dirty.&lt;/p&gt;

&lt;p&gt;Finally, if we are fixing HLog compression for real, we need to also put TestReplicationKillMasterRSCompressed back AKA &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13733935" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 20:21:48 +0000"  >&lt;p&gt;The inclusion of changes to TestReplicationHLogReaderManager was to show that the problem has been solved.&lt;/p&gt;

&lt;p&gt;Since restoring TestReplicationKillMasterRSCompressed would be done in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt;, how about dropping the changes to TestReplicationHLogReaderManager in patch v4 ?&lt;/p&gt;

&lt;p&gt;Please comment.&lt;/p&gt;</comment>
                            <comment id="13733944" author="jdcryans" created="Thu, 8 Aug 2013 20:30:39 +0000"  >&lt;p&gt;I understand why you put it there and I think it&apos;s a valuable test because it&apos;s a micro-er (???) test than TestReplicationKillMasterRSCompressed. It just needs to be cleaned up.&lt;/p&gt;</comment>
                            <comment id="13734112" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 22:42:08 +0000"  >&lt;p&gt;See if patch v4 makes the test better.&lt;/p&gt;</comment>
                            <comment id="13734145" author="jdcryans" created="Thu, 8 Aug 2013 23:07:03 +0000"  >&lt;p&gt;+1 on v4, but on commit make it a Large test instead since now it takes 2 minutes to run.&lt;/p&gt;</comment>
                            <comment id="13734166" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 23:20:25 +0000"  >&lt;p&gt;Patch v5 changes the test to large test.&lt;/p&gt;</comment>
                            <comment id="13734375" author="yuzhihong@gmail.com" created="Fri, 9 Aug 2013 04:01:50 +0000"  >&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6669/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6669/console&lt;/a&gt; :&lt;/p&gt;

&lt;p&gt;Running org.apache.hadoop.hbase.replication.regionserver.TestReplicationHLogReaderManager&lt;br/&gt;
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 230.327 sec&lt;/p&gt;</comment>
                            <comment id="13734377" author="yuzhihong@gmail.com" created="Fri, 9 Aug 2013 04:07:09 +0000"  >&lt;p&gt;Integrated to trunk.&lt;/p&gt;

&lt;p&gt;If TestReplicationHLogReaderManager passes on hadoop 2.0, I will integrate to 0.95 branch.&lt;/p&gt;

&lt;p&gt;Thanks for the reviews.&lt;/p&gt;</comment>
                            <comment id="13734451" author="hudson" created="Fri, 9 Aug 2013 06:29:38 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #659 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; HLog Compression may fail due to Hadoop fs input stream returning partial bytes (tedyu: rev 1512133)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationHLogReaderManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13734454" author="hudson" created="Fri, 9 Aug 2013 06:34:08 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #4360 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4360/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4360/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; HLog Compression may fail due to Hadoop fs input stream returning partial bytes (tedyu: rev 1512133)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationHLogReaderManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13734794" author="yuzhihong@gmail.com" created="Fri, 9 Aug 2013 13:55:49 +0000"  >&lt;p&gt;Integrated to 0.95 as well&lt;/p&gt;</comment>
                            <comment id="13734980" author="hudson" created="Fri, 9 Aug 2013 16:44:47 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.95 #422 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/422/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/422/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; HLog Compression may fail due to Hadoop fs input stream returning partial bytes (tedyu: rev 1512305)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationHLogReaderManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13734987" author="hudson" created="Fri, 9 Aug 2013 16:53:37 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.95-on-hadoop2 #227 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/227/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/227/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; HLog Compression may fail due to Hadoop fs input stream returning partial bytes (tedyu: rev 1512305)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationHLogReaderManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13735024" author="hudson" created="Fri, 9 Aug 2013 17:32:51 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #660 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/660/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/660/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt; Put back TestReplicationKillMasterRSCompressed when fixed over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; (Ted Yu) (tedyu: rev 1512345)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationKillMasterRSCompressed.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13735096" author="hudson" created="Fri, 9 Aug 2013 18:17:11 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #4361 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4361/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4361/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt; Put back TestReplicationKillMasterRSCompressed when fixed over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; (Ted Yu) (tedyu: rev 1512345)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationKillMasterRSCompressed.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13735302" author="hudson" created="Fri, 9 Aug 2013 21:04:10 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.95 #423 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/423/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/423/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt; Put back TestReplicationKillMasterRSCompressed when fixed over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; (Ted Yu) (tedyu: rev 1512431)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationKillMasterRSCompressed.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13735465" author="hudson" created="Fri, 9 Aug 2013 23:12:37 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.95-on-hadoop2 #228 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/228/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/228/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9061&quot; title=&quot;Put back TestReplicationKillMasterRSCompressed when fixed over in HBASE-8615&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9061&quot;&gt;&lt;del&gt;HBASE-9061&lt;/del&gt;&lt;/a&gt; Put back TestReplicationKillMasterRSCompressed when fixed over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8615&quot; title=&quot;HLog Compression may fail due to Hadoop fs input stream returning partial bytes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8615&quot;&gt;&lt;del&gt;HBASE-8615&lt;/del&gt;&lt;/a&gt; (Ted Yu) (tedyu: rev 1512431)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationKillMasterRSCompressed.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13735471" author="stack" created="Fri, 9 Aug 2013 23:13:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ted_yu&quot; class=&quot;user-hover&quot; rel=&quot;ted_yu&quot;&gt;Ted Yu&lt;/a&gt; committed this.  Resolving.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12660222">HBASE-9061</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12595525" name="172.21.3.117%2C60020%2C1375222888304.1375222894855.zip" size="8598849" author="jdcryans" created="Fri, 2 Aug 2013 00:13:49 +0000"/>
                            <attachment id="12596744" name="8615-v2.txt" size="4848" author="yuzhihong@gmail.com" created="Wed, 7 Aug 2013 23:52:08 +0000"/>
                            <attachment id="12596761" name="8615-v3.txt" size="4590" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 02:18:05 +0000"/>
                            <attachment id="12596963" name="8615-v4.txt" size="5701" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 22:42:08 +0000"/>
                            <attachment id="12596980" name="8615-v5.txt" size="5938" author="yuzhihong@gmail.com" created="Thu, 8 Aug 2013 23:20:25 +0000"/>
                            <attachment id="12595524" name="HBASE-8615-test.patch" size="3460" author="jdcryans" created="Fri, 2 Aug 2013 00:13:49 +0000"/>
                            <attachment id="12584767" name="org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed-output.txt" size="762001" author="yuzhihong@gmail.com" created="Fri, 24 May 2013 22:27:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 25 Jul 2013 20:47:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>329736</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 18 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kvz3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330071</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>