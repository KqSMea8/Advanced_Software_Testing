<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:55:47 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8496/HBASE-8496.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8496] Implement tags and the internals of how a tag should look like</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8496</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The intent of this JIRA comes from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7897&quot; title=&quot;Add support for tags to Cell Interface&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7897&quot;&gt;&lt;del&gt;HBASE-7897&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
This would help us to decide on the structure and format of how the tags should look like. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12646149">HBASE-8496</key>
            <summary>Implement tags and the internals of how a tag should look like</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ram_krish">ramkrishna.s.vasudevan</assignee>
                                    <reporter username="ram_krish">ramkrishna.s.vasudevan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 03:45:53 +0000</created>
                <updated>Fri, 20 Nov 2015 11:55:13 +0000</updated>
                            <resolved>Sat, 21 Sep 2013 18:21:03 +0000</resolved>
                                    <version>0.98.0</version>
                    <version>0.95.2</version>
                                    <fixVersion>0.98.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>26</watches>
                                                                                                            <comments>
                            <comment id="13651576" author="ram_krish" created="Wed, 8 May 2013 02:56:16 +0000"  >&lt;p&gt;Before i could start further discussion, what type of changes does one foresee in the current KeyValue structure to support Tags and how does it work in tandem with different Encoders available including NONE type.&lt;/p&gt;</comment>
                            <comment id="13651587" author="mcorgan" created="Wed, 8 May 2013 03:30:28 +0000"  >&lt;p&gt;As for existing encoders, I think someone will have to go back and add tag encoding support to them, else they&apos;ll be a black hole for tags.  Tags will go in, but none will come out.&lt;/p&gt;

&lt;p&gt;I don&apos;t have any use cases in mind for tags, but to share what i was envisioning: the tags section could be composed of a sorted list of byte[]s of the form: &lt;span class=&quot;error&quot;&gt;&amp;#91;vint numTags&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;vint length0&amp;#93;&lt;/span&gt;[byte[] tag0]&lt;span class=&quot;error&quot;&gt;&amp;#91;vint lengthN&amp;#93;&lt;/span&gt;[byte[] tagN].&lt;/p&gt;

&lt;p&gt;Should probably sort them at write time so it only has to happen once.  Assume there will be &amp;gt;=1 reads so might as well sort when writing.&lt;/p&gt;

&lt;p&gt;If the basic structure above is followed, then encoders can use dictionary or trie style encoding for the tag section.&lt;/p&gt;</comment>
                            <comment id="13669096" author="ram_krish" created="Wed, 29 May 2013 08:39:54 +0000"  >&lt;p&gt;I have some patches ready for this.  Before i could bring them for further discussion,&lt;br/&gt;
-&amp;gt;From the client perspective the tags will now be added as part of Puts?&lt;br/&gt;
  Put.add() will now have an option to pass tag array.  One more option that we thought of is to have OperationAttributes and set the tags over there.  But we need some CPs to take care     of this so that these tags set in OperationAttr can be added to the KVs of the Put.&lt;br/&gt;
-&amp;gt; Tag will be an integral part of the KVs? &lt;br/&gt;
-&amp;gt; A sort of new hfilereader and writer is needed to read them and write them to the block byte buffer&lt;/p&gt;

&lt;p&gt;What are your suggestions on the above? I would come up with patches sooner.  Thanks all.&lt;/p&gt;</comment>
                            <comment id="13675541" author="ram_krish" created="Wed, 5 Jun 2013 02:53:58 +0000"  >&lt;p&gt;The strucuture of tag may look like this&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
&amp;lt;1 byte type code&amp;gt;&amp;lt;2 byte tag length&amp;gt;&amp;lt;tag&amp;gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;We need to provide some TagIterators inside the CellUtil so that we will be able to iterate the tag array.&lt;br/&gt;
The Iterator must use the above tag structure to build this info.&lt;br/&gt;
Other utility methods may also be needed for this like getNumTags(), given a type get the tags of that type etc.&lt;br/&gt;
If we are having the structure with the type in it then it may not be possible to actually have some validation on the client side for specific tag types.&lt;br/&gt;
The reason for having type is to have different usecases for tags and the CP that we add for the different usecase should help us in achieving it.&lt;/p&gt;

&lt;p&gt;We also need to identify different usecases for tags other than Visibility and ACLs so that we can ensure that we provide proper client support for tags.  Currently the idea is to go with the CP based approach.&lt;br/&gt;
From the client perspective the tags will now be added as part of Puts?&lt;br/&gt;
Put.add(KeyValue) will now have an option to pass tag array. One more option that we thought of is to have OperationAttributes and set the tags over there.&lt;br/&gt;
Tried out different options on getting Tags working with the KeyValues and existing formats.&lt;br/&gt;
The KV can be modified to &lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
&amp;lt;keylength&amp;gt;&amp;lt;valuelength&amp;gt;&amp;lt;keyarray&amp;gt;&amp;lt;valuearray&amp;gt;&amp;lt;taglength&amp;gt;&amp;lt;tagarray&amp;gt;&lt;/font&gt;&lt;br/&gt;
So if a kv does not have any tags still the taglength will be 0 but there will not be any tag array.  &lt;br/&gt;
This will involve some changes in the format of the HFileWriter and reader probably a new version of the Writer/Reader is needed.  (Minor should be enough?)&lt;br/&gt;
Incase of encoders the base encoder BufferedDataEncoder will be tag aware and currently there is not encoding logic applies on the tag part.  It is just written and parsed so that while scan we are able to get the tags in the output KVs.&lt;/p&gt;

&lt;p&gt;Similar applies for the PrefixTree codec.  In this case the backward compatability should be taken care of.&lt;/p&gt;

&lt;p&gt;Incase we don&apos;t need to do the above one more thing that can be done is &lt;br/&gt;
        &lt;font color=&quot;red&quot;&gt;&lt;br/&gt;
	&amp;lt;Existing KV format&amp;gt;&amp;lt;int &#8211; negative integer indicating the length of the tag&amp;gt;&amp;lt;tag array&amp;gt;&lt;br/&gt;
        &lt;/font&gt;&lt;br/&gt;
Here the negative length is used only when there is a tag and the existing KV format is left untouched when there is no tag.&lt;br/&gt;
In this approach we would be every time reading the next KVs keylength and then decide if there is a tag presence or not.  If not present we just rewind the position of the buffer.&lt;br/&gt;
This has a performance impact but does not involve changes to the HFileFormats.&lt;/p&gt;


&lt;p&gt;So in both of the cases we tend to write the tag info whether or not user needs it.  So one way to avoid it could be like the way we do for MemstoreTS.&lt;br/&gt;
Add a meta data to the hfile saying tagpresent = true/false based on the KVs in that HFile.  &lt;br/&gt;
Even if there is only one KV with tag this meta data will be true.&lt;br/&gt;
Now on compaction we will read this metadata and decide whether to compact data with Tag or without tag.&lt;br/&gt;
The advantage is that for scenarios where there are no tags we will have not have a drop in read performance (this applies after compaction is done).&lt;br/&gt;
The downside of this approach is that the KeyValue format itself now becomes 2 ways of representation.  Sometimes the KV that we retrieve will have tag info sometimes will not be having tag.&lt;br/&gt;
Thanks to Anoop and Andy for their suggestions/inputs.&lt;/p&gt;

&lt;p&gt;I have some patches ready for the above approaches except for that option tag part.  Wanted to know if that can be provided as a feature in the future?  anyway will try out the optional part also to see what type of changes/issues we may face while implementing it.&lt;br/&gt;
Comments/feedback welcome.  Anyother ideas am open to hear them also.  &lt;/p&gt;</comment>
                            <comment id="13676451" author="stack" created="Wed, 5 Jun 2013 22:46:57 +0000"  >&lt;p&gt;A few notes on above Ram.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&amp;lt;1 byte type code&amp;gt;&amp;lt;2 byte tag length&amp;gt;&amp;lt;tag&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You don&apos;t want to use a vint for length?  Most tags will only need a single byte for length I&apos;d imagine.&lt;/p&gt;

&lt;p&gt;Have we said what tags will actually look like?  For instance for ACL and Visibility, what will they look like?  Will a tag for Visibility be the Accumulo list of who can view?&lt;/p&gt;

&lt;p&gt;On the 1 byte type, I am not clear why.&lt;/p&gt;

&lt;p&gt;Would suggest too that you start up a one or two page design doc.  Will help w/ review of design.  Easier than trying to aggregate JIRA comments spread over multiple issues.&lt;/p&gt;

&lt;p&gt;Do you think we need tag iterators?  Is that overkill since for the vast majority of cases there will be one tag or two at most? (I&apos;d guess).&lt;/p&gt;

&lt;p&gt;Tags will be done by a CP?  Does it have to be that way?  Can tags not be first class beside timestamp, column qualifier, etc.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we are having the structure with the type in it then it may not be possible to actually have some validation on the client side for specific tag types.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Pardon me, I do not follow the above.&lt;/p&gt;

&lt;p&gt;Is putting tags after value a good idea?  We&apos;ll have to skip over the value to see if we should return the KV?  Would be easier if the tag were part of the key?&lt;/p&gt;

&lt;p&gt;Sounds like we need to change the hfileformats (smile)?&lt;/p&gt;

&lt;p&gt;&quot;option tag part&quot; is optionally adding tags to hfile?&lt;/p&gt;

&lt;p&gt;Good on you Ram.&lt;/p&gt;</comment>
                            <comment id="13676625" author="ram_krish" created="Thu, 6 Jun 2013 03:11:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would suggest too that you start up a one or two page design doc.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;You don&apos;t want to use a vint for length? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I can do this. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;For instance for ACL and Visibility, what will they look like? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;ACL related tags will be something like UserTablePermissions saying which user has what type of permissions.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; UserTablePermissions()
+            .add(user, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TablePermission(Permission.Action.READ)))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above is an example from Andy&apos;s patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6222&quot; title=&quot;Add per-KeyValue Security&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6222&quot;&gt;&lt;del&gt;HBASE-6222&lt;/del&gt;&lt;/a&gt;.  Something like above will now be added as part of tags.&lt;br/&gt;
Visibility tags are the ones that Accumulo supports.  A set of valide ascii characters that define the labels and thus ensuring authorization to the users who pass those labels for reads.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On the 1 byte type, I am not clear why.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is something to be looked into keenly.  My idea was if i say ACL and Visibility are the two types of tags, i need to have different CPs to process them.  So now to identify which CP should do what, the tag needs some categorization which is provided by the Type part. I will cover more on the doc that i attach over here.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Do you think we need tag iterators? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;May be needed, will see if there is other way.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Can tags not be first class beside timestamp, column qualifier, etc.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Is putting tags after value a good idea?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Oops, So you mean that tags needs to be part of the KV comparisions itself. Was thinking that would be a major change.  So we need to sort KVs based on tags also?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Sounds like we need to change the hfileformats (smile)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;YEs ofcourse it needs change&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;option tag part&quot; is optionally adding tags to hfile?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya. So if the user does not have any tags atleast the hfiles that gets created after compactions will be that of existing ones.&lt;br/&gt;
And thanks for your reviews/comments Stack.&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopsamjohn&quot; class=&quot;user-hover&quot; rel=&quot;anoopsamjohn&quot;&gt;Anoop Sam John&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;&lt;br/&gt;
you would like to pitch in with your ideas here?&lt;/p&gt;

</comment>
                            <comment id="13678821" author="apurtell" created="Sat, 8 Jun 2013 19:16:11 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Is putting tags after value a good idea?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops, So you mean that tags needs to be part of the KV comparisions itself. Was thinking that would be a major change. So we need to sort KVs based on tags also?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would strongly caution against this. Tags will be &lt;em&gt;arbitrary&lt;/em&gt; metadata and won&apos;t have anything to do with locating the value itself. &lt;/p&gt;

&lt;p&gt;On the other hand, some use cases may want it, see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6222?focusedCommentId=13396190&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13396190&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-6222?focusedCommentId=13396190&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13396190&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;I don&apos;t have a good answer for resolving this conflict. &lt;/p&gt;

&lt;p&gt;We may just want to live with the constraints imposed by not having tags be part of the key. This would significantly simplify implementation.&lt;/p&gt;</comment>
                            <comment id="13693247" author="jeffreyz" created="Tue, 25 Jun 2013 18:29:22 +0000"  >&lt;p&gt;I want to post a following user case to see if current design can accommodate or can easily be extended to support it.&lt;/p&gt;

&lt;p&gt;In high level, we&apos;d like to have support of optional system tags. Basically  HBase internals can tag a KV with a value and consume these tags without using co-processors. These tags are invisible to end users(application end users).  &lt;/p&gt;

&lt;p&gt;A possible user case(just for example as hbase-8701 may go different approach.) is for hbase-8701 where we can tag a KV with sequence number value during log replay and later these tags are removable by a major compaction.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13693623" author="ram_krish" created="Wed, 26 Jun 2013 04:30:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Basically HBase internals can tag a KV with a value and consume these tags without using co-processors.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The HBase internals will know about the tags and the read and write path would know how to deal with them.  But they will just read the tag part of the KV from the bytebuffer and return back as KVs with or without tags as per that individual KV.&lt;br/&gt;
If we need to take specific action for the system tags on the read path, then we need to add the behaviour inside the HBase read path. Currently this would be handled by CPs based on the type of the tags.&lt;br/&gt;
So may be once i attach a first cut version of the patch you would be able to understand better.&lt;/p&gt;</comment>
                            <comment id="13693880" author="ram_krish" created="Wed, 26 Jun 2013 10:01:46 +0000"  >&lt;p&gt;Attaching a simple design document that says how tags will be supported by HBase and the advantage of using KeyValuecodec. &lt;br/&gt;
It also touches on the way how tags can be implemented in an optional way when we don&apos;t go with KeyValuecodec.  Pls feel free to share your comments/reviews.  Thanks to Andy and Anoop for their reviews/suggestions.&lt;/p&gt;</comment>
                            <comment id="13694379" author="yuzhihong@gmail.com" created="Thu, 27 Jun 2013 00:49:45 +0000"  >&lt;p&gt;On page 6:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In case of per HFile&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The sentence seems to be incomplete.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;once we close the file we add the Meta data saying tagpresent = true and avg_tag_len = 0.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;avg_tag_len = 0 would indicate that there is no tag present. Why do we need two flags (tagpresent and avg_tag_len) ?&lt;br/&gt;
Later compaction is mentioned where tagpresent is changed to false. But we should be able to achieve this at the time of flush, right ?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] tagArray = kv.getTagsArray();
Tag decodeTag = KeyValueUtil.decodeTag(tagArray);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the above sample, I would expect decodeTag() to return more than one Tag.&lt;br/&gt;
Would all Tags in the KeyValue be returned to filterKeyValue() ? I think it would be better if Tag.Type.Visibility is passed to decodeTag() so that only visibility Tag is returned.&lt;/p&gt;</comment>
                            <comment id="13694470" author="ram_krish" created="Thu, 27 Jun 2013 04:10:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;avg_tag_len = 0 would indicate that there is no tag present. Why do we need two flags (tagpresent and avg_tag_len) ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;When we don&apos;t use the keyvaluecodec approach, when i flush the memstore i would be getting every KV and then writing it into blocks.  So in one flush i can have only one KV with tag and all others without tag.  So i cannot make a decision on the presence of tags before i could complete one Hfileblock.&lt;br/&gt;
So while flush happens i would always write the taglength part of the kv but there may not be any tags in that block.  So inorder to decode this block when i read i should have an indicator that i have written this block with the taglength (tagpresent flag) but the avg_tag_len would indicate whether i need not read the 4 byte INT but just skip the 4 bytes and reposition the buffer.  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Later compaction is mentioned where tagpresent is changed to false. But we should be able to achieve this at the time of flush, right ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Always flush would right the taglength even if tags are not present.  when the same HFileblock is being read for compaction i would just use the above logic and avoid writing the even taglength part in the compacted file and so now in this compacted file the hfileblock would have tagpresent=false and avg_tag_len=0.  Pls note that in the HFileblock level this would be two individual bytes - 1 indicates true and 0 indicates false.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In the above sample, I would expect decodeTag() to return more than one Tag.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes Ted you are right.  In the example that i attached there there was only one tag.  Ideally we would be using like this&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    Iterator&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; tagIterator = CellUtil.getTagIterator(tagArray);
    List&amp;lt;Tag&amp;gt; tagList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;Tag&amp;gt;();
    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (tagIterator.hasNext()) {
      &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] tag = tagIterator.next();
      Tag t =(KeyValueUtil.decodeTag(tag));
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;&lt;p&gt;I think it would be better if Tag.Type.Visibility is passed to decodeTag() so that only visibility Tag is returned.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We can have one such method so that decodeTag would only return a KV if the specified type of tag is present.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Would all Tags in the KeyValue be returned to filterKeyValue() ? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If you see in terms of visibility/ACL tags if a user is authorised to read that KV then returning the KV with tags should be fine i feel.  We can discuss on this.&lt;br/&gt;
I am working on the performance reports on using KeyValueCodec. Will share more info on that soon.&lt;br/&gt;
Thanks for your reviews.&lt;/p&gt;
</comment>
                            <comment id="13694858" author="mcorgan" created="Thu, 27 Jun 2013 16:53:23 +0000"  >&lt;p&gt;A quick comment on encoding the tag lengths - I would recommend using a VInt rather than fixed 2 bytes.  Most tags will be &amp;lt; 128 or 256 bytes (depending on which VInt you choose), so will fit nicely into 1 byte.  A 1 byte VInt is pretty trivial to decode, maybe as easy or easier than 2 bytes.&lt;/p&gt;</comment>
                            <comment id="13694923" author="stack" created="Thu, 27 Jun 2013 17:56:12 +0000"  >&lt;p&gt;Add author, date, and JIRA you are referring to.&lt;/p&gt;

&lt;p&gt;Tags are going to be handled by cps and not be native?  Or is thought that we do them as CP first and then pull them native?&lt;/p&gt;

&lt;p&gt;Why does hfile care about tags?  It is not doing interpretation of the Cells it has?&lt;/p&gt;

&lt;p&gt;You don&apos;t want to add addTags to Mutation so you can do Put#addTags?  We can do this later I suppose.&lt;/p&gt;

&lt;p&gt;If tags as attribute, maybe have a special key, something like, tags.visibility... so know which attributes are for inclusion in tags.&lt;/p&gt;

&lt;p&gt;Should you make a TaggedKeyValueCodec or you think it fine just making KeyValueCodec handle tags if present?&lt;/p&gt;

&lt;p&gt;So, pass a cellblock to hfile and then add codec metadata to hfile metadata?  Hmm... I suppose using a codec breaks when you get to hfile because you have to do a kv at a time, unless you can do append(Codec).  Besides, hfile is broke at the moment in that it only knows one kind of kv serialization and it is baked in everwhere.  How you propose we fix this?  Can we move hfile to be Cell based?&lt;/p&gt;

&lt;p&gt;Is it good adding tags at end of kv?  I suppose it is fine for now getting them in.  We can do an alternate serialization later, one that keeps tags close so we can spin through them fast w/o having to read value data.&lt;/p&gt;

&lt;p&gt;&quot;With KeyValuecodecs in place now we would issue two reads to read the total KV size and then read the  entire byte array and then form the KVs.&quot; &amp;#8211; it has to be two reads?  COuld we not write the block as a KeyValueCodec?  And then in hfile metadata say what Codec class writing blocks was?&lt;/p&gt;

&lt;p&gt;We need to change hfile so it does Cells.  HFileBlockEncoders also are broke in that they presume the KV serialization format.  HFileBlockEncoders should be like the new Cell Codecs.&lt;/p&gt;

&lt;p&gt;You say &quot;All the encoders will need to understand the tags.&quot;  Would be best for all if hfiles understood Cells.  When you say additional &apos;read&apos;, do you mean a new seek?&lt;/p&gt;

&lt;p&gt;&quot;...but we would not be  able to use the KeyValueCodec.decoder() on the HFileBlocks.&quot; can we not make this happen?  HFileBlockEncoders are broke.&lt;/p&gt;

&lt;p&gt;&quot;This would involve changes to the HFileBlockHeader.&quot;  Could hfile blocks be cellblocks?  And in meta data for hfile say what decoder to use?&lt;/p&gt;

&lt;p&gt;Thanks Ram.&lt;/p&gt;

</comment>
                            <comment id="13694928" author="stack" created="Thu, 27 Jun 2013 18:04:38 +0000"  >&lt;p&gt;I suppose bottom-line, can we not just do Cells rather than KV-with-tags?  The same problems have to be solved (basically).  If Cells, you&apos;ll get your tags carried along for you.  Your CPs could then exploit them when present.  The serialization could be your proposed KV-with-tags-on-the-end but when we touch hfile, can we pass cellblocks and read cellblocks (encoding and/or compression could be metadata in hfile &amp;#8211; I suppose this means one encoding/compression per file which is probably fine.  Compressed/encoded blocks in memory would have to be accessed w/ CellScanner... would need resettable CellScanner though I suppose.&lt;/p&gt;</comment>
                            <comment id="13695002" author="apurtell" created="Thu, 27 Jun 2013 19:53:28 +0000"  >&lt;p&gt;My read is tags are in core but the example users are coprocessors. Except for the operation attribute part, but that&apos;s just the other side of the story: if a cp is consuming tags presumably it is setting/managing them too. &lt;/p&gt;

&lt;p&gt;To what extent are we comfortable changing the client API to be tags aware? In 0.94 too?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Could hfile blocks be cellblocks?  And in meta data for hfile say what decoder to use?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it makes sense to have one codec for cells, or transitionally cells as two distinct serializers - keyvalue+tags, leaving the keyvalue class alone for the most part. We have keyvaluecodec in both trunk/0.95 and 0.94. Right now its only used for WALs. Should extend this to use for HFile blocks too - one common codec for keyvalue/cell serialization dealing with stuff like tags. So agreed hfile block encoding should change at least to incorporate this new common interface. If we have leeway to change how HFile blocks are constructed, maybe we can bump HFile minor and try more than just cell by cell. Could pack tags together at the block level (and even dedup/share) if we can go this far with the kind of changes people would be comfortable with in trunk &lt;b&gt;and&lt;/b&gt; 0.94.&lt;/p&gt;</comment>
                            <comment id="13695056" author="stack" created="Thu, 27 Jun 2013 21:09:13 +0000"  >&lt;p&gt;You fellas want this to work on 0.94?&lt;/p&gt;

&lt;p&gt;Otherwise, hfilev3!  Go for it!&lt;/p&gt;</comment>
                            <comment id="13695067" author="apurtell" created="Thu, 27 Jun 2013 21:22:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;You fellas want this to work on 0.94?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, in the sense for cell ACLs, visibility labels, and such we would like to share as much as possible between 0.94 (prod) and 0.95+ (future) &lt;/p&gt;</comment>
                            <comment id="13695314" author="ram_krish" created="Fri, 28 Jun 2013 08:08:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;Add author, date, and JIRA you are referring to.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Will do.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Should you make a TaggedKeyValueCodec or you think it fine just making KeyValueCodec handle tags if present?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think KeyValueCodec will server the purpose because KVCodec does not mind what is the internal byte structure so with or without tag is should be able to handle.  What you feel?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;If tags as attribute, maybe have a special key, something like, tags.visibility.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;A special constant you mean? Should be fine. Mine just showed an example we can make that key something like a keyword.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Besides, hfile is broke at the moment in that it only knows one kind of kv serialization and it is baked in everwhere. How you propose we fix this? Can we move hfile to be Cell based?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;HFile to cell based should be the best choice but converting the current hfile blocks to cell based blocks  i need to check the changes.  Let me give a try at it.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We can do an alternate serialization later, one that keeps tags close so we can spin through them fast w/o having to read value data.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Making alternate serialization later may involve changes to the existing comparators i feel, may be with Cell based this change should be simple i think.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;HFileBlockEncoders also are broke in that they presume the KV serialization format. HFileBlockEncoders should be like the new Cell Codecs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.  Everywhere the code just tries to go with KV format.  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;When you say additional &apos;read&apos;, do you mean a new seek?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No i meant the read issued on the byte buffers.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Could hfile blocks be cellblocks? And in meta data for hfile say what decoder to use?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;If Cells, you&apos;ll get your tags carried along for you. Your CPs could then exploit them when present. The serialization could be your proposed KV-with-tags-on-the-end but when we touch hfile, can we pass cellblocks and read cellblocks (encoding and/or compression could be metadata in hfile &#8211; I suppose this means one encoding/compression per file which is probably fine. Compressed/encoded blocks in memory would have to be accessed w/ CellScanner... would need resettable CellScanner though I suppose.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As said above will check this also.  May be i can comment on this based on the analysis that i do in next couple of days and get back on this.  &lt;/p&gt;

&lt;p&gt;If we try to use KeyValueCodec and try to use it per Cellblock then the KeyValueCodec.decoder() should work on the Cellblock but rather KeyValueCodec does not help much in the decoding time.&lt;/p&gt;

&lt;p&gt;The performance results with KVCodec seemed to be performing less than the other prototypes that i tried out.&lt;/p&gt;</comment>
                            <comment id="13695412" author="anoop.hbase" created="Fri, 28 Jun 2013 12:11:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;A quick comment on encoding the tag lengths - I would recommend using a VInt rather than fixed 2 bytes&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes Matt, we have discussed abt that also.. I think have not done it yet in any of the poc &lt;/p&gt;</comment>
                            <comment id="13696694" author="ram_krish" created="Mon, 1 Jul 2013 10:14:53 +0000"  >&lt;p&gt;@Stack/Andy &lt;br/&gt;
We could create the CellBlock decoder that reads Cellblocks but the decoder would be able to operate on the ByteBuffer and not on the InputStream directly as how it is designed now.&lt;br/&gt;
Ideally we would be reading from DFS using IOUtils.readFully and have bytebuffer filled up on which we can have a new CellDecoder that has the resettable property also.&lt;br/&gt;
Did you mean this way Stack? This argument is same as what i have described above wrt KeyValueCodec.  &lt;/p&gt;</comment>
                            <comment id="13702935" author="stack" created="Tue, 9 Jul 2013 05:26:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think KeyValueCodec will server the purpose because KVCodec does not mind what is the internal byte structure so with or without tag is should be able to handle. What you feel?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ideally we would be reading from DFS using IOUtils.readFully and have bytebuffer filled up on which we can have a new CellDecoder that has the resettable property also.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Is ByteBuffer required Ram?  IOUtils.readFully fills a byte array?&lt;/p&gt;


</comment>
                            <comment id="13708228" author="ram_krish" created="Mon, 15 Jul 2013 04:23:27 +0000"  >&lt;p&gt;I would like to get your suggestions on this.&lt;br/&gt;
-&amp;gt; Ideal soln would be to use the codecs to work with Tags.  But the current apis in Codec are more suitable for WAL and RPC but not for HFile level implementation.  Atleast they are not straightforward. The HFile scan involves positional seek and we tend not to read KV by KV but most of the time we try to keep positioning the byte buffer and form the KVs. &lt;br/&gt;
Usage of codec would not allow us to do this because doing a Codec.advance() would allow us to advance per KV.  Also this type of advance() is not suitable for positional Seek.  Hence it either makes us to introduce apis like previous() or backward() (for seekbefore)in the CellScanner or Create a Seeker interface in the Decoder (like the Seeker in DatablockEncoders) and implement the postional seeks in it.  Doing this type of positional seek in the Util classes(discussion with Stack) am bit reluctant on this.&lt;br/&gt;
-&amp;gt; Another problem when we use Codec would be with the DatablockEncoders.  How does the DatablockEncoders work now is&lt;br/&gt;
HFileWriter-&amp;gt;append(kv) &lt;del&gt;&amp;gt; form Hfileblock byte buffer&lt;/del&gt;&amp;gt;Encoders read the bytebuffer-&amp;gt; Encode per kv into new bytebuffer-&amp;gt; The new bytebuffer is persisted.&lt;br/&gt;
Read flow&lt;br/&gt;
==========&lt;br/&gt;
Read the encoded byte buffer-&amp;gt; The Seekers in the DatablockEncoders decode the bytebuffer to form the actual bytebuffer&lt;/p&gt;

&lt;p&gt;When we try to use Codec we may want to modify this as&lt;br/&gt;
HFileWriter-&amp;gt;Codec.encode(kv)&lt;del&gt;&amp;gt; form hfileblock byte buffer -&amp;gt; Codec.decode(Bytebuffer) form KVs&lt;/del&gt;&amp;gt; Encode per KV into new byte buffer &lt;del&gt;&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;If this KV has tag we may need to again have an encoder here for tags&amp;#93;&lt;/span&gt;&lt;/del&gt;&amp;gt; The new bytebuffer is persisted   (1)&lt;br/&gt;
Read flow&lt;br/&gt;
========&lt;br/&gt;
REad the encoded byte buffer -&amp;gt; The Seekers in the DatablockEncoders decode the bytebuffer to form the actual bytebuffer.&lt;/p&gt;

&lt;p&gt;One thing to be noted is that we may have to rewrite all the Encoding algo to work with Tags by either subclassing the actual ones or rewriting new ones.  Now how can this decision be made? Here again we have few options options&lt;br/&gt;
-&amp;gt; If user has tags add new Encoding Algos to the DataBlockEncoding enum like PRefixKeyDeltaEncodingWithTags, FastDiffkeyEncodingWithTags etc. and when we ever we see that the codec used for hfile has the ability to understand tags we just use the new Algos.&lt;br/&gt;
-&amp;gt; The other way could be let internally the code instantiate the new classes and work with them to use the Tags also. But this would involve changes in the code with some if/else checks and this would apply for every algorithm.  Tomorrow if a new codec is added then we may have to keep doing this.&lt;br/&gt;
-&amp;gt; Another thing that Anoop suggested was, have a new HFileCodec internally it will be having the HFileCompressedEncoder.  And every time you add a new type of codec it is upto the user to implement the Prefixkey, Fastdiff, Diffkey, PrefixTree to work with that codec. &lt;/p&gt;

&lt;p&gt;One more thing would be to change the way DAtablockEncoders work.  As you can see in &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; since the blockencoders work on the Hfileblocks we are not able to make the most of the codec way of encoding and decoding. So we could make it work on per KV  in the sense&lt;br/&gt;
HFileWriter-&amp;gt;append(kv)&lt;del&gt;&amp;gt;Codec.encode(kv)&lt;/del&gt;&amp;gt; Create the encoded buffer-&amp;gt; Fill in the buffer till the block size is reached.&lt;/p&gt;

&lt;p&gt;As you can see all the above changes are like having an impact on the core code and we need good amout of changes to do this.  Considering the effort on 0.96 this would be a major effort.  &lt;br/&gt;
One suggestion that we would like to make is and also reading Stack&apos;s earlier comment HfileV3 would be a viable soln.&lt;br/&gt;
So HFileV3 would be the one which would know about the Tags and the read and write path in HFileV3 would understand tags.  This would also mean that the datablockencoder code path will have some ugly if/else checks to handle the code flow with and without Tags (or something similar). I think this would make us have Tag support in 0.96 code base and the same could be changed based on discussion in community and bring about the changes for 0.98 with codec and also make the code talk in terms of Cells.&lt;br/&gt;
I can raise a discussion/voting on the dev list for this.  It would be great if we can come up with a consensus on this.&lt;/p&gt;
</comment>
                            <comment id="13708649" author="apurtell" created="Mon, 15 Jul 2013 17:10:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;So HFileV3 would be the one which would know about the Tags and the read and write path in HFileV3 would understand tags. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What I especially like about this is any performance or functional risks which might possibly be introduced by the tags work is completely optional to take on this way - just don&apos;t select HFileV3. We can even mark it as experimental until 0.98. &lt;/p&gt;

&lt;p&gt;I have been able to observe Ram&apos;s work over the past couple of months trying out various other approaches just shy of introducing a new file format. It&apos;s not a decision come to overnight.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13710653" author="ram_krish" created="Wed, 17 Jul 2013 03:28:05 +0000"  >&lt;p&gt;Thinking on the compatibility issues once we have Codec to work with HFiles,&lt;/p&gt;

&lt;p&gt;If we introduce V3 without changing the HFileBlock headers it would be easy for us to make the Codec to work in trunk.&lt;br/&gt;
As the plan is to write the Codec used in the HFile header, for those files written using existing HFileV2 and the HFileV3(tags) we would need to read the Hfile header and as we come to know that there is no codec used in these hfiles, find out the major version of these files.&lt;br/&gt;
If it is V2 instantiate a default codec that works with KVs(without tags) and if the major version is V3 instantiate a default codec that works with KVs(with tags).  By this way we solve the problem of compatibility.&lt;br/&gt;
Later V2 and V3 would ideally become the same code and we can decide on the version later.&lt;/p&gt;

&lt;p&gt;Ideally speaking, the codec way of encoding and decoding the KVs is the best way of doing things. But because of all said above we need a simpler and viable solution and that is why we would like to move ahead with HFile V3&lt;br/&gt;
This V3 way of implementation can make the Tags as an optional feature and so not risky.&lt;br/&gt;
Considering the above facts we would like to propose that going with HFileV3 would help us have tags in 0.96.&lt;/p&gt;</comment>
                            <comment id="13719840" author="ram_krish" created="Thu, 25 Jul 2013 17:59:31 +0000"  >&lt;p&gt;Patch that work with HFile V3 and makes Tags in memory to the KV.  The attached design doc is about having Tags in the KV byte array.&lt;br/&gt;
We had tried both the options and the attached patch is with inmemory Tags rather than appending to the KV byte array.  There are few pros and cons with both the approaches.  The support for PerfEval and LoadTestTool will attach in a seperate JIRA.  &lt;/p&gt;

&lt;p&gt;Many thanks to Anoop for his quality ideas/contributions and review.  &lt;br/&gt;
Thanks to Andy for his inputs for the prototypes and reviews.&lt;/p&gt;

&lt;p&gt;Pls provide your suggestion/feedback.  &lt;/p&gt;</comment>
                            <comment id="13719846" author="ram_krish" created="Thu, 25 Jul 2013 18:01:26 +0000"  >&lt;p&gt;I can also attach the patch that adds tags with the kv byte buffer.  Incase we need to discuss more on some of the design decisions taken.  Just to add on there are some pros and cons with both the approaches.&lt;/p&gt;
</comment>
                            <comment id="13719863" author="ram_krish" created="Thu, 25 Jul 2013 18:14:36 +0000"  >&lt;p&gt;Attaching the comparison doc between inmemory tags and tag n the kv byte buffer.&lt;/p&gt;</comment>
                            <comment id="13720082" author="yuzhihong@gmail.com" created="Thu, 25 Jul 2013 21:25:21 +0000"  >&lt;p&gt;Great effort, Ram.&lt;/p&gt;

&lt;p&gt;With the attached patch, I got the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-testCompile) on project hbase-server: Compilation failure: Compilation failure:
[ERROR] /Users/tyu/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java:[346,79] VALUE_LENGTH has &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; access in org.apache.hadoop.hbase.PerformanceEvaluation
[ERROR] /Users/tyu/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java:[346,36] cannot find symbol
[ERROR] symbol  : method generateData(java.util.Random,&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
[ERROR] location: class org.apache.hadoop.hbase.PerformanceEvaluation
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13720420" author="yuzhihong@gmail.com" created="Fri, 26 Jul 2013 05:27:14 +0000"  >&lt;p&gt;Browsed through HFileWriterV3 which needs class javadoc.&lt;br/&gt;
Although there is code duplication with HFileWriterV2, I think it is fine for first cut.&lt;/p&gt;

&lt;p&gt;HFileReaderV3 needs license and class javadoc.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; class EncodedScannerV3 &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; EncodedScannerV2 {^M
+    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; DataBlockEncoder.EncodedSeeker seeker = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;^M
+    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; HFileReaderV3 reader;^M
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why does EncodedScannerV3 need to keep reference to HFileReaderV3 ? AbstractHFileReader#Scanner#getReader() would return the reader, right ?&lt;/p&gt;

&lt;p&gt;Can you upload patch onto review board ? Please remove the trailing ^M.&lt;/p&gt;</comment>
                            <comment id="13720452" author="anoop.hbase" created="Fri, 26 Jul 2013 06:23:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why does EncodedScannerV3 need to keep reference to HFileReaderV3 ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Using a field includesTag and to avoid the type casting, kept a reference this way&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
dataBlockEncoder.createSeeker(reader.getComparator(),
+          includesMemstoreTS, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.reader.includesTag);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;&lt;p&gt;Please remove the trailing ^M.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure. Sorry &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Although there is code duplication with HFileWriterV2, I think it is fine for first cut.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya tried to avoid many. Still possible to avoid some more duplication with refactoring.&lt;/p&gt;

&lt;p&gt;Thanks Ted&lt;/p&gt;</comment>
                            <comment id="13720800" author="yuzhihong@gmail.com" created="Fri, 26 Jul 2013 13:53:41 +0000"  >&lt;p&gt;It would be desirable to have performance comparison both in writing and reading between HFileV2 and HFileV3 where the contents of non-tagging are the same.&lt;/p&gt;</comment>
                            <comment id="13721310" author="yuzhihong@gmail.com" created="Fri, 26 Jul 2013 22:33:23 +0000"  >&lt;p&gt;EncodedScannerV3 has reference to HFileReaderV3.&lt;br/&gt;
All it needs is reader.includesTag and reader.getComparator()&lt;br/&gt;
reader is accessible to EncodedScannerV2. We only need to store reader.includesTag, or cast reader to HFileReaderV3 and obtain includesTag at runtime.&lt;/p&gt;

&lt;p&gt;In Mutation.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  /*
+   * Create a KeyValue with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; objects row key and the Put identifier.
+   *
+   * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; a KeyValue with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; objects row key and the Put identifier.
+   */
+  KeyValue createPutKeyValue(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] family, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] qualifier, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; ts, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] value, Tag[] tag) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can you add javadoc for tag parameter ? BTW calling the parameter tags would be better since an array of Tags may be passed.&lt;/p&gt;

&lt;p&gt;TagFilter.java needs license. In its filterKeyValue():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (t.getType() == (&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;) 1) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can you introduce a constant so that the meaning of tag type 1 can be easily understood ?&lt;/p&gt;

&lt;p&gt;In transform() method:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (CloneNotSupportedException e) {
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Add debug log for the above case ?&lt;/p&gt;

&lt;p&gt;In CellUtil, I see copyTagTo() and copyTagToForPrefix() but they look the same. Did I miss something ?&lt;/p&gt;

&lt;p&gt;In createCell():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// I need a Cell Factory here.  Using KeyValue &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; now. TODO.
&lt;/span&gt;+    &lt;span class=&quot;code-comment&quot;&gt;// TODO: Make a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Cell implementation that just carries these
&lt;/span&gt;+    &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; arrays.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above would be done in a follow-on JIRA ?&lt;/p&gt;

&lt;p&gt;For tagsIterator():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void remove() {
+        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IllegalStateException();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Mind add a message to the exception ?&lt;/p&gt;</comment>
                            <comment id="13721456" author="apurtell" created="Sat, 27 Jul 2013 01:05:24 +0000"  >&lt;p&gt;I posted the changes to hbase-common and hbase-server to RB on Ram&apos;s behalf here: &lt;a href=&quot;https://reviews.apache.org/r/12981/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/12981/&lt;/a&gt; See comments there on testing done. Ram indicated he will shortly post to a subtask a separate patch with optional test-mostly changes to hbase-client and hbase-it. Those are not essential changes.&lt;/p&gt;</comment>
                            <comment id="13721699" author="ram_krish" created="Sat, 27 Jul 2013 17:43:22 +0000"  >&lt;p&gt;The patch that works with KV Buffer, testcases are not yet completely running with this. But can be used to compare the changes between the two approaches.&lt;/p&gt;</comment>
                            <comment id="13721701" author="ram_krish" created="Sat, 27 Jul 2013 17:44:49 +0000"  >&lt;p&gt;Patch addressing Ted&apos;s comments.&lt;br/&gt;
The createCell() comment is just copied from the existing createCell().  I have not yet updated this to review board as Andy has created the RB with git patch.  Let me create one tomorrow.&lt;/p&gt;</comment>
                            <comment id="13721718" author="hadoopqa" created="Sat, 27 Jul 2013 18:59:19 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594548/HBASE-8496_2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594548/HBASE-8496_2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 94 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 7 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6497//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13721752" author="yuzhihong@gmail.com" created="Sat, 27 Jul 2013 20:55:51 +0000"  >&lt;p&gt;In PrefixTreeBlockMeta.java, there is method setTagValueBytes().&lt;br/&gt;
Is it used anywhere ?&lt;/p&gt;

&lt;p&gt;In PrefixTreeCodec.java :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-comment&quot;&gt;//TODO : Should i pass &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;  here &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; includeTags
&lt;/span&gt;+      searcher = DecoderFactory.checkOut(block, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Passing includesTag parameter to checkOut() method ?&lt;/p&gt;

&lt;p&gt;In TestRowData.java, I saw:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      all.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TestRowDataSimple());
+      /*all.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TestRowDataSimple());
       all.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TestRowDataDeeper());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Did you encounter some issue that prevented the test to pass ?&lt;/p&gt;

&lt;p&gt;In PrefixTree tests, false is passed for includesTag:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    encoder = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PrefixTreeEncoder(os, includeMemstoreTS);
+    encoder = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PrefixTreeEncoder(os, includeMemstoreTS, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Do you want to add tag tests for PrefixTree in another issue ?&lt;/p&gt;</comment>
                            <comment id="13722021" author="apurtell" created="Sun, 28 Jul 2013 18:25:10 +0000"  >&lt;p&gt;Making this critical because &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6222&quot; title=&quot;Add per-KeyValue Security&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6222&quot;&gt;&lt;del&gt;HBASE-6222&lt;/del&gt;&lt;/a&gt; is blocked by it. RM: Please feel free to change this back if you feel otherwise.&lt;/p&gt;</comment>
                            <comment id="13728429" author="ram_krish" created="Sat, 3 Aug 2013 03:44:44 +0000"  >&lt;p&gt;Updated design document. Patch to follow based on this.  &lt;br/&gt;
The optional part of writing tags could be done in a follow up JIRA.&lt;/p&gt;</comment>
                            <comment id="13728918" author="yuzhihong@gmail.com" created="Sun, 4 Aug 2013 17:11:27 +0000"  >&lt;p&gt;Skimmed through latest design doc.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Pls note that we would not be persisting any tag related information on the HFileBlock.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Based on the Encoding/Decoding context state the Encoder and decoding logic of the algos would handle tags.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can you elaborate on the above a bit more ?&lt;/p&gt;</comment>
                            <comment id="13729855" author="ram_krish" created="Mon, 5 Aug 2013 19:33:54 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;Pls note that we would not be persisting any tag related information on the HFileBlock.&lt;br/&gt;
HFileBlock would not be modified in terms of what is persisted.  In the recent patch that we have worked up on we are just enclosing some of the state variables into a POJO.&lt;br/&gt;
So specifically for tags there are no modifications on HfileBlock.  So there is no need for subclassing HFileBlock or add a new version to the hfileblock.&lt;br/&gt;
&amp;gt;&amp;gt;Based on the Encoding/Decoding context state the Encoder and decoding logic of the algos would handle tags.&lt;br/&gt;
In the previous version of the patches the includeMemstoreTS and the includeTags created changes to the interface apis.  So as to avoid this we enclosed these things inside the Context. Iin the recent patches the context would have the POJO mentioned above).&lt;br/&gt;
So from the context we would be able to get the various decision points like to include tags or not, includememstoreTS or not.&lt;br/&gt;
The encoding apis carry the context but the actual seekers that does the actual decoding does not use contexts.  So we have made changes such that the encoding logic and the seekers use the context related objects. &lt;/p&gt;</comment>
                            <comment id="13730092" author="stack" created="Mon, 5 Aug 2013 22:56:58 +0000"  >&lt;p&gt;On the design doc:&lt;/p&gt;

&lt;p&gt;+ A whole byte to keep the type when the number of types will be small seems profligate in our base type?&lt;br/&gt;
+ Two bytes of length ditto.&lt;/p&gt;

&lt;p&gt;You could save 50% putting type and length together in a short?&lt;/p&gt;

&lt;p&gt;Or is the tag length, the overall tags length?&lt;/p&gt;

&lt;p&gt;What else changed in the design doc?&lt;/p&gt;</comment>
                            <comment id="13730322" author="ram_krish" created="Tue, 6 Aug 2013 04:12:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;Or is the tag length, the overall tags length?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is for individual tag length.  The overall tag length is short still.&lt;br/&gt;
And then we have a byte indicating the tag type.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What else changed in the design doc?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It now adds how we will be using V3 and how it is implemented to avoid more code changes.  It also covers changes done to the existing Encoding/Decoding contexts to implement tags in the DBEs.&lt;/p&gt;</comment>
                            <comment id="13730470" author="ram_krish" created="Tue, 6 Aug 2013 07:21:24 +0000"  >&lt;p&gt;Posted a new RB &lt;a href=&quot;https://reviews.apache.org/r/13311/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/13311/&lt;/a&gt;.  &lt;/p&gt;</comment>
                            <comment id="13734399" author="ram_krish" created="Fri, 9 Aug 2013 05:02:49 +0000"  >&lt;p&gt;I have updated the patch in RB.  Pls share your comments/feedback.&lt;/p&gt;</comment>
                            <comment id="13735173" author="apurtell" created="Fri, 9 Aug 2013 19:26:22 +0000"  >&lt;p&gt;+1 on latest patch. &lt;/p&gt;</comment>
                            <comment id="13736765" author="ram_krish" created="Mon, 12 Aug 2013 11:17:22 +0000"  >&lt;p&gt;Latest patch updated with the current code base in RB (after loadtesttool changes, Datatype changes etc.)&lt;br/&gt;
All testcases passes.&lt;br/&gt;
Tested in cluster with different combinations of Encoding including NONE.&lt;br/&gt;
Tested with and without compression.&lt;br/&gt;
Tested cluster restart scenarios also and tested WAL replay with Tags.&lt;/p&gt;</comment>
                            <comment id="13737068" author="apurtell" created="Mon, 12 Aug 2013 17:20:54 +0000"  >&lt;p&gt;+1 on latest patch&lt;/p&gt;</comment>
                            <comment id="13738499" author="ram_krish" created="Tue, 13 Aug 2013 17:01:08 +0000"  >&lt;p&gt;Latest patch available in RB.  Addresses the review comments on RB.&lt;br/&gt;
It would be great if reviews are done and we could get this in 0.95.2.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt;&lt;br/&gt;
What you guys think?&lt;/p&gt;</comment>
                            <comment id="13740034" author="ram_krish" created="Wed, 14 Aug 2013 18:45:52 +0000"  >&lt;p&gt;Once Stack completes his review will update the patch.  Already updated the patch after Jon&apos;s change went in.  Final updated patch will update after Stack is done with his review.&lt;br/&gt;
Thanks Stack.&lt;/p&gt;</comment>
                            <comment id="13740131" author="stack" created="Wed, 14 Aug 2013 20:22:54 +0000"  >&lt;p&gt;Lads: I made it about half way through the patch up on rb.  I was mostly skimming.  High-level, it has come a long ways.  It is getting close.   It needs some more review cycles I&apos;d say before it can go in but it viable now (where I had my doubts previously).  As RM for 0.96 I am making the call that this will not make the 0.96 cut &amp;#8211; it is too late &amp;#8211; but keep going and get this into trunk and work on getting 0.98 out just after 0.96.  I can help out w/ reviews in a few days after I have 0.95.2 tied off and the first 0.96RC is up; pester others for reviews in meantime.  Good work lads (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopamz&quot; class=&quot;user-hover&quot; rel=&quot;anoopamz&quot;&gt;anoop&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="13750944" author="ram_krish" created="Tue, 27 Aug 2013 04:09:44 +0000"  >&lt;p&gt;An update on this &lt;br/&gt;
Since this feature has moved to 0.98&lt;br/&gt;
-&amp;gt; We have added the HFileContext changes&lt;br/&gt;
-&amp;gt; Done with compression of tags on WAL and HFiles using dictionary (yet to test)&lt;br/&gt;
-&amp;gt; Making tags optional too.&lt;br/&gt;
Will update patch on RB after some more testing. &lt;/p&gt;</comment>
                            <comment id="13762743" author="ram_krish" created="Tue, 10 Sep 2013 05:21:59 +0000"  >&lt;p&gt;Updated the RB Posted a new RB &lt;a href=&quot;https://reviews.apache.org/r/13311/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/13311/&lt;/a&gt;.&lt;br/&gt;
This changes has &lt;br/&gt;
Tags with V3, HFileContext changes and also makes tags optional in V3.&lt;br/&gt;
All testcases passes.  Ran the PE and LoadTestTool in a single machine and a cluster with 4 nodes.&lt;br/&gt;
Ensured that HFiles with Version 2 can be read back with Verions 3 by switching versions.  Request you to provide feedback/reviews so that we can take this into 0.98.&lt;/p&gt;</comment>
                            <comment id="13765700" author="ram_krish" created="Thu, 12 Sep 2013 17:57:33 +0000"  >&lt;p&gt;@Ted&lt;br/&gt;
Thanks for the reviews.  Once  your review is done will update the patch. &lt;/p&gt;</comment>
                            <comment id="13766056" author="yuzhihong@gmail.com" created="Fri, 13 Sep 2013 00:11:49 +0000"  >&lt;p&gt;I am currently on page 5.&lt;br/&gt;
Since HFileContext is used in so many places, it would be nice if HFileContext uses the Builder pattern.&lt;/p&gt;</comment>
                            <comment id="13768053" author="ram_krish" created="Mon, 16 Sep 2013 04:29:46 +0000"  >&lt;p&gt;Addressed few of review comments.  Few more are remaining. Will update a patch shortly.  &lt;br/&gt;
Regarding the Builder pattern, you mind moving it as an improvement?&lt;/p&gt;</comment>
                            <comment id="13768514" author="ram_krish" created="Mon, 16 Sep 2013 17:24:52 +0000"  >&lt;p&gt;@Ted&lt;br/&gt;
Would update the patch soon.&lt;/p&gt;

&lt;p&gt;I would like to get this patch committed soon in trunk.  Any reviews/comments are welcome. &lt;/p&gt;</comment>
                            <comment id="13768585" author="yuzhihong@gmail.com" created="Mon, 16 Sep 2013 18:33:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;Regarding the Builder pattern, you mind moving it as an improvement?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I created a sub-task for the above. I am fine with implementing Builder pattern later.&lt;/p&gt;</comment>
                            <comment id="13771765" author="ram_krish" created="Thu, 19 Sep 2013 10:14:37 +0000"  >&lt;p&gt;Latest patch for tags that addresses the review comments.  &lt;br/&gt;
Tested with 4 nodes (RS and DN) + 1 node (Master and NN).  Ran for about 20 hours without any issues.  Tested various scenarios with and without compression, with and without encoding, reading files with Version V2 and upgrading to V3.  Will attach performance results also.&lt;/p&gt;</comment>
                            <comment id="13771767" author="ram_krish" created="Thu, 19 Sep 2013 10:16:45 +0000"  >&lt;p&gt;Performance report attached.  Shows there is no performance regression with the latest changes. &lt;/p&gt;</comment>
                            <comment id="13771773" author="hadoopqa" created="Thu, 19 Sep 2013 10:22:54 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12604019/Performance_report.xlsx&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12604019/Performance_report.xlsx&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7300//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7300//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13771779" author="ram_krish" created="Thu, 19 Sep 2013 10:33:38 +0000"  >&lt;p&gt;Reattaching for hadoopQA.&lt;/p&gt;</comment>
                            <comment id="13771788" author="ram_krish" created="Thu, 19 Sep 2013 10:52:50 +0000"  >&lt;p&gt;Please prvoide your reviews/comments. Plan to commit this in the next 48hours into trunk/0.98 if there are no objections.&lt;/p&gt;</comment>
                            <comment id="13772621" author="hadoopqa" created="Fri, 20 Sep 2013 04:32:48 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12604194/HBASE-8496_3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12604194/HBASE-8496_3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 185 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7315//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7315//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13772867" author="ram_krish" created="Fri, 20 Sep 2013 08:24:46 +0000"  >&lt;p&gt;Updated patch to make hadoopQA run.&lt;/p&gt;</comment>
                            <comment id="13772920" author="hadoopqa" created="Fri, 20 Sep 2013 10:01:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12604214/HBASE-8496_4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12604214/HBASE-8496_4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 185 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 18 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 8 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7318//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13773179" author="apurtell" created="Fri, 20 Sep 2013 16:58:39 +0000"  >&lt;p&gt;+1 on latest patch&lt;/p&gt;

&lt;p&gt;I filed two subtasks for follow ups along with the builder pattern request from Ted. &lt;/p&gt;</comment>
                            <comment id="13773723" author="ram_krish" created="Sat, 21 Sep 2013 04:41:34 +0000"  >&lt;p&gt;Patch corrects all findbugs and javadoc warnings. Hope the count becomes 0 now.&lt;br/&gt;
All testcases passed except &lt;br/&gt;
testAll(org.apache.hadoop.hbase.thrift.TestThriftServer. Seems unrelated.  Submitting for hadoopQA.&lt;/p&gt;</comment>
                            <comment id="13773739" author="hadoopqa" created="Sat, 21 Sep 2013 06:10:16 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12604374/HBASE-8496_5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12604374/HBASE-8496_5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 185 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7328//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13773756" author="ram_krish" created="Sat, 21 Sep 2013 09:09:06 +0000"  >&lt;p&gt;Updated patch, corrects that single findbug warning. &lt;br/&gt;
Plan to commit this later in the day unless objections.&lt;/p&gt;</comment>
                            <comment id="13773781" author="hadoopqa" created="Sat, 21 Sep 2013 10:31:08 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12604382/HBASE-8496_6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12604382/HBASE-8496_6.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 185 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7330//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13773867" author="ram_krish" created="Sat, 21 Sep 2013 18:10:37 +0000"  >&lt;p&gt;Committed the patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt;_6.patch to trunk.  For reference the performance report has also been attached with this.&lt;br/&gt;
My sincere thanks to Anoop who was pairing up and helped in getting the design, coding to be done.  Thanks to his ideas on HFileContext and his patient code reviews.&lt;br/&gt;
Thanks to Andy for making the design review and helping in various testings.&lt;/p&gt;

&lt;p&gt;Thanks to Stack, Ted, Matt and Jon for their reviews.  &lt;/p&gt;</comment>
                            <comment id="13773881" author="hudson" created="Sat, 21 Sep 2013 19:57:14 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4544 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4544/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4544/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt; - Implement tags and the internals of how a tag should look like (Ram) (ramkrishna: rev 1525269)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Put.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/Tag.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/codec/CellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/CopyKeyDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DiffKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/FastDiffDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultDecodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultEncodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockEncodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/PrefixKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/test/RedundantKVGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestLazyCfLoading.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/DecoderFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArrayReversibleScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArrayScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArraySearcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeCell.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/column/ColumnNodeReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/column/ColumnReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/row/RowNodeReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/PrefixTreeEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/column/ColumnNodeWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/column/ColumnSectionWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/other/ColumnNodeType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/row/RowNodeWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/keyvalue/TestKeyValueTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/column/TestColumnBuilder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowData.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/data/TestRowDataRandomKeyValuesWithTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/data/TestRowDataTrivialWithTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/CellProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Cell.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogPrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/KeyValueCompression.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/CompressionTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HFilePerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TagUsage.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFilePerformance.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/DataBlockEncodingTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCacheOnWriteInSchema.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionServerBulkLoad.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestKeyValueCompression.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALCellCodecWithCompression.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedAction.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedUpdater.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedWriterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/RestartMetaTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadParallel.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/resources/mapred-site.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13773895" author="stack" created="Sat, 21 Sep 2013 20:32:50 +0000"  >&lt;p&gt;Pity.  I wanted to review before it went in.  Any chance of this stuff going into a branch first before it goes on branch?  My fault I did not review before this and don&apos;t want to hold up trunk but might be good to get more eyes on it; there is opportunity here for opening up the hfile/filescanner apis. Thanks.&lt;/p&gt;</comment>
                            <comment id="13773902" author="hudson" created="Sat, 21 Sep 2013 20:48:20 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #751 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/751/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/751/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt; - Implement tags and the internals of how a tag should look like (Ram) (ramkrishna: rev 1525269)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Put.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/Tag.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/codec/CellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/CopyKeyDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DiffKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/FastDiffDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultDecodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultEncodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockEncodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/PrefixKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/test/RedundantKVGenerator.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestLazyCfLoading.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/DecoderFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArrayReversibleScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArrayScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArraySearcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeCell.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/column/ColumnNodeReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/column/ColumnReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/row/RowNodeReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/PrefixTreeEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/column/ColumnNodeWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/column/ColumnSectionWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/other/ColumnNodeType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/row/RowNodeWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/keyvalue/TestKeyValueTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/column/TestColumnBuilder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowData.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/data/TestRowDataRandomKeyValuesWithTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/data/TestRowDataTrivialWithTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/CellProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Cell.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogPrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/KeyValueCompression.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/CompressionTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HFilePerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TagUsage.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFilePerformance.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/DataBlockEncodingTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCacheOnWriteInSchema.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionServerBulkLoad.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestTags.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestKeyValueCompression.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALCellCodecWithCompression.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedAction.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedUpdater.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedWriterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/RestartMetaTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadParallel.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/resources/mapred-site.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13774364" author="hudson" created="Mon, 23 Sep 2013 07:58:27 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4549 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4549/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4549/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt;-Implement tags and the internals of how a tag should look like - Addendum to remove ChecksumFactory.java (Ram) (ramkrishna: rev 1525504)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13774508" author="hudson" created="Mon, 23 Sep 2013 12:32:25 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #756 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/756/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/756/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt;-Implement tags and the internals of how a tag should look like - Addendum to remove ChecksumFactory.java (Ram) (ramkrishna: rev 1525504)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13798309" author="stack" created="Thu, 17 Oct 2013 19:25:28 +0000"  >&lt;p&gt;Shouldn&apos;t this issue have a release note?   I marked it as reviewed and an incompatible change (is that right?).  What should we add to the refguide on tags?  Or, we are not ready to add anything there just yet?&lt;/p&gt;

&lt;p&gt;On the updated design doc:&lt;/p&gt;

&lt;p&gt;There is nothing in the way of altering how tags are currently added, right?  It is just done this way for expediency given so much of the core is still up on KV.&lt;/p&gt;

&lt;p&gt;The below should be 0 or more... right?&lt;/p&gt;

&lt;p&gt;Every KV can have 1 or more tags.&lt;/p&gt;

&lt;p&gt;.... hmm... nevermind the rest of the comments.  It looks like this design doc. is a long way from what was implemented.  np.  We just need a bit of a write up on what went in.... before 0.98.  Can ignore the below.&lt;/p&gt;

&lt;p&gt;On slide #3, every tag has a type byte preceeding it?  On slide #3 you don&apos;t say what a tag is?  Just a run of bytes?&lt;/p&gt;

&lt;p&gt;Oh, so looks like the implementation has deviated from the design, right?  OK.   Is it written up in short form anywhere?  What was implemented?&lt;/p&gt;

&lt;p&gt;The tag structure on slide #5 is different from what is on #3.  On #5 it talks of a tagarray (am I being too literal)?&lt;/p&gt;

&lt;p&gt;Are there big changes between hfilev2 and hfilev3?  They seem small going by this design doc.&lt;/p&gt;


</comment>
                            <comment id="13798775" author="ram_krish" created="Fri, 18 Oct 2013 04:26:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Shouldn&apos;t this issue have a release note? I marked it as reviewed and an incompatible change (is that right?). What should we add to the refguide on tags? Or, we are not ready to add anything there just yet?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I can add a release note and reference guide on tags.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The below should be 0 or more... right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Intention was to say tags can be 1 or more in the sense we support more than 1.  Ya per KV it is 0 or more tags.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It looks like this design doc. is a long way from what was implemented&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The implementation is not much deviated as per the design. But the thing is we added terms like HFileContext just to have a POJO for all the hfile file related attributes.  Mainly that avoids the problem that was once pointed out in the older review requests where inorder to include/exclude tags we were passing booleans in method parameters like how includeMemstoreTS is passed through out the code flow.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On slide #3 you don&apos;t say what a tag is? Just a run of bytes?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I can add them.  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The tag structure on slide #5 is different from what is on #3. On #5 it talks of a tagarray (am I being too literal)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The slide on #3 describes how per KV the tag looks like.  As every KV can have one or more tags we are having a format that gives the length, type and the tag bytes.&lt;br/&gt;
When we write it in the HFile we need to write the total tag length and all the tags that is available. I cannot say that as a different format, it is the way it is persisted in HFile.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Are there big changes between hfilev2 and hfilev3?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agree that the change is not much.  But the fact that changing the exising HFileV2 was looked upon as a risky area for accomodating tags and hence decided to go with V3.&lt;/p&gt;</comment>
                            <comment id="13798802" author="stack" created="Fri, 18 Oct 2013 05:00:51 +0000"  >&lt;p&gt;All is good &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;  Would suggest not spending any more time on the design doc.  Release note would be good.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13798842" author="stack" created="Fri, 18 Oct 2013 06:32:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Why do we not wholesale move to hfilev3?  Why do we have to enable the config?  Why not write all as hfilev3 going forward?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13798868" author="anoop.hbase" created="Fri, 18 Oct 2013 07:16:21 +0000"  >&lt;p&gt;Initially we didnt have ways to make optional tags. Now also if V3 is enabled and writes are with out any tags, during flush we will write extra 2 bytes of tag length (0) with every KV. But later during the compaction this also will get removed. Being available this it might be better to make the default version to 3 so that no need to change explicitely to use tags. I am +1 for that now.&lt;/p&gt;</comment>
                            <comment id="13798870" author="ram_krish" created="Fri, 18 Oct 2013 07:21:29 +0000"  >&lt;p&gt;If that additional 2 bytes in flush is ok we can make the version to v3. +1&lt;/p&gt;</comment>
                            <comment id="13798885" author="anoop.hbase" created="Fri, 18 Oct 2013 07:44:33 +0000"  >&lt;p&gt;Raised &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9801&quot; title=&quot;Change the default HFile version to V3&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9801&quot;&gt;&lt;del&gt;HBASE-9801&lt;/del&gt;&lt;/a&gt; for this.&lt;/p&gt;</comment>
                            <comment id="13799404" author="apurtell" created="Fri, 18 Oct 2013 18:50:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;But the fact that changing the exising HFileV2 was looked upon as a risky area for accomodating tags and hence decided to go with V3.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it makes sense to tag v3 experimental for the 0.98 cycle so it is a safe place for collecting new features, to iron them out.&lt;/p&gt;

&lt;p&gt;Tags may not be the only difference with v3. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7544&quot; title=&quot;Transparent table/CF encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7544&quot;&gt;&lt;del&gt;HBASE-7544&lt;/del&gt;&lt;/a&gt; proposes to add encryption.&lt;/p&gt;</comment>
                            <comment id="13820443" author="hudson" created="Tue, 12 Nov 2013 20:53:09 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #835 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/835/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/835/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9816&quot; title=&quot;Address review comments in HBASE-8496&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9816&quot;&gt;&lt;del&gt;HBASE-9816&lt;/del&gt;&lt;/a&gt;-Address review comments in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt; (Ram) (ramkrishna: rev 1540785)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/Tag.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/CopyKeyDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DiffKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/FastDiffDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/PrefixKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/other/ColumnNodeType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/CompressionTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFilePerformance.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/DataBlockEncodingTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionServerBulkLoad.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13820544" author="hudson" created="Tue, 12 Nov 2013 22:15:28 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4678 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4678/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4678/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9816&quot; title=&quot;Address review comments in HBASE-8496&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9816&quot;&gt;&lt;del&gt;HBASE-9816&lt;/del&gt;&lt;/a&gt;-Address review comments in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt; (Ram) (ramkrishna: rev 1540785)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/Tag.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/CopyKeyDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DiffKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/FastDiffDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/PrefixKeyDeltaEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/encode/other/ColumnNodeType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/CompressionTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFilePerformance.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/DataBlockEncodingTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionServerBulkLoad.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15016427" author="lars_francke" created="Fri, 20 Nov 2015 11:55:13 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12674960">HBASE-9816</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12674462">HBASE-9801</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12633453">HBASE-7897</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12560859">HBASE-6222</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12627246">HBASE-7544</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12594219" name="Comparison.pdf" size="51591" author="ram_krish" created="Thu, 25 Jul 2013 18:14:36 +0000"/>
                            <attachment id="12594213" name="HBASE-8496.patch" size="344724" author="ram_krish" created="Thu, 25 Jul 2013 17:59:31 +0000"/>
                            <attachment id="12594548" name="HBASE-8496_2.patch" size="344152" author="ram_krish" created="Sat, 27 Jul 2013 17:44:49 +0000"/>
                            <attachment id="12604194" name="HBASE-8496_3.patch" size="592798" author="ram_krish" created="Fri, 20 Sep 2013 04:23:27 +0000"/>
                            <attachment id="12604022" name="HBASE-8496_3.patch" size="592798" author="ram_krish" created="Thu, 19 Sep 2013 10:33:38 +0000"/>
                            <attachment id="12604018" name="HBASE-8496_3.patch" size="592798" author="ram_krish" created="Thu, 19 Sep 2013 10:14:37 +0000"/>
                            <attachment id="12604214" name="HBASE-8496_4.patch" size="593236" author="ram_krish" created="Fri, 20 Sep 2013 08:24:46 +0000"/>
                            <attachment id="12604374" name="HBASE-8496_5.patch" size="595547" author="ram_krish" created="Sat, 21 Sep 2013 04:41:34 +0000"/>
                            <attachment id="12604382" name="HBASE-8496_6.patch" size="595807" author="ram_krish" created="Sat, 21 Sep 2013 09:09:06 +0000"/>
                            <attachment id="12604019" name="Performance_report.xlsx" size="28993" author="ram_krish" created="Thu, 19 Sep 2013 10:16:45 +0000"/>
                            <attachment id="12589731" name="Tag design.pdf" size="121112" author="ram_krish" created="Wed, 26 Jun 2013 10:01:46 +0000"/>
                            <attachment id="12595730" name="Tag design_updated.pdf" size="47301" author="ram_krish" created="Sat, 3 Aug 2013 03:44:44 +0000"/>
                            <attachment id="12594547" name="Tag_In_KV_Buffer_For_reference.patch" size="310080" author="ram_krish" created="Sat, 27 Jul 2013 17:43:22 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12660112">HBASE-9045</subtask>
                            <subtask id="12660191">HBASE-9056</subtask>
                            <subtask id="12660192">HBASE-9057</subtask>
                            <subtask id="12661457">HBASE-9118</subtask>
                            <subtask id="12662057">HBASE-9136</subtask>
                            <subtask id="12662085">HBASE-9137</subtask>
                            <subtask id="12668837">HBASE-9546</subtask>
                            <subtask id="12669688">HBASE-9595</subtask>
                            <subtask id="12669694">HBASE-9596</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>13.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 May 2013 03:30:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326507</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbun:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326852</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tags are additional metadata to be added with the KVs.  &lt;br/&gt;
To enable the tags to be persisted in the HFiles, V3 version of HFile should be used.&lt;br/&gt;
&amp;lt;property&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;lt;name&amp;gt;hfile.format.version&amp;lt;/name&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;lt;/property&amp;gt;&lt;br/&gt;
The tags has the below format&lt;br/&gt;
&amp;lt;2 byte tag length&amp;gt;&amp;lt;1 byte type code&amp;gt;&amp;lt;tag&amp;gt;&lt;br/&gt;
where &amp;lt;type&amp;gt; is the type of the tag, &amp;lt;tag&amp;gt; is a byte[] that has the tag data.&lt;br/&gt;
To add Tags using Puts&lt;br/&gt;
Put.add(byte[] family, byte [] qualifier, byte [] value, Tag[] tag)&lt;br/&gt;
Put.add(byte[] family, byte[] qualifier, long ts, byte[] value, Tag[] tag)&lt;br/&gt;
Can be used.&lt;br/&gt;
Note that even after changing the version to V3, the no-tag case will also be working fine as in V2 format. &lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>