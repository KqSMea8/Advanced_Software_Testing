<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:29:53 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12116/HBASE-12116.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12116] Hot contention spots; writing</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12116</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Playing with flight recorder, here are some write-time contentious synchronizations/locks (picture coming)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12744825">HBASE-12116</key>
            <summary>Hot contention spots; writing</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 30 Sep 2014 00:11:39 +0000</created>
                <updated>Thu, 28 Apr 2016 16:45:07 +0000</updated>
                                                            <fixVersion>2.0.0</fixVersion>
                                    <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>16</watches>
                                                                                                            <comments>
                            <comment id="14152576" author="stack" created="Tue, 30 Sep 2014 00:14:03 +0000"  >&lt;p&gt;Let me address first few in this list.&lt;/p&gt;</comment>
                            <comment id="14152581" author="eclark" created="Tue, 30 Sep 2014 00:16:52 +0000"  >&lt;p&gt;I assume that properties is coming from hadoop&apos;s config ?&lt;/p&gt;</comment>
                            <comment id="14152726" author="apurtell" created="Tue, 30 Sep 2014 02:28:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;I assume that properties is coming from hadoop&apos;s config ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If so see also &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12117&quot; title=&quot;Constructors that use Configuration may be harmful&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12117&quot;&gt;HBASE-12117&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14152857" author="stack" created="Tue, 30 Sep 2014 06:36:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; Sample was for 5 minutes.  There is a small bit of getting values from configuration which does getProperty but main culprit here is not very interesting... its stringifying exceptions (Was throwing loads of NSRE around sample time).  Let me get a better sampling.&lt;/p&gt;

&lt;p&gt;This tool seems to do better job reporting CPU use, or at least, agrees that CRC is the main consumer of CPU as per our flame graph experiments.  Hopefully its good reporting contention. Has a dtrace plugin.  Let me see if can get that to work....&lt;/p&gt;

</comment>
                            <comment id="14152914" author="stack" created="Tue, 30 Sep 2014 07:53:42 +0000"  >&lt;p&gt;Some small items of contention; cache the max row size so we don&apos;t look it up each time which is contentious when lots of threads reading and then stringify exception has us resizing backing array repeatedly which shows in the sampling window I ran because many NSREs going on.&lt;/p&gt;</comment>
                            <comment id="14153970" author="stack" created="Tue, 30 Sep 2014 23:05:57 +0000"  >&lt;p&gt;Small potatoes changes reviewing contention writing.&lt;/p&gt;

&lt;p&gt;Only one of significance is the TimeRangeTracker and even then only if we are pounding one column family.&lt;/p&gt;

&lt;p&gt;Other changes avoid reading Configuration on each scanner construction &amp;#8211; this is read side to avoid contending on the Properties instance that backs hadoop Configuration and a minor presizing of StringWriter so we avoid resizing which gets contended in my little samples.&lt;/p&gt;

&lt;p&gt;The above are small potatoes.&lt;/p&gt;</comment>
                            <comment id="14154382" author="stack" created="Wed, 1 Oct 2014 05:39:24 +0000"  >&lt;p&gt;Don&apos;t check for replica count after every successful sync.  They cost, especially when contention as all threads pile up on DFSOutputStream synchronized get replicas count.&lt;/p&gt;</comment>
                            <comment id="14154384" author="stack" created="Wed, 1 Oct 2014 05:41:13 +0000"  >&lt;p&gt;Picture showing how some calls to getNumCurrentReplicas can cost.&lt;/p&gt;

&lt;p&gt;Testing the previous patch, I see TimeRangeTracker is better but still can cause pileups.&lt;/p&gt;</comment>
                            <comment id="14154407" author="anoop.hbase" created="Wed, 1 Oct 2014 05:58:22 +0000"  >&lt;p&gt;As we work with TRT here Stack&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
   * Update the current TimestampRange to include the timestamp from Key.
   * If the Key is of type DeleteColumn or DeleteFamily, it includes the
   * entire time range from 0 to timestamp of the key.
   * @param key
   */
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void includeTimestamp(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] key) {
    includeTimestamp(Bytes.toLong(key,key.length-KeyValue.TIMESTAMP_TYPE_SIZE));
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; type = key[key.length - 1];
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (type == Type.DeleteColumn.getCode() ||
        type == Type.DeleteFamily.getCode()) {
      includeTimestamp(0);
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This above can be removed. This is not used by any one and it expects the KV style key format.&lt;/p&gt;</comment>
                            <comment id="14154418" author="anoop.hbase" created="Wed, 1 Oct 2014 06:06:59 +0000"  >&lt;p&gt;On the TRT patch&lt;br/&gt;
For the 1st time call on includeTimestamp () we need set the minimumTimestamp and maximumTimestamp to the give ts no?&lt;br/&gt;
If the includeTimestamp () call happens in a decreasing ts way you can see the min value will get changed all the time and the max will never change and be at -1 always !&lt;/p&gt;</comment>
                            <comment id="14155109" author="stack" created="Wed, 1 Oct 2014 16:58:49 +0000"  >&lt;p&gt;Thanks for review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;.  It seems highly unlikely timestamps would go in reverse but let me fix.&lt;/p&gt;

&lt;p&gt;On TRT, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; suggests doing below to cut down on need for synchronization:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void includeTimestamp(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timestamp) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (maximumTimestamp == -1) {
      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (maximumTimestamp == -1) {
          minimumTimestamp = timestamp;
          maximumTimestamp = timestamp;
        }
      }
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (minimumTimestamp &amp;gt; timestamp) {
      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (minimumTimestamp &amp;gt; timestamp) {
          minimumTimestamp = timestamp;
        }
      }
    }
    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (maximumTimestamp &amp;lt; timestamp) {
      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (maximumTimestamp &amp;lt; timestamp) {
          maximumTimestamp = timestamp;
        }
      }
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let me measure it. Let me make a subissue and measure.&lt;/p&gt;</comment>
                            <comment id="14493084" author="stack" created="Mon, 13 Apr 2015 21:05:37 +0000"  >&lt;p&gt;A few flame graphs doing sequential writes of 1M by 50 clients run on 5 different machines. Cells are zipfian 0-1024 bytes in size. Source is perf recording.&lt;/p&gt;

&lt;p&gt;Mostly GC. Next is CRC and unsafe compareto from memstore.&lt;/p&gt;

&lt;p&gt;Attached is associated flight recorder taken just after. It fingers our sending of exceptions back to client as expensive beyond compareto and crc.&lt;/p&gt;</comment>
                            <comment id="14493630" author="stack" created="Tue, 14 Apr 2015 06:07:29 +0000"  >&lt;p&gt;Esteban and I did some messing with a YCSB pure write load this afternoon. We got to a place where the four disks were saturated writing (CPU was not). Here&apos;s a few notes from the session:&lt;/p&gt;

&lt;p&gt;+ Esteban found that upping ringbuffer slot count helped; default is 16k.. he was running at 512k (hbase.regionserver.wal.disruptor.event.count). Also said deferred sync helped too.&lt;br/&gt;
+ Would be good to figure how to do bigger writes so we get more on disk per op.&lt;br/&gt;
+ Adding to CSLM doPut, CRC, and compares are the big consumers of CPU (apart from G1GC) according to perf (see below), no surprise. Flight Recorder has CRC and unsafe compareto at 20% each, then CSLM#doPut at 12%.&lt;br/&gt;
+ Minors but interesting (according to FR) are ByteBloomFilter#set... could do with a tune up (the BB#gets are showing as 3.5% &amp;#8211; unsafe it). The murmur hashing shows up as a percent too (look at faster implementaitons &amp;#8211; guava?). We has ACL audit on. Thats 2% of CPU according to perf.&lt;/p&gt;

&lt;p&gt;Perf top during run.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
6.53%  perf-18890.map      [.] Ljava/util/concurrent/ConcurrentSkipListMap;.doPut
  5.78%  libjvm.so          [.] OtherRegionsTable::add_reference(void*, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
  4.14%  perf-18890.map      [.] Lorg/apache/hadoop/util/PureJavaCrc32;.update
  3.27%  libjvm.so          [.] G1RemSet::refine_card(signed &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, bool)
  2.99%  libjvm.so          [.] G1ParCopyClosure&amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, (G1Barrier)2, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;gt;::copy_to_survivor_space(oopDesc*)
  2.90%  libjvm.so          [.] G1BlockOffsetArrayContigSpace::block_start_unsafe(void &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;*)
  2.69%  libjvm.so          [.] HeapRegion::oops_on_card_seq_iterate_careful(MemRegion, FilterOutOfRegionClosure*, bool, signed &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*)
  2.66%  libc-2.12.so        [.] memcpy
  2.54%  perf-18890.map      [.] Lorg/apache/hadoop/hbase/KeyValue$KVComparator;.compare
  2.54%  libjvm.so          [.] void G1ParCopyClosure&amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, (G1Barrier)2, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;gt;::do_oop_work&amp;lt;unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt;(unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;*)
  2.09%  perf-18890.map      [.] jbyte_disjoint_arraycopy
  1.84%  libjvm.so          [.] instanceKlass::oop_oop_iterate_backwards_nv(oopDesc*, G1ParScanClosure*)
  1.71%  libjvm.so          [.] G1ParScanThreadState::trim_queue()
  1.63%  libjvm.so          [.] SparsePRT::add_card(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
  1.43%  libjvm.so          [.] G1BlockOffsetArray::forward_to_block_containing_addr_const(HeapWord*, HeapWord*, void &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;*) &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;
  1.39%  perf-18890.map      [.] Lorg/apache/hadoop/hbase/util/Bytes$LexicographicalComparerHolder$UnsafeComparer;.compareTo
  1.35%  libc-2.12.so        [.] vfprintf
  1.23%  perf-18890.map      [.] Lorg/apache/hadoop/fs/FSDataOutputStream$PositionCache;.write
  1.12%  libjvm.so          [.] G1UpdateRSOrPushRefOopClosure::do_oop(unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;*)
  1.09%  libjvm.so          [.] instanceKlass::oop_oop_iterate_nv(oopDesc*, FilterOutOfRegionClosure*)
  1.09%  libjvm.so          [.] G1SATBCardTableModRefBS::mark_card_deferred(unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)
  1.04%  libjvm.so          [.] HeapRegionDCTOC::walk_mem_region_with_cl(MemRegion, HeapWord*, HeapWord*, OopClosure*)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14494162" author="apurtell" created="Tue, 14 Apr 2015 14:32:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;We has ACL audit on. Thats 2% of CPU according to perf.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;AccessController? Let&apos;s look, but 2-3% of perf is performance to design expectations, so that&apos;s actually good&lt;/p&gt;</comment>
                            <comment id="14494176" author="apurtell" created="Tue, 14 Apr 2015 14:42:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;CSLM#doPut at 12%&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Revive the CSLM alternative JIRAs? (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3484&quot; title=&quot;Replace memstore&amp;#39;s ConcurrentSkipListMap with our own implementation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3484&quot;&gt;HBASE-3484&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3993&quot; title=&quot;Alternatives to ConcurrentSkipListMap in MemStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3993&quot;&gt;HBASE-3993&lt;/a&gt; (+subtasks), &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10713&quot; title=&quot;A MemStore implementation with in memory flushes to CellBlocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10713&quot;&gt;&lt;del&gt;HBASE-10713&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="14494185" author="apurtell" created="Tue, 14 Apr 2015 14:52:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;CRC and unsafe compareto at 20% each&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Assumed this is with HBase doing its own checksumming. If we know we have DFSInputStream#read variants that accept BBs (and zero copy read under the covers), then we could move all reads over to this interface, check if Hadoop&apos;s native CRC (&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10838&quot; title=&quot;Byte array native checksumming&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10838&quot;&gt;&lt;del&gt;HADOOP-10838&lt;/del&gt;&lt;/a&gt;) is available to us, and if so run it over the contents of the BBs we get from HDFS? We&apos;d need 2.6.0 as the floor of Hadoop support so maybe do this in trunk for 2.0? &lt;/p&gt;</comment>
                            <comment id="14494226" author="apurtell" created="Tue, 14 Apr 2015 15:12:09 +0000"  >&lt;p&gt;I know you were just using YCSB as a load generator but if playing with YCSB you might find this interesting: &lt;a href=&quot;https://github.com/apurtell/YCSB2/tree/new_hbase_client&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apurtell/YCSB2/tree/new_hbase_client&lt;/a&gt;&lt;br/&gt;
Blog post on coordinated omission corrections in this version: &lt;a href=&quot;http://psy-lob-saw.blogspot.co.at/2015/03/fixing-ycsb-coordinated-omission.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://psy-lob-saw.blogspot.co.at/2015/03/fixing-ycsb-coordinated-omission.html&lt;/a&gt; (TL;DR: Use -target and -p measurementtype=hdrhistogram. Optionally,-p  hdrhistogram.fileoutput=&amp;lt;true|false&amp;gt; -p hdrhistogram.output.path=&amp;lt;path&amp;gt; and &lt;a href=&quot;https://github.com/HdrHistogram/HdrHistogram/blob/master/HistogramLogProcessor&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HistogramLogProcessor&lt;/a&gt; and &lt;a href=&quot;https://github.com/HdrHistogram/HdrHistogram/blob/master/GoogleChartsExample/plotFiles.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;plotFiles&lt;/a&gt; to plot latency by percentile.)&lt;br/&gt;
I&apos;ve been meaning to try it out. &lt;/p&gt;</comment>
                            <comment id="14494360" author="esteban" created="Tue, 14 Apr 2015 16:34:34 +0000"  >&lt;p&gt;Good stuff &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;!. I&apos;ll try this out today.&lt;/p&gt;</comment>
                            <comment id="14494434" author="stack" created="Tue, 14 Apr 2015 17:23:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; Chatting w/ Esteban, its an audit CP that is run in CDH.  Yeah on CSLM worth digging in on &amp;#8211; big payback especially if can save a f few compares (in // with work to compress CSLM snapshots). On CRC, have work to do in HDFS if we want to continue doing our own CRC on read path so can read blocks that have been natively CRC&apos;d and decompressed all offheap. On write path ditto (more awkward here even given no BB interface at write time). A hbase native lib to do native CRC and compression so not tied to a particular HDFS version would be crazy?, Or have HDFS do the checksum for us again (CPU for an extra seek &amp;#8211; ok if SSD).&lt;/p&gt;
</comment>
                            <comment id="14494454" author="apurtell" created="Tue, 14 Apr 2015 17:33:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;Chatting w/ Esteban, its an audit CP that is run in CDH&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ah, well 2% for audit is still not bad. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On write path ditto (more awkward here even given no BB interface at write time). &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yep, but if raising the floor of supported Hadoop version on trunk, maybe we could work up something together with HDFS for a 2.0 release timeframe. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A hbase native lib to do native CRC and compression so not tied to a particular HDFS version would be crazy?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure, if taking on checksumming at our layer instead of pushing off to HDFS is something we still want to do. I think it still makes sense, we trade complexity in our code for a big cut in IOPS needed for reading. Native bits in HBase should be optional and have a Java only fallback, native code is a PITA for deployment, even if compiled for the correct architecture we may fail to dlopen if native symbol versioning gets in the way.&lt;/p&gt;</comment>
                            <comment id="14496031" author="nkeywal" created="Wed, 15 Apr 2015 10:49:55 +0000"  >&lt;p&gt;I had a look at crc a while ago.&lt;br/&gt;
My understanding back then was that there are specific instruction in x86 processors to calculate crc, unfortunately a little bit different than the standard crc32. When I was looking at Intel/Hadoop roadmap 2 years ago, it looked like Intel was planning to do the changes in hadoop to use the hw one.&lt;/p&gt;

&lt;p&gt;There is some info here: &lt;a href=&quot;http://www.strchr.com/crc32_popcnt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.strchr.com/crc32_popcnt&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12672254" name="12116.checkForReplicas.txt" size="2372" author="stack" created="Wed, 1 Oct 2014 05:39:24 +0000"/>
                            <attachment id="12671989" name="12116.stringify.and.cache.scanner.maxsize.txt" size="26414" author="stack" created="Tue, 30 Sep 2014 07:53:42 +0000"/>
                            <attachment id="12672185" name="12116.txt" size="30609" author="stack" created="Tue, 30 Sep 2014 23:05:57 +0000"/>
                            <attachment id="12671922" name="Screen Shot 2014-09-29 at 5.12.51 PM.png" size="255148" author="stack" created="Tue, 30 Sep 2014 00:14:03 +0000"/>
                            <attachment id="12672255" name="Screen Shot 2014-09-30 at 10.39.34 PM.png" size="117416" author="stack" created="Wed, 1 Oct 2014 05:41:13 +0000"/>
                            <attachment id="12725049" name="Screen Shot 2015-04-13 at 2.03.05 PM.png" size="481389" author="stack" created="Mon, 13 Apr 2015 21:05:37 +0000"/>
                            <attachment id="12725048" name="perf.write3.svg" size="568549" author="stack" created="Mon, 13 Apr 2015 21:05:37 +0000"/>
                            <attachment id="12725047" name="perf.write4.svg" size="476074" author="stack" created="Mon, 13 Apr 2015 21:05:37 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12745376">HBASE-12148</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 30 Sep 2014 00:16:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 35 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i20m33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>