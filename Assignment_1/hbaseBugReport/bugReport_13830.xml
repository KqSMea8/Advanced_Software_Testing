<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:47:04 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-13830/HBASE-13830.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-13830] Hbase REVERSED may throw Exception sometimes</title>
                <link>https://issues.apache.org/jira/browse/HBASE-13830</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;run a scan at hbase shell command.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scan &apos;analytics_access&apos;,{ENDROW=&amp;gt;&apos;9223370603647713262-flume01.hadoop-10.32.117.111-373563509&apos;,LIMIT=&amp;gt;10,REVERSED=&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;will throw exception&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.io.IOException: java.io.IOException: Could not seekToPreviousRow StoreFileScanner[HFileScanner &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; reader reader=hdfs:&lt;span class=&quot;code-comment&quot;&gt;//nameservice1/hbase/data/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/analytics_access/a54c47c568c00dd07f9d92cfab1accc7/cf/2e3a107e9fec4930859e992b61fb22f6, compression=lzo, cacheConf=CacheConfig:enabled [cacheDataOnRead=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;] [cacheDataOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheIndexesOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheBloomsOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheEvictOnClose=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheCompressed=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;], firstKey=9223370603542781142-flume01.hadoop-10.32.117.111-378180911/cf:key/1433311994702/Put, lastKey=9223370603715515112-flume01.hadoop-10.32.117.111-370923552/cf:timestamp/1433139261951/Put, avgKeyLen=80, avgValueLen=115, entries=43544340, length=1409247455, cur=9223370603647710245-flume01.hadoop-10.32.117.111-373563545/cf:payload/1433207065597/Put/vlen=644/mvcc=0] to key 9223370603647710245-flume01.hadoop-10.32.117.111-373563545/cf:payload/1433207065597/Put/vlen=644/mvcc=0
&lt;/span&gt;	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:448)
	at org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.seekToPreviousRow(ReversedKeyValueHeap.java:88)
	at org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.seekToPreviousRow(ReversedStoreScanner.java:128)
	at org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.seekToNextRow(ReversedStoreScanner.java:88)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:503)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:140)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:3866)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3946)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:3814)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:3805)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3136)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29497)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2012)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.io.IOException: On-disk size without header provided is 47701, but block header contains 10134. Block offset: -1, data starts with: DATABLK*\x00\x00&apos;\x96\x00\x01\x00\x04\x00\x00\x00\x005\x96^\xD2\x01\x00\x00@\x00\x00\x00&apos;
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.validateOnDiskSizeWithoutHeader(HFileBlock.java:451)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.access$400(HFileBlock.java:87)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1466)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1314)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:355)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(HFileReaderV2.java:569)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:413)
	... 17 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.6.0_65]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) ~[na:1.6.0_65]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) ~[na:1.6.0_65]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513) ~[na:1.6.0_65]
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) ~[hadoop-common-2.3.0-cdh5.1.0.jar:na]
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95) ~[hadoop-common-2.3.0-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:284) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:198) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:57) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:114) [hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:90) [hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:336) [hbase-client-0.98.1-cdh5.1.0.jar:na]
	at com.saic.bigdata.storm.test.HbaseGet2.main(HbaseGet2.java:29) [test-classes/:na]
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException: java.io.IOException: Could not seekToPreviousRow StoreFileScanner[HFileScanner &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; reader reader=hdfs:&lt;span class=&quot;code-comment&quot;&gt;//nameservice1/hbase/data/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/analytics_access/a54c47c568c00dd07f9d92cfab1accc7/cf/2e3a107e9fec4930859e992b61fb22f6, compression=lzo, cacheConf=CacheConfig:enabled [cacheDataOnRead=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;] [cacheDataOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheIndexesOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheBloomsOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheEvictOnClose=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheCompressed=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;], firstKey=9223370603542781142-flume01.hadoop-10.32.117.111-378180911/cf:key/1433311994702/Put, lastKey=9223370603715515112-flume01.hadoop-10.32.117.111-370923552/cf:timestamp/1433139261951/Put, avgKeyLen=80, avgValueLen=115, entries=43544340, length=1409247455, cur=9223370603647710245-flume01.hadoop-10.32.117.111-373563545/cf:payload/1433207065597/Put/vlen=644/mvcc=0] to key 9223370603647710245-flume01.hadoop-10.32.117.111-373563545/cf:payload/1433207065597/Put/vlen=644/mvcc=0
&lt;/span&gt;	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:448)
	at org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.seekToPreviousRow(ReversedKeyValueHeap.java:88)
	at org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.seekToPreviousRow(ReversedStoreScanner.java:128)
	at org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.seekToNextRow(ReversedStoreScanner.java:88)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:503)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:140)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:3866)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3946)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:3814)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:3805)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3136)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29497)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2012)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.io.IOException: On-disk size without header provided is 47701, but block header contains 10134. Block offset: -1, data starts with: DATABLK*\x00\x00&apos;\x96\x00\x01\x00\x04\x00\x00\x00\x005\x96^\xD2\x01\x00\x00@\x00\x00\x00&apos;
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.validateOnDiskSizeWithoutHeader(HFileBlock.java:451)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.access$400(HFileBlock.java:87)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1466)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1314)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:355)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(HFileReaderV2.java:569)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:413)
	... 17 more

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1453) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1657) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1715) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:29900) ~[hbase-protocol-0.98.1-cdh5.1.0.jar:na]
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:168) ~[hbase-client-0.98.1-cdh5.1.0.jar:na]
	... 5 common frames omitted
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12834976">HBASE-13830</key>
            <summary>Hbase REVERSED may throw Exception sometimes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sunny.davy">ryan.jin</reporter>
                        <labels>
                    </labels>
                <created>Wed, 3 Jun 2015 09:17:38 +0000</created>
                <updated>Mon, 7 Nov 2016 15:17:07 +0000</updated>
                                            <version>0.98.1</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="14652873" author="benlau" created="Tue, 4 Aug 2015 00:52:18 +0000"  >&lt;p&gt;Hey Ryan, do you have more information on this bug.  We are interested in using the reverse scan feature at Yahoo and would like to clear up any known bugs before internal users take it up for production use.  If you had for example an independent program and/or data that could be used to reproduce this issue, we would like to see it.  If you cannot reproduce the bug anymore, we&apos;d like to know anything else you remember, like the version of HDFS, any custom patches you had on your version of HBase, the table schema at the time (eg any particular block encodings), etc.&lt;/p&gt;</comment>
                            <comment id="14707111" author="benlau" created="Fri, 21 Aug 2015 17:39:46 +0000"  >&lt;p&gt;Possibly the same bug as in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14283&quot; title=&quot;Reverse scan doesn&#8217;t work with HFile inline index/bloom blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14283&quot;&gt;&lt;del&gt;HBASE-14283&lt;/del&gt;&lt;/a&gt;, or related.&lt;/p&gt;</comment>
                            <comment id="15643754" author="nilsmagnus@gmail.com" created="Mon, 7 Nov 2016 10:23:41 +0000"  >&lt;p&gt;I still run into this issue, using hbase-client 1.2.3&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.io.IOException: On-disk size without header provided is 142128, but block header contains 10929. Block offset: -1, data starts with: DATABLK*\x00\x00*\xB1\x00\x01\x00\x1A\x00\x00\x00\x00\x02\x0E&quot;w\x01\x00\x00@\x00\x00\x00*
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.validateOnDiskSizeWithoutHeader(HFileBlock.java:500)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.access$700(HFileBlock.java:85)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockDataInternal(HFileBlock.java:1625)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockData(HFileBlock.java:1470)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:437)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(HFileReaderV2.java:673)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(HFileReaderV2.java:646)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:425)
	... 13 more

	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1267) ~[hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) ~[hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) ~[hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) ~[hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:219) ~[hbase-client-1.2.3.jar:1.2.3]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I get this on large results, when repeatedly calling next( n ) on the result-scanner to fetch more values. &lt;/p&gt;

&lt;p&gt;Edit: ignore this, the hbase-version I used when getting this was outdated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Aug 2015 00:52:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2fkdb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>