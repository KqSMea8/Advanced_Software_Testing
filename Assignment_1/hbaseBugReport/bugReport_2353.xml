<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:01:09 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2353/HBASE-2353.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2353] HBASE-2283 removed bulk sync optimization for multi-row puts</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2353</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;previously to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt; we used to call flush/sync once per put(Put[]) call (ie: batch of commits).  Now we do for every row.  &lt;/p&gt;

&lt;p&gt;This makes bulk uploads slower if you are using WAL.  Is there an acceptable solution to achieve both safety and performance by bulk-sync&apos;ing puts?  Or would this not work in face of atomic guarantees?&lt;/p&gt;

&lt;p&gt;discuss!&lt;/p&gt;</description>
                <environment></environment>
        <key id="12459817">HBASE-2353</key>
            <summary>HBASE-2283 removed bulk sync optimization for multi-row puts</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="ryanobjc">ryan rawson</reporter>
                        <labels>
                            <label>moved_from_0_20_5</label>
                    </labels>
                <created>Mon, 22 Mar 2010 03:11:18 +0000</created>
                <updated>Fri, 20 Nov 2015 12:43:56 +0000</updated>
                            <resolved>Sun, 13 Jun 2010 18:55:42 +0000</resolved>
                                                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="12848059" author="apurtell" created="Mon, 22 Mar 2010 08:31:27 +0000"  >&lt;p&gt;I believe this also affects 0.20 branch as both group commit and 2283 were backported, so 2283 would have clobbered group commit on branch also.&lt;/p&gt;</comment>
                            <comment id="12848229" author="kannanm" created="Mon, 22 Mar 2010 17:47:10 +0000"  >
&lt;p&gt;The important thing is that memstore edits should happen after append+sync.&lt;/p&gt;

&lt;p&gt;Currently, batch put is simply a loop around append/sync/memstore-edit per put.&lt;/p&gt;

&lt;p&gt;If we tried to move to a model, where we first do append for each row, then a common sync, and then all the memstore changes-- then we would end up having to &quot;lock&quot; all the rows for the entire duration; (rather than the current model, which locks one row at a time.)&lt;/p&gt;

&lt;p&gt;Also, the code structure would get uglier I think &amp;#8211; right now batch put pretty much is a thin wrapper around single Puts.&lt;/p&gt;

&lt;p&gt;This was a conscious change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt; for restoring correctness of semantics. But I should have perhaps called it out explicitly.&lt;/p&gt;

&lt;p&gt;@Ryan: Is the bulk upload case now noticeably slower?&lt;/p&gt;

&lt;p&gt;@Andrew: You are right that this affects 0.20 also. But you might be mixing the &quot;group commit&quot; and &quot;multi-row put&quot; terminology. Group commit should not have been cloberred by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt;. But yes, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt; does remove, for correctness, the &quot;batch sync&quot; optimization in multi-row puts.&lt;/p&gt;
</comment>
                            <comment id="12848231" author="kannanm" created="Mon, 22 Mar 2010 17:48:29 +0000"  >&lt;p&gt;update the title of the bug to be more specific.&lt;/p&gt;</comment>
                            <comment id="12848462" author="stack" created="Tue, 23 Mar 2010 00:13:57 +0000"  >&lt;p&gt;@Ryan What if for batch put, first we wrote all that is in the batch out to the WAL and then per edit, you called the individual put method but with the do-not-WAL flag set to true?  Would that get you your speed back?  But how to treat errors?  What do you tell the client if you&apos;ve written the WAL but you fail to update memstore?  How were errors treated previously?  Seems like you have to reason about this stuff on a row by row basis?&lt;/p&gt;</comment>
                            <comment id="12848464" author="tlipcon" created="Tue, 23 Mar 2010 00:18:19 +0000"  >&lt;p&gt;Under what scenarios would you fail to update memstore? It seems to me that those scenarios necessitate a full RS stop.&lt;/p&gt;</comment>
                            <comment id="12848468" author="ryanobjc" created="Tue, 23 Mar 2010 00:26:35 +0000"  >&lt;p&gt;the existing code has a return code interpreted as &apos;failed past index&lt;br/&gt;
i&apos; and the client will retry a number of times.  so that might work.&lt;/p&gt;
</comment>
                            <comment id="12848539" author="stack" created="Tue, 23 Mar 2010 04:24:06 +0000"  >&lt;p&gt;.bq Under what scenarios would you fail to update memstore? It seems to me that those scenarios necessitate a full RS stop. &lt;/p&gt;

&lt;p&gt;I suppose, i was thinking memstore update would fail because the RS had crashed/stopped.  Can&apos;t think of any reason we&apos;d part fail.  Client wouldn&apos;t get a return code though edits had gone in because the bulk put had not completed (client would see an exception).&lt;/p&gt;

&lt;p&gt;Then there is the case where we add N of the M edits to the WAL file before we hit some HDFS issue that forces us return to the client.  In this case, wouldn&apos;t you have to report the bulk put had completely failed since edits had no edits had made it to the MemStore?&lt;/p&gt;

&lt;p&gt;It seems like you have to process the bulk put, row by row.&lt;/p&gt;
</comment>
                            <comment id="12848987" author="ryanobjc" created="Wed, 24 Mar 2010 00:53:44 +0000"  >&lt;p&gt;I have new numbers, basically my bulk puts are now much slower than previously.  This is a killer for us.  Single thread import performance is now down to 2000-6000 rows/sec, down from 16,000+.  &lt;/p&gt;

&lt;p&gt;The first fix to this is to bring back deferred log flush.  I have a forthcoming patch. &lt;/p&gt;

&lt;p&gt;Here are my arguments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;There is no multi-row atomicity guarantee. Having other clients see the partial results of your batch put is acceptable because that is our consistency model - per row. That is the defacto situation right now anyways.&lt;/li&gt;
	&lt;li&gt;If the call succeeds, then we expect the puts to be durable.  By ensuring syncFs() call returns before returning to the client we have this.&lt;/li&gt;
	&lt;li&gt;Partial failure by exception leaves the HLog in an uncertain state.  The client will not know how many rows were successfully made durable, and thus would be required to redo the put.&lt;/li&gt;
	&lt;li&gt;Partial &quot;failure&quot; by return code means only part of the rows were made durable and available to other clients.  This is normal and covered by the above cases I think.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Given this, what makes the most sense?  It seems like hlog.append() then syncFs() of all the puts, THEN memstore mutate is the way to go. In HRS.put our protection from &apos;over memory&apos; is this call :&lt;/p&gt;

&lt;p&gt;        this.cacheFlusher.reclaimMemStoreMemory();&lt;/p&gt;

&lt;p&gt;which will synchronously flush until we arent going to go over memory.  If we somehow fail to add to memstore, it would be OOME which would kill the RS anyways.  Considering the data for the Put is already in memory and we are just adjusting data structure nodes, it seems unlikely that we&apos;d be in this case often/ever.&lt;/p&gt;</comment>
                            <comment id="12848996" author="kannanm" created="Wed, 24 Mar 2010 01:19:01 +0000"  >&lt;p&gt;&amp;lt;&amp;lt;&amp;lt; The first fix to this is to bring back deferred log flush. I have a forthcoming patch. &amp;gt;&amp;gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;How are the numbers looking with the posted patch (of not syncing if deferred log flush is set?).&lt;/p&gt;

&lt;p&gt;&amp;lt;&amp;lt;&amp;lt;Given this, what makes the most sense? It seems like hlog.append() then syncFs() of all the puts, THEN memstore mutate is the way to go. In HRS.put our protection from &apos;over memory&apos; is this call :&amp;gt;&amp;gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;Are you talking about how to improve things for batch puts in the default case (i.e. when deferred log flush is not set?). Is so, can you refer to my update on &amp;lt;22/Mar/10 05:47 PM&amp;gt; &amp;#8211; do you plan to lock all the rows for the entire duration? Or reget the locks before doing the memstore mutates? If you reget the row locks, I think you&apos;ll introduce other correctness issues.&lt;/p&gt;



</comment>
                            <comment id="12848998" author="kannanm" created="Wed, 24 Mar 2010 01:22:39 +0000"  >&lt;p&gt;@ Saw JD&apos;s update on another JIRA. Looks like default in trunk is deferred log flush is set.&lt;/p&gt;

&lt;p&gt;So my &amp;lt;&amp;lt;&amp;lt;Are you talking about how to improve things for batch puts in the default case (i.e. when deferred log flush is not set?).&amp;gt;&amp;gt;&amp;gt; should simply read &amp;lt;&amp;lt;&amp;lt; Are you talking about how to improve things for batch puts when deferred log flush is not set?&amp;gt;&amp;gt;&amp;gt;&lt;/p&gt;</comment>
                            <comment id="12849001" author="ryanobjc" created="Wed, 24 Mar 2010 01:30:30 +0000"  >&lt;p&gt;We cant do things like hold row locks for any substantial length of&lt;br/&gt;
time, that introduces the opportunities to deadlock.&lt;/p&gt;

&lt;p&gt;My original code patch moved the sync to the top level at the end of&lt;br/&gt;
the put(Put[]) call.  Maybe for this particular use case that might be&lt;br/&gt;
the solution.  It isn&apos;t perfect, but we dont want to cripple this use&lt;br/&gt;
case (hbase is great if you can wait the months to load your data...)&lt;/p&gt;

&lt;p&gt;On Tue, Mar 23, 2010 at 6:20 PM, Kannan Muthukkaruppan (JIRA)&lt;/p&gt;</comment>
                            <comment id="12849009" author="tlipcon" created="Wed, 24 Mar 2010 01:46:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;We cant do things like hold row locks for any substantial length of time, that introduces the opportunities to deadlock.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Howso? Time of locking doesn&apos;t introduce deadlock, just order of locking. We could sort the rows first to avoid internal deadlock. Of course, the fact that we expose locks to users does break this - if a user has a lock on row C, and we try to lock A,B,C, we&apos;ll block on that row while holding the others. If a user locks in the &quot;wrong order&quot; the problem&apos;s even worse because we&apos;d deadlock against the client.&lt;/p&gt;

&lt;p&gt;So, I don&apos;t think we can hold multiple row locks at the same time, no matter how short a period we do it for, assuming row locks continue to be user-exposed.&lt;/p&gt;

&lt;p&gt;Unfortunately, the opposite problem is just as bad... if we do log(a) memstore(a) log(b) memstore(b) syncAll(), then edit A becomes visible before it&apos;s synced, and that&apos;s a no-no.&lt;/p&gt;

&lt;p&gt;I don&apos;t have any good solutions, but here&apos;s a bad solution: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2332&quot; title=&quot;Remove client-exposed row locks from region server&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2332&quot;&gt;&lt;del&gt;HBASE-2332&lt;/del&gt;&lt;/a&gt; (remove user-exposed row locks from region server). That JIRA could be made a little bit less drastic and say that user-exposed row locks are advisory locks (eg like flock) and they don&apos;t block IO (just other lock operations). That is to say, decouple the user exposed locks from the internal locks needed for consistency purposes.&lt;/p&gt;</comment>
                            <comment id="12849010" author="kannanm" created="Wed, 24 Mar 2010 01:51:52 +0000"  >&lt;p&gt;&amp;lt;&amp;lt;&amp;lt; Maybe for this particular use case that might be the solution. It isn&apos;t perfect, but we dont want to cripple this use case (hbase is great if you can wait the months to load your data...&amp;gt;&amp;gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;But that has the issue of memstore edits happening before sync, which we don&apos;t want.&lt;/p&gt;</comment>
                            <comment id="12849011" author="ryanobjc" created="Wed, 24 Mar 2010 01:56:48 +0000"  >&lt;p&gt;are we sure we dont want memstore edits happening before sync in a bulk load case?&lt;/p&gt;

&lt;p&gt;Are we sure that holding hundreds (or thousands) of row locks open for like 10-20 seconds is a good idea?&lt;/p&gt;

&lt;p&gt;I know people point to disabling the WAL completely to be fast, but I don&apos;t think we have to choose between fast (enough) and reasonably safe.&lt;/p&gt;</comment>
                            <comment id="12849012" author="kannanm" created="Wed, 24 Mar 2010 01:59:14 +0000"  >&lt;p&gt;Ryan: So for your use case, if you are planning to go with deferredLogFlush to true, is this still a serious issue?&lt;/p&gt;</comment>
                            <comment id="12849013" author="ryanobjc" created="Wed, 24 Mar 2010 02:01:21 +0000"  >&lt;p&gt;With deferred log flush we are in a better position.  Do you think that we should provide a bulk commit code path that (sort of) mimics the group commit code path?  &lt;/p&gt;

&lt;p&gt;Another thing to watch out for is people running the default config then writing nasty email/twitter notes because our out of the box performance isnt good unless you do tweaks X,Y,Z.  It&apos;d be nice to be fully performant without tweaking values such as deferredLogFlush.  &lt;/p&gt;</comment>
                            <comment id="12849015" author="ryanobjc" created="Wed, 24 Mar 2010 02:02:30 +0000"  >&lt;p&gt;Are you willing to cripple the performance of hbase put speed to&lt;br/&gt;
ensure certain log atomic order of operation guarantees in a bulk&lt;br/&gt;
insert case?&lt;/p&gt;

&lt;p&gt;On Tue, Mar 23, 2010 at 6:52 PM, Kannan Muthukkaruppan (JIRA)&lt;/p&gt;</comment>
                            <comment id="12849016" author="tlipcon" created="Wed, 24 Mar 2010 02:05:40 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Are you willing to cripple the performance of hbase put speed to&lt;br/&gt;
ensure certain log atomic order of operation guarantees in a bulk&lt;br/&gt;
insert case?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it&apos;s crucial that correctness is an &lt;em&gt;option&lt;/em&gt;. That is to say, I am strongly&lt;br/&gt;
against any design that &lt;em&gt;precludes&lt;/em&gt; correct operation of bulk puts (where correct&lt;br/&gt;
is the set of guarantees we&apos;re talking about in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2294&quot; title=&quot;Enumerate ACID properties of HBase in a well defined spec&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2294&quot;&gt;&lt;del&gt;HBASE-2294&lt;/del&gt;&lt;/a&gt; - visible edits must be&lt;br/&gt;
durable, etc). I also am totally with you that for cases like mapreduce bulk loads&lt;br/&gt;
there should be a &quot;throw caution to the wind and shove that data in as fast as&lt;br/&gt;
our little hard drives can spin&quot; &lt;em&gt;option&lt;/em&gt;.&lt;/p&gt;</comment>
                            <comment id="12849017" author="tlipcon" created="Wed, 24 Mar 2010 02:07:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Another thing to watch out for is people running the default config then writing nasty email/twitter notes because our out of the box performance isnt good unless you do tweaks X,Y,Z&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this is simply a matter of education. I personally care less about the opinions of people on twitter than I do about correct operation. Correct operation has its costs. HBase has been &quot;cheating&quot; for some time and hence had great performance. I am certain that it&apos;s going to be slower once it&apos;s correct, and absolutely OK with that.&lt;/p&gt;</comment>
                            <comment id="12849022" author="apurtell" created="Wed, 24 Mar 2010 02:18:28 +0000"  >&lt;p&gt;@Todd: Unfortunately the project will suffer if HBase is not as fast as reasonable for the default config. That is not strictly a technical consideration but is an important point. We have a bit of a PR battle going on because another project wants to be the prom queen. It is not possible to pretend that is not happening.&lt;/p&gt;</comment>
                            <comment id="12849024" author="tlipcon" created="Wed, 24 Mar 2010 02:23:06 +0000"  >&lt;p&gt;If the &quot;other project&quot; isn&apos;t correct, make the PR battle should be about that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; If the &quot;other project&quot; &lt;em&gt;is&lt;/em&gt; correct and still faster, we shouldn&apos;t compete by cheating, we should optimize the correct path!&lt;/p&gt;</comment>
                            <comment id="12849081" author="stack" created="Wed, 24 Mar 2010 06:50:25 +0000"  >&lt;p&gt;/me sorry, late to the game&lt;/p&gt;

&lt;p&gt;Correctness must be an option, if not the way we ship by default.  We can choose to not ship it as default but hbase has to be able to be correct (I&apos;m thinking that default we might ship with deferred logging if it improves our speed some but we must be clear to user about the cost to them of not syncing each row mutation).&lt;/p&gt;

&lt;p&gt;Bulk put is a relatively new feature.  Its addition made for some nice upload numbers but our write speed before bulk put had been fine, at least compared to the competition (See Y! paper).&lt;/p&gt;

&lt;p&gt;What if you added flags to the bulk put Ryan that allowed you ask for a &quot;sloppy&quot; bulk put behavior for those of us who are fine redoing the bulk put if it doesn&apos;t all go in.  The sloppy bulk put would write all to the WAL first (you might look at making yourself a special version of WALEdit and HLogKey for this case... would need special handling at split time, etc.), sync, and then do he memstore update (the latter could be done by calling single-row put with WAL set to false) w/o locking (or write the WAL afterward... though I think writing it first better).  By default the bulk put would run row-by-row, WAL, sync, memstore-update.&lt;/p&gt;</comment>
                            <comment id="12849083" author="apurtell" created="Wed, 24 Mar 2010 07:00:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m thinking that default we might ship with deferred logging if it improves our speed&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was thinking the same with my above comment, and/or other similar trade offs as they are available.&lt;/p&gt;</comment>
                            <comment id="12849084" author="tlipcon" created="Wed, 24 Mar 2010 07:03:11 +0000"  >&lt;p&gt;I like the idea of flags to decide on when to give up correctness.&lt;/p&gt;

&lt;p&gt;Here&apos;s a pseudocode idea that may be able to maintain correctness and speed... just brainstorming (there may be flaws!)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def bulk_put(rows_to_write):
  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; not rows_to_write.empty():
    minibatch = []

    # all minibatches must get at least one row
    row = rows_to_write.take()
    row.lock()
    minibatch.append(row)

    # &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; to grab as many more locks as we can
    # without blocking (prevents deadlock)
    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; not rows_to_write.empty():
      row = rows_to_write.peek()
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; row.trylock():
        rows_to_write.take()
        minibatch.append(row)
      &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
        &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;
    # we now have locks on a number of rows
    write_to_hlog(minibatch)
    sync_hlog()
    write_to_memstore(minibatch)
    unlock_all_rows(minibatch)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Essentially the thought here is that we try to lock as many rows together as we can without risking deadlock. This algorithm is deadlock free because we&apos;ll never block on a lock while holding another. So in the uncontended case, this algorithm turns into the &quot;lock all rows, write all to hlog, sync, write all to memstore&quot; but in the pathological contended case it turns into a sync per row.&lt;/p&gt;

&lt;p&gt;A couple variations are certainly available (eg loop all the way through rows_to_write making a minibatch of anything lockable might be better), but this general idea might be worth exploring?&lt;/p&gt;</comment>
                            <comment id="12849333" author="kannanm" created="Wed, 24 Mar 2010 18:22:20 +0000"  >&lt;p&gt;Having &quot;durable&quot; semantics as the default, and providing an optional  &quot;sloppy&quot; overload of Put (which does the deferredLogFlush optimization) seems better to me. &lt;/p&gt;

&lt;p&gt;With regards to making the basic multi-row Put case faster, I guess it would help the single-threaded client case the most. If the client was already multi-threaded, then the group commit benefits would already be kicking in to amortize the cost of the syncs.  Todd&apos;s suggestion of optimistically acquiring locks in batches of rows sounds good to me.&lt;/p&gt;

</comment>
                            <comment id="12849367" author="apurtell" created="Wed, 24 Mar 2010 19:22:29 +0000"  >&lt;p&gt;I disagree. I think higher performing options should be the default. I want durability as much if not more that others. However, the only users of out of the box configurations are prototypers, evaluators, and benchmarkers (and in this last case only the na&#239;ve ones) and it is good strategy to seek to avoid being labeled slow again by new users, unnecessarily. Any move into production requires some attention paid to configuration changes and tuning. As long as we provide clear guidance and detail what deferred log flushing trades away, we get the best result here in my opinion.&lt;/p&gt;</comment>
                            <comment id="12849407" author="streamy" created="Wed, 24 Mar 2010 20:23:31 +0000"  >&lt;p&gt;I agree with Andrew.  We were always burdened in the Postgres world by having horrid out-of-the-box performance, but awesome out-of-the-box durability.  &lt;/p&gt;

&lt;p&gt;Being able to adjust these things for performance vs durability guarantees is awesome.&lt;/p&gt;

&lt;p&gt;Whichever the default is, there must be ample documentation explaining the various knobs and various trade-offs.  People running HBase without diving into those docs are far more likely to be testing for performance, not durability.  They will also likely not be in a production environment, or on clusters large enough and be running for enough time that node failure is likely.&lt;/p&gt;</comment>
                            <comment id="12849409" author="tlipcon" created="Wed, 24 Mar 2010 20:26:52 +0000"  >&lt;p&gt;We&apos;ve derailed this JIRA a fair amount, but I&apos;ll add to the pile. One solution might be to ship with example configurations, one for speed, one for correctness, and let users pick at setup time which they want to base their -site off of.&lt;/p&gt;</comment>
                            <comment id="12849411" author="streamy" created="Wed, 24 Mar 2010 20:32:14 +0000"  >&lt;p&gt;There are probably some jiras laying around for some kind of CLI that would generate configuration after taking some user input about their requirements, cluster information, etc... Could boil that into there if it ever gets done.  But since those things are always nice-to-haves that rarely get built, shipping with a few sample hbase-site&apos;s could be a good solution.&lt;/p&gt;

&lt;p&gt;Part of the initial setup in the docs would be to decide which to use and rename it to hbase-site.xml.&lt;/p&gt;

&lt;p&gt;Even still, there will need to be defaults, so can we still fight about that? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12849412" author="streamy" created="Wed, 24 Mar 2010 20:33:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1173&quot; title=&quot;HBase configuration wizard&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1173&quot;&gt;&lt;del&gt;HBASE-1173&lt;/del&gt;&lt;/a&gt; was what I was thinking of I guess.  Has been closed.&lt;/p&gt;</comment>
                            <comment id="12849418" author="apurtell" created="Wed, 24 Mar 2010 20:42:32 +0000"  >&lt;p&gt;Well worked example configs or some kind of wizard would be great to have, but to get back on track a little that means sufficient flexibility in the implementation to support those options. The proposal above to turn on and off features on the write path according to flags is a good one, a generic and extensible mechanism that can support many different policies. And, at no time should we accept a change that permanently reduces performance without providing a credible alternative, unless there is no such option.&lt;/p&gt;</comment>
                            <comment id="12849424" author="kannanm" created="Wed, 24 Mar 2010 20:49:06 +0000"  >&lt;p&gt;@ Andrew/Jonathan: I see your point of view. The default isn&apos;t a major issue for contention for me-- was just stating a personal preference, but it wouldn&apos;t bother me a whole lot either way assuming the choices are well documented.&lt;/p&gt;</comment>
                            <comment id="12849425" author="tlipcon" created="Wed, 24 Mar 2010 20:49:32 +0000"  >&lt;p&gt;Andrew, I agree with you in sentiment, but I also want to weigh in code complexity and QA. Specific to this issue (trying to drag this runaway train back!) I think it is very dangerous to have a configuration option that changes the &lt;em&gt;order&lt;/em&gt; in which key operations occur. It makes it very tough to reason about how different processes will affect the system, especially if this sort of config option proliferates. And the matrix of configurations that we&apos;ll have to test explodes in a really bad way.&lt;/p&gt;</comment>
                            <comment id="12849442" author="apurtell" created="Wed, 24 Mar 2010 21:14:31 +0000"  >&lt;p&gt;@Todd: At least in the scope of this jira the choice is between two sets of behaviors that are not difficult to explain or reason about in my opinion. Allowing some reordering (or even violation in consequence of failure) for the pretty specific use case of bulk importing, or more generally, high speed insertion of regeneratable data, I think is ok. We should have the option.&lt;/p&gt;</comment>
                            <comment id="12849746" author="karthik.ranga" created="Thu, 25 Mar 2010 16:16:42 +0000"  >&lt;p&gt;Jumping in late here... just wanted to throw in my opinion.&lt;/p&gt;

&lt;p&gt;I feel that having the option to configure the behavior is good. I also feel that we should make correctness the default - because it takes someone some amount of working knowledge to differentiate between the two. When I think of any DB (whose internals I do not know), I always assume that it preserves data. And I almost always expect to tweak some settings to get better performance if it does not cut my needs - but do not expect to have to tweak something to get absolute data correctness.&lt;/p&gt;

&lt;p&gt;Another fallout of this &quot;sloppy&quot; option is that there is a possibility of data changing from underneath the application using it. The memstore may return a certain value when the application queries it, then region server goes down, replays the log and now the application may get a different answer (this case the correct one).  While ok for the most part, it may not play nice with some application not aware of this. And its pretty hard to debug as well &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Just my 2 cents.&lt;/p&gt;</comment>
                            <comment id="12849758" author="apurtell" created="Thu, 25 Mar 2010 16:29:37 +0000"  >&lt;p&gt;I like Todd&apos;s suggestion to have multiple example configs tuned for different trade offs that might be useful for different use cases but also vetted to be sane. I think that can satisfy everyone.&lt;/p&gt;</comment>
                            <comment id="12849770" author="streamy" created="Thu, 25 Mar 2010 16:44:25 +0000"  >&lt;p&gt;+1 on shipping with multiple example configs.  As long as getting started docs are clear, I don&apos;t care so much what the shipped-with defaults are and am fine w/ karthik&apos;s take that we should ship w/ correctness/durability.&lt;/p&gt;</comment>
                            <comment id="12849774" author="apurtell" created="Thu, 25 Mar 2010 16:55:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;+1 on shipping with multiple example configs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that is settled. &lt;/p&gt;

&lt;p&gt;What about Ryan&apos;s original point that bulk importers now only have the option to turn off writes to the WAL? Can we get a performance option and correctness? What about the &quot;minibatching&quot; concept?&lt;/p&gt;</comment>
                            <comment id="12849776" author="tlipcon" created="Thu, 25 Mar 2010 16:59:05 +0000"  >&lt;p&gt;I think the minibatching should actually give us both. Just need to find some time to write the code and give it a benchmark! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12849778" author="streamy" created="Thu, 25 Mar 2010 17:02:51 +0000"  >&lt;p&gt;I like the optimistic mini-batching concept as a potential performance+correctness solution.&lt;/p&gt;

&lt;p&gt;I think in many heavy-write scenarios, there is a lot of region concurrency, but often little or no per-row concurrency.  Even for non-import situations like a web application with user activity writes, you don&apos;t expect much row contention.&lt;/p&gt;</comment>
                            <comment id="12853477" author="jdcryans" created="Mon, 5 Apr 2010 18:21:57 +0000"  >&lt;p&gt;Marking as blocker.&lt;/p&gt;

&lt;p&gt;Testing trunk with PE seqWrite, it&apos;s now a bit more than 5x slower (what took 55 secs now takes 320). Deferred log flushing would help here but it would still be slower than the bulk sync optimization we had. This is a huge performance regression, even if they get durability some of our users will see MR jobs that took maybe an hour now take more than 5... for a variety of reasons this is enough to make this issue a blocker.&lt;/p&gt;

&lt;p&gt;I think shipping with configs is good, but it won&apos;t solve this problem.&lt;/p&gt;

&lt;p&gt;This mini-batching solution sounds awesome, unsure how soon we can get it tho.&lt;/p&gt;

&lt;p&gt;Like Ryan was initially saying, bringing deferred log flush in 0.20 would be an easy task since it&apos;s a few lines to fix. The issue then is to decide whether we want to ship with this turned on or off by default (we already had a vote on this issue for trunk in November, we decided to enable it by default for all tables). Also if we turn this on, how big would the window be (currently 1 second in trunk).&lt;/p&gt;

&lt;p&gt;I would like to point out that the MySQL binary log isn&apos;t flushed for every edit by default. See &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/binary-log.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/binary-log.html&lt;/a&gt;, grep for &quot;sync_binlog&quot;. We can&apos;t rely on HDFS to flush the HLog so we do it with the polling timeout, also we already force flush catalog edits and tables with deferred log flush disabled are flushing others edits. We could set a very small window, say 100ms?, and everyone is free to change it for their own tables.&lt;/p&gt;</comment>
                            <comment id="12853480" author="tlipcon" created="Mon, 5 Apr 2010 18:28:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;I would like to point out that the MySQL binary log isn&apos;t flushed for every edit by default.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;FWIW the binlog in MySQL is used for point-in-time-recovery from backups, and for replication, but it&apos;s not the analogue of the HLog. The InnoDB transaction log is the thing like HLog, and its default is to sync on every commit (but also allows tuning to be periodic)&lt;/p&gt;</comment>
                            <comment id="12853482" author="apurtell" created="Mon, 5 Apr 2010 18:38:15 +0000"  >&lt;p&gt;I am seeing similar performance killing effects on the write path benching up on EC2. I was so concerned have switched from m1.large to c1.xlarge and am currently getting a new baseline using the larger instance types, presumably with better i/o characteristics, with 0.20.3 and 0.20.4 with dfs.support.append=false. When I switch dfs.support.append=true I expect to go off a cliff.&lt;/p&gt;</comment>
                            <comment id="12853483" author="tlipcon" created="Mon, 5 Apr 2010 18:39:21 +0000"  >&lt;p&gt;BTW, regarding defaults, I&apos;m OK with deferred flush on or off, so long as it&apos;s very clearly documented in the &quot;getting started&quot; guide, and we provide an example config for &quot;absolute durability&quot; as well.&lt;/p&gt;</comment>
                            <comment id="12853488" author="ryanobjc" created="Mon, 5 Apr 2010 18:50:37 +0000"  >&lt;p&gt;I think Todd was going to try implementing his algorithm above. Lets see how&lt;br/&gt;
that looks.&lt;/p&gt;

&lt;p&gt;On Apr 5, 2010 11:22 AM, &quot;Jean-Daniel Cryans (JIRA)&quot; &amp;lt;jira@apache.org&amp;gt;&lt;br/&gt;
wrote:&lt;/p&gt;


&lt;p&gt;[&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2353?page=com.atlassian.jira.plugin.system.issue&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-2353?page=com.atlassian.jira.plugin.system.issue&lt;/a&gt;.&lt;br/&gt;
..&lt;br/&gt;
Jean-Daniel Cryans updated &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2353&quot; title=&quot;HBASE-2283 removed bulk sync optimization for multi-row puts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2353&quot;&gt;&lt;del&gt;HBASE-2353&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
--------------------------------------&lt;/p&gt;

&lt;p&gt;        Priority: Blocker  (was: Major)&lt;br/&gt;
   Fix Version/s: 0.20.4&lt;/p&gt;

&lt;p&gt;Marking as blocker.&lt;/p&gt;

&lt;p&gt;Testing trunk with PE seqWrite, it&apos;s now a bit more than 5x slower (what&lt;br/&gt;
took 55 secs now takes 320). Deferred log flushing would help here but it&lt;br/&gt;
would still be slower than the bulk sync optimization we had. This is a huge&lt;br/&gt;
performance regression, even if they get durability some of our users will&lt;br/&gt;
see MR jobs that took maybe an hour now take more than 5... for a variety of&lt;br/&gt;
reasons this is enough to make this issue a blocker.&lt;/p&gt;

&lt;p&gt;I think shipping with configs is good, but it won&apos;t solve this problem.&lt;/p&gt;

&lt;p&gt;This mini-batching solution sounds awesome, unsure how soon we can get it&lt;br/&gt;
tho.&lt;/p&gt;

&lt;p&gt;Like Ryan was initially saying, bringing deferred log flush in 0.20 would be&lt;br/&gt;
an easy task since it&apos;s a few lines to fix. The issue then is to decide&lt;br/&gt;
whether we want to ship with this turned on or off by default (we already&lt;br/&gt;
had a vote on this issue for trunk in November, we decided to enable it by&lt;br/&gt;
default for all tables). Also if we turn this on, how big would the window&lt;br/&gt;
be (currently 1 second in trunk).&lt;/p&gt;

&lt;p&gt;I would like to point out that the MySQL binary log isn&apos;t flushed for every&lt;br/&gt;
edit by default. See &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/binary-log.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/binary-log.html&lt;/a&gt;,&lt;br/&gt;
grep for &quot;sync_binlog&quot;. We can&apos;t rely on HDFS to flush the HLog so we do it&lt;br/&gt;
with the polling timeout, also we already force flush catalog edits and&lt;br/&gt;
tables with deferred log flush disabled are flushing others edits. We could&lt;br/&gt;
set a very small window, say 100ms?, and everyone is free to change it for&lt;br/&gt;
their own tables.&lt;/p&gt;


</comment>
                            <comment id="12864078" author="jdcryans" created="Tue, 4 May 2010 23:49:37 +0000"  >&lt;p&gt;Patch to fix deferred log flush in trunk, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt; stripped the calls. I also set it to false by default, less durability would be an option.&lt;/p&gt;</comment>
                            <comment id="12866806" author="stack" created="Wed, 12 May 2010 23:48:19 +0000"  >&lt;p&gt;Bulk move of 0.20.5 issues into 0.21.0 after vote that we merge branch into TRUNK up on list.&lt;/p&gt;</comment>
                            <comment id="12875525" author="tlipcon" created="Fri, 4 Jun 2010 08:33:16 +0000"  >&lt;p&gt;I&apos;m going to take a stab at the optimistic mini-batching technique suggested above.&lt;/p&gt;

&lt;p&gt;Andrew: did you get any final numbers with your EC2 testing of my HDFS-side sync parallelization? In my tests here I saw similar performance on trunk vs 20 when my patches were included, but haven&apos;t done a real rigorous comparison.&lt;/p&gt;</comment>
                            <comment id="12875688" author="apurtell" created="Fri, 4 Jun 2010 18:10:12 +0000"  >&lt;p&gt;Todd: So much has been in flux, we&apos;ve been waiting for it to settle. &lt;/p&gt;</comment>
                            <comment id="12877748" author="hbasereviewboard" created="Fri, 11 Jun 2010 07:52:01 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hbase, Kannan Muthukkaruppan and Ryan Rawson.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;I implemented the &quot;mini batching&quot; idea we talked about on the JIRA.&lt;/p&gt;

&lt;p&gt;This currently breaks some of the error handling, so I dont intend to commit as is, but everyone is busy so wanted to put a review up now while I tidy up the rest.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2353&quot; title=&quot;HBASE-2283 removed bulk sync optimization for multi-row puts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2353&quot;&gt;&lt;del&gt;HBASE-2353&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HBASE-2353&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HBASE-2353&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java 6b6d098 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java a1baff4 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java 034690e &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.hbase.org/r/167/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Some PEs on a real sync-enabled cluster, seems faster but haven&apos;t done scientific benchmarking.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Todd&lt;/p&gt;

</comment>
                            <comment id="12877859" author="hbasereviewboard" created="Fri, 11 Jun 2010 17:03:04 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review181&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review181&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;p&gt;Looks good to me.  Minor comments below.&lt;/p&gt;


&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment848&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment848&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Should this be public?  Isn&apos;t it just used internally?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment847&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment847&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Is this a copy?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment849&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment849&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    You were going to replace these w/ something from guava (or is this it?)&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment850&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment850&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Same here&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment851&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment851&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This creates new Map, pass in Map.Entry instead?&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment852&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment852&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    I hate that this is even an option (smile)&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment853&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment853&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    w can never be null here?  (There was null check previous)&lt;/p&gt;



&lt;p&gt;src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/#comment854&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#comment854&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Missing javadoc on new param&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12877866" author="hbasereviewboard" created="Fri, 11 Jun 2010 17:26:03 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1439&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1439&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1439&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Should this be public?  Isn&apos;t it just used internally?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;good call, will make it package private&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1442&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1442&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1442&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Is this a copy?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep. I did it the simple way following the pseudocode in the JIRA, but we can definitely do it more efficiently by indexing into a list or arraylist. My bet is that the efficiency gains are marginal compared to the cost of actually writing to the WAL, etc, and this patch should already be a big gain over what we used to have.&lt;/p&gt;

&lt;p&gt;After this is committed let&apos;s file a followup JIRA to remove extra shallow copies. I&apos;ll add a TODO in the code also.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1467&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1467&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1467&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     You were going to replace these w/ something from guava (or is this it?)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The guava Preconditions thing is supposed to be more for parameter checking, etc, than for internal assertions. Currently these don&apos;t get run, but I think we should enable -ea at least for unit tests.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1482&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1482&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1482&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This creates new Map, pass in Map.Entry instead?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought both .keySet() and .entrySet() were just views into the existing map? (and p.getFamilyMap() just returns a member)&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1777&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1777&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1777&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     w can never be null here?  (There was null check previous)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yea, since it&apos;s assigned first in the try block, and that function doesn&apos;t throw exceptions.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Todd&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review181&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review181&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12877891" author="hbasereviewboard" created="Fri, 11 Jun 2010 18:01:20 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1442&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1442&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1442&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Is this a copy?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Yep. I did it the simple way following the pseudocode in the JIRA, but we can definitely do it more efficiently by indexing into a list or arraylist. My bet is that the efficiency gains are marginal compared to the cost of actually writing to the WAL, etc, and this patch should already be a big gain over what we used to have.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After this is committed let&apos;s file a followup JIRA to remove extra shallow copies. I&apos;ll add a TODO in the code also.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fine by me&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1467&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1467&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1467&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     You were going to replace these w/ something from guava (or is this it?)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;The guava Preconditions thing is supposed to be more for parameter checking, etc, than for internal assertions. Currently these don&apos;t get run, but I think we should enable -ea at least for unit tests.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;NM.  Just saw this &quot;By default, Surefire enables JVM assertions for the execution of your test cases.&quot;  So, keep your asserts as is (we should all take them on)&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1482&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1482&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1482&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This creates new Map, pass in Map.Entry instead?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I thought both .keySet() and .entrySet() were just views into the existing map? (and p.getFamilyMap() just returns a member)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like I&apos;m wrong, at least regards JDK1.6.  Internally it seems to use entrySet.  Below is from java.util.AbstractMap:&lt;/p&gt;


&lt;p&gt;    public Set&amp;lt;K&amp;gt; keySet() {&lt;br/&gt;
    if (keySet == null) {&lt;br/&gt;
        keySet = new AbstractSet&amp;lt;K&amp;gt;() {&lt;br/&gt;
        public Iterator&amp;lt;K&amp;gt; iterator() {&lt;br/&gt;
            return new Iterator&amp;lt;K&amp;gt;() {&lt;br/&gt;
            private Iterator&amp;lt;Entry&amp;lt;K,V&amp;gt;&amp;gt; i = entrySet().iterator();&lt;br/&gt;
....&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review181&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review181&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12877932" author="hbasereviewboard" created="Fri, 11 Jun 2010 19:21:58 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-11 09:59:29, stack wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java, line 1439&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1439&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff/1/?file=1237#file1237line1439&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Should this be public?  Isn&apos;t it just used internally?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Todd Lipcon wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;good call, will make it package private&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, all the other put methods are also public, even though HRegion itself is basically internal to the RS&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Todd&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review181&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review181&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12878110" author="hbasereviewboard" created="Fri, 11 Jun 2010 22:21:13 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-06-11 15:18:10.087969)&lt;/p&gt;


&lt;p&gt;Review request for hbase, Kannan Muthukkaruppan and Ryan Rawson.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Significantly changed patch - now batch put returns a list of status codes. Also added some tests to make sure all the behavior is correct with locking, bad families, etc.&lt;/p&gt;

&lt;p&gt;I&apos;d like to change HRegionInterface and HTable to return lists of status codes at some point too, but I think that can wait for a later patch. This one at least gets our performance back up by batching the syncs.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;I implemented the &quot;mini batching&quot; idea we talked about on the JIRA.&lt;/p&gt;

&lt;p&gt;This currently breaks some of the error handling, so I dont intend to commit as is, but everyone is busy so wanted to put a review up now while I tidy up the rest.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2353&quot; title=&quot;HBASE-2283 removed bulk sync optimization for multi-row puts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2353&quot;&gt;&lt;del&gt;HBASE-2353&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HBASE-2353&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HBASE-2353&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/HConstants.java 1e59533 &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java 62617ac &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java adc505b &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java 541ec9b &lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java ba04820 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/MultithreadedTestUtil.java 870f925 &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java 8a5206c &lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java e75767d &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.hbase.org/r/167/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Some PEs on a real sync-enabled cluster, seems faster but haven&apos;t done scientific benchmarking.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Todd&lt;/p&gt;

</comment>
                            <comment id="12878122" author="hbasereviewboard" created="Fri, 11 Jun 2010 22:54:13 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review197&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review197&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;p&gt;Looks good to me.  No comments.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12878166" author="hbasereviewboard" created="Sat, 12 Jun 2010 00:59:34 +0000"  >&lt;p&gt;Message from: &quot;Ryan Rawson&quot; &amp;lt;ryanobjc@gmail.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review204&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review204&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;generally looks interesting and sound. This may need to be reconciled with &lt;a href=&quot;http://review.hbase.org/r/151/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/151/&lt;/a&gt; - batch operations for put/delete/get.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ryan&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12878207" author="stack" created="Sat, 12 Jun 2010 04:25:32 +0000"  >&lt;p&gt;@Todd Translating the above comments by myself and Ryan, I think thats two +1s you got there.&lt;/p&gt;</comment>
                            <comment id="12878420" author="tlipcon" created="Sun, 13 Jun 2010 18:55:42 +0000"  >&lt;p&gt;Committed to trunk. Thanks for review, Stack and Ryan.&lt;/p&gt;</comment>
                            <comment id="12878421" author="tlipcon" created="Sun, 13 Jun 2010 18:56:53 +0000"  >&lt;p&gt;Attaching patch I committed (r2 from review board)&lt;/p&gt;</comment>
                            <comment id="12879649" author="hbasereviewboard" created="Thu, 17 Jun 2010 03:28:31 +0000"  >&lt;p&gt;Message from: &quot;Kannan Muthukkaruppan&quot; &amp;lt;kannan@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review247&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review247&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;Todd: I know this is already reviewed and committed. I just got around to reviewing this and the related HBase-2733. Looks really good!!&lt;/p&gt;

&lt;p&gt;One side effect of this change is that now a single WALEdit could contain data for more than 1 row. Previously all KVs inside a WALEdit corresponded to the same row. I don&apos;t think it should cause any problems, but thought I should call it out in case others can think of potential issues.&lt;/p&gt;




&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Kannan&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12879671" author="hbasereviewboard" created="Thu, 17 Jun 2010 05:27:36 +0000"  >&lt;p&gt;Message from: stack@duboce.net&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-06-16 20:24:22, Kannan Muthukkaruppan wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; Todd: I know this is already reviewed and committed. I just got around to reviewing this and the related HBase-2733. Looks really good!!&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; One side effect of this change is that now a single WALEdit could contain data for more than 1 row. Previously all KVs inside a WALEdit corresponded to the same row. I don&apos;t think it should cause any problems, but thought I should call it out in case others can think of potential issues.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think its going to be alright Kannan.  The patch over in hbase-1025, the fixup to the replay of split edits, is applying the kvs it finds in a WALEdit value one at a time.  That they are for different rows but of the same region, it should be fine I&apos;d say.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stack&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/167/#review247&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167/#review247&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="14104439" author="techbuddy" created="Wed, 20 Aug 2014 19:52:15 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I wanted to see the file diff for the fix to this issue, but it seems &lt;a href=&quot;http://review.hbase.org/r/167&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/167&lt;/a&gt; is broken.&lt;br/&gt;
Could someone point me to the diff url?&lt;/p&gt;

&lt;p&gt;If it&apos;s migrated to git, how do I get the pull request,if any.&lt;/p&gt;

&lt;p&gt;-thanks&lt;br/&gt;
SB&lt;/p&gt;</comment>
                            <comment id="15017659" author="lars_francke" created="Fri, 20 Nov 2015 12:43:56 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12443661" name="HBASE-2353_def_log_flush.patch" size="1660" author="jdcryans" created="Tue, 4 May 2010 23:49:37 +0000"/>
                            <attachment id="12446986" name="hbase-2353.txt" size="32752" author="tlipcon" created="Sun, 13 Jun 2010 18:56:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 22 Mar 2010 08:31:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26269</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hhdz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100079</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>