<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:44:47 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7336/HBASE-7336.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7336] HFileBlock.readAtOffset does not work well with multiple threads</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7336</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;HBase grinds to a halt when many threads scan along the same set of blocks and neither read short circuit is nor block caching is enabled for the dfs client ... disabling the block cache makes sense on very large scans.&lt;/p&gt;

&lt;p&gt;It turns out that synchronizing in istream in HFileBlock.readAtOffset is the culprit.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12623489">HBASE-7336</key>
            <summary>HFileBlock.readAtOffset does not work well with multiple threads</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12623791">HBASE-7347</parent>
                                    <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Wed, 12 Dec 2012 05:51:12 +0000</created>
                <updated>Sun, 16 Nov 2014 19:44:25 +0000</updated>
                            <resolved>Mon, 17 Dec 2012 22:14:08 +0000</resolved>
                                                    <fixVersion>0.94.4</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                <comments>
                            <comment id="13529642" author="lhofhansl" created="Wed, 12 Dec 2012 05:53:36 +0000"  >&lt;p&gt;Here&apos;s my test case: 20m rows, single column family, single column, blockcache disabled for the scan, no HDFS short circuiting, all data fits into the OS buffer cache. Full scan over all rows.&lt;/p&gt;

&lt;p&gt;One client scanning: 15s (regionserver keeps one core busy ~120%)&lt;br/&gt;
Two clients scanning along the same set of blocks: They both time out. (regionserver is a 5-6% CPU, clearly just waiting)&lt;/p&gt;

&lt;p&gt;Then I hacked readAtOffset to always do preads. Now:&lt;br/&gt;
One client scanning: 39s (regionserver at ~120%)&lt;br/&gt;
Two clients scanning: 39s each (regionserver at ~210%)&lt;/p&gt;

&lt;p&gt;With short circuiting enabled:&lt;br/&gt;
One client: 15s (120% CPU)&lt;br/&gt;
Two clients: 41s each (160% CPU)&lt;/p&gt;

&lt;p&gt;with pread:&lt;br/&gt;
One client: 18s (160% CPU)&lt;br/&gt;
Two clients: 19s each (250% CPU)&lt;/p&gt;</comment>
                            <comment id="13529647" author="lhofhansl" created="Wed, 12 Dec 2012 06:00:31 +0000"  >&lt;p&gt;I have a patch, that changes that synchronized to a ReentrantLock and reverts to pread if the lock cannot be acquired.&lt;br/&gt;
That way we get seek + read when possible and pread when necessary or requested. Not that this is only for scans. Get default to pread anyway.&lt;/p&gt;

&lt;p&gt;With that patch I get the following behavior:&lt;br/&gt;
One client: 15s&lt;br/&gt;
Two clients: 22s each&lt;/p&gt;

&lt;p&gt;Which seems reasonable given above numbers.&lt;/p&gt;

&lt;p&gt;I wouldn&apos;t really consider this a proper fix, although I also wouldn&apos;t know what the proper fix should be.&lt;br/&gt;
The limiting factor here is a single FSInputStream per store file, which can be devastating for performance if many threads read the same store file and it does not fit into the block cache (or the scans chose not to cache the blocks).&lt;/p&gt;</comment>
                            <comment id="13529649" author="lhofhansl" created="Wed, 12 Dec 2012 06:06:09 +0000"  >&lt;p&gt;0.94 version of said patch.&lt;/p&gt;</comment>
                            <comment id="13529663" author="lhofhansl" created="Wed, 12 Dec 2012 06:23:41 +0000"  >&lt;p&gt;And a trunk version&lt;/p&gt;</comment>
                            <comment id="13529669" author="stack" created="Wed, 12 Dec 2012 06:40:48 +0000"  >&lt;p&gt;Should the tryLock have a timeout on it?&lt;/p&gt;

&lt;p&gt;Else patch is an improvement for sure worth committing till we do better.&lt;/p&gt;

&lt;p&gt;I wonder what the difference is if more than one Reader.&lt;/p&gt;

&lt;p&gt;Looking at hdfs, each open goes to the namenode so can&apos;t open a reader per scanner... would cost a bit on setup?  If we could distingush short from long scan we could do pread on the shorts and open a reader per Scanner for the long runners?&lt;/p&gt;</comment>
                            <comment id="13529682" author="lhofhansl" created="Wed, 12 Dec 2012 07:01:49 +0000"  >&lt;p&gt;tryLock without a timeout returns immediately. I think in this case it should, waiting here would potentially wait (at least a threads context switch) on each single next or get request.&lt;/p&gt;

&lt;p&gt;I think this issue would be most prominent in long scans, where the scans typically do not want to mess up the block cache.&lt;/p&gt;

&lt;p&gt;Multiple readers is probably the right solution. How many, though? And I am not sure how this would interact with the block cache (would probably be OK).&lt;/p&gt;</comment>
                            <comment id="13529712" author="stack" created="Wed, 12 Dec 2012 07:37:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;tryLock without a timeout returns immediately.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry.  Thought for some reason it waited.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;How many, though? And I am not sure how this would interact with the block cache (would probably be OK).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;One per scanner?  Can we look at a scanner and figure somehow if its long or short?  If start/stop row?  Limit?  Maybe allow someone pass a hint?  Compactions should go get their own Reader?&lt;/p&gt;</comment>
                            <comment id="13529730" author="lhofhansl" created="Wed, 12 Dec 2012 08:02:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;Compactions should go get their own Reader?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That sounds like a save and important improvement.&lt;/p&gt;

&lt;p&gt;In other cases it actually seems best to try to get a stream and fall back to pread if that fails.&lt;/p&gt;

&lt;p&gt;Could drive # of reader by he size of the store file, something like a reader per n GB (n = 1 or 2 maybe). Then we round robin the readers.&lt;/p&gt;

&lt;p&gt;Should I commit this for now (assuming it passes HadoopQA and no objections), and we investigate other options further? Or discuss a bit more to see if we kind other options?&lt;/p&gt;</comment>
                            <comment id="13529785" author="hadoopqa" created="Wed, 12 Dec 2012 09:52:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12560514/7336-0.96.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12560514/7336-0.96.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 104 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 23 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestMultiParallel&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3490//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13530074" author="lhofhansl" created="Wed, 12 Dec 2012 16:24:45 +0000"  >&lt;p&gt;TestMultiParallel passed locally.&lt;/p&gt;</comment>
                            <comment id="13530512" author="lhofhansl" created="Thu, 13 Dec 2012 00:02:19 +0000"  >&lt;p&gt;Any objections to committing this (0.94 and 0.96). I&apos;m pretty sure it won&apos;t make things worse, and it provably improves some scenarios.&lt;/p&gt;</comment>
                            <comment id="13530580" author="lhofhansl" created="Thu, 13 Dec 2012 01:28:07 +0000"  >&lt;p&gt;Numbers with patch and read short circuit enabled for completeness:&lt;br/&gt;
One client: 15s (104%)&lt;br/&gt;
Two clients: 22s (180% CPU)&lt;/p&gt;</comment>
                            <comment id="13530612" author="xieliang007" created="Thu, 13 Dec 2012 02:17:19 +0000"  >&lt;p&gt;+1, LGTM,a nice test case, Lars&lt;/p&gt;</comment>
                            <comment id="13531265" author="stack" created="Thu, 13 Dec 2012 18:12:45 +0000"  >&lt;p&gt;+1 on committing this for now.&lt;/p&gt;

&lt;p&gt;On Reader per long-running scanner, it will complicate the swapping in of new files on compaction but probably worth figuring out.  Lets file issues for further improvement.&lt;/p&gt;

&lt;p&gt;Good stuff Lars.&lt;/p&gt;</comment>
                            <comment id="13531372" author="lhofhansl" created="Thu, 13 Dec 2012 19:34:55 +0000"  >&lt;p&gt;Thanks for the reviews.&lt;/p&gt;</comment>
                            <comment id="13531500" author="hudson" created="Thu, 13 Dec 2012 20:59:46 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #625 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/625/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/625/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; HFileBlock.readAtOffset does not work well with multiple threads (Revision 1421439)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13531506" author="hudson" created="Thu, 13 Dec 2012 21:10:45 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3618 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3618/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3618/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; HFileBlock.readAtOffset does not work well with multiple threads (Revision 1421440)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13531664" author="hudson" created="Thu, 13 Dec 2012 23:59:02 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #295 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/295/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/295/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; HFileBlock.readAtOffset does not work well with multiple threads (Revision 1421440)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13532736" author="lhofhansl" created="Fri, 14 Dec 2012 22:34:39 +0000"  >&lt;p&gt;Note that the previous tests all were scans that did not return anything to the client.&lt;br/&gt;
Did another verification test with scans in blocks and returns data to the client. Even in that case the performance is better, because of improved concurrency.&lt;br/&gt;
(Three concurrent clients went from 74s to 65s)&lt;/p&gt;</comment>
                            <comment id="13533567" author="lhofhansl" created="Sun, 16 Dec 2012 23:39:38 +0000"  >&lt;p&gt;TestHFileBlock.testConcurrentReading&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; is failing in the 0.94 test runs now (with OOMs).&lt;/p&gt;

&lt;p&gt;I do not think this is because of this change, but at the same time I do not see any other related changes.&lt;br/&gt;
It does not fail locally.&lt;/p&gt;</comment>
                            <comment id="13533583" author="lhofhansl" created="Mon, 17 Dec 2012 00:49:19 +0000"  >&lt;p&gt;Running the test locally also seems to consume &lt;b&gt;less&lt;/b&gt; memory with the patch. So I have no explanation really, why this test is failing now.&lt;/p&gt;</comment>
                            <comment id="13533606" author="lhofhansl" created="Mon, 17 Dec 2012 02:34:24 +0000"  >&lt;p&gt;The latest test run passed.&lt;/p&gt;

&lt;p&gt;Looking at testConcurrentReading, it is a time bounded test. Checking the number of blocks that the concurrent readers manage to read within the time bound is actually &lt;b&gt;larger&lt;/b&gt; without this patch (i.e. this patch is slowing this down)... Presumably because more threads are now using pread.&lt;br/&gt;
(This test is reading random blocks randomly choosing pread vs not from many threads. And these blocks are very small too. So not sure how real world that is.)&lt;/p&gt;

&lt;p&gt;On the other hand, without this patch scanners that scan large HFiles concurrently in a tight loop are useless (i.e. never make enough progress to not time out).&lt;/p&gt;</comment>
                            <comment id="13533608" author="lhofhansl" created="Mon, 17 Dec 2012 02:41:56 +0000"  >&lt;p&gt;Somewhat tempted to revert this patch.&lt;/p&gt;</comment>
                            <comment id="13533655" author="lhofhansl" created="Mon, 17 Dec 2012 05:15:17 +0000"  >&lt;p&gt;Actually that test is not performance representative. When I revert this change and then have this test only do preads it is quite slow. If I have this test only do seek+read it is much faster. And that is even though the reads of these blocks are random (each thread on each iteration reads a random block), which should favor preads.&lt;/p&gt;

&lt;p&gt;My changes then makes this slightly slower, because the likelihood of a pread is slightly higher.&lt;/p&gt;</comment>
                            <comment id="13533680" author="lhofhansl" created="Mon, 17 Dec 2012 06:40:33 +0000"  >&lt;p&gt;I&apos;ll revert this in 0.94 to see whether the OOMs will go away.&lt;br/&gt;
(No such problem in 0.96 interestingly)&lt;/p&gt;</comment>
                            <comment id="13533726" author="hudson" created="Mon, 17 Dec 2012 08:17:38 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #632 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/632/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/632/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; Revert due to OOMs on TestHFileBlock potentially caused by this. (Revision 1422767)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13534149" author="lhofhansl" created="Mon, 17 Dec 2012 18:33:48 +0000"  >&lt;p&gt;The 0.94 tests fail with the same OOM even without this patch, so I am going to reapply. Sorry for the noise, but I had to make sure.&lt;/p&gt;</comment>
                            <comment id="13534366" author="lhofhansl" created="Mon, 17 Dec 2012 22:14:08 +0000"  >&lt;p&gt;I reapplied the patch.&lt;br/&gt;
(the other anomaly of this test is that all data fits into a single HDFS block, so of course seek+read will be favored here)&lt;/p&gt;</comment>
                            <comment id="13534423" author="hudson" created="Mon, 17 Dec 2012 23:24:08 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #635 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/635/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/635/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; Reapply, the OOMs were not caused by this. (Revision 1423084)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13537918" author="hudson" created="Fri, 21 Dec 2012 14:17:11 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #87 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/87/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/87/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; Reapply, the OOMs were not caused by this. (Revision 1423084)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; Revert due to OOMs on TestHFileBlock potentially caused by this. (Revision 1422767)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; HFileBlock.readAtOffset does not work well with multiple threads (Revision 1421439)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13544426" author="hudson" created="Sat, 5 Jan 2013 00:42:29 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #10 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/10/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/10/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; Reapply, the OOMs were not caused by this. (Revision 1423084)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; Revert due to OOMs on TestHFileBlock potentially caused by this. (Revision 1422767)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; HFileBlock.readAtOffset does not work well with multiple threads (Revision 1421439)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14050538" author="vrodionov" created="Wed, 2 Jul 2014 18:37:23 +0000"  >&lt;p&gt;I am looking into this stuff now, trying to figure out how to make parallel scan on a region more efficient. The code in AbstractFSReader looks dangerous and does not provide any benefits in terms of MT performance.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; readAtOffset(FSDataInputStream istream,
        &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] dest, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; destOffset, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; size,
        &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; peekIntoNextBlock, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; fileOffset, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; pread)
        &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (peekIntoNextBlock &amp;amp;&amp;amp;
          destOffset + size + hdrSize &amp;gt; dest.length) {
        &lt;span class=&quot;code-comment&quot;&gt;// We are asked to read the next block&apos;s header as well, but there is
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// not enough room in the array.
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Attempted to read &quot;&lt;/span&gt; + size + &lt;span class=&quot;code-quote&quot;&gt;&quot; bytes and &quot;&lt;/span&gt; +
            hdrSize + &lt;span class=&quot;code-quote&quot;&gt;&quot; bytes of next header into a &quot;&lt;/span&gt; + dest.length +
            &lt;span class=&quot;code-quote&quot;&gt;&quot;-&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; array at offset &quot;&lt;/span&gt; + destOffset);
      }

      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!pread &amp;amp;&amp;amp; streamLock.tryLock()) {
        &lt;span class=&quot;code-comment&quot;&gt;// Seek + read. Better &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; scanning.
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          istream.seek(fileOffset);

          &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; realOffset = istream.getPos();
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (realOffset != fileOffset) {
            &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Tried to seek to &quot;&lt;/span&gt; + fileOffset + &lt;span class=&quot;code-quote&quot;&gt;&quot; to &quot;&lt;/span&gt;
                + &lt;span class=&quot;code-quote&quot;&gt;&quot;read &quot;&lt;/span&gt; + size + &lt;span class=&quot;code-quote&quot;&gt;&quot; bytes, but pos=&quot;&lt;/span&gt; + realOffset
                + &lt;span class=&quot;code-quote&quot;&gt;&quot; after seek&quot;&lt;/span&gt;);
          }

          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!peekIntoNextBlock) {
            IOUtils.readFully(istream, dest, destOffset, size);
            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -1;
          }

          &lt;span class=&quot;code-comment&quot;&gt;// Try to read the next block header.
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!readWithExtra(istream, dest, destOffset, size, hdrSize))
            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -1;
        } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
          streamLock.unlock();
        }
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        &lt;span class=&quot;code-comment&quot;&gt;// Positional read. Better &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; random reads; or when the streamLock is already locked.
&lt;/span&gt;        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; extraSize = peekIntoNextBlock ? hdrSize : 0;

        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ret = istream.read(fileOffset, dest, destOffset, size + extraSize);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (ret &amp;lt; size) {
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Positional read of &quot;&lt;/span&gt; + size + &lt;span class=&quot;code-quote&quot;&gt;&quot; bytes &quot;&lt;/span&gt; +
              &lt;span class=&quot;code-quote&quot;&gt;&quot;failed at offset &quot;&lt;/span&gt; + fileOffset + &lt;span class=&quot;code-quote&quot;&gt;&quot; (returned &quot;&lt;/span&gt; + ret + &lt;span class=&quot;code-quote&quot;&gt;&quot;)&quot;&lt;/span&gt;);
        }

        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (ret == size || ret &amp;lt; size + extraSize) {
          &lt;span class=&quot;code-comment&quot;&gt;// Could not read the next block&apos;s header, or did not &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;.
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -1;
        }
      }

      &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt; peekIntoNextBlock;
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Bytes.toInt(dest, destOffset + size + BlockType.MAGIC_LENGTH) +
          hdrSize;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Positional reads in FSInputStream (DFSInputStream) are heavily synchronized. It is lock on stream than seek and read, unlock. Here is the code for FSInputStream:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; read(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] buffer, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; offset, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; length)
    &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; oldPos = getPos();
      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; nread = -1;
      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        seek(position);
        nread = read(buffer, offset, length);
      } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
        seek(oldPos);
      }
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; nread;
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DFSInputStream extends FSInputStream but does not override the above method. Taking into account that code is synchronized, it is hard to explain observed performance improvement published in this JIRA.&lt;/p&gt;


</comment>
                            <comment id="14050541" author="vrodionov" created="Wed, 2 Jul 2014 18:38:46 +0000"  >&lt;p&gt;Upd. The code is not dangerous - it just does not do what it was supposed to do.&lt;/p&gt;</comment>
                            <comment id="14050768" author="lhofhansl" created="Wed, 2 Jul 2014 21:56:00 +0000"  >&lt;p&gt;The trylock stuff is from the patch here:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;try to do seek + read (if requested, i.e. a scan)&lt;/li&gt;
	&lt;li&gt;if that is not possible rather than locking, do a pread immediately.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My tests showed a significant improvement, you can always verify yourself. Note that this was 1.5 years ago.&lt;/p&gt;

&lt;p&gt;Curious... If what you say is true there would be no difference at all between seek+read and pread. That would indeed be bad. Hmm.&lt;/p&gt;</comment>
                            <comment id="14050777" author="vrodionov" created="Wed, 2 Jul 2014 22:02:34 +0000"  >&lt;p&gt;I was not right, Lars. &lt;b&gt;DFSInputStream&lt;/b&gt; overrides positional read - no locks. But there is something else ...&lt;/p&gt;

&lt;p&gt;There is no much sense in allowing one random scanner run in a stream mode as since, there is no guarantee that next call to read HFile block from the &quot;lucky&quot; scanner will use the same streaming API and pre-cached data will still be valid. Some other scanner might dump this data before. Correct? &lt;/p&gt;

&lt;p&gt;You may try all &lt;b&gt;pread&lt;/b&gt;&apos;s, for all scanners and compare performance. I bet it will be close to what we have right now. &lt;/p&gt;</comment>
                            <comment id="14050778" author="lhofhansl" created="Wed, 2 Jul 2014 22:02:54 +0000"  >&lt;p&gt;DFSInputStream &lt;b&gt;does&lt;/b&gt; override this method (checked Hadoop-trunk). The overridden method directly calculates the offset without locking as it should. All is good on this front.&lt;/p&gt;</comment>
                            <comment id="14050791" author="lhofhansl" created="Wed, 2 Jul 2014 22:12:31 +0000"  >&lt;p&gt;I agree with your assessment on the seek+read vs pread. The current should not be worse than doing all pread, though.&lt;/p&gt;

&lt;p&gt;I see you commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5979&quot; title=&quot;Non-pread DFSInputStreams should be associated with scanners, not HFile.Readers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5979&quot;&gt;HBASE-5979&lt;/a&gt; as well, and that would be a correct way to fix this. Each scanner would have its own stream and hence seek+read should be better there.&lt;br/&gt;
The issue there is invalidation after a compaction or flush, although that needs some fixing anyway - I tried (unsuccessfully) in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10060&quot; title=&quot;Unsynchronized scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10060&quot;&gt;&lt;del&gt;HBASE-10060&lt;/del&gt;&lt;/a&gt;. The issue there is that even the memory barriers taken for a lock that is uncontended 99.9999% of the time is a significant performance problem, but I have not been able to remove it and still ensure correct behavior.&lt;/p&gt;

&lt;p&gt;I&apos;m glad you&apos;re looking at this, this area needs some TLC.&lt;/p&gt;</comment>
                            <comment id="14062356" author="vrodionov" created="Tue, 15 Jul 2014 17:22:43 +0000"  >&lt;h3&gt;&lt;a name=&quot;Effectofcompactiononlargescanoperationsandviceverse&quot;&gt;&lt;/a&gt;Effect of compaction on large scan operations and vice verse&lt;/h3&gt;

&lt;p&gt;The compaction scanner and user scanner will compete for the same input stream (DFSInputStream). This results in a sub optimal performance for both of them, becuase &lt;b&gt;there is no guarantee that next call to read HFile block from the &quot;lucky&quot; scanner will use the same streaming API and pre-cached data will still be valid&lt;/b&gt;. Yep? Both scanners, periodically, switch between stream/pread API calls, hdfs cache can not be used &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, performance of both of them is defined by positional read performance (which is low for scan mode operation).&lt;/p&gt;

&lt;p&gt;Is this correct assessment?    &lt;/p&gt;</comment>
                            <comment id="14062733" author="vrodionov" created="Tue, 15 Jul 2014 22:00:39 +0000"  >&lt;p&gt;DFSInputStream class is heavily synchronized (at least in HDFS 2.2) and regardless of a read op type (stream, positional) all readers will be waiting on a single lock eventually.  This is what I see in my local tests. &lt;/p&gt;

&lt;p&gt;1 scanner - 14 sec&lt;br/&gt;
2 scanners - 36 sec (!!!) &lt;br/&gt;
4 scanners - too long to be true. &lt;/p&gt;

&lt;p&gt;I have no explanation yet, but something is wrong here.&lt;/p&gt;</comment>
                            <comment id="14062740" author="vrodionov" created="Tue, 15 Jul 2014 22:07:06 +0000"  >&lt;p&gt;Forgot to mention:&lt;/p&gt;

&lt;p&gt;HBase 0.98.3 hadoop2. All tests are in a local mode with HBase mini cluster.&lt;/p&gt;</comment>
                            <comment id="14062749" author="stack" created="Tue, 15 Jul 2014 22:11:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; Can you try on hdfs?&lt;/p&gt;</comment>
                            <comment id="14062814" author="vrodionov" created="Tue, 15 Jul 2014 23:00:55 +0000"  >&lt;p&gt;I monitor thread stack traces during test run. Usually, just one thread (Scanner) is running, all others are waiting on DFSInputStream in some places (as I said, too many synchronized methods). This is HDFS, not HBase.&lt;/p&gt;</comment>
                            <comment id="14063209" author="xieliang007" created="Wed, 16 Jul 2014 06:24:54 +0000"  >&lt;p&gt;Yes, i observed similar problem.  Long time ago i had a raw idea to impl a multi streams/readers prototype, maybe i can share the patch once ready&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14063630" author="lhofhansl" created="Wed, 16 Jul 2014 15:42:10 +0000"  >&lt;p&gt;&quot;Local mode&quot; is not the same. It does not actually run HDFS, but just pretty ad hoc DFS wrapper.&lt;br/&gt;
Tests are only valid when tested again real HDFS - even when HDFS is in single node mode.&lt;/p&gt;

&lt;p&gt;With actual HDFS I have not observed your numbers &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14063652" author="vrodionov" created="Wed, 16 Jul 2014 16:06:25 +0000"  >&lt;p&gt;HBase mini cluster runs HDFS and code path to access files/data is the same as in a real cluster mode, I think. At least, PackageSender/PackageReceiver(s) and all IPC stuff for NN and DN are present in stack traces.&lt;/p&gt;</comment>
                            <comment id="14063662" author="vrodionov" created="Wed, 16 Jul 2014 16:12:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;], I am working on efficient multiple scanners support for single store file as well. We  need this for several purposes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Improve single task granularity during query execution (currently, it is a single region)&lt;/li&gt;
	&lt;li&gt;Improve scanner performance during compaction(s)&lt;/li&gt;
	&lt;li&gt;Improve compaction performance during normal operations.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch will be submitted soon when we get all testing done.  &lt;/p&gt;</comment>
                            <comment id="14074812" author="lhofhansl" created="Fri, 25 Jul 2014 19:41:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;, curious about how you will find good splitpoints &lt;b&gt;inside&lt;/b&gt; a region. Regions can be assumed to be roughly of equal size (in terms of bytes, not rows), but inside a region the distribution of keys can be arbitrarily skewed, and hence unless you have more state you cannot find good splits inside a region.&lt;br/&gt;
(the region split points actually are a very rough histogram for data distribution)&lt;/p&gt;</comment>
                            <comment id="14074849" author="vrodionov" created="Fri, 25 Jul 2014 20:09:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The major priority right now is to improve compaction and normal operations during compaction. Sure we need to track region stats to make optimal inter-region splits, but even without such a stats we can decrease data skew significantly. &lt;/p&gt;</comment>
                            <comment id="14213870" author="lhofhansl" created="Sun, 16 Nov 2014 06:52:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;, I have a quite simple patch that would allow compaction to have their own, private readers. With what you&apos;ve seen, would that be a benefit?&lt;/p&gt;</comment>
                            <comment id="14214002" author="vrodionov" created="Sun, 16 Nov 2014 18:45:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yes that would be helpful for some use cases (compaction + 1 application scanner). There is a (not so simple) patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12031&quot; title=&quot;Parallel Scanners inside Region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12031&quot;&gt;HBASE-12031&lt;/a&gt; that fixes the issue for all use cases (compaction + N application scanners) but it seems that nobody has tried it yet. Phoenix parallel intra region scanners would benefit from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12031&quot; title=&quot;Parallel Scanners inside Region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12031&quot;&gt;HBASE-12031&lt;/a&gt; the most. &lt;/p&gt;</comment>
                            <comment id="14214031" author="lhofhansl" created="Sun, 16 Nov 2014 19:44:25 +0000"  >&lt;p&gt;See patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12411&quot; title=&quot;Optionally enable p-reads and private readers for compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12411&quot;&gt;&lt;del&gt;HBASE-12411&lt;/del&gt;&lt;/a&gt;, relatively easy way to have compactions work with their own scanners.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12553264">HBASE-5898</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12560511" name="7336-0.94.txt" size="2671" author="lhofhansl" created="Wed, 12 Dec 2012 06:06:09 +0000"/>
                            <attachment id="12560514" name="7336-0.96.txt" size="2721" author="lhofhansl" created="Wed, 12 Dec 2012 06:23:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 12 Dec 2012 06:40:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>297197</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 4 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i14n07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>235191</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Improves read concurrency by changing HFileBlock#readAtOffset from synchronized to reentrant lock; will have contending scanners fall back to preading rather than synchronized seek+read.  Keeps all cores busy rather than just the one.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>