<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:20:13 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-4583/HBASE-4583.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-4583] Integrate RWCC with Append and Increment operations</title>
                <link>https://issues.apache.org/jira/browse/HBASE-4583</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently Increment and Append operations do not work with RWCC and hence a client could see the results of multiple such operation mixed in the same Get/Scan.&lt;br/&gt;
The semantics might be a bit more interesting here as upsert adds and removes to and from the memstore.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12526942">HBASE-4583</key>
            <summary>Integrate RWCC with Append and Increment operations</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Wed, 12 Oct 2011 22:11:31 +0000</created>
                <updated>Tue, 27 Jan 2015 18:52:56 +0000</updated>
                            <resolved>Tue, 13 Nov 2012 02:04:48 +0000</resolved>
                                                    <fixVersion>0.95.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>19</watches>
                                                                <comments>
                            <comment id="13126224" author="streamy" created="Wed, 12 Oct 2011 22:56:55 +0000"  >&lt;p&gt;We likely won&apos;t be able to do in-place modifications or direct KV removal from MemStore.  A simple way would be to also introduce a delete marker that removes the previous value, but the marker will have the rwcc of the new edit, so you&apos;ll have the right consistency.&lt;/p&gt;

&lt;p&gt;This will lead to a build up of unnecessary KVs in the MemStore.  Periodically cleaning that up would be possible but unnecessarily complex I think.&lt;/p&gt;

&lt;p&gt;Another option would be to remove the previous KVs after you roll rwcc forward and release the row lock, before dropping the region-level lock.  Should definitely be possible.  Will obviously require a remangling of upsert but it&apos;s kinda dirty anyways.&lt;/p&gt;</comment>
                            <comment id="13139124" author="lhofhansl" created="Sat, 29 Oct 2011 05:41:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;Another option would be to remove the previous KVs after you roll rwcc forward and release the row lock, before dropping the region-level lock.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That should work. I&apos;ll take a crack at it.&lt;/p&gt;</comment>
                            <comment id="13139468" author="lhofhansl" created="Sat, 29 Oct 2011 22:04:09 +0000"  >&lt;p&gt;Looking at the code. There are some other weird things:&lt;br/&gt;
1. HRegion.applyFamilyMapToMemstore calls Store.add for each KV, which in turns calls Memstore.add. At each iteration both the Store and the Memstore take and release the read lock. Should be more efficient to pass a set of only take the locks once (at the expense of slightly reduce lock granularity).&lt;br/&gt;
2. Both HRegion.increment and HRegion.append (which is modeled after increment) update the memstore first, and then write the WAL. If the WAL sync fails there would be uncommitted state in the memstore. Fixing this should either incur a performance penalty (need to sync the WAL with the update.readLock held, or require memstore rollback (like we do for put now).&lt;/p&gt;

&lt;p&gt;I think these two should have separate jiras.&lt;/p&gt;</comment>
                            <comment id="13139471" author="yuzhihong@gmail.com" created="Sat, 29 Oct 2011 22:12:30 +0000"  >&lt;p&gt;Let&apos;s log an issue for #2 above.&lt;/p&gt;</comment>
                            <comment id="13139550" author="lhofhansl" created="Sun, 30 Oct 2011 07:03:58 +0000"  >&lt;p&gt;Here&apos;s a &lt;b&gt;sketch&lt;/b&gt; of a patch.&lt;br/&gt;
May need some clean up but should work.&lt;/p&gt;

&lt;p&gt;Basically the KVs of Append and Increment are applied to memstore through a call to the &quot;standard&quot; applyFamilyMapToMemstore(...); then duplicates are removed after the rwcc is moved forward.&lt;br/&gt;
Still a lot of boilerplate shared between Append and Increment.&lt;/p&gt;

&lt;p&gt;I think the dup removal does not need to hold the regions updatesLock.readLock (just the lock.readLock), but I am not entirely sure.&lt;/p&gt;

&lt;p&gt;Comments/suggestions/flames/praise are welcome. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13139551" author="lhofhansl" created="Sun, 30 Oct 2011 07:05:14 +0000"  >&lt;p&gt;Also changes some calls to take  &quot;? extends Collection&quot;  rather than List, so that I can use guava&apos;s MultiMap. If all callers would be changed the  &quot;? extends&quot;  could be removed.&lt;/p&gt;</comment>
                            <comment id="13139641" author="yuzhihong@gmail.com" created="Sun, 30 Oct 2011 15:20:18 +0000"  >&lt;p&gt;Publishing on reviewboard would make reviewing much easier.&lt;/p&gt;

&lt;p&gt;Patch looks good overall.&lt;/p&gt;

&lt;p&gt;A few minor comments.&lt;br/&gt;
newFamilyMap.asMap() is called more than once in append() and increment(). We can use a variable to hold its return and reuse the variable in place of the second call.&lt;br/&gt;
Line 3948 can be omitted:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       flush = isFlushSize(size);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;because we have the same call at line 3964.&lt;br/&gt;
Same argument can be made for the call at line 3824.&lt;/p&gt;

&lt;p&gt;In MemStore.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   * For each KeyValue &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the keyValue did already exist, with a
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should read &apos;if the KeyValue does already ...&apos;&lt;/p&gt;

&lt;p&gt;This comment in Store.java can be refined:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   * qualifier exists in MemStore with a memstoreTS &amp;lt; the passed KV, it will be removed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;because we only pass keyvalues to this.memstore.removeDups().&lt;/p&gt;</comment>
                            <comment id="13139660" author="yuzhihong@gmail.com" created="Sun, 30 Oct 2011 16:25:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;Still a lot of boilerplate shared between Append and Increment.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think we should take this opportunity to reduce duplicate code.&lt;/p&gt;</comment>
                            <comment id="13139721" author="lhofhansl" created="Sun, 30 Oct 2011 19:27:29 +0000"  >&lt;p&gt;The reason why I am calling isFlushSize again is because the duplicate removal might fail and that should not impact the operation. So I call it first in the required part and then again in the part that might fail. If the 2nd part fails, the first value should be used.&lt;/p&gt;

&lt;p&gt;Agree on the boiler plate removal.&lt;/p&gt;</comment>
                            <comment id="13139734" author="yuzhihong@gmail.com" created="Sun, 30 Oct 2011 20:03:48 +0000"  >&lt;p&gt;@Lars:&lt;br/&gt;
removeDupsInMemstore() isn&apos;t declared to throw exception. So I didn&apos;t expect failure in that part of the code.&lt;br/&gt;
If runtime exception comes out of it, would requestFlush() still be executed ?&lt;/p&gt;</comment>
                            <comment id="13139750" author="lhofhansl" created="Sun, 30 Oct 2011 20:38:34 +0000"  >&lt;p&gt;New patch on rb: &lt;a href=&quot;https://reviews.apache.org/r/2633/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/2633/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13139751" author="lhofhansl" created="Sun, 30 Oct 2011 20:40:09 +0000"  >&lt;p&gt;Some amount of boilerplate is necessary, because of the locking requirements (i.e. cannot have an upsert method in HRegion, since the setup and the first part of upsert need to have the same locks held).&lt;br/&gt;
Could have a boilerplate method and pass in a command object, but that would not necessarily make it more readable.&lt;/p&gt;</comment>
                            <comment id="13139788" author="yuzhihong@gmail.com" created="Sun, 30 Oct 2011 21:40:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;and then when the rowlock and the updatesLock.readLock are released, but after the rwcc is forwarded, the old rows are removed from the memstore.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think the above description would be more readable if expressed this way:&lt;/p&gt;

&lt;p&gt;after the rwcc is forwarded and, the rowlock and the updatesLock.readLock are released, the old rows are removed from the memstore.&lt;/p&gt;

&lt;p&gt;Correct me if the above is wrong.&lt;/p&gt;</comment>
                            <comment id="13139804" author="lhofhansl" created="Sun, 30 Oct 2011 21:56:08 +0000"  >&lt;p&gt;Sure, that is more to the point.&lt;/p&gt;</comment>
                            <comment id="13139837" author="hadoopqa" created="Mon, 31 Oct 2011 00:23:23 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12501538/4583-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12501538/4583-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -166 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestMasterFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/106//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/106//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/106//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/106//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/106//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/106//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13139876" author="lhofhansl" created="Mon, 31 Oct 2011 02:58:49 +0000"  >&lt;p&gt;Much cleaned up patch. Unifies the atomicUpsert (the called must acquire the locks, atomicUpsert releases them).&lt;/p&gt;

&lt;p&gt;Also includes rollback logic in case the sync of the WAL fails.&lt;/p&gt;</comment>
                            <comment id="13139900" author="lhofhansl" created="Mon, 31 Oct 2011 04:00:16 +0000"  >&lt;p&gt;Latest patch (also on RB, but needs to be attached so that I can trigger a patch build).&lt;/p&gt;</comment>
                            <comment id="13139907" author="hadoopqa" created="Mon, 31 Oct 2011 04:44:20 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12501555/4583-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12501555/4583-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -166 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailover&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/107//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/107//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/107//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/107//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/107//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/107//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13139936" author="hadoopqa" created="Mon, 31 Oct 2011 05:47:03 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12501559/4583-v4.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12501559/4583-v4.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -166 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestMasterFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitLogWorker&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/108//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/108//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/108//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/108//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/108//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/108//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13140916" author="yuzhihong@gmail.com" created="Tue, 1 Nov 2011 04:36:00 +0000"  >&lt;p&gt;I don&apos;t see &apos;Too many open files&apos; in &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/108//testReport/org.apache.hadoop.hbase.regionserver/TestSplitLogWorker/testAcquireTaskAtStartup/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/108//testReport/org.apache.hadoop.hbase.regionserver/TestSplitLogWorker/testAcquireTaskAtStartup/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13140923" author="lhofhansl" created="Tue, 1 Nov 2011 04:53:46 +0000"  >&lt;p&gt;TestSplitLogWorker passes locally with patch applied.&lt;/p&gt;</comment>
                            <comment id="13141914" author="lhofhansl" created="Wed, 2 Nov 2011 04:35:18 +0000"  >&lt;p&gt;As discussed on rb (thank Prakash and Jon), this is a bit more complicated than expected. Because append and increment are not idempotent we have to produce serializable schedules&lt;br/&gt;
(when we start with a value of 1 and add 1 by two separate increment operations, the end result has to be 3, regardless of how the two increment operations are interleaved).&lt;/p&gt;

&lt;p&gt;There are various ways to produce serializable schedules (pessimistic locking, optimistic locking with rechecking of pre conditions, snapshot isolation, etc), all which will probably mean worse performance for both append and increment.&lt;/p&gt;

&lt;p&gt;As said above the current implementation sync&apos;s the WAL after the memstore is updated and the new values are visible to other threads, and after the locks are released. A failure to sync the WAL will leave uncommitted state in the memstore, in addition other threads can be see uncommitted state.&lt;/p&gt;

&lt;p&gt;We can only safely make the changes available to other threads after (1) the WAL is committed (for these atomic, non-idempotent operations at least), at the same time we need to (2) retain the row lock until the rwcc is forwarded (otherwise two increment operations could come in and both see the same start value, leading to a non serializable schedule)... So my current patch is no good (it leads to problem (2))&lt;/p&gt;

&lt;p&gt;(1) and (2) together mean that the WAL needs to be sync&apos;ed with the row lock held (which would be quite a performance degradation).&lt;/p&gt;

&lt;p&gt;Now, what we could do is use rwcc to make the changes to the CFs atomic, and still sync the WAL after all the locks are released (as we do now). With this compromise everything would be correct &lt;b&gt;unless&lt;/b&gt; the sync&apos;ing of WAL fails (the theme used for puts to release locks early, then forward rwcc, and do a rollback of the applied values if WAL sync fails, does not work here).&lt;/p&gt;</comment>
                            <comment id="13142236" author="stack" created="Wed, 2 Nov 2011 16:02:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;There are various ways to produce serializable schedules (pessimistic locking, optimistic locking with rechecking of pre conditions, snapshot isolation, etc), all which will probably mean worse performance for both append and increment.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Shouldn&apos;t we do it anyways (though big yuck on your list above &amp;#8211; it makes my brain hurt just thinking on it.  Can you imagine rechecking pre-conditions and then replaying the failed transaction.. how much fun that&apos;ll be to code up!)?&lt;/p&gt;

&lt;p&gt;Shouldn&apos;t we be correct first and then performant?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;As said above the current implementation sync&apos;s the WAL after the memstore is updated and the new values are visible to other threads, and after the locks are released. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds broke to me; sounds like big compromise for sake of better perf.  Should we open new issue on this?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;(1) and (2) together mean that the WAL needs to be sync&apos;ed with the row lock held (which would be quite a performance degradation).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Shouldn&apos;t we ship with this config. with options to run hbase otherwise (memstore put then sync, etc.)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Now, what we could do is use rwcc to make the changes to the CFs atomic, and still sync the WAL after all the locks are released (as we do now). With this compromise everything would be correct unless the sync&apos;ing of WAL fails&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds broke still?&lt;/p&gt;

&lt;p&gt;Thanks for the write up and for digging in here fellas.&lt;/p&gt;
</comment>
                            <comment id="13142398" author="lhofhansl" created="Wed, 2 Nov 2011 18:35:55 +0000"  >&lt;p&gt;You make a good point. If people want performance they&apos;d pass false as wreToWal. Otherwise they will get correct and &quot;slow&quot; behavior. &lt;/p&gt;</comment>
                            <comment id="13142767" author="lhofhansl" created="Thu, 3 Nov 2011 01:30:27 +0000"  >&lt;p&gt;After thinking about this for a bit I am going to follow a different approach:&lt;br/&gt;
1. get locks&lt;br/&gt;
2. setup rwcc&lt;br/&gt;
3. sync WAL (of requested)&lt;br/&gt;
4. update memstore (add KVS)&lt;br/&gt;
5. forward rwcc&lt;br/&gt;
6. release locks&lt;br/&gt;
7. remove old dup KVs from memstore (pure optimization)&lt;/p&gt;

&lt;p&gt;This is guaranteed to produce serializable schedules (but the WAL is sync&apos;ed with lock held). Somebody who&apos;s not interested in absolute correctness, could pass false as writeToWal or enable deferredFlush.&lt;br/&gt;
Since the expensive part is sync&apos;ing the WAL I do not see any ways to make this better.&lt;/p&gt;

&lt;p&gt;Will have a new patch later tonight.&lt;/p&gt;</comment>
                            <comment id="13142770" author="lhofhansl" created="Thu, 3 Nov 2011 01:32:46 +0000"  >&lt;p&gt;Oops. Hit &quot;add&quot; too early.&lt;br/&gt;
6. Release row lock&lt;br/&gt;
7. remove old dup KVs from memstore (pure optimization)&lt;br/&gt;
8. release region lock&lt;/p&gt;</comment>
                            <comment id="13142794" author="stack" created="Thu, 3 Nov 2011 03:24:16 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;If a correct path in place, we might spend time trying to make it faster rather than speedup the by-pass.&lt;/p&gt;</comment>
                            <comment id="13142914" author="lhofhansl" created="Thu, 3 Nov 2011 07:21:58 +0000"  >&lt;p&gt;I have a new patch that does the above.&lt;br/&gt;
I wrote a multithreaded stress test and I found the following:&lt;/p&gt;

&lt;p&gt;1. I get incorrect behavior if I remove duplicates after the rowlock is released. (doing that with the rowlock held solved the problem).&lt;/p&gt;

&lt;p&gt;2. Even though the end result is correct, if I have the threads do GET operations I see that they do not always get all columns for a row. More interestingly I find sometimes that even KVs with a different timestamps and different memstoreTS show up in the same Get. (note that no flushing happens during the tests, so this has nothing to do with store files not carrying a memstoreTS).&lt;/p&gt;

&lt;p&gt;I thought at the least the Memstore was consistent (i.e. scanners only see columns when rwcc is rolled forward, but then they would see all columns affected by that writepoint).&lt;/p&gt;</comment>
                            <comment id="13143349" author="lhofhansl" created="Thu, 3 Nov 2011 17:27:35 +0000"  >&lt;p&gt;The problem is that if the changes are not visible immediately there might be old scanners still scanning the old KVs in the memstore and hence these cannot be removed.&lt;/p&gt;

&lt;p&gt;Increment/Append/ICV currently work because all changes are visible to &lt;b&gt;all&lt;/b&gt; scanners, because only then can we safely remove the duplicates.&lt;/p&gt;

&lt;p&gt;I now think that this:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Another option would be to remove the previous KVs after you roll rwcc forward and release the row lock, before dropping the region-level lock&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually does not work.&lt;/p&gt;

&lt;p&gt;In order to make this work we would need to know the lowest readpoint currently used by any other (read) transaction and only remove duplicate KVs &lt;b&gt;before&lt;/b&gt; that readpoint.&lt;br/&gt;
Since we do not have that information and readers also do not take out any locks, I don&apos;t see any way of making this work.&lt;/p&gt;</comment>
                            <comment id="13143458" author="stack" created="Thu, 3 Nov 2011 19:14:31 +0000"  >&lt;p&gt;Nice work Lars.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Increment/Append/ICV currently work because all changes are visible to all scanners, because only then can we safely remove the duplicates.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is &apos;cheating&apos;, right?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Since we do not have that information and readers also do not take out any locks, I don&apos;t see any way of making this work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Downside to leaving the duplicates in place would make for an explosion in versions?&lt;/p&gt;
</comment>
                            <comment id="13143633" author="lhofhansl" created="Fri, 4 Nov 2011 00:05:32 +0000"  >&lt;p&gt;Using memstoreTS of 0 is not necessarily cheating. Depends on how we define the semantics.&lt;br/&gt;
Not removing the old versions leads to an explosion of versions indeed, i also found hard to define behavior if two increments happen in the same ms.&lt;br/&gt;
The question is also: do we need increments/ appends consistent across cfs?&lt;br/&gt;
The real problem is that we&apos;re making values available before the wal was written.&lt;br/&gt;
(Typed on a phone) &lt;/p&gt;

</comment>
                            <comment id="13143712" author="lhofhansl" created="Fri, 4 Nov 2011 03:02:31 +0000"  >&lt;p&gt;(on a computer now)&lt;/p&gt;

&lt;p&gt;So to be more specific... The problem is that we cannot remove duplicate KVs unless we can guarantee that no scanners still operation on these KVs; the only way (currently) to guarantee this is to set the memstoreTS of the changed (new) KVs to 0 and hence making them available to all scanners immediately.&lt;br/&gt;
That on the other hand means that we cannot delay the visibility of any CFs until after all CFs are updated.&lt;br/&gt;
If we do not remove duplicate KVs the memstore will explode &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; (and I also have to investigate the strange behavior I saw with atomic operations with identical timestamps).&lt;/p&gt;

&lt;p&gt;We can still, however, at least update and sync the WAL first and then modify the memstore.&lt;/p&gt;</comment>
                            <comment id="13143716" author="yuzhihong@gmail.com" created="Fri, 4 Nov 2011 03:23:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;We can still, however, at least update and sync the WAL first and then modify the memstore.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sounds fine to me.&lt;/p&gt;

&lt;p&gt;Consistency across multiple column families can be handled in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2856&quot; title=&quot;TestAcidGuarantee broken on trunk &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2856&quot;&gt;&lt;del&gt;HBASE-2856&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13144580" author="lhofhansl" created="Sat, 5 Nov 2011 04:47:34 +0000"  >&lt;p&gt;I don&apos;t think that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2856&quot; title=&quot;TestAcidGuarantee broken on trunk &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2856&quot;&gt;&lt;del&gt;HBASE-2856&lt;/del&gt;&lt;/a&gt; will address the issues I raised above (which is caused by deleting KVs from the memstore).&lt;/p&gt;

&lt;p&gt;Updating the WAL first, then applying the changes to the memstore, and making them visible immediately, all while holding the rowlock is a relatively little change. It&apos;ll make Increment/Append/ICV behave correctly in the face of failing WAL sync&apos;s, but will also significantly slow them down (in terms of throughput, but not latency).&lt;/p&gt;

&lt;p&gt;I will factor some common bits out (similar to my initial patch), so that if we want to tackle this in the future (for example by maintaining the lowest current readpoint in use, or something), there&apos;ll be just one place to change it.&lt;/p&gt;

&lt;p&gt;If one want performance, one would set writeToWal to false; but maybe these three ops should get another flag to allow for delayed log flush (which would be the current behavior).&lt;/p&gt;

&lt;p&gt;Lastly, we can just document that the Append and Increment operations are convenience methods for grouping many updates into a single roundtrip (not to achieve consistency between CFs).&lt;/p&gt;</comment>
                            <comment id="13153419" author="lhofhansl" created="Sat, 19 Nov 2011 07:26:11 +0000"  >&lt;p&gt;I think I might be able to use HRegion.getSmallestReadPoint() for this (introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2856&quot; title=&quot;TestAcidGuarantee broken on trunk &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2856&quot;&gt;&lt;del&gt;HBASE-2856&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We cannot unconditionally remove cells from the memstore as we do now, but we can remove all those that are before the region&apos;s smallestReadPoint, as we know that no scanner can see those anyway.&lt;/p&gt;</comment>
                            <comment id="13153423" author="lhofhansl" created="Sat, 19 Nov 2011 07:39:04 +0000"  >&lt;p&gt;Ah no, I&apos;d need the equivalent of getLargestReadPoint() and then could remove KVs never than that, might be too expensive to do anyway, though, as all active scanners need to be traversed.&lt;/p&gt;</comment>
                            <comment id="13153454" author="yuzhihong@gmail.com" created="Sat, 19 Nov 2011 11:15:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;then could remove KVs never than that&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I guess the above should read &apos;then could remove KVs newer than that&apos;&lt;/p&gt;</comment>
                            <comment id="13153645" author="lhofhansl" created="Sun, 20 Nov 2011 02:32:46 +0000"  >&lt;p&gt;Yep. Thinking about it, though, that wouldn&apos;t be very good, because any scanner scanning any row would prevent the older from being cleaned from the memstore.&lt;/p&gt;</comment>
                            <comment id="13185161" author="lhofhansl" created="Thu, 12 Jan 2012 19:19:05 +0000"  >&lt;p&gt;There currently is no good solution for this.&lt;/p&gt;</comment>
                            <comment id="13485503" author="lhofhansl" created="Sat, 27 Oct 2012 21:08:39 +0000"  >&lt;p&gt;See discussion on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7051&quot; title=&quot;CheckAndPut should properly read MVCC&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7051&quot;&gt;&lt;del&gt;HBASE-7051&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
I think if we wait for prior MVCC transactions to finish we can make this correct without setting the memstoreTS to 0&lt;/p&gt;</comment>
                            <comment id="13485529" author="lhofhansl" created="Sun, 28 Oct 2012 00:06:48 +0000"  >&lt;p&gt;Here&apos;s a pretty radical change!&lt;/p&gt;

&lt;p&gt;It removes Memstore.upsert completely along with all callers and all tests that were testing that functionality.&lt;/p&gt;

&lt;p&gt;Note that while upsert is no longer needed for &lt;b&gt;correctness&lt;/b&gt; (it used to set the memstoreTS to 0 so that other increments/appends would be guaranteed to see the previous values), it was still a potential performance improvement because stale KVs were removed immediately.&lt;/p&gt;

&lt;p&gt;However, this actually used to violate the HBase VERSIONS contract.&lt;br/&gt;
TestAtomicOperation.testIncrementMultiThreads is not measurably slower on my machine.&lt;/p&gt;

&lt;p&gt;With this patch Increment and Append are no longer special w.r.t. MVCC.&lt;/p&gt;</comment>
                            <comment id="13485531" author="lhofhansl" created="Sun, 28 Oct 2012 00:09:51 +0000"  >&lt;p&gt;Let&apos;s get a HadoopQA run.&lt;/p&gt;</comment>
                            <comment id="13485534" author="lhofhansl" created="Sun, 28 Oct 2012 00:34:16 +0000"  >&lt;p&gt;Not that Memstore.upsert could be made to honor MVCC by passing in the regions smallest readPoint of any scanner and only deleting KVs older than that - but that would still break the HBase contract that everything in HBase is versioned.&lt;/p&gt;</comment>
                            <comment id="13485559" author="yuzhihong@gmail.com" created="Sun, 28 Oct 2012 03:27:50 +0000"  >&lt;p&gt;Looking at PreCommit build #3166, looks like there was compilation error against Hadoop 2.0&lt;/p&gt;</comment>
                            <comment id="13485566" author="lhofhansl" created="Sun, 28 Oct 2012 04:16:57 +0000"  >&lt;p&gt;Hmm... The log output there is quite useless.&lt;/p&gt;</comment>
                            <comment id="13485567" author="lhofhansl" created="Sun, 28 Oct 2012 04:21:36 +0000"  >&lt;p&gt;Somehow the changes to TestMemstore did not make it into the patch. Should compile now.&lt;/p&gt;</comment>
                            <comment id="13485572" author="hadoopqa" created="Sun, 28 Oct 2012 05:24:47 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551105/4583-trunk-radical_v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551105/4583-trunk-radical_v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3167//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13485574" author="lhofhansl" created="Sun, 28 Oct 2012 05:30:21 +0000"  >&lt;p&gt;Correctness wise this looks pretty good and it does remove a lot of goofy code.&lt;/p&gt;

&lt;p&gt;Please have a careful look, this will impact Increment/Append performance as each increment will no longer remove the old KVs from the memstore (if it is still found in the memstore).&lt;/p&gt;

&lt;p&gt;But it will make it correct w.r.t. version and TTL handling and remove any special status from Increment and Append.&lt;/p&gt;</comment>
                            <comment id="13485707" author="lhofhansl" created="Sun, 28 Oct 2012 20:47:12 +0000"  >&lt;p&gt;This makes it even more like all other other operation: Use the existing applyFamilyMapToMemstore method to make the actual changes to the memstore. &lt;/p&gt;</comment>
                            <comment id="13485721" author="hadoopqa" created="Sun, 28 Oct 2012 21:44:54 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551123/4583-trunk-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551123/4583-trunk-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3168//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13486291" author="gchanan" created="Mon, 29 Oct 2012 19:49:55 +0000"  >&lt;p&gt;Patch looks good, +1.&lt;/p&gt;

&lt;p&gt;I don&apos;t think these need to be covered in this JIRA, but some things to consider:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Should we do the same for checkAndPut?&lt;/li&gt;
	&lt;li&gt;Ideally we would have some performance testing in this area.  Like a YCSB job that does appends/increments in a uniform distribution.  This may be significantly slower now?&lt;/li&gt;
	&lt;li&gt;Also some unit (correctness) testing would be good.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13486363" author="lhofhansl" created="Mon, 29 Oct 2012 21:08:24 +0000"  >&lt;p&gt;Yes, I think the same can work for checkAndXXX... In fact maybe now we can unify all of those. They all have 3 steps:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;precondition/get old values&lt;/li&gt;
	&lt;li&gt;internal logic&lt;/li&gt;
	&lt;li&gt;update values&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It might be possible to extract that boilerplate and pass in an implementation of an &quot;AtomicOperation&quot; interface or something.&lt;/p&gt;

&lt;p&gt;In terms of performance... It will be slower. It&apos;s no longer doing upserts (i.e. removing old KVs still found in the memstore).&lt;br/&gt;
Personally I do not understand why Increment would be special here. All other operations work by creating new versions and they all could be sped up if we would remove stale versions from the memstore immediately. Why are Puts not doing upserts? And why would we care less about the history of an increment column?&lt;br/&gt;
I think if we wanted an upsert type functionality it should be an option for every operation (except Delete, I guess). We&apos;d declare we do not care about the history and then the operation could go through existing versions of KVs for which it can prove that no scanner is using them (by using the region&apos;s smallest readpoint).&lt;/p&gt;

&lt;p&gt;The only performance test I did was to run TestAtomicOperation#testIncrementMultiThreads, which is about 30% slower (6.5s vs 5s before). This is in part due to the MVCC enforcement and in part due to the fact the memstore will fill up sooner.&lt;/p&gt;

&lt;p&gt;Edit: Spelling&lt;/p&gt;</comment>
                            <comment id="13486369" author="lhofhansl" created="Mon, 29 Oct 2012 21:13:11 +0000"  >&lt;p&gt;If I only add the MVCC waiting part to Increment I see about 10% decrease in performance.&lt;/p&gt;</comment>
                            <comment id="13486376" author="lhofhansl" created="Mon, 29 Oct 2012 21:19:53 +0000"  >&lt;p&gt;Hmm... And if I set maxversions to 1 in the Region used by TestAtomicOperation#testIncrementMultiThreads I see a 15% decrease in performance only.&lt;br/&gt;
(There&apos;s high variance in these number, though).&lt;/p&gt;</comment>
                            <comment id="13486377" author="lhofhansl" created="Mon, 29 Oct 2012 21:21:15 +0000"  >&lt;p&gt;So the main question is: Keep the upsert functionality for Increment and make it MVCC aware? Or say that Increment is not special here and everything in HBase is versioned?&lt;/p&gt;</comment>
                            <comment id="13486381" author="jdcryans" created="Mon, 29 Oct 2012 21:25:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why are Puts not doing upserts? And why would we care less about the history of an increment column?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Most of the Increment workloads I know about are usually trying to push a lot more ops/sec than puts, which in turn generates both MemStore and HLog garbage. The way we currently upsert in the MemStore is saving us from flushing hundreds of GBs of crap than then needs to be compacted. &lt;/p&gt;

&lt;p&gt;As to if we should do upsert for Puts... good question, I guess we could permit that.&lt;/p&gt;</comment>
                            <comment id="13486390" author="gchanan" created="Mon, 29 Oct 2012 21:36:46 +0000"  >&lt;p&gt;I agree with your comments about making a common code path for the read/update operations and in there we could decide if we want to do upserts each time.&lt;/p&gt;

&lt;p&gt;The upsert argument is complicated because it&apos;s really a question of the read workload as much as the write workload, but we have to decide at write-time w/o much information (at least now as we don&apos;t collect statistics or anything).  Off the top of my head I could see upserts being more useful for increments than puts, since increments are only holding numerical values (so old version x is probably just the current version minus the usual increment amount times x).  Puts might have information you&apos;d actually want to look at (job titles, times of last submitted help-desk tickets,etc).  This is very hand-wavy though.&lt;/p&gt;

&lt;p&gt;So, I think I&apos;d just keep the upsert functionality for now and make it MVCC aware.  We can revisit if/when we unify the implementations.&lt;/p&gt;</comment>
                            <comment id="13486394" author="lhofhansl" created="Mon, 29 Oct 2012 21:40:10 +0000"  >&lt;p&gt;Yeah... You guys are right.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I was enjoying all that removed code.&lt;/p&gt;</comment>
                            <comment id="13486517" author="lhofhansl" created="Mon, 29 Oct 2012 23:50:37 +0000"  >&lt;p&gt;Trying a patch right now with upsert honoring MVCC. I get extreme lock contention right now (test that took 5s takes over 10m now)... Not sure what&apos;s going on, yet.&lt;/p&gt;</comment>
                            <comment id="13486694" author="lhofhansl" created="Tue, 30 Oct 2012 07:02:00 +0000"  >&lt;p&gt;Here&apos;s a less radical patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
TestAtomicOperation also tests concurrency with Gets (which fails without the rest of this patch).&lt;br/&gt;
The change in performance is within the noise. I suppose an unclosed scanner could cause a pathological situation where upsert wouldn&apos;t be able to remove older KVs, because it cannot prove that they are not accessed by a current scanner. When enforcing MVCC this is unavoidable, though.&lt;/p&gt;

&lt;p&gt;So I this patch is good.&lt;/p&gt;</comment>
                            <comment id="13486703" author="lhofhansl" created="Tue, 30 Oct 2012 07:12:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The way we currently upsert in the MemStore is saving us from flushing hundreds of GBs of crap than then needs to be compacted. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That is actually not entirely true. With &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4241&quot; title=&quot;Optimize flushing of the Store cache for max versions and (new) min versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4241&quot;&gt;&lt;del&gt;HBASE-4241&lt;/del&gt;&lt;/a&gt; it would flush the store more frequently, but during flush older versions of KVs are ignored (i.e. not flushed at all, and thus they do not need to be compacted later). That&apos;s the reason why the &quot;radical&quot; patch is not 100x slower, but just 15% (with VERSIONS set to 1).&lt;/p&gt;

&lt;p&gt;Please have a look at the &quot;less radical&quot; patch.&lt;br/&gt;
Because of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4241&quot; title=&quot;Optimize flushing of the Store cache for max versions and (new) min versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4241&quot;&gt;&lt;del&gt;HBASE-4241&lt;/del&gt;&lt;/a&gt; I still prefer the &quot;radical&quot; version (trunk-v3). With many increments for a single row the search in the memstore for upsert might even become counter productive.&lt;/p&gt;

&lt;p&gt;Anyway... I&apos;m fine with committing either of the two patches here. Both should be correct in terms of MVCC behavior.&lt;/p&gt;</comment>
                            <comment id="13486724" author="hadoopqa" created="Tue, 30 Oct 2012 08:05:31 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551310/4583-trunk-less-radical.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551310/4583-trunk-less-radical.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3179//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13486849" author="ram_krish" created="Tue, 30 Oct 2012 13:05:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;We&apos;d declare we do not care about the history and then the operation could go through existing versions of KVs &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This could be done.&lt;br/&gt;
+1 on doing the same for checkAndPut also.&lt;/p&gt;</comment>
                            <comment id="13487076" author="lhofhansl" created="Tue, 30 Oct 2012 18:06:34 +0000"  >&lt;p&gt;Cleaned up version of the less radical patch.&lt;br/&gt;
Fixed some bugs in the existing upsert code on the way.&lt;/p&gt;

&lt;p&gt;This is the one I would like to commit soon.&lt;/p&gt;</comment>
                            <comment id="13487078" author="zhihyu@ebaysf.com" created="Tue, 30 Oct 2012 18:06:41 +0000"  >&lt;p&gt;Nice effort, Lars.&lt;/p&gt;

&lt;p&gt;For 4583-trunk-less-radical.txt:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; The smallest mvcc readPoint across all the scanners in &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
+   * region. Writes newer than &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; readPoint, are guaranteed not to be seen
+   * by any current scanner.
+   */
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getLargestReadPoint() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The first line of javadoc doesn&apos;t seem to match name of method - smallest in javadoc vs. largest in method name.&lt;br/&gt;
For MemStore.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * This now only used by tests.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Insert an &apos;is&apos; between This and now.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    * @param kvs
    * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; change in memstore size
    */
-  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; upsert(Iterable&amp;lt;KeyValue&amp;gt; kvs) {
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; upsert(Iterable&amp;lt;KeyValue&amp;gt; kvs, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; readpoint) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please add javadoc for new parameter readPoint. Same with upsert().&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (cur.getType() == KeyValue.Type.Put.getCode() &amp;amp;&amp;amp; cur.getMemstoreTS() &amp;lt; readpoint - 1) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why do we need to subtract one from readPoint ? Considering less than is used already.&lt;/p&gt;</comment>
                            <comment id="13487099" author="lhofhansl" created="Tue, 30 Oct 2012 18:30:01 +0000"  >&lt;p&gt;Hey Ted... Thanks. You looked at an older patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Please see 4583-trunk-less-radical-v2.txt&lt;/p&gt;</comment>
                            <comment id="13487105" author="lhofhansl" created="Tue, 30 Oct 2012 18:32:59 +0000"  >&lt;p&gt;I guess v2 and you comment were posted at exactly the same time &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13487107" author="zhihyu@ebaysf.com" created="Tue, 30 Oct 2012 18:34:02 +0000"  >&lt;p&gt;I did look at 4583-trunk-less-radical-v2.txt&lt;br/&gt;
Can you enlighten me on my last question above ?&lt;/p&gt;</comment>
                            <comment id="13487116" author="gchanan" created="Tue, 30 Oct 2012 18:45:20 +0000"  >&lt;p&gt;Taking a look now.&lt;/p&gt;

&lt;p&gt;What made the performance within the noise now when it was so bad before?&lt;/p&gt;</comment>
                            <comment id="13487132" author="hadoopqa" created="Tue, 30 Oct 2012 19:05:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551392/4583-trunk-less-radical-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551392/4583-trunk-less-radical-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3181//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13487163" author="gchanan" created="Tue, 30 Oct 2012 19:52:29 +0000"  >&lt;p&gt;New test for increment looks good.  Should we have a similar one for append as well?&lt;/p&gt;

&lt;p&gt;I also have the same question as Ted about &quot;readpoint -1&quot;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       &lt;span class=&quot;code-comment&quot;&gt;// create or update (upsert) a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue with
&lt;/span&gt;       &lt;span class=&quot;code-comment&quot;&gt;// &apos;now&apos; and a 0 memstoreTS == immediately visible
&lt;/span&gt;       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; upsert(Arrays.asList(
-          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, family, qualifier, now, Bytes.toBytes(newValue)))
+          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, family, qualifier, now, Bytes.toBytes(newValue))), 1L
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;it looks from here like we will never remove anything via updateColumnValue, because we would need cur.getMemstoreTS() &amp;lt; readpoint - 1 =&amp;gt; cur.getMemstoreTS() &amp;lt; 1-1 =&amp;gt; cur.getMemstoreTS() &amp;lt; 0?  Why do we pass 1 in the above?&lt;/p&gt;

&lt;p&gt;I also notice in append/increment we call completeMemstoreInsert before we sync to the WAL, while other calls like put do it after.  Is it safe to do it before?  Why doesn&apos;t put do it that way, then?&lt;/p&gt;</comment>
                            <comment id="13487168" author="gchanan" created="Tue, 30 Oct 2012 20:00:19 +0000"  >&lt;p&gt;Thinking about completeMemstoreInsert again, it seems wrong to have it before we sync to the WAL.  Otherwise, a read could see the new data, a crash could occur before the WAL sync finishes, and recovery would lose the data.&lt;/p&gt;</comment>
                            <comment id="13487174" author="lhofhansl" created="Tue, 30 Oct 2012 20:06:20 +0000"  >&lt;p&gt;@Ted: As for readpoint - 1. Now that you ask, I found this through &lt;b&gt;long&lt;/b&gt; debugging. I am not actually sure I can explain that right now.&lt;/p&gt;

&lt;p&gt;@Gregory: My initial code had a bug where it did not remove the old values at all, and hence it not only exploded the memstore, it also churned through all KVs every single time to see if some of them can be removed.&lt;/p&gt;</comment>
                            <comment id="13487189" author="jdcryans" created="Tue, 30 Oct 2012 20:25:10 +0000"  >&lt;p&gt;Patch looks good although I&apos;m not too familiar with that part of the code.&lt;/p&gt;

&lt;p&gt;I tested it locally and it doesn&apos;t really seem to have a big impact on performance (3 threads pounding 1 row with ICVs).&lt;/p&gt;

&lt;p&gt;I&apos;m not sure about putting this into 0.94 tho, we&apos;re already pretty late in the point releases for changes like this one.&lt;/p&gt;</comment>
                            <comment id="13487326" author="lhofhansl" created="Tue, 30 Oct 2012 22:40:57 +0000"  >&lt;p&gt;I was checking out why readpoint - 1 is needed. Turns out the patch is not entirely correct.&lt;/p&gt;

&lt;p&gt;The new KV is newer than the current readpoint (by definition, because it is written from a new transaction). A scanner running at the current readpoint, thus, will not see the new KV, but rather the older one. That means that we can only remove older KVs if there is a newer one that is still older than the current readpoint (which means all new scanner will see that one).&lt;br/&gt;
readpoint - 1 fixed it for my test case, but it is not generally correct.&lt;/p&gt;</comment>
                            <comment id="13487348" author="lhofhansl" created="Tue, 30 Oct 2012 23:05:47 +0000"  >&lt;p&gt;This patch is doing the right thing (TM).&lt;br/&gt;
A KV is removable if it is not the newest one older than that smallest readpoint.&lt;/p&gt;

&lt;p&gt;I.e. no current scanner sees that KV.&lt;/p&gt;</comment>
                            <comment id="13487359" author="lhofhansl" created="Tue, 30 Oct 2012 23:14:00 +0000"  >&lt;p&gt;@Gregory: updateColumnValue is only used in tests... It should just be removed, but there&apos;re tests using it still.&lt;br/&gt;
And you&apos;re right the memstore transaction should not be completed before the WAL is sync&apos;ed.&lt;/p&gt;

&lt;p&gt;Update coming.&lt;/p&gt;</comment>
                            <comment id="13487366" author="lhofhansl" created="Tue, 30 Oct 2012 23:24:30 +0000"  >&lt;p&gt;Does completeMemstoreInsert after the WAL sync. (good catch Gregory).&lt;br/&gt;
Unfortunately the only way to do this without more restructuring is another try/catch wrapper.&lt;br/&gt;
As for updateColumnValue... All the test there make the call directly, there is no region to derive a readpoint from. No not actually deleting anything is the best approach.&lt;/p&gt;</comment>
                            <comment id="13487382" author="gchanan" created="Tue, 30 Oct 2012 23:55:34 +0000"  >&lt;p&gt;append looks like it calls completeMemstoreInsert twice (once before sync, once after)&lt;/p&gt;</comment>
                            <comment id="13487387" author="lhofhansl" created="Wed, 31 Oct 2012 00:00:10 +0000"  >&lt;p&gt;Ah crap... I&apos;m tired today. Fixed.&lt;/p&gt;</comment>
                            <comment id="13487393" author="zhihyu@ebaysf.com" created="Wed, 31 Oct 2012 00:08:56 +0000"  >&lt;p&gt;Putting the patch on review board, I was able to understand the changes better &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
completeMemstoreInsert() doesn&apos;t throw exception:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void completeMemstoreInsert(WriteEntry e) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I wonder if the last mvcc.completeMemstoreInsert(w) call can be latched onto (before) closeRegionOperation():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        mvcc.completeMemstoreInsert(w);        
       }
-      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (writeToWAL) {
-        syncOrDefer(txid); &lt;span class=&quot;code-comment&quot;&gt;// sync the transaction log outside the rowlock
&lt;/span&gt;-      }
     } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
       closeRegionOperation();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This way there is no need to add one more try / catch block.&lt;br/&gt;
There are also some white spaces introduced in patch v5.&lt;/p&gt;</comment>
                            <comment id="13487407" author="lhofhansl" created="Wed, 31 Oct 2012 00:31:24 +0000"  >&lt;p&gt;@Ted: I was thinking about that. It would have meant to put mvcc.beginMemstoreInsert up and out of the first try/catch block, and since we have to do this after the lock was acquired, we&apos;d have to move that up too.&lt;/p&gt;</comment>
                            <comment id="13487408" author="hadoopqa" created="Wed, 31 Oct 2012 00:33:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551452/4583-trunk-less-radical-v4.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551452/4583-trunk-less-radical-v4.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestHRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3190//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13487414" author="gchanan" created="Wed, 31 Oct 2012 00:41:51 +0000"  >&lt;p&gt;#1&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// only remove Puts that concurrent scanners cannot possibly see (readpoint - 1)&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the &quot;readpoint -1&quot; stuff is out of date I think.&lt;/p&gt;

&lt;p&gt;#2 I&apos;m fine with updateColumnValue if it&apos;s only used in tests and the tests pass.&lt;/p&gt;

&lt;p&gt;#3 I&apos;ll file some JIRAs for adding a test for append (similar to your test for increment) and for doing what you have done here for checkAndPut.  checkAndPut should be simple because I don&apos;t think it upserts.&lt;/p&gt;

&lt;p&gt;#4 We may also need to a test to check that append/increment properly wait for all writes to complete.  Your test, as best as I can tell, checks that the upsert behaves properly with scanners, but the waiting for all writes to complete is sort of a separate issue.  Something like what I suggested over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7051&quot; title=&quot;CheckAndPut should properly read MVCC&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7051&quot;&gt;&lt;del&gt;HBASE-7051&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
current cell value is 10.  Do a put of 15 and an increment by 1.  Only acceptable answers are 15 and 16, but without this patch, we can get 11.&lt;br/&gt;
Again, this can be handled in a separate JIRA.&lt;/p&gt;

&lt;p&gt;#5 I&apos;m fine with this for 0.96.  What do you think about 0.94?  JD makes a good point that we are far along to have such a big change, but on the other hand, atomic issues are pretty serious.  Wondering what your thoughts are.  I&apos;d at least want to do some of my own performance testing before putting it in 0.94.&lt;/p&gt;</comment>
                            <comment id="13487439" author="hadoopqa" created="Wed, 31 Oct 2012 01:32:16 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551462/4583-trunk-less-radical-v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551462/4583-trunk-less-radical-v5.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3192//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13487442" author="lhofhansl" created="Wed, 31 Oct 2012 01:44:38 +0000"  >&lt;p&gt;#1 Yeah, old comment.&lt;br/&gt;
#2 Should refactor the tests to call Upsert on Store and Memstore directly rather than this - now defunct - method. The patch at least removes it from the public API on both cases.&lt;br/&gt;
#3 I should add a test for Append. Bit more tricky than Increment as you get ever increasing values (in terms of size) &lt;br/&gt;
#4 the test validates that. TestAtomicOperation would not return correct results without the Increments waiting for all previous changes. (before this patch this was handled by forcing the memTSs of all KV to 0 immediately)&lt;br/&gt;
#5 I&apos;m fine either here, actually. Definitely 0.96, +0 on 0.94.&lt;/p&gt;</comment>
                            <comment id="13487454" author="lhofhansl" created="Wed, 31 Oct 2012 02:06:42 +0000"  >&lt;p&gt;Another interesting thought: If in addition to counting all the KVs older than the readpoint I also count all versions of the KVs seen so far we can use this for &quot;memstore compactions&quot;. I.e. each memstore change would be an upsert that would add the new KVs and then remove all KVs that not be flushed to disk anyway.&lt;/p&gt;</comment>
                            <comment id="13487499" author="lhofhansl" created="Wed, 31 Oct 2012 03:54:41 +0000"  >&lt;p&gt;Alas, that would not work nicely with mslab.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt; I was wondering whether you could do your same performance test with the &quot;radical&quot; version of this patch (4583-trunk-v3.txt)?&lt;/p&gt;</comment>
                            <comment id="13487527" author="lhofhansl" created="Wed, 31 Oct 2012 05:03:15 +0000"  >&lt;p&gt;This is hopefully the last version here.&lt;br/&gt;
Add a test for Append.&lt;/p&gt;

&lt;p&gt;I tried to remove updateColumnValue, but the tests are in part testing specific updateColumnValue functionality, which is hard to separate from the upsert tests. That is for another jira, I think.&lt;/p&gt;</comment>
                            <comment id="13487579" author="hadoopqa" created="Wed, 31 Oct 2012 06:28:54 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551483/4583-trunk-less-radical-v6.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551483/4583-trunk-less-radical-v6.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 85 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3196//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13489112" author="jdcryans" created="Thu, 1 Nov 2012 23:04:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;Jean-Daniel Cryans I was wondering whether you could do your same performance test with the &quot;radical&quot; version of this patch (4583-trunk-v3.txt)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What I saw is it&apos;s 10% slower, but also that it was flushing tiny HFiles.&lt;/p&gt;</comment>
                            <comment id="13489119" author="lhofhansl" created="Thu, 1 Nov 2012 23:10:28 +0000"  >&lt;p&gt;You guys used this more extensively at SU than anybody else, I think. Would you stick to your statement that the upsert complexity and breaking of the general HBase VERSIONS contract is warranted for the performance gain?&lt;/p&gt;

&lt;p&gt;It would probably be am even bigger problem if there&apos;s other load (that fills the memstore) that now unnecessarily needs to be flushed because of many increments.&lt;/p&gt;</comment>
                            <comment id="13489136" author="jdcryans" created="Thu, 1 Nov 2012 23:24:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;You guys used this more extensively at SU than anybody else, I think. Would you stick to your statement that the upsert complexity and breaking of the general HBase VERSIONS contract is warranted for the performance gain?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&apos;re kind of dependent of the current performance now, unless we start double counting or missing increments then statu quo I&apos;d say is preferred. It&apos;s still a bit unclear to me what the implications of not having this jira mean. And also what strick and non-strict means.&lt;/p&gt;

&lt;p&gt;Let me phrase it like this then: I think everyone can agree that we don&apos;t want data loss (eg no missed increments), so taking a performance hit is likely necessary. If it&apos;s only a case where a client reading a counter would miss the most updated values, then that&apos;s something at least I can live with.&lt;/p&gt;</comment>
                            <comment id="13489600" author="lhofhansl" created="Fri, 2 Nov 2012 18:00:19 +0000"  >&lt;p&gt;The problem this fixes is how Increments/Appends interact with &lt;b&gt;other&lt;/b&gt; operations.&lt;br/&gt;
There are two problems:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;A race between a prior Put and a following Increment. The Increment might not see the latest state generated by the Put.&lt;/li&gt;
	&lt;li&gt;An increment that updates multiple columns on a row can cause a concurrent scanner to see partially applied rows. The specifics here are that in order to make Increments strictly serializable upsert used to set the memstoreTS to 0, making the change visible immediately to all concurrent and future scanners.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;As long as only increments are used and you do not care for partially applied rows, the current code is correct.&lt;/p&gt;

&lt;p&gt;#1 is fixed by having the Increment wait for prior MVCC transactions with the lock held.&lt;br/&gt;
#2 is fixed by either getting rid of upsert altogether (the &quot;radical&quot; version of this patch, which incurs the 10% overhead you measured) or make upsert MVCC aware (the &quot;less radical&quot; version of this patch, which should only incur minimal overhead).&lt;/p&gt;

&lt;p&gt;The objective of the &quot;radical&quot; patch was to fix these problems and to also get rid of a lot of code specific to increment (and which also breaks the VERSIONS contract).&lt;br/&gt;
The &quot;less radical&quot; patch fixes the issues by fixing upsert to be MVCC aware.&lt;/p&gt;

&lt;p&gt;TL;DR: I&apos;m happy with either patch, slightly leaning towards the &quot;radical&quot; version. But I think you&apos;re right that the current Increment performance is now expected, so the &quot;less radical&quot; version is probably the way to go.&lt;/p&gt;</comment>
                            <comment id="13489635" author="jdcryans" created="Fri, 2 Nov 2012 18:30:45 +0000"  >&lt;p&gt;Wonderful write-up, thanks for taking the time to do it Lars.&lt;/p&gt;

&lt;p&gt;I&apos;m not too worried about #1, it seems like a weird use case but it looks like it&apos;s easily fixed.&lt;/p&gt;

&lt;p&gt;About #2, that&apos;s more important... I think we should always be correct, but I would skip putting this in 0.94&lt;/p&gt;</comment>
                            <comment id="13489653" author="gchanan" created="Fri, 2 Nov 2012 18:55:59 +0000"  >&lt;p&gt;Great write-up, Lars.&lt;/p&gt;

&lt;p&gt;I&apos;m leaning towards the &quot;less radical version&quot; at this point.  10% is right on the border of what I would consider acceptable without a way for the user to opt out (why wouldn&apos;t they opt out?  if they care about breaking the VERSIONS contract I guess).&lt;/p&gt;

&lt;p&gt;Is there a sensible API change we could make here or a sensible change of the VERSIONS definition?  We are just doing a write on a single row with &quot;logical&quot; deletes (not via delete markers).  It seems like we should be able to fit this in our model.&lt;/p&gt;</comment>
                            <comment id="13489743" author="lhofhansl" created="Fri, 2 Nov 2012 20:54:59 +0000"  >&lt;p&gt;The logic in upsert could be changed to also count the number of versions (in addition to versions older than then the current readpoint) and then consider both counts before removing KVs. That way we get the current upsert logic (if you set VERSIONS =&amp;gt; 1 for the CF) and also keep at least as many versions as declared in the CF.&lt;br/&gt;
That&apos;s for another jira, though.&lt;/p&gt;

&lt;p&gt;OK. Any opposition to committing the &quot;less radical&quot; version to 0.96?&lt;/p&gt;</comment>
                            <comment id="13489827" author="varunsharma" created="Fri, 2 Nov 2012 23:11:00 +0000"  >&lt;p&gt;Hi folks,&lt;/p&gt;

&lt;p&gt;Firstly, awesome to have this patch. Thanks, lars and everyone.&lt;/p&gt;

&lt;p&gt;We have been trying to build a consistent application on top of hbase which also works well with counters - consider a user and all his liked &quot;pins&quot; or &quot;tweets&quot;. Row is User Id and liked pins are column qualifiers. Also, there is a column maintaining the &quot;count&quot;. For maintaining consistent data, it would be nice if we could do the following - write a like and increment the count and delete a like and decrement the count.&lt;/p&gt;

&lt;p&gt;I am wondering if we can now couple &quot;put(s)&quot; and &quot;increment(s)&quot; or &quot;delete(s)&quot; and &quot;decrement(s)&quot; from the client side, as part of a single row mutation and ensure a consistent table view for the user in the above application (it will be of course be a separate JIRA, though).&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Varun&lt;/p&gt;</comment>
                            <comment id="13489834" author="lhofhansl" created="Fri, 2 Nov 2012 23:22:50 +0000"  >&lt;p&gt;RowMutation is currently limited to Puts and Deletes. Generalizing this is not trivial:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;You have make all the changes to the WAL first, sync the WAL, then change the memstore&lt;/li&gt;
	&lt;li&gt;Potentially you want to release the row lock before the WAL-sync, which mean a rollback phase to the memstore if the WAL sync failed, etc.&lt;/li&gt;
	&lt;li&gt;Puts and Deletes only need snapshot isolation for consistency, whereas Increment and Append need to be serializable.&lt;/li&gt;
	&lt;li&gt;Put/Delete/etc are idempotent (client can retry on error) whereas Incement/Append generally aren&apos;t (we could make so by passing tokens along).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Long way of saying: It&apos;s possible, but maybe not as simple as might imagine. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13489846" author="varunsharma" created="Fri, 2 Nov 2012 23:41:51 +0000"  >&lt;p&gt;Agreed - this is not simple. In fact, the complexity within this JIRA itself shows that MVCC&apos;ing the increment has itself issues.&lt;/p&gt;

&lt;p&gt;Thanks for pointing out the above concerns. Lets forget concern #4 since that is an issue irrespective of whether the increment is called within a mutation or outside a mutation, you can have increments applied twice, thrice etc.&lt;/p&gt;

&lt;p&gt;I was thinking that we could potentially do this in steps.&lt;br/&gt;
1) Class IncrementMutation which inherits from Increment and Mutation&lt;br/&gt;
2) In the mutateRow call, we add a case for &quot;IncrementMutation&quot; object&lt;br/&gt;
3) Factor out the code wrapped inside the &quot;lock and MVCC&quot; from increment() function to internalIncrement.&lt;br/&gt;
4) Call internalIncrement from mutateRow and increment()&lt;/p&gt;

&lt;p&gt;It seems that walEdits for Increment and Append are indeed put(s) - so that might be okay. Shall I move this discussion over to another JIRA ?&lt;/p&gt;</comment>
                            <comment id="13489854" author="lhofhansl" created="Fri, 2 Nov 2012 23:47:05 +0000"  >&lt;p&gt;What I meant with the fourth issue is that if a RowMutation contains an Increment/Append it is no longer repeatable.&lt;br/&gt;
Yes, let&apos;s move this into a different jira, probably against 0.96 only.&lt;/p&gt;</comment>
                            <comment id="13489869" author="varunsharma" created="Sat, 3 Nov 2012 00:25:23 +0000"  >&lt;p&gt;Okay - created JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-7093&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This might sound like a naive question though but why are mutations required to be idempotent - is it so that their result is always gauranteed (feel free to discuss over the other JIRA) ?&lt;/p&gt;</comment>
                            <comment id="13489912" author="lhofhansl" created="Sat, 3 Nov 2012 03:31:24 +0000"  >&lt;p&gt;Typically the client will retry an operation. That can happen for example when a region moved or is moving. In that case an Increment will just fail, whereas a Put/Delete will be transparently retried by a client.&lt;br/&gt;
As I said, we can make Increment idempotent too (in a sense) by having the client send a token along and then verifying (somehow, waving hands here) that token at the server to apply the Increment at most once.&lt;/p&gt;</comment>
                            <comment id="13490840" author="varunsharma" created="Mon, 5 Nov 2012 19:18:12 +0000"  >&lt;p&gt;I had a quick follow up question on the less radical patch - particularly when we have multi-column increment operation. When we apply an upsert with the correct MVCC read point, does upsert override the previous keyvalue ? In that case, is the previous keyvalue lost ?&lt;/p&gt;

&lt;p&gt;Varun&lt;/p&gt;</comment>
                            <comment id="13490877" author="lhofhansl" created="Mon, 5 Nov 2012 20:01:08 +0000"  >&lt;p&gt;It only &quot;replaces&quot; (it actually add a KV and then removes the old one), if it can prove that no scanner can (or will) see the old KV. The previous KV is lost (that is also what currently happens), only the &quot;radical&quot; patch will fix that.&lt;/p&gt;</comment>
                            <comment id="13491212" author="lhofhansl" created="Tue, 6 Nov 2012 05:01:25 +0000"  >&lt;p&gt;If there&apos;re no objections I&apos;ll commit the &quot;less radical&quot; version to 0.96 tomorrow.&lt;/p&gt;

&lt;p&gt;But not after I mention another advantage of the &quot;radical&quot; version: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
It will work fine with mslab!&lt;br/&gt;
mslab is not used for any KV added or deleted via upsert (that is true before and after this patch, and is due to the fact that upsert will fragment the slab quickly leading to OOMs).&lt;br/&gt;
The radical patch is more friendly to the GC.&lt;/p&gt;</comment>
                            <comment id="13491654" author="jdcryans" created="Tue, 6 Nov 2012 17:54:37 +0000"  >&lt;p&gt;In my latest comment I meant to say that I&apos;m +1 on the more radical patch for 0.96&lt;/p&gt;</comment>
                            <comment id="13491765" author="stack" created="Tue, 6 Nov 2012 19:55:03 +0000"  >&lt;p&gt;I&apos;d be +1 for radical patch in 0.96.&lt;/p&gt;</comment>
                            <comment id="13491768" author="stack" created="Tue, 6 Nov 2012 19:59:08 +0000"  >&lt;p&gt;I think I understand the implications &amp;#8211; noticeably slower (TBD) &amp;#8211; but more obviously correct and for those who come after, more obvious what the right way (correctness) forward is.  Looking at the patch, do we suffer version explosion (I don&apos;t see memstore cleanup going on).&lt;/p&gt;</comment>
                            <comment id="13491776" author="lhofhansl" created="Tue, 6 Nov 2012 20:08:08 +0000"  >&lt;p&gt;Yes, the &quot;radical&quot; version has no cleanup (that is what upsert does). Not cleaning up makes it slab friendly and also fullfills the VERSIONS contracts, but it will lead to more frequent region flushes (at flush time most of the KVs will be removed, but it will flush a tiny HFile).&lt;/p&gt;</comment>
                            <comment id="13491779" author="stack" created="Tue, 6 Nov 2012 20:11:53 +0000"  >&lt;p&gt;How would we do cleanup?  Delete from behind smallest read point?  Do this in a memstore compressor step?  Something that sits between current memstore and the snapshot we make when flushing?&lt;/p&gt;</comment>
                            <comment id="13491817" author="varunsharma" created="Tue, 6 Nov 2012 20:56:30 +0000"  >&lt;p&gt;I am more +1 on the less radical patch - the more frequent flushing and tiny HFiles means that counters are now using a much larger fraction of the memstore as opposed to before. Also, more hfiles means that data will be more fragmented on disk until compaction happens.&lt;/p&gt;</comment>
                            <comment id="13491854" author="lhofhansl" created="Tue, 6 Nov 2012 21:48:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; That&apos;s what the less radical patch does, it removed old versions of the KVs when they are no longer visible to concurrent scanners.&lt;br/&gt;
You cannot clean up the in memory KVs (without a lot of refactoring and repacking into new slabs) while still using mslab.&lt;br/&gt;
There was talk about in memory compactions that could something like this... If we consider this an issue then that would be the proper route.&lt;/p&gt;

&lt;p&gt;Let me try to summarize:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;The &quot;less radical&quot; patch is correct w.r.t. to MVCC. It does not correct the Increment behavior when it comes to historical scans. For practical purposes there is only a single version of the Incremented column, which is changed - regardless of how the CF is configured.&lt;/li&gt;
	&lt;li&gt;The &quot;radical&quot; removes upsert. Increments are just treated like Puts, all special code is removed.&lt;br/&gt;
Upon flush all excess versions are removed before they are flushed to disk (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4241&quot; title=&quot;Optimize flushing of the Store cache for max versions and (new) min versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4241&quot;&gt;&lt;del&gt;HBASE-4241&lt;/del&gt;&lt;/a&gt;). The flushed files will be small, compaction will be fast. No attempt is made to clean up KVs before that, so it works with mslab, but the memstore will fill up more quickly. This patch causes a 10-15% performance degradation for pure Increments.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;As I stated before, in my mind only the &quot;radical&quot; version is true to HBase&apos;s design and upsert was a hack, which should be removed.&lt;br/&gt;
However, I&apos;m fine committing the &quot;less radical&quot; version, which retains (mostly) the current performance and fixes the behavior w.r.t. MVCC.&lt;/p&gt;</comment>
                            <comment id="13491871" author="streamy" created="Tue, 6 Nov 2012 22:03:50 +0000"  >&lt;p&gt;My vote (if only for one implementation) would be for the less radical patch that removes in-memory versions that are not visible rather than doing this cleanup on flush which has a number of performance implications.  I can see some reasons for wanting to keep versions around (providing support to an Omid-like transaction engine requires retaining old versions for at least some time), but it would be cool to have an option to prevent the deletion of the old versions rather than require that these exist in cases I won&apos;t ever use them.  In all my increment performance tests, of which there have been many, the upsert/removal of old versions is one of the biggest gains, especially if you have particularly hot columns.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure which design you are referring to when you talk about being true to HBase&apos;s design &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Or maybe you&apos;re referring to the general principles of HBase (append-only), but the increment operation itself was not part of any original design or implementation of HBase and has been a hack in one way or another from the very first implementation.  For the reason that the implementation has been targeted at performance over purity.  I&apos;ve always seen it as an atomic operation that would have any notion of versioning as opaque to the user of the atomic increment.  Again, I can see use cases for it, but I&apos;d lean towards having it as an option rather than requirement.&lt;/p&gt;

&lt;p&gt;Thanks for doing this work, good stuff.  +1&lt;/p&gt;</comment>
                            <comment id="13491884" author="lhofhansl" created="Tue, 6 Nov 2012 22:21:18 +0000"  >&lt;p&gt;As I said I&apos;m fine with the &quot;less radical&quot; patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Increments are special in they are only useful when updating something existing.&lt;/p&gt;</comment>
                            <comment id="13492006" author="hadoopqa" created="Wed, 7 Nov 2012 01:00:13 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12551483/4583-trunk-less-radical-v6.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12551483/4583-trunk-less-radical-v6.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3241//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3241//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13492116" author="lhofhansl" created="Wed, 7 Nov 2012 04:35:35 +0000"  >&lt;p&gt;Another thought... As I described above I can also make upsert VERSIONS aware, by also counting the versions in upsert. That way even historical queries would be correct... Could be slow if many version are to be retained.&lt;/p&gt;

&lt;p&gt;There&apos;s also one other options: Use upsert if VERSIONS is set to 1 and use the normal Store.add otherwise.&lt;/p&gt;

&lt;p&gt;In both cases Omid type transaction engines could still work.&lt;/p&gt;

&lt;p&gt;I&apos;m going to take it as a given from now on that we want to keep the upsert logic as the default option.&lt;/p&gt;</comment>
                            <comment id="13492132" author="lhofhansl" created="Wed, 7 Nov 2012 05:33:05 +0000"  >&lt;p&gt;In that case both Append and Increment should also get an optional timestamp member (like Put and Delete) to set the TS to use.&lt;/p&gt;

&lt;p&gt;While looking at Increment and Append in trunk, were they never protobuf&apos;ed?&lt;/p&gt;</comment>
                            <comment id="13492139" author="lhofhansl" created="Wed, 7 Nov 2012 05:49:09 +0000"  >&lt;p&gt;Here&apos;s what I mean:&lt;br/&gt;
Use upsert for Increment and Append if VERSIONS == 1, use Store.add otherwise (just like Puts in that case)&lt;/p&gt;

&lt;p&gt;TODO:&lt;br/&gt;
I can easily adept Append to take the TS (in fact it already does, just not per column); for Increments it&apos;s a bit more tricky as currently just serializes a column -&amp;gt; long mapping.&lt;/p&gt;</comment>
                            <comment id="13492144" author="streamy" created="Wed, 7 Nov 2012 05:55:47 +0000"  >&lt;p&gt;That makes sense to me (versions = 1 means upsert).&lt;/p&gt;

&lt;p&gt;Big +1 from me on adding support for setting the timestamp.&lt;/p&gt;</comment>
                            <comment id="13492146" author="lhofhansl" created="Wed, 7 Nov 2012 06:02:01 +0000"  >&lt;p&gt;Do you think we need this per column (as in Puts/Deletes) or just one TS per Increment/Append, which would be used for all columns?&lt;/p&gt;

&lt;p&gt;The latter would be easier to do, especially for Increment.&lt;/p&gt;</comment>
                            <comment id="13492149" author="streamy" created="Wed, 7 Nov 2012 06:06:15 +0000"  >&lt;p&gt;A single timestamp for all columns is sufficient for the types of use cases I am imagining, so that&apos;s fine with me.&lt;/p&gt;</comment>
                            <comment id="13492150" author="hadoopqa" created="Wed, 7 Nov 2012 06:07:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12552419/4583-mixed.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12552419/4583-mixed.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 87 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 17 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestResettingCounters&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3247//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13492629" author="stack" created="Wed, 7 Nov 2012 19:34:58 +0000"  >&lt;p&gt;VERSIONs == 1 == upsert hack vs VERSIONs &amp;gt; 1 bypassing the hack sounds like good compromise to me &amp;#8211; till we come around and introduce a memstore gleaning step as means of postponing small file flushes.&lt;/p&gt;</comment>
                            <comment id="13492687" author="lhofhansl" created="Wed, 7 Nov 2012 20:55:03 +0000"  >&lt;p&gt;I started with adding a timerange to Append and TS to Increment, but that quickly leads to a lot of changes. Let&apos;s do that in another jira.&lt;/p&gt;

&lt;p&gt;Will some tests to 4583-mixed and have a final version for review.&lt;/p&gt;</comment>
                            <comment id="13492844" author="lhofhansl" created="Thu, 8 Nov 2012 00:19:38 +0000"  >&lt;p&gt;Same patch, but runs TestAtomicOperation with Increments and Appends that atomically update two column families one with VERSIONS=1 and one with VERSIONS=3. So even atomicity between these is working.&lt;/p&gt;</comment>
                            <comment id="13492966" author="hadoopqa" created="Thu, 8 Nov 2012 05:28:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12552574/4583-mixed-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12552574/4583-mixed-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 87 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 17 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestResettingCounters&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3261//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13492999" author="yuzhihong@gmail.com" created="Thu, 8 Nov 2012 06:34:10 +0000"  >&lt;p&gt;For increment(), the first line below should have been kept:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-          allKVs.addAll(entry.getValue());
+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (store.getFamily().getMaxVersions() == 1) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Patch v3 passes TestResettingCounters&lt;/p&gt;</comment>
                            <comment id="13493002" author="yuzhihong@gmail.com" created="Thu, 8 Nov 2012 06:40:58 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (versionsOlderThanReadpoint &amp;gt; 1) {
+            &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we get here we have seen at least one version older than the readpoint,&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Does the above condition match the comment ? If one version old than readpoint is required, versionsOlderThanReadpoint == 1 should be enough, right ?&lt;/p&gt;</comment>
                            <comment id="13493027" author="hadoopqa" created="Thu, 8 Nov 2012 07:53:45 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12552622/4583-mixed-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12552622/4583-mixed-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 87 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 17 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3263//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13493252" author="lhofhansl" created="Thu, 8 Nov 2012 15:21:44 +0000"  >&lt;p&gt;Yep. that line was removed by accident. Cool that a test caught it.&lt;br/&gt;
Thanks Ted!&lt;/p&gt;</comment>
                            <comment id="13493278" author="lhofhansl" created="Thu, 8 Nov 2012 16:20:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does the above condition match the comment ? If one version old than readpoint is required, versionsOlderThanReadpoint == 1 should be enough, right ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the comment and code is correct. We need make sure that any scanner does not see the KV to be removed, which means that must be one that is newer than this one, but still older than the readpoint.&lt;/p&gt;

&lt;p&gt;(A possible change, though, would be to count KVs with cur.getMemstoreTS() &amp;lt;= readpoint, instead of cur.getMemstoreTS() &amp;lt; readpoint)&lt;/p&gt;</comment>
                            <comment id="13493283" author="lhofhansl" created="Thu, 8 Nov 2012 16:28:10 +0000"  >&lt;p&gt;Version that does this.&lt;/p&gt;</comment>
                            <comment id="13493316" author="hadoopqa" created="Thu, 8 Nov 2012 17:27:01 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12552670/4583-mixed-v4.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12552670/4583-mixed-v4.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 87 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 17 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3264//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13493400" author="stack" created="Thu, 8 Nov 2012 19:11:04 +0000"  >&lt;p&gt;I&apos;m not expert in this area.  I like the way you make it so can do both upsert and add (need to release note it).  I like how you add the test only methods to HStore and not to the Interface.  Is that test ok w/ 100 threads?  Its pretty resource heavy?  It runs ok?  I&apos;m +1 on committing to trunk if all tests pass.  Good stuff Lars.&lt;/p&gt;</comment>
                            <comment id="13493828" author="varunsharma" created="Fri, 9 Nov 2012 08:45:15 +0000"  >&lt;p&gt;In the spirit of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7051&quot; title=&quot;CheckAndPut should properly read MVCC&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7051&quot;&gt;&lt;del&gt;HBASE-7051&lt;/del&gt;&lt;/a&gt; which fixes the race condition between put and checkAndPut for both 0.94 and 0.96 - I think we should at least fix the race condition for 0.94 for Append and Increment operations, like we did for checkAndPut. I would also be in favour of fixing the entire issue for 0.94, now that we have a very elegant and clear patch for 0.96. Unless, there are strong objections, I can help replicate this patch for 0.94 ? &lt;/p&gt;</comment>
                            <comment id="13494439" author="lhofhansl" created="Fri, 9 Nov 2012 23:48:35 +0000"  >&lt;p&gt;@Varun: I mostly agree.&lt;br/&gt;
Increment/Append won&apos;t play nicely with concurrent Puts/Deletes anyway (without this patch that is), whereas checkAndXXX does.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; These tests finish pretty quickly on my laptop (about 2m), and &amp;lt; 15s on my (beefy) desktop. Should be OK.&lt;/p&gt;

&lt;p&gt;OK... Going to commit later today. TestHFileOutputFormat is unrelated - I&apos;ll double check.&lt;br/&gt;
This is nice correctness improvement to HBase.&lt;/p&gt;</comment>
                            <comment id="13494560" author="lhofhansl" created="Sat, 10 Nov 2012 04:28:48 +0000"  >&lt;p&gt;Committed to 0.96... Pfeeww. After one year. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Thanks for the reviews folks.&lt;/p&gt;</comment>
                            <comment id="13494576" author="hudson" created="Sat, 10 Nov 2012 06:04:10 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3527 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3527/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3527/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4583&quot; title=&quot;Integrate RWCC with Append and Increment operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4583&quot;&gt;&lt;del&gt;HBASE-4583&lt;/del&gt;&lt;/a&gt; Integrate RWCC with Append and Increment operations (Revision 1407725)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13494636" author="hudson" created="Sat, 10 Nov 2012 11:48:04 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #255 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/255/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/255/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4583&quot; title=&quot;Integrate RWCC with Append and Increment operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4583&quot;&gt;&lt;del&gt;HBASE-4583&lt;/del&gt;&lt;/a&gt; Integrate RWCC with Append and Increment operations (Revision 1407725)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13494725" author="lhofhansl" created="Sat, 10 Nov 2012 16:44:12 +0000"  >&lt;p&gt;The jenkins builds are somewhat unstable, the first build after this hung (somewhere) the next one had some kind of the env problems with OOMs.&lt;br/&gt;
I don&apos;t think that was caused by this patch, but it is hard to say.&lt;/p&gt;</comment>
                            <comment id="13494778" author="lhofhansl" created="Sat, 10 Nov 2012 21:51:04 +0000"  >&lt;p&gt;The latest run looks good. Still fails an unrelated test, but no weird issue. So all&apos;s good it seems.&lt;/p&gt;</comment>
                            <comment id="13494819" author="stack" created="Sun, 11 Nov 2012 03:43:57 +0000"  >&lt;p&gt;Good on you Lars.&lt;/p&gt;</comment>
                            <comment id="13495849" author="varunsharma" created="Tue, 13 Nov 2012 01:58:38 +0000"  >&lt;p&gt;Adding patch for 0.94 - I had to rework incrementColumnValue to use Increment() instead so that it is MVCC&apos;ised as well.&lt;/p&gt;</comment>
                            <comment id="13495850" author="varunsharma" created="Tue, 13 Nov 2012 01:59:03 +0000"  >&lt;p&gt;Attaching patch.&lt;/p&gt;</comment>
                            <comment id="13495853" author="lhofhansl" created="Tue, 13 Nov 2012 02:04:41 +0000"  >&lt;p&gt;Sorry, not for 0.94. (As much as I like this patch as improvement, this is too radical for 0.94)&lt;/p&gt;</comment>
                            <comment id="13495856" author="varunsharma" created="Tue, 13 Nov 2012 02:09:08 +0000"  >&lt;p&gt;Oh okay - I thought from your previous comment that you agreed on a solution for 0.94 - maybe you only meant that we fix the Race condition b/w put and append/increment like we do it for checkAndPut and not really do the MVCC part ? Or did I misunderstand ?&lt;/p&gt;

&lt;p&gt;Varun&lt;/p&gt;</comment>
                            <comment id="13495920" author="lhofhansl" created="Tue, 13 Nov 2012 04:08:21 +0000"  >&lt;p&gt;I&apos;m actually not opposed to 0.94, but other folks voiced (valid) concerns.&lt;br/&gt;
We can fix the race condition between Puts followed by Increment or Append, but I don&apos;t think that would be that useful without the rest of this patch.&lt;/p&gt;

&lt;p&gt;I see this more as a strategic correctness fix. This has been &quot;incorrect&quot; since the beginning, so not fixing this in 0.94 is OK, I think.&lt;/p&gt;

&lt;p&gt;Anyway. Thanks for working on a 0.94 patch, Varun.&lt;br/&gt;
So you have a strong usecase for this in 0.94?&lt;/p&gt;</comment>
                            <comment id="13495936" author="varunsharma" created="Tue, 13 Nov 2012 04:27:06 +0000"  >&lt;p&gt;I see - i thought since 0.94 is the current stable version, the one we currently use and we are going heavily use it for counters - we wanted to see if we could use it. Eventually, the other JIRA i am looking into (allowing puts + increments + deletes) in a single mutation is also important for the use case - basically to have counts + puts go in as a single mutation and have a consistent view of the table - also, it helps cut down write latency for us.&lt;/p&gt;

&lt;p&gt;But judging from the reaction, it looks like we might not want that other JIRA to go into 0.94 either (even if we possibly flag protected the change) - in which case, I am okay with this not going through (we can probably use a manually patched version for our usage). Btw, when is the 0.96 expected to ship - it has lots of good features/fixes in it.&lt;/p&gt;

&lt;p&gt;Thanks !&lt;/p&gt;</comment>
                            <comment id="13532888" author="gchanan" created="Sat, 15 Dec 2012 01:55:53 +0000"  >&lt;p&gt;It is a little strange that checkAndPuts now follow MVCC in 0.94 (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7051&quot; title=&quot;CheckAndPut should properly read MVCC&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7051&quot;&gt;&lt;del&gt;HBASE-7051&lt;/del&gt;&lt;/a&gt;) but append/increments don&apos;t.  I think I agree with the reasoning here, though.&lt;/p&gt;</comment>
                            <comment id="13532921" author="lhofhansl" created="Sat, 15 Dec 2012 03:28:22 +0000"  >&lt;p&gt;it is, but checkAndXXX operation are must work together with Puts, whereas increment and append are typically used on their own.&lt;/p&gt;</comment>
                            <comment id="13774997" author="stack" created="Mon, 23 Sep 2013 18:30:31 +0000"  >&lt;p&gt;Marking closed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12614112">HBASE-7076</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12614114">HBASE-7078</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12770407">HBASE-12931</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12613427">HBASE-7051</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12615566">HBASE-7141</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12552574" name="4583-mixed-v2.txt" size="19231" author="lhofhansl" created="Thu, 8 Nov 2012 00:19:38 +0000"/>
                            <attachment id="12552670" name="4583-mixed-v4.txt" size="19211" author="lhofhansl" created="Thu, 8 Nov 2012 16:28:10 +0000"/>
                            <attachment id="12552419" name="4583-mixed.txt" size="18222" author="lhofhansl" created="Wed, 7 Nov 2012 05:49:09 +0000"/>
                            <attachment id="12551392" name="4583-trunk-less-radical-v2.txt" size="14627" author="lhofhansl" created="Tue, 30 Oct 2012 18:06:34 +0000"/>
                            <attachment id="12551448" name="4583-trunk-less-radical-v3.txt" size="15328" author="lhofhansl" created="Tue, 30 Oct 2012 23:05:47 +0000"/>
                            <attachment id="12551452" name="4583-trunk-less-radical-v4.txt" size="29508" author="lhofhansl" created="Tue, 30 Oct 2012 23:24:30 +0000"/>
                            <attachment id="12551462" name="4583-trunk-less-radical-v5.txt" size="29465" author="lhofhansl" created="Wed, 31 Oct 2012 00:00:10 +0000"/>
                            <attachment id="12551483" name="4583-trunk-less-radical-v6.txt" size="18218" author="lhofhansl" created="Wed, 31 Oct 2012 05:03:15 +0000"/>
                            <attachment id="12551310" name="4583-trunk-less-radical.txt" size="11907" author="lhofhansl" created="Tue, 30 Oct 2012 07:02:00 +0000"/>
                            <attachment id="12551099" name="4583-trunk-radical.txt" size="21020" author="lhofhansl" created="Sun, 28 Oct 2012 00:06:48 +0000"/>
                            <attachment id="12551105" name="4583-trunk-radical_v2.txt" size="24429" author="lhofhansl" created="Sun, 28 Oct 2012 04:21:36 +0000"/>
                            <attachment id="12551123" name="4583-trunk-v3.txt" size="27916" author="lhofhansl" created="Sun, 28 Oct 2012 20:47:12 +0000"/>
                            <attachment id="12501538" name="4583-v2.txt" size="14926" author="lhofhansl" created="Sun, 30 Oct 2011 22:35:27 +0000"/>
                            <attachment id="12501555" name="4583-v3.txt" size="24266" author="lhofhansl" created="Mon, 31 Oct 2011 02:58:49 +0000"/>
                            <attachment id="12501559" name="4583-v4.txt" size="24544" author="lhofhansl" created="Mon, 31 Oct 2011 04:00:16 +0000"/>
                            <attachment id="12501500" name="4583.txt" size="15440" author="lhofhansl" created="Sun, 30 Oct 2011 07:03:58 +0000"/>
                            <attachment id="12553246" name="4584-0.94-v1.txt" size="23237" author="varunsharma" created="Tue, 13 Nov 2012 01:59:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>17.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 12 Oct 2011 22:56:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>84828</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 12 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0cukv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72898</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This issue fixes MVCC issues with Increment and Append. To retain the current performance characteristics, VERSIONS should be set to 1 on column families with columns to be incremented/appended-to.&lt;br/&gt;
If VERSIONS is &amp;gt; 1 historical versions are kept for timerange queries, but Increment/Appends will be slower due to changes accumulating the memstore leading to frequent flushes.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>