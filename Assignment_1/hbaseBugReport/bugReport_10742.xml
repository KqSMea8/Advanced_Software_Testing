<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:16:44 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-10742/HBASE-10742.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-10742] Data temperature aware compaction policy</title>
                <link>https://issues.apache.org/jira/browse/HBASE-10742</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Reading &quot;Identifying Hot and Cold Data in Main-Memory Databases&quot; (Levandoski, Larson, and Stoica), it occurred to me that some of the motivation applies to HBase and some of the results can inform a data temperature aware compaction policy implementation.&lt;/p&gt;

&lt;p&gt;We also wish to optimize retention of cells in the working set in memory, in blockcache. &lt;/p&gt;

&lt;p&gt;We can also consider further and related performance optimizations in HBase that awareness of hot and cold data can enable, even for cases where the working set does not fit in memory. If we could partition HFiles into hot and cold (cold+lukewarm) and move cells between them at compaction time, then we could:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Migrate hot HFiles onto alternate storage tiers with improved read latency and throughput characteristics. This has been discussed before on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6572&quot; title=&quot;Tiered HFile storage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6572&quot;&gt;HBASE-6572&lt;/a&gt;. Or, migrate cold HFiles to an archival tier.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Preload hot HFiles into blockcache to increase cache hit rates, especially when regions are first brought online. And/or add another LRU priority to increase the likelihood of retention of blocks in hot HFiles. This could be sufficiently different from ARC to avoid issues there.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Reduce the compaction priorities of cold HFiles, with proportional reduction in priority IO and write amplification, since cold files would less frequently participate in reads.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Levandoski et. al. describe determining data temperature with low overhead using an out of band estimation process running in the background over an access log. We could consider logging reads along with mutations and similarly process the result in the background. The WAL could be overloaded to carry access log records, or we could follow the approach described in the paper and maintain an in memory access log only. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We chose the offline approach for several reasons. First, as mentioned earlier, the overhead of even the simplest caching scheme is very high. Second, the offline approach is generic and requires minimum changes to the database engine. Third, logging imposes very little overhead during normal operation. Finally, it allows flexibility in when, where, and how to analyze the log and estimate access frequencies. For instance, the analysis can be done on a separate machine, thus reducing overhead on the system running the transactional workloads.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Importantly, they only log a sample of all accesses.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;To implement sampling, we have each worker thread flip a biased coin before starting a new query (where bias correlates with sample rate). The thread records its accesses in log buffers (or not) based on the outcome of the coin flip. In Section V, we report experimental results showing that sampling 10% of the accesses reduces the accuracy by only 2.5%,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Likewise we would only record a subset of all accesses to limit overheads.&lt;/p&gt;

&lt;p&gt;The offline process estimates access frequencies over discrete time slices using exponential smoothing. (Markers representing time slice boundaries are interleaved with access records in the log.) Forward and backward classification algorithms are presented. The forward algorithm requires a full scan over the log and storage proportional to the number of unique cell addresses, while the backward algorithm requires reading a least the tail of the log in reverse order.&lt;/p&gt;

&lt;p&gt;If we overload the WAL to carry the access log, offline data temperature estimation can piggyback as a WAL listener. The forward algorithm would then be a natural choice. The HBase master is fairly idle most of the time and less memory hungry as a regionserver, at least in today&apos;s architecture. We could probably get away with considering only row+family as a unique coordinate to minimize space overhead.  Or if instead we maintain the access logs in memory at the RegionServer, then there is a parallel formulation and we could benefit from the reverse algorithm&apos;s ability to terminate early once confidence bounds are reached and backwards scanning IO wouldn&apos;t be a concern. This handwaves over a lot of details.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12701361">HBASE-10742</key>
            <summary>Data temperature aware compaction policy</summary>
                <type id="13" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Brainstorming</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Thu, 13 Mar 2014 21:44:31 +0000</created>
                <updated>Tue, 12 Jan 2016 08:01:14 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="13934342" author="vrodionov" created="Fri, 14 Mar 2014 00:16:11 +0000"  >&lt;p&gt;Usually, hot = recent. This should be implemented first, I mean recency - based compaction policy.  &lt;/p&gt;</comment>
                            <comment id="13934489" author="apurtell" created="Fri, 14 Mar 2014 02:38:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;Usually, hot = recent. This should be implemented first, I mean recency - based compaction policy.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sure. Is that a subset of this or another JIRA? Another JIRA I think.&lt;/p&gt;</comment>
                            <comment id="13948468" author="vrodionov" created="Wed, 26 Mar 2014 21:09:28 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Reading &quot;Identifying Hot and Cold Data in Main-Memory Databases&quot; &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am going to host a session @HBaseCon 2014 (HBase: Extreme makeover) and it turned out that a part of this presentation is related to the subj. In a few words, one can keep track of a hotness of a cached blocks by using of eviction data (LRU - last access time, LFU - total number of accesses) making periodic sampling of a cache and keeping histogram of eviction data distribution, then you can easily request which quantile a particular block belongs to. If its 0.8- its quite hot, if its 0.2 it is going to be purged soon. I am using this technique to dynamically re-compress blocks in a cache. The decision which codec to use is based on a data hotness.&lt;/p&gt;
</comment>
                            <comment id="15093497" author="organge" created="Tue, 12 Jan 2016 08:01:14 +0000"  >&lt;p&gt;Whether hbase can determine data temperature now?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 14 Mar 2014 00:16:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>379707</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            48 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1tfav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>379992</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>