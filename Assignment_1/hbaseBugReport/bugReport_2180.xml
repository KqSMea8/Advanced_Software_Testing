<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:59:36 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2180/HBASE-2180.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2180] Bad random read performance from synchronizing hfile.fddatainputstream</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2180</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;deep in the HFile read path, there is this code:&lt;/p&gt;

&lt;p&gt;    synchronized (in) &lt;/p&gt;
{
      in.seek(pos);
      ret = in.read(b, off, n);
    }


&lt;p&gt;this makes it so that only 1 read per file per thread is active. this prevents the OS and hardware from being able to do IO scheduling by optimizing lots of concurrent reads. &lt;/p&gt;

&lt;p&gt;We need to either use a reentrant API (pread may be partially reentrant according to Todd) or use multiple stream objects, 1 per scanner/thread.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12455120">HBASE-2180</key>
            <summary>Bad random read performance from synchronizing hfile.fddatainputstream</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="ryanobjc">ryan rawson</reporter>
                        <labels>
                    </labels>
                <created>Tue, 2 Feb 2010 22:11:31 +0000</created>
                <updated>Fri, 12 Oct 2012 06:14:57 +0000</updated>
                            <resolved>Mon, 26 Apr 2010 16:17:16 +0000</resolved>
                                                    <fixVersion>0.20.4</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="12829324" author="stack" created="Wed, 3 Feb 2010 23:58:33 +0000"  >&lt;p&gt;Using pread &amp;#8211; its present in the code already, its just commented out on the line following the above cited by Ryan &amp;#8211; I see doubled throughput when 16 clients concurrently random reading out of a single regionserver so it helps.  i&apos;ll try and get some more numbers in here (I see &apos;wa&apos; in top running at about the same for both cases but the regionserver is definetly working harder for the pread case using about double the CPU).&lt;/p&gt;

&lt;p&gt;Numbers are not that good though &amp;#8211; about 50ms latency doing a random read when 16 concurrent clients.  This is a RS carrying 16M rows on 92 regions where there is 1 storefile only in the family and 4DNs under it.&lt;/p&gt;

&lt;p&gt;Way back when we were looking at pread, it improved the random read latency by some small percentage IIRC, about 11%, but then scan speed slowed some... but these would have been for the case of low numbers of concurrent clients.&lt;/p&gt;

&lt;p&gt;Its scanning 27k rows/second before the pread change using single client.  And 21k/second after.&lt;/p&gt;

&lt;p&gt;Let me get some more numbers... up the concurrent client count and get some other points on how pread changes throughput.&lt;/p&gt;</comment>
                            <comment id="12829401" author="stack" created="Thu, 4 Feb 2010 02:31:22 +0000"  >&lt;p&gt;Link to issue that suggests we pread when doing random read and read when scanning.&lt;/p&gt;</comment>
                            <comment id="12829800" author="adragomir" created="Thu, 4 Feb 2010 21:40:38 +0000"  >&lt;p&gt;We ran some testing that show improved performance by commenting in the change in BoundedFileInputStream, by replacing the synchronized statement with the one commented out, that uses the PositionalReader interface&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    //synchronized (in) {
    //  in.seek(pos);
    //  ret = in.read(b, off, n);
    //}
    ret = in.read(pos, b, off, n);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12829874" author="stack" created="Fri, 5 Feb 2010 00:29:49 +0000"  >&lt;p&gt;This patch has gets do preads fetching blocks and uses the old seek+read for scans.&lt;/p&gt;

&lt;p&gt;Patch removes the old HFile.Reader.getScanner methods and replaces both with a getScanner that takes two arguments &amp;#8211; whether to cache blocks read and whether to use pread or not pulling in the block.  I got rid of the old getScanners to force all getScanners to be explicit about what they want regards caching and pread.&lt;/p&gt;

&lt;p&gt;This patch does not include tests.  Its hard to test for this performance change.&lt;/p&gt;

&lt;p&gt;A further improvement would recognize short scans &amp;#8211; i.e. scans that are &amp;lt; an hfile block size.  In this case, we&apos;d want to pread rather than seek+scan (especially so when scan one row replaces get)&lt;/p&gt;
</comment>
                            <comment id="12829990" author="stack" created="Fri, 5 Feb 2010 07:42:33 +0000"  >&lt;p&gt;This patch includes fixes for tests making them use new getScanner method and includes small PE fix when --rows is small (We would NPE).  I might need a v3.  A test is failing (TestGetDeleteTracker).  Need to investigate.&lt;/p&gt;

&lt;p&gt;In testing on something that tries to resemble the yahoo papers testing &amp;#8211; ~20M rows per server, 116 regions on a RS and only one replica &amp;#8211; this patch seems to double the throughput if ~20 concurrent clients on a RS.  I tested scans and scan speeds are what they were w/ this patch in place.  They have not deterioated.&lt;/p&gt;

&lt;p&gt;One thing I noticed was that scanning when the data is not local &amp;#8211; i.e. the data is in a DN on another machine &amp;#8211; there is added latency for sure.... taking maybe 25% as long again for the test to complete.  I need to see if same is true of random reads.  Cosmin suggested that the yahoo test with its single replica only might be doing lots of remote accessing and could be incurring the extra latency.&lt;/p&gt;</comment>
                            <comment id="12830585" author="ryanobjc" created="Sat, 6 Feb 2010 22:59:29 +0000"  >&lt;p&gt;+1 thanks for doing this!&lt;/p&gt;</comment>
                            <comment id="12830654" author="stack" created="Sun, 7 Feb 2010 05:29:52 +0000"  >&lt;p&gt;Committed branch and trunk.&lt;/p&gt;</comment>
                            <comment id="12831193" author="stack" created="Mon, 8 Feb 2010 23:40:12 +0000"  >&lt;p&gt;Really commit to TRUNK.&lt;/p&gt;</comment>
                            <comment id="12835520" author="stack" created="Fri, 19 Feb 2010 00:18:32 +0000"  >&lt;p&gt;Committed a while back.  Resolving.&lt;/p&gt;</comment>
                            <comment id="12838302" author="dlrozendaal" created="Thu, 25 Feb 2010 11:11:07 +0000"  >&lt;p&gt;After applying this patch to 0.20.3 I got the following errors in my regionserver logs when doing high loads of gets and puts:&lt;/p&gt;

&lt;p&gt;2010-02-25 11:44:08,243 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region inrdb_ticket,\x07R\x00\x00\x00\x00\x80\xFF\xFF\xFF\x7F\x00\x00\x00\x01,1267094341820 i&lt;br/&gt;
n 6sec&lt;br/&gt;
1177:java.net.BindException: Cannot assign requested address&lt;br/&gt;
        at sun.nio.ch.Net.connect(Native Method)&lt;br/&gt;
        at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:507)&lt;br/&gt;
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)&lt;br/&gt;
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:404)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchBlockByteRange(DFSClient.java:1825)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1898)&lt;br/&gt;
        at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:46)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:88)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:81)&lt;br/&gt;
        at org.apache.hadoop.io.compress.BlockDecompressorStream.rawReadInt(BlockDecompressorStream.java:121)&lt;br/&gt;
        at org.apache.hadoop.io.compress.BlockDecompressorStream.getCompressedData(BlockDecompressorStream.java:96)&lt;br/&gt;
        at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:82)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:74)&lt;br/&gt;
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)&lt;br/&gt;
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)&lt;br/&gt;
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:1018)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:966)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1159)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1463)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2396)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2385)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1731)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)&lt;/p&gt;

&lt;p&gt;The DataNode logs are fine (no maximum xcievers exceeded errors). Turns out that the OS was running out of port numbers. netstat showed more than 20,000 connections in TIME_WAIT state. Reverting to the original hbase-0.20.3 jar solved the problem. Only very few (&amp;lt;10) TIME_WAIT connections even after running gets/puts for a while.&lt;/p&gt;

&lt;p&gt;So it looks like this patch causes some network connection issues. Any ideas if that could be the case?&lt;/p&gt;

&lt;p&gt;PS Running only gets seems to be fine, but I&apos;ve mostly run tests with reads from the block cache.&lt;/p&gt;</comment>
                            <comment id="12838316" author="stack" created="Thu, 25 Feb 2010 12:03:55 +0000"  >&lt;p&gt;Reopening to take a look.&lt;/p&gt;

&lt;p&gt;I have a vague recollection of stuff not being closed down if not all is read out of the socket.  Thanks for reporting this Erik.&lt;/p&gt;</comment>
                            <comment id="12838394" author="stack" created="Thu, 25 Feb 2010 16:22:22 +0000"  >&lt;p&gt;I was thinking of a very old issue, &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-2341&quot; title=&quot;Datanode active connections never returns to 0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-2341&quot;&gt;&lt;del&gt;HADOOP-2341&lt;/del&gt;&lt;/a&gt;, but that was about CLOSE_WAIT, not TIME_WAIT.  Erik I presume the TIME_WAIT are on the datanode side?  I suppose there could be an issue here if many random reads in a short amount of time and the minimum segment lifetime (MSL) time is long in your tcp/ip implementation.  Do you know what it is?  2minutes seems default reading up on the internets so could be in TIME_WAIT for 4 minutes.  This what you are seeing you think Erik?   They go away after a while?  Whats the OS?  This would seem to be a new issue then.  We need pread that does keep-alive reusing sockets (Todd!).&lt;/p&gt;</comment>
                            <comment id="12838399" author="dlrozendaal" created="Thu, 25 Feb 2010 16:32:56 +0000"  >&lt;p&gt;I saw both CLOSE_WAIT and TIME_WAIT. Maybe CLOSE_WAIT was in the majority. Connections were mostly to the data node.&lt;/p&gt;

&lt;p&gt;$ uname -a&lt;br/&gt;
Linux inrdb-worker1.ripe.net 2.6.18-164.11.1.el5 #1 SMP Wed Jan 20 07:32:21 EST 2010 x86_64 x86_64 x86_64 GNU/Linux&lt;/p&gt;

&lt;p&gt;They do go after a while, since after a few of the &quot;Cannot assign requested address&quot; exceptions the server starts working again.&lt;/p&gt;

&lt;p&gt;Unfortunately I&apos;ll be away for the weekend and won&apos;t be able to investigate further. I wonder why so many connections are being opened so quickly that the server runs out of ports within a few minutes of starting the gets/puts?&lt;/p&gt;</comment>
                            <comment id="12839250" author="stack" created="Sat, 27 Feb 2010 13:08:26 +0000"  >&lt;p&gt;.bq I wonder why so many connections are being opened so quickly that the server runs out of ports within a few minutes of starting the gets/puts?&lt;/p&gt;

&lt;p&gt;Gets used hdfs pread.  pread opens a socket per access.  My guess is that high rate of gets soon overwhelms the time each socket takes to clean up after close.  What kinda rates are we talking here Erik?&lt;/p&gt;</comment>
                            <comment id="12840885" author="tlipcon" created="Wed, 3 Mar 2010 21:23:30 +0000"  >&lt;p&gt;In the absence of reusing sockets, I think the TIME_WAIT issue could be dealt with on the system level by toggling /proc/sys/net/ipv4/tcp_tw_recycle&lt;/p&gt;</comment>
                            <comment id="12860976" author="stack" created="Mon, 26 Apr 2010 16:17:16 +0000"  >&lt;p&gt;Resolving against 0.20.4.  I opened hbase-2492 to cover underlying new socket per pread.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12427424">HBASE-1505</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12434936" name="2180-v2.patch" size="23744" author="stack" created="Fri, 5 Feb 2010 07:42:33 +0000"/>
                            <attachment id="12434906" name="2180.patch" size="11938" author="stack" created="Fri, 5 Feb 2010 00:29:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 3 Feb 2010 23:58:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26193</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 34 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08syn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>49292</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>