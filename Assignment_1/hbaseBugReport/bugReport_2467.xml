<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:02:09 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2467/HBASE-2467.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2467] Concurrent flushers in HLog sync using HDFS-895</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2467</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; changes hflush() to be able to run concurrently from multiple threads, where flushes can be concurrent with further writes to the same file.&lt;/p&gt;

&lt;p&gt;We need to rip out/amend the group commit code a bit to take advantage of this.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12462472">HBASE-2467</key>
            <summary>Concurrent flushers in HLog sync using HDFS-895</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                            <label>moved_from_0_20_5</label>
                    </labels>
                <created>Mon, 19 Apr 2010 19:38:38 +0000</created>
                <updated>Fri, 20 Nov 2015 12:42:09 +0000</updated>
                            <resolved>Mon, 6 Dec 2010 21:00:41 +0000</resolved>
                                                    <fixVersion>0.90.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12858710" author="tlipcon" created="Mon, 19 Apr 2010 22:39:23 +0000"  >&lt;p&gt;Here&apos;s a preliminary total hack patch, ran a 5 node random write PE on it with 40 writers multithreaded mode, got about 12.7K rows/sec over 5 RSes.&lt;/p&gt;

&lt;p&gt;(not to be committed yet, needs a bit more work)&lt;/p&gt;</comment>
                            <comment id="12859032" author="stack" created="Tue, 20 Apr 2010 19:25:46 +0000"  >&lt;p&gt;Patch looks good to me (What you think j-d?).  I need hdfs-895 in place to play with this, right?&lt;/p&gt;</comment>
                            <comment id="12859057" author="tlipcon" created="Tue, 20 Apr 2010 20:46:14 +0000"  >&lt;p&gt;yep, you need &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt;. Still needs to be cleaned up a lot and tested&lt;/p&gt;</comment>
                            <comment id="12859101" author="jdcryans" created="Tue, 20 Apr 2010 22:35:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;We need to rip out/amend the group commit code a bit to take advantage of this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;-1 the advantage of group commit is that you don&apos;t sync every append, Dhruba created &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; because it was slowing down group commit (syncs would wait on appends from other threads, doesn&apos;t make sense).&lt;/p&gt;</comment>
                            <comment id="12859103" author="tlipcon" created="Tue, 20 Apr 2010 22:41:12 +0000"  >&lt;p&gt;JD, the issue here is that group commit ends up creating &quot;bubbles&quot;. With the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; code, calling sync doesn&apos;t block other syncers or writers, so each thread can just sync its own edits.&lt;/p&gt;

&lt;p&gt;There&apos;s a slight improvement to be made by doing batching on a very small scale, to increase HDFS packet size if the edits are &amp;lt;512 bytes, but this patch resulted in a 3-5x speed increase without having to turn on deferred log flush.&lt;/p&gt;</comment>
                            <comment id="12859109" author="jdcryans" created="Tue, 20 Apr 2010 22:49:26 +0000"  >&lt;p&gt;But at a lower level somehow you still have to wait for another thread to finish before writing your own stuff in the block right? So what you&apos;re telling me is that 895 basically takes the grouping at a lower level? &lt;/p&gt;</comment>
                            <comment id="12859111" author="tlipcon" created="Tue, 20 Apr 2010 22:53:52 +0000"  >&lt;p&gt;Writing is still synchronized, but flushing isn&apos;t. Basically, each packet that the DFS Client sends out gets a sequence number. Flush has two parts: (a) any data that hasnt&apos; been sent yet gets sent, and (b) client needs to wait for an ack that this data has been received by the full pipeline. We used to do both parts synchronized. &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; makes it so only part A is synchronized, and then the waiting can happen concurrently with more writes, flushes, etc.&lt;/p&gt;</comment>
                            <comment id="12859114" author="jdcryans" created="Tue, 20 Apr 2010 22:58:33 +0000"  >&lt;p&gt;Cool +1 then, thanks for the explanation.&lt;/p&gt;</comment>
                            <comment id="12859118" author="stack" created="Tue, 20 Apr 2010 23:07:40 +0000"  >&lt;p&gt;@ J-D: What you think of todd&apos;s patch?&lt;/p&gt;</comment>
                            <comment id="12859251" author="jdcryans" created="Wed, 21 Apr 2010 08:15:41 +0000"  >&lt;p&gt;I think like he says, it needs more work. The forceSync isn&apos;t used anymore but it&apos;s still in hflush, we lose the ability to set flushLogEntries, and there&apos;s refactoring around logRollRequested that&apos;s out of scope.&lt;/p&gt;</comment>
                            <comment id="12863677" author="stack" created="Tue, 4 May 2010 05:44:43 +0000"  >&lt;p&gt;Need this for 0.20.5, 0.21.&lt;/p&gt;</comment>
                            <comment id="12863898" author="dhruba" created="Tue, 4 May 2010 17:17:52 +0000"  >&lt;p&gt;I would not support putting this on 0.20.5, especially because this is a performance fix. Isn&apos;t it posible to defer this to a new major release?&lt;/p&gt;</comment>
                            <comment id="12863913" author="dhruba" created="Tue, 4 May 2010 17:42:48 +0000"  >&lt;p&gt;Just to elaborate, has somebody already measured the gain from this one?&lt;/p&gt;</comment>
                            <comment id="12863930" author="tlipcon" created="Tue, 4 May 2010 18:24:09 +0000"  >&lt;p&gt;dhruba: I&apos;ve been running all of my tests with these patches for the last several weeks and it&apos;s been very stable. I haven&apos;t done a recent benchmark but it was a substantial gain - close to 2x if I remember correctly. Before this patch gets finally committed I&apos;ll do a proper benchmark comparison.&lt;/p&gt;</comment>
                            <comment id="12863933" author="dhruba" created="Tue, 4 May 2010 18:35:38 +0000"  >&lt;p&gt;Awesome. Thanks Todd!&lt;/p&gt;</comment>
                            <comment id="12866801" author="stack" created="Wed, 12 May 2010 23:48:14 +0000"  >&lt;p&gt;Bulk move of 0.20.5 issues into 0.21.0 after vote that we merge branch into TRUNK up on list.&lt;/p&gt;</comment>
                            <comment id="12898446" author="jdcryans" created="Fri, 13 Aug 2010 22:31:54 +0000"  >&lt;p&gt;Kind of refreshed patch for trunk. I applied it to our internal branch and tested with YCSB (and cdh3), on pure insert tests I get around 25-30% faster with the patch.&lt;/p&gt;

&lt;p&gt;One issue to solve is that this removes deferred log flushing, which can be pretty useful in cases like ours where we keep tons of counters and don&apos;t really mind missing 2-3 increments.&lt;/p&gt;</comment>
                            <comment id="12899426" author="stack" created="Tue, 17 Aug 2010 14:49:01 +0000"  >&lt;p&gt;What did you do to the patch J-D?  In the hadoop we ship, we should include hdfs-895? (Its a dfsclient-only fix, right?).  What should we do about group commit.  Open a new issue?  If hdfs-895 is not in place, we just run slower, is that right?&lt;/p&gt;

&lt;p&gt;On the patch:&lt;/p&gt;

&lt;p&gt;If concurrency, should &apos;private boolean logRollRequested&apos; be volatile?  (Maybe not necessary &amp;#8211; I see check is done in a synchronized method?)&lt;/p&gt;

&lt;p&gt;I don&apos;t get this bit:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
+        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.syncTime += &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis() - now;
+        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.syncOps++;
+      }
+
+      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.updateLock) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Why not do the syncTime and syncOps under the updateLock rather than do a synchronize on &apos;this&apos;?  Wouldn&apos;t it have same effect but be less obnoxious? (Haven&apos;t looked at rest of this class to check if syncops and synctime updates are done under a synchronize(this)).&lt;/p&gt;
</comment>
                            <comment id="12899459" author="jdcryans" created="Tue, 17 Aug 2010 16:36:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;What did you do to the patch J-D?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mostly just a refresh, and I removed an now-unused boolean on sync().&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In the hadoop we ship, we should include hdfs-895?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it would be great.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What should we do about group commit. Open a new issue?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We don&apos;t need it anymore, but having deferred log flush could still be useful. Should be in the same issue.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If hdfs-895 is not in place, we just run slower, is that right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, under concurrent writers it&apos;s much slower without 895.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If concurrency, should &apos;private boolean logRollRequested&apos; be volatile?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As a matter of fact, it&apos;s under 2 different sync (this and updateLock). Maybe safer to put volatile?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why not do the syncTime and syncOps under the updateLock rather than do a synchronize on &apos;this&apos;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Makes sense.&lt;/p&gt;</comment>
                            <comment id="12899478" author="tlipcon" created="Tue, 17 Aug 2010 17:18:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;We don&apos;t need it anymore, but having deferred log flush could still be useful. Should be in the same issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There is one case in which group commit is still helpful - the way sync works is that it always sends the last &quot;chunk&quot; of the file, even if some of the bytes were already sent. The chunks here are 512 bytes (ie checksum boundaries). So, if you&apos;re always syncing very small edits (ie &amp;lt;512 bytes) then there is a benefit to waiting a milli or two to cross that 512-byte boundary. Otherwise with each write we will re-send the previous writes as well during the sync.&lt;/p&gt;

&lt;p&gt;We can do a little better on the HDFS side to get this &quot;for free&quot;, though, so probably not worth worrying about in this patch.&lt;/p&gt;</comment>
                            <comment id="12901635" author="jdcryans" created="Mon, 23 Aug 2010 22:30:40 +0000"  >&lt;p&gt;Rebased patch after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2922&quot; title=&quot;HLog preparation and cleanup are done under the updateLock, major slowdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2922&quot;&gt;&lt;del&gt;HBASE-2922&lt;/del&gt;&lt;/a&gt;, also I changed the synchronization bit that Stack referred to and added the missing bits for deferred log flushing to be fully working. I did some loading tests, with deferred log flush it&apos;s 80-100% faster than without it, but still using &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; along with the rest of this patch (which is a good bit faster already). To sum up:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;With this patch and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt;, it&apos;s 25-30% faster.&lt;/li&gt;
	&lt;li&gt;With this patch and deferred log flush on, it&apos;s another 80-100% faster, but less durable (obviously).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12918254" author="ryanobjc" created="Tue, 5 Oct 2010 22:16:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; is client side only, so we should patch that into a build that we ship with HBase and also apply this patch.&lt;/p&gt;</comment>
                            <comment id="12926645" author="streamy" created="Sat, 30 Oct 2010 20:05:12 +0000"  >&lt;p&gt;What&apos;s story on this?  We&apos;re waiting for 895 to be committed to 20-append branch then this is closed?  Or still HBase code to be committed?&lt;/p&gt;</comment>
                            <comment id="12926664" author="tlipcon" created="Sun, 31 Oct 2010 00:30:41 +0000"  >&lt;p&gt;We can&apos;t commit this to hbase until &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; is committed to HDFS. If you run this HBase patch without &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; you lose group commit and everything goes much slower. &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; needs to go into both trunk and 20-append&lt;/p&gt;</comment>
                            <comment id="12926666" author="ryanobjc" created="Sun, 31 Oct 2010 00:39:43 +0000"  >&lt;p&gt;Since 895 is client side only we can ship with special jars in hbase this&lt;br/&gt;
closing this issue.&lt;/p&gt;</comment>
                            <comment id="12927638" author="stack" created="Tue, 2 Nov 2010 21:54:32 +0000"  >&lt;p&gt;We have to have this to ship.  Made it a blocker.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; is client-side only (check) so we can make our own hadoop jar if we have to.&lt;/p&gt;</comment>
                            <comment id="12929855" author="jdcryans" created="Tue, 9 Nov 2010 00:56:43 +0000"  >&lt;p&gt;Refreshed patch that doesn&apos;t include the deferred log flushing reenabling since it was done in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3204&quot; title=&quot;Reenable deferred log flush&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3204&quot;&gt;&lt;del&gt;HBASE-3204&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12931176" author="nspiegelberg" created="Thu, 11 Nov 2010 20:04:13 +0000"  >&lt;p&gt;How much operational experience have you had with production machines running &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; + &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2467&quot; title=&quot;Concurrent flushers in HLog sync using HDFS-895&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2467&quot;&gt;&lt;del&gt;HBASE-2467&lt;/del&gt;&lt;/a&gt;?  I did a code review of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; and feel like it&apos;s pretty solid.  We have it applied to our internal branch, but we don&apos;t have HBASE=2467 applied.  Although I think the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-895&quot; title=&quot;Allow hflush/sync to occur in parallel with new writes to the file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-895&quot;&gt;&lt;del&gt;HDFS-895&lt;/del&gt;&lt;/a&gt; code is good, there&apos;s no question that it&apos;s very intricate and needs plenty of test time with large traffic before we should rely on it.  I hear some of you guys have been running it on production traffic for months, is that correct?  If so, I think that&apos;s sufficient test time and we can commit this.&lt;/p&gt;</comment>
                            <comment id="12931181" author="jdcryans" created="Thu, 11 Nov 2010 20:09:45 +0000"  >&lt;p&gt;We&apos;ve been running it since August on all our clusters, never had a single issue.&lt;/p&gt;</comment>
                            <comment id="12931217" author="tlipcon" created="Thu, 11 Nov 2010 21:43:25 +0000"  >&lt;p&gt;The only potential issue I&apos;m aware of is this possible case where HBase will call hflush() on a closed stream... maybe that problem is gone in the most recent iteration of this patch. JD, have you seen that come up on recent versions? I think we can look carefully through the HBase side to see if this race still exists &amp;#8211; it was happening when the log rolled in between the append and hflush. We may need an rwlock to protect log rolling.&lt;/p&gt;</comment>
                            <comment id="12931222" author="jdcryans" created="Thu, 11 Nov 2010 21:57:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;JD, have you seen that come up on recent versions?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here&apos;s one that happened while the server was going down:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2010-10-29 03:11:33,017 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.io.IOException: Cannot append; log is closed
        at org.apache.hadoop.hbase.regionserver.wal.HLog.append(HLog.java:840)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1641)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1261)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1777)
        at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:560)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1027)
2010-10-29 03:11:33,053 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.lang.NullPointerException
        at org.apache.hadoop.io.SequenceFile$Writer.checkAndWriteSync(SequenceFile.java:975)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1017)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:984)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:111)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.doWrite(HLog.java:996)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.append(HLog.java:851)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another that happens when the RS is going down:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2010-11-03 03:18:40,137 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
:java.lang.NullPointerException
	at org.apache.hadoop.io.SequenceFile$Writer.getLength(SequenceFile.java:1048)
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.getLength(SequenceFileLogWriter.java:132)
	at org.apache.hadoop.hbase.regionserver.wal.HLog.sync(HLog.java:913)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But I don&apos;t see it during normal runtime.&lt;/p&gt;</comment>
                            <comment id="12966379" author="stack" created="Fri, 3 Dec 2010 01:28:40 +0000"  >&lt;p&gt;Todd updated hdfs-895 patch for 0.20 append.  I built an hadoop with his new patch.  Ryan posted it up on his repo.  Going to test it basically works.&lt;/p&gt;</comment>
                            <comment id="12968406" author="jdcryans" created="Mon, 6 Dec 2010 21:00:41 +0000"  >&lt;p&gt;Committed to the last patch to branch and trunk after running unit tests and doing some cluster testing, thanks for the great work Todd!&lt;/p&gt;</comment>
                            <comment id="15017175" author="lars_francke" created="Fri, 20 Nov 2015 12:42:09 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12445416">HDFS-895</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12452064" name="HBASE-2467-v2.patch" size="11057" author="jdcryans" created="Fri, 13 Aug 2010 22:31:54 +0000"/>
                            <attachment id="12452872" name="HBASE-2467-v3.patch" size="10552" author="jdcryans" created="Mon, 23 Aug 2010 22:30:40 +0000"/>
                            <attachment id="12459120" name="HBASE-2467-v4.patch" size="9351" author="jdcryans" created="Tue, 9 Nov 2010 00:56:43 +0000"/>
                            <attachment id="12442238" name="hbase-2467.txt" size="11032" author="tlipcon" created="Mon, 19 Apr 2010 22:39:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 20 Apr 2010 19:25:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32600</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hhu7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100152</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>