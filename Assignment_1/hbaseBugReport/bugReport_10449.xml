<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:13:53 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-10449/HBASE-10449.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-10449] Wrong execution pool configuration in HConnectionManager</title>
                <link>https://issues.apache.org/jira/browse/HBASE-10449</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;There is a confusion in the configuration of the pool. The attached patch fixes this. This may change the client performances, as we were using a single thread.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692564">HBASE-10449</key>
            <summary>Wrong execution pool configuration in HConnectionManager</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nkeywal">Nicolas Liochon</assignee>
                                    <reporter username="nkeywal">Nicolas Liochon</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 18:59:25 +0000</created>
                <updated>Wed, 16 Sep 2015 22:42:30 +0000</updated>
                            <resolved>Mon, 3 Feb 2014 13:23:38 +0000</resolved>
                                    <version>0.98.0</version>
                    <version>0.99.0</version>
                    <version>0.96.1.1</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.96.2</fixVersion>
                    <fixVersion>0.99.0</fixVersion>
                                    <component>Client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13888085" author="ndimiduk" created="Fri, 31 Jan 2014 19:49:21 +0000"  >&lt;p&gt;Ouch. Is it better to leave the default value of hbase.hconnection.threads.core at 0 and let your new default logic kick in?&lt;/p&gt;</comment>
                            <comment id="13888092" author="nkeywal" created="Fri, 31 Jan 2014 19:56:13 +0000"  >&lt;p&gt;It&apos;s something new (~3 months old, not in .94), so imho it&apos;s better to come back to the initial behavior, as the performances should be better. We can also play if safe, with a different patch for the .96 and for trunk. This makes things more complicated to understand &amp;amp; test however...&lt;/p&gt;</comment>
                            <comment id="13888156" author="hadoopqa" created="Fri, 31 Jan 2014 20:50:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626350/HBASE-10449.v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626350/HBASE-10449.v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12626350&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.TestAcidGuarantees.testGetAtomicity(TestAcidGuarantees.java:331)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8568//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888503" author="nkeywal" created="Sat, 1 Feb 2014 09:42:45 +0000"  >&lt;p&gt;TestAcidGuarantees is likely unrelated. I will run it locally a few times to be sure.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, what do you think? Should I commit the patch to trunk,.96 &amp;amp; .98 as it is, if TestAcidGuarantees is proven to be unrelated?&lt;/p&gt;</comment>
                            <comment id="13888666" author="apurtell" created="Sat, 1 Feb 2014 18:48:56 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13889463" author="nkeywal" created="Mon, 3 Feb 2014 13:23:20 +0000"  >&lt;p&gt;Committed to trunk/.98/.96 (this way it will be in the next .98 RC) Stack; Nick, if you prefer something different for trunk / .96 I can revert/change the patch. But it seems simpler to have the same logic for all versions.&lt;/p&gt;</comment>
                            <comment id="13889562" author="hudson" created="Mon, 3 Feb 2014 15:43:35 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4875 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4875/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4875/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10449&quot; title=&quot;Wrong execution pool configuration in HConnectionManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10449&quot;&gt;&lt;del&gt;HBASE-10449&lt;/del&gt;&lt;/a&gt; Wrong execution pool configuration in HConnectionManager (nkeywal: rev 1563878)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13889596" author="hudson" created="Mon, 3 Feb 2014 16:24:54 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.96 #277 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96/277/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96/277/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10449&quot; title=&quot;Wrong execution pool configuration in HConnectionManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10449&quot;&gt;&lt;del&gt;HBASE-10449&lt;/del&gt;&lt;/a&gt; Wrong execution pool configuration in HConnectionManager (nkeywal: rev 1563879)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13889642" author="hudson" created="Mon, 3 Feb 2014 17:17:28 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.98-on-Hadoop-1.1 #113 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/113/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/113/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10449&quot; title=&quot;Wrong execution pool configuration in HConnectionManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10449&quot;&gt;&lt;del&gt;HBASE-10449&lt;/del&gt;&lt;/a&gt; Wrong execution pool configuration in HConnectionManager (nkeywal: rev 1563880)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13889656" author="stack" created="Mon, 3 Feb 2014 17:27:22 +0000"  >&lt;p&gt;Thank &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;  To be clear, default was 8 * cores rather than agreed upon 256?&lt;/p&gt;</comment>
                            <comment id="13889702" author="ndimiduk" created="Mon, 3 Feb 2014 18:14:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; I have no objection to the change in default as I have no evidence to argue for one value or another. I do find it strange that this default changes as part of a point release on 0.96. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;: it appears the default for hbase.hconnection.threads.core on 0.96, 0.98, and trunk is now 256. An administrator can attain the 8 * cores behavior by setting this configuration value to 0.&lt;/p&gt;</comment>
                            <comment id="13889707" author="stack" created="Mon, 3 Feb 2014 18:19:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt; You have a point but a release note should be cover enough for a change few if any will notice IMO.&lt;/p&gt;</comment>
                            <comment id="13890132" author="hudson" created="Mon, 3 Feb 2014 23:46:33 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK-on-Hadoop-1.1 #76 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-1.1/76/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-1.1/76/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10449&quot; title=&quot;Wrong execution pool configuration in HConnectionManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10449&quot;&gt;&lt;del&gt;HBASE-10449&lt;/del&gt;&lt;/a&gt; Wrong execution pool configuration in HConnectionManager (nkeywal: rev 1563878)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13890160" author="hudson" created="Tue, 4 Feb 2014 00:07:47 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-0.98 #123 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.98/123/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.98/123/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10449&quot; title=&quot;Wrong execution pool configuration in HConnectionManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10449&quot;&gt;&lt;del&gt;HBASE-10449&lt;/del&gt;&lt;/a&gt; Wrong execution pool configuration in HConnectionManager (nkeywal: rev 1563880)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13890282" author="hudson" created="Tue, 4 Feb 2014 02:08:05 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.96-hadoop2 #191 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96-hadoop2/191/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96-hadoop2/191/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10449&quot; title=&quot;Wrong execution pool configuration in HConnectionManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10449&quot;&gt;&lt;del&gt;HBASE-10449&lt;/del&gt;&lt;/a&gt; Wrong execution pool configuration in HConnectionManager (nkeywal: rev 1563879)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13890522" author="nkeywal" created="Tue, 4 Feb 2014 09:30:30 +0000"  >&lt;p&gt;Note that we&apos;re not exactly changing a default. &lt;br/&gt;
The code wanted to do:&lt;/p&gt;
 &lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;Create up to &apos;max&apos; (default: 256) threads. Expires them if they are not used for 10 seconds, excepted for &apos;core&apos; (default 0) of them. If there is more than &apos;max&apos; tasks, queue them.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Actually it was doing:&lt;/p&gt;
&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;Create a single thread, queue all the tasks for this thread.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So the patch actually implements that was supposed to be implemented (or tries to implement it at least &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ). I&lt;/p&gt;

&lt;p&gt;Moreover, it&apos;s a regression from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9917&quot; title=&quot;Fix it so Default Connection Pool does not spin up max threads even when not needed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9917&quot;&gt;&lt;del&gt;HBASE-9917&lt;/del&gt;&lt;/a&gt;, so actually 96.0 really uses 256 threads. It&apos;s a &lt;b&gt;96.1&lt;/b&gt; issue only. But yes, it does have an impact on performances, and this impact can be good or bad. That&apos;s why I would like it to be in the .98 RC, and also why I think it&apos;s simpler to have the same defaults on all versions.&lt;/p&gt;

&lt;p&gt;Lastly, and unrelated, we didn&apos;t have a limit of the number of threads before the .96. I&apos;m wondering if we don&apos;t have an impact if a server hangs. The client may ends up with all its connections stuck to this server, until it timeouts.&lt;/p&gt;</comment>
                            <comment id="14331096" author="enis" created="Sat, 21 Feb 2015 23:33:27 +0000"  >&lt;p&gt;Closing this issue after 0.99.0 release. &lt;/p&gt;</comment>
                            <comment id="14744187" author="stack" created="Mon, 14 Sep 2015 20:24:46 +0000"  >&lt;p&gt;Back again &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m looking at failing tests and see thread dumps with pools of 256 threads per client instance.&lt;/p&gt;

&lt;p&gt;Where does &apos;Create a single thread, queue all the tasks for this thread.&apos; come from?&lt;/p&gt;

&lt;p&gt;Our &apos;core&apos; setting is same as our &apos;max&apos; so we will keep spinning new threads until we hit max whether all of the other 255 are idle or not. That seems wrong (it is for sure a PITA looking at thread dumps of 256 threads doing nought.&lt;/p&gt;

&lt;p&gt;I opened new issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14433&quot; title=&quot;Set down the client executor core thread count from 256 in tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14433&quot;&gt;&lt;del&gt;HBASE-14433&lt;/del&gt;&lt;/a&gt; for discussion.&lt;/p&gt;</comment>
                            <comment id="14746863" author="nkeywal" created="Wed, 16 Sep 2015 04:53:06 +0000"  >&lt;p&gt;Sorry for the delay, I&apos;m seeing this now only.&lt;br/&gt;
Let me have a look.&lt;/p&gt;</comment>
                            <comment id="14746875" author="nkeywal" created="Wed, 16 Sep 2015 05:06:54 +0000"  >&lt;p&gt;&amp;gt; Where does &apos;Create a single thread, queue all the tasks for this thread.&apos; come from?&lt;br/&gt;
This is what &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9917&quot; title=&quot;Fix it so Default Connection Pool does not spin up max threads even when not needed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9917&quot;&gt;&lt;del&gt;HBASE-9917&lt;/del&gt;&lt;/a&gt; actually implemented: with the ThreadPoolExecutor if the task queue is unbounded, it does not create new threads:&lt;/p&gt;

&lt;p&gt;From: &lt;a href=&quot;http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadPoolExecutor.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadPoolExecutor.html&lt;/a&gt;&lt;br/&gt;
If fewer than corePoolSize threads are running, the Executor always prefers adding a new thread rather than queuing.&lt;br/&gt;
If corePoolSize or more threads are running, the Executor always prefers queuing a request rather than adding a new thread.&lt;br/&gt;
If a request cannot be queued, a new thread is created unless this would exceed maximumPoolSize, in which case, the task will be rejected.&lt;/p&gt;

&lt;p&gt;But having less than 256 threads is fine. This was just restoring the previous value.&lt;/p&gt;</comment>
                            <comment id="14746886" author="stack" created="Wed, 16 Sep 2015 05:15:33 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Our queue is unbounded then so we do not create new threads once we hit core ? Rather, we just queue?  Can we make queue size zero ?&lt;/p&gt;

&lt;p&gt;I suppose I should test....&lt;/p&gt;</comment>
                            <comment id="14746897" author="nkeywal" created="Wed, 16 Sep 2015 05:25:38 +0000"  >&lt;p&gt;As I understand the doc, if we do that we create maxThreads and then reject all the tasks. Not really useful.&lt;br/&gt;
But the patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14433&quot; title=&quot;Set down the client executor core thread count from 256 in tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14433&quot;&gt;&lt;del&gt;HBASE-14433&lt;/del&gt;&lt;/a&gt; seems ok:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;we create up to core threads (Runtime.getRuntime().availableProcessors()). If we have 10 tasks in parallel we still have Runtime.getRuntime().availableProcessors() threads.&lt;/li&gt;
	&lt;li&gt;the expire quite quickly (because we do allowCoreThreadTimeOut(true)&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;May be we should set maxThreads to coreThreads as well and increase HConstants.DEFAULT_HBASE_CLIENT_MAX_TOTAL_TASKS.&lt;/p&gt;

&lt;p&gt;But I&apos;m +1 with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14433&quot; title=&quot;Set down the client executor core thread count from 256 in tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14433&quot;&gt;&lt;del&gt;HBASE-14433&lt;/del&gt;&lt;/a&gt; as it is now.&lt;/p&gt;</comment>
                            <comment id="14746905" author="stack" created="Wed, 16 Sep 2015 05:34:08 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; Let me commit &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14433&quot; title=&quot;Set down the client executor core thread count from 256 in tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14433&quot;&gt;&lt;del&gt;HBASE-14433&lt;/del&gt;&lt;/a&gt;. Lets go with less threads till we do the test that proves we need more. Thanks for the review boss.&lt;/p&gt;</comment>
                            <comment id="14746919" author="nkeywal" created="Wed, 16 Sep 2015 05:43:51 +0000"  >&lt;p&gt;Actually I&apos;m having two doubts:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the core threads should already have this timeout, no. We should not see 256 threads, because they should expire already&lt;/li&gt;
	&lt;li&gt;IIRC, this thread pool is used when connecting to the various regionserver, and they block until they have an answer. So with 4 core threads (for example), it means that if we do a multi we contact 4 servers simultaneously at most. The threads are not really using CPUs, they&apos;re waiting  (old i/o style). BUt may be it has changed?&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="14768844" author="nkeywal" created="Wed, 16 Sep 2015 12:31:11 +0000"  >&lt;p&gt;What&apos;s happening for the expire is:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;we have a 60s timeout with 256 seconds.&lt;/li&gt;
	&lt;li&gt;let&apos;s imagine we have 1 query per second. We will still have 60 threads, because each new request will create a new thread until we reach coreSize. As the timeout is 60s, the oldest threads will expire after 60s.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I haven&apos;t double-checked, but I believe that the threads are needed because of the old i/o pattern. So we do need a max in the x00 range (it&apos;s like this since 0.90 at least. In theory, it&apos;s good for small cluster (100 nodes), but not as good if the cluster is composed of thousands of nodes)&lt;/p&gt;

&lt;p&gt;I did actually spent some time on this a year ago, in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11590&quot; title=&quot;use a specific ThreadPoolExecutor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11590&quot;&gt;HBASE-11590&lt;/a&gt;. @stack, what do you think of the approach? I can finish the work I started there. But I will need a review. There are also some ideas/hacks in &lt;a href=&quot;http://stackoverflow.com/questions/19528304/how-to-get-the-threadpoolexecutor-to-increase-threads-to-max-before-queueing/19528305#19528305&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/19528304/how-to-get-the-threadpoolexecutor-to-increase-threads-to-max-before-queueing/19528305#19528305&lt;/a&gt; I haven&apos;t reviewed them yet.&lt;/p&gt;</comment>
                            <comment id="14790587" author="stack" created="Wed, 16 Sep 2015 15:52:03 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We should not see 256 threads, because they should expire already&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Maybe they spin up inside the keepalive time of 60 seconds.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We will still have 60 threads, because each new request will create a new thread until we reach coreSize&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, I was thinking that we&apos;d go to core size &amp;#8211; say # of cores &amp;#8211; and then if one request a second, we&apos;d just stay at core size because there would be a free thread when the request-per-second came in (assuming request took a good deal &amp;lt; a second).&lt;/p&gt;

&lt;p&gt;Let me look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11590&quot; title=&quot;use a specific ThreadPoolExecutor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11590&quot;&gt;HBASE-11590&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What I saw was each client with hundreds &amp;#8211; up to 256 on one &amp;#8211; threads all in WAITING like follows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;hconnection-0x3065a6a9-shared--pool13-t247&quot;&lt;/span&gt; daemon prio=10 tid=0x00007f31c1ab2000 nid=0x7718 waiting on condition [0x00007f2f9ecec000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;  &amp;lt;0x00000007f841b388&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... usually in TestReplicasClient.  Here is example: &lt;a href=&quot;https://builds.apache.org/view/H-L/view/HBase/job/PreCommit-HBASE-Build/15581/consoleText&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/view/H-L/view/HBase/job/PreCommit-HBASE-Build/15581/consoleText&lt;/a&gt;  See zombies on the end.&lt;/p&gt;

&lt;p&gt;I also have second thoughts on HBASE-114433. I am going to change it so we set config for tests only. We need to do more work before can set the core threads down from max is what I am thinking.&lt;/p&gt;

&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; I&apos;ll look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11590&quot; title=&quot;use a specific ThreadPoolExecutor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11590&quot;&gt;HBASE-11590&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Didn&apos;t we have a mock server somewhere such that we could standup a client with no friction and watch it in operation? I thought we&apos;d make such a beast....&lt;/p&gt;</comment>
                            <comment id="14790660" author="nkeywal" created="Wed, 16 Sep 2015 16:24:58 +0000"  >&lt;p&gt;&amp;gt; I was thinking that we&apos;d go to core size &#8211; say # of cores &#8211; and then if one request a second, we&apos;d just stay at core size because there would be a free thread when the request-per-second came in (assuming request took a good deal &amp;lt; a second).&lt;/p&gt;

&lt;p&gt;I expect that if we have more than coreSize calls in timeout (256 vs 60 seconds in our case) then we always have coreSize threads.&lt;/p&gt;

&lt;p&gt;&amp;gt; Didn&apos;t we have a mock server somewhere such that we could standup a client with no friction and watch it in operation? I thought we&apos;d make such a beast....&lt;br/&gt;
Yep, you built one, we used it when we looked at the perf issues in the client (the protobuf nightmare if you remember ;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;). &lt;/p&gt;</comment>
                            <comment id="14790698" author="stack" created="Wed, 16 Sep 2015 16:42:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;I expect that if we have more than coreSize calls in timeout (256 vs 60 seconds in our case) then we always have coreSize threads.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Say again. I&apos;m not following &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;  Thanks.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...the protobuf nightmare if you remember &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes. Smile. Need to revive it for here and for doing client timeouts....&lt;/p&gt;</comment>
                            <comment id="14791129" author="nkeywal" created="Wed, 16 Sep 2015 21:11:13 +0000"  >&lt;p&gt;The algo for the ThreadPoolExecutor is:&lt;/p&gt;

&lt;p&gt;onNewTask()&lt;/p&gt;
{
  if (currentSize &amp;lt; coreSize) createNewThread() else reuseThread()
}

&lt;p&gt;And there is a timeout for each thread.&lt;/p&gt;

&lt;p&gt;So if we do a coreSize of 2, a time of 20s, and a query every 15s, we have:&lt;br/&gt;
0s query1: create thread1, poolSize=1&lt;br/&gt;
15s query2: create thread2, poolSize=2&lt;br/&gt;
20s close thread1, poolSize=1&lt;br/&gt;
30s query3: create thread3, poolSize=2&lt;br/&gt;
35s: close thread2, poolSize=1&lt;br/&gt;
45s: query4: create thread4, poolSize=2&lt;/p&gt;

&lt;p&gt;And so on. So even if we have 1 query each 15s, we have 2 threads in the pool nearly all the time.&lt;/p&gt;

&lt;p&gt;&amp;gt; Yes. Smile. Need to revive it for here and for doing client timeouts....&lt;br/&gt;
I found the code in TestClientNoCluster#run , ready to be reused!&lt;/p&gt;

&lt;p&gt;I think we need to go for a hack like in Stackoverflow or for a different implementation for TPE like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11590&quot; title=&quot;use a specific ThreadPoolExecutor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11590&quot;&gt;HBASE-11590&lt;/a&gt;...&lt;/p&gt;</comment>
                            <comment id="14791135" author="stack" created="Wed, 16 Sep 2015 21:23:08 +0000"  >&lt;p&gt;That makes sense. What happens if query happens if query every second: i.e. so there are periods when we have more queries than coreSize? Do the &amp;gt; coreSize query go in queue or do we make new threads to handle them? If latter, good, if former bad. Let me look at other issue.&lt;/p&gt;</comment>
                            <comment id="14791145" author="nkeywal" created="Wed, 16 Sep 2015 21:27:48 +0000"  >&lt;p&gt;It&apos;s the former: in this case, the queries are queued. A new thread will be created only when the queue is full. Then, if we reach maxThreads and the queue is full the new tasks are rejected. In our case the queue is nearly unbounded, so we stay with corePoolSize.&lt;/p&gt;</comment>
                            <comment id="14791253" author="stack" created="Wed, 16 Sep 2015 22:42:30 +0000"  >&lt;p&gt;Ok. Not what we want. Lets look at alternative...&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626350" name="HBASE-10449.v1.patch" size="1935" author="nkeywal" created="Fri, 31 Jan 2014 19:02:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 19:49:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371159</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 13 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1rytz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371463</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>