<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:39:32 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6752/HBASE-6752.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6752] On region server failure, serve writes and timeranged reads during the log split</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6752</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Opening for write on failure would mean:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Assign the region to a new regionserver. It marks the region as recovering
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;specific exception returned to the client when we cannot server.&lt;/li&gt;
		&lt;li&gt;allow them to know where they stand. The exception can include some time information (failure stated on: ...)&lt;/li&gt;
		&lt;li&gt;allow them to go immediately on the right regionserver, instead of retrying or calling the region holding meta to get the new address&lt;br/&gt;
     =&amp;gt; save network calls, lower the load on meta.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Do the split as today. Priority is given to region server holding the new regions
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;help to share the load balancing code: the split is done by region server considered as available for new regions&lt;/li&gt;
		&lt;li&gt;help locality (the recovered edits are available on the region server) =&amp;gt; lower the network usage&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;When the split is finished, we&apos;re done as of today&lt;/li&gt;
	&lt;li&gt;while the split is progressing, the region server can
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;serve writes
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;that&apos;s useful for all application that need to write but not read immediately:&lt;/li&gt;
			&lt;li&gt;whatever logs events to analyze them later&lt;/li&gt;
			&lt;li&gt;opentsdb is a perfect example.&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;serve reads if they have a compatible time range. For heavily used tables, it could be an help, because:
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;we can expect to have a few minutes of data only (as it&apos;s loaded)&lt;/li&gt;
			&lt;li&gt;the heaviest queries, often accepts a few &lt;del&gt;or more&lt;/del&gt; minutes delay.&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some &quot;What if&quot;:&lt;br/&gt;
1) the split fails&lt;br/&gt;
=&amp;gt; Retry until it works. As today. Just that we serves writes. We need to know (as today) that the region has not recovered if we fail again.&lt;br/&gt;
2) the regionserver fails during the split&lt;br/&gt;
=&amp;gt; As 1 and as of today/&lt;br/&gt;
3) the regionserver fails after the split but before the state change to fully available.&lt;br/&gt;
=&amp;gt; New assign. More logs to split (the ones already dones and the new ones).&lt;br/&gt;
4) the assignment fails&lt;br/&gt;
=&amp;gt; Retry until it works. As today.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12606885">HBASE-6752</key>
            <summary>On region server failure, serve writes and timeranged reads during the log split</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="nkeywal">Nicolas Liochon</reporter>
                        <labels>
                    </labels>
                <created>Mon, 10 Sep 2012 14:57:06 +0000</created>
                <updated>Wed, 16 Nov 2016 22:18:29 +0000</updated>
                                            <version>2.0.0</version>
                                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                            <comments>
                            <comment id="13452467" author="stack" created="Mon, 10 Sep 2012 21:35:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;specific exception returned to the client when we cannot server.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Who would return this?  Not the server that just failed?&lt;/p&gt;

&lt;p&gt;Or is it during recovery?  The region will be assigned this new location and meta gets updated w/ new location only the region is not fully on line because its still recovering?&lt;/p&gt;

&lt;p&gt;Or is this when region is moved?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Priority is given to region server holding the new regions&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What does this mean?  What kinda of priority?&lt;/p&gt;

&lt;p&gt;I like being able to take writes the sooner.&lt;/p&gt;</comment>
                            <comment id="13452486" author="nkeywal" created="Mon, 10 Sep 2012 21:53:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Who would return this? Not the server that just failed?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If we reassign immediately, the client will go to the new regionserver. So the region server will be able to tell it a real status (for example, on reads, we can estimate the recovery time left and the regionserver can say: come back in 20 seconds for this region).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What does this mean? What kinda of priority?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Today, the split is performed by any available RS. If we preassign the regions, the split can be done by the regionserver which is owning some of the data we&apos;re expecting to find in the hlog file...&lt;/p&gt;</comment>
                            <comment id="13452496" author="stack" created="Mon, 10 Sep 2012 22:00:49 +0000"  >&lt;p&gt;Makes sense.  Sounds great.  How we know what regionserver to give a log split too when the log has edits for all regions that were on a regionserver.  You thinking we could give all regions on the crashed regionserver to a particular regionserver?&lt;/p&gt;</comment>
                            <comment id="13452549" author="kannanm" created="Mon, 10 Sep 2012 22:54:28 +0000"  >&lt;p&gt;There might be a bunch of nitty gritties to be ironed out-- but being able to take writes nearly all the time would be a very nice win. So big +1 for exploring this effort. Will throw out a few things that come to mind:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We do want the old edits to come in the correct order of sequence ids (i.e. be considered older than the newer puts that arrive when the region is in recovery mode, correct)? So, we somehow need to cheaply find the correct sequence id to use for the new puts. It needs to be bigger than sequence ids for all the edits for that region in the log files. So maybe all that&apos;s needed here is to open recover the latest log file, and scan it to find the last sequence id?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Picking a winner among duplicates in two files relies on using sequence id of the HFile as a tie-break. And therefore, today, compactions always pick  a dense subrange of files order by sequence ids. That is if we have HFiles a, b, c, d, e sorted by sequence id, we might compact a,b,c or c,d,e but never say a,d,e. With this new scheme, we should take care that we don&apos;t violate this property. The old data should correctly be recovered into HFiles with the correct sequence id.. and even if newer data has been flushed before the recovery is complete we shouldn&apos;t compact those newer files with older HFiles given that some new files are supposed to come in between (after recovery).&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="13460662" author="gchanan" created="Fri, 21 Sep 2012 17:55:00 +0000"  >&lt;p&gt;On timeranged reads:&lt;/p&gt;

&lt;p&gt;if the user specified his own timestamps, couldn&apos;t the correct value to return be only in the WAL?&lt;/p&gt;</comment>
                            <comment id="13460703" author="gchanan" created="Fri, 21 Sep 2012 18:53:20 +0000"  >&lt;p&gt;Assigned to myself, I&apos;m definitely up for the serving writes part, need to think some more about the timeranged reads.  May file separate JIRAs.&lt;/p&gt;</comment>
                            <comment id="13460742" author="nkeywal" created="Fri, 21 Sep 2012 19:23:54 +0000"  >&lt;p&gt;Seems reasonable, there are still some dark areas around timerange. Let&apos;s do thing smoothly &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. But I think your comment is right.&lt;/p&gt;

&lt;p&gt;Some various points I had in mind:&lt;br/&gt;
There is another use case mentionned in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3745&quot; title=&quot;Add the ability to restrict major-compactible files by timestamp&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3745&quot;&gt;&lt;del&gt;HBASE-3745&lt;/del&gt;&lt;/a&gt;: &quot;In some applications, a common access pattern is to frequently scan tables with a time range predicate restricted to a fairly recent time window. For example, you may want to do an incremental aggregation or indexing step only on rows that have changed in the last hour. We do this efficiently by tracking min and max timestamp on an HFile level, so that old HFiles don&apos;t have to be read.&quot;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;We do want the old edits to come in the correct order of sequence ids &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Imho yes, we should not relax any point of the HBase consistency.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So, we somehow need to cheaply find the correct sequence id to use for the new puts. It needs to be bigger than sequence ids for all the edits for that region in the log files. So maybe all that&apos;s needed here is to open recover the latest log file, and scan it to find the last sequence id?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I would like HBase to be resilient to log files issues (no replica, corrupted files, overloaded datanodes, bad luck when choosing the datanode to read from...) by not opening them at all during this process. Would a guess estimate be ok? counting the number of files/blocks to calculate the maximum number of id?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Picking a winner among duplicates in two files relies on using sequence id of the HFile as a tie-break. And therefore, today, compactions always pick a dense subrange of files order by sequence ids. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I wonder if we need major compactions? I was thinking that they could be skipped. But we need to be able to manage small compactions for sure. I imagine that we can have some critical cases where we can be in the intermediate state a few days: (week end + trying to fix the broken hlog on a test cluster + waiting for a non critical moment for fixing the production env)... &lt;/p&gt;

</comment>
                            <comment id="13540005" author="nkeywal" created="Thu, 27 Dec 2012 16:03:38 +0000"  >&lt;p&gt;@Gregory: As you have unassigned the jira, I will have a look in the next weeks. Have you studied some options in more details and rejected them?&lt;/p&gt;</comment>
                            <comment id="13540076" author="gchanan" created="Thu, 27 Dec 2012 17:55:42 +0000"  >&lt;p&gt;@nkeywal: didn&apos;t study anything in too much depth.&lt;/p&gt;

&lt;p&gt;For the read part, my thought was to implement a config (in HTableDescriptor?) that would reject user-set timestamps on writes, so we know for sure there can&apos;t be any writes in the timestamp range that need to be replayed from the WAL.  I suspect there are other optimizations we could do with that information, but haven&apos;t thought it through.&lt;/p&gt;

&lt;p&gt;For writes, do you create a new WAL for the new writes that are happening while the log is still replaying?  If so, management could be complicated and it might make sense to have support for multiple WALs already before tackling that.  If not (you write to the same WAL), would that even work?  I guess you would want to avoid replaying the new writes (might be okay if all WAL updates are idempotent, but could be an issue if a lot of writes go in during the replay time).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12551766">HBASE-5843</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="12611460">HBASE-6984</subtask>
                            <subtask id="12611461">HBASE-6985</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 10 Sep 2012 21:35:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>241875</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 51 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02fpr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12147</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>