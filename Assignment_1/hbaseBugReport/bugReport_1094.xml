<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:50:41 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1094/HBASE-1094.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1094] Region Server throw NotServingRegionException when batchUpdate irredicly (After a large amount of file inserts)</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1094</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;After a large amount of file (~400,000) , once in a while during rapid inserts RegionServer returns NotServingRegionException when doing batchUpdate. &lt;br/&gt;
A restart of the client usually fixes the problem , but it happens again after a while. &lt;/p&gt;

&lt;p&gt;LogFiles excerpts: &lt;/p&gt;

&lt;p&gt;&lt;b&gt;RegionServer&lt;/b&gt;&lt;br/&gt;
2008-12-16 09:17:14,413 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1333&lt;br/&gt;
2008-12-16 09:17:14,413 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1334&lt;br/&gt;
2008-12-16 09:17:14,414 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1333 size:65557 offsetInBlock:19507200 lastPacketInBlock:false&lt;br/&gt;
2008-12-16 09:17:14,439 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 in 2sec&lt;br/&gt;
2008-12-16 09:17:14,441 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,442 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,462 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,462 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395. Current region memcache size 236.3k&lt;br/&gt;
2008-12-16 09:17:14,463 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,484 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960/data: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,505 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960/index: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 0&lt;br/&gt;
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1&lt;br/&gt;
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.211:50010&lt;br/&gt;
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,527 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:14,530 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:0 size:65557 offsetInBlock:0 lastPacketInBlock:false&lt;br/&gt;
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1&lt;br/&gt;
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 2&lt;br/&gt;
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:1 size:65557 offsetInBlock:65024 lastPacketInBlock:false&lt;br/&gt;
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 2&lt;br/&gt;
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 3&lt;br/&gt;
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:2 size:65557 offsetInBlock:130048 lastPacketInBlock:false&lt;br/&gt;
2008-12-16 09:17:14,533 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:3 size:49273 offsetInBlock:195072 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:14,534 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:14,535 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 1&lt;br/&gt;
2008-12-16 09:17:14,536 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 2&lt;br/&gt;
2008-12-16 09:17:14,538 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 3&lt;br/&gt;
2008-12-16 09:17:14,538 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_4611894842462358439_1544&lt;br/&gt;
2008-12-16 09:17:14,557 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:14,557 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.211:50010&lt;br/&gt;
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:14,561 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-6152926948595840609_1544 wrote packet seqno:0 size:276 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:14,564 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:14,564 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-6152926948595840609_1544&lt;br/&gt;
2008-12-16 09:17:14,586 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/info/5474929915463365960: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,609 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:14,609 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:14,613 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_2767846628464404081_1545 wrote packet seqno:0 size:38 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:14,616 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:14,617 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_2767846628464404081_1545&lt;br/&gt;
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960 with 56 entries, sequence id 235152, data size 236.3k, file size 238.2k&lt;br/&gt;
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 in 182ms, sequence id=235152, compaction requested=true&lt;br/&gt;
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 1608250010/obde_content&lt;br/&gt;
2008-12-16 09:17:14,644 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:14,649 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020, call batchUpdate([B@552a2a7d, row =&amp;gt; f+C7Y24r+apSz+joQUhiQQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:14,651 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/1405033884904780036.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,694 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/1405033884904780036.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,717 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:14,717 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,719 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:14,721 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-4579777298287321197_1547 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:14,724 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:14,724 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-4579777298287321197_1547&lt;br/&gt;
2008-12-16 09:17:14,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@18084038, row =&amp;gt; hflk16ESykcggRSkrq7vgQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:14,746 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/215038473253378290.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,790 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/215038473253378290.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:14,813 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:14,837 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@74da3b58, row =&amp;gt; rG4yO2bs4Rw+JU4QKY7X2w==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:14,847 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:14,849 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:14,864 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@51575d48, row =&amp;gt; aNq6QyMT+FePc7M78PaQMQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:14,885 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@63442ff5, row =&amp;gt; iA4QenOmdZMbB8PTQPSnRw==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:14,998 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call batchUpdate([B@59eb5159, row =&amp;gt; t5gRF1zQOrx27LTUS84ADA==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,023 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60020, call batchUpdate([B@132fa7c8, row =&amp;gt; Tu0dl1jFT2spZmEZundPoA==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,045 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 1333&lt;br/&gt;
2008-12-16 09:17:15,226 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@4696de68, row =&amp;gt; Skj4FHgWdrR+DSOppIaG6Q==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,237 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate([B@16a3f072, row =&amp;gt; gWd3yPCu6A9CxjBAhO3UPg==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,453 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1334&lt;br/&gt;
2008-12-16 09:17:15,453 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1334 size:65557 offsetInBlock:19572224 lastPacketInBlock:false&lt;br/&gt;
2008-12-16 09:17:15,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@171591e3, row =&amp;gt; ddd8ecfGPwfgKzuLNMvOAw==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,498 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@452719a0, row =&amp;gt; bJOTHv64AsNoFYsh7D0UyA==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,508 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@6a76000a, row =&amp;gt; XVNFoDhT1NeKnT0YwhopHg==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,548 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 60020, call batchUpdate([B@2b753bb9, row =&amp;gt; jHxdShcit3A24oL3HHHgdg==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@7b4286a2, row =&amp;gt; VYUtICqregww41FxZUJkig==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,558 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1335&lt;br/&gt;
2008-12-16 09:17:15,659 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-1532247345865982631_1549 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:15,661 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:15,661 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-1532247345865982631_1549&lt;br/&gt;
2008-12-16 09:17:15,679 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/4722584128214377088.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:15,721 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/4722584128214377088.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:15,744 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:15,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate([B@3f229bc1, row =&amp;gt; WQXUl6gepHza8rVTmr8BSA==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,745 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:15,747 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:15,750 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_9044590686588152812_1551 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:15,752 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:15,752 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_9044590686588152812_1551&lt;br/&gt;
2008-12-16 09:17:15,774 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/6108448749728539444.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:15,797 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@74d3776e, row =&amp;gt; hfCFR4B8pMF3mnY9mMnkDQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,817 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/6108448749728539444.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:15,841 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:15,841 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:15,848 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-3568743239673676944_1553 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:15,850 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:15,850 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-3568743239673676944_1553&lt;br/&gt;
2008-12-16 09:17:15,876 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/3431594424093212534.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:15,901 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@366480d7, row =&amp;gt; j4MGoh0tZvLe0bwYS5lqFQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,925 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate([B@24af9995, row =&amp;gt; z1Uyyyuot9H+G5kHIOfveg==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,926 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/3431594424093212534.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:15,949 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:15,949 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:15,950 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:15,950 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:15,950 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:15,951 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:15,954 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-1561317920938610537_1555 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:15,956 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:15,956 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-1561317920938610537_1555&lt;br/&gt;
2008-12-16 09:17:15,981 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60020, call batchUpdate([B@46823b18, row =&amp;gt; uwp0i8x0qk8RVIjimK1Nfg==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:15,983 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/4022324240389174248.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:16,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate([B@4718f92, row =&amp;gt; VS0OVRXK4BnH9VUHB3rrSQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:16,030 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/4022324240389174248.1608250010: masked=rwxr-xr-x&lt;br/&gt;
2008-12-16 09:17:16,053 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0&lt;br/&gt;
2008-12-16 09:17:16,053 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block&lt;br/&gt;
2008-12-16 09:17:16,054 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:16,054 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010&lt;br/&gt;
2008-12-16 09:17:16,054 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010&lt;br/&gt;
2008-12-16 09:17:16,055 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071&lt;br/&gt;
2008-12-16 09:17:16,058 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_5499006216568952565_1557 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true&lt;br/&gt;
2008-12-16 09:17:16,060 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0&lt;br/&gt;
2008-12-16 09:17:16,060 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_5499006216568952565_1557&lt;br/&gt;
2008-12-16 09:17:16,081 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460/1010339458&lt;br/&gt;
2008-12-16 09:17:16,117 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbase/my_table/1010339458/obde_content/info/1405033884904780036.1608250010, isReference=true, sequence id=207793&lt;br/&gt;
2008-12-16 09:17:16,126 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbase/my_table/1010339458/obde_content/info/3431594424093212534.1608250010, isReference=true, sequence id=235152&lt;br/&gt;
2008-12-16 09:17:16,134 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbase/my_table/1010339458/obde_content/info/4722584128214377088.1608250010, isReference=true, sequence id=235051&lt;br/&gt;
2008-12-16 09:17:16,135 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 3 file(s) in hstore 1010339458/obde_content, max sequence id 235152&lt;br/&gt;
2008-12-16 09:17:16,149 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,149 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,149 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,149 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,156 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,156 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,156 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,156 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2008-12-16 09:17:16,157 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Next sequence id for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 is 235153&lt;br/&gt;
2008-12-16 09:17:16,159 INFO org.apache.hadoop.hbase.regionserver.HRegion: region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460/1010339458 available&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 1010339458/obde_content&lt;br/&gt;
2008-12-16 09:17:16,159 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,159 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460/2015194550&lt;br/&gt;
2008-12-16 09:17:16,185 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbase/my_table/2015194550/obde_content/info/215038473253378290.1608250010, isReference=true, sequence id=207793&lt;br/&gt;
2008-12-16 09:17:16,193 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbase/my_table/2015194550/obde_content/info/4022324240389174248.1608250010, isReference=true, sequence id=235152&lt;br/&gt;
2008-12-16 09:17:16,202 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbase/my_table/2015194550/obde_content/info/6108448749728539444.1608250010, isReference=true, sequence id=235051&lt;br/&gt;
2008-12-16 09:17:16,203 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 3 file(s) in hstore 2015194550/obde_content, max sequence id 235152&lt;br/&gt;
2008-12-16 09:17:16,229 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Next sequence id for region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460 is 235153&lt;br/&gt;
2008-12-16 09:17:16,231 INFO org.apache.hadoop.hbase.regionserver.HRegion: region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460/2015194550 available&lt;br/&gt;
2008-12-16 09:17:16,231 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,231 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,231 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,231 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,231 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,231 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 2015194550/obde_content&lt;br/&gt;
2008-12-16 09:17:16,231 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&lt;br/&gt;
2008-12-16 09:17:16,245 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Cleaned up /hbase/my_table/1608250010/splits true&lt;br/&gt;
2008-12-16 09:17:16,247 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cache hit in table locations for row &amp;lt;&amp;gt; and tableName .META.: location server MY.IP.102:60020, location region name .META.,,1&lt;br/&gt;
2008-12-16 09:17:16,249 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: region split, META updated, and report to master all successful. Old region=REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1608250010, OFFLINE =&amp;gt; true, SPLIT =&amp;gt; true, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}, new regions: my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460, my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460. Split took 1sec&lt;br/&gt;
2008-12-16 09:17:16,291 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate([B@4d2637c2, row =&amp;gt; ZEhP2cZMl+ovnXmpbN5UOQ==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1519)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1105)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:16,301 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call batchUpdate([B@816c920, row =&amp;gt; bDPORkmlvmRIZH0yOux0Sg==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1519)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1105)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-16 09:17:16,352 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1335&lt;br/&gt;
2008-12-16 09:17:16,352 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1335 size:65557 offsetInBlock:19637248 lastPacketInBlock:false&lt;br/&gt;
2008-12-16 09:17:16,356 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1336&lt;br/&gt;
2008-12-16 09:17:16,416 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@fee5806, row =&amp;gt; o8MMWrSbpBj8hFPXSyhZ+g==, &lt;/p&gt;
{column =&amp;gt; obde_content:, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;/p&gt;


&lt;p&gt;&lt;b&gt;Master:&lt;/b&gt;&lt;br/&gt;
2008-12-16 09:15:31,712 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:15:31,878 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region &lt;/p&gt;
{regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}
&lt;p&gt;2008-12-16 09:15:31,908 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}, {NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:15:31,909 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020} complete&lt;br/&gt;
2008-12-16 09:15:37,794 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}&lt;br/&gt;
2008-12-16 09:15:37,817 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,,1229374459395&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENCODED =&amp;gt; 1847652518, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:15:37,818 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1608250010, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:15:37,819 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020} complete&lt;br/&gt;
2008-12-16 09:15:37,819 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2008-12-16 09:15:46,728 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:16:01,743 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:16:16,760 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:16:31,775 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:16:31,889 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}&lt;br/&gt;
2008-12-16 09:16:31,920 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;, &lt;/p&gt;
{NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:16:31,922 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020} complete&lt;br/&gt;
2008-12-16 09:16:37,804 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}&lt;br/&gt;
2008-12-16 09:16:37,826 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,,1229374459395&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENCODED =&amp;gt; 1847652518, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:16:37,827 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1608250010, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:16:37,827 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020} complete&lt;br/&gt;
2008-12-16 09:16:37,827 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2008-12-16 09:16:46,791 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:17:01,807 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:17:16,823 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 4, Num Servers: 2, Avg Load: 2.0&lt;br/&gt;
2008-12-16 09:17:16,902 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395: [B@674c5b37 from MY.IP.102:60020&lt;br/&gt;
2008-12-16 09:17:19,826 INFO org.apache.hadoop.hbase.master.RegionManager: assigning region my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460 to server MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:19,828 INFO org.apache.hadoop.hbase.master.RegionManager: assigning region my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 to server MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,833 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_PROCESS_OPEN: my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 from MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,833 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460 from MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,833 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 from MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,833 DEBUG org.apache.hadoop.hbase.master.HMaster: Main processing loop: PendingOpenOperation from MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,833 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460 open on MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,833 DEBUG org.apache.hadoop.hbase.master.RegionServerOperation: numberOfMetaRegions: 1, onlineMetaRegions.size(): 1&lt;br/&gt;
2008-12-16 09:17:22,833 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: updating row my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460 in region .META.,,1 with startcode 1229433746880 and server MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,835 DEBUG org.apache.hadoop.hbase.master.HMaster: Main processing loop: PendingOpenOperation from MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,835 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 open on MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:22,835 DEBUG org.apache.hadoop.hbase.master.RegionServerOperation: numberOfMetaRegions: 1, onlineMetaRegions.size(): 1&lt;br/&gt;
2008-12-16 09:17:22,835 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: updating row my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 in region .META.,,1 with startcode 1229433746880 and server MY.IP.213:60020&lt;br/&gt;
2008-12-16 09:17:31,845 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:17:31,900 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}&lt;br/&gt;
2008-12-16 09:17:31,932 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}, {NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:17:31,934 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region &lt;/p&gt;
{regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}
&lt;p&gt; complete&lt;br/&gt;
2008-12-16 09:17:37,816 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region &lt;/p&gt;
{regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}
&lt;p&gt;2008-12-16 09:17:37,838 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,,1229374459395&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENCODED =&amp;gt; 1847652518, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:17:37,839 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1608250010, OFFLINE =&amp;gt; true, SPLIT =&amp;gt; true, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:17:37,839 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENCODED =&amp;gt; 1010339458, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:17:37,840 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 2015194550, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:17:37,856 DEBUG org.apache.hadoop.hbase.master.BaseScanner: my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460 no longer has references to my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:17:37,857 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region &lt;/p&gt;
{regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}
&lt;p&gt; complete&lt;br/&gt;
2008-12-16 09:17:37,857 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2008-12-16 09:17:46,864 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:18:01,879 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:18:16,895 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:18:31,910 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region &lt;/p&gt;
{regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}
&lt;p&gt;2008-12-16 09:18:31,912 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:18:31,935 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}, {NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:18:31,936 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020} complete&lt;br/&gt;
2008-12-16 09:18:37,827 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}&lt;br/&gt;
2008-12-16 09:18:37,851 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,,1229374459395&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENCODED =&amp;gt; 1847652518, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:18:37,852 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1608250010, OFFLINE =&amp;gt; true, SPLIT =&amp;gt; true, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:18:37,853 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENCODED =&amp;gt; 1010339458, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:18:37,853 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 2015194550, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:18:37,857 DEBUG org.apache.hadoop.hbase.master.BaseScanner: my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460 no longer has references to my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395&lt;br/&gt;
2008-12-16 09:18:37,857 INFO org.apache.hadoop.hbase.master.BaseScanner: Deleting region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 because daughter splits no longer hold references&lt;br/&gt;
2008-12-16 09:18:37,858 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: DELETING region hdfs://be4.nydc1.outbrain.com:54310/hbase/my_table/1608250010&lt;br/&gt;
2008-12-16 09:18:37,891 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020} complete&lt;br/&gt;
2008-12-16 09:18:37,891 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2008-12-16 09:18:46,927 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:19:01,943 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:19:16,960 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:19:31,921 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}&lt;br/&gt;
2008-12-16 09:19:31,949 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;, &lt;/p&gt;
{NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:19:31,950 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020} complete&lt;br/&gt;
2008-12-16 09:19:31,976 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:19:37,837 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}&lt;br/&gt;
2008-12-16 09:19:37,861 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,,1229374459395&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENCODED =&amp;gt; 1847652518, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:19:37,862 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENCODED =&amp;gt; 1010339458, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:19:37,863 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 2015194550, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:19:37,863 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020} complete&lt;br/&gt;
2008-12-16 09:19:37,863 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2008-12-16 09:19:46,992 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:20:02,006 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:20:17,022 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:20:31,931 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}&lt;br/&gt;
2008-12-16 09:20:31,955 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}, {NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:20:31,956 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region &lt;/p&gt;
{regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}
&lt;p&gt; complete&lt;br/&gt;
2008-12-16 09:20:32,037 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:20:37,848 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region &lt;/p&gt;
{regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}
&lt;p&gt;2008-12-16 09:20:37,870 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,,1229374459395&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENCODED =&amp;gt; 1847652518, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:20:37,871 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,RQue7uxNoe59vJxljcd1rQ==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;RQue7uxNoe59vJxljcd1rQ==&apos;, ENDKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENCODED =&amp;gt; 1010339458, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:20:37,872 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;my_table,iGnmMuO6Z0jyDJoteHYqKA==,1229437034460&apos;, STARTKEY =&amp;gt; &apos;iGnmMuO6Z0jyDJoteHYqKA==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 2015194550, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;my_table&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.213:60020&apos;, STARTCODE =&amp;gt; 1229433746880&lt;br/&gt;
2008-12-16 09:20:37,872 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region &lt;/p&gt;
{regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: MY.IP.102:60020}
&lt;p&gt; complete&lt;br/&gt;
2008-12-16 09:20:37,872 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2008-12-16 09:20:47,052 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:21:02,069 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:21:17,084 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;br/&gt;
2008-12-16 09:21:31,942 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region &lt;/p&gt;
{regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}
&lt;p&gt;2008-12-16 09:21:31,964 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;, &lt;/p&gt;
{NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;MY.IP.102:60020&apos;, STARTCODE =&amp;gt; 1229433746854&lt;br/&gt;
2008-12-16 09:21:31,965 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region &lt;/p&gt;
{regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: MY.IP.213:60020}
&lt;p&gt; complete&lt;br/&gt;
2008-12-16 09:21:32,100 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 5, Num Servers: 2, Avg Load: 3.0&lt;/p&gt;

</description>
                <environment>&lt;p&gt;CentOS 64bit , Hadoop 0.18.1 , 5 DataNode + 2 RegionServers &lt;/p&gt;</environment>
        <key id="12411412">HBASE-1094</key>
            <summary>Region Server throw NotServingRegionException when batchUpdate irredicly (After a large amount of file inserts)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yossale">Yossi Ittach</reporter>
                        <labels>
                    </labels>
                <created>Mon, 29 Dec 2008 16:20:00 +0000</created>
                <updated>Thu, 19 Aug 2010 16:58:07 +0000</updated>
                            <resolved>Thu, 19 Aug 2010 16:58:07 +0000</resolved>
                                    <version>0.18.0</version>
                    <version>0.18.1</version>
                                                    <component>Client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12659578" author="yossale" created="Mon, 29 Dec 2008 16:21:50 +0000"  >&lt;p&gt;part of the log files &lt;/p&gt;</comment>
                            <comment id="12659580" author="yossale" created="Mon, 29 Dec 2008 16:23:31 +0000"  >&lt;p&gt;The error logs are quite similiar , I think it&apos;s the same problem&lt;/p&gt;</comment>
                            <comment id="12660083" author="jdcryans" created="Wed, 31 Dec 2008 15:15:15 +0000"  >&lt;p&gt;Yossi,&lt;/p&gt;

&lt;p&gt;What I&apos;m seeing is is a completely normal system. When a region gets closed, the clients with a stale cache will still try to use it unless they get a NotServingRegionException and they will show up in the HRS log. Also you say that a client restart solves the problem, which leads me to believe that the problem is not there.&lt;/p&gt;

&lt;p&gt;So, how are you inserting the files in HBase? Many java clients? Using Thrift? How many clients? How do they react when getting this exception? You should also be getting some logs in your client, can we see it (make sure they also are in DEBUG just like your cluster)? Did you open this JIRA when seeing the NotServingRegionException  in the HRS log? &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="12660085" author="yossale" created="Wed, 31 Dec 2008 15:36:16 +0000"  >&lt;p&gt;Hey Jean-Daniel,&lt;/p&gt;


&lt;p&gt;&amp;gt;&amp;gt;Did you open this JIRA when seeing the NotServingRegionException  in the HRS log&lt;br/&gt;
Nope , I started it because I&apos;m recieving the NSRE in my console , under a RetriesExhaustedException&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;When a region gets closed, the clients with a stale cache will still try to use it unless &lt;br/&gt;
&amp;gt;&amp;gt;they get a NotServingRegionException and they will show up in the HRS log&lt;/p&gt;

&lt;p&gt;I figured that this is how it should happen , but the problem is that It doesn&apos;t work:&lt;br/&gt;
In my console I get an RetriesExhaustedException (Originiated in (I think) the HConnectionManager@getRegionServerWithRetries), with a list of NSRE&apos;s - and since then , any attempt to write to the same region fails.&lt;/p&gt;

&lt;p&gt;Also - this happens after a substantial amount of files  - we&apos;ve already had many region splits before it happened - so it doesn&apos;t seem to be so straight forward &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; So, how are you inserting the files in HBase?&lt;br/&gt;
HBase 0.18.1 on Hadoop 0.18.1 , 3 DN&amp;amp;RS + 1HBM &amp;amp; 1HNN&lt;/p&gt;

&lt;p&gt;Using hTable.commit(batchUpdate); (Same as the API example...)&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Many java clients?&lt;br/&gt;
Just one currently&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Using Thrift? Nope&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; many clients? How do they react when getting this exception?&lt;br/&gt;
Currently 1 client - catches the exception and skips this file (Also tried re-entering the same file - didn&apos;t work)&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;Client log:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,RRs+UqZuI30ot7HG+X57FQ==,1230551636802&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;/p&gt;

&lt;p&gt;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Looked for the region in the shell , and got this:&lt;br/&gt;
hbase(main):002:0&amp;gt; get &apos;.META.&apos;, &apos;obde_documentEntries,RRs+UqZuI30ot7HG+X57FQ==,1230551636802&apos;&lt;br/&gt;
08/12/30 07:48:12 DEBUG client.HConnectionManager$TableServers: Cache hit in table locations for row &amp;lt;&amp;gt; and tableName .META.: location server 192.168.252.216:60020, location region name .META.,,1&lt;br/&gt;
COLUMN                       CELL&lt;br/&gt;
 historian:assignment        timestamp=1230640777222, value=Region assigned to server 192.168.252.200:60020&lt;br/&gt;
 historian:compaction        timestamp=1230640790641, value=Region compaction completed in 5sec&lt;br/&gt;
 historian:open              timestamp=1230640780231, value=Region opened on server : My_Server_Name&lt;br/&gt;
 historian:split             timestamp=1230551637944, value=Region split from  : obde_documentEntries,RRs+UqZu&lt;br/&gt;
                             I30ot7HG+X57FQ==,1230477626688&lt;br/&gt;
 info:regioninfo             timestamp=1230551637946, value=REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,RRs+UqZuI&lt;br/&gt;
                             30ot7HG+X57FQ==,1230551636802&apos;, STARTKEY =&amp;gt; &apos;RRs+UqZuI30ot7HG+X57FQ==&apos;, ENDKEY =&amp;gt;&lt;br/&gt;
                              &apos;SSv6VcCov7wlee67ZjNlXQ==&apos;, ENCODED =&amp;gt; 1710096259, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_docu&lt;br/&gt;
                             mentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde
                             _content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCA

                             CHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}&lt;br/&gt;
 info:server                 timestamp=1230640780230, value=192.168.252.200:60020&lt;br/&gt;
 info:serverstartcode        timestamp=1230640780230, value=1230640763821&lt;br/&gt;
7 row(s) in 0.0270 seconds&lt;/p&gt;</comment>
                            <comment id="12660111" author="jdcryans" created="Wed, 31 Dec 2008 18:00:58 +0000"  >&lt;p&gt;Oh so you did get the RetriesExhaustedException, that&apos;s better (would be nice to see the whole exception with the 10 NSRE and timestamps ). Relooking at the logs, I see that your client got the NSRE 10 times under 3 seconds which is not enough for the master to finish the splitting procedure it seems. First one was at 09:17:14,649 and last one at 09:17:16,416. This is weird, because we have a minimum of a 1 or 2 seconds retry then it&apos;s incremental. Did you change the hbase.client.pause value? If not, you could try putting it at 4000 instead of 2000.&lt;/p&gt;

&lt;p&gt;Could you also describe the hardware you are using? I&apos;d also like to know, when the inserts fail, if the machines are swapping/using 100% CPU.&lt;/p&gt;

&lt;p&gt;Thx!&lt;/p&gt;</comment>
                            <comment id="12660134" author="yossale" created="Wed, 31 Dec 2008 19:48:37 +0000"  >&lt;p&gt;Nope , we haven&apos;t touched the pause time. &lt;br/&gt;
to the best of my understanding , the consecutive requests in the HRS are not the same request - notice it&apos;s a different row each time , but they all get the same NSRE reply.  I&apos;m trying to recreate the same error again (it happens sporadically , so I can&apos;t promise a date). &lt;/p&gt;

&lt;p&gt;What do you think happens here? is it because it&apos;s in the middle of a split (Aren&apos;t the request to a splitted region frozen until the split is over?)  or is it the client using stale data (that somehow wasn&apos;t refreshed on time)? If so , wasn&apos;t it so suppose to update after the first NSRE ? &lt;/p&gt;

&lt;p&gt;Will increasing the hbase.client.rpc.maxattempts do the trick?&lt;/p&gt;

&lt;p&gt;I&apos;ll try to find the exact console log again and post it &lt;/p&gt;





</comment>
                            <comment id="12660150" author="jdcryans" created="Wed, 31 Dec 2008 21:13:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;to the best of my understanding , the consecutive requests in the HRS are not the same request - notice it&apos;s a different row each time ,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ah yes I overlooked that, with those crazy row names it&apos;s hard to follow &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; You should just keep the HBase DEBUG, not the Hadoop stuff so that the logs contain only what we need.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What do you think happens here? is it because it&apos;s in the middle of a split (Aren&apos;t the request to a splitted region frozen until the split is over?) or is it the client using stale data (that somehow wasn&apos;t refreshed on time)? If so , wasn&apos;t it so suppose to update after the first NSRE ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes the splits block the updates and after a NSRE the client cache refreshes. If the split is taking too long, META does not get updated and the client still gets the same information. Without your client log and your clean HRS log, it&apos;s really hard to get a hold of what&apos;s going on. Maybe it&apos;s because of an overwhelmed hardware (see my question in my last comment regards this subject).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will increasing the hbase.client.rpc.maxattempts do the trick?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean the hbase.client.retries.number? Yes, it should help along with hbase.client.pause.&lt;/p&gt;

&lt;p&gt;Keep up the good work Yossi!&lt;/p&gt;</comment>
                            <comment id="12660154" author="yossale" created="Wed, 31 Dec 2008 21:55:54 +0000"  >&lt;p&gt;10x , I&apos;m trying - This bug is driving me insane &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Maybe it&apos;s because of an overwhelmed hardware (see my question in my last comment regards this subject).&lt;br/&gt;
All the machines  (3 RS+DN , 1 HBM&amp;amp;HNN) are Intel dual cores with 4G Ram , 80GB disk , and really weren&apos;t too busy (I remember checking that , but I can&apos;t give you actual figures) &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; You mean the hbase.client.retries.number? Yes, it should help along with hbase.client.pause &lt;br/&gt;
Actually I meant the maxRPCAttempts  (in the HConnectionManager : &quot;this.maxRPCAttempts = conf.getInt(&quot;hbase.client.rpc.maxattempts&quot;, 1);&quot;)&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;Without your client log and your clean HRS log, it&apos;s really hard to get a hold of what&apos;s going on&lt;/p&gt;

&lt;p&gt;I&apos;ll try to keep everything next time it fails. - I&apos;ve attached some console log I found . It&apos;s pretty repetitive , but notice that same problem occurs on 2 different region servers (213 &amp;amp; 216) . &lt;br/&gt;
After a NSRE the system just skip What bothers me the most is that from that moment on , all calls for that region fails (for hours!) - So this problem persist even long after the region split is way over... and after I restart the client - everything works again. &lt;/p&gt;

&lt;p&gt;Console logs:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,s2WGdnjkfzOQ36wsxZFsGw==,1230546252886&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:214)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;br/&gt;
2008-12-30 07:48:55,056 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-6&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@5b9bb7ff&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.216:60020 for region obde_documentEntries,AxIfrQtyK6ln3gAx7Z6lg==,1230557004812, row &apos;BXabo2C5jyl9a0mC1XtlOg==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,AxIfrQtyK6ln3gAx7Z6lg==,1230557004812&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:214)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.213:60020 for region obde_documentEntries,TUpPkdJDxYdsWCxlMhxJLQ==,1230551614916, row &apos;UQU17V6ogCy6Dl+0gQcUw==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,TUpPkdJDxYdsWCxlMhxJLQ==,1230551614916&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:222)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;

&lt;p&gt;2008-12-30 07:48:55,262 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-4&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@5b9bb7ff&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.213:60020 for region obde_documentEntries,ukzPch1iK2Z2ALoHEiVA==,1230546207170, row &apos;vE2+lFgz1znEI7sSpTr4Xw==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,ukzPch1iK2Z2ALoHEiVA==,1230546207170&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:214)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;

&lt;p&gt;2008-12-30 07:48:55,611 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-6&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@5b9bb7ff&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.216:60020 for region obde_documentEntries,KazxMIqswPDW3U4XJZNa3w==,1230560572107, row &apos;L78TGyh0zoNNw7JRg1XnJA==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,KazxMIqswPDW3U4XJZNa3w==,1230560572107&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:222)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;

&lt;p&gt;2008-12-30 07:48:55,734 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-4&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@5b9bb7ff&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.213:60020 for region obde_documentEntries,TUpPkdJDxYdsWCxlMhxJLQ==,1230551614916, row &apos;TUtfp4qZwWVZK3NEmYpAA==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,TUpPkdJDxYdsWCxlMhxJLQ==,1230551614916&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:214)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;


&lt;p&gt;2008-12-30 07:48:56,635 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-4&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@5b9bb7ff&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.213:60020 for region obde_documentEntries,irBHbhckwm0G71ycf3K1IQ==,1230546338725, row &apos;jFyN0kMQHJgf5UIyiEYk5w==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,irBHbhckwm0G71ycf3K1IQ==,1230546338725&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:214)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;

&lt;p&gt;2008-12-30 07:48:57,350 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-6&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@5b9bb7ff&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.213:60020 for region obde_documentEntries,ukzPch1iK2Z2ALoHEiVA==,1230546207170, row &apos;vsGhQwtevCAOmYrevAPYQ==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,ukzPch1iK2Z2ALoHEiVA==,1230546207170&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
	at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:222)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
	at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)&lt;br/&gt;
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:595)&lt;/p&gt;


</comment>
                            <comment id="12660156" author="jdcryans" created="Wed, 31 Dec 2008 22:08:40 +0000"  >&lt;p&gt;Okay the hardware is alright, cluster is small but you only have 1 client inserting rows so it shouldn&apos;t be that bad.&lt;/p&gt;

&lt;p&gt;Regards hbase.client.rpc.maxattempts, it&apos;s weird to have a conf missing from hbase-default.xml, care to open a JIRA for this? Thx. But upping it would not affect your situation.&lt;/p&gt;

&lt;p&gt;That thing with the client holding of the HRS, it&apos;s very weird. Next time it happens, try to get a Thread Dump from the stuck region server. You can get it from the HRS web UI or by using jstack on the machine.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="12661916" author="yossale" created="Thu, 8 Jan 2009 09:54:51 +0000"  >&lt;p&gt;Finally happened again&lt;/p&gt;

&lt;p&gt;As you requested , I&apos;ve got the stuck RS dump and the Master dump. (attached)&lt;br/&gt;
Also attached are the MasterUI and the RSUI. Notice both doesn&apos;t have the Region specified in the error , but have one that is very similar in name (I don&apos;t know if this is just a coincidence or not)&lt;/p&gt;

&lt;p&gt;I&apos;ve found these lines in an old master log file (from 1/109) - this is the lost region:&lt;/p&gt;

&lt;p&gt;2009-01-01 16:08:04,169 DEBUG org.apache.hadoop.hbase.master.BaseScanner: obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230844034165 no longer has references to obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230485251740&lt;br/&gt;
2009-01-01 16:08:04,171 DEBUG org.apache.hadoop.hbase.master.BaseScanner: obde_documentEntries,13k7Nop1AFBjYnwLf6p9KQ==,1230844034165 no longer has references to obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230485251740&lt;br/&gt;
2009-01-01 16:08:04,172 INFO org.apache.hadoop.hbase.master.BaseScanner: Deleting region obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230485251740 because daughter splits no longer hold references&lt;br/&gt;
2009-01-01 16:08:04,172 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: DELETING region hdfs://be4.nydc1.outbrain.com:54310/hbase/obde_documentEntries/318630300&lt;/p&gt;






&lt;ul&gt;
	&lt;li&gt;The console error: *&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2009-01-08 03:31:57,419 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;pool-3-thread-1&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;com.outbrain.globals.io.filesystem.HBaseFeedEntries&amp;#93;&lt;/span&gt; (HBaseFeedEntries.java:130)     - Could not commit to table: [B@59653bcb&lt;br/&gt;
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 192.168.252.213:60020 for region obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230485251740, row &apos;1QGcnGSzaWZRtT5FcsTwwA==&apos;, but failed after 1 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230485251740&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1524)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1110)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;


&lt;p&gt;        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
        at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveToMechanisem(HBaseFeedEntries.java:125)&lt;br/&gt;
        at com.outbrain.globals.io.filesystem.HBaseFeedEntries.saveTo(HBaseFeedEntries.java:102)&lt;br/&gt;
        at com.outbrain.globals.io.filesystem.FeedEntriesFS.saveTo(FeedEntriesFS.java:157)&lt;br/&gt;
        at com.outbrain.source_detector.sourceCrawler.SourceCrawler.updateDocuments(SourceCrawler.java:214)&lt;br/&gt;
        at com.outbrain.source_detector.sourceCrawler.SourceCrawler.handleSource(SourceCrawler.java:89)&lt;br/&gt;
        at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:52)&lt;br/&gt;
        at com.outbrain.source_detector.sourceCrawler.SourceCrawler.call(SourceCrawler.java:30)&lt;br/&gt;
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)&lt;br/&gt;
        at java.util.concurrent.FutureTask.run(FutureTask.java:123)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The master log from that time:&lt;/b&gt;&lt;br/&gt;
2009-01-08 03:30:44,890 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,w4eULkuoDVg9wtidBiSwHQ==,1230546207170&apos;, STARTKEY =&amp;gt; &apos;w4eULkuoDVg9wtidBiSwHQ==&apos;, ENDKEY =&amp;gt; &apos;xOZ+gfzITX5kg242uCQ==&apos;, ENCODED =&amp;gt; 1259721264, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;192.168.252.216:60020&apos;, STARTCODE =&amp;gt; 1230815082235&lt;br/&gt;
2009-01-08 03:30:44,891 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,xOZ+gfzITX5kg242uCQ==,1230546225176&apos;, STARTKEY =&amp;gt; &apos;xOZ+gfzITX5kg242uCQ==&apos;, ENDKEY =&amp;gt; &apos;yhiJBIFf8OObcxlCY2qgsw==&apos;, ENCODED =&amp;gt; 1441754713, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;192.168.252.200:60020&apos;, STARTCODE =&amp;gt; 1230815082100&lt;br/&gt;
2009-01-08 03:30:44,942 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,yhiJBIFf8OObcxlCY2qgsw==,1230546225176&apos;, STARTKEY =&amp;gt; &apos;yhiJBIFf8OObcxlCY2qgsw==&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 552003722, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;192.168.252.216:60020&apos;, STARTCODE =&amp;gt; 1230815082235&lt;br/&gt;
2009-01-08 03:30:44,943 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 192.168.252.213:60020} complete&lt;br/&gt;
2009-01-08 03:30:44,943 INFO org.apache.hadoop.hbase.master.BaseScanner: all meta regions scanned&lt;br/&gt;
2009-01-08 03:30:47,486 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 63, Num Servers: 3, Avg Load: 21.0&lt;br/&gt;
2009-01-08 03:30:58,225 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cache hit in table locations for row &amp;lt;&amp;gt; and tableName .META.: location server 192.168.252.213:60020, location region name .META.,,1&lt;br/&gt;
2009-01-08 03:31:02,502 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 63, Num Servers: 3, Avg Load: 21.0&lt;br/&gt;
2009-01-08 03:31:17,522 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 63, Num Servers: 3, Avg Load: 21.0&lt;br/&gt;
2009-01-08 03:31:29,074 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cache hit in table locations for row &amp;lt;&amp;gt; and tableName .META.: location server 192.168.252.213:60020, location region name .META.,,1&lt;br/&gt;
2009-01-08 03:31:32,539 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 63, Num Servers: 3, Avg Load: 21.0&lt;br/&gt;
2009-01-08 03:31:41,728 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: 192.168.252.216:60020}&lt;br/&gt;
2009-01-08 03:31:41,737 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;, ENCODED =&amp;gt; 1028785192, TABLE =&amp;gt; &lt;tt&gt;NAME =&amp;gt; &apos;.META.&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;true&apos;, FAMILIES =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;{NAME =&amp;gt; &apos;historian&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}, {NAME =&amp;gt; &apos;info&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;1&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}&amp;#93;&lt;/span&gt;&lt;/tt&gt;}, SERVER =&amp;gt; &apos;192.168.252.213:60020&apos;, STARTCODE =&amp;gt; 1230815085374&lt;br/&gt;
2009-01-08 03:31:41,738 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: 192.168.252.216:60020} complete&lt;br/&gt;
2009-01-08 03:31:44,841 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 192.168.252.213:60020}&lt;br/&gt;
2009-01-08 03:31:44,865 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,,1230824142963&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;+frhmXa3XDL4Hk4La1aUw==&apos;, ENCODED =&amp;gt; 1237218248, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;192.168.252.216:60020&apos;, STARTCODE =&amp;gt; 1230815082235&lt;br/&gt;
2009-01-08 03:31:44,865 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,+frhmXa3XDL4Hk4La1aUw==,1230824142963&apos;, STARTKEY =&amp;gt; &apos;+frhmXa3XDL4Hk4La1aUw==&apos;, ENDKEY =&amp;gt; &apos;0NCwYeyHUHMQUlwlhQhiWQ==&apos;, ENCODED =&amp;gt; 152138444, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}}}, SERVER =&amp;gt; &apos;192.168.252.216:60020&apos;, STARTCODE =&amp;gt; 1230815082235&lt;br/&gt;
2009-01-08 03:31:44,866 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230844034165&apos;, STARTKEY =&amp;gt; &apos;0NCwYeyHUHMQUlwlhQhiWQ==&apos;, ENDKEY =&amp;gt; &apos;13k7Nop1AFBjYnwLf6p9KQ==&apos;, ENCODED =&amp;gt; 311750939, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;192.168.252.213:60020&apos;, STARTCODE =&amp;gt; 1230815085374&lt;br/&gt;
2009-01-08 03:31:44,866 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION =&amp;gt; {NAME =&amp;gt; &apos;obde_documentEntries,13k7Nop1AFBjYnwLf6p9KQ==,1230844034165&apos;, STARTKEY =&amp;gt; &apos;13k7Nop1AFBjYnwLf6p9KQ==&apos;, ENDKEY =&amp;gt; &apos;1kqulDKTmT8Doi0Axzv2gA==&apos;, ENCODED =&amp;gt; 1338919791, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}}}, SERVER =&amp;gt; &apos;192.168.252.213:60020&apos;, STARTCODE =&amp;gt; 1230815085374&lt;/p&gt;

&lt;p&gt;The RegionServer log from that time:&lt;br/&gt;
2009-01-08 03:31:57,188 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call get([B@293aa2ad, [B@488e2100, [B@6b18ac36, -1, -1) from 192.168.252.216:43548: error: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region obde_documentEntries,Xll7oHIEuAXIGxMQn68onw==,1230549771985 in table {NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}&lt;br/&gt;
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region obde_documentEntries,Xll7oHIEuAXIGxMQn68onw==,1230549771985 in table {NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.checkColumn(HRegion.java:1776)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:1151)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1020)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2009-01-08 03:31:57,189 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call get([B@4c78aeed, [B@72470d4, [B@696b71f5, -1, -1) from 192.168.252.216:43548: error: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region obde_documentEntries,7L08uqnO1h1SjsFbQHvYw==,1230815130454 in table {NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}&lt;br/&gt;
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region obde_documentEntries,7L08uqnO1h1SjsFbQHvYw==,1230815130454 in table {NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.checkColumn(HRegion.java:1776)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:1151)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1020)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2009-01-08 03:31:57,190 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call get([B@36a3a811, [B@326f101d, [B@198af9c9, -1, -1) from 192.168.252.216:43548: error: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region obde_documentEntries,UW4y+oARe5pOGYqAmDwDg==,1230551614916 in table {NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}]}&lt;br/&gt;
org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region obde_documentEntries,UW4y+oARe5pOGYqAmDwDg==,1230551614916 in table {NAME =&amp;gt; &apos;obde_documentEntries&apos;, IS_ROOT =&amp;gt; &apos;false&apos;, IS_META =&amp;gt; &apos;false&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;obde_content&apos;, BLOOMFILTER =&amp;gt; &apos;false&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, LENGTH =&amp;gt; &apos;2147483647&apos;, BLOCKCACHE =&amp;gt; &apos;false&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;-1&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;}
&lt;p&gt;]}&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.checkColumn(HRegion.java:1776)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:1151)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1020)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:585)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;




</comment>
                            <comment id="12661965" author="jdcryans" created="Thu, 8 Jan 2009 13:32:35 +0000"  >&lt;p&gt;The region with a similiar name is a child of the region your client is searching. After a split, one of the 2 regions will retain the same start key but the ID (the numbers after that) will be different since it&apos;s kind of a timestamp.&lt;/p&gt;

&lt;p&gt;You seem to have a case of leftovers in META. To make sure, do a scan of .META. in the shell on column family &apos;historian:&apos; and look for a row key named &quot;obde_documentEntries,0NCwYeyHUHMQUlwlhQhiWQ==,1230485251740&quot;. If so, delete that.&lt;/p&gt;

&lt;p&gt;Regards your region server log, I don&apos;t think it&apos;s the good one since it says org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family on content: does not exist in region &lt;/p&gt;</comment>
                            <comment id="12665354" author="yossale" created="Tue, 20 Jan 2009 07:21:18 +0000"  >&lt;p&gt;Jean-Daniel , is there something else that I can get to help fixing this issue? &lt;/p&gt;</comment>
                            <comment id="12679908" author="guiga" created="Sat, 7 Mar 2009 20:25:20 +0000"  >&lt;p&gt;Hi Yossi and Jean-Daniel,&lt;/p&gt;

&lt;p&gt;I&apos;ve just had a similar problem when evaluating HBase. &lt;/p&gt;

&lt;p&gt;When I was running a simple stress test (many threads putting data into a single table), my client started to throw several org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server Some server for region t,w45x D??&lt;cite&gt;|?v?-?,1236452295439, row &apos;x4q?1??t(??j?(G?.&lt;/cite&gt;&apos;, but failed after &lt;b&gt;1&lt;/b&gt; attempts. The strange thing was that I was quite sure that I have set both hbase.client.retries.number and hbase.client.rpc.maxattempts to 10. So I thought there was no way to my client fail after only one attempt. &lt;/p&gt;

&lt;p&gt;After further investigation, I think I&apos;ve found where was the problem. &lt;/p&gt;

&lt;p&gt;My client, just before starting the threads, invokes HBaseAdmin.checkHBaseAvailable(config). Although this method copies the HBaseConfiguration object and sets hbase.client.retries.number to 1 (see HBaseAdmin, line 751), it creates an HBaseAdmin object, which  invokes HConnectionManager.getConnection(conf). Please notice that this conf is that with hbase.client.retries.number equals to 1. HConnectionManager.getConnection then creates a HConnection using this conf and puts it into a somekind of cache (see HConnectionManager, line 93). Then, the problem with my client is when my it creates a HTable object to be used by its threads it will invoke HConnectionManager.getConnection(conf) again (see HTable, line 109), this time with the correct Configuration object &amp;#8211; the one with hbase.client.retries.number equals to 10. However, when it checks the cache for a HConnection it finds one &amp;#8211; the one previously created by the HBaseAdmin object and using another Configuration object &amp;#8211; and returns it without creating a new one with the correct Configuration. &lt;/p&gt;

&lt;p&gt;Well, I&apos;ve fixed the client for my tests removing the line HBaseAdmin.checkHBaseAvailable(), however I don&apos;t think the behavior I&apos;ve described is expected. What do you think, Jean-Daniel? &lt;/p&gt;

&lt;p&gt;Thank you very much&lt;/p&gt;</comment>
                            <comment id="12679919" author="yossale" created="Sat, 7 Mar 2009 22:41:58 +0000"  >&lt;p&gt;A very interesting observation - I&apos;ll try to check if it works for me too !&lt;/p&gt;

&lt;p&gt;Vale et me ama&lt;br/&gt;
Yossi&lt;/p&gt;


&lt;p&gt;On Sat, Mar 7, 2009 at 10:26 PM, Guilherme Mauro Germoglio Barbosa (JIRA) &amp;lt;&lt;/p&gt;
</comment>
                            <comment id="12679926" author="stack" created="Sat, 7 Mar 2009 23:46:32 +0000"  >&lt;p&gt;Guilherme: Not expected behavior.  Should we make a new issue to fix what you&apos;ve observed?  Yossi, doing as Guilherme suggests, do things work better for you?&lt;/p&gt;</comment>
                            <comment id="12680016" author="guiga" created="Sun, 8 Mar 2009 21:16:40 +0000"  >&lt;p&gt;I think so. &lt;/p&gt;

&lt;p&gt;Also, I&apos;ve edited HConnectionManager in order to use all HBaseConfiguration instead of only HBASE_DIR as key on the HBASE_INSTANCES map. To do so, I&apos;ve implemented HBaseConfiguration.hashcode() &amp;#8211; just like a HashMap.hashCode() is implemented &amp;#8211; and all tests are green with these two modifications. So, I can upload the patch as soon as the issue is created. &lt;/p&gt;</comment>
                            <comment id="12900358" author="stack" created="Thu, 19 Aug 2010 16:58:06 +0000"  >&lt;p&gt;Filed against 0.18.x hbase and we don&apos;t have BatchUpdate anymore.  Issue may remain but manifestation is going to be decidedly different. Lets make an issue when we see it that better fits our new context.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12410629">HBASE-1061</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12397402" name="1-Bug-Master.JPG" size="344040" author="yossale" created="Thu, 8 Jan 2009 09:54:51 +0000"/>
                            <attachment id="12397403" name="1-Bug-egionServer2.JPG" size="224660" author="yossale" created="Thu, 8 Jan 2009 09:54:51 +0000"/>
                            <attachment id="12396852" name="HMBugLog.log" size="26354" author="yossale" created="Mon, 29 Dec 2008 16:21:50 +0000"/>
                            <attachment id="12396853" name="RSbugLog.log" size="48760" author="yossale" created="Mon, 29 Dec 2008 16:21:50 +0000"/>
                            <attachment id="12397405" name="hbase-master-dump.out" size="12678" author="yossale" created="Thu, 8 Jan 2009 10:02:19 +0000"/>
                            <attachment id="12397406" name="hbase-regionserver-dump.out" size="16094" author="yossale" created="Thu, 8 Jan 2009 10:02:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 31 Dec 2008 15:15:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25569</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 18 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hbaf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99091</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>