<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:13:10 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3789/HBASE-3789.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3789] Cleanup the locking contention in the master</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3789</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The new master uses a lot of synchronized blocks to be safe, but it only takes a few jstacks to see that there&apos;s multiple layers of lock contention when a bunch of regions are moving (like when the balancer runs). The main culprits are regionInTransition in AssignmentManager, ZKAssign that uses ZKW.getZNnodes (basically another set of region in transitions), and locking at the RegionState level. &lt;/p&gt;

&lt;p&gt;My understanding is that even tho we have multiple threads to handle regions in transition, everything is actually serialized. Most of the time, lock holders are talking to ZK or a region server, which can take a few milliseconds.&lt;/p&gt;

&lt;p&gt;A simple example is when AssignmentManager wants to update the timers for all the regions on a RS, it will usually be waiting on another thread that&apos;s holding the lock while talking to ZK.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12504420">HBASE-3789</key>
            <summary>Cleanup the locking contention in the master</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jdcryans">Jean-Daniel Cryans</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Fri, 15 Apr 2011 22:53:44 +0000</created>
                <updated>Fri, 20 Nov 2015 12:43:02 +0000</updated>
                            <resolved>Wed, 15 Jun 2011 18:23:54 +0000</resolved>
                                    <version>0.90.2</version>
                                    <fixVersion>0.92.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13020470" author="jdcryans" created="Fri, 15 Apr 2011 23:13:02 +0000"  >&lt;p&gt;This first patch is a dirty work in progress. &lt;/p&gt;

&lt;p&gt;First thing I changed is in ZKW I used a ConcurrentSkipListSet instead of a HashSet which resulted in removing all the weird locking in ZKAssign.&lt;/p&gt;

&lt;p&gt;Next up is AssignmentManager where I removed all the sync done in nodeCreated/DataChanged/ChildrenChanged since it was already handled inside handleRegion(). Also it is doing ZK operations under that sync so it&apos;s double bad.&lt;/p&gt;

&lt;p&gt;Third I changed RegionState so that the stamp is atomically modifiable since it doesn&apos;t really matter that both the state and the stamp be changed by exactly the same person, what you want in the end is progress. This was also the source of a lot of locking in updateTimers.&lt;/p&gt;

&lt;p&gt;I tested this patch under load while killing region servers (multiple at a time), and then running the balancer. Didn&apos;t a single bug. Still needs more testing and need to document the locking and see if there&apos;s any other optimization that could be done.&lt;/p&gt;

&lt;p&gt;At least, my profiling shows that the master is now only waiting on ZK.&lt;/p&gt;
</comment>
                            <comment id="13020471" author="jdcryans" created="Fri, 15 Apr 2011 23:15:43 +0000"  >&lt;p&gt;I might also add that with this patch, when it usually took 25 seconds to run the balancer command it now returns under 1 second.&lt;/p&gt;</comment>
                            <comment id="13020473" author="yuzhihong@gmail.com" created="Fri, 15 Apr 2011 23:21:23 +0000"  >&lt;p&gt;Good job J-D&lt;br/&gt;
Can you disclose roughly how many regions were moved during the 1 second balancing ?&lt;/p&gt;</comment>
                            <comment id="13020476" author="jdcryans" created="Fri, 15 Apr 2011 23:24:23 +0000"  >&lt;p&gt;The balancer only sends the unassign messages before returning. About 500. The total time to balance is halved.&lt;/p&gt;</comment>
                            <comment id="13038229" author="stack" created="Mon, 23 May 2011 21:05:11 +0000"  >&lt;p&gt;You should remove rather than comment out code.&lt;/p&gt;

&lt;p&gt;There is more to be done on this still, right J-D?&lt;/p&gt;</comment>
                            <comment id="13038231" author="jdcryans" created="Mon, 23 May 2011 21:09:09 +0000"  >&lt;p&gt;Yes, like I wrote in the first comment it&apos;s a dirty WIP.&lt;/p&gt;</comment>
                            <comment id="13039368" author="jdcryans" created="Wed, 25 May 2011 22:05:05 +0000"  >&lt;p&gt;There&apos;s one major issue with my current patch and it&apos;s that there&apos;s a race between the master&apos;s OpenedRegionHandler and the events thread. It goes like this:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;RS transitions a region to OPENING&lt;/li&gt;
	&lt;li&gt;RS transitions again to OPENING&lt;/li&gt;
	&lt;li&gt;Master receives the first event, reads ZK and sees OPENING&lt;/li&gt;
	&lt;li&gt;RS transitions to OPENED&lt;/li&gt;
	&lt;li&gt;Master receives the second event, reads ZK and sees OPENED instead of OPENING, kicks of the OpenedRegionHandler&lt;/li&gt;
	&lt;li&gt;The handler will at some point delete the znode in the ZKW.getNodes structure (such a bad method name) before deleting the actual znode&lt;/li&gt;
	&lt;li&gt;Master receives the third event, reads ZK, sees OPENED but finds that getNodes doesn&apos;t contain the znode and considers this as a new region in transition so it adds it back in getNodes()&lt;/li&gt;
	&lt;li&gt;The handler deletes the znode&lt;/li&gt;
	&lt;li&gt;The Master does a no-op when it figures it cannot transition from OPEN to OPENED&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;At this point the region is assigned and everything is &quot;fine&quot;... until the master decides for any reason to unassign the region. It sends the unassignment, receives an event but doesn&apos;t process it in nodeChildrenChanged because ZKW.getNodes() already has it. From the point the master will spin in &quot;Region has been PENDING_CLOSE for too long&quot; until it&apos;s put out of its misery.&lt;/p&gt;

&lt;p&gt;The issue here is that the region server is creating the unassigned znode by itself, unlike an assignment where it&apos;s the master that does it. Doing that in the master won&apos;t fully solve the issue tho because in 0.92 the RS still create znodes for splits and there&apos;s no way that could be done by the master is it would be basically like returning back to how it used to work.&lt;/p&gt;

&lt;p&gt;So this is what Stack and I thought about:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The master needs to create the unassigned znode before telling a RS to close a region, the RS will now just update it&lt;/li&gt;
	&lt;li&gt;ZKW needs to stop keeping track of the znodes, getting into a situation where we have a mismatch is too easy&lt;/li&gt;
	&lt;li&gt;The SplitTransaction will still create the znode, but it will then wait at the very end until it gets deleted by the master. To make sure the master sees the change, it will tickle the znode like we do for OPENING so that the master doesn&apos;t miss it&lt;/li&gt;
	&lt;li&gt;The method AssignmentManager.nodeChildrenChanged will only put watchers on znodes and won&apos;t keep track of anything&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13040011" author="jdcryans" created="Fri, 27 May 2011 00:37:29 +0000"  >&lt;p&gt;New cleaned up patch that does what I listed in the previous comment, except the splitting part since this is currently a patch for 0.90&lt;/p&gt;

&lt;p&gt;My testing shows that creating the znodes when closing in the master is slower since, duh, it&apos;s not done in parallel by the region servers. The patch is still much faster than the current master and people tweaking the number of handlers higher should see good speedups. I haven&apos;t seen any bug with this patch.&lt;/p&gt;

&lt;p&gt;Up next is more testing and porting to trunk with the handling of splits.&lt;/p&gt;</comment>
                            <comment id="13040475" author="jdcryans" created="Fri, 27 May 2011 22:20:34 +0000"  >&lt;p&gt;With the previous patch all the tests passed except for hbck. Looking deeper, I see hbck creates it&apos;s own znodes so now the master doesn&apos;t see that. It&apos;s not clear to my why it&apos;s not using HBA.assign instead of the trickery with the HBCK_CODE_NAME.&lt;/p&gt;

&lt;p&gt;This patch modifies hbck so that it uses &quot;normal&quot; tools provided by the master instead of bypassing it.&lt;/p&gt;

&lt;p&gt;I&apos;m also working on porting that to trunk. I got the previous patch I posted working but didn&apos;t do the hbck stuff yet because it&apos;s different.&lt;/p&gt;

&lt;p&gt;Also I still didn&apos;t touch the splitting code in trunk.&lt;/p&gt;</comment>
                            <comment id="13040476" author="jdcryans" created="Fri, 27 May 2011 22:22:40 +0000"  >&lt;p&gt;Patch without the conf/ stuff in it (duh).&lt;/p&gt;</comment>
                            <comment id="13042973" author="jdcryans" created="Thu, 2 Jun 2011 18:42:12 +0000"  >&lt;p&gt;I&apos;m posting the equivalent to the v3 patch for trunk. I still need to handle the splitting.&lt;/p&gt;</comment>
                            <comment id="13043077" author="jdcryans" created="Thu, 2 Jun 2011 21:45:07 +0000"  >&lt;p&gt;Patch for trunk with the split fixes. I had to remove a test because it wasn&apos;t an issue anymore (the master now creates the znode when closing a region), then I had to do a bunch of fixes for AssignmentManager for cases when we report regions that are already split or skipped steps and finally I added the part of the code that waits for the master to delete the znode.&lt;/p&gt;

&lt;p&gt;One thing I might do further cleanup on is the latter part of SplitTransaction that has a few methods that all look the same. Also I&apos;m not thrilled having to do a sleep to wait on the master, but that was the easiest way.&lt;/p&gt;</comment>
                            <comment id="13048898" author="stack" created="Mon, 13 Jun 2011 23:54:08 +0000"  >&lt;p&gt;I love this patch.  +1&lt;/p&gt;</comment>
                            <comment id="13048905" author="jdcryans" created="Mon, 13 Jun 2011 23:57:35 +0000"  >&lt;p&gt;Thanks Stack for the +1.&lt;/p&gt;

&lt;p&gt;Also it&apos;s important to note that the 0.90 patch breaks rolling restarts because of the way it changes the closing sequence (which is why this is targeted for 0.92). Apply at your own risk &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13049936" author="jdcryans" created="Wed, 15 Jun 2011 18:23:54 +0000"  >&lt;p&gt;Committed to trunk, thanks for the review Stack.&lt;/p&gt;</comment>
                            <comment id="13050592" author="jdcryans" created="Thu, 16 Jun 2011 17:45:16 +0000"  >&lt;p&gt;Attaching the 0.90 patch refreshed for that branch. It&apos;s not meant for inclusion, leaving it here if it&apos;s of use to anyone. Remember it breaks rolling restarts if you plan on deploying it.&lt;/p&gt;</comment>
                            <comment id="13050991" author="hudson" created="Fri, 17 Jun 2011 11:00:07 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #1976 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/1976/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/1976/&lt;/a&gt;)&lt;/p&gt;
</comment>
                            <comment id="15017414" author="lars_francke" created="Fri, 20 Nov 2015 12:43:02 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12521500">HBASE-4335</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12481291" name="HBASE-3789-trunk.patch" size="36451" author="jdcryans" created="Thu, 2 Jun 2011 21:45:07 +0000"/>
                            <attachment id="12482830" name="HBASE-3789-v4-0.90.patch" size="27736" author="jdcryans" created="Thu, 16 Jun 2011 17:45:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 15 Apr 2011 23:21:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33209</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hnwf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101134</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>The master now creates the znode when closing a region, which is an incompatible change.&lt;br/&gt;
SplitTransaction now waits on the master to delete the znode that it created before it can finish.&lt;br/&gt;
The master doesn&amp;#39;t keep track of znodes being deleted and created anymore, it was getting out of sync too easily. </customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>