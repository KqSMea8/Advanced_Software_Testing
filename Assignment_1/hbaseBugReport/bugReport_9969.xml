<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:09:16 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9969/HBASE-9969.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9969] Improve KeyValueHeap using loser tree</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9969</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;LoserTree is the better data structure than binary heap. It saves half of the comparisons on each next(), though the time complexity is on O(logN).&lt;/p&gt;

&lt;p&gt;Currently A scan or get will go through two KeyValueHeaps, one is merging KVs read from multiple HFiles in a single store, the other is merging results from multiple stores. This patch should improve the both cases whenever CPU is the bottleneck (e.g. scan with filter over cached blocks, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9811&quot; title=&quot;ColumnPaginationFilter is slow when offset is large&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9811&quot;&gt;HBASE-9811&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;All of the optimization work is done in KeyValueHeap and does not change its public interfaces. The new code looks more cleaner and simpler to understand.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12679182">HBASE-9969</key>
            <summary>Improve KeyValueHeap using loser tree</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="stepinto">Chao Shi</assignee>
                                    <reporter username="stepinto">Chao Shi</reporter>
                        <labels>
                    </labels>
                <created>Thu, 14 Nov 2013 08:54:34 +0000</created>
                <updated>Tue, 17 Nov 2015 10:52:14 +0000</updated>
                                                            <fixVersion>2.0.0</fixVersion>
                                    <component>Performance</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>19</watches>
                                                                <comments>
                            <comment id="13822263" author="stepinto" created="Thu, 14 Nov 2013 09:12:00 +0000"  >&lt;p&gt;I ran two benchmarks:&lt;/p&gt;

&lt;p&gt;A) KeyValueHeapBenchmark class included in the patch&lt;/p&gt;

&lt;p&gt;It simply constructs a KeyValueHeap from several CollectionBackedKeyValueScanner and sees how many next/reseek calls per second.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;scanners&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; lt-next &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; lt-reseek &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; pq-next &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; pq-reseek &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17543859.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3058104&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18181818.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1798561.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;11299435&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5102040.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;11173184.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3053435.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8547008.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4854368.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7915567.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2859866.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7936507.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4866180&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5891016.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2507837&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6711409.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4739336.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4748338.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2296738.6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;&quot;lt-&quot; denotes LoserTree based KeyValueHeap.&lt;br/&gt;
&quot;pq-&quot; denotes PriorityQueue based KeyValueHeap.&lt;br/&gt;
A complete result (with up to 19 scanners) is attached.&lt;/p&gt;

&lt;p&gt;B) ColumnPaginationFilter with offset=1M&lt;br/&gt;
I ran a mini-cluster and put a huge number of columns on a single row. Thes columns are uniformly written to several HFiles. Then query using ColumnPaginationFilter with offset = 1M. Blocks are cached, so it is CPU intensive. Qualifiers and values are 4 byte integers. Row key is &quot;test_row&quot;. Blocks are not compressed.&lt;/p&gt;

&lt;p&gt;The below table shows how long the scan takes.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; hfiles &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; lt &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; pq &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 749.8 ms &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 986.69 ms &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1511.28 ms &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 2190.97 ms &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2392.8 ms &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4029.8 ms &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3318.8 ms &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5760.22 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

</comment>
                            <comment id="13822265" author="stepinto" created="Thu, 14 Nov 2013 09:13:56 +0000"  >&lt;p&gt;Submit to hadoop QA.&lt;/p&gt;</comment>
                            <comment id="13822285" author="hadoopqa" created="Thu, 14 Nov 2013 09:46:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12613807/kvheap-benchmark.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12613807/kvheap-benchmark.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7859//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7859//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13822372" author="stepinto" created="Thu, 14 Nov 2013 12:27:12 +0000"  >&lt;p&gt;Repost the patch, as hadoop QA thought the benchmark result is the patch&lt;/p&gt;</comment>
                            <comment id="13822529" author="hadoopqa" created="Thu, 14 Nov 2013 15:46:30 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12613822/hbase-9969.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12613822/hbase-9969.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 2 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7863//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13822603" author="yuzhihong@gmail.com" created="Thu, 14 Nov 2013 16:53:37 +0000"  >&lt;p&gt;Putting patch on review board would make reviewing easier.&lt;/p&gt;

&lt;p&gt;For benchmark B, can you try ColumnPaginationFilter with smaller offset ?&lt;br/&gt;
Giving percentage improvement in the tables is desirable.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+ */
+&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class LoserTree&amp;lt;T&amp;gt; {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please add annotation for audience.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * {@code tree[i]} where i &amp;gt; 0 stores the index to greater value between {@code value[tree[2*i]]}
+   * and {@code value[tree[2*i + 1]]}.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;value[&apos; should be &apos;values[&apos;, right ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the index to the minimal elements.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;elements -&amp;gt; element&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * Pushes next value from the stream that we previously taken the minimal element from.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;taken -&amp;gt; took&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * Passes {@code NULL} to value &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the stream has been reached EOF.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Remove &apos;been&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (index != topIndex()) {
+      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IllegalArgumentException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Only the top index can be updated&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Consider including index and topIndex in the exception message.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (value == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; values.get(index) != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+      numOpenStreams--;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (numOpenStreams &amp;lt; 0) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In what condition would numOpenStreams become negative ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AssertionError(&lt;span class=&quot;code-quote&quot;&gt;&quot;numOpenStreams is negative: &quot;&lt;/span&gt; + numOpenStreams);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Throw IllegalStateException.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; getOpenStreamsForTesting() {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above is used in KeyValueHeap, consider renaming.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * from bottom up to the root. Once it &lt;span class=&quot;code-quote&quot;&gt;&quot;loses&quot;&lt;/span&gt;, it stops there and the winner continues to fight to up.
+   */
+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void update(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;fight to up&apos; -&amp;gt; &apos;fight to top&apos;&lt;br/&gt;
Please add @param for i.&lt;/p&gt;

&lt;p&gt;KeyValueHeapBenchmark.java and TestLoserTree.java need license.&lt;/p&gt;</comment>
                            <comment id="13822760" author="yuzhihong@gmail.com" created="Thu, 14 Nov 2013 18:49:16 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there are more keys, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; all scanners are done
    */
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; next(List&amp;lt;Cell&amp;gt; result, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; limit) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
...
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; loserTree.isEmpty();
   }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should the return value from loserTree.isEmpty() be negated ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isLazy &amp;amp;&amp;amp; loserTree.getNumOfOpenStreams() &amp;gt; 1) {
         &lt;span class=&quot;code-comment&quot;&gt;// If there is only one scanner left, we don&apos;t &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; lazy seek.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please update comment above to match the condition.&lt;/p&gt;</comment>
                            <comment id="13822944" author="stack" created="Thu, 14 Nov 2013 21:33:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stepinto&quot; class=&quot;user-hover&quot; rel=&quot;stepinto&quot;&gt;Chao Shi&lt;/a&gt; Very nice work.  Thank you for digging in on this thorny area.  That is a nice provable improvement (numbers look great).  Thanks for putting up the graphic and the benchmarking tool.  I agree the code is now cleaner.&lt;/p&gt;
</comment>
                            <comment id="13823029" author="lhofhansl" created="Thu, 14 Nov 2013 22:24:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stepinto&quot; class=&quot;user-hover&quot; rel=&quot;stepinto&quot;&gt;Chao Shi&lt;/a&gt; Nice!&lt;br/&gt;
I&apos;ve been looking into this on and off in the past. This looks like a great improvement.&lt;/p&gt;</comment>
                            <comment id="13823128" author="lhofhansl" created="Thu, 14 Nov 2013 23:49:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stepinto&quot; class=&quot;user-hover&quot; rel=&quot;stepinto&quot;&gt;Chao Shi&lt;/a&gt;, are these numbers on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9915&quot; title=&quot;Performance: isSeeked() in EncodedScannerV2 always returns false&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9915&quot;&gt;&lt;del&gt;HBASE-9915&lt;/del&gt;&lt;/a&gt;? Or are they on top a release version of HBase?&lt;/p&gt;</comment>
                            <comment id="13823163" author="lhofhansl" created="Fri, 15 Nov 2013 00:34:19 +0000"  >&lt;p&gt;Did a quick port to 0.94, tested with Phoenix and a fully flushed and compacted table (i.e. the worst case for this patch). Still found a few percent performance improvement - no slowdown. Will test with a some more HFiles next.&lt;/p&gt;</comment>
                            <comment id="13823176" author="mcorgan" created="Fri, 15 Nov 2013 01:06:34 +0000"  >&lt;p&gt;One problem with the current java.util.PriorityQueue is that it makes the wrong assumption (for HBase) about where the next key will land in the queue.  It assumes a worst case scenario where each KV added to it is &quot;sifted up&quot; from the end of the queue.  I think in HBase it&apos;s best to assume that the next KV will jump immediately to the front of the queue since many consecutive KV&apos;s are often clumped together in a row.  With 8 storefiles, the normal case would go from ~3 comparisons down to 1.  I think the behavior could be reversed by negating the comparator.&lt;/p&gt;

&lt;p&gt;Maybe the LoserTree could also benefit by optimistically assuming each new KV will sort to the front and be the next result.&lt;/p&gt;</comment>
                            <comment id="13823210" author="vrodionov" created="Fri, 15 Nov 2013 02:04:22 +0000"  >&lt;p&gt;Matt, yes, this is exactly what needs to be done. Most of the time, KVs comes in batches from a single scanner and the optimal assumption in this case is to check next from a top scanner first and compare it against second scanner&apos;s top (I am talking about loser-winner-tree here). &lt;/p&gt;</comment>
                            <comment id="13823246" author="vrodionov" created="Fri, 15 Nov 2013 03:17:03 +0000"  >&lt;p&gt;I just ran StoreScanner with 8 store files and the same test after compaction. All data is in block cache in both runs. The results I can not explain. Scanner after compaction is slower: 3.7 sec vs 3.5 sec. The  effect of KeyValueHeap sub-par implementation is probably negligible.  &lt;/p&gt;
</comment>
                            <comment id="13823248" author="stepinto" created="Fri, 15 Nov 2013 03:34:28 +0000"  >&lt;p&gt;v2 is attached, fixed Ted mentioned problems.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/15563&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/15563&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13823256" author="stepinto" created="Fri, 15 Nov 2013 03:54:12 +0000"  >&lt;p&gt;To &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;tedyu@apache.org&quot;&gt;Ted Yu&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In what condition would numOpenStreams become negative ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There must be some bug if this happens, such as multi-threading access.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should the return value from loserTree.isEmpty() be negated ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, you are correct. It seems this return value is ignored by RegionScannerImpl, so the tests do not catch this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For benchmark B, can you try ColumnPaginationFilter with smaller offset ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This optimization is only effective when it is skipping a large number of KVs. So I think such filter is required.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Giving percentage improvement in the tables is desirable.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I will update the table once these issues you guys mentioned are fixed.&lt;/p&gt;

&lt;p&gt;To &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I just ran StoreScanner with 8 store files and the same test after compaction. All data is in block cache in both runs. The results I can not explain. Scanner after compaction is slower: 3.7 sec vs 3.5 sec. The effect of KeyValueHeap sub-par implementation is probably negligible.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess other things are the dominant overhead in your case, such as RPC? This patch optimize the case scanning with filter that rarely accepts a KV. Perhaps &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&apos;s case on phoenix is a good one.&lt;/p&gt;

&lt;p&gt;To &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Chao Shi, are these numbers on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9915&quot; title=&quot;Performance: isSeeked() in EncodedScannerV2 always returns false&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9915&quot;&gt;&lt;del&gt;HBASE-9915&lt;/del&gt;&lt;/a&gt;? Or are they on top a release version of HBase?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;These numbers are from a one-month-ago trunk. It does not have &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9915&quot; title=&quot;Performance: isSeeked() in EncodedScannerV2 always returns false&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9915&quot;&gt;&lt;del&gt;HBASE-9915&lt;/del&gt;&lt;/a&gt;. The benchmark I ran does not use encoded blocks, so &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9915&quot; title=&quot;Performance: isSeeked() in EncodedScannerV2 always returns false&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9915&quot;&gt;&lt;del&gt;HBASE-9915&lt;/del&gt;&lt;/a&gt; should have no effects on this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Did a quick port to 0.94, tested with Phoenix and a fully flushed and compacted table (i.e. the worst case for this patch). Still found a few percent performance improvement - no slowdown. Will test with a some more HFiles next.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Glad to hear that. I&apos;m looking forward to your numbers.&lt;/p&gt;

&lt;p&gt;To &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mcorgan&quot; class=&quot;user-hover&quot; rel=&quot;mcorgan&quot;&gt;Matt Corgan&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;With 8 storefiles, the normal case would go from ~3 comparisons down to 1. I think the behavior could be reversed by negating the comparator.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t quite understand this. The one I understood to improve is to compare against the previous second top value (i.e. tree[1]) before going through leaf to root comparisions. But this will add one more comparison on the worst case. &lt;/p&gt;</comment>
                            <comment id="13823272" author="vrodionov" created="Fri, 15 Nov 2013 04:39:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I just ran StoreScanner with 8 store files and the same test after compaction. All data is in block cache in both runs. The results I can not explain. Scanner after compaction is slower: 3.7 sec vs 3.5 sec. The effect of KeyValueHeap sub-par implementation is probably negligible. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, that was a wrong test. Actual results:  1.9sec before compaction and 1.5 sec after ~ 20% improvement. 2M rows (400M cache size). Full scan time. All data cached in block cache. The potential win for Loser tree is ~ 20% currently, but if &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9778&quot; title=&quot;Add hint to ExplicitColumnTracker to avoid seeking&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9778&quot;&gt;&lt;del&gt;HBASE-9778&lt;/del&gt;&lt;/a&gt; will be resolved  and  ScanQueryMatcher will be optimized ...&lt;/p&gt;</comment>
                            <comment id="13823319" author="lhofhansl" created="Fri, 15 Nov 2013 05:54:10 +0000"  >&lt;p&gt;Tested again without performing a major compaction. In my scenario I have 10m rows with 5 columns each. Ends up being only three regions and only that last one has more than one store file (4 in this case).&lt;br/&gt;
With that I still did not see any improvement.&lt;/p&gt;

&lt;p&gt;Re: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9778&quot; title=&quot;Add hint to ExplicitColumnTracker to avoid seeking&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9778&quot;&gt;&lt;del&gt;HBASE-9778&lt;/del&gt;&lt;/a&gt;, it&apos;s still not immediately clear there how to optimize the cases mentioned there (many small KVs) while keeping other optimizations (for example for large KVs, where the likelihood is high that a call to next() will land us unnecessarily in the next block).&lt;/p&gt;

&lt;p&gt;Anything that will bring HBase&apos;s CPU consumption down is a win. Unless all data is in the cache I would expect us always being IO bound, that is not always true (with SSDs for example).&lt;/p&gt;

&lt;p&gt;Edit: Whoops. Meant &quot;IO bound&quot; but wrote &quot;CPU bound&quot;. Fixed.&lt;/p&gt;</comment>
                            <comment id="13823336" author="mcorgan" created="Fri, 15 Nov 2013 06:09:51 +0000"  >&lt;p&gt;KeyValueHeapBenchmark.java&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; List&amp;lt;KeyValue&amp;gt; randomKeyValues() {
    List&amp;lt;KeyValue&amp;gt; kvs = Lists.newArrayListWithExpectedSize(NUM_KEYS_PER_SCANNER);
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; NUM_KEYS_PER_SCANNER; i++) {
      &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] row = Bytes.toBytes(random.nextLong());
      KeyValue kv = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, FAMILY, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
      kvs.add(kv);
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; kvs;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I wonder if you should make ~10 cols/row, and NUM_KEYS_PER_SCANNER/10 rows.  This should exacerbate the problem i mentioned above.  Right now it&apos;s testing the ideal scenario which almost never exists.  In fact, with time series data you have the exact opposite scenario where every Cell should go straight to the front of the queue.&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;I don&apos;t quite understand this. The one I understood to improve is to compare against the previous second top value (i.e. tree&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;) before going through leaf to root comparisions. But this will add one more comparison on the worst case.&lt;/p&gt;&lt;/blockquote&gt;Could a slightly customized version of the algorithm eliminate the extra comparison for the worst case scenario?  Even if not, I think the best case scenario happens 10x+ as often as worst case, so maybe it&apos;s a good trade-off.&lt;/p&gt;</comment>
                            <comment id="13823342" author="lhofhansl" created="Fri, 15 Nov 2013 06:33:00 +0000"  >&lt;p&gt;0.94 patch for playing.&lt;/p&gt;

&lt;p&gt;I ran my old tight loop scan test (with a real client and real server).&lt;br/&gt;
Time to scan through 20rows (1 col) went from 16.8s to 11.6s (using WildcardColumntracker - no columns specified in scan).&lt;br/&gt;
When using ExplicitColumnTracker it went from 26s to 21s.&lt;/p&gt;

&lt;p&gt;That&apos;s pretty impressive. On top of that the code is easier to understand now.&lt;/p&gt;</comment>
                            <comment id="13823363" author="hadoopqa" created="Fri, 15 Nov 2013 07:02:00 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12614002/hbase-9969-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12614002/hbase-9969-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7876//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13823473" author="hadoopqa" created="Fri, 15 Nov 2013 08:36:22 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12614022/9969-0.94.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12614022/9969-0.94.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7879//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7879//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13824125" author="lhofhansl" created="Fri, 15 Nov 2013 21:39:17 +0000"  >&lt;p&gt;As for the discussion about optimizing it... I think we need to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;make sure there is no scenario where this is significantly slower&lt;/li&gt;
	&lt;li&gt;all corner cases were explored for correctness&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This literally sits at the core of HBase, and we&apos;d better be a 100% sure it&apos;s OK.&lt;br/&gt;
That said, it looks good to me (haven&apos;t studied the details of the LoserTree class, though).&lt;/p&gt;</comment>
                            <comment id="13824130" author="mcorgan" created="Fri, 15 Nov 2013 21:40:53 +0000"  >&lt;p&gt;Another possible tweak to KeyValueHeapBenchmark.java: the row keys should have a longer common prefix.  Maybe prepend 16 identical bytes, which is a common real-world scenario and will help differentiate the implementations.&lt;/p&gt;</comment>
                            <comment id="13824319" author="lhofhansl" created="Sat, 16 Nov 2013 01:21:50 +0000"  >&lt;p&gt;I have not found a scenario, yet, where this is slower. Seems generally safe to pull into all branches.&lt;br/&gt;
And since we now &quot;own&quot; the heap implementation we can optimize this later as we see fit.&lt;/p&gt;</comment>
                            <comment id="13825382" author="stepinto" created="Mon, 18 Nov 2013 15:04:44 +0000"  >&lt;p&gt;upload v3&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add an assertion as Ted mentioned&lt;/li&gt;
	&lt;li&gt;prepend a 16 bytes prefix to row keys in the benchmark (will update the benchmark result tomorrow when I have access to my devbox)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13825391" author="stepinto" created="Mon, 18 Nov 2013 15:15:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;I wonder if you should make ~10 cols/row, and NUM_KEYS_PER_SCANNER/10 rows. This should exacerbate the problem i mentioned above. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I tried this on my laptop but seems your case above is even faster than before. Maybe there is something wrong with my environment. I will try it on my devbox tomorrow.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This literally sits at the core of HBase, and we&apos;d better be a 100% sure it&apos;s OK.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m totally agree with you! I think we can delay the optimization to future and make it correct first. As it is a so critical piece and the original implementation is so tricky (the bloomfilter part), I&apos;d like to invite all folks to review this patch, particularity who know KeyValueHeap better than me (e.g. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liyin&quot; class=&quot;user-hover&quot; rel=&quot;liyin&quot;&gt;Liyin Tang&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="13825455" author="hadoopqa" created="Mon, 18 Nov 2013 16:40:03 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12614398/hbase-9969-v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12614398/hbase-9969-v3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 10 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to cause Findbugs (version 1.3.9) to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7916//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7916//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7916//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7916//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13825471" author="jmhsieh" created="Mon, 18 Nov 2013 16:53:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;I have not found a scenario, &lt;b&gt;yet&lt;/b&gt;, where this is slower. Seems generally safe to pull into all branches.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Emphasis mine. &lt;/p&gt;

&lt;p&gt;I&apos;m a bit concerned with such a fundamental change going in without a way of &quot;going back&quot; in the case we find a slower case, especially in the stable branch.  Wouldn&apos;t it be prudent if this were to make it into 0.94 make it an option?&lt;/p&gt;
</comment>
                            <comment id="13825519" author="liyin" created="Mon, 18 Nov 2013 17:45:39 +0000"  >&lt;p&gt;That&apos;s a very promising idea ! Will take a closer look. &lt;br/&gt;
Nice work &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stepinto&quot; class=&quot;user-hover&quot; rel=&quot;stepinto&quot;&gt;Chao Shi&lt;/a&gt; !&lt;/p&gt;</comment>
                            <comment id="13825816" author="mcorgan" created="Mon, 18 Nov 2013 21:53:47 +0000"  >&lt;p&gt;Regarding adding 10 cols/row:&lt;br/&gt;
&lt;blockquote&gt;&lt;p&gt;I tried this on my laptop but seems your case above is even faster than before. Maybe there is something wrong with my environment. I will try it on my devbox tomorrow.&lt;/p&gt;&lt;/blockquote&gt;yes, you are right.  i was profiling this weekend and confirmed the current heap is handling that situation favorably.  still good to test to make sure we don&apos;t lose this aspect!&lt;/p&gt;

&lt;p&gt;I made a stripped down version of the PriorityQueue based heap to compare with the LoserTree.  It adds some counters to track the number of KV comparisons which is interesting to see.  I was seeing that PQ is faster for next(), especially with just 1 file, and LT is faster for reseek().  I&apos;ll try to post a patch tonight.&lt;/p&gt;

&lt;p&gt;I was paying particular attention to this code at KeyValueHeap:103&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      KeyValueScanner topScanner = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.heap.peek();
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (topScanner == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ||
          &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.comparator.compare(kvNext, topScanner.peek()) &amp;gt;= 0) {
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.heap.add(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.current);
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.current = pollRealKV();
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I can&apos;t figure out why we need to do a heap.add() and pollRealKV when topScanner==null.  I actually removed the topScanner==null check from the above and the single file scanner was 50% faster.  The whole test suite passed, so either it&apos;s not necessary, or we could use another unit test.  Maybe it has something to do with LazySeek?&lt;/p&gt;</comment>
                            <comment id="13825824" author="yuzhihong@gmail.com" created="Mon, 18 Nov 2013 21:59:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;I actually removed the topScanner==null check from the above and the single file scanner was 50% faster.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This optimization would benefit both PriorityQueue and LoserTree implementations, right ?&lt;/p&gt;</comment>
                            <comment id="13826052" author="lhofhansl" created="Tue, 19 Nov 2013 01:31:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;I can&apos;t figure out why we need to do a heap.add() and pollRealKV when topScanner==null.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do we still have to enforce a seek if !current.realSeekDone()?&lt;br/&gt;
Getting there we know current.peek != null, if current is not seeked we need to enforce that it seems.&lt;/p&gt;</comment>
                            <comment id="13826238" author="lhofhansl" created="Tue, 19 Nov 2013 06:22:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mcorgan&quot; class=&quot;user-hover&quot; rel=&quot;mcorgan&quot;&gt;Matt Corgan&lt;/a&gt;&lt;br/&gt;
Interestingly I also do not see any measurable performance gain from removing that check.&lt;/p&gt;

&lt;p&gt;This does not seem too surprising. If current was the last scanner on the heap, adding it back causes no extra comparison, neither does pollRealKV do any appreciable work. If there is only scanner it will be returned in the first iteration of the loop (and might do a real seek in that process, which is necessary for lazy seek).&lt;/p&gt;

&lt;p&gt;Do have data for the number of comparisons.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt; I agree. We can let this stew (if we want) in trunk for a bit and then decide about backports. I&apos;ll remove 0.94 from the fix targets.&lt;/p&gt;</comment>
                            <comment id="13826248" author="mcorgan" created="Tue, 19 Nov 2013 06:43:35 +0000"  >&lt;p&gt;attaching hbase-9969-pq-v1.patch&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;adds KeyValueScannerPriorityQueue, which is a stripped down copy of PriorityQueue that we can play with&lt;/li&gt;
	&lt;li&gt;adds KeyValueScannerHeap (almost identical to KeyValueHeap, but uses the above)&lt;/li&gt;
	&lt;li&gt;includes LoserTreeKeyValueHeap and LoserTree&lt;/li&gt;
	&lt;li&gt;each of the 3 heaps implments BenchmarkableKeyValueHeap (not complete)&lt;/li&gt;
	&lt;li&gt;enhances KeyValueHeapBenchmark to benchmark all 3 implementations&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;always tests 1mm KVs, no matter how many scanners&lt;/li&gt;
	&lt;li&gt;sorts the input KVs, though that doesn&apos;t seem to matter much&lt;/li&gt;
	&lt;li&gt;does a few warmup runs&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;One problem is that this goes from 1 to 3 implementations behind the same interface which may not get inlined as well.  Absolute performance will therefore be lower, but hopefully performance will be comparable across the 3 implementations.&lt;/p&gt;</comment>
                            <comment id="13826258" author="mcorgan" created="Tue, 19 Nov 2013 06:53:37 +0000"  >&lt;p&gt;Attaching KeyValueHeapBenchmark_v1.ods with the benchmark output for both 1 col/row and 16 cols/row.&lt;/p&gt;

&lt;p&gt;Some of it&apos;s hard to explain.  Looks like LoserTree is often faster at next() when there is more heaping to do, but not when KVs are coming from the same scanner, like when numScanners=1 or colsPerRow=16.  Maybe because it doesn&apos;t have an optimization for that case?&lt;/p&gt;

&lt;p&gt;Anyway, just putting it up there for people to poke holes in or continue to test.&lt;/p&gt;</comment>
                            <comment id="13826272" author="hadoopqa" created="Tue, 19 Nov 2013 07:13:13 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12614566/KeyValueHeapBenchmark_v1.ods&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12614566/KeyValueHeapBenchmark_v1.ods&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7926//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7926//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13826366" author="hadoopqa" created="Tue, 19 Nov 2013 10:13:25 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12614566/KeyValueHeapBenchmark_v1.ods&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12614566/KeyValueHeapBenchmark_v1.ods&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7927//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7927//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13826388" author="mcorgan" created="Tue, 19 Nov 2013 11:06:03 +0000"  >&lt;p&gt;Not sure how i didn&apos;t see it before, but here is the optimization that avoids sending the scanner through the heap when the next KV is from the same scanner:&lt;/p&gt;

&lt;p&gt;KeyValueHeap.pollRealKV() : line 350&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          &lt;span class=&quot;code-comment&quot;&gt;// Compare the current scanner to the next scanner. We &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; to avoid
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// putting the current one back into the heap &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; possible.
&lt;/span&gt;          KeyValue nextKV = nextEarliestScanner.peek();
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nextKV == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || comparator.compare(curKV, nextKV) &amp;lt; 0) {
            &lt;span class=&quot;code-comment&quot;&gt;// We already have the scanner with the earliest KV, so &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; it.
&lt;/span&gt;            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; kvScanner;
          }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Does the LoserTreeKeyValueHeap do a check like that?&lt;/p&gt;</comment>
                            <comment id="13826922" author="yuzhihong@gmail.com" created="Tue, 19 Nov 2013 20:51:23 +0000"  >&lt;p&gt;Uh ... KeyValueScannerPriorityQueue.java mentions Oracle&lt;/p&gt;</comment>
                            <comment id="13826982" author="yuzhihong@gmail.com" created="Tue, 19 Nov 2013 21:53:42 +0000"  >&lt;p&gt;I couldn&apos;t compile Matt&apos;s patch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-compile) on project hbase-server: Compilation failure: Compilation failure:
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[46,49] cannot find symbol
[ERROR] symbol: class BenchmarkableKeyValueHeap
[ERROR] &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; KeyValueScanner, InternalScanner, BenchmarkableKeyValueHeap {
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScannerHeap.java:[45,49] cannot find symbol
[ERROR] symbol: class BenchmarkableKeyValueHeap
[ERROR] &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; KeyValueScanner, InternalScanner, BenchmarkableKeyValueHeap{
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LoserTreeKeyValueHeap.java:[48,49] cannot find symbol
[ERROR] symbol: class BenchmarkableKeyValueHeap
[ERROR] &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; KeyValueScanner, InternalScanner, BenchmarkableKeyValueHeap {
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[394,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[399,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[404,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[409,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[414,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScannerHeap.java:[399,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScannerHeap.java:[404,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScannerHeap.java:[409,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScannerHeap.java:[414,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScannerHeap.java:[419,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LoserTreeKeyValueHeap.java:[354,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LoserTreeKeyValueHeap.java:[359,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LoserTreeKeyValueHeap.java:[364,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LoserTreeKeyValueHeap.java:[369,2] method does not override or implement a method from a supertype
[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LoserTreeKeyValueHeap.java:[374,2] method does not override or implement a method from a supertype
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13827005" author="mcorgan" created="Tue, 19 Nov 2013 22:16:29 +0000"  >&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;Uh ... KeyValueScannerPriorityQueue.java mentions Oracle&lt;/p&gt;&lt;/blockquote&gt;it&apos;s java.util.PriorityQueue with stuff deleted&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[ERROR] /Users/tyu/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java:[46,49] cannot find symbol
[ERROR] symbol: class BenchmarkableKeyValueHeap&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;sorry, must not have staged BenchmarkableKeyValueHeap before git diff or something.  will post another patch tonight.&lt;/p&gt;</comment>
                            <comment id="13827054" author="yuzhihong@gmail.com" created="Tue, 19 Nov 2013 22:52:38 +0000"  >&lt;p&gt;Some classes, e.g. BenchmarkableKeyValueHeap.java, miss license header.&lt;/p&gt;

&lt;p&gt;Currently KeyValueHeap is used by StoreScanner and RegionScannerImpl.&lt;br/&gt;
I wonder if a config parameter, e.g. hbase.scanner.heap.impl.class, can be introduced so that different implementations of BenchmarkableKeyValueHeap can be plugged in.&lt;/p&gt;</comment>
                            <comment id="13827066" author="mcorgan" created="Tue, 19 Nov 2013 23:06:06 +0000"  >&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;Some classes, e.g. BenchmarkableKeyValueHeap.java, miss license header.&lt;/p&gt;&lt;/blockquote&gt;this patch is only for benchmarking&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;Currently KeyValueHeap is used by StoreScanner and RegionScannerImpl.&lt;br/&gt;
I wonder if a config parameter, e.g. hbase.scanner.heap.impl.class, can be introduced so that different implementations of BenchmarkableKeyValueHeap can be plugged in.&lt;/p&gt;&lt;/blockquote&gt;Multiple heaps could be interesting but may not be necessary if LoserTree can be optimized for consecutive KVs from the same scanner.  It seems to handle consecutive KVs better than non-consecutive, but still not as well as trunk.&lt;/p&gt;</comment>
                            <comment id="13827376" author="mcorgan" created="Wed, 20 Nov 2013 06:01:46 +0000"  >&lt;p&gt;attaching hbase-9969-pq-v2.patch and KeyValueHeapBenchmark_v2.ods&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;this patch will hopefully apply (previous one accidentally had BenchmarkableKeyValueHeap.java in the src/test directory)&lt;/li&gt;
	&lt;li&gt;KeyValueScannerPriorityQueue is no longer based on PriorityQueue.  it&apos;s now a custom implementation with class comments explaining&lt;/li&gt;
	&lt;li&gt;KeyValueScannerHeap (based on KeyValueScannerPriorityQueue) looks to beat the existing KeyValueHeap in all cases (tested up to 32 scanners)&lt;/li&gt;
	&lt;li&gt;LoserTree is usually faster with more scanners, but still slower when many consecutive KVs come from the same scanner&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13827409" author="hadoopqa" created="Wed, 20 Nov 2013 07:34:08 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12614796/hbase-9969-pq-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12614796/hbase-9969-pq-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 4 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 2 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestAdmin&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7943//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13828030" author="yuzhihong@gmail.com" created="Wed, 20 Nov 2013 19:42:16 +0000"  >&lt;p&gt;@Matt:&lt;br/&gt;
Putting patch on review board would be nice.&lt;/p&gt;

&lt;p&gt;Some classes miss license.&lt;/p&gt;

&lt;p&gt;For KeyValueScannerHeap, there is some duplicate code with KeyValueHeap. Looks like some refactoring would help ease maintenance of these two classes.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; KeyValueScannerPriorityQueue getHeap() {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.heap;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can the return type be widened to PriorityQueue&amp;lt;KeyValueScanner&amp;gt; ?&lt;/p&gt;

&lt;p&gt;For KeyValueScannerPriorityQueue:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+ * * numScanners is always &amp;lt;= the capacity provided at construction time&amp;lt;br/&amp;gt;
+ * * the number of scanners is usually &amp;lt; 10, almost always &amp;lt; 100&amp;lt;br/&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Did the above assumption come from experience with your clusters ?&lt;/p&gt;

&lt;p&gt;For KeyValueHeap.java, I don&apos;t see where numNextComparisons is updated.&lt;/p&gt;</comment>
                            <comment id="13828100" author="mcorgan" created="Wed, 20 Nov 2013 20:54:24 +0000"  >&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;@Matt:&lt;br/&gt;
Putting patch on review board would be nice.&lt;/p&gt;&lt;/blockquote&gt;It&apos;s still just for benchmarking.  We wouldn&apos;t want to commit this as is.  We&apos;d probably only commit one implementation, or maybe a hybrid if we can&apos;t get a single clear winner.&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;numScanners is always &amp;lt;= the capacity provided at construction time&lt;/p&gt;&lt;/blockquote&gt;i &lt;b&gt;think&lt;/b&gt; this is always true in hbase?  Am missing somewhere that we add new scanners that were not present at heap construction?&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;the number of scanners is usually &amp;lt; 10, almost always &amp;lt; 100&lt;/p&gt;&lt;/blockquote&gt;yes, it&apos;s almost always true in my cluster, but doesn&apos;t hbase try to enforce this in general by issuing compactions?  And then it enforces it during the compactions with hbase.hstore.compaction.max defaulting to 10.&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;For KeyValueHeap.java, I don&apos;t see where numNextComparisons is updated.&lt;/p&gt;&lt;/blockquote&gt;yes, sorry, some of the counts are still missing or are not named well&lt;/p&gt;</comment>
                            <comment id="13828111" author="yuzhihong@gmail.com" created="Wed, 20 Nov 2013 21:03:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;enforces it during the compactions with hbase.hstore.compaction.max defaulting to 10.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;From hbase-default.xml :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &amp;lt;description&amp;gt;Max number of HStoreFiles to compact per &apos;minor&apos; compaction.&amp;lt;/description&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;&lt;p&gt;We&apos;d probably only commit one implementation, or maybe a hybrid if we can&apos;t get a single clear winner.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I agree.&lt;br/&gt;
From your experiments, looks like there is one winner &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13828176" author="mcorgan" created="Wed, 20 Nov 2013 21:50:54 +0000"  >&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;From your experiments, looks like there is one winner&lt;/p&gt;&lt;/blockquote&gt;I don&apos;t know... I think LoserTree does fewer comparisons when there are more scanners and is therefore better.  However, it looks like KeyValueScannerHeap is faster with consecutive KVs from the same scanner (a single scanner or many cols/row).  I&apos;m hoping this benchmark can help us mix and match the best aspects of the two.&lt;/p&gt;

&lt;p&gt;I may even take a stab at replacing the binary search behavior in KeyValueScannerHeap with a hard-coded comparison order when numScanners is between 2 and ~4.&lt;/p&gt;</comment>
                            <comment id="13828502" author="stepinto" created="Thu, 21 Nov 2013 05:13:40 +0000"  >&lt;p&gt;I found it is hard to optimize the consecutive for loser tree. Doing a quick comparison against the second minimal element is not possible, as the second minimal element in the loser tree is not always &quot;tree[1]&quot; (consider the case that the two top players meet in the quarterfinal in a tournament game). &lt;/p&gt;

&lt;p&gt;I also noticed that loser tree has generally better performance on &quot;reseek&quot;, which is the use case my benchmark B in the first post (you know, SEEK_NEXT_ROW will result in reseeks). &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mcorgan&quot; class=&quot;user-hover&quot; rel=&quot;mcorgan&quot;&gt;Matt Corgan&lt;/a&gt;, do you have any ideas regarding to mix the good of both? I have no idea, as the two are so different.&lt;/p&gt;

&lt;p&gt;Another optimization: as KVs are usually sharing common prefixes, we can skip such common part during comparisons. I haven&apos;t thought on this carefully. Just mention it here in case someone may have better thoughts based on it.&lt;/p&gt;</comment>
                            <comment id="13828507" author="stepinto" created="Thu, 21 Nov 2013 05:33:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;Doing a quick comparison against the second minimal element is not possible, as the second minimal element in the loser tree is not always &quot;tree[1]&quot; (consider the case that the two top players meet in the quarterfinal in a tournament game).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;To elaborate the problem more clearly, let&apos;s consider updateTop() method of LoserTree, which takes logN comparisons to decide the new minimal after the original one has gone. If we want to get the second minimal as well, we have to compare among the losers to the newly updated winner, which takes another logN comparisons (there are logN losers in the path from a leave up to the root). Thus it will cost 2logN in total. This is equivalent to a binary heap.&lt;/p&gt;

&lt;p&gt;The benefit of keeping the second minimal, is where there are consecutive KVs from one HFile, we can compare the it against the second minimal first. If it is still less than the second minimal, then it is therefore the winner. This optimization naturally fit in the binary heap.&lt;/p&gt;

&lt;p&gt;I wonder if we can find some data structure in the middle, or perhaps don&apos;t always keep the second minimal and determine it when every n calls of next.&lt;/p&gt;</comment>
                            <comment id="13828529" author="vrodionov" created="Thu, 21 Nov 2013 06:25:10 +0000"  >&lt;p&gt;Loser tree will always need at least 2 comparison for consecutive optimization. One need to compare new element with winner of a first half tree and with 2nd runner of a second half tree (the previous top element was a winner in this half - tree). &lt;/p&gt;</comment>
                            <comment id="13829666" author="mcorgan" created="Fri, 22 Nov 2013 05:35:40 +0000"  >&lt;p&gt;It looks like the LoserTree always maintains the top element at the top after a call to updateTopValue(current), and you can easily peek() the top element (using topValue()).  Could the LoserTreeKeyValueHeap simply compare the current scanner to topValue(), and only updateTopValue(current) if it&apos;s greater than topValue()?  I think that&apos;s what current KeyValueHeap does.&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;Another optimization: as KVs are usually sharing common prefixes, we can skip such common part during comparisons. I haven&apos;t thought on this carefully. Just mention it here in case someone may have better thoughts based on it.&lt;/p&gt;&lt;/blockquote&gt;yeah, I think there&apos;s potential here.  You could maintain a heap for each level: row, family, qualifier, timestamp.  This would probably require adding methods to the KeyValueScanner: nextRow(), nextQualifier(), etc.  PrefixTree, in particular, would benefit from this because it can execute the nextRow() method with a trivial amount of work while the other encodings have to scan through every row key in the block and do a comparison on it.  If someone tried it, you could start with only the nextRow() optimization which would have the biggest payoff.&lt;/p&gt;</comment>
                            <comment id="13829669" author="mcorgan" created="Fri, 22 Nov 2013 05:37:30 +0000"  >&lt;p&gt;Actually, the delta encoders could execute a nextRow() method pretty well too because the comparison just needs to check if 0 row bytes changed since the previous key.&lt;/p&gt;</comment>
                            <comment id="13831610" author="stepinto" created="Mon, 25 Nov 2013 16:35:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;It looks like the LoserTree always maintains the top element at the top after a call to updateTopValue(current), and you can easily peek() the top element (using topValue()). Could the LoserTreeKeyValueHeap simply compare the current scanner to topValue(), and only updateTopValue(current) if it&apos;s greater than topValue()? I think that&apos;s what current KeyValueHeap does.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think we can do this with LoserTree, because it can only used to determine minimal among a &lt;b&gt;fixed&lt;/b&gt; number of streams at construction time. topValue(). It does not support &quot;extractMin&quot; operation as defined by a heap. So the winner must remain in the tree.&lt;/p&gt;

&lt;p&gt;I tried to optimize LoserTreeKeyValueHeap and got ~10% improvement, but it is still worse than the priority queue based implementations. The LoserTree knows whether the added value is on the same row with others. I&apos;m trying to think about other optimization techniques.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Loser tree will always need at least 2 comparison for consecutive optimization. One need to compare new element with winner of a first half tree and with 2nd runner of a second half tree (the previous top element was a winner in this half - tree).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Is it true? The global 2nd runner of the tree may sit very near the leave. To find it out, we need logN comparisons.&lt;/p&gt;</comment>
                            <comment id="13836204" author="apurtell" created="Mon, 2 Dec 2013 03:13:01 +0000"  >&lt;p&gt;This should either be committed or unscheduled.&lt;/p&gt;</comment>
                            <comment id="13836285" author="lhofhansl" created="Mon, 2 Dec 2013 06:36:30 +0000"  >&lt;p&gt;This is not ready to be committed.&lt;br/&gt;
In 0.94 I move issues like these to the next point release if I think they are generally useful for 0.94 but not quite ready yet, otherwise I unschedule them. Unscheduled issues tend to be forgotten.&lt;/p&gt;</comment>
                            <comment id="13836320" author="apurtell" created="Mon, 2 Dec 2013 07:24:38 +0000"  >&lt;p&gt;Ok. Moved out of 0.98.0.&lt;/p&gt;</comment>
                            <comment id="13889818" author="apurtell" created="Mon, 3 Feb 2014 19:45:12 +0000"  >&lt;p&gt;Cancelling stale patch&lt;/p&gt;</comment>
                            <comment id="13942476" author="lhofhansl" created="Thu, 20 Mar 2014 23:03:48 +0000"  >&lt;p&gt;I take back what I said about this above:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      KeyValueScanner topScanner = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.heap.peek();
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (topScanner == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ||
          &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.comparator.compare(kvNext, topScanner.peek()) &amp;gt;= 0) {
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.heap.add(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.current);
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.current = pollRealKV();
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Looking again, we already have the invariant that the &amp;lt;current&amp;gt; scanner always had a real seek done it already. So if current is the last/only scanner we can avoid those checks. Did some more tests (20m rows, 5 cols each, everything in the cache, fully compacted - i.e. one HFile per store). With the check a scan that filters everything at the server through all 100m KVs takes 15.1s without it takes 13.3s, so a 12% improvement.&lt;br/&gt;
Definitely a change we should make after all, I&apos;ll roll this into my experiments on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10625&quot; title=&quot;Remove unnecessary key compare from AbstractScannerV2.reseekTo&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10625&quot;&gt;&lt;del&gt;HBASE-10625&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13942784" author="lhofhansl" created="Fri, 21 Mar 2014 04:50:32 +0000"  >&lt;p&gt;Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10805&quot; title=&quot;Speed up KeyValueHeap.next() a bit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10805&quot;&gt;&lt;del&gt;HBASE-10805&lt;/del&gt;&lt;/a&gt; instead.&lt;/p&gt;</comment>
                            <comment id="13943896" author="lhofhansl" created="Sat, 22 Mar 2014 04:17:52 +0000"  >&lt;p&gt;A colleague of mine (Jamie Martin to give credit) implemented something similar for different project.&lt;/p&gt;

&lt;p&gt;I think some of the performance issues we&apos;re seeing is that the scanners and the heap are not really integrated. In order to pop something of the topScanner we need to take the scanner out of the heap, pop the next KV, seek the scanner, and put it back on the heap, which now has to rejigger everything.&lt;/p&gt;

&lt;p&gt;His solution is a simple sorted array of scanners the scanner with the next key is first. When we pop something of that first scanner we simply compare the next key with the top key of the 2nd scanner, when larger (i.e. it&apos;s the next) we&apos;re done, just one comparison, no movement in the array needed. If not the scanner is insert-sorted into the right spot.&lt;/p&gt;

&lt;p&gt;The assumption is that that most keys come from the same scanner and in that case should safe a lot of overhead. It&apos;s somewhat similar to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mcorgan&quot; class=&quot;user-hover&quot; rel=&quot;mcorgan&quot;&gt;Matt Corgan&lt;/a&gt; attempt to insert the scanner back at the beginning, but integrates the scanner with the &quot;heap&quot; and should safe overhead. It&apos;s also simple and should be easy to follow.&lt;/p&gt;

&lt;p&gt;If I get time I&apos;m going to implement this as an alternative into Matt&apos;s testing framework here and see how it fares.&lt;/p&gt;</comment>
                            <comment id="13946197" author="lhofhansl" created="Tue, 25 Mar 2014 05:36:50 +0000"  >&lt;p&gt;Then again, the snippet above does that already. Specifically:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.comparator.compare(kvNext, topScanner.peek()) &amp;gt;= 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is true only when we have exhausted the current scanner. Not sure why I missed it, especially since it was subject to discussion above.&lt;br/&gt;
So upon next we only do a single comparison if the next KV comes from the same scanner (and with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10805&quot; title=&quot;Speed up KeyValueHeap.next() a bit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10805&quot;&gt;&lt;del&gt;HBASE-10805&lt;/del&gt;&lt;/a&gt; we&apos;re doing no comparison if only a single scanner is left), only when that is not the case do we put the scanner back into the heap.&lt;/p&gt;

&lt;p&gt;At least this warrants a comment in the code I think.&lt;/p&gt;

&lt;p&gt;I still want to implement this. It&apos;s possible that we will see no benefit from it, though.&lt;/p&gt;</comment>
                            <comment id="15008473" author="ram_krish" created="Tue, 17 Nov 2015 10:52:14 +0000"  >&lt;p&gt;Pls see this comment &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14221?focusedCommentId=15008465&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15008465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-14221?focusedCommentId=15008465&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15008465&lt;/a&gt; over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14221&quot; title=&quot;Reduce the number of time row comparison is done in a Scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14221&quot;&gt;&lt;del&gt;HBASE-14221&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12614022" name="9969-0.94.txt" size="27755" author="lhofhansl" created="Fri, 15 Nov 2013 06:33:00 +0000"/>
                            <attachment id="12614566" name="KeyValueHeapBenchmark_v1.ods" size="7273" author="mcorgan" created="Tue, 19 Nov 2013 06:53:37 +0000"/>
                            <attachment id="12614795" name="KeyValueHeapBenchmark_v2.ods" size="7263" author="mcorgan" created="Wed, 20 Nov 2013 06:01:46 +0000"/>
                            <attachment id="12614563" name="hbase-9969-pq-v1.patch" size="55054" author="mcorgan" created="Tue, 19 Nov 2013 06:43:35 +0000"/>
                            <attachment id="12614796" name="hbase-9969-pq-v2.patch" size="54673" author="mcorgan" created="Wed, 20 Nov 2013 06:01:46 +0000"/>
                            <attachment id="12614002" name="hbase-9969-v2.patch" size="28168" author="stepinto" created="Fri, 15 Nov 2013 03:34:28 +0000"/>
                            <attachment id="12614398" name="hbase-9969-v3.patch" size="28574" author="stepinto" created="Mon, 18 Nov 2013 15:04:44 +0000"/>
                            <attachment id="12613822" name="hbase-9969.patch" size="25599" author="stepinto" created="Thu, 14 Nov 2013 12:27:12 +0000"/>
                            <attachment id="12613805" name="hbase-9969.patch" size="25599" author="stepinto" created="Thu, 14 Nov 2013 09:12:00 +0000"/>
                            <attachment id="12613806" name="kvheap-benchmark.png" size="16246" author="stepinto" created="Thu, 14 Nov 2013 09:12:00 +0000"/>
                            <attachment id="12613807" name="kvheap-benchmark.txt" size="836" author="stepinto" created="Thu, 14 Nov 2013 09:12:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 14 Nov 2013 09:46:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>358547</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1pt4f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>358837</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>