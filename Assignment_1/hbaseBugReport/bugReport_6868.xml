<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:40:34 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6868/HBASE-6868.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6868] Skip checksum is broke; are we double-checksumming by default?</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6868</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The HFile contains checksums for decrease the iops, so when Hbase read HFile , that dont&apos;t need to read the checksum from meta file of HDFS.  But HLog file of Hbase don&apos;t contain the checksum, so when HBase read the HLog, that must read checksum from meta file of HDFS.  We could  add setSkipChecksum per file to hdfs or we could write checksums into WAL if this skip checksum facility is enabled &lt;/p&gt;</description>
                <environment></environment>
        <key id="12608728">HBASE-6868</key>
            <summary>Skip checksum is broke; are we double-checksumming by default?</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="liulei.cn">LiuLei</reporter>
                        <labels>
                    </labels>
                <created>Sat, 22 Sep 2012 03:20:42 +0000</created>
                <updated>Sun, 7 Apr 2013 05:03:39 +0000</updated>
                            <resolved>Tue, 25 Sep 2012 17:39:00 +0000</resolved>
                                    <version>0.94.0</version>
                    <version>0.94.1</version>
                                    <fixVersion>0.94.2</fixVersion>
                                    <component>HFile</component>
                    <component>wal</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                <comments>
                            <comment id="13461017" author="stack" created="Sat, 22 Sep 2012 04:07:37 +0000"  >&lt;p&gt;Making critical.  Maybe HLog could use a version of fs that used hdfs checksums always.&lt;/p&gt;</comment>
                            <comment id="13461019" author="lhofhansl" created="Sat, 22 Sep 2012 04:19:25 +0000"  >&lt;p&gt;Assuming that this affects 0.96 as well.&lt;/p&gt;</comment>
                            <comment id="13461021" author="lhofhansl" created="Sat, 22 Sep 2012 04:20:47 +0000"  >&lt;p&gt;I&apos;m starting to think that this entire &quot;avoid the checksum&quot; issue was a but premature.&lt;br/&gt;
I forget, is this by default enabled or disabled?&lt;/p&gt;</comment>
                            <comment id="13461023" author="lhofhansl" created="Sat, 22 Sep 2012 04:23:06 +0000"  >&lt;p&gt;Sigh... It&apos;s enabled by default.&lt;/p&gt;</comment>
                            <comment id="13461035" author="stack" created="Sat, 22 Sep 2012 06:15:07 +0000"  >&lt;p&gt;As LiuLei suggests, it looks like defaults have us double-checksumming reading hfile blocks.  If we set local read, then we avoid hdfs checksums and only do the checksum in hbase (if blocks are local) &amp;#8211; but then we do no checksum checking of the WAL (if blocks are local).  Yeah, sounds like we should turn it off.  We need to solve checksums for WAL when flag is enabled (it may be ok, this issue is about eliciting yes or no) and we can&apos;t enable the flag really until &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3429&quot; title=&quot;DataNode reads checksums even if client does not need them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3429&quot;&gt;&lt;del&gt;HDFS-3429&lt;/del&gt;&lt;/a&gt; is in place (Mighty Todd has a patch up on it).&lt;/p&gt;</comment>
                            <comment id="13461037" author="stack" created="Sat, 22 Sep 2012 06:17:09 +0000"  >&lt;p&gt;Changed topic.  Made this issue a blocker.&lt;/p&gt;</comment>
                            <comment id="13461209" author="lhofhansl" created="Sat, 22 Sep 2012 16:37:18 +0000"  >&lt;p&gt;So the first task should be checking that turning it off actually undoes all of its effects.&lt;br/&gt;
Seems like I think should 0.94.2 for this.&lt;/p&gt;</comment>
                            <comment id="13461213" author="lhofhansl" created="Sat, 22 Sep 2012 16:56:59 +0000"  >&lt;p&gt;Taking a quick glance at the code, this is not actually just a simple switch. There&apos;s code at various places where we unconditionally create unchecksummed filesystems.&lt;/p&gt;

&lt;p&gt;I wonder whether it is possible to revert the entire change and start again.&lt;/p&gt;</comment>
                            <comment id="13461286" author="lhofhansl" created="Sat, 22 Sep 2012 22:42:04 +0000"  >&lt;p&gt;So I am looking through the patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;@LiuLei: Did you positively verify that we&apos;re not reading the checksums for the HLogs?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; introduces HFileSystem, which has a getNoChecksumFs() method, as well as a getBackingFs() method. The backingFs is not checksummed. Looks like for the HLog the backingFs is used, which does not have checksums disabled.&lt;/p&gt;</comment>
                            <comment id="13461290" author="aoxiang" created="Sat, 22 Sep 2012 23:29:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;br/&gt;
I check the current implementations, hbase.regionserver.checksum.verify is enabled by default, so when reading HFile, it uses the noChecksumFs in HFileSystem, when reading HLog , it uses the fs in HFileSystem, they use different FS.&lt;br/&gt;
fs in HFileSystem  // filesystem object that has checksum verification turned on.&lt;br/&gt;
noChecksumFs in HFileSystem // filesystem object that has checksum verification turned off.&lt;/p&gt;

&lt;p&gt;(1) dfs.client.read.shortcircuit = false&#65292; short circuit read turned off. DataNode read file data and send it to DFSClient(HRegionServer is a DFSClient)&lt;br/&gt;
HFile : DataNode will read block file and meta file. DFSClient will not checksum the data, HRegionServer(HFile) will checksum the HFile data.&lt;br/&gt;
HLog : DataNode will read block file and meta file. DFSClient will checksum the data, HRegionServer will not checksum   HLog data.&lt;/p&gt;

&lt;p&gt;(2)dfs.client.read.shortcircuit = true, dfs.client.read.shortcircuit.skip.checksum=false, short circuit read turned on. If the block is local, DFSClient will read file data direct (HRegionServer is a DFSClient).&lt;br/&gt;
HFile : DFSClient will read block file and meta file. DFSClient will not checksum the data, HRegionServer(HFile) will checksum the HFile data.&lt;br/&gt;
HLog : DFSClient will read block file and meta file. DFSClient will checksum the data, HRegionServer will not checksum   HLog data.&lt;/p&gt;

&lt;p&gt;(3)dfs.client.read.shortcircuit = true, dfs.client.read.shortcircuit.skip.checksum=true, short circuit read turned on.&lt;br/&gt;
If the block is local, DFSClient will read file data direct (HRegionServer is a DFSClient).&lt;br/&gt;
HFile : DFSClient will read block file only. DFSClient will not checksum the data, HRegionServer(HFile) will checksum the HFile data.&lt;br/&gt;
HLog : DFSClient will read block file and meta file. DFSClient will checksum the data, HRegionServer will not checksum   HLog data.&lt;/p&gt;

&lt;p&gt;If i am wrong, please corrent me.&lt;/p&gt;</comment>
                            <comment id="13461293" author="gqchen" created="Sat, 22 Sep 2012 23:40:46 +0000"  >&lt;p&gt;On 89-fb, we are depending on inline HDFS checksum to solve the checksum iop overhead. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2699&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-2699&lt;/a&gt;. Our HDFS progress can be seen here: &lt;a href=&quot;https://github.com/facebook/hadoop-20/tree/develop&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/facebook/hadoop-20/tree/develop&lt;/a&gt;. It is code complete (not committed to github yet) and is under production testing. &lt;/p&gt;</comment>
                            <comment id="13461299" author="lhofhansl" created="Sun, 23 Sep 2012 00:17:20 +0000"  >&lt;p&gt;@Jerry: That seems like a better approach. It always bothers me when we&apos;re trying to solve HDFS problems in HBase. On the other hand that change will never (at or at least much later) be in an official HDFS.&lt;/p&gt;

&lt;p&gt;@binlijin:&lt;br/&gt;
Are you sure about case (2)? You&apos;re saying that even if dfs.client.read.shortcircuit.skip.checksum=false the DFSClient will still skip the checksumming?&lt;/p&gt;

&lt;p&gt;Are there more cases:&lt;br/&gt;
(3a) the block is not local.&lt;br/&gt;
Both DFSClient and HRegionserver will calculate the checksum&lt;br/&gt;
(4) dfs.client.read.shortcircuit = false, dfs.client.read.shortcircuit.skip.checksum=true&lt;br/&gt;
Both DFSClient and HRegionserver will calculate the checksum&lt;/p&gt;

&lt;p&gt;?&lt;/p&gt;

&lt;p&gt;I it seems we&apos;re mostly good here. The double checksumming for non local blocks is not ideal of course (but that&apos;s &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3429&quot; title=&quot;DataNode reads checksums even if client does not need them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3429&quot;&gt;&lt;del&gt;HDFS-3429&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="13461312" author="aoxiang" created="Sun, 23 Sep 2012 03:26:29 +0000"  >&lt;p&gt;@Lars Hofhansl  &lt;br/&gt;
Sorry about that, &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (2) dfs.client.read.shortcircuit = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, dfs.client.read.shortcircuit.skip.checksum=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt; circuit read turned on.
 If the block is local, DFSClient will read file data direct (HRegionServer is a DFSClient).
 HFile : DFSClient will read block file and meta file. DFSClient will checksum the data, HRegionServer(HFile) will checksum the HFile data.  This is the &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;-checksumming. 
 HLog : DFSClient will read block file and meta file. DFSClient will checksum the data, HRegionServer will not checksum HLog data.

(2a) the block is not local.
HFile : DataNode will read block file and meta file. DFSClient will not checksum the data, HRegionServer(HFile) will checksum the HFile data.
HLog : DataNode will read block file and meta file. DFSClient will checksum the data, HRegionServer will not checksum HLog data.

(3a) the block is not local.
HFile : DataNode will read block file and meta file. DFSClient will not checksum the data, HRegionServer(HFile) will checksum the HFile data.
HLog : DataNode will read block file and meta file. DFSClient will checksum the data, HRegionServer will not checksum HLog data.

(4) dfs.client.read.shortcircuit = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, dfs.client.read.shortcircuit.skip.checksum=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
 The same as &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;(1)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13461319" author="lhofhansl" created="Sun, 23 Sep 2012 04:52:53 +0000"  >&lt;p&gt;OK. If that is all true, then we only benefit if:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;dfs.client.read.shortcircuit = true&lt;/li&gt;
	&lt;li&gt;dfs.client.read.shortcircuit.skip.checksum=true&lt;/li&gt;
	&lt;li&gt;the block is local&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In all cases we do not improve the number of IOs.&lt;br/&gt;
Can we just recommend then to enable the two setting above?&lt;br/&gt;
Problem is that then we&apos;ll lose checksumming for all locally read blocks...?&lt;/p&gt;</comment>
                            <comment id="13461321" author="liulei.cn" created="Sun, 23 Sep 2012 05:08:59 +0000"  >&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;1. Local Read&lt;br/&gt;
When we set dfs.client.read.shortcircuit=true and dfs.client.read.shortcircuit.skip.checksum=false, and verifyChecksum parameter is ture in BlockReaderLocal constructor,   the DFSClient read meta file and verify checksum.&lt;/p&gt;

&lt;p&gt;When we set dfs.client.read.shortcircuit=true and dfs.client.read.shortcircuit.skip.checksum=true, the DFSClient don&apos;t read meta file and don&apos;t verify checksum.&lt;/p&gt;

&lt;p&gt;2. Remote Read&lt;br/&gt;
When we call DistributedFileSystem.setVerifyChecksum(false),  the DFSClient don&apos;t  verify checksum.&lt;br/&gt;
When we call DistributedFileSystem.setVerifyChecksum(true),  the DFSClient  verify checksum.&lt;/p&gt;

&lt;p&gt;the verifyChecksum property default value is true.&lt;/p&gt;



&lt;p&gt;I think  there is another problem in local read,   BlockReaderLocal class use  &quot;static Map&amp;lt;Integer, LocalDatanodeInfo&amp;gt; localDatanodeInfoMap&quot; property to store local block file path and local meta file path. When I stop HDFS cluster or I kill the local DataNode and delete file use &quot;./hadoop dfs -rm path&quot; command ,  the RegionServer still can read the data form local file. I think that may lead to RegionServer read wrong data.&lt;/p&gt;</comment>
                            <comment id="13461485" author="lhofhansl" created="Sun, 23 Sep 2012 18:36:57 +0000"  >&lt;p&gt;OK. So can we just document then that dfs.client.read.shortcircuit.skip.checksum should not be enabled globally, and then we only enable it for the nonCheckSumFs?&lt;/p&gt;

&lt;p&gt;If that does not work I let&apos;s revert &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; (at least from 0.94). It&apos;s not worth it.&lt;br/&gt;
(Although that will be a big task now, since so much has changed since it got committed.)&lt;/p&gt;

&lt;p&gt;The 2nd part you mention sounds like another bug in HDFS with local reads.&lt;/p&gt;</comment>
                            <comment id="13461494" author="lhofhansl" created="Sun, 23 Sep 2012 19:16:05 +0000"  >&lt;p&gt;We keep going back and forth between different issues. There at least three issues now discussed here:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;HLogs are not checksummed when dfs.client.read.shortcircuit.skip.checksum and dfs.client.read.shortcircuit are both true&lt;/li&gt;
	&lt;li&gt;double checksumming when dfs.client.read.shortcircuit = true and dfs.client.read.shortcircuit.skip.checksum=false&lt;/li&gt;
	&lt;li&gt;local files lingering with DN is down and file was deleted via DFS.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The first two are related.&lt;/p&gt;</comment>
                            <comment id="13461495" author="lhofhansl" created="Sun, 23 Sep 2012 19:21:13 +0000"  >&lt;p&gt;So how about this?&lt;br/&gt;
Check that short circuit is enabled for HBase checksumming. Also disables short circuit checksum for the noChecksumFs.&lt;/p&gt;</comment>
                            <comment id="13461496" author="lhofhansl" created="Sun, 23 Sep 2012 19:24:02 +0000"  >&lt;p&gt;The right patch, this time.&lt;/p&gt;</comment>
                            <comment id="13461941" author="lhofhansl" created="Mon, 24 Sep 2012 17:50:31 +0000"  >&lt;p&gt;Comments? Concerns?&lt;br/&gt;
This should fix the first two issues I listed above.&lt;/p&gt;</comment>
                            <comment id="13462135" author="lhofhansl" created="Mon, 24 Sep 2012 21:06:45 +0000"  >&lt;p&gt;I would like to commit this (and then respin a 0.94.2RC). Does anybody have an issue with the patch I posted?&lt;/p&gt;</comment>
                            <comment id="13462194" author="lhofhansl" created="Mon, 24 Sep 2012 22:16:59 +0000"  >&lt;p&gt;Hmm... Just checked Hadoop 0.20.x, 0.21.x, 0.22.x, and 0.23.x do not have DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_KEY, so this would need to be reflected.&lt;br/&gt;
Anyway, until somebody else comments here, I won&apos;t spend more time on this.&lt;/p&gt;</comment>
                            <comment id="13462268" author="lhofhansl" created="Mon, 24 Sep 2012 23:49:59 +0000"  >&lt;p&gt;Patch that should work with all versions of Hadoop. Instead of reflection, just spells out the relevant config option.&lt;/p&gt;</comment>
                            <comment id="13462319" author="stack" created="Tue, 25 Sep 2012 01:01:09 +0000"  >&lt;p&gt;Sorry.  Distracted today.  On DFS_CLIENT_READ_SHORTCIRCUIT_KEY, I&apos;d checked and yeah, hadoop 1.0.x has it so patch would be fine for 0.96.&lt;/p&gt;

&lt;p&gt;The patch permanently ties the checksumming feature to local short circuit.  Is that what we want to do?  Might be ok for 0.94 but we might not want it for trunk/0.96 which we want working w/ h2 and hopefully it&apos;ll get hdfs-3429 soon.&lt;/p&gt;

&lt;p&gt;Can we do this Lars:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;dfs.client.read.shortcircuit = true&lt;br/&gt;
dfs.client.read.shortcircuit.skip.checksum=true&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It means we read that when we read a WAL with blocks that are local, we&apos;ll not be checking their checksum.&lt;/p&gt;

&lt;p&gt;Should we just turn off the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt;?  Set &lt;a href=&quot;http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/HRegionServer.html#468&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/HRegionServer.html#468&lt;/a&gt; to false?  Will that get us the old behavior?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liulei.cn&quot; class=&quot;user-hover&quot; rel=&quot;liulei.cn&quot;&gt;LiuLei&lt;/a&gt; Regards &quot;I think there is another problem in local read....I think that may lead to RegionServer read wrong data.&quot;, I thought it a known hdfs issue w/ local read but could not find an issue describing the problem.  I&apos;d say file an hdfs issue for it.&lt;/p&gt;</comment>
                            <comment id="13462368" author="lhofhansl" created="Tue, 25 Sep 2012 02:23:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;The patch permanently ties the checksumming feature to local short circuit&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, this is the reality currently. When that changes, we should change the patch, methinks.&lt;/p&gt;

&lt;p&gt;On setting both config options... This would lead to issue reported here that HLogs are not checksummed.&lt;/p&gt;

&lt;p&gt;I think with the proposed change we get best we can get right now. If HDFS is setup such that disabling checksumming would have a benefit, it is switched on and enabled correctly in HBase.&lt;/p&gt;

&lt;p&gt;Once &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3429&quot; title=&quot;DataNode reads checksums even if client does not need them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3429&quot;&gt;&lt;del&gt;HDFS-3429&lt;/del&gt;&lt;/a&gt; is in (and in a mainstream HDFS release, which might be a while) we should rethink this.&lt;br/&gt;
(Just doing this for 0.94 and leave 0.96 the way it is seems OK too.)&lt;/p&gt;</comment>
                            <comment id="13462397" author="stack" created="Tue, 25 Sep 2012 03:13:44 +0000"  >&lt;p&gt;Only downside is no checksumming when reading (local) WAL blocks.  You ok w/ that?  It could be rare enough but when it&apos;d be kinda ugly when we get bitten by rotten bits; will we even fall back to non-local block if read fails because unparesable section?&lt;/p&gt;</comment>
                            <comment id="13462410" author="lhofhansl" created="Tue, 25 Sep 2012 03:41:36 +0000"  >&lt;p&gt;Oh... I see what you meant before. What we could do is:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;disable HBase checksum by default.&lt;/li&gt;
	&lt;li&gt;folks can then enable HBase checksums and dfs.client.read.shortcircuit together in the respective config files.&lt;/li&gt;
	&lt;li&gt;when HBase checksums we enabled dfs.client.read.shortcircuit.skip.checksum for the noChecksymFs in HFileSystem.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;That way we&apos;d have no double checksumming and HLog will be checksummed (because HLog used the backingFs - not the noChecksumFs).&lt;/p&gt;</comment>
                            <comment id="13462414" author="lhofhansl" created="Tue, 25 Sep 2012 03:48:39 +0000"  >&lt;p&gt;This is what I meant.&lt;/p&gt;

&lt;p&gt;Now we document that:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;dfs.client.read.shortcircuit should true&lt;/li&gt;
	&lt;li&gt;dfs.client.read.shortcircuit.skip.checksum should be false&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;That way this is no longer tied to short circuiting in the code. And if short circuiting happens to be enabled it is always correct to enable dfs.client.read.shortcircuit.skip.checksum if we want HBase checksum.&lt;/p&gt;

&lt;p&gt;Sounds good?&lt;/p&gt;</comment>
                            <comment id="13462440" author="stack" created="Tue, 25 Sep 2012 04:40:27 +0000"  >&lt;p&gt;+1 on patch.  Default is let hdfs worry about checksums.  No chance of dbl-checksumming.  If you did enable &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; hbase checksums and also enabled shortcircuit, you should be good (you&apos;ll be doing an unwanted extra seek if you have to do a non-local until hdfs-3429 goes in but thats another issue).  Your setting of dfs.client.read.shortcircuit.skip.checksum on the hfile fs, will make it so we avoid a dbl-checksum.  The new Configuration is important before you set the boolean as you have it.  I think this is good for trunk and 0.94.&lt;/p&gt;

&lt;p&gt;We should test starting a 0.94.2 on top of data written when the flag was true to see if we skip over the hbase inserted checksums.&lt;/p&gt;

&lt;p&gt;I can write a little note for the refguide on this after goes in.  Will also look at verifying it.&lt;/p&gt;
</comment>
                            <comment id="13462457" author="lhofhansl" created="Tue, 25 Sep 2012 05:39:29 +0000"  >&lt;p&gt;Cool... The only strange spot left is here: &lt;a href=&quot;http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/HFileBlock.html#1473&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/HFileBlock.html#1473&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We&apos;re setting useHBaseChecksum to true in the absence of any information from HFileSystem.&lt;br/&gt;
As far as I can tell this only triggered by tests, so I think we&apos;re good.&lt;/p&gt;

&lt;p&gt;Will commit tomorrow unless there are any objections. Agree on the testing, I will add this to the testing spreadsheet. I think I will sink the current 0.94.2 RC for this.&lt;/p&gt;</comment>
                            <comment id="13462923" author="hadoopqa" created="Tue, 25 Sep 2012 16:29:46 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12546437/6868-0.96-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12546437/6868-0.96-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 140 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2931//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13462925" author="lhofhansl" created="Tue, 25 Sep 2012 16:33:11 +0000"  >&lt;p&gt;I looked through the run, nothing stuck out... All the tests passed.&lt;/p&gt;

&lt;p&gt;I&apos;ll do some manual testing today and then commit.&lt;/p&gt;</comment>
                            <comment id="13463017" author="lhofhansl" created="Tue, 25 Sep 2012 17:36:23 +0000"  >&lt;p&gt;I manually did these tests (0.94 patch):&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;started HBase with HBase checksums off, inserted some data, flushed, compacted, scanned&lt;/li&gt;
	&lt;li&gt;restarted HBase with HBase checksums on, inserted some more data, flush/compacted, scanned&lt;/li&gt;
	&lt;li&gt;restarted HBase again with HBase checksums off, inserted some more data, flush/compacted, scanned&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Checked the logs for anything weird. Looks good. Going to commit to 0.94 and 0.96.&lt;/p&gt;</comment>
                            <comment id="13463020" author="lhofhansl" created="Tue, 25 Sep 2012 17:39:00 +0000"  >&lt;p&gt;Committed to 0.94 and 0.96.&lt;/p&gt;</comment>
                            <comment id="13463079" author="hudson" created="Tue, 25 Sep 2012 18:16:20 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #57 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/57/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/57/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6868&quot; title=&quot;Skip checksum is broke; are we double-checksumming by default?&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6868&quot;&gt;&lt;del&gt;HBASE-6868&lt;/del&gt;&lt;/a&gt; Skip checksum is broke; are we double-checksumming by default? (Revision 1390012)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13463090" author="hudson" created="Tue, 25 Sep 2012 18:25:25 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #488 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/488/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/488/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6868&quot; title=&quot;Skip checksum is broke; are we double-checksumming by default?&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6868&quot;&gt;&lt;del&gt;HBASE-6868&lt;/del&gt;&lt;/a&gt; Skip checksum is broke; are we double-checksumming by default? (Revision 1390012)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13463105" author="hudson" created="Tue, 25 Sep 2012 18:37:29 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3377 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3377/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3377/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6868&quot; title=&quot;Skip checksum is broke; are we double-checksumming by default?&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6868&quot;&gt;&lt;del&gt;HBASE-6868&lt;/del&gt;&lt;/a&gt; Skip checksum is broke; are we double-checksumming by default? (Revision 1390013)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13463346" author="hudson" created="Tue, 25 Sep 2012 23:26:52 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #192 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/192/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/192/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6868&quot; title=&quot;Skip checksum is broke; are we double-checksumming by default?&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6868&quot;&gt;&lt;del&gt;HBASE-6868&lt;/del&gt;&lt;/a&gt; Skip checksum is broke; are we double-checksumming by default? (Revision 1390013)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13469913" author="hudson" created="Fri, 5 Oct 2012 00:37:48 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #8 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/8/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/8/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6868&quot; title=&quot;Skip checksum is broke; are we double-checksumming by default?&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6868&quot;&gt;&lt;del&gt;HBASE-6868&lt;/del&gt;&lt;/a&gt; Skip checksum is broke; are we double-checksumming by default? (Revision 1390012)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13624694" author="stack" created="Sun, 7 Apr 2013 05:03:39 +0000"  >&lt;p&gt;Fix up after bulk move overwrote some 0.94.2 fix versions w/ 0.95.0 (Noticed by Lars Hofhansl)&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12607846">HBASE-6798</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12555960">HDFS-3429</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12535789">HBASE-5074</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12556287">HBASE-6040</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12546550" name="6868-0.94.txt" size="1525" author="lhofhansl" created="Tue, 25 Sep 2012 17:18:10 +0000"/>
                            <attachment id="12546219" name="6868-0.96-idea.txt" size="1940" author="lhofhansl" created="Sun, 23 Sep 2012 19:24:02 +0000"/>
                            <attachment id="12546409" name="6868-0.96-v2.txt" size="1481" author="lhofhansl" created="Mon, 24 Sep 2012 23:49:59 +0000"/>
                            <attachment id="12546437" name="6868-0.96-v3.txt" size="1998" author="lhofhansl" created="Tue, 25 Sep 2012 03:48:39 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 22 Sep 2012 04:07:37 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>241999</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 36 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02hrr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12480</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>