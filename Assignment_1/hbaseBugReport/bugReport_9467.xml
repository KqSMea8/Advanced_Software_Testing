<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:04:43 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9467/HBASE-9467.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9467] write can be totally blocked temporarily by a write-heavy region</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9467</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Write to a region can be blocked temporarily if the memstore of that region reaches the threshold(hbase.hregion.memstore.block.multiplier * hbase.hregion.flush.size) until the memstore of that region is flushed.&lt;/p&gt;

&lt;p&gt;For a write-heavy region, if its write requests saturates all the handler threads of that RS when write blocking for that region occurs, requests of other regions/tables to that RS also can&apos;t be served due to no available handler threads...until the pending writes of that write-heavy region are served after the flush is done. Hence during this time period, from the RS perspective it can&apos;t serve any request from any table/region just due to a single write-heavy region.&lt;/p&gt;

&lt;p&gt;This sounds not very reasonable, right? Maybe write requests from a region can only be served by a sub-set of the handler threads, and then write blocking of any single region can&apos;t lead to the scenario mentioned above?&lt;/p&gt;

&lt;p&gt;Comment?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12667575">HBASE-9467</key>
            <summary>write can be totally blocked temporarily by a write-heavy region</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fenghh">Honghua Feng</assignee>
                                    <reporter username="fenghh">Honghua Feng</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Sep 2013 13:42:59 +0000</created>
                <updated>Fri, 20 Nov 2015 11:54:01 +0000</updated>
                            <resolved>Tue, 17 Sep 2013 03:37:04 +0000</resolved>
                                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.96.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="13762027" author="ndimiduk" created="Mon, 9 Sep 2013 16:56:54 +0000"  >&lt;p&gt;See also &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8836&quot; title=&quot;Separate reader and writer thread pool in RegionServer, so that write throughput will not be impacted when the read load is very high&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8836&quot;&gt;HBASE-8836&lt;/a&gt;. Dupe?&lt;/p&gt;</comment>
                            <comment id="13762037" author="nkeywal" created="Mon, 9 Sep 2013 17:05:39 +0000"  >&lt;p&gt;It&apos;s not fully a duplicate, as this one is about ensuring that a workload of a region does not impact the others. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8836&quot; title=&quot;Separate reader and writer thread pool in RegionServer, so that write throughput will not be impacted when the read load is very high&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8836&quot;&gt;HBASE-8836&lt;/a&gt; concentrates the writers, freeing resources for the reader. But an heavy write on a region would block the others.&lt;br/&gt;
In any case, if you have a fixed number of worker thread, the activity of someone in the system can block the others (vs. only slowing them). &lt;/p&gt;

&lt;p&gt;There is no definitive solutions for this (if it&apos;s slow and you add queries it will become slower: like it or not, the regionserver shares its resources between all clients, and the load of a region impacts the others).  I tend to think that priorities are the best option.&lt;/p&gt;</comment>
                            <comment id="13762680" author="fenghh" created="Tue, 10 Sep 2013 03:17:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; Can we provide a percentage config which means how big the sub-set of handler threads any region&apos;s requests can use? And for any region we can hash its region name to a determined start index of the handler thread array, and the percentage config together with the count the handler threads determines the count of the sub-array of the handler threads to serve this region&apos;s requests. This way any region at worst can only saturate its sub-set of handler threads without impacting all the handler threads, and hence somewhat mitigates the symptom&lt;/p&gt;</comment>
                            <comment id="13763383" author="nkeywal" created="Tue, 10 Sep 2013 19:30:02 +0000"  >&lt;p&gt;Yes.&lt;br/&gt;
Just that the number of handlers is not usually not that high compared to the number of regions.&lt;br/&gt;
Note that the scheduler is now pluggable on trunk, so it&apos;s possible to put its own implementation.&lt;/p&gt;

&lt;p&gt;In theory, we should have as little handler as possible to limit the context switches. In practise, it depends, I have conflicting results on my tests around this. Obviously, if you can have a large number of handlers compared to the number of regions, it&apos;s easier.&lt;/p&gt;

&lt;p&gt;I was thinking about something like:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;there are 30 handlers total&lt;/li&gt;
	&lt;li&gt;50% can be used for any task, we don&apos;t do any analysis&lt;/li&gt;
	&lt;li&gt;if we have more then 50% of these handlers used, then we ensure that the remaining handlers are shared fairly (or prioritized).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The advantage of not doing any prioritization on the first 50% is that the shared counters can be expensive if the queries hit the cache.&lt;/p&gt;

&lt;p&gt;In your case, what is your configuration (number of regions / number of handlers / write load vs. read load in cache) currently? &lt;/p&gt;

</comment>
                            <comment id="13763396" author="stack" created="Tue, 10 Sep 2013 19:41:02 +0000"  >&lt;p&gt;Should we make server async internally rather than thread per request?&lt;/p&gt;</comment>
                            <comment id="13763417" author="nkeywal" created="Tue, 10 Sep 2013 19:53:40 +0000"  >&lt;p&gt;Yes. But I can&apos;t say how much we would gain.&lt;br/&gt;
Ideally, we should have one thread, and any i/o would put be put on the queue list. And we would not use the queue if there is no i/o.&lt;/p&gt;

&lt;p&gt;We have Reader -&amp;gt; queue -&amp;gt; ThreadPool execution the &apos;Call&apos;. It&apos;s not ideal to have a queue if there is no i/o.&lt;/p&gt;

&lt;p&gt;But I&apos;ve just tested that (removing this queue, Reader calling &apos;Call&apos;, after having removed all the synchronization), and the difference in performances was minimal. May be 5%.  So it&apos;s not our bottleneck today.&lt;/p&gt;

&lt;p&gt;This said, I hope it will become our bottleneck a day, hence this idea of doing a 50% between what we do w/o thinking and what we put in a priority list.&lt;/p&gt;
</comment>
                            <comment id="13763481" author="stack" created="Tue, 10 Sep 2013 20:40:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yes. But I can&apos;t say how much we would gain.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, there&apos;d be a usability angle where you wouldn&apos;t have to set # of handlers as well as we wouldn&apos;t have the silly situation where on big servers we have 300 handlers and for the most part 250 are just sitting there doing noting (&quot;do you have something for me to do? No?  Ok, well, do you?  No... Do you?...&quot; and so on).&lt;/p&gt;

&lt;p&gt;Isn&apos;t the story worse than you paint?&lt;/p&gt;

&lt;p&gt;Listener -&amp;gt; Readers (static N threads) -&amp;gt; queue (block/contend/3 different queues) -&amp;gt; Handlers (static M threads) -&amp;gt; WAL (block/contend) -&amp;gt; MemStore (block/contend) -&amp;gt; Responder queue (block/contend)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;But I&apos;ve just tested that (removing this queue, Reader calling &apos;Call&apos;, after having removed all the synchronization), and the difference in performances was minimal. May be 5%. So it&apos;s not our bottleneck today.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for doing this.  It is interesting it makes so little difference.  If so little, yeah, we should go dig elsewhere.  What was the concurrency like in your server?  tens or hundreds of handlers/readers?&lt;/p&gt;</comment>
                            <comment id="13763677" author="nkeywal" created="Tue, 10 Sep 2013 23:13:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;Isn&apos;t the story worse than you paint?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah. But for the WAL, I don&apos;t care that much: whatever we do, it&apos;s at the minimum network call. Even if I add memory, SSD drives, whatever, it will be expensive. gets into the cache (ours or OS caches) that do not require any i/o are a different animal.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;What was the concurrency like in your server? tens or hundreds of handlers/readers?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;500 threads doing gets like crazy&lt;br/&gt;
10 readers, the handlers were not called as I was doing the call from the reader.&lt;/p&gt;

&lt;p&gt;Basically, if the load is CPU bound (a search in a cache), having more threads than core is nearly useless (nearly because we have some i/o in the sockets).&lt;/p&gt;


&lt;p&gt;The main issue around this test is that the performances depends a lot on the cpu cache (hence the impr)ovement I got when I used the disruptor). But it&apos;s difficult to estimate how much you&apos;re crashing the cache on a real workload.&lt;/p&gt;

&lt;p&gt;Here I wanted to propose a kind of &quot;fast path&quot; for the operations that are likely to take no i/o. But the result of the attempt was not great. I will try again (merging this with the disruptor). I wanted to merge the responder call as well but I failed.&lt;/p&gt;

&lt;p&gt;I&apos;m also trying a (very simple) rowkey cache, and this seems to help more. Stay tuned for this one &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13763698" author="tlipcon" created="Tue, 10 Sep 2013 23:28:30 +0000"  >&lt;p&gt;Rather than blocking writes to a region which is above its memstore limit, why not reject them with a &quot;RegionOverloadedException&quot; or somesuch? This way it wouldn&apos;t occupy threads needlessly, and avoid long queueing delays. The client could then perform some exponential backoff.&lt;/p&gt;

&lt;p&gt;In the future, we could avoid the &quot;polling retry&quot; containing heavy batches of puts by changing the client to retry with a simple probe RPC until the region indicates that it&apos;s unblocked.&lt;/p&gt;</comment>
                            <comment id="13763699" author="tlipcon" created="Tue, 10 Sep 2013 23:30:17 +0000"  >&lt;p&gt;Sorry, hit submit too quickly... I meant to add that this approach is much better because it also helps with the problem of multiple different priority clients hitting the same region &amp;#8211; for example, a low priority MR job doing bulk puts into a region at the same time as a latency sensitive web app is doing single row requests. If you could set the watermarks for the low priority clients differently than high-priority clients, then rejecting the low priority ones and making them retry on the client side will leave room (both handler-wise and capacity wise) for the high priority ones to get in without sitting in lengthy RPC queues.&lt;/p&gt;</comment>
                            <comment id="13764010" author="stack" created="Wed, 11 Sep 2013 05:45:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Basically, if the load is CPU bound (a search in a cache), having more threads than core is nearly useless&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It would be worse than useless?  They get in the way?&lt;/p&gt;

&lt;p&gt;This sounds like good stuff &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lets just do &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt; suggestion &amp;#8211; would be good if calls only got as far as the front door mat and not into the parlor before we sent then back to where they came from.&lt;/p&gt;</comment>
                            <comment id="13764082" author="fenghh" created="Wed, 11 Sep 2013 07:48:32 +0000"  >&lt;p&gt;I like &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt;&apos;s idea that we reject write by RegionOverloadedException rather than blocking writes. This treatment can also avoid the unnecessary scenario where RS eventually finishes the write after the memstore flush is done but client gets timeout response if memstore flush takes too long&lt;/p&gt;

&lt;p&gt;But the client receiving such exception can only perform backoff for writes with the same rowKey as which is responsed such exception, hence can&apos;t prevent writes with different rowKeys belonging to the same region from hitting the RS and get RegionOverloadedException as well (considering client typically is unaware of the region key range when doing write)&lt;/p&gt;</comment>
                            <comment id="13764125" author="nkeywal" created="Wed, 11 Sep 2013 08:40:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fenghh&quot; class=&quot;user-hover&quot; rel=&quot;fenghh&quot;&gt;Honghua Feng&lt;/a&gt; the client knows the key ranges: it sends the writes only to the right regions servers.&lt;/p&gt;

&lt;p&gt;Agreed, Todd&apos;s solution is good here. Ok, so who writes the patch now? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13764133" author="fenghh" created="Wed, 11 Sep 2013 08:54:47 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~liochon&amp;#93;&lt;/span&gt; maybe I used wrong term here, I meant code calling HTable.put() etc. to write data to HBase for &apos;client&apos;. Sure HBase client knows the key range of region.&lt;/p&gt;

&lt;p&gt;I can write the patch per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt;&apos;s solution, if no any objection. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13764141" author="nkeywal" created="Wed, 11 Sep 2013 09:08:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;HTable.put() &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ok, I misunderstood. If you do a synchronous put, the client will wait until it succeeds. The server exception will be hidden from the final user and managed by the hbase client api code, (except if we fails to many times of course). So we can raise an exception on the server, to be managed by the hbase client API. In this case, there is likely nothing to change on the client side: the standard retry mechanism will do. On trunk, if you do an asynchronous put (HTable#setAutoFlush(false)), the writes will continue on the other regions, but this one will be ignored until the write buffer becomes full. As well, with some luck you don&apos;t have anything to change here.&lt;/p&gt;

&lt;p&gt;Thanks a lot for doing the patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, don&apos;t hesitate if you have any question.&lt;/p&gt;</comment>
                            <comment id="13764146" author="fenghh" created="Wed, 11 Sep 2013 09:12:54 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnicolas&quot; class=&quot;user-hover&quot; rel=&quot;dnicolas&quot;&gt;Damien Nicolas&lt;/a&gt; for the reminder, I&apos;ll take these into account.&lt;/p&gt;</comment>
                            <comment id="13764150" author="fenghh" created="Wed, 11 Sep 2013 09:15:34 +0000"  >&lt;p&gt;correct a typo in above comment: Thanks &lt;span class=&quot;error&quot;&gt;&amp;#91;~liochon&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;btw: no way to delete/edit a submitted comment? sounds inconvenient &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13764154" author="nkeywal" created="Wed, 11 Sep 2013 09:17:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;btw: no way to delete/edit a submitted comment? sounds inconvenient &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeah, a long time ago it was decided that discussions were simpler to follow this way.&lt;/p&gt;</comment>
                            <comment id="13766239" author="fenghh" created="Fri, 13 Sep 2013 04:42:28 +0000"  >&lt;p&gt;patch for trunk&lt;/p&gt;</comment>
                            <comment id="13766263" author="fenghh" created="Fri, 13 Sep 2013 06:00:27 +0000"  >&lt;p&gt;Change and explanation of the patch:&lt;/p&gt;

&lt;p&gt;1. Throw RegionOverloadedException immediately rather than wait/retry within HRegion when the target region is above the memstore limit, this avoid write requests on region above memstore limit occupying/saturating handler threads. This change is in HRegion.checkResources method.&lt;/p&gt;

&lt;p&gt;2. Reuse the exception handling and retry mechanism of AsyncProcess in client to handle RegionOverloadedException thrown from RS. Since RegionOverloadedException is not a DoNotRetryIOException, it&apos;ll be handled the same way as other non-DoNotRetryIOException thrown from RS by AsyncProcess and the according request will be retried using incremental backoff. &lt;br/&gt;
   In a more general sense, we can view RegionOverloadedException as another kind of retriable exception and reuse all the current handling for it in AsyncProcess/client, so no change in client side code. And if we really want to use exponential backoff rather than incremental backoff for RegionOverloadedException, as Todd suggested, we can change the code in AsyncProcess accordingly.&lt;/p&gt;

&lt;p&gt;3. We also need to check memstore limit and throw RegionOverloadedException for &apos;increment&apos; and &apos;append&apos; operations, since they also insert kv to memstore and increase its size. (checkResources is not called for these two operations in HRegion previously, corrected here)&lt;/p&gt;

&lt;p&gt;4. In UT TestHFileArchiving, RegionOverloadedException is thrown during loadRegion and since the &apos;put&apos; operations are called directly via HRegion, not via client/AsyncProcess, a similiar &apos;catch-and-wait&apos; handling is added here to proceed without failure.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; / &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; / &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt; : Any feedback for the patch? Thanks in advance.&lt;/p&gt;</comment>
                            <comment id="13766419" author="stack" created="Fri, 13 Sep 2013 11:29:54 +0000"  >&lt;p&gt;So we no longer block?  That would be great.&lt;/p&gt;

&lt;p&gt;Patch is clean.&lt;/p&gt;

&lt;p&gt;Don&apos;t do this: &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (this.getRegionInfo().isMetaRegion()) return;&lt;br/&gt;
+    if (this.getRegionInfo().isMetaRegion())&lt;br/&gt;
+      return;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I can fix on commit.&lt;/p&gt;

&lt;p&gt;Trying hadoopqa.&lt;/p&gt;
</comment>
                            <comment id="13766433" author="nkeywal" created="Fri, 13 Sep 2013 12:27:22 +0000"  >&lt;p&gt;I like the patch. And I like code removal.&lt;/p&gt;

&lt;p&gt;As stack for the return.&lt;/p&gt;

&lt;p&gt;I would propose to reuse RegionTooBusyException. It&apos;s seems too similar to RegionOverloadedException. Or at least one should extend the other. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+              &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+                &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(pause);
+              } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException ie) {
+              }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You can use Threads.sleep (with an &apos;s&apos;), it will handle InterruptedException.&lt;br/&gt;
It&apos;s in the tests, but the less we shallow interruptedException the better.&lt;/p&gt;


&lt;p&gt;+1 with the modifications above, very nice one.&lt;/p&gt;</comment>
                            <comment id="13766459" author="hadoopqa" created="Fri, 13 Sep 2013 13:03:01 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12602958/HBASE-9467-trunk-v0.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12602958/HBASE-9467-trunk-v0.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestMasterObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableInputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestRowCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestChangingEncoding&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTableUtil&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestClassLoading&lt;br/&gt;
                  org.apache.hadoop.hbase.thrift.TestThriftServer&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.trace.TestHTraceHooks&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestCopyTable&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportExport&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTablePool$TestHTableThreadLocalPool&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTool&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestTablePermissions&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestExportSnapshot&lt;br/&gt;
                  org.apache.hadoop.hbase.TestZooKeeper&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestClientTimeouts&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailoverBalancerPersistence&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan2&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideNoCodec&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessControlFilter&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestTimestampsFilter&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestRegionSplitter&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaMigrationConvertingToPB&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMetaScanner&lt;br/&gt;
                  org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestAdmin&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMultipleTimestamps&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.handler.TestCreateTableHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterMetricsWrapper&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable&lt;br/&gt;
                  org.apache.hadoop.hbase.TestAcidGuarantees&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRollingRestart&lt;br/&gt;
                  org.apache.hadoop.hbase.TestFullLogReconstruction&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestWALPlayer&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestScannersFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestCellCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.TestIOFencing&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterTransitions&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestScannerTimeout&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTable&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestShell&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRestartCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotMetadata&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTablePool$TestHTableReusablePool&lt;br/&gt;
                  org.apache.hadoop.hbase.TestDrainingServer&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFileSystem&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestOpenedRegionHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.io.TestFileLink&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterMetrics&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTableMultiplexer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestTableLockManager&lt;br/&gt;
                  org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHRegionPartitioner&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHCM&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterShutdown&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestWALObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadEncoded&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRegionPlacement&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide3&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaReaderEditor&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestFSUtils&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRolling&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestHBaseFsck&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.regionserver.TestCompaction.testTrackingCompactionRequest(TestCompaction.java:700)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7210//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13766885" author="tlipcon" created="Fri, 13 Sep 2013 20:09:11 +0000"  >&lt;p&gt;I don&apos;t have time to look at the patch itself, but one thing that comes to mind: is this a compatible change? Or do you need to add a new client parameter of some time that tells the server that it knows how to handle the new exception? It would be bad if existing clients all started getting some ClassNotFoundException trying to unwrap the new exception type, and actually failing rather than retrying. I don&apos;t know if that happens, but worth double checking (eg run YCSB with an old client against a new server)&lt;/p&gt;</comment>
                            <comment id="13768045" author="fenghh" created="Mon, 16 Sep 2013 03:58:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I would propose to reuse RegionTooBusyException. It&apos;s seems too similar to RegionOverloadedException&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;agree. I&apos;ll make a new patch accordingly&lt;/p&gt;</comment>
                            <comment id="13768046" author="fenghh" created="Mon, 16 Sep 2013 04:00:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;is this a compatible change?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;thanks for the reminder. per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt;&apos;s suggestion, there is no compatibility issue when we reuse RegionTooBusyException here, right?&lt;/p&gt;</comment>
                            <comment id="13768233" author="fenghh" created="Mon, 16 Sep 2013 11:19:30 +0000"  >&lt;p&gt;new patch reusing RegionTooBusyException&lt;/p&gt;</comment>
                            <comment id="13768282" author="hadoopqa" created="Mon, 16 Sep 2013 12:31:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12603321/HBASE-9467-trunk-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12603321/HBASE-9467-trunk-v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestMasterObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableInputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestRowCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestChangingEncoding&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTableUtil&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestClassLoading&lt;br/&gt;
                  org.apache.hadoop.hbase.thrift.TestThriftServer&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.trace.TestHTraceHooks&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestCopyTable&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportExport&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTablePool$TestHTableThreadLocalPool&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTool&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestTablePermissions&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestExportSnapshot&lt;br/&gt;
                  org.apache.hadoop.hbase.TestZooKeeper&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestClientTimeouts&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailoverBalancerPersistence&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan2&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideNoCodec&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessControlFilter&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestTimestampsFilter&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestRegionSplitter&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaMigrationConvertingToPB&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMetaScanner&lt;br/&gt;
                  org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestAdmin&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMultipleTimestamps&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.handler.TestCreateTableHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterMetricsWrapper&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable&lt;br/&gt;
                  org.apache.hadoop.hbase.TestAcidGuarantees&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRollingRestart&lt;br/&gt;
                  org.apache.hadoop.hbase.TestFullLogReconstruction&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestWALPlayer&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestScannersFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestCellCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.TestIOFencing&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestCompaction&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterTransitions&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestScannerTimeout&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTable&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestShell&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRestartCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotMetadata&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTablePool$TestHTableReusablePool&lt;br/&gt;
                  org.apache.hadoop.hbase.TestDrainingServer&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFileSystem&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestOpenedRegionHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.io.TestFileLink&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterMetrics&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTableMultiplexer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestTableLockManager&lt;br/&gt;
                  org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHRegionPartitioner&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHCM&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterShutdown&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestWALObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadEncoded&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRegionPlacement&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide3&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessController&lt;br/&gt;
                  org.apache.hadoop.hbase.TestLocalHBaseCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaReaderEditor&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestFSUtils&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRolling&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestHBaseFsck&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7240//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13768287" author="fenghh" created="Mon, 16 Sep 2013 12:41:57 +0000"  >&lt;p&gt;unit tests on my local machine are OK. but failed so many Hadoop QA &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13768404" author="stack" created="Mon, 16 Sep 2013 15:23:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fenghh&quot; class=&quot;user-hover&quot; rel=&quot;fenghh&quot;&gt;Honghua Feng&lt;/a&gt; It is not you.  Hadoopqa is having issues (device full &amp;#8211; trying to get it seen to).&lt;/p&gt;</comment>
                            <comment id="13768564" author="stack" created="Mon, 16 Sep 2013 18:10:58 +0000"  >&lt;p&gt;Retry. Device has been cleaned.&lt;/p&gt;</comment>
                            <comment id="13768565" author="stack" created="Mon, 16 Sep 2013 18:12:40 +0000"  >&lt;p&gt;Patch lgtm.  Lets see if passes hadoopqa.  Will commit if it does (will add some detail to the exception message on commit).&lt;/p&gt;</comment>
                            <comment id="13768664" author="hadoopqa" created="Mon, 16 Sep 2013 19:31:39 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12603381/HBASE-9467-trunk-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12603381/HBASE-9467-trunk-v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestMasterObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestRowCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestChangingEncoding&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTableUtil&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestClassLoading&lt;br/&gt;
                  org.apache.hadoop.hbase.thrift.TestThriftServer&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.trace.TestHTraceHooks&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestCopyTable&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportExport&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTablePool$TestHTableThreadLocalPool&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTool&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestTablePermissions&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestExportSnapshot&lt;br/&gt;
                  org.apache.hadoop.hbase.TestZooKeeper&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestClientTimeouts&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailoverBalancerPersistence&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan2&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideNoCodec&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessControlFilter&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestHRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestTimestampsFilter&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestRegionSplitter&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaMigrationConvertingToPB&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMetaScanner&lt;br/&gt;
                  org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestAdmin&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestMultipleTimestamps&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.handler.TestCreateTableHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterMetricsWrapper&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable&lt;br/&gt;
                  org.apache.hadoop.hbase.TestAcidGuarantees&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRollingRestart&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.TestFullLogReconstruction&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestWALPlayer&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestScannersFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestCellCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.TestIOFencing&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterTransitions&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestScannerTimeout&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTable&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestShell&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRestartCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotMetadata&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTablePool$TestHTableReusablePool&lt;br/&gt;
                  org.apache.hadoop.hbase.TestDrainingServer&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFileSystem&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestOpenedRegionHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.io.TestFileLink&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterMetrics&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHTableMultiplexer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestTableLockManager&lt;br/&gt;
                  org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHRegionPartitioner&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHCM&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMasterShutdown&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestWALObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMiniClusterLoadEncoded&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestRegionPlacement&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide3&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessController&lt;br/&gt;
                  org.apache.hadoop.hbase.TestLocalHBaseCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaReaderEditor&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestDistributedLogSplitting&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestFSUtils&lt;br/&gt;
                  org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRolling&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestHBaseFsck&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestClusterId&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7244//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13768676" author="stack" created="Mon, 16 Sep 2013 19:43:26 +0000"  >&lt;p&gt;Retry.  I moved MAVEN_OPTS from jenkins config box to a setting before the test-patch.sh runs up on hadoopqa&lt;/p&gt;</comment>
                            <comment id="13769114" author="hadoopqa" created="Tue, 17 Sep 2013 02:34:52 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12603410/HBASE-9467-trunk-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12603410/HBASE-9467-trunk-v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7260//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13769136" author="stack" created="Tue, 17 Sep 2013 03:07:47 +0000"  >&lt;p&gt;TestOfflineMetaRebuildOverlap is another issue, not because of this patch.  Will commit in a sec.&lt;/p&gt;</comment>
                            <comment id="13769138" author="fenghh" created="Tue, 17 Sep 2013 03:10:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; Thanks for the effort&lt;/p&gt;</comment>
                            <comment id="13769160" author="stack" created="Tue, 17 Sep 2013 03:37:04 +0000"  >&lt;p&gt;Committed to trunk and to 0.96.  Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fenghh&quot; class=&quot;user-hover&quot; rel=&quot;fenghh&quot;&gt;Honghua Feng&lt;/a&gt; and to the reviewing crew.&lt;/p&gt;</comment>
                            <comment id="13769170" author="hadoopqa" created="Tue, 17 Sep 2013 04:02:53 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12603410/HBASE-9467-trunk-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12603410/HBASE-9467-trunk-v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7262//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13769213" author="hudson" created="Tue, 17 Sep 2013 05:24:23 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4519 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4519/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4519/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9467&quot; title=&quot;write can be totally blocked temporarily by a write-heavy region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9467&quot;&gt;&lt;del&gt;HBASE-9467&lt;/del&gt;&lt;/a&gt; write can be totally blocked temporarily by a write-heavy region (stack: rev 1523881)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13769214" author="hudson" created="Tue, 17 Sep 2013 05:27:21 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #735 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/735/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/735/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9467&quot; title=&quot;write can be totally blocked temporarily by a write-heavy region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9467&quot;&gt;&lt;del&gt;HBASE-9467&lt;/del&gt;&lt;/a&gt; write can be totally blocked temporarily by a write-heavy region (stack: rev 1523881)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13769235" author="hudson" created="Tue, 17 Sep 2013 05:57:44 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.96 #59 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96/59/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96/59/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9467&quot; title=&quot;write can be totally blocked temporarily by a write-heavy region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9467&quot;&gt;&lt;del&gt;HBASE-9467&lt;/del&gt;&lt;/a&gt; write can be totally blocked temporarily by a write-heavy region (stack: rev 1523880)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13769465" author="hudson" created="Tue, 17 Sep 2013 12:15:51 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.96-hadoop2 #33 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96-hadoop2/33/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96-hadoop2/33/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9467&quot; title=&quot;write can be totally blocked temporarily by a write-heavy region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9467&quot;&gt;&lt;del&gt;HBASE-9467&lt;/del&gt;&lt;/a&gt; write can be totally blocked temporarily by a write-heavy region (stack: rev 1523880)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15016123" author="lars_francke" created="Fri, 20 Nov 2015 11:54:01 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12602958" name="HBASE-9467-trunk-v0.patch" size="7270" author="fenghh" created="Fri, 13 Sep 2013 04:42:28 +0000"/>
                            <attachment id="12603410" name="HBASE-9467-trunk-v1.patch" size="4822" author="stack" created="Mon, 16 Sep 2013 19:43:26 +0000"/>
                            <attachment id="12603381" name="HBASE-9467-trunk-v1.patch" size="4822" author="stack" created="Mon, 16 Sep 2013 18:10:58 +0000"/>
                            <attachment id="12603321" name="HBASE-9467-trunk-v1.patch" size="4822" author="fenghh" created="Mon, 16 Sep 2013 11:19:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 9 Sep 2013 16:56:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>347512</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nx9b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>347811</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>