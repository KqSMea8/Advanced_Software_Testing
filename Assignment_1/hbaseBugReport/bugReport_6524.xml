<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:37:31 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6524/HBASE-6524.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6524] Hooks for hbase tracing</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6524</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Includes the hooks that use &lt;a href=&quot;http://www.github.com/cloudera/htrace&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;htrace&lt;/a&gt; library to add dapper-like tracing to hbase.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12602090">HBASE-6524</key>
            <summary>Hooks for hbase tracing</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12600049">HBASE-6449</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jonathan.leavitt">Jonathan Leavitt</assignee>
                                    <reporter username="jonathan.leavitt">Jonathan Leavitt</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 Aug 2012 22:19:32 +0000</created>
                <updated>Thu, 20 Mar 2014 17:56:34 +0000</updated>
                            <resolved>Thu, 30 Aug 2012 05:54:33 +0000</resolved>
                                                    <fixVersion>0.95.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                <comments>
                            <comment id="13430678" author="jonathan.leavitt" created="Tue, 7 Aug 2012 22:21:03 +0000"  >&lt;p&gt;First patch for tracing hooks in hbase.&lt;/p&gt;</comment>
                            <comment id="13430682" author="jonathan.leavitt" created="Tue, 7 Aug 2012 22:24:39 +0000"  >&lt;p&gt;Here&apos;s the review board link for the patch I uploaded: &lt;a href=&quot;https://reviews.apache.org/r/6454/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;review board&lt;/a&gt;.&lt;br/&gt;
The library is on &lt;a href=&quot;http://www.github.com/cloudera/htrace&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;github&lt;/a&gt; and is in maven central.&lt;/p&gt;</comment>
                            <comment id="13430694" author="stack" created="Tue, 7 Aug 2012 22:39:33 +0000"  >&lt;p&gt;I added comments up in rb.&lt;/p&gt;</comment>
                            <comment id="13431523" author="jonathan.leavitt" created="Thu, 9 Aug 2012 01:09:37 +0000"  >&lt;p&gt;Commented back. Doing a small release of htrace now, and will upload a new patch incorporating your and todd&apos;s suggestions. &lt;/p&gt;</comment>
                            <comment id="13432031" author="jonathan.leavitt" created="Thu, 9 Aug 2012 18:15:33 +0000"  >&lt;p&gt;uploading updated patch with changes from stack and todd&lt;/p&gt;</comment>
                            <comment id="13432033" author="jonathan.leavitt" created="Thu, 9 Aug 2012 18:16:14 +0000"  >&lt;p&gt;new patch with changes from stack and todd.&lt;/p&gt;</comment>
                            <comment id="13433775" author="jonathan.leavitt" created="Tue, 14 Aug 2012 00:23:46 +0000"  >&lt;p&gt;added some tests&lt;/p&gt;</comment>
                            <comment id="13433978" author="hadoopqa" created="Tue, 14 Aug 2012 07:52:33 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12540811/htracehooks1.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12540811/htracehooks1.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 2 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 7 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplication&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2563//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13435664" author="jonathan.leavitt" created="Thu, 16 Aug 2012 00:51:44 +0000"  >&lt;p&gt;In response to hadoop QA: &lt;/p&gt;

&lt;p&gt;TestReplication passes for me, so I don&apos;t think I caused the failure. &lt;br/&gt;
The new findbugs come from the protobuf generated classes. &lt;/p&gt;

&lt;p&gt;As for the additional javac compiler warning, I am not completely sure.  When I compile myself I only get 4 warnings, not 5. The hadoop QA console output seems to suggest it is a maven problem.  I will look into this further. &lt;/p&gt;

&lt;p&gt;@stack: given the above, what would you recommend I do to make progress on getting this committed? &lt;/p&gt;
</comment>
                            <comment id="13436104" author="jonathan.leavitt" created="Thu, 16 Aug 2012 17:02:35 +0000"  >&lt;p&gt;Apologies, I realized that the generated protubufs should not contribute additional findbugs warnings because they should be in findbugx-exclude.xml.  I believe I remember hsieh mentioning that changing the pbufs could affect findbug warnings, but maybe I misunderstood.  &lt;/p&gt;

&lt;p&gt;I did however look through all the files I changed at the findbugs warnings for those files and I was unable to find anything.  I will keep looking. &lt;/p&gt;</comment>
                            <comment id="13437990" author="jonathan.leavitt" created="Mon, 20 Aug 2012 16:31:16 +0000"  >&lt;p&gt;Final update on findbugs:&lt;br/&gt;
I installed the findbugs eclipse plugin and inspected all of the files I edited. I saw no bugs introduced by any code from my patch. &lt;/p&gt;
</comment>
                            <comment id="13438135" author="stack" created="Mon, 20 Aug 2012 19:54:42 +0000"  >&lt;p&gt;@Jonathan Sorry for delayed review.  Thanks for looking at the findbugs and javac stuff.  Probably not you as you figured.&lt;/p&gt;

&lt;p&gt;On the patch:&lt;/p&gt;

&lt;p&gt;You change hbase-site.xml license indent.  Would suggest you don&apos;t do that.  I can fix that on commit.&lt;/p&gt;

&lt;p&gt;Is htrace up in  mvn central?&lt;/p&gt;

&lt;p&gt;Why do we create a new instance of TInfo here rather than just use the one we have (presuming hasTinfo means the request has a TInfo?)?&lt;/p&gt;

&lt;p&gt;+        call = new Call(id, param, this, responder, callSize, new TraceInfo(&lt;br/&gt;
+            request.getTinfo().getTraceId(), request.getTinfo().getParentId()));&lt;/p&gt;

&lt;p&gt;Should say what a spanReceiverHost is.  When I load receivers, what kind of resources are we allocating?&lt;/p&gt;

&lt;p&gt;Is that all it takes to add tracing?  That is pretty sweet.  I&apos;d say this patch is close to commit.  See comments above.  You going to do a bit of a blog w/ fancy tracing pictures?    Something we could reference from the refguide?  Any more pretty pictures for us?&lt;/p&gt;



</comment>
                            <comment id="13438381" author="jonathan.leavitt" created="Tue, 21 Aug 2012 01:33:43 +0000"  >&lt;p&gt;updated diff&lt;/p&gt;</comment>
                            <comment id="13438391" author="jonathan.leavitt" created="Tue, 21 Aug 2012 01:50:03 +0000"  >&lt;p&gt;@Stack&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Is htrace up in mvn central?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt; Why do we create a new instance of TInfo here rather than just use the one we have (presuming hasTinfo means the request has a TInfo?)?&lt;br/&gt;
+ call = new Call(id, param, this, responder, callSize, new TraceInfo(&lt;br/&gt;
+ request.getTinfo().getTraceId(), request.getTinfo().getParentId()));&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m trying to keep HTrace agnostic of RPC mechanism, so the TraceInfo in the request is a protobuf TraceInfo (RPCTinfo from Tracing.proto). I just convert it to the TraceInfo defined in HTrace to decrease dependency on protobufs. &lt;br/&gt;
On the other hand, it&apos;s not a big deal to store the RPCTinfo in the Call, so if you think the extra overhead from crating the TraceInfo is bad, I&apos;m happy to change it. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should say what a spanReceiverHost is. When I load receivers, what kind of resources are we allocating?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Do you mean I should explain SpanReceiverHosts in HMaster? Or describe them more thoroughly in SpanReceiverHost.java? Or somewhere else? &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is that all it takes to add tracing? That is pretty sweet. I&apos;d say this patch is close to commit. See comments above. You going to do a bit of a blog w/ fancy tracing pictures? Something we could reference from the refguide? Any more pretty pictures for us?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This patch is enough to add tracing for RPCs. There are still places in HBase that need to be instrumented (by that I mean wrapping any thread changes).  It would also be useful to add some more spans for interesting HBaseEvents (maybe start a new span any time we talk to HDFS). &lt;/p&gt;

&lt;p&gt;I will work on a blog post.  I started working on a more thorough README for &lt;a href=&quot;https://github.com/cloudera/htrace&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;htrace&lt;/a&gt;. After I am happy with that I can write up something more specific for the refguide if necessary. &lt;/p&gt;</comment>
                            <comment id="13438417" author="hadoopqa" created="Tue, 21 Aug 2012 02:46:34 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12541691/hbase-6524.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12541691/hbase-6524.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 2 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 8 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient&lt;br/&gt;
                  org.apache.hadoop.hbase.io.encoding.TestUpgradeFromHFileV1ToEncoding&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2634//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13438859" author="stack" created="Tue, 21 Aug 2012 17:05:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;.. so if you think the extra overhead from crating the TraceInfo is bad, I&apos;m happy to change it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its fine.  Its a small object instantiation.  Better if we didn&apos;t have to do it but if it makes for cleaner hand off, its fine.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...or describe them more thoroughly in SpanReceiverHost.java? Or somewhere else?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its fine.  The class comment in SpanReceiverHost is enough.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...maybe start a new span any time we talk to HDFS&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, that sounds good.  Can do that in new JIRA?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I will work on a blog post.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I just think this a topic that will be of general interest.&lt;/p&gt;

&lt;p&gt;For refguide, a sentence or two w/ pointers on  how to set it all up would be great.&lt;/p&gt;

&lt;p&gt;I think we should commit this if its fine by you.&lt;/p&gt;</comment>
                            <comment id="13438860" author="stack" created="Tue, 21 Aug 2012 17:06:17 +0000"  >&lt;p&gt;Do you have any more pretty graphs you can post here?&lt;/p&gt;</comment>
                            <comment id="13438971" author="jonathan.leavitt" created="Tue, 21 Aug 2012 19:27:05 +0000"  >&lt;p&gt;A trace of a createTable. &lt;/p&gt;</comment>
                            <comment id="13438973" author="hadoopqa" created="Tue, 21 Aug 2012 19:33:15 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12541798/createTableTrace.png&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12541798/createTableTrace.png&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2643//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2643//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13438980" author="jonathan.leavitt" created="Tue, 21 Aug 2012 19:41:54 +0000"  >&lt;p&gt;@Stack. I uploaded another image.  As you may notice, the descriptions on this image are not as descriptive as they are in the first image I uploaded.  This is because the toString() on HBaseServer.Call is different with the ProtobufRpcEngine.  It now just concatenates the toString of the rpcRequestBody with the toString of the connection. Unfortunately the default protobuf toString does not give the most useful information.  You can still make out the basics of the requests.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yeah, that sounds good. Can do that in new JIRA?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. I think that this commit is good for including htrace in maven dependencies and the basic instrumentation, and additional instrumentation should go in other JIRAs. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I just think this a topic that will be of general interest.&lt;br/&gt;
For refguide, a sentence or two w/ pointers on how to set it all up would be great. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll try to have some sort of blog post and ref guide stuff done today or tomorrow. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think we should commit this if its fine by you.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sounds good. &lt;/p&gt;
</comment>
                            <comment id="13439079" author="stack" created="Tue, 21 Aug 2012 21:46:47 +0000"  >&lt;p&gt;Committed to trunk.  Thanks for the patch Jonathan.&lt;/p&gt;

&lt;p&gt;Would suggest you file an issue on the protobuf toString issue.  If you add a line or two for the refguide here, I&apos;ll commit that too.  Thanks boss.&lt;/p&gt;</comment>
                            <comment id="13439129" author="hudson" created="Tue, 21 Aug 2012 22:50:58 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3251 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3251/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3251/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; Hooks for hbase tracing (Revision 1375812)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/pom.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/EnableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/Tracing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/HBaseLocalFileSpanReceiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/SpanReceiverHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/RPC.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/Tracing.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace/TestHTraceHooks.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13439142" author="hudson" created="Tue, 21 Aug 2012 23:29:15 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #141 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/141/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/141/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; Hooks for hbase tracing (Revision 1375812)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/pom.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/EnableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/Tracing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/HBaseLocalFileSpanReceiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/SpanReceiverHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/RPC.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/Tracing.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace/TestHTraceHooks.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13439168" author="zhihyu@ebaysf.com" created="Tue, 21 Aug 2012 23:47:51 +0000"  >&lt;p&gt;When I remove the patch from this JIRA, TestClusterBootOrder passed.&lt;/p&gt;

&lt;p&gt;With patch, TestClusterBootOrder fails.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testBootRegionServerFirst(org.apache.hadoop.hbase.TestClusterBootOrder)  Time elapsed: 0.002 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
        at org.apache.hadoop.hbase.TestClusterBootOrder.tearDown(TestClusterBootOrder.java:55)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here is the command I used:&lt;br/&gt;
mvn clean -Dhadoop.profile=2.0 test -Dtest=TestClusterBootOrder#testBootRegionServerFirst&lt;/p&gt;</comment>
                            <comment id="13439193" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 00:52:21 +0000"  >&lt;p&gt;Hadoop 2.0 build is broken.&lt;/p&gt;</comment>
                            <comment id="13439211" author="jonathan.leavitt" created="Wed, 22 Aug 2012 01:18:47 +0000"  >&lt;p&gt;Sorry about this. I am not sure what is going wrong with hadoop 2.0.  I am looking into it. &lt;/p&gt;</comment>
                            <comment id="13439238" author="stack" created="Wed, 22 Aug 2012 02:50:37 +0000"  >&lt;p&gt;@Jonathan Thanks for taking a look.  You clear on how to run w/ 2.0?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
MAVEN_OPTS=&lt;span class=&quot;code-quote&quot;&gt;&quot;-Xmx3g&quot;&lt;/span&gt; ~/bin/mvn/bin/mvn  -Dhadoop.profile=2.0 -P localTests -Dtest=TestClusterBootOrder test
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; </comment>
                            <comment id="13439633" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 16:09:08 +0000"  >&lt;p&gt;There were 90 more failed tests introduced for hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;I suggest we temporarily rollback the patch and give Jonathan enough time to iron out the 90+ test failures.&lt;/p&gt;</comment>
                            <comment id="13439723" author="jonathan.leavitt" created="Wed, 22 Aug 2012 18:03:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;There were 90 more failed tests introduced for hadoop 2.0 profile.&lt;br/&gt;
I suggest we temporarily rollback the patch and give Jonathan enough time to iron out the 90+ test failures.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think I have the fix. Stay tuned. &lt;/p&gt;</comment>
                            <comment id="13439789" author="jonathan.leavitt" created="Wed, 22 Aug 2012 19:38:05 +0000"  >&lt;p&gt;So I believe the problem was that htrace was depending on hadoop 1.0.3 and there was some problem when running it with hadoop 2 on the classpath. I removed the hadoop dependency from htrace, so now it just uses what it needs, which is better anyways. &lt;br/&gt;
The only change to the patch is depending on htrace version 1.49 as opposed to 1.48.  Should I upload a new patch that just changes the dependency version, or one that has all of the hooks and depends on htrace 1.49?&lt;/p&gt;

&lt;p&gt;Also, the htrace maven repo won&apos;t be synced to maven central for another 2 hours, so I can&apos;t upload a patch until then.&lt;/p&gt;</comment>
                            <comment id="13439800" author="stack" created="Wed, 22 Aug 2012 19:54:58 +0000"  >&lt;p&gt;Make new issue that changes the pom to 1.49.  We can wait 2 hours.  Thanks Jonathan.&lt;/p&gt;</comment>
                            <comment id="13439802" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 20:02:11 +0000"  >&lt;p&gt;Using snapshot build of htrace 1.49, I was able to run TestClusterBootOrder with hadoop 2.0 profile.&lt;br/&gt;
But the test failed with:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testBootRegionServerFirst(org.apache.hadoop.hbase.TestClusterBootOrder)  Time elapsed: 0.263 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.IncompatibleClassChangeError: Implementing class
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.defineClass1(Native Method)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.defineClassCond(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:631)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.defineClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:615)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)
        at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:197)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:306)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:247)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:169)
        at org.apache.hadoop.hbase.mapreduce.MapreduceTestingShim.&amp;lt;clinit&amp;gt;(MapreduceTestingShim.java:45)
        at org.apache.hadoop.hbase.HBaseTestingUtility.createDirsAndSetProperties(HBaseTestingUtility.java:475)
        at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:426)
        at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:392)
        at org.apache.hadoop.hbase.TestClusterBootOrder.setUp(TestClusterBootOrder.java:47)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The test passed with hadoop 1.0 profile.&lt;/p&gt;</comment>
                            <comment id="13439810" author="jonathan.leavitt" created="Wed, 22 Aug 2012 20:12:19 +0000"  >&lt;p&gt;With htrace 1.49 I run:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;mvn clean -Dhadoop.profile=2.0 test -Dtest=TestClusterBootOrder&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;with no problems.&lt;/p&gt;

&lt;p&gt;Just to make sure, I&apos;m assuming you got htrace 1.49 snapshot from github? Can you pull and install again? &lt;/p&gt;


</comment>
                            <comment id="13439814" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 20:18:12 +0000"  >&lt;p&gt;The above error might be related to local .m2 repo.&lt;br/&gt;
I will wait till maven repo is populated.&lt;/p&gt;

&lt;p&gt;In the mean time, please run the whole test suite with hadoop 2.0 profile.&lt;/p&gt;</comment>
                            <comment id="13439873" author="jonathan.leavitt" created="Wed, 22 Aug 2012 21:38:37 +0000"  >&lt;p&gt;htrace 1.49 is available in maven now. I&apos;ve run the whole test suite, and I am still failing some tests when I run with the hadoop 2.0 profile. &lt;br/&gt;
I will continue to look into it, and put updates here.&lt;/p&gt;</comment>
                            <comment id="13439882" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 21:43:05 +0000"  >&lt;p&gt;With the following change:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index: hbase-server/pom.xml
===================================================================
--- hbase-server/pom.xml	(revision 1376206)
+++ hbase-server/pom.xml	(working copy)
@@ -454,7 +454,7 @@
     &amp;lt;dependency&amp;gt;
       &amp;lt;groupId&amp;gt;org.cloudera.htrace&amp;lt;/groupId&amp;gt;
       &amp;lt;artifactId&amp;gt;htrace&amp;lt;/artifactId&amp;gt;
-      &amp;lt;version&amp;gt;1.48&amp;lt;/version&amp;gt;
+      &amp;lt;version&amp;gt;1.49&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
   &amp;lt;/dependencies&amp;gt;
   &amp;lt;profiles&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I got:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[ERROR] Failed to execute goal on project hbase-server: Could not resolve dependencies &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; project org.apache.hbase:hbase-server:jar:0.95-SNAPSHOT: Failure to find org.cloudera.htrace:htrace:jar:1.49 in http:&lt;span class=&quot;code-comment&quot;&gt;//repository-netty.forge.cloudbees.com/snapshot/ was cached in the local repository, resolution will not be reattempted until the update interval of cloudbees netty has elapsed or updates are forced -&amp;gt; [Help 1]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please list the failed tests when hadoop 2.0 profile is used.&lt;/p&gt;</comment>
                            <comment id="13439886" author="jonathan.leavitt" created="Wed, 22 Aug 2012 21:49:11 +0000"  >&lt;p&gt;@Zhihong, try running maven with -U flag (forces it to update dependencies). List of failed tests coming soon (have to rerun). &lt;/p&gt;</comment>
                            <comment id="13439887" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 21:49:43 +0000"  >&lt;p&gt;Using another Linux box I was able to run tests against hadoop 2.0&lt;/p&gt;

&lt;p&gt;Will see what tests fail.&lt;/p&gt;</comment>
                            <comment id="13439924" author="jonathan.leavitt" created="Wed, 22 Aug 2012 22:52:08 +0000"  >&lt;p&gt;So I ran the full test suite with:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;mvn clean -Dhadoop.profile=2.0 test&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which yielded:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;


[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] HBase ............................................. SUCCESS [2.814s]
[INFO] HBase - Common .................................... SUCCESS [8.505s]
[INFO] HBase - Hadoop Compatibility ...................... SUCCESS [1.194s]
[INFO] HBase - Hadoop Two Compatibility .................. SUCCESS [3.113s]
[INFO] HBase - Server .................................... FAILURE [25:57.982s]
[INFO] HBase - Hadoop One Compatibility .................. SKIPPED
[INFO] HBase - Integration Tests ......................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 26:14.129s
[INFO] Finished at: Wed Aug 22 15:39:03 PDT 2012
[INFO] Final Memory: 90M/630M
[INFO] ------------------------------------------------------------------------
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The failures:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Failed tests:   testRowCounterNoColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testRowCounterHiddenColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testMROnTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMROnTableWithTimestamp(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMROnTableWithCustomMapper(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testBulkOutputWithoutAnExistingTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)

Tests in error: 
  testRowCounterExclusiveColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testSimpleCase(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testWithDeletes(org.apache.hadoop.hbase.mapreduce.TestImportExport)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So it seems I fixed most of the problems, but not all of them. will continue to investigate &lt;/p&gt;</comment>
                            <comment id="13439945" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 23:35:41 +0000"  >&lt;p&gt;Addendum uses 1.49 of htrace&lt;/p&gt;</comment>
                            <comment id="13439954" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 23:50:43 +0000"  >&lt;p&gt;I got a few test failures running test suite:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Running org.apache.hadoop.hbase.mapreduce.TestImportExport
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 51.918 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.client.TestHCM
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 72.583 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.client.TestAdmin
Tests run: 40, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 129.109 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.TestFullLogReconstruction
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 44.385 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 178.483 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I ran the following:&lt;br/&gt;
mvn -Dhadoop.profile=2.0 -P localTests test -Dtest=TestHCM#testRegionCaching&lt;br/&gt;
and got:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testRegionCaching(org.apache.hadoop.hbase.client.TestHCM)  Time elapsed: 60.047 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.Exception: test timed out after 60000 milliseconds
        at java.util.concurrent.ConcurrentHashMap$Segment.get(ConcurrentHashMap.java:344)
        at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:769)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getOnlineRegion(HRegionServer.java:2596)
        at org.apache.hadoop.hbase.client.TestHCM.testRegionCaching(TestHCM.java:244)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13439956" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 23:57:05 +0000"  >&lt;p&gt;Two other failed tests:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testCreateTableRPCTimeOut(org.apache.hadoop.hbase.client.TestAdmin)  Time elapsed: 15.187 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
org.apache.hadoop.hbase.TableNotEnabledException: Retries exhausted &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; still waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; table: testCreateTableRPCTimeOut to be enabled
        at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:460)
        at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:373)
        at org.apache.hadoop.hbase.client.TestAdmin.testCreateTableRPCTimeOut(TestAdmin.java:1125)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testReconstruction(org.apache.hadoop.hbase.TestFullLogReconstruction)  Time elapsed: 26.141 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
        at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1211)
        at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1142)
        at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1116)
        at org.apache.hadoop.hbase.TestFullLogReconstruction.testReconstruction(TestFullLogReconstruction.java:99)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13439989" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 01:08:01 +0000"  >&lt;p&gt;Here is the list of failed tests:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Failed tests:   testMultipleTables(org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient): Archived HFiles (hdfs:&lt;span class=&quot;code-comment&quot;&gt;//localhost:58500/user/zhihyu/hbase/.archive/otherTable/8f2bf3dfdf9ce281bec682f7160e4098/fam) should have gotten deleted, but didn&apos;t, remaining files:...
&lt;/span&gt;
Tests in error:
  testDisableInactivePeer(org.apache.hadoop.hbase.replication.TestReplication): Shutting down
  testCreateTableRPCTimeOut(org.apache.hadoop.hbase.client.TestAdmin): Retries exhausted &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; still waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; table: testCreateTableRPCTimeOut to be enabled
  testGetRowVersions(org.apache.hadoop.hbase.TestMultiVersions): Shutting down
  testScanMultipleVersions(org.apache.hadoop.hbase.TestMultiVersions): org.apache.hadoop.hbase.MasterNotRunningException: Can create a proxy to master, but it is not running
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I also saw two hanging tests:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; prio=10 tid=0x0000000040544800 nid=0x1e09 in &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() [0x00007ffc85ca6000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: TIMED_WAITING (on object monitor)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method)
	- waiting on &amp;lt;0x00000000a8807010&amp;gt; (a org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.join(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:1194)
	- locked &amp;lt;0x00000000a8807010&amp;gt; (a org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread)
	at org.apache.hadoop.hbase.util.Threads.threadDumpingIsAlive(Threads.java:116)
	at org.apache.hadoop.hbase.LocalHBaseCluster.join(LocalHBaseCluster.java:405)
	at org.apache.hadoop.hbase.MiniHBaseCluster.join(MiniHBaseCluster.java:408)
	at org.apache.hadoop.hbase.HBaseTestingUtility.shutdownMiniHBaseCluster(HBaseTestingUtility.java:599)
	at org.apache.hadoop.hbase.HBaseTestingUtility.shutdownMiniCluster(HBaseTestingUtility.java:573)
	at org.apache.hadoop.hbase.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.TestVersionResource.tearDownAfterClass(TestVersionResource.java:69)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; prio=10 tid=0x0000000040d5b800 nid=0x64df waiting on condition [0x00007f50b379b000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: TIMED_WAITING (sleeping)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(Native Method)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1225)
	at org.apache.hadoop.hbase.zookeeper.RootRegionTracker.blockUntilAvailable(RootRegionTracker.java:176)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:940)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1056)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:955)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1056)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:959)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.relocateRegion(HConnectionManager.java:923)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionLocation(HConnectionManager.java:834)
	at org.apache.hadoop.hbase.client.ServerCallable.connect(ServerCallable.java:88)
	at org.apache.hadoop.hbase.client.ScannerCallable.connect(ScannerCallable.java:95)
	at org.apache.hadoop.hbase.client.ServerCallable.withRetries(ServerCallable.java:168)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.&amp;lt;init&amp;gt;(ClientScanner.java:127)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:649)
	at org.apache.hadoop.hbase.replication.TestReplication.setUp(TestReplication.java:183)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In order to clear all the above, I think more time is needed.&lt;/p&gt;

&lt;p&gt;Rolling back the patch would allow &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6581&quot; title=&quot;Build with hadoop.profile=3.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6581&quot;&gt;HBASE-6581&lt;/a&gt; to proceed.&lt;/p&gt;</comment>
                            <comment id="13439991" author="jonathan.leavitt" created="Thu, 23 Aug 2012 01:18:11 +0000"  >&lt;p&gt;Strange, I pass some of the tests that you fail (all run locally though). &lt;/p&gt;

&lt;p&gt;I&apos;m still not sure exactly what&apos;s causing these errors, but it seems to me that it must have something to do with some missing dependencies or something, especially considering that tracing is never on for any of the failing tests, meaning very little htrace code is actually getting called run. I did remove the commons-logging dependency from htrace, to no avail. It seems bizarre that using hadoop 2 would cause the tests to fail.&lt;/p&gt;

&lt;p&gt;I&apos;m fine with removing with the patch so I have more time to figure out exactly what&apos;s going on. &lt;/p&gt;</comment>
                            <comment id="13439997" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 01:52:28 +0000"  >&lt;p&gt;I actually trimmed a few tests which passed when run individually from my list posted @ 23/Aug/12 00:57&lt;/p&gt;

&lt;p&gt;I agree the tests in list might just be flaky. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6627&quot; title=&quot;TestMultiVersions.testGetRowVersions is flaky&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6627&quot;&gt;&lt;del&gt;HBASE-6627&lt;/del&gt;&lt;/a&gt; only covers one of the TestMultiVersions tests.&lt;/p&gt;

&lt;p&gt;I think we should add a QA build for hadoop 2.0 so that we don&apos;t have to use trunk build to discover these failed tests.&lt;/p&gt;

&lt;p&gt;Thanks for your persistence, Jonathan.&lt;/p&gt;</comment>
                            <comment id="13440017" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 02:55:09 +0000"  >&lt;p&gt;Will revert the patch late tonight if I don&apos;t hear objection.&lt;/p&gt;</comment>
                            <comment id="13440059" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 05:09:38 +0000"  >&lt;p&gt;Reverted patch from trunk.&lt;/p&gt;

&lt;p&gt;TestHTraceHooks.java missed license header.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.cloudera.htrace.impl.NullSpan;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the intent of putting htrace into maven repo is for wider adoption.&lt;br/&gt;
I wonder if the above namespace (involving cloudera which should not be an org) would serve that purpose well.&lt;/p&gt;

&lt;p&gt;For HBaseLocalFileSpanReceiver.java, year is not needed in license header:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+ * Copyright 2010 The Apache Software Foundation
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&apos;s conduct thorough testing against hadoop 2.0 profile&lt;/p&gt;</comment>
                            <comment id="13440100" author="hudson" created="Thu, 23 Aug 2012 07:33:38 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3254 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3254/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3254/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; revert due to new test failures against hadoop 2.0 (Revision 1376365)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/pom.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/EnableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/Tracing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/HBaseLocalFileSpanReceiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/SpanReceiverHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/RPC.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/Tracing.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace/TestHTraceHooks.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13440223" author="hudson" created="Thu, 23 Aug 2012 11:40:59 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #143 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/143/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/143/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; revert due to new test failures against hadoop 2.0 (Revision 1376365)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/pom.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/EnableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/Tracing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/HBaseLocalFileSpanReceiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/SpanReceiverHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/RPC.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/Tracing.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace/TestHTraceHooks.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13440412" author="tlipcon" created="Thu, 23 Aug 2012 16:15:34 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think the intent of putting htrace into maven repo is for wider adoption.&lt;br/&gt;
I wonder if the above namespace (involving cloudera which should not be an org) would serve that purpose well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hey Ted. We use &lt;tt&gt;org.cloudera&lt;/tt&gt; here to distinguish that this is a fully open source component, distinct from other software like Cloudera Manager which uses &lt;tt&gt;com.cloudera&lt;/tt&gt;. The project is open on github and we fully anticipate that, if some community springs up around contributions, we&apos;ll accept pull requests and eventually move it to the Apache Incubator. At this point, though, it would be inappropriate to publish under &lt;tt&gt;org.apache&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;Consider it the same as a project like Guava which is under Google&apos;s namespace but is still open source.&lt;/p&gt;</comment>
                            <comment id="13440421" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 16:33:38 +0000"  >&lt;p&gt;Thanks Todd for the explanation. I understand the support of open source from Cloudera.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cloudera.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://cloudera.org&lt;/a&gt; is redirected to cloudera.com&lt;/p&gt;

&lt;p&gt;As for Google code, it is under com.google:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; com.google.common.base.Function;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; com.google.protobuf.ByteString;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13440631" author="jonathan.leavitt" created="Thu, 23 Aug 2012 20:33:16 +0000"  >&lt;p&gt;I&apos;m running the test suite with hadoop 2.0 profile &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;mvn clean  -Dhadoop.profile=2.0 -P localTests test &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; with and without patch. So far, the same test failures are affecting both. &lt;br/&gt;
Will update again once the whole suite is done running. &lt;/p&gt;</comment>
                            <comment id="13440664" author="jonathan.leavitt" created="Thu, 23 Aug 2012 21:08:56 +0000"  >&lt;p&gt;Update after running &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;mvn clean  -Dhadoop.profile=2.0 -P localTests test&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;with and without the patch. Many of the failed tests fail on both, and there are some failures unique to each. I would bet the results would be different if I ran the tests again. I believe that some of the tests are not completely stable for hadoop 2.0. &lt;/p&gt;

</comment>
                            <comment id="13440680" author="stack" created="Thu, 23 Aug 2012 21:21:27 +0000"  >&lt;p&gt;That could indeed be the case.  If you don&apos;t mind Jonathan, do some more runs.  If the set of flakey tests goes roughly unchanged when this patch is added, we can put it back and work on the flakeyness in other JIRAs.&lt;/p&gt;</comment>
                            <comment id="13440687" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 21:30:29 +0000"  >&lt;p&gt;I received the following from Jonathan:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
with htrace:

Failed tests:   testWALPlayer(org.apache.hadoop.hbase.mapreduce.TestWALPlayer): expected:&amp;lt;0&amp;gt; but was:&amp;lt;1&amp;gt;
  testMultiRegionTable(org.apache.hadoop.hbase.mapreduce.TestTableMapReduce)
  testMROnTableWithTimestamp(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMROnTableWithCustomMapper(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testRowCounterExclusiveColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testRowCounterHiddenColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)

Tests in error: 
  testMRIncrementalLoad(org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat)
  testMRIncrementalLoadWithSplit(org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat)
  testExcludeMinorCompaction(org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat)
  testMROnTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testBulkOutputWithoutAnExistingTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testRowCounterNoColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testMultithreadedTableMapper(org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper)
  testSimpleCase(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testMetaExport(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testWithDeletes(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testScanOBBToOPP(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan)
  testGetRowVersions(org.apache.hadoop.hbase.TestMultiVersions): Shutting down
  testScanMultipleVersions(org.apache.hadoop.hbase.TestMultiVersions): org.apache.hadoop.hbase.MasterNotRunningException: Can create a proxy to master, but it is not running
  testMultiRegionTable(org.apache.hadoop.hbase.mapred.TestTableMapReduce): Job failed!
  testUpgrade(org.apache.hadoop.hbase.io.encoding.TestUpgradeFromHFileV1ToEncoding): Shutting down
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As you can see, the count was much higher than 3&lt;br/&gt;
Please refer to &lt;a href=&quot;https://builds.apache.org/view/G-L/view/HBase/job/HBase-TRUNK-on-Hadoop-2.0.0/143/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/view/G-L/view/HBase/job/HBase-TRUNK-on-Hadoop-2.0.0/143/testReport/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13440693" author="jonathan.leavitt" created="Thu, 23 Aug 2012 21:37:17 +0000"  >&lt;p&gt;I may have some other problem then because here are the failed tests without htrace: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;


Failed tests:  
  testBulkOutputWithoutAnExistingTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testExcludeMinorCompaction(org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat)
  testMRIncrementalLoadWithSplit(org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat)
  testMROnTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMROnTableWithCustomMapper(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMultiRegionTable(org.apache.hadoop.hbase.mapreduce.TestTableMapReduce)
  testMultipleTables(org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient): Archived HFiles (hdfs:&lt;span class=&quot;code-comment&quot;&gt;//localhost:56525/user/jonathan/hbase/.archive/otherTable/188a593a472f6acc10b09c919b9b0659/fam) should have gotten deleted, but didn&apos;t, remaining files:[hdfs
&lt;/span&gt;  testMultithreadedTableMapper(org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper)
  testRowCounterExclusiveColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testRowCounterHiddenColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testRowCounterNoColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
 testMRIncrementalLoad(org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat)

Tests in error: 
  testDisableInactivePeer(org.apache.hadoop.hbase.replication.TestReplication): Shutting down
  testGetRowVersions(org.apache.hadoop.hbase.TestMultiVersions): Shutting down
  testMROnTableWithTimestamp(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMetaExport(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testMultiRegionTable(org.apache.hadoop.hbase.mapred.TestTableMapReduce): Job failed!
  testScanEmptyToAPP(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan)
  testScanEmptyToEmpty(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan)
  testScanMultipleVersions(org.apache.hadoop.hbase.TestMultiVersions): org.apache.hadoop.hbase.MasterNotRunningException: Can create a proxy to master, but it is not running
  testScanOPPToEmpty(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan)
  testScanYZYToEmpty(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan)
  testSimpleCase(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testWALPlayer(org.apache.hadoop.hbase.mapreduce.TestWALPlayer)
  testWithDeletes(org.apache.hadoop.hbase.mapreduce.TestImportExport)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Also more than 3. &lt;/p&gt;</comment>
                            <comment id="13440728" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 22:29:19 +0000"  >&lt;p&gt;Patch v2 changes htrace version to 1.49&lt;/p&gt;

&lt;p&gt;Also adds license headers to new files.&lt;/p&gt;</comment>
                            <comment id="13440738" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 22:46:05 +0000"  >&lt;p&gt;Here is the OS:&lt;br/&gt;
Linux s-2 2.6.38-11-generic #48-Ubuntu SMP Fri Jul 29 19:02:55 UTC 2011 x86_64 x86_64 x86_64 GNU/Linux&lt;br/&gt;
I got the following failures with htrace patch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testGetRowVersions(org.apache.hadoop.hbase.TestMultiVersions)  Time elapsed: 201.963 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.io.IOException: Shutting down
  at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:229)
  at org.apache.hadoop.hbase.MiniHBaseCluster.&amp;lt;init&amp;gt;(MiniHBaseCluster.java:92)
  at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:688)
  at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:661)
  at org.apache.hadoop.hbase.TestMultiVersions.testGetRowVersions(TestMultiVersions.java:143)
...
Caused by: java.lang.RuntimeException: Master not initialized after 200 seconds
  at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:208)
  at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:424)
  at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:222)
testScanMultipleVersions(org.apache.hadoop.hbase.TestMultiVersions)  Time elapsed: 70.623 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
org.apache.hadoop.hbase.MasterNotRunningException: org.apache.hadoop.hbase.MasterNotRunningException: Can create a proxy to master, but it is not running
  at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.createMasterWithRetries(HConnectionManager.java:782)
  at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveMasterProtocol(HConnectionManager.java:1618)
  at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveMasterAdmin(HConnectionManager.java:1649)
  at org.apache.hadoop.hbase.client.HBaseAdmin.execute(HBaseAdmin.java:2049)
  at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:510)
  at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:397)
  at org.apache.hadoop.hbase.TestMultiVersions.testScanMultipleVersions(TestMultiVersions.java:199)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The test passed without patch.&lt;/p&gt;</comment>
                            <comment id="13440754" author="jonathan.leavitt" created="Thu, 23 Aug 2012 23:12:27 +0000"  >&lt;p&gt;I pass TestMultiVersions with the sometimes, and fail it sometimes. The same happens without the patch.&lt;br/&gt;
Linux jsleavit 3.2.0-27-generic #43-Ubuntu SMP Fri Jul 6 14:25:57 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux&lt;/p&gt;</comment>
                            <comment id="13440767" author="stack" created="Thu, 23 Aug 2012 23:29:17 +0000"  >&lt;p&gt;Looking at the patch, its hard to see how this could cause problems: its .proto files, some generated files, and some intercession in a few locations, a test, and thats it.   Unless the calls into htrace are stalling somehow?&lt;/p&gt;

&lt;p&gt;Looking up on jenkins at the hadoop 2.0 build, I see where we were failing 95 unit tests after the first version of this patch went in.  Was there a run with the addendum applied?  (I don&apos;t see it.  Maybe I&apos;m missing something).&lt;/p&gt;


</comment>
                            <comment id="13440797" author="hadoopqa" created="Thu, 23 Aug 2012 23:57:06 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12542198/6524-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12542198/6524-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 9 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestMultiVersions&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2674//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13440835" author="zhihyu@ebaysf.com" created="Fri, 24 Aug 2012 00:45:45 +0000"  >&lt;p&gt;Looks like TestMultiVersions is broken in trunk, as evidenced by trunk build #3260 and the above QA report.&lt;br/&gt;
Here is list of failed tests with htrace patch against hadoop 2.0:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Failed tests:   testMultiSlaveReplication(org.apache.hadoop.hbase.replication.TestMultiSlaveReplication): Waited too much time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; put replication

Tests in error:
  testGetRowVersions(org.apache.hadoop.hbase.TestMultiVersions): Shutting down
  testScanMultipleVersions(org.apache.hadoop.hbase.TestMultiVersions): org.apache.hadoop.hbase.MasterNotRunningException: Can create a proxy to master, but it is not running
  testDisablingTableRegionsAssignmentDuringCleanClusterStartup(org.apache.hadoop.hbase.master.TestAssignmentManager): Problem binding to sea-lab-0/10.249.196.101:60000 : Address already in use
  testStopDuringStart(org.apache.hadoop.hbase.master.TestMasterNoCluster): Problem binding to sea-lab-0/10.249.196.101:60000 : Address already in use
  testFailover(org.apache.hadoop.hbase.master.TestMasterNoCluster): Problem binding to sea-lab-0/10.249.196.101:60000 : Address already in use
  testCatalogDeploys(org.apache.hadoop.hbase.master.TestMasterNoCluster): Problem binding to sea-lab-0/10.249.196.101:60000 : Address already in use
  testDisableInactivePeer(org.apache.hadoop.hbase.replication.TestReplication): Shutting down
  testSimpleCase(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testMetaExport(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testWithDeletes(org.apache.hadoop.hbase.mapreduce.TestImportExport)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;&lt;p&gt;Unless the calls into htrace are stalling somehow?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That was my guess as well.&lt;/p&gt;</comment>
                            <comment id="13440874" author="zhihyu@ebaysf.com" created="Fri, 24 Aug 2012 01:54:24 +0000"  >&lt;p&gt;I ran through tests using freshly checked out workspace against hadoop 2.0 on another box.&lt;br/&gt;
Here is list of failed tests:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Failed tests:   queueFailover(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; queueFailover replication. Waited 33733ms.

Tests in error:
  loadTest[0](org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel): test timed out after 120000 milliseconds
  loadTest[1](org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel): test timed out after 120000 milliseconds
  loadTest[0](org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential): test timed out after 120000 milliseconds
  testSimpleCase(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testMetaExport(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testWithDeletes(org.apache.hadoop.hbase.mapreduce.TestImportExport)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The list is shorter than the one where patch was applied.&lt;/p&gt;</comment>
                            <comment id="13441185" author="jonathan.leavitt" created="Fri, 24 Aug 2012 14:26:37 +0000"  >&lt;p&gt;Is there one test that is passing without patch consistently that fails consistently with patch? I haven&apos;t been able to find one, but I will continue to look. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Unless the calls into htrace are stalling somehow?  &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As with anything, this is certainly possible, however it does not seem very likely, given that tracing is never on in any of the tests, only a very small subset of HTrace code is ever run. I will continue to look at the HTrace code, as well as run the tests so we can get to the bottom of this. &lt;/p&gt;

&lt;p&gt;@zhihong, it&apos;s strange that the tests that fail without patch are not a subset of the tests that fail with htrace.&lt;/p&gt;</comment>
                            <comment id="13441234" author="stack" created="Fri, 24 Aug 2012 15:15:00 +0000"  >&lt;p&gt;We could commit it again and run tests up on jenkins and compare before and after.&lt;/p&gt;</comment>
                            <comment id="13441322" author="jonathan.leavitt" created="Fri, 24 Aug 2012 17:36:59 +0000"  >&lt;p&gt;@stack, it would be nice to see what jenkins has to say about the build. I understand though if we want to avoid committing something that is potentially causing test failures. &lt;br/&gt;
I&apos;m just having trouble pinpointing the problem when I don&apos;t have a test that hbase w. htrace is failing that hbase w.o htrace is passing. &lt;/p&gt;

&lt;p&gt;Also, it&apos;s worth noting that I&apos;ve run TestMasterNoCluster w. htrace and hadoop 2.0 successfully a few times (run as a single test though).  &lt;/p&gt;</comment>
                            <comment id="13441343" author="stack" created="Fri, 24 Aug 2012 18:01:58 +0000"  >&lt;p&gt;Are you game for trying it Ted?  We can always back it out again.&lt;/p&gt;</comment>
                            <comment id="13441497" author="jonathan.leavitt" created="Fri, 24 Aug 2012 20:58:39 +0000"  >&lt;p&gt;Just another quick testing update:&lt;br/&gt;
I just got this output after running the full test suite with htrace and hadoop 2.0:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

Results :

Failed tests:   testRowCounterNoColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testRowCounterHiddenColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testMROnTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testMROnTableWithCustomMapper(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
  testBulkOutputWithoutAnExistingTable(org.apache.hadoop.hbase.mapreduce.TestImportTsv)

Tests in error: 
  testRowCounterExclusiveColumn(org.apache.hadoop.hbase.mapreduce.TestRowCounter)
  testSimpleCase(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testMetaExport(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testWithDeletes(org.apache.hadoop.hbase.mapreduce.TestImportExport)
  testMROnTableWithTimestamp(org.apache.hadoop.hbase.mapreduce.TestImportTsv)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you look at this build: &lt;a href=&quot;https://builds.apache.org/view/G-L/view/HBase/job/HBase-TRUNK-on-Hadoop-2.0.0/144/#showFailuresLink&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/view/G-L/view/HBase/job/HBase-TRUNK-on-Hadoop-2.0.0/144/#showFailuresLink&lt;/a&gt; it seems like the same tests are causing problems on both. &lt;/p&gt;</comment>
                            <comment id="13441501" author="stack" created="Fri, 24 Aug 2012 21:06:39 +0000"  >&lt;p&gt;Lets commit.  Ted?&lt;/p&gt;</comment>
                            <comment id="13443470" author="stack" created="Tue, 28 Aug 2012 20:02:55 +0000"  >&lt;p&gt;@Ted Commit?&lt;/p&gt;</comment>
                            <comment id="13443472" author="yuzhihong@gmail.com" created="Tue, 28 Aug 2012 20:05:10 +0000"  >&lt;p&gt;Fine with me.&lt;/p&gt;

&lt;p&gt;FYI: I didn&apos;t receive email notification on Aug 24th.&lt;/p&gt;</comment>
                            <comment id="13444709" author="stack" created="Thu, 30 Aug 2012 05:51:25 +0000"  >&lt;p&gt;This is v2 only the pb stuff was regen&apos;d.  There were some issues applying v2 to current trunk.&lt;/p&gt;</comment>
                            <comment id="13444712" author="stack" created="Thu, 30 Aug 2012 05:54:33 +0000"  >&lt;p&gt;Reapplied using v3.  Lets see how it does up on jenkins.  Thanks again Jonathan.&lt;/p&gt;</comment>
                            <comment id="13444805" author="hudson" created="Thu, 30 Aug 2012 09:06:15 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #154 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/154/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/154/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; Hooks for hbase tracing; REAPPLICATION (Revision 1378809)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; Hooks for hbase tracing; REAPPLICATION (Revision 1378807)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/Tracing.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/HBaseLocalFileSpanReceiver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/trace/SpanReceiverHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/Tracing.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/trace/TestHTraceHooks.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/pom.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DisableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/EnableTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/RPCProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/protobuf/RPC.proto&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13449788" author="stack" created="Thu, 6 Sep 2012 16:37:10 +0000"  >&lt;p&gt;@Jonathan Was wondering if we need to add a bit of doc on how to make tracing work to the refguide.  In general, this is a &apos;cool feature&apos; (tm) and it would be a shame if it was buried for the want of someone talking it up.&lt;/p&gt;</comment>
                            <comment id="13450284" author="jonathan.leavitt" created="Fri, 7 Sep 2012 03:01:05 +0000"  >&lt;p&gt;@stack I agree, I will write something up for the refguide, and I&apos;m also working on a more in-depth blog post. Maybe have them done in a week or two (hopefully less depending on my motivation this weekend).&lt;/p&gt;
</comment>
                            <comment id="13456492" author="jonathan.leavitt" created="Sat, 15 Sep 2012 21:09:02 +0000"  >&lt;p&gt;@stack: &lt;a href=&quot;https://docs.google.com/document/d/11kM7dHetY5LYaC8rIkXfCHoxcbliTb9Xa3SZUfFhDu8/edit&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; is a link to my ref guide tracing stuff so far. The link is public and anyone can comment on it.&lt;br/&gt;
Let me know how it looks.&lt;/p&gt;
</comment>
                            <comment id="13457309" author="stack" created="Mon, 17 Sep 2012 20:49:53 +0000"  >&lt;p&gt;Doc is great.  &quot;(it would not be very difficult to remove this requirement).&quot;  What would this take?  The doc. is great.  I should add it to the manual?  Can we do this for hdfs too  yet?  What about an example that enables trace over hdfs too while the Get is going on?  Good on you Jonathan.&lt;/p&gt;</comment>
                            <comment id="13457579" author="stack" created="Tue, 18 Sep 2012 03:37:00 +0000"  >&lt;p&gt;On doc in general, I came across this recent quote &quot;Documentation is like sex: when it is good, it is very very good; and when it is bad, it is better than nothing.&quot;&lt;/p&gt;</comment>
                            <comment id="13459785" author="jonathan.leavitt" created="Thu, 20 Sep 2012 17:44:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;Doc is great. &quot;(it would not be very difficult to remove this requirement).&quot; What would this take?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Well to remove the client addendum we would have to instrument the entry points into hbase. &lt;br/&gt;
I will try to find one good class to instrument as the entry point in to the system.  HTable.java might work, but it doesn&apos;t include all operations, and importantly does not include all of the steps of a &apos;get&apos;, bx getting the HTable is a big part, right? &lt;br/&gt;
Maybe HTablePool.java would work. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can we do this for hdfs too yet? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not yet. I think Matt or Todd might be working on it. I have been looking into, but it does require all of the additional instrumentation to HDFS. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What about an example that enables trace over hdfs too while the Get is going on?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m not sure what you mean by this. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On doc in general, I came across this recent quote &quot;Documentation is like sex: when it is good, it is very very good; and when it is bad, it is better than nothing.&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Great quote. &lt;/p&gt;</comment>
                            <comment id="13459798" author="stack" created="Thu, 20 Sep 2012 17:56:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;What about an example that enables trace over hdfs too while the Get is going on?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Prerequisite is tracing in hdfs which is not done yet so ignore the above.&lt;/p&gt;</comment>
                            <comment id="13459838" author="stack" created="Thu, 20 Sep 2012 18:33:05 +0000"  >&lt;p&gt;Ok I integrate your doc into the book?&lt;/p&gt;</comment>
                            <comment id="13460247" author="jonathan.leavitt" created="Fri, 21 Sep 2012 05:54:36 +0000"  >&lt;p&gt;Sounds good. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13460265" author="stack" created="Fri, 21 Sep 2012 06:25:08 +0000"  >&lt;p&gt;Committed the doc. as appendix I in the manual.  Will show next time I push the doc.  Thanks Jonathan.&lt;/p&gt;</comment>
                            <comment id="13460326" author="hudson" created="Fri, 21 Sep 2012 07:45:12 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3364 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3364/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3364/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; Hooks for hbase tracing; add documentation as an appendix (Revision 1388337)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/docbkx/book.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13460447" author="hudson" created="Fri, 21 Sep 2012 12:17:18 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #185 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/185/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/185/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6524&quot; title=&quot;Hooks for hbase tracing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6524&quot;&gt;&lt;del&gt;HBASE-6524&lt;/del&gt;&lt;/a&gt; Hooks for hbase tracing; add documentation as an appendix (Revision 1388337)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/docbkx/book.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13774850" author="stack" created="Mon, 23 Sep 2013 18:30:12 +0000"  >&lt;p&gt;Marking closed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600049">HBASE-6449</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12542198" name="6524-v2.txt" size="60895" author="zhihyu@ebaysf.com" created="Thu, 23 Aug 2012 22:29:19 +0000"/>
                            <attachment id="12542055" name="6524.addendum" size="416" author="zhihyu@ebaysf.com" created="Wed, 22 Aug 2012 23:35:41 +0000"/>
                            <attachment id="12543041" name="6524v3.txt" size="27589" author="stack" created="Thu, 30 Aug 2012 05:51:25 +0000"/>
                            <attachment id="12541798" name="createTableTrace.png" size="308955" author="jonathan.leavitt" created="Tue, 21 Aug 2012 19:27:05 +0000"/>
                            <attachment id="12541691" name="hbase-6524.diff" size="62778" author="jonathan.leavitt" created="Tue, 21 Aug 2012 01:33:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 7 Aug 2012 22:39:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>256624</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 12 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hv2f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>102295</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Adds hooks so can track rpcs using htrace</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>