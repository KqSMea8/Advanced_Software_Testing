<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:52:49 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-14417/HBASE-14417.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-14417] Incremental backup and bulk loading</title>
                <link>https://issues.apache.org/jira/browse/HBASE-14417</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently, incremental backup is based on WAL files. Bulk data loading bypasses WALs for obvious reasons, breaking incremental backups. The only way to continue backups after bulk loading is to create new full backup of a table. This may not be feasible for customers who do bulk loading regularly (say, every day).&lt;/p&gt;

&lt;p&gt;Here is the review board:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/54258/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/54258/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Google doc for design:&lt;br/&gt;
&lt;a href=&quot;https://docs.google.com/document/d/1ACCLsecHDvzVSasORgqqRNrloGx4mNYIbvAU7lq5lJE&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://docs.google.com/document/d/1ACCLsecHDvzVSasORgqqRNrloGx4mNYIbvAU7lq5lJE&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12863553">HBASE-14417</key>
            <summary>Incremental backup and bulk loading</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="yuzhihong@gmail.com">Ted Yu</assignee>
                                    <reporter username="vrodionov">Vladimir Rodionov</reporter>
                        <labels>
                            <label>backup</label>
                    </labels>
                <created>Fri, 11 Sep 2015 22:31:11 +0000</created>
                <updated>Tue, 13 Dec 2016 22:08:27 +0000</updated>
                                            <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="15368585" author="yuzhihong@gmail.com" created="Fri, 8 Jul 2016 22:13:15 +0000"  >&lt;p&gt;Looks like bulk data loading should be applied to target table(s) as well.&lt;/p&gt;</comment>
                            <comment id="15368619" author="vrodionov" created="Fri, 8 Jul 2016 22:48:05 +0000"  >&lt;p&gt;Bulk loading produces new HFiles, we need to register these files and move them to backup destination during next incremental phase. Something like this.&lt;/p&gt;</comment>
                            <comment id="15375729" author="yuzhihong@gmail.com" created="Wed, 13 Jul 2016 20:47:12 +0000"  >&lt;p&gt;After registering these files, would they still participate in the next round of major compaction (assuming major compaction comes before the next incremental backup) ?&lt;/p&gt;</comment>
                            <comment id="15382805" author="yuzhihong@gmail.com" created="Mon, 18 Jul 2016 18:36:52 +0000"  >&lt;p&gt;If bulk loading is scheduled at regular interval, one approach is to align incremental backup activity with the bulk load.&lt;/p&gt;</comment>
                            <comment id="15414447" author="yuzhihong@gmail.com" created="Tue, 9 Aug 2016 23:37:21 +0000"  >&lt;p&gt;Discussed with Devaraj.&lt;br/&gt;
Quick solution is to detect the presence of bulk loaded hfiles between full backup and incremental backup. If bulk load is detected, convert incremental backup to full backup.&lt;/p&gt;

&lt;p&gt;Better solution, related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14141&quot; title=&quot;HBase Backup/Restore Phase 3: Filter WALs on backup to include only edits from backup tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14141&quot;&gt;HBASE-14141&lt;/a&gt;, is to list bulk loaded hfiles during incremental backup and put them in their own backup image.&lt;/p&gt;</comment>
                            <comment id="15414450" author="devaraj" created="Tue, 9 Aug 2016 23:42:33 +0000"  >&lt;p&gt;The question is should we do this first or &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14141&quot; title=&quot;HBase Backup/Restore Phase 3: Filter WALs on backup to include only edits from backup tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14141&quot;&gt;HBASE-14141&lt;/a&gt; first. We need both in reality. We could put in a short term solution for backing up bulk-loaded data but wondering if we should bite the bullet and do &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14141&quot; title=&quot;HBase Backup/Restore Phase 3: Filter WALs on backup to include only edits from backup tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14141&quot;&gt;HBASE-14141&lt;/a&gt; and then this.&lt;/p&gt;</comment>
                            <comment id="15414459" author="yuzhihong@gmail.com" created="Tue, 9 Aug 2016 23:48:22 +0000"  >&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14141&quot; title=&quot;HBase Backup/Restore Phase 3: Filter WALs on backup to include only edits from backup tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14141&quot;&gt;HBASE-14141&lt;/a&gt; should be done first which would lay foundation for proper resolution of this issue.&lt;/p&gt;</comment>
                            <comment id="15437430" author="yuzhihong@gmail.com" created="Thu, 25 Aug 2016 18:36:13 +0000"  >&lt;p&gt;During offline discussion, Vladimir suggested that we record the list of bulk loaded hfiles into hbase:backup table at the end of bulk load.&lt;/p&gt;</comment>
                            <comment id="15439447" author="yuzhihong@gmail.com" created="Fri, 26 Aug 2016 17:40:42 +0000"  >&lt;p&gt;There may be more than one round of bulk load between the full backup and incremental backup(s).&lt;br/&gt;
For each round, we may use timestamp of completion of bulk load for the loaded hfiles (in terms of record in hbase:backup).&lt;/p&gt;

&lt;p&gt;When the next incremental backup takes place, we consolidate all the recorded bulk loaded hfiles and save the list in manifest of the incremental backup.&lt;/p&gt;</comment>
                            <comment id="15449794" author="enis" created="Tue, 30 Aug 2016 18:44:50 +0000"  >&lt;p&gt;We should use a similar design for this issue with &quot;HFile replication&quot; via &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13153&quot; title=&quot;Bulk Loaded HFile Replication&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13153&quot;&gt;&lt;del&gt;HBASE-13153&lt;/del&gt;&lt;/a&gt;. Replication of hfiles is conceptually very similar to incremental bulk load, and we already have the tools. Please read the design doc and corresponding code. &lt;/p&gt;

&lt;p&gt;For this issue, we can mainly do this: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Similar to replication, everytime BL happens, we create a reference per incremental backup as a part of the BL process. These references can be saved in the hbase:backup table.&lt;/li&gt;
	&lt;li&gt;A custom hfile cleaner (like the ReplicationHFileCleaner) will monitor the bulk loaded hfiles, and makes sure that they are not deleted even after compactions, etc if there is still incremental backup to be performed.&lt;/li&gt;
	&lt;li&gt;Incremental backup will also copy the files that are from BL by referring to the references saved in hbase:backup table in the next round.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15449854" author="yuzhihong@gmail.com" created="Tue, 30 Aug 2016 19:08:59 +0000"  >&lt;p&gt;In backup package, a new class would be added which extends WALActionsListener.Base&lt;br/&gt;
It overrides postAppend() where we look for Cell with qualifier of WALEdit.BULK_LOAD.&lt;br/&gt;
If found, BulkLoadDescriptor is extracted and StoreDescriptor&apos;s can be retrieved.&lt;br/&gt;
The store file list would be persisted to hbase:backup table.&lt;/p&gt;</comment>
                            <comment id="15452524" author="yuzhihong@gmail.com" created="Wed, 31 Aug 2016 15:24:35 +0000"  >&lt;p&gt;ReplicationHFileCleaner retrieves hfile refs from zookeeper in order to check for deletable files.&lt;br/&gt;
The new BackupHFileCleaner would retrieve hfile refs by scanning hbase:backup table.&lt;br/&gt;
The hfile refs may be stored separately if no incremental / full backup has been performed since the bulk load or, in manifest of some incremental backup.&lt;br/&gt;
Since we don&apos;t know which incremental backup manifest may contain related hfile ref, we need to scan backwards until one incremental backup is found or, one full backup is found.&lt;/p&gt;</comment>
                            <comment id="15452786" author="vrodionov" created="Wed, 31 Aug 2016 17:12:27 +0000"  >&lt;p&gt;Delete file ref from hbase:backup after backup completes - do not keep them there forever.&lt;/p&gt;

&lt;p&gt;Now we have two different types of files in backup : HFile (snapshot/full), WAL (incremental). Bulk load adds third type - HFile (bulk load/incremental)&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;New storage layout for incremental backup image, that has bulk loaded files?&lt;/li&gt;
	&lt;li&gt;Shipping HFiles to backup destination during incremental backup?&lt;/li&gt;
	&lt;li&gt;The algorithm for restore incremental backup that has both : WALs and HFiles?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15452824" author="yuzhihong@gmail.com" created="Wed, 31 Aug 2016 17:27:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;Delete file ref from hbase:backup after backup completes&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Did you mean after restore completes ?&lt;br/&gt;
What if the user wants to restore to a different destination afterward ?&lt;br/&gt;
The removal of hfile ref from hbase:backup can be coupled with the deletion of backup(s).&lt;/p&gt;

&lt;p&gt;Restoring incremental backup would ship hfiles along with WAL files to destination.&lt;/p&gt;

&lt;p&gt;Suppose given this sequence of events where f means full backup, b means bulk load and i means incremental backup:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;f&lt;/li&gt;
	&lt;li&gt;b1 (with hfile1)&lt;/li&gt;
	&lt;li&gt;b2 (with hfile2)&lt;/li&gt;
	&lt;li&gt;i1&lt;/li&gt;
	&lt;li&gt;b3 (with hfile3)&lt;/li&gt;
	&lt;li&gt;i2&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The design of hfile ref in hbase:backup should make BackupHFileCleaner operation efficient.&lt;br/&gt;
If we consolidate hfile ref from b1 and b2 into i1, b3 into i2, BackupHFileCleaner needs to search backward (across all outstanding incremental backups): i2 -&amp;gt; i1 -&amp;gt; f.&lt;br/&gt;
If we consolidate hfile ref from b1 and b2 by merging them and storing b1&apos;, there is no need to search incremental backup(s).&lt;/p&gt;</comment>
                            <comment id="15452938" author="vrodionov" created="Wed, 31 Aug 2016 18:14:16 +0000"  >&lt;p&gt;I thought we need these HFile references in hbase:backup only until we ship them (bulk loaded files) to backup destination? What do we need them for after backup is complete and HFiles reached the backup destination, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;? &lt;/p&gt;</comment>
                            <comment id="15452950" author="yuzhihong@gmail.com" created="Wed, 31 Aug 2016 18:18:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;HFiles reached the backup destination&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The above is restore, right ?&lt;br/&gt;
For backup, we only keep hfile refs.&lt;/p&gt;</comment>
                            <comment id="15453063" author="vrodionov" created="Wed, 31 Aug 2016 18:57:18 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The above is restore, right ?&lt;br/&gt;
For backup, we only keep hfile refs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, for backup. Where are you going to keep bulkloaded files after backup is complete? Not sure, I am following you here.&lt;/p&gt;</comment>
                            <comment id="15453160" author="yuzhihong@gmail.com" created="Wed, 31 Aug 2016 19:37:31 +0000"  >&lt;p&gt;HFile references would stay, assisted by BackupHFileCleaner.&lt;br/&gt;
Please read the earlier comments.&lt;/p&gt;

&lt;p&gt;Suppose there&apos;re two backup sets involving common table(s). The bulk loaded hfiles for the common table should be shared by the two backups.&lt;/p&gt;</comment>
                            <comment id="15453728" author="vrodionov" created="Wed, 31 Aug 2016 23:36:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Suppose there&apos;re two backup sets involving common table(s). The bulk loaded hfiles for the common table should be shared by the two backups.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its fine. We keep backup data per table (in incremental mode), means, that we need ship bulk load only once to backup destination. Design doc, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;?  &lt;/p&gt;</comment>
                            <comment id="15453774" author="yuzhihong@gmail.com" created="Wed, 31 Aug 2016 23:54:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;we need ship bulk load only once to backup destination&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What about multiple restore destinations ?&lt;/p&gt;

&lt;p&gt;I can write up some doc after getting consensus.&lt;/p&gt;</comment>
                            <comment id="15453795" author="vrodionov" created="Thu, 1 Sep 2016 00:01:25 +0000"  >&lt;blockquote&gt;
&lt;p&gt;What about multiple restore destinations ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Multiple destination support is tricky, agree, this is why we need to see full design doc, step-by-step, to start a productive discussion.&lt;/p&gt;</comment>
                            <comment id="15510578" author="yuzhihong@gmail.com" created="Wed, 21 Sep 2016 17:25:54 +0000"  >&lt;p&gt;Patch v1 shows basic flow of bulk loaded hfiles support.&lt;/p&gt;

&lt;p&gt;To be added:&lt;br/&gt;
cleanup of BulkLoadDescriptor at the completion of full backup&lt;br/&gt;
BackupHFileCleaner which guards bulk loaded hfiles which are referenced by backup&lt;/p&gt;</comment>
                            <comment id="15511698" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 00:59:25 +0000"  >&lt;p&gt;I was adding new test which does one more full table backup after the incremental restore and verifies that BulkLoadDescriptor&apos;s are cleaned up from hbase:backup.&lt;br/&gt;
It turns out the bulk loaded hfiles were renamed during the incremental restore which resulted in FileNotFoundException.&lt;/p&gt;

&lt;p&gt;Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16672&quot; title=&quot;Add option for bulk load to always copy hfile(s) instead of renaming&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16672&quot;&gt;&lt;del&gt;HBASE-16672&lt;/del&gt;&lt;/a&gt; so that the bulk loaded hfiles can be used for multiple restore destinations.&lt;/p&gt;</comment>
                            <comment id="15511934" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 02:54:25 +0000"  >&lt;p&gt;Patch v2 adds second full back up in the test.&lt;/p&gt;

&lt;p&gt;Not working yet.&lt;/p&gt;</comment>
                            <comment id="15514628" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 22:12:53 +0000"  >&lt;p&gt;Currently there is one BulkLoadHandler inside each region server which writes BulkLoadDescriptor periodically to hbase:backup table.&lt;br/&gt;
Ideally only BulkLoadDescriptor&apos;s for tables which have gone through full backup should be written.&lt;/p&gt;

&lt;p&gt;Looking for a way to pass Set of such tables to region servers so that each server doesn&apos;t have to poll hbase:backup table periodically.&lt;/p&gt;</comment>
                            <comment id="15552566" author="yuzhihong@gmail.com" created="Thu, 6 Oct 2016 17:18:58 +0000"  >&lt;p&gt;Patch v6 is updated with current &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7912&quot; title=&quot;HBase Backup/Restore Based on HBase Snapshot&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7912&quot;&gt;HBASE-7912&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15563463" author="yuzhihong@gmail.com" created="Mon, 10 Oct 2016 20:49:49 +0000"  >&lt;p&gt;While working on BackupHFileCleaner, the counterpart to ReplicationHFileCleaner, I notice the potential impact on the server hosting hbase:backup because we need to have up-to-date information on the hfiles which are still referenced by the incremental backup.&lt;/p&gt;

&lt;p&gt;One potential approach is to store hfile information in zookeeper.&lt;br/&gt;
This would also alleviate the issue mentioned above about reducing writing BulkLoadDescriptor&apos;s to hbase:backup table.&lt;/p&gt;

&lt;p&gt;Any suggestions, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; ?&lt;/p&gt;</comment>
                            <comment id="15563507" author="vrodionov" created="Mon, 10 Oct 2016 21:07:50 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; One potential approach is to store hfile information in zookeeper.&lt;/p&gt;

&lt;p&gt;-1. No Zk, please.&lt;/p&gt;</comment>
                            <comment id="15564243" author="yuzhihong@gmail.com" created="Tue, 11 Oct 2016 02:48:48 +0000"  >&lt;p&gt;Constructive suggestion is welcome.&lt;/p&gt;</comment>
                            <comment id="15589103" author="yuzhihong@gmail.com" created="Wed, 19 Oct 2016 15:52:59 +0000"  >&lt;p&gt;Patch v11 rebased on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7912&quot; title=&quot;HBase Backup/Restore Based on HBase Snapshot&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7912&quot;&gt;HBASE-7912&lt;/a&gt; branch.&lt;/p&gt;</comment>
                            <comment id="15589109" author="yuzhihong@gmail.com" created="Wed, 19 Oct 2016 15:55:28 +0000"  >&lt;p&gt;Discussed with Enis.&lt;br/&gt;
The persistence of bulk loaded hfiles should be synchronous with the bulk load.&lt;br/&gt;
Writing to hbase:backup table through postAppend() hook is tricky.&lt;/p&gt;

&lt;p&gt;The precedent of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13153&quot; title=&quot;Bulk Loaded HFile Replication&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13153&quot;&gt;&lt;del&gt;HBASE-13153&lt;/del&gt;&lt;/a&gt; can be used for the persistence of reference to bulk loaded hfiles.&lt;/p&gt;</comment>
                            <comment id="15595673" author="yuzhihong@gmail.com" created="Fri, 21 Oct 2016 16:56:13 +0000"  >&lt;p&gt;In patch v13, BulkLoadHandler stores bulk loaded hfiles in zookeeper.&lt;/p&gt;</comment>
                            <comment id="15605689" author="yuzhihong@gmail.com" created="Tue, 25 Oct 2016 16:01:02 +0000"  >&lt;p&gt;When running TestFullRestore, I found an interesting issue: bulk load can happen to the table which is fully backed up - when overwrite option is specified.&lt;/p&gt;

&lt;p&gt;I can think of two ways to omit these bulk loaded files:&lt;br/&gt;
1. under backup zookeeper subtree, create znode with tables which are being restored to with overwrite option. This allows the postAppend() hook to skip these tables for the duration of the restore&lt;br/&gt;
2. at the end of bulk load, issue deletes against the znodes which are added during the bulk load&lt;/p&gt;

&lt;p&gt;I am leaning toward first option.&lt;/p&gt;</comment>
                            <comment id="15605864" author="yuzhihong@gmail.com" created="Tue, 25 Oct 2016 17:04:19 +0000"  >&lt;p&gt;In IncrementalTableBackupClient, before marking the backup complete, I am adding code to copy the bulk loaded hfiles to destination filesystem and persist the list of copied files to hbase:backup table.&lt;/p&gt;</comment>
                            <comment id="15613220" author="yuzhihong@gmail.com" created="Thu, 27 Oct 2016 21:11:15 +0000"  >&lt;p&gt;Patch v23 is working version.&lt;/p&gt;

&lt;p&gt;All backup / restore tests pass.&lt;/p&gt;</comment>
                            <comment id="15622755" author="yuzhihong@gmail.com" created="Mon, 31 Oct 2016 17:10:50 +0000"  >&lt;p&gt;Patch v24 registers tables being fully backed up in zookeeper so that BulkLoadHandler on respective region server can avoid unnecessary post to zookeeper.&lt;/p&gt;</comment>
                            <comment id="15622790" author="vrodionov" created="Mon, 31 Oct 2016 17:23:05 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Patch v24 registers tables being fully backed up in zookeeper so that BulkLoadHandler on respective region server can avoid unnecessary post to zookeeper.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why can not we use hbase:backup table for that?&lt;/p&gt;</comment>
                            <comment id="15622809" author="yuzhihong@gmail.com" created="Mon, 31 Oct 2016 17:31:23 +0000"  >&lt;p&gt;hbase:backup table is used to retrieve Set of tables which have gone through full backup after region server comes up (since the region server may have missed prior zk notifications).&lt;br/&gt;
Afterwards, BulkLoadHandler would receive notifications from zookeeper and doesn&apos;t need to poll hbase:backup table.&lt;/p&gt;</comment>
                            <comment id="15623137" author="vrodionov" created="Mon, 31 Oct 2016 19:38:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;tedyu@apache.org&quot;&gt;Ted Yu&lt;/a&gt;, is patch ready for review? If yes, then please open review on RB.&lt;/p&gt;</comment>
                            <comment id="15625901" author="yuzhihong@gmail.com" created="Tue, 1 Nov 2016 16:35:09 +0000"  >&lt;p&gt;Patch v25 deletes the copied bulk loaded files upon deletion of backup.&lt;/p&gt;

&lt;p&gt;There is some enhancement in LoadIncrementalHFiles which is only in master branch.&lt;br/&gt;
I would wait after the merge before publishing review request.&lt;/p&gt;</comment>
                            <comment id="15626239" author="stack" created="Tue, 1 Nov 2016 18:22:36 +0000"  >&lt;p&gt;I like what &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; asks here. We are busy elsewhere trying to undo our reliance on zk for all but the bare minimum yet here we are dev&apos;ing new features on it. &lt;/p&gt;</comment>
                            <comment id="15629369" author="yuzhihong@gmail.com" created="Wed, 2 Nov 2016 15:49:11 +0000"  >&lt;p&gt;I observed this in the TestHRegionServerBulkLoad-output for the version (v11 and earlier) where bulk load marker is written directly to hbase:backup table in postAppend hook:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2016-09-13 23:10:14,072 DEBUG [B.defaultRpcServer.handler=4,queue=0,port=35667] ipc.CallRunner(112): B.defaultRpcServer.handler=4,queue=0,port=35667: callId: 10646 service: ClientService methodName: Scan size: 264 connection:    172.18.128.12:59780
org.apache.hadoop.hbase.RegionTooBusyException: failed to get a lock in 60000 ms. regionName=atomicBulkLoad,,1473808150804.6b6c67612b01bce3348c144b959b7f0e., server=cn012.l42scl.hortonworks.com,35667,1473808145352
  at org.apache.hadoop.hbase.regionserver.HRegion.lock(HRegion.java:7744)
  at org.apache.hadoop.hbase.regionserver.HRegion.lock(HRegion.java:7725)
  at org.apache.hadoop.hbase.regionserver.HRegion.startRegionOperation(HRegion.java:7634)
  at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2588)
  at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2582)
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2569)
  at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33516)
  at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2229)
  at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)
  at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:136)
  at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:111)
  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here was the state of the BulkLoadHandler thread (stuck):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;RS:0;cn012:36301.append-pool9-t1&quot;&lt;/span&gt; #453 prio=5 os_prio=0 tid=0x00007fc3945bb000 nid=0x18ec in &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() [0x00007fc30dada000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: TIMED_WAITING (on object monitor)
  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method)
  at org.apache.hadoop.hbase.client.AsyncProcess.waitForMaximumCurrentTasks(AsyncProcess.java:1727)
  - locked &amp;lt;0x0000000794750580&amp;gt; (a java.util.concurrent.atomic.AtomicLong)
  at org.apache.hadoop.hbase.client.AsyncProcess.waitForAllPreviousOpsAndReset(AsyncProcess.java:1756)
  at org.apache.hadoop.hbase.client.BufferedMutatorImpl.backgroundFlushCommits(BufferedMutatorImpl.java:241)
  at org.apache.hadoop.hbase.client.BufferedMutatorImpl.flush(BufferedMutatorImpl.java:191)
  - locked &amp;lt;0x0000000794750048&amp;gt; (a org.apache.hadoop.hbase.client.BufferedMutatorImpl)
  at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:949)
  at org.apache.hadoop.hbase.client.HTable.put(HTable.java:569)
  at org.apache.hadoop.hbase.backup.impl.BackupSystemTable.writeBulkLoadDesc(BackupSystemTable.java:227)
  at org.apache.hadoop.hbase.backup.impl.BulkLoadHandler.postAppend(BulkLoadHandler.java:83)
  at org.apache.hadoop.hbase.regionserver.wal.FSHLog.postAppend(FSHLog.java:1448)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Even increasing handler count didn&apos;t help:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/hbase-server/src/test/resources/hbase-site.xml b/hbase-server/src/test/resources/hbase-site.xml
index bca90a3..829fcc9 100644
--- a/hbase-server/src/test/resources/hbase-site.xml
+++ b/hbase-server/src/test/resources/hbase-site.xml
@@ -30,6 +30,10 @@
     &amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
+    &amp;lt;name&amp;gt;hbase.backup.enable&amp;lt;/name&amp;gt;
+    &amp;lt;value&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&amp;lt;/value&amp;gt;
+  &amp;lt;/property&amp;gt;
+  &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hbase.defaults.&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;.version.skip&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
@@ -48,11 +52,11 @@
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hbase.regionserver.handler.count&amp;lt;/name&amp;gt;
-    &amp;lt;value&amp;gt;5&amp;lt;/value&amp;gt;
+    &amp;lt;value&amp;gt;50&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Post v11, the data stored in zookeeper is temporary: once an incremental backup is run for the table receiving bulk load, data in zookeeper would be stored for the backup Id in the backup table and removed from zookeeper.&lt;/p&gt;</comment>
                            <comment id="15629891" author="vrodionov" created="Wed, 2 Nov 2016 18:16:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;, calling remote region in postAppend hook does not look like a good idea. How about putting all this logic into RSRpcServices.bulkLoadHFile? Not necessary do synchronous call, you can use queue and update backup table on bulk load finish.&lt;/p&gt;</comment>
                            <comment id="15638081" author="devaraj" created="Fri, 4 Nov 2016 23:45:22 +0000"  >&lt;p&gt;A summary of some internal discussions on the high-level flow that doesn&apos;t use ZK...&lt;br/&gt;
1. Client updates the hbase:backup table with a set of paths that are to be bulkloaded (if the tables in question have been fully backed up at least once in the past)&lt;br/&gt;
2. Client performs the bulkload of the data. If the client fails before the bulkload was fully complete, the cleaner chore in (5) would take care of cleaning up the unneeded entries from hbase:backup&lt;br/&gt;
3. There is a HFileCleaner that makes sure that paths that came about due to (1) are held until the next incremental backup&lt;br/&gt;
4. As part of the incremental backup, the hbase:backup table is updated to reflect the right location where the earlier bulkloaded file got copied to&lt;br/&gt;
5. A chore runs periodically (in the BackupController) that eliminates entries from the hbase:backup table if the corresponding paths don&apos;t exist in the filesystem until after a configured time period (default, say 24 hours; bulkload timeout is assumed to be much smaller than this, and hence all bulkloads that are meant to successfully complete would complete).&lt;br/&gt;
Thoughts?&lt;/p&gt;</comment>
                            <comment id="15650599" author="yuzhihong@gmail.com" created="Wed, 9 Nov 2016 10:40:43 +0000"  >&lt;p&gt;I am proceeding to implement the above proposal.&lt;/p&gt;</comment>
                            <comment id="15684763" author="yuzhihong@gmail.com" created="Mon, 21 Nov 2016 21:21:22 +0000"  >&lt;p&gt;14417-tbl-ext.v9.txt is based on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17123&quot; title=&quot;Add postBulkLoadHFile variant that notifies the final paths for the hfiles&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17123&quot;&gt;&lt;del&gt;HBASE-17123&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;All bulk load and backup related tests pass.&lt;/p&gt;

&lt;p&gt;There is no zookeeper involved.&lt;/p&gt;</comment>
                            <comment id="15685093" author="yuzhihong@gmail.com" created="Mon, 21 Nov 2016 23:30:55 +0000"  >&lt;p&gt;org.apache.hadoop.hbase.backup.BackupHFileCleaner should be registered through hbase.master.hfilecleaner.plugins . It is responsible for keeping bulk loaded hfiles so that incremental backup can pick them up.&lt;br/&gt;
org.apache.hadoop.hbase.backup.BackupObserver should be registered through hbase.coprocessor.region.classes&lt;br/&gt;
It is notified when bulk load completes and writes records into hbase:backup table.&lt;/p&gt;</comment>
                            <comment id="15694965" author="ashish singhi" created="Fri, 25 Nov 2016 06:17:09 +0000"  >&lt;p&gt;Can you upload the patch on RB. It will be easy to review.&lt;/p&gt;</comment>
                            <comment id="15712616" author="yuzhihong@gmail.com" created="Thu, 1 Dec 2016 18:03:09 +0000"  >&lt;p&gt;Due to lack of access to gmail, I didn&apos;t see the above until several minutes ago.&lt;/p&gt;

&lt;p&gt;Here is the review board:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/54258/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/54258/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15715023" author="ashish singhi" created="Fri, 2 Dec 2016 12:38:07 +0000"  >&lt;p&gt;I don&apos;t want to block this jira. I will be on holiday for next two weeks so will not be able to check this before that. If any one else is fine with the patch pls go ahead and commit it. I will review it later.&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="15730046" author="yuzhihong@gmail.com" created="Wed, 7 Dec 2016 21:57:41 +0000"  >&lt;p&gt;Patch 14417-tbl-ext.v10.txt is rebased on mega patch v40.&lt;/p&gt;</comment>
                            <comment id="15732531" author="yuzhihong@gmail.com" created="Thu, 8 Dec 2016 15:34:37 +0000"  >&lt;p&gt;More response to Vlad&apos;s review comment w.r.t. fault tolerance in bulk load.&lt;/p&gt;

&lt;p&gt;When bulk load fails midway, the user should provide complete set of hfiles again because the staging directory is not exposed to end users.&lt;br/&gt;
With this in mind, the benefit of using another hook (prior to postBulkLoadHFile()) to persist location of bulk loaded hfiles is minimal - since in subsequent bulk load attempt(s), the same set of (source) hfiles would be loaded again.&lt;/p&gt;

&lt;p&gt;Another factor is that the more writes to hbase:backup table, the higher the chance of getting (write) failure.&lt;/p&gt;

&lt;p&gt;One optimization we can do in the future is to combine writes (performed in postBulkLoadHFile()) from several regions on the same region server, provided that these writes are sufficiently close (300 ms apart, e.g.). The completion of bulk load on a single region server is determined by the slowest participating region, so this optimization would keep the response time on par with the current implementation (where hbase:backup table is not involed).&lt;/p&gt;</comment>
                            <comment id="15733183" author="yuzhihong@gmail.com" created="Thu, 8 Dec 2016 19:25:58 +0000"  >&lt;p&gt;The sequence Id for bulk loaded hfile is generated inside HRegion#bulkLoadHFiles().&lt;br/&gt;
Coming out of bulkLoadHFiles() call, postBulkLoadHFile() hook is called with actual file names.&lt;/p&gt;</comment>
                            <comment id="15733635" author="yuzhihong@gmail.com" created="Thu, 8 Dec 2016 22:50:47 +0000"  >&lt;p&gt;The final filename is available here in HRegion#bulkLoadHFiles() :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          Path commitedStoreFile = store.bulkLoadHFile(finalPath, seqId);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If we add one more hook above which records final filename in hbase:backup table, we still depend on postBulkLoadHFile() hook to write final filename one more time (with state of completion) - because bulk load event persistence (done in finally block) may fail. Meaning BackupHFileCleaner wouldn&apos;t have enough information whether the bulk load succeeded by simply checking the existence of store file(s) in region directory:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-comment&quot;&gt;// write a bulk load event when not all hfiles are loaded
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          WALProtos.BulkLoadDescriptor loadDescriptor = ProtobufUtil.toBulkLoadDescriptor(
              &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.getRegionInfo().getTable(),
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15733829" author="yuzhihong@gmail.com" created="Fri, 9 Dec 2016 00:28:55 +0000"  >&lt;p&gt;In patch v11, postBulkLoadHFile() would return false for hasLoaded if the write to hbase:backup table doesn&apos;t go through.&lt;/p&gt;

&lt;p&gt;This would trigger retry mechanism in LoadIncrementalHFiles.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12863549">HBASE-14414</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12842220" name="14417-tbl-ext.v10.txt" size="67530" author="yuzhihong@gmail.com" created="Wed, 7 Dec 2016 21:57:41 +0000"/>
                            <attachment id="12842452" name="14417-tbl-ext.v11.txt" size="67866" author="yuzhihong@gmail.com" created="Fri, 9 Dec 2016 00:28:55 +0000"/>
                            <attachment id="12839890" name="14417-tbl-ext.v9.txt" size="68495" author="yuzhihong@gmail.com" created="Mon, 21 Nov 2016 21:21:22 +0000"/>
                            <attachment id="12829627" name="14417.v1.txt" size="66623" author="yuzhihong@gmail.com" created="Wed, 21 Sep 2016 17:25:54 +0000"/>
                            <attachment id="12834189" name="14417.v11.txt" size="53458" author="yuzhihong@gmail.com" created="Wed, 19 Oct 2016 15:52:59 +0000"/>
                            <attachment id="12834708" name="14417.v13.txt" size="59777" author="yuzhihong@gmail.com" created="Fri, 21 Oct 2016 16:56:13 +0000"/>
                            <attachment id="12829744" name="14417.v2.txt" size="70644" author="yuzhihong@gmail.com" created="Thu, 22 Sep 2016 02:54:25 +0000"/>
                            <attachment id="12835392" name="14417.v21.txt" size="75311" author="yuzhihong@gmail.com" created="Wed, 26 Oct 2016 18:24:20 +0000"/>
                            <attachment id="12835665" name="14417.v23.txt" size="75799" author="yuzhihong@gmail.com" created="Thu, 27 Oct 2016 21:11:15 +0000"/>
                            <attachment id="12836179" name="14417.v24.txt" size="82609" author="yuzhihong@gmail.com" created="Mon, 31 Oct 2016 17:10:50 +0000"/>
                            <attachment id="12836405" name="14417.v25.txt" size="85442" author="yuzhihong@gmail.com" created="Tue, 1 Nov 2016 18:04:23 +0000"/>
                            <attachment id="12831997" name="14417.v6.txt" size="43937" author="yuzhihong@gmail.com" created="Thu, 6 Oct 2016 17:18:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 8 Jul 2016 22:13:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 week ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2k2xb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>