<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:54:16 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8338/HBASE-8338.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8338] Latency Resilience; umbrella list of issues that will help us ride over bad disk, bad region, ec2, etc.</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8338</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Chatting w/ Elliott, we started listing out items to fix that would help keep hbase latency approximately constant as disks went bad, were saturated by a neighbour (ec2), etc.&lt;/p&gt;

&lt;p&gt;I must made a new LatencyResilience issue category to tag issues that contribute to this project.&lt;/p&gt;

&lt;p&gt;I have to go at moment but when I get back I&apos;ll start to link in existing issues that help this project along and I&apos;ll file new ones.&lt;/p&gt;

&lt;p&gt;Here is what we chatted about:&lt;/p&gt;

&lt;p&gt;+ Multiple WALs effort will help keep write latency roughly constant.&lt;br/&gt;
+ Figuring how to get a new read started over dfsclient if current replica read is taking too long would help keep reads about constant (maybe could exploit the nkeywal hackery messing w/ replicas order).&lt;br/&gt;
+ There is an issue where client can currently pile up on a single region because of the way we do client queues by regionserver.  This needs fixing.&lt;/p&gt;

&lt;p&gt;The above are few ideas worth further exploration at least.&lt;/p&gt;

&lt;p&gt;Idea is to try and bring down our 95percentiles and to make us more robust in the face of dying disks, etc.  I see this issue rising to the fore now there has been good progress on the MTTR project.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12642305">HBASE-8338</key>
            <summary>Latency Resilience; umbrella list of issues that will help us ride over bad disk, bad region, ec2, etc.</summary>
                <type id="14" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Umbrella</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Fri, 12 Apr 2013 19:33:24 +0000</created>
                <updated>Wed, 1 May 2013 01:58:18 +0000</updated>
                                                                            <component>LatencyResilience</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>26</watches>
                                                                <comments>
                            <comment id="13630535" author="nkeywal" created="Fri, 12 Apr 2013 19:38:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;There is an issue where client can currently pile up on a single region because of the way we do client queues by regionserver. This needs fixing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This should be fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;. While it&apos;s still a hack from a code point of view, I plan to keep the general approach of the implementation.&lt;/p&gt;</comment>
                            <comment id="13630543" author="eclark" created="Fri, 12 Apr 2013 19:44:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; Yep that&apos;s almost exactly what we were thinking for the client queuing problem.  I had forgotten about processBatchCallback in HConnection.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13630830" author="stack" created="Sat, 13 Apr 2013 00:42:49 +0000"  >&lt;p&gt;Adding to a related link that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; is working on.  This looks like &apos;There is an issue where client can currently pile up on....&apos; from above.&lt;/p&gt;</comment>
                            <comment id="13630833" author="stack" created="Sat, 13 Apr 2013 00:47:48 +0000"  >&lt;p&gt;I linked multiple wals and what Nicolas is working on.  Regards getting a new read started if a replica is slow from dfsclient, will do some digging first to see if it is even possible before filing an issue.&lt;/p&gt;</comment>
                            <comment id="13630834" author="stack" created="Sat, 13 Apr 2013 00:48:13 +0000"  >&lt;p&gt;Marking this a critical project.&lt;/p&gt;</comment>
                            <comment id="13630866" author="aoxiang" created="Sat, 13 Apr 2013 02:13:55 +0000"  >&lt;p&gt;I think hdfs quorum reads is important for read&#65292;facebook already implement this.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;http://research.google.com/people/jeff/latency.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://research.google.com/people/jeff/latency.html&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
http:&lt;span class=&quot;code-comment&quot;&gt;//svn.apache.org/viewvc/hbase/branches/0.89-fb/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java?view=log
&lt;/span&gt;[89-fb] [HBASE-7509] Regionserver support to control quorum reads

Author: aaiyer

Summary:
It will be good to have the ability to control the
paramaters &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; quorum reads &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; the regionserver is still running.

We want to control:
  1) the timeout that we wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;, before initiating the second read.
  2) number of threads allocated &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; quorum reads
     - setting &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to 0 will disable quorum reads

 Depends on the quorum diff in HDFS to add the DFSClient calls.
https:&lt;span class=&quot;code-comment&quot;&gt;//phabricator.fb.com/D615354&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13631111" author="ram_krish" created="Sat, 13 Apr 2013 17:54:08 +0000"  >&lt;p&gt;I would like to work/help on multiple WAL.  &lt;br/&gt;
I feel there are multiple usecases that i can support too.&lt;/p&gt;</comment>
                            <comment id="13631158" author="stack" created="Sat, 13 Apr 2013 21:04:55 +0000"  >&lt;p&gt;Linking hbase-7509 (thanks Binlijin).  Looking in the 0.89-fb branch, though it claims hbase-7509 is fixed, it is something else that is fixed.  &quot;Export quorum metrics from HRegionServer&quot; is fixed not &quot;Enable RS to query a secondary datanode in parallel, if the primary takes too long&quot; which sounds more interesting (I asked the lads whats up w/ the diff and if stuff missing from 0.89-fb branch).&lt;/p&gt;</comment>
                            <comment id="13631159" author="stack" created="Sat, 13 Apr 2013 21:05:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Would suggest reading over the old multi-wal ticket set.  There is a bunch of good discussion in them.&lt;/p&gt;</comment>
                            <comment id="13638381" author="nkeywal" created="Mon, 22 Apr 2013 20:03:17 +0000"  >&lt;p&gt;Some general configuration:&lt;br/&gt;
I hope 6295 solves the &apos;temporary slow or non responding machine&apos; issue. Then, as we are today, I think that we more or less doomed to be &apos;as slow as the slowest&apos;. The usual solutions for this are use an asynchronous client / send large buffer to get a chance to go the average result.&lt;/p&gt;

&lt;p&gt;But more fundamentally, we really need the cluster to be well balanced. If we want this, we need more than a global balancer imho: we need the regionserver to prioritize the queries.&lt;br/&gt;
In other words there are 3 cases of unbalanced clusters:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;long term (difference in machine for example): this should be managed by the balancer we have today&lt;/li&gt;
	&lt;li&gt;short term (dead machine, GC issue, ...): &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;, i.e. asynchronous/large buffer&lt;/li&gt;
	&lt;li&gt;medium term (specific temporary load on a machine, compactions, ...): client and regionserver priorities. 6295 has a bit of a priority feature t(the number of task).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13645796" author="stack" created="Tue, 30 Apr 2013 18:09:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt; helps a bunch but we still need more along this direction; if a region is totally dead we&apos;ll ultimately block all in/out if we accumulate data for this region that makes us hit global limit.  We need a way to exclude bad regions completely so never blocks access to all other regions.&lt;/p&gt;</comment>
                            <comment id="13645813" author="nkeywal" created="Tue, 30 Apr 2013 18:25:56 +0000"  >&lt;p&gt;Agreed, but it can&apos;t be done without the client application: it was writing something and writing this something can&apos;t be done as the region is not there. For example, we have a callback during the put process. We call this callback only on success. We could call it on failure, and let the user decides:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ignore&lt;/li&gt;
	&lt;li&gt;stop (today&apos;s behavior)&lt;/li&gt;
	&lt;li&gt;replace.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;basically the callback would return a boolean to let the process continue or not.&lt;/p&gt;

&lt;p&gt;It&apos;s quite easy to do, if that&apos;s what we want...&lt;/p&gt;</comment>
                            <comment id="13646296" author="enis" created="Wed, 1 May 2013 01:58:18 +0000"  >&lt;p&gt;Related, there is this idea of opening two wal writers, and switching to the other one, if we run into slowness, which is mentioned in the Bigtable paper. Do we have a jira for something similar? It might be addressed at multi-wal as well. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12626380">HBASE-7509</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12549194">HBASE-5699</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12596502">HBASE-6295</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 12 Apr 2013 19:38:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>322719</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 33 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1johz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323064</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>