<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:15:09 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-4018/HBASE-4018.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-4018] Attach memcached as secondary block cache to regionserver</title>
                <link>https://issues.apache.org/jira/browse/HBASE-4018</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently, block caches are limited by heap size, which is limited by garbage collection times in Java.&lt;/p&gt;

&lt;p&gt;We can get around this by using memcached w/JNI as a secondary block cache. This should be faster than the linux file system&apos;s caching, and allow us to very quickly gain access to a high quality slab allocated cache.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12511264">HBASE-4018</key>
            <summary>Attach memcached as secondary block cache to regionserver</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="li">Li Pi</assignee>
                                    <reporter username="li">Li Pi</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jun 2011 17:22:31 +0000</created>
                <updated>Tue, 19 Jul 2011 19:58:29 +0000</updated>
                            <resolved>Tue, 19 Jul 2011 19:58:29 +0000</resolved>
                                                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13053418" author="jasonrutherglen" created="Wed, 22 Jun 2011 19:39:38 +0000"  >&lt;p&gt;Does this mean a cache on another server?  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This should be faster than the linux file system&apos;s caching&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why is that?&lt;/p&gt;</comment>
                            <comment id="13053445" author="li" created="Wed, 22 Jun 2011 20:19:05 +0000"  >&lt;p&gt;Memcached on the same server - thus JNI rather than TCP. I currently have it working over TCP, but thats slower.&lt;/p&gt;</comment>
                            <comment id="13053446" author="streamy" created="Wed, 22 Jun 2011 20:19:10 +0000"  >&lt;p&gt;The perf gain over the FS caching would be less-so if using short-circuited local reads.  But anything that bypasses the DataNode is great for random read perf.&lt;/p&gt;

&lt;p&gt;Even still, making a copy out of in-process memory should be faster than linux fs caching.&lt;/p&gt;</comment>
                            <comment id="13053453" author="li" created="Wed, 22 Jun 2011 20:28:27 +0000"  >&lt;p&gt;Optimal solution would be building a slab allocated block cache within java. Use reference counting for a zero copy solution. This is difficult to implement and debug though.&lt;/p&gt;

&lt;p&gt;Memcached is already well debugged and optimized.&lt;/p&gt;</comment>
                            <comment id="13053454" author="jasonrutherglen" created="Wed, 22 Jun 2011 20:28:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;Even still, making a copy out of in-process memory should be faster than linux fs caching.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why&apos;s that?  For a base reference Lucene relies on the filesystem cache and makes use of Java&apos;s memory map capability to deliver very fast results.  It would seem best to move in the direction of local HDFS file access and allow plugging in the block cache as a point of comparison / legacy.&lt;/p&gt;</comment>
                            <comment id="13053486" author="streamy" created="Wed, 22 Jun 2011 21:44:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;Optimal solution would be building a slab allocated block cache within java. Use reference counting for a zero copy solution. This is difficult to implement and debug though.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m working on this.  I think implementing both directions is worthwhile and we can run good comparisons (including against linux fs cache + local datanodes).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It would seem best to move in the direction of local HDFS file access and allow plugging in the block cache as a point of comparison / legacy.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it&apos;s best to move in all directions and do comparisons.  I&apos;ve already seen performance differences between fs cache and the actual hbase block cache.  There&apos;s also compressed vs. decompressed (fs cache will always be compressed)&lt;/p&gt;</comment>
                            <comment id="13053628" author="li" created="Thu, 23 Jun 2011 03:18:24 +0000"  >&lt;p&gt;To add on that, the fs cache isn&apos;t the best thing to rely on. What if some user uses the node, runs a package manager to update things, or uses scp to get things off the server? the fs cache is likely to get screwed.&lt;/p&gt;

&lt;p&gt;I found out memcached supports domain sockets, I&apos;m now working on implementing this around domain sockets.&lt;/p&gt;</comment>
                            <comment id="13053646" author="tlipcon" created="Thu, 23 Jun 2011 04:37:23 +0000"  >&lt;p&gt;I don&apos;t imagine the Java client will support domain sockets, since they don&apos;t exist in Java.&lt;/p&gt;

&lt;p&gt;I agree it&apos;s worth looking at all these options in parallel and doing some shootouts to at least understand the performance differences.&lt;/p&gt;</comment>
                            <comment id="13053998" author="li" created="Thu, 23 Jun 2011 17:40:02 +0000"  >&lt;p&gt;Java has a JNI domain sockets library - though at that point you might as well go JNI -&amp;gt; Memcached directly. But my C-fu is weaker than expected, and this is taking me longer than it should.&lt;/p&gt;</comment>
                            <comment id="13054156" author="jasonrutherglen" created="Thu, 23 Jun 2011 22:54:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;fs cache will always be compressed&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s likely where the slowdown occurs.  I agree the values should be compressed, in many cases the CPU overhead dwarfs (or should) the extra RAM consumption from uncompressing into heap space.  Right now in HBase there&apos;s effectively a page fault when a block isn&apos;t in the cache, eg it then loads from disk or network and uncompress&apos;es into RAM while &lt;span class=&quot;error&quot;&gt;&amp;#91;likely&amp;#93;&lt;/span&gt; also removing existing pages/blocks.  That seems likely to be problematic.&lt;/p&gt;

&lt;p&gt;CPU should be cheaper than RAM especially for HBase which logically should be IO bound.  This is also true of search, eg compression of posting lists is implemented using vint or PFOR, instead of laying all the ints out on disk.  Search then becomes CPU bound from the iteration of multiple posting lists.  HBase is iterating one effective &quot;list&quot; though the compression algorithm likely consumes far greater CPU.  Perhaps it&apos;s easily offset with a less intensive comp algorithm.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What if some user uses the node, runs a package manager to update things, or uses scp to get things off the server? the fs cache is likely to get screwed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The fs cache becoming invalid in the examples given would be few and far between.  More worrisome is the block/page fault issue that I&apos;m assuming can happen frequently at the moment.  I guess one could always set the block cache to be quite small, and make the block sizes on the small side as well.  Effectively shifting the problem back to the system IO cache.&lt;/p&gt;

&lt;p&gt;I think we need to benchmark.  Also running yet another process on an HBase node sounds scary.  &lt;/p&gt;</comment>
                            <comment id="13054172" author="streamy" created="Thu, 23 Jun 2011 23:26:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;in many cases the CPU overhead dwarfs (or should) the extra RAM consumption from uncompressing into heap space.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not necessarily the case.  Many applications see 4-5X compression ratio and it means being able to increase your cache capacity by that much.  Some applications can also be CPU bound, or the might be IO bound, or they might actually be IO bound because they are RAM bound (can&apos;t fit working set in memory).  In general, it&apos;s hard to generalize here I think.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Perhaps it&apos;s easily offset with a less intensive comp algorithm.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s one of the major motivations for an hbase-specific &quot;prefix&quot; compression algorithm&lt;/p&gt;</comment>
                            <comment id="13054180" author="jasonrutherglen" created="Thu, 23 Jun 2011 23:43:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;Some applications can also be CPU bound&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The main user of CPU with HBase should be &lt;span class=&quot;error&quot;&gt;&amp;#91;de&amp;#93;&lt;/span&gt;compression?  In just browsing the BigTable paper, they mention caching individual key-values for applications that require random reads.  If an application is more scan oriented, then the block cache makes sense for the duration of the scan of that block.  The paper also goes on to describe compression per-row vs. per-block.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That&apos;s one of the major motivations for an hbase-specific &quot;prefix&quot; compression algorithm&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;However that&apos;s only for keys which is a separate discussion.&lt;/p&gt;</comment>
                            <comment id="13054194" author="jasonrutherglen" created="Fri, 24 Jun 2011 00:37:28 +0000"  >&lt;p&gt;I understand the problem you&apos;re trying to solve here a little better, eg, the block cache and the GC.  Perhaps JNA &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; can also be used for this use case, eg &lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; enables direct creation and destruction of an array (unlike direct byte buffers which doesn&apos;t enable &apos;direct&apos; destruction).&lt;/p&gt;

&lt;p&gt;1. &lt;a href=&quot;https://github.com/twall/jna&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/twall/jna&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2. &lt;a href=&quot;https://github.com/twall/jna/blob/master/src/com/sun/jna/Memory.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/twall/jna/blob/master/src/com/sun/jna/Memory.java&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13067925" author="li" created="Tue, 19 Jul 2011 19:56:55 +0000"  >&lt;p&gt;I just went directly to direct byte buffers. See 4027. Closing this for now.&lt;/p&gt;</comment>
                            <comment id="13067927" author="li" created="Tue, 19 Jul 2011 19:58:29 +0000"  >&lt;p&gt;Wrote slab allocator in java using directbytebuffers instead of using memcached. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4027&quot; title=&quot;Enable direct byte buffers LruBlockCache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4027&quot;&gt;&lt;del&gt;HBASE-4027&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jun 2011 19:39:38 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33327</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hp07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101313</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>