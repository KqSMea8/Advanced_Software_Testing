<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:12:18 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3692/HBASE-3692.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3692] Handle RejectedExecutionException in HTable</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3692</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;A user on IRC yesterday had an issue with RejectedExecutionException coming out of HTable sometimes. Apart from being very confusing to the user as it comes with no message at all, it exposes the HTable internals. &lt;/p&gt;

&lt;p&gt;I think we should handle it and instead throw something like DontUseHTableInMultipleThreadsException or something more clever. In his case, the user had a HTable leak with the pool that he was able to figure out once I told him what to look for.&lt;/p&gt;

&lt;p&gt;It could be an unchecked exception and we could consider adding in 0.90 but marking for 0.92 at the moment.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12502204">HBASE-3692</key>
            <summary>Handle RejectedExecutionException in HTable</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 Mar 2011 17:18:02 +0000</created>
                <updated>Sat, 11 Apr 2015 01:20:36 +0000</updated>
                            <resolved>Sat, 11 Apr 2015 01:20:36 +0000</resolved>
                                    <version>0.90.1</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13010238" author="eonnen" created="Wed, 23 Mar 2011 17:26:22 +0000"  >&lt;p&gt;The root cause in this case was that I didn&apos;t return the table reference to the HTabelPool I was using. After enough activity, the table&apos;s work queue backed up resulting in the exception. Maybe the addition of a finalizer to the HTableInterface class causing the reference to release itself from the pool would prevent coding mistakes like this one?&lt;/p&gt;</comment>
                            <comment id="13010247" author="yuzhihong@gmail.com" created="Wed, 23 Mar 2011 17:36:40 +0000"  >&lt;p&gt;How about enriching RejectedExecutionException message reminding user that HTable reference should be returned to the pool ?&lt;/p&gt;</comment>
                            <comment id="13010277" author="eonnen" created="Wed, 23 Mar 2011 18:21:20 +0000"  >&lt;p&gt;Not sure that would be always correct. The pool has a finite number of tasks it can accept and if the back end servers are overloaded it&apos;s possible that you falsely blame incorrect code when in reality you&apos;re overwhelming the region servers.&lt;/p&gt;</comment>
                            <comment id="13012231" author="iamknome" created="Mon, 28 Mar 2011 21:25:49 +0000"  >&lt;p&gt;Erik:&lt;/p&gt;

&lt;p&gt;Could you please help with some hint on how to recreate this problem so I can work on a possible fix? &lt;/p&gt;</comment>
                            <comment id="13012329" author="iamknome" created="Tue, 29 Mar 2011 03:52:37 +0000"  >&lt;p&gt;It seems to me that this one is coming out from HTable&apos;s ThreadPoolExecutor during batch calls/or flush. May be we can add a RejectedExecutionHandler and handle this exception gracefully with proper message to the caller.&lt;/p&gt;

&lt;p&gt;I am seeing that this could pop-out in all the places where we use ThreadPoolExecutor and may be we need a global policy on how to address rejected execution requests? &lt;/p&gt;

</comment>
                            <comment id="13012649" author="eonnen" created="Tue, 29 Mar 2011 19:53:14 +0000"  >&lt;p&gt;I tried several incarnations of reproducing this but I&apos;m apparently doing something stupid because I can&apos;t seem to get to the same state where it was breaking in my local dev environment. The stack trace we saw was:&lt;/p&gt;</comment>
                            <comment id="13012652" author="eonnen" created="Tue, 29 Mar 2011 19:54:42 +0000"  >&lt;p&gt;Oops. Stack trace was:&lt;/p&gt;

&lt;p&gt;Caused by: java.util.concurrent.RejectedExecutionException&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:1768)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:767)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:658)&lt;br/&gt;
        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:92)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1136)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchOfPuts(HConnectionManager.java:1234)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:819)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:675)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:660)&lt;/p&gt;

&lt;p&gt;We also run with a configuration of hbase.htable.threads.max=128. Despite attempting that configuration and using nearly identical code, I still can&apos;t manage to reproduce the exception.&lt;/p&gt;</comment>
                            <comment id="13047575" author="stack" created="Fri, 10 Jun 2011 22:45:54 +0000"  >&lt;p&gt;Moving out of 0.92.0. Pull it back in if you think different.&lt;/p&gt;</comment>
                            <comment id="13056627" author="whitingj" created="Tue, 28 Jun 2011 16:58:08 +0000"  >&lt;p&gt;We have seen the same stack trace and have had the same problem.  Seems useful to know that others are having this problem as well.  The exception is confusing, and I don&apos;t really understand what is going on...&lt;/p&gt;

&lt;p&gt;java.util.concurrent.RejectedExecutionException&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:1956)&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:816)&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1337)&lt;br/&gt;
 at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:120)&lt;br/&gt;
 at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1136)&lt;br/&gt;
 at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchOfPuts(HConnectionManager.java:1234)&lt;br/&gt;
 at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:819)&lt;br/&gt;
 at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:675)&lt;br/&gt;
 at org.apache.hadoop.hbase.client.HTable.put(HTable.java:660)&lt;br/&gt;
...&lt;/p&gt;

&lt;p&gt;We are running cdh3u0.&lt;/p&gt;

&lt;p&gt;We do implement our own connection pooling on top of the HTablePool while we always put it back to our connection pool stuff is rarely put back into the HTablePool, would that cause this problem?&lt;/p&gt;</comment>
                            <comment id="13056635" author="jdcryans" created="Tue, 28 Jun 2011 17:02:59 +0000"  >&lt;p&gt;Jeff,&lt;/p&gt;

&lt;p&gt;Most likely, somewhere, an HTable instance is used between at least 2 threads.&lt;/p&gt;</comment>
                            <comment id="13154789" author="vrodionov" created="Tue, 22 Nov 2011 01:06:30 +0000"  >&lt;p&gt;No, we just hit this issue in one of our reducers (which is single thread by design)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ava.util.concurrent.RejectedExecutionException
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:1768)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:767)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:658)
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:92)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1155)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchOfPuts(HConnectionManager.java:1253)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:836)
	at com.carrieriq.m2m.platform.mmp2.input.StripedHBaseTable.insert(StripedHBaseTable.java:462)
	at com.carrieriq.m2m.platform.mmp3.output.hbase.HBaseDimensionsTable.put(HBaseDimensionsTable.java:151)
	at com.carrieriq.m2m.platform.mmp3.output.DimensionMapper.putDimensionNameValue(DimensionMapper.java:309)
	at com.carrieriq.m2m.platform.mmp3.output.DimNormalizationReducer.onReduce(DimNormalizationReducer.java:465)
	at com.carrieriq.m2m.platform.mmp3.output.DimNormalizationReducer.onReduce(DimNormalizationReducer.java:53)
	at com.carrieriq.m2m.platform.util.hadoop.AbstractReportingReducer.reduce(AbstractReportingReducer.java:23)
	at com.carrieriq.m2m.platform.util.hadoop.AbstractReportingReducer.reduce(AbstractReportingReducer.java:15)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:485)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:433)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:268)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1074)
	at org.apache.hadoop.mapred.Child.main(Child.java:262)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;HBase 0.90.2 &lt;/p&gt;</comment>
                            <comment id="13184859" author="andy" created="Thu, 12 Jan 2012 10:22:40 +0000"  >&lt;p&gt;I&apos;ve also seen this when accessing HBase through DataNucleus (JDO or JPA APIs). Never occurs on 0.90.0 (or earlier), yet switching to 0.90.1 through 0.90.4 the same testcase fails. Apologies that I haven&apos;t been able to narrow it down to the precise HBase calls, but am attaching a testcase that uses DataNucleus+HBase if that is of use (it&apos;s as minimal as I can get) - understand totally if you don&apos;t want to have 3rd party libs in a testcase, just that it does reproduce the problem (can you see what HBase API calls are made from the log, for example?).&lt;/p&gt;

&lt;p&gt;Stack trace with hbase-0.90.3 and hadoop-core-1.0.0 is as follows &lt;/p&gt;

&lt;p&gt;java.util.concurrent.RejectedExecutionException&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:1768)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:767)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:658)&lt;br/&gt;
        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:92)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1143)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchOfPuts(HConnectionManager.java:1241)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:826)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:682)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:667)&lt;br/&gt;
        at org.datanucleus.store.hbase.HBasePersistenceHandler.insertObject(HBasePersistenceHandler.java:274)&lt;/p&gt;

&lt;p&gt;i.e HTable.put() is called. Note this is &lt;b&gt;single&lt;/b&gt; threaded.&lt;/p&gt;

&lt;p&gt;Test is a Maven project, and simply type &quot;mvn clean compile exec:java&quot; to execute it.&lt;/p&gt;</comment>
                            <comment id="13185306" author="jdcryans" created="Thu, 12 Jan 2012 22:33:24 +0000"  >&lt;p&gt;@Andy,&lt;/p&gt;

&lt;p&gt;I tried the attached test (which gave me a hard time with mvn 3.0), by adding some debugging in HTable I can see that HBasePersistenceHandler repeatedly closes and reuses the same HTables. That close() method got beefed up it seems during our 0.90 point releases and it now closes the TPE which generates the rejected execution you see. It also closes the connection to HBase. The fix would be to not reuse the HTables that are closed.&lt;/p&gt;

&lt;p&gt;To add to this jira, we should handle RejectedExecutionException when it comes from a closed HTable.&lt;/p&gt;</comment>
                            <comment id="13185467" author="andy" created="Fri, 13 Jan 2012 07:27:08 +0000"  >&lt;p&gt;@Jean-Daniel,&lt;br/&gt;
thanks very much. Hoped it was an error on my side; now fixed.&lt;/p&gt;</comment>
                            <comment id="13229515" author="chinmayd" created="Wed, 14 Mar 2012 19:10:23 +0000"  >&lt;p&gt;@anyone&lt;/p&gt;

&lt;p&gt;We using  CDH3u0 dist and we see the same issue. It occurs during htable.put. Increasing the pool size seems to delay the issue (or just reduce the probability) . &lt;span class=&quot;error&quot;&gt;&amp;#91;HTablePool(conf, 100)  vs HTablePool(conf, Interger.MAX_VALUE)&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;As per CDH support, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3777&quot; title=&quot;Redefine Identity Of HBase Configuration&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3777&quot;&gt;&lt;del&gt;HBASE-3777&lt;/del&gt;&lt;/a&gt; along with the thread management changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3553&quot; title=&quot;number of active threads in HTable&amp;#39;s ThreadPoolExecutor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3553&quot;&gt;&lt;del&gt;HBASE-3553&lt;/del&gt;&lt;/a&gt; might have solved this issue....but I seriously doubt it. Just wanted to check if anybody tried CDH3u3 before i embark onto a wild goose chase...&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13232995" author="jdcryans" created="Mon, 19 Mar 2012 23:01:46 +0000"  >&lt;p&gt;Chinmay,&lt;/p&gt;

&lt;p&gt;Could it be that you are re-inserting closed HTables in that pool? At this point no one has been able to provide code here that we could test that shows a bug. As far as I can tell there&apos;s no bug just API misusage (and poor error reporting on HBase&apos;s end).&lt;/p&gt;</comment>
                            <comment id="13233037" author="lhofhansl" created="Mon, 19 Mar 2012 23:56:00 +0000"  >&lt;p&gt;In 0.92 you can also use &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4805&quot; title=&quot;Allow better control of resource consumption in HTable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4805&quot;&gt;&lt;del&gt;HBASE-4805&lt;/del&gt;&lt;/a&gt;. It let&apos;s you create an HConnection and ExecutorService separately and pass them to the HTable constructor.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12510353" name="test_datanucleus.zip" size="4987" author="andy" created="Thu, 12 Jan 2012 10:22:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 23 Mar 2011 17:26:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 39 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hnef:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101053</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>