<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:02:27 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2504/HBASE-2504.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2504] Double assigned znodes in regionserver</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2504</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;regionserver log:&lt;/p&gt;

&lt;p&gt;Thu Apr 29 13:34:27 CEST 2010 Starting regionserver on dell102&lt;br/&gt;
...&lt;br/&gt;
2010-04-29 13:34:29,656 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server dell147/10.1.3.147:2181&lt;br/&gt;
2010-04-29 13:34:29,657 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to dell147/10.1.3.147:2181, initiating session&lt;br/&gt;
2010-04-29 13:34:29,678 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server dell147/10.1.3.147:2181, sessionid = 0x284958aa550001, negotiated timeout = 60000&lt;br/&gt;
...&lt;br/&gt;
2010-04-29 14:13:30,096 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=dell149:2181,dell148:2181,dell147:2181 sessionTimeout=60000 watcher=org.apache.hadoop.hbase.client.HConnectionManager$ClientZKWatcher@46d895e1&lt;br/&gt;
2010-04-29 14:13:30,096 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server dell147/10.1.3.147:2181&lt;br/&gt;
2010-04-29 14:13:30,161 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to dell147/10.1.3.147:2181, initiating session&lt;br/&gt;
2010-04-29 14:13:30,194 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server dell147/10.1.3.147:2181, sessionid = 0x284958aa550014, negotiated timeout = 60000&lt;br/&gt;
2010-04-29 14:13:30,195 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.1.3.123:60020&lt;br/&gt;
2010-04-29 14:13:30,226 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT at 10.1.3.123:60020&lt;br/&gt;
2010-04-29 14:13:30,243 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cached location for .META.,,1 is 10.1.3.125:60020&lt;br/&gt;
2010-04-29 14:13:30,247 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Read ZNode /hbase/master got 10.1.3.150:60000&lt;br/&gt;
...&lt;br/&gt;
2010-04-29 22:06:01,637 INFO org.apache.zookeeper.ZooKeeper: Session: 0x284958aa550014 closed&lt;br/&gt;
2010-04-29 22:06:02,012 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Closed connection with ZooKeeper&lt;/p&gt;

&lt;p&gt;Clearly the reinitializeZooKeeper() method was called for some reason.&lt;/p&gt;

&lt;p&gt;Unfortunately:&lt;br/&gt;
hbase(main):005:0&amp;gt; zk &apos;get /hbase/rs/1272540873161&apos;&lt;br/&gt;
10.1.3.102:60020&lt;br/&gt;
cZxid = 0x5f0000002b&lt;br/&gt;
ctime = Thu Apr 29 13:34:33 CEST 2010&lt;br/&gt;
mZxid = 0x5f0000003e&lt;br/&gt;
mtime = Thu Apr 29 13:34:33 CEST 2010&lt;br/&gt;
pZxid = 0x5f0000002b&lt;br/&gt;
cversion = 0&lt;br/&gt;
dataVersion = 1&lt;br/&gt;
aclVersion = 0&lt;br/&gt;
ephemeralOwner = 0x284958aa550001&lt;br/&gt;
dataLength = 16&lt;br/&gt;
numChildren = 0&lt;/p&gt;

&lt;p&gt;The owner of the zookeeper node is the first session which was never closed.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12463377">HBASE-2504</key>
            <summary>Double assigned znodes in regionserver</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mkurucz">Miklos Kurucz</reporter>
                        <labels>
                    </labels>
                <created>Thu, 29 Apr 2010 21:39:04 +0000</created>
                <updated>Thu, 29 Apr 2010 23:38:36 +0000</updated>
                            <resolved>Thu, 29 Apr 2010 23:38:36 +0000</resolved>
                                    <version>0.20.3</version>
                                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12862429" author="mkurucz" created="Thu, 29 Apr 2010 21:39:40 +0000"  >&lt;p&gt;I think  zooKeeperWrapper.close() should be called in reinitializeZooKeeper() &lt;span class=&quot;error&quot;&gt;&amp;#91;HRegionServer.java:316&amp;#93;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="12862437" author="jdcryans" created="Thu, 29 Apr 2010 21:58:07 +0000"  >&lt;p&gt;The znode is actually written from reportForDuty(), reinitializeZooKeeper is called from either on the constructor path or by calling restart (which is disabled by default).&lt;/p&gt;

&lt;p&gt;Also I think the second connection to ZK your log shows is from the HCM initialization path, not a second call for the RS itself.&lt;/p&gt;</comment>
                            <comment id="12862449" author="mkurucz" created="Thu, 29 Apr 2010 22:25:57 +0000"  >&lt;p&gt;Right, I did not realize there is actually two different connections.&lt;br/&gt;
Then my problem is that the shutdown procedure hangs up before actually reaching the zooKeeperWrapper.close() line in the regionserver.&lt;/p&gt;

&lt;p&gt;regionserver log: &lt;br/&gt;
2010-04-29 16:35:47,379 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting&lt;br/&gt;
2010-04-29 16:36:00,620 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -9142708263997773555 lease expired&lt;br/&gt;
2010-04-29 16:36:00,620 INFO org.apache.hadoop.hbase.Leases: regionserver/10.1.3.102:60020.leaseChecker closing leases&lt;br/&gt;
2010-04-29 16:36:00,621 INFO org.apache.hadoop.hbase.Leases: regionserver/10.1.3.102:60020.leaseChecker closed leases&lt;br/&gt;
2010-04-29 22:06:01,264 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread&lt;br/&gt;
2010-04-29 22:06:01,421 ERROR org.apache.hadoop.hdfs.DFSClient: Exception closing file /hbase/.logs/dell102.cluster,60020,1272540873161/hlog.dat.1272551586893 : java.io.IOException: IOException flush:java.io.IOException: All datanodes 10.1.3.127:50010 are bad. Aborting...&lt;br/&gt;
java.io.IOException: IOException flush:java.io.IOException: All datanodes 10.1.3.127:50010 are bad. Aborting...&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3149)&lt;br/&gt;
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Writer.syncFs(SequenceFile.java:944)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:90)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog.hflush(HLog.java:839)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:768)&lt;br/&gt;
2010-04-29 22:06:01,441 ERROR org.apache.hadoop.hdfs.DFSClient: Exception closing file /hbase/Test5/compaction.dir/2080282894/8986023427157807963 : java.io.IOException: All datanodes 10.1.3.101:50010 are bad. Aborting...&lt;br/&gt;
java.io.IOException: All datanodes 10.1.3.101:50010 are bad. Aborting...&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2593)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2137)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2302)&lt;br/&gt;
2010-04-29 22:06:01,637 INFO org.apache.zookeeper.ZooKeeper: Session: 0x284958aa550014 closed&lt;br/&gt;
2010-04-29 22:06:02,012 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Closed connection with ZooKeeper&lt;/p&gt;

&lt;p&gt;Regionserver hung up, until I manually sent a kill signal to it after some time, and then hung up again.&lt;br/&gt;
But this is not related to zookeeper at all, my mistake.&lt;/p&gt;</comment>
                            <comment id="12862452" author="jdcryans" created="Thu, 29 Apr 2010 22:34:14 +0000"  >&lt;p&gt;I do see the ZK session shutdown lines at the end... but the error you got looks like you either didn&apos;t configure ulimit or xcievers. The 0.20.3 documentation wasn&apos;t very clear about it, but do take a look at the last requirement in the new Getting Started &lt;a href=&quot;http://people.apache.org/~stack/hbase-0.20.4-candidate-5/hbase-0.20.4/docs/api/overview-summary.html#requirements&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://people.apache.org/~stack/hbase-0.20.4-candidate-5/hbase-0.20.4/docs/api/overview-summary.html#requirements&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12862461" author="mkurucz" created="Thu, 29 Apr 2010 22:50:24 +0000"  >&lt;p&gt;Yes the ZK session shutdown lines you see belong to the HCM session, not the regionserver which is still seen as alive by the master(and thus makes the cluster mostly unusable).&lt;/p&gt;

&lt;p&gt;Our ulimit is:&lt;br/&gt;
ulimit -n 65536&lt;br/&gt;
and our xcievers is:&lt;br/&gt;
&amp;lt;property&amp;gt;&lt;br/&gt;
 &amp;lt;name&amp;gt;dfs.datanode.max.xcievers&amp;lt;/name&amp;gt;&lt;br/&gt;
 &amp;lt;value&amp;gt;2048&amp;lt;/value&amp;gt;&lt;br/&gt;
 &amp;lt;final&amp;gt;true&amp;lt;/final&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;Our main problem is that HDFS is very unreliable due to some bad disk space assignment behavior.&lt;br/&gt;
That should be fixed in the near future, but until then I would like to get familiar with HBASE(and fix bugs if I can)&lt;/p&gt;</comment>
                            <comment id="12862464" author="jdcryans" created="Thu, 29 Apr 2010 22:55:53 +0000"  >&lt;p&gt;It must have been holding up on something else, next time it happens use jstack to see what happens to the threads and work out how we could get un-stuck.&lt;/p&gt;</comment>
                            <comment id="12862467" author="mkurucz" created="Thu, 29 Apr 2010 23:09:47 +0000"  >&lt;p&gt;Okay, stackdump attached.&lt;br/&gt;
Seems bad as the other IPC Server handler could exit with something like:&lt;/p&gt;

&lt;p&gt;2010-04-29 16:35:40,069 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 2 on 60020, call multiPut(org.apache.hadoop.hbase.client.MultiPut@5890e821&lt;br/&gt;
) from 10.1.3.117:60265: error: java.io.IOException: IOException flush:java.io.IOException: All datanodes 10.1.3.127:50010 are bad. Aborting...&lt;br/&gt;
java.io.IOException: IOException flush:java.io.IOException: All datanodes 10.1.3.127:50010 are bad. Aborting...&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3149)&lt;br/&gt;
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Writer.syncFs(SequenceFile.java:944)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:90)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog.hflush(HLog.java:839)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:768)&lt;/p&gt;</comment>
                            <comment id="12862471" author="jdcryans" created="Thu, 29 Apr 2010 23:16:04 +0000"  >&lt;p&gt;This looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2447&quot; title=&quot;LogSyncer.addToSyncQueue doesn&amp;#39;t check if syncer is still running before waiting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2447&quot;&gt;&lt;del&gt;HBASE-2447&lt;/del&gt;&lt;/a&gt;, how recent is your revision?&lt;/p&gt;</comment>
                            <comment id="12862475" author="mkurucz" created="Thu, 29 Apr 2010 23:30:18 +0000"  >&lt;p&gt;We last updated on Wed, 21 Apr 2010&lt;br/&gt;
Okay, I guess that is already outdated.&lt;br/&gt;
HBase development is really fast.&lt;br/&gt;
I will update and wait if any similar problem comes up again.&lt;br/&gt;
Also I&apos;m convinced that this issue is duplicated.&lt;/p&gt;

&lt;p&gt;Thanks for your help!&lt;/p&gt;</comment>
                            <comment id="12862477" author="jdcryans" created="Thu, 29 Apr 2010 23:38:36 +0000"  >&lt;p&gt;I think you should use an official release instead of checking out directly from SVN, I would use the latest candidate for 0.20.4 if I was a new user. Also, unless you are quite sure you found an HBase bug, I would suggest first writing to the hbase-user mailing list so that we can help you with the triage.&lt;/p&gt;

&lt;p&gt;Closing this jira now.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12443244" name="stackdump" size="9788" author="mkurucz" created="Thu, 29 Apr 2010 23:09:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 29 Apr 2010 21:58:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26338</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hhzr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100177</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>