<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:36:30 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12790/HBASE-12790.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12790] Support fairness across parallelized scans</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12790</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Some HBase clients parallelize the execution of a scan to reduce latency in getting back results. This can lead to starvation with a loaded cluster and interleaved scans, since the RPC queue will be ordered and processed on a FIFO basis. For example, if there are two clients, A &amp;amp; B that submit largish scans at the same time. Say each scan is broken down into 100 scans by the client (broken down into equal depth chunks along the row key), and the 100 scans of client A are queued first, followed immediately by the 100 scans of client B. In this case, client B will be starved out of getting any results back until the scans for client A complete.&lt;/p&gt;

&lt;p&gt;One solution to this is to use the attached AbstractRoundRobinQueue instead of the standard FIFO queue. The queue to be used could be (maybe it already is) configurable based on a new config parameter. Using this queue would require the client to have the same identifier for all of the 100 parallel scans that represent a single logical scan from the clients point of view. With this information, the round robin queue would pick off a task from the queue in a round robin fashion (instead of a strictly FIFO manner) to prevent starvation over interleaved parallelized scans.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12764341">HBASE-12790</key>
            <summary>Support fairness across parallelized scans</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="ram_krish">ramkrishna.s.vasudevan</assignee>
                                    <reporter username="jamestaylor">James Taylor</reporter>
                        <labels>
                            <label>Phoenix</label>
                    </labels>
                <created>Wed, 31 Dec 2014 03:19:43 +0000</created>
                <updated>Thu, 12 Nov 2015 07:43:59 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>19</watches>
                                                                <comments>
                            <comment id="14261852" author="jamestaylor" created="Wed, 31 Dec 2014 03:22:34 +0000"  >&lt;p&gt;Alternate round-robin based-queue implementation for ThreadPoolExecutor&lt;/p&gt;</comment>
                            <comment id="14369782" author="ram_krish" created="Thu, 19 Mar 2015 17:47:13 +0000"  >&lt;p&gt;Based on @&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=giacomotaylor&quot; class=&quot;user-hover&quot; rel=&quot;giacomotaylor&quot;&gt;James Taylor&lt;/a&gt; AbstractRoundrobinqueue implementation, tried out patch that helps to establish the fairness.  &lt;br/&gt;
Thanks to James for helping on this.&lt;br/&gt;
Currently the RPC scheduler is FIFO based when there is no deadline. As the description of the JIRA suggests that we would like to establish a round robin nature so that the scans submitted parallely need not wait for the other to complete before it gets &lt;br/&gt;
scheduled.&lt;/p&gt;

&lt;p&gt;In order to establish this fairness in scan queries we would allow the scan to set some grouping Id - a string. &lt;br/&gt;
A new scheduling policy needs to be used if we need this scheduler that works based on grouping. (this is based on a configuration).&lt;/p&gt;

&lt;p&gt;Here again we have two cases.  &lt;br/&gt;
CALL_QUEUE_TYPE_FIFO_CONF_VALUE and CALL_QUEUE_TYPE_DEADLINE_CONF_VALUE&lt;br/&gt;
For CALL_QUEUE_TYPE_FIFO_CONF_VALUE we will use the AbstractRoundRobinQueue which would group the calls based on the groupId set&lt;br/&gt;
in the scan query and the calls gets scheduled in a round robin manner based on FIFO order. &lt;br/&gt;
The AbstractRoundrobinqueue is the one which Phoenix currently uses to schedule the parallel scans.&lt;/p&gt;

&lt;p&gt;For CALL_QUEUE_TYPE_DEADLINE_CONF_VALUE case we have AbstractRoundRobinPriorityQueue which would sort the calls based on the priority&lt;br/&gt;
(here the deadline) and on that it would group the calls based on the groupId set in the scan query. So the round robin happens&lt;br/&gt;
with the group of same priority.&lt;/p&gt;

&lt;p&gt; The configuration that enables the Scheduler to work based on this grouping is&lt;br/&gt;
&apos;hbase.ipc.server.callqueue.grouping&apos;.  Set this to true for this feature.  By default it is false.&lt;br/&gt;
Just attaching a patch for reference.  Ideas and suggestions are welcome.&lt;/p&gt;</comment>
                            <comment id="14377764" author="ram_krish" created="Tue, 24 Mar 2015 12:11:58 +0000"  >&lt;p&gt;Updated patch with test case.  The round robin nature for the AbstractPriorityBasedRoundRobinQueue has been corrected as in the first patch we were using one producer under a given priority and once it was over was moving over to the next producer.  Which means under Priority A if we had two groups A and B each with 10 task, then we were consuming all the 10 tasks under A and then moving on to B.  With the latest patch we ensure that we round robin between the task in A and B.&lt;/p&gt;</comment>
                            <comment id="14377807" author="hadoopqa" created="Tue, 24 Mar 2015 13:03:20 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12706892/HBASE-12790_1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12706892/HBASE-12790_1.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 80d230e1fbeac24d3dfdac8165e24f35ec26f988.&lt;br/&gt;
  ATTACHMENT ID: 12706892&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 10 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 8 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1923 checkstyle errors (more than the master&apos;s current 1917 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the master&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              new java.lang.String[] &lt;/p&gt;
{ &quot;Column&quot;, &quot;Attribute&quot;, &quot;StartRow&quot;, &quot;StopRow&quot;, &quot;Filter&quot;, &quot;TimeRange&quot;, &quot;MaxVersions&quot;, &quot;CacheBlocks&quot;, &quot;BatchSize&quot;, &quot;MaxResultSize&quot;, &quot;StoreLimit&quot;, &quot;StoreOffset&quot;, &quot;LoadColumnFamiliesOnDemand&quot;, &quot;Small&quot;, &quot;Reversed&quot;, &quot;Consistency&quot;, &quot;Caching&quot;, &quot;GroupingId&quot;, }
&lt;p&gt;);&lt;br/&gt;
+ * An &lt;/p&gt;
{@link RpcExecutor}
&lt;p&gt; that will balance requests in a round robin way across all its queues based on &lt;br/&gt;
+    boolean callQueueGrouping = conf.getBoolean(CALL_QUEUE_GROUPING, CALL_QUEUE_GROUPING_DEFAULT_VALUE);&lt;br/&gt;
+        // TODO : Introduce configuration that strictly allows the Balanced way of Write QueueExecutor&lt;br/&gt;
+              conf, abortable, FairSharePriorityBasedBlockingQueue.class, maxQueueLength, callPriority);&lt;br/&gt;
+        // TODO : Introduce configuration that strictly allows the balanced way of write queue executor&lt;br/&gt;
+            // we need to adjust the current thread pointer in case it pointed to this thread list, which is now removed&lt;br/&gt;
+    AbstractPriorityBasedRoundRobinQueue&amp;lt;TestObject&amp;gt; testList = new AbstractRoundRobinPriorityQueueImpl(&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestOperation&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/patchReleaseAuditWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/patchReleaseAuditWarnings.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13381//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14378115" author="ram_krish" created="Tue, 24 Mar 2015 16:38:34 +0000"  >&lt;p&gt;Any chance of a review here?&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14378201" author="mbertozzi" created="Tue, 24 Mar 2015 17:27:10 +0000"  >&lt;p&gt;skimmed the patch and look good. &lt;br/&gt;
can you upload it on reviewboard since it is quite long and it will be easier to comment&lt;/p&gt;</comment>
                            <comment id="14378218" author="ram_krish" created="Tue, 24 Mar 2015 17:36:22 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/32447/diff/#&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/32447/diff/#&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14379890" author="stack" created="Wed, 25 Mar 2015 13:55:37 +0000"  >&lt;p&gt;Skimmed patch.&lt;/p&gt;

&lt;p&gt;That is an awful lot of code to do a bit of round robin and it seems burdensome expecting that clients identify their own scan &apos;group&apos;; can&apos;t we pick an identifier internal to the scan and not bother users with such detail?&lt;/p&gt;</comment>
                            <comment id="14379912" author="ram_krish" created="Wed, 25 Mar 2015 14:19:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;seems burdensome expecting that clients identify their own scan &apos;group&apos;; can&apos;t we pick an identifier internal to the scan and not bother users with such detail?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is based on the Phoenix use case. Pls take a look at &lt;br/&gt;
&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=phoenix.git;a=blob;f=phoenix-core/src/main/java/org/apache/phoenix/job/JobManager.java;h=31ef7424d4ad04ddbd286c32ef27f187266a7728;hb=a94a6f4195af2867379803f19c90045eb3943c2d&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=phoenix.git;a=blob;f=phoenix-core/src/main/java/org/apache/phoenix/job/JobManager.java;h=31ef7424d4ad04ddbd286c32ef27f187266a7728;hb=a94a6f4195af2867379803f19c90045eb3943c2d&lt;/a&gt;.&lt;br/&gt;
Phoenix currently tries to use its own thread pool executor to execute the task in parallel which are grouped.&lt;br/&gt;
Currently in HBase we have only FIFO model for which we use the LinkedBlockingQueue that java provides and for the deadline  based prioirty we use the BoundedPrioirtyQueue impl.  &lt;/p&gt;

&lt;p&gt;In order to implement the round robin impl based on the Grouping the current RPC executor does not have any data structure.  &lt;br/&gt;
Regarding the change to Scan - we could actually do that setting the Attributes. That was initially thought as the best way.  But the thing is that inside the Executor inorder to identify the Attribute corresponding to the groupId we have to iterate the list of attributes because from the Protobuf we don&apos;t get a map. If that is fine I can remove the changes to Scan.java and the patch will not have protobuf changes. &lt;/p&gt;

&lt;p&gt;But regarding the round robin nature I think we need a generic queue impl that would do the round robin work like how a new BoundedPriorityQueue was implemented just to have the FIFO nature.&lt;/p&gt;
</comment>
                            <comment id="14379915" author="ram_krish" created="Wed, 25 Mar 2015 14:21:51 +0000"  >&lt;p&gt;To be more precise on the FIFO nature, FIFO that would order tasks with the same priority as FIFO nature.&lt;/p&gt;</comment>
                            <comment id="14380093" author="jamestaylor" created="Wed, 25 Mar 2015 15:47:16 +0000"  >&lt;p&gt;The client is the one that knows which set of scans corresponds to a single &quot;job&quot;, as it&apos;s the one orchestrating the set of parallel scans. The server doesn&apos;t have that knowledge.&lt;/p&gt;</comment>
                            <comment id="14380251" author="ram_krish" created="Wed, 25 Mar 2015 17:07:34 +0000"  >&lt;p&gt;As mentioned in the description, Phoenix tries to do a scan by splitting a scan to equal sized chunks and tries to execute in parallel. So every scan is split in to mulitiple sub scans.  So two scans which trying to create these chunks will set its own group id.&lt;/p&gt;</comment>
                            <comment id="14380329" author="stack" created="Wed, 25 Mar 2015 17:42:31 +0000"  >&lt;p&gt;Does this new RR Q fall back to FIFO or priority when no grouping present? Or is the scheduling fit for this phoenix use case only? Thanks.&lt;/p&gt;</comment>
                            <comment id="14380338" author="jamestaylor" created="Wed, 25 Mar 2015 17:46:16 +0000"  >&lt;p&gt;With no grouping present, it would end up being FIFO because there&apos;d be a single group that the requests would go in. You&apos;d end up round robining among this single group which is the same thing as FIFO.&lt;/p&gt;</comment>
                            <comment id="14381357" author="ram_krish" created="Thu, 26 Mar 2015 04:40:06 +0000"  >&lt;p&gt;Without any GROUPING Id present things would work as it was previously. As round robin with in a the same Group would any way be the FIFO based manner.&lt;/p&gt;</comment>
                            <comment id="14381407" author="stack" created="Thu, 26 Mar 2015 05:47:05 +0000"  >&lt;p&gt;So is &apos;grouping&apos; a pure phoenix construct or is &apos;grouping&apos; just a client identifier?  Or does a single phoenix client run multiple groups? Do we see grouping being generally useful? Could clients other than phoenix make use of it? I ask because this scheduling of rpc in the server is a hot spot when I profile. Are we doing more work to support grouping? Thanks.&lt;/p&gt;</comment>
                            <comment id="14381440" author="jamestaylor" created="Thu, 26 Mar 2015 06:15:51 +0000"  >&lt;p&gt;The grouping ID is any client identifier that links a set of scans as a &quot;unit of work&quot;. It&apos;s not Phoenix specific. Every SQL query that is executed by Phoenix is parallelized as a set of scans. This set will have the same grouping ID to define them as a single unit of work. We just generate a UUID on the client for the grouping ID. I&apos;m sure there&apos;s room for improvement in the performance of the round robin priority queue (but isn&apos;t there always &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ).&lt;/p&gt;</comment>
                            <comment id="14381446" author="ram_krish" created="Thu, 26 Mar 2015 06:23:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;So is &apos;grouping&apos; a pure phoenix construct or is &apos;grouping&apos; just a client identifier?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I would say it is a client identifier. It may not be phoenix specific.  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Or does a single phoenix client run multiple groups?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Single phoenix client - I am not getting your point here. When you say client you mean every Phoenix client will generate a fixed group Id?&lt;br/&gt;
 Every query can be split into parallel scans. And each query can set a unique Scan Id. I think Phoenix does it with a random ID. (Correct me if am wrong here &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=giacomotaylor&quot; class=&quot;user-hover&quot; rel=&quot;giacomotaylor&quot;&gt;James Taylor&lt;/a&gt;.)&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I ask because this scheduling of rpc in the server is a hot spot when I profile&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We could do a profile to say how much it is.  I think the Phoenix team would already have some profiling information on this area.&lt;/p&gt;</comment>
                            <comment id="14381449" author="ram_krish" created="Thu, 26 Mar 2015 06:24:10 +0000"  >&lt;p&gt;James has just replied to your question.  Just seeing.&lt;/p&gt;</comment>
                            <comment id="14381450" author="ram_krish" created="Thu, 26 Mar 2015 06:26:40 +0000"  >&lt;p&gt;Updated patch available in RB.&lt;/p&gt;</comment>
                            <comment id="14388359" author="ram_krish" created="Tue, 31 Mar 2015 10:52:58 +0000"  >&lt;p&gt;Clients that require this grouping strategy would go for this RoundRobin with Priroity (if there is deadline set for the Calls). Hence it would be the same. In fact we have a configuration to be set if this scheduler needs to get used. &lt;br/&gt;
Any more reviews welcome!!&lt;/p&gt;</comment>
                            <comment id="14388654" author="stack" created="Tue, 31 Mar 2015 14:57:33 +0000"  >&lt;p&gt;So looking at the patch, a new concept &amp;#8211; &apos;grouping&apos; &amp;#8211; is added to Scan as public apis with no doc on what it is about.&lt;/p&gt;

&lt;p&gt;Why is a grouping id a &apos;string&apos;?&lt;/p&gt;

&lt;p&gt;Does FairShareBalancedRPCExecutor add anything? Why in class comment does it talk about scan when it plainly does nothing with scan.  Ditto FairShareRWQueueRPCExecutor.&lt;/p&gt;

&lt;p&gt;So, simplerpcscheduler has defines for&lt;/p&gt;

&lt;p&gt;53	  public static final String CALL_QUEUE_GROUPING = &quot;hbase.ipc.server.callqueue.grouping&quot;;&lt;br/&gt;
54	  public static final boolean CALL_QUEUE_GROUPING_DEFAULT_VALUE = false;&lt;/p&gt;

&lt;p&gt;and other grouping pollution.  Is this because you wanted to avoid putting in place a fair scheduler implementation? Wouldn&apos;t it be cleaner doing this than adding flags and conditional construction to simplerpcscheduler (its not a simple scheduler anymore if it has fair scheduling stuff in it).&lt;/p&gt;

&lt;p&gt;Back in a sec.&lt;/p&gt;
</comment>
                            <comment id="14388730" author="stack" created="Tue, 31 Mar 2015 15:48:27 +0000"  >&lt;p&gt;I see the new queue implementation doing a bunch of extra work while the q lock is held. Any micro-benchmark compare of this implementation to current q implementation even with no grouping enabled?&lt;/p&gt;

&lt;p&gt;Is a &apos;producer&apos; a &apos;group&apos;? (Odd having method named extractProducer return group).&lt;/p&gt;

&lt;p&gt;Why only &apos;scans&apos; implemented? Wouldn&apos;t we want fairness for any method invoked against the server?&lt;/p&gt;

&lt;p&gt;Do you have any proof this code delivers what is suggested at the top of this issue, that if all cilent A&apos;s scans are queued before all of client B&apos;s, that client B will get some action.&lt;/p&gt;

&lt;p&gt;So, users would have to &apos;enable&apos; this on the cluster? It would not be on by default?  If no degradation in scheduler, why would we not want this always on (if it indeed does fairness)?&lt;/p&gt;


</comment>
                            <comment id="14388771" author="ram_krish" created="Tue, 31 Mar 2015 16:18:16 +0000"  >&lt;p&gt;Thanks Stack for the review. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;a new concept &#8211; &apos;grouping&apos; &#8211; is added to Scan as public apis with no doc on what it is about.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I added the comment (not as doc) on the groupingId String variable. Will add a doc on the setters and getters. bq.Why is a bq.grouping id a &apos;string&apos;?&lt;br/&gt;
What do you think we could add, an Integer? I thought a groupingId could a be a simple random string formed from a Unique random Id generated and use it with a clientId - Atleast currently in Phoenix it is a String.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Does FairShareBalancedRPCExecutor add anything? Why in class comment does it talk about scan when it plainly does nothing with scan. Ditto FairShareRWQueueRPCExecutor.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.  It actually instantiates the PriorityQueue that will be used.  In the BalancedRPCExecutor it will be LinkedBlockingQueue or BoundedPriorityQueue.  Here we instantiate the FairShareBlockingQueue or the FairSharePriorityBasedBlockingQueue.&lt;br/&gt;
What I mean in the comment is that currently as I had tried out only for scan wanted to highlight that this feature works with SCan only.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;and other grouping pollution. Is this because you wanted to avoid putting in place a fair scheduler implementation?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;May be yes.  That would be cleaner. I did this way because wanted to use this new queue only in the read part.  &lt;br/&gt;
As you suggested if you go with a new scheduler then should we use this for Replication, write and read also?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Any micro-benchmark compare of this implementation to current q implementation even with no grouping enabled?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes sure.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Is a &apos;producer&apos; a &apos;group&apos;? (Odd having method named extractProducer return group).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes here producer is a group. The AbstractPriorityRoundRobinQueue is a generic impl. So here in this case we have the producer as a simple grouping String.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Do you have any proof this code delivers what is suggested at the top of this issue, that if all cilent A&apos;s scans are queued before all of client B&apos;s, that client B will get some action.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes I will add a real world test case.  Mainly this patch is to highlight the idea.  &lt;br/&gt;
My main question would be should we use this scheduler in all cases like writes and replication?  OR may be as a first cut as in this patch we go only &apos;scans&apos; or &apos;gets&apos;?&lt;br/&gt;
Even in the current way we have different queues for writes and reads.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So, users would have to &apos;enable&apos; this on the cluster? It would not be on by default? If no degradation in scheduler, why would we not want this always on &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure we could try this, based on the above question.&lt;br/&gt;
Once again thanks for the review.&lt;/p&gt;</comment>
                            <comment id="14394235" author="ram_krish" created="Fri, 3 Apr 2015 09:23:16 +0000"  >&lt;p&gt;Seeing the current code, SimpleRPCScheduler is the only scheduler created from the RPCSchedulerFactory. So we will introduce a PriorityRPCSchedulerFactory and initialize a new PriorityRPCScheduler? So that we don&apos;t add the Grouping information to the SimpleRPCScheduler.  &lt;br/&gt;
What do you think?&lt;/p&gt;</comment>
                            <comment id="14494501" author="ram_krish" created="Tue, 14 Apr 2015 18:03:03 +0000"  >&lt;p&gt;Am not very clear on how to write an end to end test case with actual scans.  Anyway am trying to do some testing in the cluster.  Will report back here.&lt;/p&gt;</comment>
                            <comment id="14497628" author="ram_krish" created="Thu, 16 Apr 2015 06:40:31 +0000"  >&lt;p&gt;While running some real time cases using PE tool. I got some NPEs here.  After spending time in digging what&apos;s going on, the reason is because once we complete a call we just cleanUp the calls.&lt;br/&gt;
This datastructure AbstractPriorityRoundRobinQueue holds the CallRunner as the Key and the same is being used in the ProducerList also. (ie) The CallPriorityComparator is used to construct the Tree Map which acts as the comparator for the keys in the tree map.  &lt;br/&gt;
Now after poll() ing for an element in the queue the RPC Executor nullifies the call.  So when a new element needs to be added this comaprator throws an NPE because already one of the calls has been nullified. &lt;br/&gt;
From the design side, we cannot pass the CallRunner directly for these type of cases because in case of BoundedPriorityQueue it is only the head that is being returned and the pointer gets moved away from that element as the head itself changes.  But in data structurs like TreeMap that is not the case.  Interesting to debug this.&lt;/p&gt;</comment>
                            <comment id="14497906" author="ram_krish" created="Thu, 16 Apr 2015 11:06:22 +0000"  >&lt;p&gt;Attaching a patch that has been tested in real cluster.  Am working on taking the performance numbers for scans.  Currently this patch implements the round robin thing only for scans.  Am not very clear on how to write a generic test case. Any suggestions in this area?&lt;br/&gt;
But pls take note of the following changes,&lt;br/&gt;
The RpcExecutor and the related Queue data structures will no longer work on CallRunner instead they will work on CallRunnerWrapper.  (better name?). This is because CallRunner every time depends on the &apos;call&apos; object to determine its deadline when we use Deadline based comparator.  But since the &apos;call&apos; can be nullified every time, the new data structure like AbstractPriorityRoundRobinQueue (Using TreeMap) suffers from NPE because of this nullification when it tries to apply the comparison. Also with this patch we calculate the deadline once when the &apos;call&apos; starts and not every time. We ensure that we no longer depend on the &apos;call&apos; object to know the deadline for comparisons.  &lt;br/&gt;
You could see that CallPriorityComparator has been removed.&lt;/p&gt;</comment>
                            <comment id="14506360" author="ram_krish" created="Wed, 22 Apr 2015 03:50:31 +0000"  >&lt;p&gt;Pointed out by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=giacomotaylor&quot; class=&quot;user-hover&quot; rel=&quot;giacomotaylor&quot;&gt;James Taylor&lt;/a&gt; over in &lt;a href=&quot;https://issues.apache.org/jira/browse/PHOENIX-1906&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/PHOENIX-1906&lt;/a&gt; for a typical usecase for this type of round robin scheduler.&lt;/p&gt;</comment>
                            <comment id="14507418" author="apurtell" created="Wed, 22 Apr 2015 17:01:48 +0000"  >&lt;p&gt;Why both FairShareBlockingQueue and FairSharePriorityBasedBlockingQueue? Which one would Phoenix use? Pick that one.&lt;/p&gt;

&lt;p&gt;In the new *BlockingQueue classes, each time we want to remove an item from the queue we have to do a string comparison? An instanceof check for ScanRequest on the result of &lt;tt&gt;o.getCall().param&lt;/tt&gt; would be faster, probably a lot faster. Need to be performance conscious here, at least in this case I&apos;m not seeing it.&lt;/p&gt;

&lt;p&gt;Have these changes been benchmarked? What is the performance difference? Going to be important to put up numbers gathered in a statistically meaningful way I think.&lt;/p&gt;

&lt;p&gt;SimpleRpcScheduler is getting more complex. Beginning to not live up to its naming.&lt;/p&gt;

&lt;p&gt;Are the changes made to SimpleRpcScheduler available to the other schedulers? In other words, are you teaching all of the schedulers about call grouping? If not, why not? &lt;/p&gt;

&lt;p&gt;Have we tried using one of the concurrent queue types instead of a blocking (locking) queue type? Does that scale better as the concurrency is turned up?&lt;/p&gt;

&lt;p&gt;Consider JMH for collecting microbenchmarks.&lt;/p&gt;</comment>
                            <comment id="14507426" author="apurtell" created="Wed, 22 Apr 2015 17:06:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;SimpleRpcScheduler is getting more complex. Beginning to not live up to its naming.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;On this part, I see why SimpleRpcScheduler is being changed so this is ok.&lt;/p&gt;</comment>
                            <comment id="14507460" author="ram_krish" created="Wed, 22 Apr 2015 17:20:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;An instanceof check for ScanRequest on the result of o.getCall().param&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I can change that.  I just used the pattern that was already in use.  But your suggestion makes sense. can change it.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Have these changes been benchmarked? What is the performance difference? Going to be important to put up numbers gathered in a statistically meaningful way I think.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No. Not yet.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Have we tried using one of the concurrent queue types instead of a blocking (locking) queue type? Does that scale better as the concurrency is turned up?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Consider JMH for collecting microbenchmarks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure will try that.  Learning to use JMH.&lt;/p&gt;</comment>
                            <comment id="14514653" author="ndimiduk" created="Mon, 27 Apr 2015 18:36:54 +0000"  >&lt;p&gt;For what it&apos;s worth, I believe there&apos;s an open ticket in Hive to break large scans down into multiple smaller ones. Don&apos;t know which one off the top of my head though. cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14514673" author="jamestaylor" created="Mon, 27 Apr 2015 18:43:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;For what it&apos;s worth, I believe there&apos;s an open ticket in Hive to break large scans down into multiple smaller ones. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;FWIW, Phoenix already does this. This is for the next step of ensuring that a big scan broken down into many small chunks doesn&apos;t lock out a small scan from being able to complete.&lt;/p&gt;</comment>
                            <comment id="14514680" author="ndimiduk" created="Mon, 27 Apr 2015 18:48:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jamestaylor&quot; class=&quot;user-hover&quot; rel=&quot;jamestaylor&quot;&gt;James Taylor&lt;/a&gt; would you say this kind of thinking applies to MR jobs as well? We&apos;d want to group all scans from a job together so that the scheduler will prevent one-off&apos;s from starving? Previously I&apos;ve thought about this in terms of &quot;batch vs online&quot; scans, but maybe &quot;group&quot; is the generalization of this thinking?&lt;/p&gt;</comment>
                            <comment id="14514696" author="jamestaylor" created="Mon, 27 Apr 2015 18:53:30 +0000"  >&lt;p&gt;Yes, I think conceptually this is the same. However, sometimes with batch jobs you don&apos;t care about latency, so the concern may be lower.&lt;/p&gt;</comment>
                            <comment id="14514737" author="ndimiduk" created="Mon, 27 Apr 2015 19:16:55 +0000"  >&lt;p&gt;I bring up batch jobs for two reasons. (1) you care about the latency of your non-batch jobs a lot, so a system that supports fairness should help non-batch running simultaneously with batch. (2) lots of people actually do care about the latency of batch jobs as they relate to each other; having one job drown out all the others on a shared cluster isn&apos;t helpful, and is why so much time goes into Hadoop/YARN schedulers. &lt;/p&gt;</comment>
                            <comment id="14514753" author="jamestaylor" created="Mon, 27 Apr 2015 19:21:35 +0000"  >&lt;p&gt;Excellent point, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14736595" author="ram_krish" created="Wed, 9 Sep 2015 10:07:13 +0000"  >&lt;p&gt;In between my &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11425&quot; title=&quot;Cell/DBB end-to-end on the read-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11425&quot;&gt;&lt;del&gt;HBASE-11425&lt;/del&gt;&lt;/a&gt; tests, I spent some time in this JIRA and completed the testing that is needed. The set up was to load a Phoenix table with 70000000 rows. &lt;br/&gt;
The RS is configured with 5 handler threads.  The table is major compacted and ensure that the STATS table is filled up with stats that would be enough to fill up the handler threads with parallel scan queries with same GROUP ID  when a count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; query is issued.&lt;br/&gt;
We basically set up a client program which infinitely runs two queries in two threads - count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; and another a point query (a query that exactly retrieves a single row).&lt;br/&gt;
The count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; is split into around 15 parallel queries each with the same group id.&lt;br/&gt;
Now before we implement such a patch where we could round robin on a group id we get this &lt;br/&gt;
In case of FIFO based implementation (0.98)&lt;br/&gt;
Without patch&lt;br/&gt;
==========&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 5
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 5
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 19793
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 12
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 20656
......
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 21127
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 5
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 22454
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 8
....
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 3
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 24144
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 26
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 18876
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 6
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With patch&lt;br/&gt;
========&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 8
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 22226
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 8
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2131
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 12628
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 6359

....

The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 22656
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 7
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2476
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 14469
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 318
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Deadline based priority queue&lt;br/&gt;
Without patch&lt;br/&gt;
===========&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 4
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 29877
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 5
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 26895
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 9

The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 4
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 29027
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 6
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 27288
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 5
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With patch&lt;br/&gt;
========&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 6
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 26445
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 8
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 3098
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 215
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1682
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 963
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 760
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1386
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1185
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2013
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 809
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2410
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 869
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1661
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1430
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1748
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1046
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1299
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 698
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1320
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 23
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 6
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 11


The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; countquery is 27141
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 5
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 3158
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 177
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1828
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1222
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 3745
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 30
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 207
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2639
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1396
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2425
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 903
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 668
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 2718
The completion time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; point query is 1863
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so we could see that instead of waiting for a single point query upto 25 to 29 secs we try to round robin with the point queries that are interspersed with the count query&apos;s scans(with same groupid).  Thus avoiding the delay due to that single point query. &lt;/p&gt;</comment>
                            <comment id="14738268" author="ram_krish" created="Thu, 10 Sep 2015 06:38:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why both FairShareBlockingQueue and FairSharePriorityBasedBlockingQueue? Which one would Phoenix use? Pick that one.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think we need to support both here because currently hbase allows both configs (fifo and deadline).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Have we tried using one of the concurrent queue types instead of a blocking (locking) queue type? Does that scale better as the concurrency is turned up?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Till now I have tried.  But may be work happening in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14331&quot; title=&quot;a single callQueue related improvements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14331&quot;&gt;HBASE-14331&lt;/a&gt; can be checked if we can accomodate it for the RoundRobin behaviour. &lt;/p&gt;</comment>
                            <comment id="14738288" author="hadoopqa" created="Thu, 10 Sep 2015 06:58:51 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12755075/HBASE-12790_5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12755075/HBASE-12790_5.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit e770cf34174c8226eaf703c303ee3d8397c38242.&lt;br/&gt;
  ATTACHMENT ID: 12755075&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 10 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15521//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15521//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14740173" author="ram_krish" created="Fri, 11 Sep 2015 04:45:00 +0000"  >&lt;p&gt;The patch that I attached was based on branch-1.0. Will create a patch based on trunk. &lt;/p&gt;</comment>
                            <comment id="14740537" author="ram_krish" created="Fri, 11 Sep 2015 10:23:33 +0000"  >&lt;p&gt;Patch for trunk.&lt;/p&gt;</comment>
                            <comment id="14740598" author="hadoopqa" created="Fri, 11 Sep 2015 11:22:01 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12755372/HBASE-12790_trunk_1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12755372/HBASE-12790_trunk_1.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit fda317cebb5d306cabf1899e05cedb0225b2b62b.&lt;br/&gt;
  ATTACHMENT ID: 12755372&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 10 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1837 checkstyle errors (more than the master&apos;s current 1834 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the master&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              new java.lang.String[] &lt;/p&gt;
{ &quot;Column&quot;, &quot;Attribute&quot;, &quot;StartRow&quot;, &quot;StopRow&quot;, &quot;Filter&quot;, &quot;TimeRange&quot;, &quot;MaxVersions&quot;, &quot;CacheBlocks&quot;, &quot;BatchSize&quot;, &quot;MaxResultSize&quot;, &quot;StoreLimit&quot;, &quot;StoreOffset&quot;, &quot;LoadColumnFamiliesOnDemand&quot;, &quot;Small&quot;, &quot;Reversed&quot;, &quot;Consistency&quot;, &quot;Caching&quot;, &quot;GroupingId&quot;, }
&lt;p&gt;);&lt;br/&gt;
+      queues.add((BlockingQueue&amp;lt;CallRunnerWrapper&amp;gt;) ReflectionUtils.newInstance(queueClass, initargs));&lt;br/&gt;
+      scheduler = new RoundRobinRPCScheduler(schedConf, 1, 1, 1, priority, HConstants.QOS_THRESHOLD);&lt;br/&gt;
+    AbstractPriorityBasedRoundRobinQueue&amp;lt;TestObject&amp;gt; testList = new AbstractRoundRobinPriorityQueueImpl(&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestOperation&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/patchReleaseAuditWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/patchReleaseAuditWarnings.txt&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15558//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14744299" author="jamestaylor" created="Mon, 14 Sep 2015 21:23:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; - would it be possible for one of you to review?&lt;/p&gt;</comment>
                            <comment id="14901876" author="ram_krish" created="Tue, 22 Sep 2015 03:55:13 +0000"  >&lt;p&gt;Updated the patch in RB. RB link is &lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/32447/diff/#&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/32447/diff/#&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14941919" author="apurtell" created="Fri, 2 Oct 2015 22:54:16 +0000"  >&lt;p&gt;I&apos;m sorry but this doesn&apos;t help. Looks like output captured from one test run?&lt;/p&gt;

&lt;p&gt;What would help is a few runs of the test, i.e. 10, with statistics average/min/max/p99 provided for the measured point and count query running times over all of the test runs with and without the patch.&lt;/p&gt;

&lt;p&gt;/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=giacomotaylor&quot; class=&quot;user-hover&quot; rel=&quot;giacomotaylor&quot;&gt;James Taylor&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14941922" author="apurtell" created="Fri, 2 Oct 2015 22:55:55 +0000"  >&lt;p&gt;I added a comment above as a reply on another comment. Basically, perf gain and impact not characterized well enough yet, but it&apos;s just a testing issue I think and an improved test run and analysis will do the trick. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12790?focusedCommentId=14941919&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14941919&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-12790?focusedCommentId=14941919&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14941919&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14942166" author="ram_krish" created="Sat, 3 Oct 2015 07:41:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;&lt;br/&gt;
Thanks for the comment Andrew. Regarding the testing part, this particular feature is not going to improve the performance of a point query or a count query but basically it is going to say how the query distribution is.  Instead of waiting for some 20 secs for one point query now we will be able to execute around 10 queries each with 2 secs time.  Let me see how I can present the reports.&lt;/p&gt;</comment>
                            <comment id="14944277" author="apurtell" created="Mon, 5 Oct 2015 23:56:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;Instead of waiting for some 20 secs for one point query now we will be able to execute around 10 queries each with 2 secs time. Let me see how I can present the reports.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Ram.&lt;/p&gt;

&lt;p&gt;Did you mean: instead of waiting 20 seconds for one count query now we will see several point queries completing during that interval? &lt;/p&gt;

&lt;p&gt;In addition to how many of the different query types can complete during the test interval, when testing the mixed point and count load you&apos;re putting on the system I wonder how does the distribution of completion times for point queries change? Should see clear improvement when the count query is running with the patch applied. (smile) Shouldn&apos;t see perf impact when not, or if we do we can see the magnitude of it and decide if its acceptable. &lt;/p&gt;</comment>
                            <comment id="14944894" author="ram_krish" created="Tue, 6 Oct 2015 11:21:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;Did you mean: instead of waiting 20 seconds for one count query now we will see several point queries completing during that interval?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;. That is right. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Should see clear improvement when the count query is running with the patch applied. (smile)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The count query still runs with the same amount of time but it is the smaller queries that stays behind the bigger queries gets benefited. I think that is a valid case and I can see that the point queries are lagging without the patch because the queues are filled up with the parallel scans launched by the bigger count query. Let me see how to present these results. &lt;/p&gt;</comment>
                            <comment id="14945217" author="apurtell" created="Tue, 6 Oct 2015 15:40:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;The count query still runs with the same amount of time but it is the smaller queries that stays behind the bigger queries gets benefited.   &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that&apos;s what I mean. And when no count query is running the point queries shouldn&apos;t show a penalty (or if they do then we discuss)&lt;/p&gt;</comment>
                            <comment id="14945252" author="ram_krish" created="Tue, 6 Oct 2015 16:00:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;And when no count query is running the point queries shouldn&apos;t show a penalty (or if they do then we discuss)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That does not happen and I have verified that. Thanks Andy.&lt;/p&gt;</comment>
                            <comment id="14959708" author="apurtell" created="Thu, 15 Oct 2015 21:56:54 +0000"  >&lt;p&gt;In the interest of moving this forward we asked the perf guys on our Phoenix team to test HBase 0.98.16-SNAPSHOT plus &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12790&quot; title=&quot;Support fairness across parallelized scans&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12790&quot;&gt;HBASE-12790&lt;/a&gt; and Phoenix 4.5.3-SNAPSHOT with a small patch that allows it to take advantage of the new Scan#getGroupingId API. The server side configuration was updated to specify RoundRobinRPCScheduler for RPC scheduling. The comparison results are attached as &quot;PHOENIX_4.5.3-HBase-0.98-2317-SNAPSHOT.zip&quot;&lt;/p&gt;

&lt;p&gt;It&apos;s an indirect result in that we are viewing perf through the Phoenix lens, but I&apos;m happy to report there are no perf regressions found, only improvements. Therefore I have no concerns in that regard about getting this committed.&lt;/p&gt;

&lt;p&gt;I put up some comments on &lt;a href=&quot;https://reviews.apache.org/r/32447&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/32447&lt;/a&gt;. Getting there.&lt;/p&gt;

&lt;p&gt;/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jamestaylor&quot; class=&quot;user-hover&quot; rel=&quot;jamestaylor&quot;&gt;James Taylor&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14960117" author="ram_krish" created="Fri, 16 Oct 2015 03:41:25 +0000"  >&lt;p&gt;Thanks Andy for the update. I have just loaded my little cluster with the required phoenix tables and thought of repeating the experiments. &lt;br/&gt;
Let me get back on the review board comments.&lt;br/&gt;
One request/suggestion - Is it possible to test the branch-1 patch also . Because that is more to do with the prirority based handling and that would be the default in the branch-1 case.  If that scheduler is also tested and we ensure we get the same benefit on the phoenix side without any regression then I would be more than happy.  I can perform my side of tests but the Phoenix team&apos;s test would be of more value add. /cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14960122" author="jamestaylor" created="Fri, 16 Oct 2015 03:45:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; - since we run HBase 0.98 in production, that&apos;s what we have installed on our test clusters. It&apos;d be best if you could test that branch, as it wouldn&apos;t be feasible on our end.&lt;/p&gt;</comment>
                            <comment id="14960135" author="ram_krish" created="Fri, 16 Oct 2015 04:01:28 +0000"  >&lt;p&gt;Sure James. My initial tests on branch-1 also revealed there were no regression and the patch worked as that of the FIFO based approach in 0.98. I will do it once again.&lt;/p&gt;</comment>
                            <comment id="14987759" author="ram_krish" created="Tue, 3 Nov 2015 18:11:11 +0000"  >&lt;p&gt;Thanks for all the comments on the RB. Had an offline discussion with Andy, James and Anoop.  I would like to update the discussion here.&lt;br/&gt;
We will extend the groupid concept to all the client requests. That includes scan, gets, MutateRequest, MultiRequest, Bulkloadrequest etc.&lt;br/&gt;
In order to do this we expose the groupId API at the Operation level. This will allow every Put, Delete, Increment, Append, Get and Scan to have a grouping id. &lt;br/&gt;
Now at the Rpc layer the scan and gets have one to one mapping with the scan requests. So the groupid set on the individual scan/gets can be used to do the round robin.&lt;br/&gt;
But for MultiRequest there could be &apos;n&apos; number of actions like Puts, deletes, gets etc. And every thing will be mapped to one multiRequest. Since we expose groupId at the Operation level it will mean that different actions can have different groupids set but at the Rpc layer we take the first groupId as the id for the entire multiRequest. I had a concern with this part because users will be allowed to set different groupIds but internally we will be using only one of them and this point gets hidden from the user totally. May be it could confuse the user is what I thought. Overall this groupingId concept is not a direct parameter that affects the users result whereas it is more on how the server is going to handle the request. &lt;br/&gt;
I can update the patch based on the above feedbacks/discussions. Any more queries and feedback are welcome!!&lt;/p&gt;</comment>
                            <comment id="14987853" author="anoop.hbase" created="Tue, 3 Nov 2015 18:51:47 +0000"  >&lt;p&gt;Basically &apos;groupId&apos; make sense for RPC requests but that is not really exposed to user.  So if there is no 1-1 mapping from Mutation/Operation to RPC things get ambiguity.&lt;/p&gt;</comment>
                            <comment id="14987863" author="apurtell" created="Tue, 3 Nov 2015 18:58:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;So if there is no 1-1 mapping from Mutation/Operation to RPC things get ambiguity.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, and we need to document this, but if the proposal is to only support group ID for reads and not writes, then I&apos;m not in favor of this change. Clients send mixed workloads to the server. Only supporting reads means only half the work is done and the feature would be only half useful.&lt;/p&gt;</comment>
                            <comment id="14989446" author="anoop.hbase" created="Wed, 4 Nov 2015 12:12:41 +0000"  >&lt;p&gt;This is a specific case with parallel scan (split one scan into many scans) so I think we can do this impl only in Phoenix?  HBase allows to plugin custom scheduler.  And if the new scheduler in this patch goes into Phoenix and sets that in conf, we can achieve the same. So instead of setting groupId on Scan we may have to pass that as an attribute in Scan.  Parsing an attribute from a PB object is having bit more overhead still not much IMO..  So we wont complicate things in HBase..   Thoughts?&lt;/p&gt;</comment>
                            <comment id="14989451" author="anoop.hbase" created="Wed, 4 Nov 2015 12:14:48 +0000"  >&lt;p&gt;And we have RpcSchedulerFactory  exposed to Phoenix&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@InterfaceAudience.LimitedPrivate({HBaseInterfaceAudience.COPROC, HBaseInterfaceAudience.PHOENIX})
@InterfaceStability.Evolving
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; RpcSchedulerFactory {

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14989453" author="ram_krish" created="Wed, 4 Nov 2015 12:15:52 +0000"  >&lt;p&gt;Ya fine with this. HBase needs to expose the attributes KEY that can be used for setting the GROUP_ID and Phoenix needs to set that and the plugged new RPC scheduler may help in doing this stuff. &lt;/p&gt;</comment>
                            <comment id="14989500" author="anoop.hbase" created="Wed, 4 Nov 2015 12:58:54 +0000"  >&lt;p&gt;No need to expose any Key.. Phoenix has its own naming convention for attributes it use.  (we use attributes in Scan itself)  Can name the new key also in similar way.  HBase has nothing to do with that key any way then.&lt;/p&gt;</comment>
                            <comment id="14989819" author="apurtell" created="Wed, 4 Nov 2015 16:18:49 +0000"  >&lt;p&gt;Doing this entirely over in Phoenix would obviously remove concerns we have over on the HBase side. If that&apos;s how you&apos;d like to proceed please resolve this JIRA accordingly.&lt;/p&gt;</comment>
                            <comment id="14989826" author="apurtell" created="Wed, 4 Nov 2015 16:22:51 +0000"  >&lt;p&gt;If this is to be a Phoenix-only thing may I suggest the implementation should depend on HBase LimitedPrivate or Public interfaces only. This way we won&apos;t have a repeat of the problems we&apos;ve faced with local indexing. Not a HBase issue so much as a potential maintenance headache for Phoenix, FWIW. If the available interfaces so designated are insufficient please open issues for what you need. &lt;/p&gt;</comment>
                            <comment id="14989896" author="jamestaylor" created="Wed, 4 Nov 2015 16:54:58 +0000"  >&lt;p&gt;The round robin scheduler could live in Phoenix, but we still need a way of configuring a different executor on the cluster. Plus what Andrew said - we should be able to only use LimitedPrivate or Public interfaces in our implementation of the round robin scheduler.&lt;/p&gt;</comment>
                            <comment id="14989995" author="ram_krish" created="Wed, 4 Nov 2015 17:35:43 +0000"  >&lt;p&gt;There are few things to check here. Once Phoenix allows this type of factory and since this is an external entity adding to hbase&apos;s scheduling - then the executors to be used with Replication, the type of queues like fifo, deadline everything needs to be handled. &lt;br/&gt;
So if HBase adds some new type of Executor all that needs to be included and as Andrew said maintenance will be a tougher. &lt;/p&gt;</comment>
                            <comment id="14990016" author="apurtell" created="Wed, 4 Nov 2015 17:44:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;then the executors to be used with Replication, the type of queues like fifo, deadline everything needs to be handled. So if HBase adds some new type of Executor all that needs to be included and as Andrew said maintenance will be a tougher.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We have a window, potentially narrow, to get in a refactor of pluggable scheduling for 1.2 and up.&lt;/p&gt;

&lt;p&gt;As I mentioned on the RB for this work (at &lt;a href=&quot;https://reviews.apache.org/r/32447/diff/4/?file=1078465#file1078465line104&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/32447/diff/4/?file=1078465#file1078465line104&lt;/a&gt;), it&apos;s unfortunate that schedulers hard code the selection of executors and queue types.&lt;/p&gt;

&lt;p&gt;/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14990039" author="busbey" created="Wed, 4 Nov 2015 17:57:50 +0000"  >&lt;p&gt;FYI, jiras I&apos;m waiting on to feature-freeze branch-1.2:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14712&quot; title=&quot;MasterProcWALs never clean up&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14712&quot;&gt;&lt;del&gt;HBASE-14712&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14329&quot; title=&quot;Report region in transition only ever operates on one region&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14329&quot;&gt;&lt;del&gt;HBASE-14329&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14233&quot; title=&quot;Branch-1.2 Merging regions can result in messed up tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14233&quot;&gt;&lt;del&gt;HBASE-14233&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I might try to convince folks to bump the first two if there isn&apos;t progress this week.&lt;/p&gt;</comment>
                            <comment id="14991075" author="ram_krish" created="Thu, 5 Nov 2015 03:50:19 +0000"  >&lt;p&gt;Am not sure whether within in end of this week can come up with a change of avoiding the hardcoded selection of executors and queue types. I have a patch ready for trunk that supports groupid for client operations. Will try to come up with tasks that needs to be done in hbase if Phoenix has to have this RoundRobinScheduler. &lt;/p&gt;</comment>
                            <comment id="14991231" author="stack" created="Thu, 5 Nov 2015 06:35:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;We will extend the groupid concept to all the client requests. That includes scan, gets, MutateRequest, MultiRequest, Bulkloadrequest etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry. Wasn&apos;t party to the conversation, but this seems at first blush (until I hear more), like the wrong direction completely. Rather than making Scan &quot;staccato&quot;, a notion that I think you could argue should be the default behavior when scanning (its already sortof &apos;staccato&apos; given its going to be preading from hdfs), instead, the codebase is to be littered with this arbitrary &apos;groupid&apos; doohickey thingy that, truth be told, is a phoenix thing (yeah, others could use it but its so exotic, only phoenix will be able to make sense of it).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This will allow every Put, Delete, Increment, Append, Get and Scan to have a grouping id. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Stinks!! (Not  directed at you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; but whoever all who came up w/ this notion sir).&lt;/p&gt;

&lt;p&gt;Why we need groupid at all? Scan already has an identifier kept in lease accounting, etc. If you want grouping, arbitrate by Connection. If Connection to coarse for a client, have your client create a new Connection per its notion of &apos;group&apos;, whatever that is.&lt;/p&gt;

&lt;p&gt;A roundrobin scheduler that lives in phoenix only and that requires a rolling restart and dedication of the cluster to phoenix-only workloads is one way to solve this, yeah, but it seems like you have a generic problem and a generic soln is not that far away as I see it making use of attributes already available to you. The generic approach could be less work and more generally beneficial.&lt;/p&gt;</comment>
                            <comment id="14991246" author="ram_krish" created="Thu, 5 Nov 2015 06:54:53 +0000"  >&lt;p&gt;To me having grouping Id for scan was ok but not to other requests.  We could go with Attributes and that is a very simple approach - but the problem was that even if Phoenix wants to add its own scheduler to the installations, the executors are not configurable, So its better we try to allow HBase to configure its executors and queues for replication and priority executions and  the basic read and write executors. Doing this would allow Phoenix to use its own impl of read and write part of the executors alone rather than have to replace the entire stuff. If you see in the current patch we only try to tweak this executor and all the other executors and queues are left the older way. Though HBase allows configuring its own schedulers it is not so generic.&lt;/p&gt;
</comment>
                            <comment id="14992100" author="stack" created="Thu, 5 Nov 2015 17:51:58 +0000"  >&lt;p&gt;Phoenix shouldn&apos;t have to add its own scheduler. Phoenix changing basic functionality of hbase is not sustainable; for phoenix nor hbase; neither project has resources to ensure custom scheduler and executor setups perform and are bug free at scale. Phoenix shouldn&apos;t have to do hbase customization given that what Phoenix wants of the scheduler is super basic (staccato scan rather than sustained). I&apos;ve asked if this groupid specialization is a deal breaker or will pulling on exisiting attributes whether connection identifier or scan attributes will do. I may have been answered above or over in rb but have not seen it if I have.&lt;/p&gt;</comment>
                            <comment id="14993243" author="ram_krish" created="Fri, 6 Nov 2015 06:59:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;ve asked if this groupid specialization is a deal breaker or will pulling on exisiting attributes whether connection identifier or scan attributes will do. I may have been answered above or over in rb but have not seen it if I have.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Scan attributes alone will not do IMHO because the queues cannot do this round robin for now. It can handle only priority but cannot round robin within the same priority.&lt;br/&gt;
Let me see if the connection identifier can be of any use. Then use this connection identifier to go thro a queue that can do the round robin with the connection identifier. Let me check that more closely in terms of phoenix code also. &lt;/p&gt;</comment>
                            <comment id="14994488" author="jamestaylor" created="Fri, 6 Nov 2015 21:41:00 +0000"  >&lt;p&gt;If HBase can provide a means for Phoenix to realize its SLAs across a fully loaded cluster, then we&apos;ll happily leverage it. The current HBase FIFO scheduled doesn&apos;t do that, so we need to either make it pluggable or provide a scheduler that does. The current patch solves the issue - how about we do the simple suggestion that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; suggested to fix up the patch to handle writes too?&lt;/p&gt;</comment>
                            <comment id="14994538" author="stack" created="Fri, 6 Nov 2015 22:01:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;Scan attributes alone will not do IMHO because the queues cannot do this round robin for now.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;They can round robin over the Scans but you are saying the scheduler needs to distinguish at a higher level than per Scan? It can&apos;t arbitrate on Scanner lease or a Scanner id attribute? Scheduler needs to make sure that we schedule scans from different clients... We could just schedule the same client over and over and shut out all others?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Let me check that more closely in terms of phoenix code also.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...or provide a scheduler that does.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree with this bit. Long scans or a single client hogging server resources is broke for everyone. Lets fix it for all rather than just for phoenix?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;....how about we do the simple suggestion that Andrew Purtell suggested to fix up the patch to handle writes too?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Because it pulls in an alien notion of &apos;groups&apos;, a tiering/complication that we can hopefully do without.&lt;/p&gt;

</comment>
                            <comment id="14994815" author="apurtell" created="Sat, 7 Nov 2015 01:11:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;Long scans or a single client hogging server resources is broke for everyone. Lets fix it for all rather than just for phoenix?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So to do that we need to give clients a way to label requests for QoS and then give them a way (or build in something we do automatically) to schedule on the server side according to label and some policy. I agree the current patch has issues but it does head toward implementing this strategy. We don&apos;t have to call it &quot;groups&quot; or make the currently proposed API changes if someone has a better approach in mind. &lt;/p&gt;</comment>
                            <comment id="14994819" author="apurtell" created="Sat, 7 Nov 2015 01:13:48 +0000"  >&lt;p&gt;It&apos;s also not only about scans. Any of the batch ops can run for a long time. &lt;/p&gt;</comment>
                            <comment id="14994830" author="apurtell" created="Sat, 7 Nov 2015 01:24:28 +0000"  >&lt;p&gt;Should this take a while to hash out and/or be a 2.0 thing, Phoenix can almost entirely do its own thing. The one enabling piece missing is a priority/group/whatever label carried in the RPC from the client to the (pluggable) scheduler. &lt;/p&gt;</comment>
                            <comment id="14994869" author="eclark" created="Sat, 7 Nov 2015 01:55:07 +0000"  >&lt;p&gt;RPC already has priority.  Adding more fields seems really dubious when we&apos;re not even using that one well yet.&lt;/p&gt;</comment>
                            <comment id="14994874" author="stack" created="Sat, 7 Nov 2015 01:59:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;So to do that we need to give clients a way to label requests for QoS and then give them a way (or build in something we do automatically) to schedule on the server side according to label and some policy. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Description asks for something much more basic than means of QoS based on a request settable label with policy-based handling. It &amp;#8211; and the patch &amp;#8211; are only about Scans. No problem broadening scope of the issue...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We don&apos;t have to call it &quot;groups&quot; or make the currently proposed API changes if someone has a better approach in mind.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Will the server round-robin&apos;ing amongst the client connections work for phoenix?&lt;/p&gt;</comment>
                            <comment id="14995037" author="apurtell" created="Sat, 7 Nov 2015 05:03:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;RPC already has priority.  Adding more fields seems really dubious when we&apos;re not even using that one well yet.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not dubious at all when there&apos;s a user lined up to take advantage of it. And optional protobuf fields cost nothing when not used. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will the server round-robin&apos;ing amongst the client connections work for phoenix?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this addresses the scenario described way up on the description: client A issues 100 parallel scans, so does client B, we don&apos;t want A&apos;s work to delay B&apos;s work. This suggests to me A and B are separate clients hence separate connections. Therefore dispatching work queued per connection in a round robin manner would satisfy the problem as stated there. Is that correct &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=giacomotaylor&quot; class=&quot;user-hover&quot; rel=&quot;giacomotaylor&quot;&gt;James Taylor&lt;/a&gt; ? However the description must miss some requirement because when working up the patch &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; then introduces the group ID claiming it&apos;s needed for the Phoenix use case and James follows up saying it&apos;s only the client who knows what work belongs in one &quot;group&quot; versus another. But is that absolutely necessary?&lt;/p&gt;</comment>
                            <comment id="14995039" author="apurtell" created="Sat, 7 Nov 2015 05:06:59 +0000"  >&lt;p&gt;BTW I personally see allowing a label to be passed and consumed by a scheduler as something generically useful but I do apologize because going off on that tangent for that reason complicates the discussion. &lt;/p&gt;

&lt;p&gt;Waiting to hear back from the Phoenix peeps. &lt;/p&gt;</comment>
                            <comment id="14995056" author="jamestaylor" created="Sat, 7 Nov 2015 05:39:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;Will the server round-robin&apos;ing amongst the client connections work for phoenix?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That won&apos;t work because an HConnection is shared by all the clients on the same JVM.&lt;/p&gt;</comment>
                            <comment id="14995080" author="stack" created="Sat, 7 Nov 2015 07:10:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Therefore dispatching work queued per connection in a round robin manner would satisfy the problem as stated there.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thank you for the summary and intercession &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrew.purtell%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;andrew.purtell@gmail.com&quot;&gt;Andrew Purtell&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That won&apos;t work because an HConnection is shared by all the clients on the same JVM.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not so &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=giacomotaylor&quot; class=&quot;user-hover&quot; rel=&quot;giacomotaylor&quot;&gt;James Taylor&lt;/a&gt;, not since hbase 1.0. But I can see where you are coming from; previous to 1.0, connection handling was voodoo. The connection handling is for the client to manage now.&lt;/p&gt;

&lt;p&gt;If a client wants to run a particular configuration (priority, etc.), I suggest that it open a new connection and set attributes appropriately and away you go. It will be easier on the server to sort the incoming loading/scheduling on a Connection-basis rather than on a per-request-and-then-on-group basis. Would this work for phoenix mighty James?&lt;/p&gt;</comment>
                            <comment id="14995085" author="jamestaylor" created="Sat, 7 Nov 2015 07:18:28 +0000"  >&lt;p&gt;Phoenix already manages the connections. We share the same HConnection for clients on the same JVM because opening an HConnection is expensive - that&apos;s why I was saying this option won&apos;t work. &lt;/p&gt;</comment>
                            <comment id="14995792" author="stack" created="Sun, 8 Nov 2015 20:29:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;We share the same HConnection for clients on the same JVM because opening an HConnection is expensive - that&apos;s why I was saying this option won&apos;t work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If Connection set up was fast, would arbitrating on Connection work for your use case?&lt;/p&gt;

&lt;p&gt;On slow Connection setup, how long you seeing? How long is too much (these are long scans, right?)? Connections taking a long time to set up is something worth working on (share cache of regions, share zookeeper). Could do pool of Connections too... that seems pretty standard way of dealing with slow connection setup.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
</comment>
                            <comment id="14995824" author="jamestaylor" created="Sun, 8 Nov 2015 21:52:40 +0000"  >&lt;p&gt;What&apos;s the resistance to having a round robin scheduler? Conceptually it&apos;s pretty simple and I think it&apos;s a good addition to HBase. The client just needs to pass some kind of identifier that tells the server that these operations are &quot;one operation&quot; that should be round robin-ed against others (that&apos;s the GroupID - we can name it something else too and it&apos;s fine as an attribute or new field). &lt;/p&gt;

&lt;p&gt;It&apos;s not Phoenix specific either. Another common use case would be if multiple MR jobs are running against a cluster - all the mappers from a given job could use the same identifier (i.e. identifying them conceptually as &quot;one operation&quot;). Then these map tasks would be round robin-ed against other sets of map task from other MR jobs.&lt;/p&gt;

&lt;p&gt;This is a real issue right now and there&apos;s a patch available (which has taken considerable effort - started back in Feb 2015). We&apos;ve perf tested it under scale and it looks good. What&apos;s the reason to &lt;b&gt;not&lt;/b&gt; have this optionally configurable, round-robin scheduler?&lt;/p&gt;</comment>
                            <comment id="14995841" author="jamestaylor" created="Sun, 8 Nov 2015 22:21:42 +0000"  >&lt;p&gt;How about this proposal?&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Address the write-side of the equation as Andrew suggested for this patch. That seems like a pretty straightforward fix that could be documented.&lt;/li&gt;
	&lt;li&gt;Longer term, for 2.0, a new client-side operation class is introduced for batch operations (BatchOperation) so that the client would have a place to set the GroupID (or whatever we call it) for batch operations. It&apos;d also be useful to have a way to set attributes for an entire batch and this could server that purpose as well.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14995953" author="stack" created="Mon, 9 Nov 2015 02:32:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;What&apos;s the resistance to having a round robin scheduler?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;None. See above where I argue this should probably be made the default. The discussion is about what to round robin over. Please answer the question asked (allow that there is a ConnectionPool as there is for other DBs so no setup-time in-line).&lt;/p&gt;

&lt;p&gt;Your Maptask illustration doesn&apos;t help your case given each Mapper will put up its own Connection (it is an argument in favor of scheduling across Connections).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What&apos;s the reason to not have this optionally configurable, round-robin scheduler?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The argument has been made a few times above (i.e. introduces a new tier/complexity/friction on scheduler when it doesn&apos;t seem like we need it, when it looks like we can do a more simple approach that would work inherently without apps having to ask for the behavior... etc.)&lt;/p&gt;</comment>
                            <comment id="14995996" author="jamestaylor" created="Mon, 9 Nov 2015 04:02:19 +0000"  >&lt;p&gt;My Maptask illustrates another reason to have the round-robining mechanism supported in this patch. As you&apos;ve pointed out this is independent of connections. I&apos;m not advocating a Connection-based approach. Opening a new HConnection takes three seconds. It&apos;s not feasible to pool enough HConnections to support the concurrency we see over the various types of queries.&lt;/p&gt;

&lt;p&gt;I don&apos;t get the &quot;complexity/friction on scheduler&quot; bit. It&apos;s pretty straight forward from the client point of view.&lt;/p&gt;
</comment>
                            <comment id="14996383" author="ram_krish" created="Mon, 9 Nov 2015 11:10:32 +0000"  >&lt;p&gt;The confusion of exposing groupID API can be avoided by going with Attributres but still for the write part we cannot set the attribute for the entire batch.&lt;br/&gt;
Going thro the comments over here - If we go with per connection approach - it would mean that all the requests coming from one client will have the same groupid (what ever the name it can be).  This id will be set in every request that that client processes and based on that id the scheduler decides on the round robin part.  This will include both reads and writes.&lt;br/&gt;
So this will not be working out for same JVM different clients and will work only if the parallel scans and the point queries are issued by 2 different clients. Am i missing some thing here?&lt;/p&gt;</comment>
                            <comment id="14996945" author="apurtell" created="Mon, 9 Nov 2015 17:26:32 +0000"  >&lt;p&gt;If we can all conceptually agree on round robin scheduling of connections then the gap here is pretty small. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Opening a new HConnection takes three seconds. It&apos;s not feasible to pool enough HConnections to support the concurrency we see over the various types of queries.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then can we make this faster? &lt;/p&gt;

&lt;p&gt;For example, when creating a new Connection object, it is not strictly necessary this must map 1:1 with communication channels at the RPC layer or TCP connections on the wire. Why can&apos;t a new Connection transparently re-use the communication channel constructed by a previous instance? In which case the distinction between the new Connection and previous is a logical identifier. A logical identifier carried in requests that can be used to schedule round robin on the server. A logical identifier which does not need to be exposed to the application. The application has control of round-robin dispatch through its allocation of Connection objects. &lt;/p&gt;
</comment>
                            <comment id="14997005" author="jamestaylor" created="Mon, 9 Nov 2015 17:55:10 +0000"  >&lt;p&gt;The Connection level idea doesn&apos;t solves the issue for our use case. We&apos;ll soon have MR jobs intermingled with Phoenix queries and this Connection-level model doesn&apos;t address this.&lt;/p&gt;</comment>
                            <comment id="14997011" author="apurtell" created="Mon, 9 Nov 2015 17:58:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;The Connection level idea doesn&apos;t solves the issue for our use case. We&apos;ll soon have MR jobs intermingled with Phoenix queries and this Connection-level model doesn&apos;t address this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The patch as-is isn&apos;t getting in so we need to find some consensus middle ground. I tried to do that above. &lt;/p&gt;</comment>
                            <comment id="14997058" author="apurtell" created="Mon, 9 Nov 2015 18:25:19 +0000"  >&lt;p&gt;On complexity.&lt;/p&gt;

&lt;p&gt;We&apos;ve added a lot of knobs and extension surfaces over the years rather than make architectural decisions that would tame complexity at the expense of addressing some use cases.&lt;/p&gt;

&lt;p&gt;Perhaps one of the worst offenses in that regard is coprocessors. I&apos;m saying that even as the person who designed them. (smile) Now of course as a means for mixin platform extensions they&apos;ve been really successful, and have enabled even something like Phoenix, which is a wild success. At the same time, when thinking about sources of complexity, the coprocessor API is right up there because by it&apos;s nature it will leak internal implementation detail all over the place. We hope coprocessor applications will treat internal data types as opaque but can&apos;t enforce that. The potential for abuse is acute. I will refrain from more than the briefest mention of local indexing.&lt;/p&gt;

&lt;p&gt;Moreover having internal extensions invites apps like Phoenix who want to, of course, make good use of other HBase internals, since they are available, leading to additional sources of abstraction leakage. On some level this is expected and ok. A risk we always have to face, though, is once we have external users of an interface we are locked into supporting its semantics as-is, or at least to providing a path to upgrade, leading to a backwards compatible code path for every iteration on semantics, even the stuff that leaked which shouldn&apos;t have. A good example of this latter phenomenon IMHO is pluggable RPC scheduling as it is today.&lt;/p&gt;

&lt;p&gt;I&apos;m not fond of the idea of applications plugging in RPC schedulers, as they are currently designed. This part of the code was meant to be private, but was promoted to LP once Phoenix extended it for indexing. I think we can debate if this was the right choice. I think it was a reasonable decision at the time and won&apos;t relitigate it, mainly because I had a big hand in it (smile). However someone with a critical perspective could call it an expedient tactical decision leaving behind an architectural smell, and they would have a point. RPC schedulers most unfortunately must specify some hard coded details on executor types and queue types. This will be a problem because third party scheduler implementations will not have the same velocity as HBase core as executor types and queue types change and maybe the whole area of scheduling is refactored. This design problem wasn&apos;t considered back when it wasn&apos;t expected third parties would plug in schedulers. Now, we&apos;ll have to live with it somehow. &lt;/p&gt;

&lt;p&gt;In that spirit let us turn and consider the current patch here and its approach. We are doubling down on leaking internal RPC scheduling implementation minutiae to third parties. Tagging RPC requests with a &quot;group ID&quot;. What is a group ID? Not discussed or documented. How is it used? Not discussed or documented, but we can look at the code. When we dig in, only scans are tagged. WTF? What about the other RPC types? What is the objective? A clean design rationalized across all HBase operation types? No, it&apos;s not that. If we accept this patch into our RPC we must support it &quot;forever&quot;. Not everyone thinks that is a good idea. One thing we can all agree on about this patch, if accepted as is it will be another expedient tactical decision leaving behind another architectural smell.&lt;/p&gt;

&lt;p&gt;We may simply need to reset this whole conversation and start over with a design discussion. What is the fundamental need? How can we address it in a way this developer community as a whole feels comfortable supporting going forward? Reviewing this JIRA from top to bottom, it looks to me like we had a problem specification, followed immediately by a tactical patch. We skipped over design discussion and therefore have reached an impasse.&lt;/p&gt;</comment>
                            <comment id="14997232" author="stack" created="Mon, 9 Nov 2015 19:43:30 +0000"  >&lt;p&gt;Thanks for the eloquence &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; summarizing where we are at and how we got here using illustration from our community past. I also appreciate and agree with your outline of the positions involved and for hitting the reset button (should have been done long ago). &lt;/p&gt;

&lt;p&gt;When we reset, can the discussion be more grounded?&lt;/p&gt;

&lt;p&gt;For example, &quot;Opening a new HConnection takes three seconds...&quot; I just measured it against a cluster. Total connection setup takes 20ms... less if I let the JVM warm up. Its 3.5 seconds to start a cold JVM, hit about 40 regions, then completely shut all down again. Improving Connection setup is an issue many could benefit from so would be worth doing in general. We can work on sharing cache/zk over Connections too.&lt;/p&gt;

&lt;p&gt;Or, &quot;It&apos;s not feasible to pool enough HConnections to support the concurrency we see over the various types of queries.&quot;... Please substantiate your claim with numbers and use case.&lt;/p&gt;


</comment>
                            <comment id="14997269" author="jamestaylor" created="Mon, 9 Nov 2015 20:09:23 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; - appreciate the write-up.&lt;/p&gt;

&lt;p&gt;Hopefully there&apos;s enough information to feed into requirements from a user perspective: round robin across parallelized operations and MR jobs running on the same cluster to prevent one job from locking out others.&lt;/p&gt;

&lt;p&gt;Would be good if we can stay on subject too. I&apos;ve already pointed out why the round-robining on Connections won&apos;t meet the use case.&lt;/p&gt;</comment>
                            <comment id="14997572" author="stack" created="Mon, 9 Nov 2015 22:51:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;ve already pointed out why the round-robining on Connections won&apos;t meet the use case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jamestaylor&quot; class=&quot;user-hover&quot; rel=&quot;jamestaylor&quot;&gt;James Taylor&lt;/a&gt; Nah. Arguments based on hyperbole and unsubstantiated &apos;concurrency we see&apos; do not carry any weight hereabouts. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We&apos;ll soon have MR jobs intermingled with Phoenix queries and this Connection-level model doesn&apos;t address this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Just have MR tasks schedule at a lower priority.&lt;/p&gt;

&lt;p&gt;It doesn&apos;t have to be a &apos;connection-based&apos; solution. It just can&apos;t be a bunch of new complexity whether a new scheduling tier (My objection has been there since the first patch was posted back in March), new configurations, or plugin points that inevitably just rot but meantime the project needs to keep them up &apos;just-in-case&apos;.&lt;/p&gt;

&lt;p&gt;The use case seems to have expanded significantly since this issue began. It has to be round robin over all ops?  We are to chunk-in large writes? That is a massive undertaking. Suggest you rein in your requirements there &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jamestaylor&quot; class=&quot;user-hover&quot; rel=&quot;jamestaylor&quot;&gt;James Taylor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This exposition, &lt;a href=&quot;http://blog.cloudera.com/blog/2014/12/new-in-cdh-5-2-improvements-for-running-multiple-workloads-on-a-single-hbase-cluster/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://blog.cloudera.com/blog/2014/12/new-in-cdh-5-2-improvements-for-running-multiple-workloads-on-a-single-hbase-cluster/&lt;/a&gt;, covers most of what has been discussed above. Would be useful if what is wanted here in this issue was situated relative to this previous work. It mentions means of  deprioritizing long-running scans (IIRC, results were murky... worth further investigation) and Scanners have since this citation was written been redone so they can return after a certain size and/or time threshold has been crossed. This latter will help mitigate long-running scans shutting out others. In this new regime, its as though a pure round-robin scheduler that did not distinguish on any attribute &amp;#8211; group or connection &amp;#8211; could work especially if long-running scans were weighted so they were scheduled less frequently.&lt;/p&gt;</comment>
                            <comment id="14997639" author="jamestaylor" created="Mon, 9 Nov 2015 23:24:10 +0000"  >&lt;p&gt;Glad to see you&apos;re working on that over at Cloudera. Hopefully you&apos;re testing with Phoenix too.&lt;/p&gt;

&lt;p&gt;I don&apos;t think having an extra optional attribute on an operation adds &quot;a bunch of new complexity&quot;. That&apos;s fine if we disagree.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; made the point that if you&apos;re round robining on reads you should be consistent and do it on writes too - I think this is a fair point. Our immediate need is on the read side - I&apos;ll share our data when the analysis is complete.&lt;/p&gt;

&lt;p&gt;Our requirement is simple: the latency of point lookups and small-ish scans shouldn&apos;t be impacted by other workloads on the cluster. What ever implementation you come up with is fine by us.&lt;/p&gt;</comment>
                            <comment id="14999067" author="stack" created="Tue, 10 Nov 2015 18:25:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Glad to see you&apos;re working on that over at Cloudera.  Hopefully you&apos;re testing with Phoenix too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You did not read it. It is not &quot;cloudera&quot; work. It is apache hbase work. See listed JIRAs.  It is a summary of the state of scheduling art in apache hbase as of a while ago.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t think having an extra optional attribute on an operation adds &quot;a bunch of new complexity&quot;. That&apos;s fine if we disagree.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Andrews&apos; considered response &apos;On complexity&apos; plainly left no mark and you can&apos;t have reviewed the attached patch and comments. Only a superficial engagement with this issue and what all is involved could result in a characterization of what is going on here as just &quot;having an extra optional attribute&quot; (or that the cited, pertinent blog post is &apos;cloudera&apos; work).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Andrew Purtell made the point that if you&apos;re round robining on reads you should be consistent and do it on writes too - I think this is a fair point. Our immediate need is on the read side - I&apos;ll share our data when the analysis is complete... Our requirement is simple: the latency of point lookups and small-ish scans shouldn&apos;t be impacted by other workloads on the cluster. What ever implementation you come up with is fine by us.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Your requirement changes every time you comment and you do not know what you are asking for.&lt;/p&gt;

&lt;p&gt;Let me try and write something up and situate it relative to work already done.&lt;/p&gt;</comment>
                            <comment id="14999119" author="apurtell" created="Tue, 10 Nov 2015 19:00:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hopefully there&apos;s enough information to feed into requirements from a user perspective: round robin across parallelized operations and MR jobs running on the same cluster to prevent one job from locking out others.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There may be an implicit &quot;in 0.98&quot; here too. Let&apos;s remove that, if so, because:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;(In 1.1 and up) Scanners can return after a certain size and/or time threshold has been crossed&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Step 1: Have both Phoenix scanners and those MR jobs set these parameters to constrain the amount of time each scanner.next call will run. Let&apos;s double check that we can set the defaults we want in site configuration. &lt;/p&gt;

&lt;p&gt;Step 2: On the server, as a generic and transparent improvement, have the scheduler round-robin requests between connections.&lt;/p&gt;

&lt;p&gt;With both of these in place, we get:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;No one client can starve other clients. That means Phoenix work is interleaved with MR work on the server side. This is what you want.&lt;/li&gt;
	&lt;li&gt;Within your own single connection, no unit of work will exceed time X. This doesn&apos;t give you everything you want &quot;within the connection&quot; but you can work with this, because the server will give you ~deterministic performance per op.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Now you can take the queue of local work - you own this, this is client side, HBase server side doesn&apos;t (and can&apos;t) know about internal client priorities - and make sure if you have internal notions of &quot;this is for query A&quot; and &quot;that is for query B&quot; that you interleave calls to scanner.next for A and B. It&apos;s more work than naively blasting ops at the servers and expecting the server side to handle differentiated QoS &quot;within the connection&quot;, but this is the step too far the community doesn&apos;t want (yet). Leave this out and we might arrive at agreement.&lt;/p&gt;</comment>
                            <comment id="14999155" author="apurtell" created="Tue, 10 Nov 2015 19:17:57 +0000"  >&lt;p&gt;Just throwing out ideas, considering existing interfaces:&lt;/p&gt;

&lt;p&gt;We might also consider if Phoenix&apos;s overloading of scanner.next processing on the server can help here. Scan parameters can be changed on the way in on the server side (in the preXXX hooks) according to Phoenix&apos;s view of the arriving requests.&lt;/p&gt;

&lt;p&gt;A static adjustment for predictable performance could be enough.&lt;/p&gt;

&lt;p&gt;However, there are interesting opportunities for making dynamic changes here: As workload increases, perhaps measured by arrival rate or by an estimation of query perf characteristics (like estimated cardinality), the amount of work by time performed by each scanner.next iteration can be made smaller, providing lower latency / better responsiveness when work is interleaved at the expense of throughput. As workload decreases, the quanta can be increased, optimizing for better throughput. &lt;/p&gt;

&lt;p&gt;In any case it&apos;s really up to the coprocessor application what wants to do with respect to rewriting scan parameters on the server. (And up to the client / query planner how it wants to set up scan parameters in the first place.)&lt;/p&gt;</comment>
                            <comment id="15001806" author="jamestaylor" created="Thu, 12 Nov 2015 07:43:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;and make sure if you have internal notions of &quot;this is for query A&quot; and &quot;that is for query B&quot; that you interleave calls to scanner.next for A and B. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; We already do that, but it won&apos;t mitigate the case when a number of clients run only a single large scan. The RS is the ultimate arbitrator.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Your requirement changes every time you comment&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; Not true. I&apos;ve stated it clearly above. I&apos;ve just given you more examples of why the round-robin-on-connection won&apos;t solve this issue. Here&apos;s another one: Apache Drill + Phoenix. There will be large scans parallelized across many distributed client nodes. It&apos;s useful for the RS scheduler to know that they&apos;re linked so that it can round-robin between them. It&apos;s similar to the MR job, but these wouldn&apos;t be batch queries, but interactive queries.&lt;/p&gt;

&lt;p&gt;When I said it was simple, I&apos;m talking from the users POV. It really is just having an extra optional attribute on an operation that links them together as one &quot;virtual operation&quot;. I agree that the implementation is kind of a mess.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; - those idea you floated are all good potential workarounds that we may need to resort to. Would be good to start with a good test case and a design IMHO. Maybe that&apos;s something we can all agree on.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12689630" name="AbstractRoundRobinQueue.java" size="8891" author="jamestaylor" created="Wed, 31 Dec 2014 03:22:34 +0000"/>
                            <attachment id="12705643" name="HBASE-12790.patch" size="76133" author="ram_krish" created="Thu, 19 Mar 2015 17:47:25 +0000"/>
                            <attachment id="12706892" name="HBASE-12790_1.patch" size="94416" author="ram_krish" created="Tue, 24 Mar 2015 12:11:58 +0000"/>
                            <attachment id="12755075" name="HBASE-12790_5.patch" size="121754" author="ram_krish" created="Thu, 10 Sep 2015 06:38:38 +0000"/>
                            <attachment id="12725838" name="HBASE-12790_callwrapper.patch" size="122380" author="ram_krish" created="Thu, 16 Apr 2015 11:06:22 +0000"/>
                            <attachment id="12755372" name="HBASE-12790_trunk_1.patch" size="122394" author="ram_krish" created="Fri, 11 Sep 2015 10:23:33 +0000"/>
                            <attachment id="12766893" name="PHOENIX_4.5.3-HBase-0.98-2317-SNAPSHOT.zip" size="327364" author="apurtell" created="Thu, 15 Oct 2015 21:56:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 19 Mar 2015 17:47:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 5 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23vfr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>