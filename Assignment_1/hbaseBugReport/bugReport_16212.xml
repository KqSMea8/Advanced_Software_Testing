<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:11:34 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-16212/HBASE-16212.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-16212] Many connections to datanode are created when doing a large scan </title>
                <link>https://issues.apache.org/jira/browse/HBASE-16212</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;As described in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-8659&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-8659&lt;/a&gt;, the datanode is suffering from logging the same repeatedly. Adding log to DFSInputStream, it outputs as follows:&lt;/p&gt;

&lt;p&gt;2016-07-10 21:31:42,147 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;B.defaultRpcServer.handler=22,queue=1,port=16020&amp;#93;&lt;/span&gt; hdfs.DFSClient: DFSClient_NONMAPREDUCE_1984924661_1 seek DatanodeInfoWithStorage&lt;span class=&quot;error&quot;&gt;&amp;#91;10.130.1.29:50010,DS-086bc494-d862-470c-86e8-9cb7929985c6,DISK&amp;#93;&lt;/span&gt; for BP-360285305-10.130.1.11-1444619256876:blk_1109360829_35627143. pos: 111506876, targetPos: 111506843&lt;br/&gt;
 ...&lt;br/&gt;
As the pos of this input stream is larger than targetPos(the pos trying to seek), A new connection to the datanode will be created, the older one will be closed as a consequence. When the wrong seeking ops are large, the datanode&apos;s block scanner info message is spamming logs, as well as many connections to the same datanode will be created.&lt;/p&gt;

&lt;p&gt;hadoop version: 2.7.1&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12988520">HBASE-16212</key>
            <summary>Many connections to datanode are created when doing a large scan </summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="10004">Not A Bug</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="dengzh">Zhihua Deng</reporter>
                        <labels>
                    </labels>
                <created>Tue, 12 Jul 2016 03:19:24 +0000</created>
                <updated>Mon, 7 Nov 2016 09:29:39 +0000</updated>
                            <resolved>Mon, 7 Nov 2016 09:29:39 +0000</resolved>
                                    <version>1.1.2</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="15372157" author="vrodionov" created="Tue, 12 Jul 2016 04:25:11 +0000"  >&lt;p&gt;This is HDFS client logging. &lt;/p&gt;</comment>
                            <comment id="15378986" author="dengzh" created="Fri, 15 Jul 2016 07:58:23 +0000"  >&lt;p&gt;I add log details to  DFSInputStream#seek(long targetPos):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(pos &amp;gt; targetPos) {
      DFSClient.LOG.info(dfsClient.getClientName() + &lt;span class=&quot;code-quote&quot;&gt;&quot; seek &quot;&lt;/span&gt; + getCurrentDatanode() + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &quot;&lt;/span&gt; + getCurrentBlock() +
              &lt;span class=&quot;code-quote&quot;&gt;&quot;. pos: &quot;&lt;/span&gt; + pos + &lt;span class=&quot;code-quote&quot;&gt;&quot;, targetPos: &quot;&lt;/span&gt; + targetPos);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The attached file named &apos;regionserver-dfsinputstream.log&apos; shows the process.&lt;/p&gt;

&lt;p&gt;Also in one of datanodes throw an exception of such a sudden close by the client side:&lt;br/&gt;
java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer&lt;br/&gt;
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)&lt;br/&gt;
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:427)&lt;br/&gt;
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:492)&lt;br/&gt;
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:607)&lt;br/&gt;
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:579)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:759)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:706)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:551)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.io.IOException: Connection reset by peer&lt;br/&gt;
	... 13 more&lt;/p&gt;

</comment>
                            <comment id="15379100" author="dengzh" created="Fri, 15 Jul 2016 09:27:50 +0000"  >&lt;p&gt;Remove the wrong unit test, The TestHFileBlock#testConcurrentReading test the case i want to.&lt;/p&gt;</comment>
                            <comment id="15381648" author="dengzh" created="Mon, 18 Jul 2016 02:59:20 +0000"  >&lt;p&gt;Similar to the case of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10676&quot; title=&quot;Removing ThreadLocal of PrefetchedHeader in HFileBlock.FSReaderV2 make higher perforamce of scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10676&quot;&gt;&lt;del&gt;HBASE-10676&lt;/del&gt;&lt;/a&gt;.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhaojianbo&quot; class=&quot;user-hover&quot; rel=&quot;zhaojianbo&quot;&gt;zhaojianbo&lt;/a&gt;,  could you help review this patch, thanks.&lt;/p&gt;</comment>
                            <comment id="15383156" author="stack" created="Mon, 18 Jul 2016 21:58:31 +0000"  >&lt;p&gt;Tell us more &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dengzh&quot; class=&quot;user-hover&quot; rel=&quot;dengzh&quot;&gt;Zhihua Deng&lt;/a&gt;? I think I get it. The thread local often held reference to a header from another file altogether and this was making for all the logging you were seeing?&lt;/p&gt;

&lt;p&gt;Looking at the patch you are making substantial changes removing the thread local that caches last header read by thread and instead doing the caching on the fsreaderimpl which is better in some ways but now we have a synchronization bottleneck for all threads to pass through. What you thinking here? You thinking it will be rare that more than one thread will be going against same file? Have you run with this patch?&lt;/p&gt;

&lt;p&gt;Is this patch for branch-1.1? Does master still have same issue (has same basic form but a bunch of refactoring has gone on in here).&lt;/p&gt;

&lt;p&gt;This patch looks like a nice one. Thanks.&lt;/p&gt;


</comment>
                            <comment id="15383158" author="stack" created="Mon, 18 Jul 2016 21:59:31 +0000"  >&lt;p&gt;Do you think we&apos;ll connect to the DN less freqently with this patch in place? Thanks.&lt;/p&gt;</comment>
                            <comment id="15383514" author="dengzh" created="Tue, 19 Jul 2016 03:08:30 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. From the logging, it implies that different threads share the same DFSInputStream instance, say &apos;defaultRpcServer.handler=7&apos;(handler7) and &apos;defaultRpcServer.handler=4&apos;(handler4), for example. The original will prefect the next block header and cache the header into thread. When defaultRpcServer.handler=4 comes,  it first checks that the cached header offset is equal to the the block starting offset, unfortunately these two numbers are unequal(-1 != offset). The handler4 knows nothing about the block header,  though the header has been prefected by handler7.  The handler4 needs to seek the inputstream with the block starting offset for the header,  while the inputstream has been over read by 33 bytes(the header size). So a new connection to datanode should be recreated, the elder one will be closed. When the datanode writes to a closed channel, a socket exception will be raised. When the same case happens frequently, the datanode will be suffered from logging the message described as it is.&lt;/p&gt;</comment>
                            <comment id="15383516" author="dengzh" created="Tue, 19 Jul 2016 03:10:29 +0000"  >&lt;p&gt;Test it on my cluster, a hmaster with two regionservers based on hbase-1.1.2, it works. Further test should carry on the master brunch&lt;/p&gt;</comment>
                            <comment id="15383565" author="dengzh" created="Tue, 19 Jul 2016 04:21:44 +0000"  >&lt;p&gt;Changing from threadlocal to synchronization, yes there will be a potential synchronization bottleneck, but it better than io operation.  So the question here is that how often the connection will be recreated for seeking + reading? The original threadlocal is declared as non static private field here,  it means that the created fsreaderimpl instance will be reused later on, also an inputstream is initiated when fsreaderimpl created. &lt;br/&gt;
Taken the case described in the attached log, The synchronization way is much better than threadlocal when acts as a sequential read .&lt;br/&gt;
How about concurrent case?  the worst case: Thread1.readBlockInternal -&amp;gt; Thread2.readBlockInternal -&amp;gt; Thread3.readBlockInternal -&amp;gt; Thread1.readBlockInternal -&amp;gt; ....&lt;br/&gt;
In this case, the synchronization way is equal to threadlocal when taken how many connections will be created into consideration.&lt;/p&gt;

</comment>
                            <comment id="15383580" author="stack" created="Tue, 19 Jul 2016 04:55:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dengzh&quot; class=&quot;user-hover&quot; rel=&quot;dengzh&quot;&gt;Zhihua Deng&lt;/a&gt; Makes sense. Nice one. Let me compare logging how many connections we make. Your patch should perform much better especially if any locality to the reads.&lt;/p&gt;</comment>
                            <comment id="15385485" author="dengzh" created="Wed, 20 Jul 2016 07:32:07 +0000"  >&lt;p&gt;Test on master branch, shows that the problem is rare so far. and Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;! &lt;/p&gt;</comment>
                            <comment id="15389757" author="anoop.hbase" created="Fri, 22 Jul 2016 16:15:31 +0000"  >&lt;p&gt;So as per this, when 2 threads work on same HFile, all chances that no one will see the correct prefetched header.&lt;br/&gt;
When the same scan flow happens and we move from one block to next, then also (yes we are in the same RS handler thread op) chances that the next block header set by this thread got reset by another in between.&lt;br/&gt;
both ways have pros and cons.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12818115" name="HBASE-16212.patch" size="8219" author="dengzh" created="Fri, 15 Jul 2016 07:40:23 +0000"/>
                            <attachment id="12818127" name="HBASE-16212.v2.patch" size="3674" author="dengzh" created="Fri, 15 Jul 2016 09:24:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 12 Jul 2016 04:25:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            21 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30ttz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>