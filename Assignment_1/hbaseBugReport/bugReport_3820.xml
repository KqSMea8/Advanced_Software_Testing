<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:13:25 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3820/HBASE-3820.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3820] Splitlog() executed while the namenode was in safemode may cause data-loss</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3820</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I found this problem while the namenode went into safemode due to some unclear reasons. &lt;br/&gt;
There&apos;s one patch about this problem:&lt;/p&gt;

&lt;p&gt;   try {&lt;br/&gt;
      HLogSplitter splitter = HLogSplitter.createLogSplitter(&lt;br/&gt;
        conf, rootdir, logDir, oldLogDir, this.fs);&lt;br/&gt;
      try &lt;/p&gt;
{
        splitter.splitLog();
      }
&lt;p&gt; catch (OrphanHLogAfterSplitException e) &lt;/p&gt;
{
        LOG.warn(&quot;Retrying splitting because of:&quot;, e);
        // An HLogSplitter instance can only be used once.  Get new instance.
        splitter = HLogSplitter.createLogSplitter(conf, rootdir, logDir,
          oldLogDir, this.fs);
        splitter.splitLog();
      }
&lt;p&gt;      splitTime = splitter.getTime();&lt;br/&gt;
      splitLogSize = splitter.getSize();&lt;br/&gt;
    } catch (IOException e) &lt;/p&gt;
{
      checkFileSystem();
      LOG.error(&quot;Failed splitting &quot; + logDir.toString(), e);
      master.abort(&quot;Shutting down HBase cluster: Failed splitting hlog files...&quot;, e);
    }
&lt;p&gt; finally &lt;/p&gt;
{
      this.splitLogLock.unlock();
    }

&lt;p&gt;And it was really give some useful help to some extent, while the namenode process exited or been killed, but not considered the Namenode safemode exception.&lt;br/&gt;
   I think the root reason is the method of checkFileSystem().&lt;br/&gt;
   It gives out an method to check whether the HDFS works normally(Read and write could be success), and that maybe the original propose of this method. This&apos;s how this method implements:&lt;/p&gt;

&lt;p&gt;    DistributedFileSystem dfs = (DistributedFileSystem) fs;&lt;br/&gt;
    try {&lt;br/&gt;
      if (dfs.exists(new Path(&quot;/&quot;))) &lt;/p&gt;
{  
        return;
      }
&lt;p&gt;    } catch (IOException e) &lt;/p&gt;
{
      exception = RemoteExceptionHandler.checkIOException(e);
    }

&lt;p&gt;   I have check the hdfs code, and learned that while the namenode was in safemode ,the dfs.exists(new Path(&quot;/&quot;)) returned true. Because the file system could provide read-only service. So this method just checks the dfs whether could be read. I think it&apos;s not reasonable.&lt;/p&gt;

</description>
                <environment></environment>
        <key id="12505149">HBASE-3820</key>
            <summary>Splitlog() executed while the namenode was in safemode may cause data-loss</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jeason">Jieshan Bean</reporter>
                        <labels>
                    </labels>
                <created>Tue, 26 Apr 2011 01:15:21 +0000</created>
                <updated>Fri, 20 Nov 2015 12:42:53 +0000</updated>
                            <resolved>Thu, 19 May 2011 21:15:35 +0000</resolved>
                                    <version>0.90.2</version>
                                    <fixVersion>0.90.4</fixVersion>
                                    <component>master</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13025039" author="stack" created="Tue, 26 Apr 2011 03:23:28 +0000"  >&lt;p&gt;@Jieshan Bean Please add a patch (See &apos;attach file&apos; above) with your change only in it.  See &lt;a href=&quot;http://wiki.apache.org/hadoop/Hbase/HowToContribute&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hbase/HowToContribute&lt;/a&gt; for how to make a patch if you are unclear.  Thank you.&lt;/p&gt;</comment>
                            <comment id="13025044" author="jeason" created="Tue, 26 Apr 2011 03:30:08 +0000"  >&lt;p&gt;Thanks stack.&lt;br/&gt;
I&apos;m just taking some test to verify my modification. And after that, I will commit the patch immediately.&lt;/p&gt;</comment>
                            <comment id="13027381" author="stack" created="Sat, 30 Apr 2011 21:17:58 +0000"  >&lt;p&gt;@Jieshan Sorry, your patch has rotted.  We now have distributed splitting in the mix.  Do you want to add a handler for this case.&lt;/p&gt;

&lt;p&gt;Reviewing current patch, we&apos;ll abort the master if fs is in safe mode splitting files but if we are recovering lease, we&apos;ll wait around.  I&apos;d think there&apos;d be one behavior only, either abort or wait (i&apos;d prefer the wait).  Waiting two minutes also seems a little short.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13028535" author="jdcryans" created="Wed, 4 May 2011 00:50:06 +0000"  >&lt;p&gt;@Jieshan, we are about the begin the process of building the first release candidate for 0.90.3, would it be possible for you to take a look at Stack&apos;s comments and post a new patch? If you can&apos;t do this soon, we&apos;ll move the issue to 0.90.4 (which is also fine). Thanks!&lt;/p&gt;</comment>
                            <comment id="13028548" author="jeason" created="Wed, 4 May 2011 01:32:54 +0000"  >&lt;p&gt;Sorry for some days delay of this issue.&lt;br/&gt;
I will post a new patch today, and I hope I can finish it well.&lt;br/&gt;
thanks.&lt;/p&gt;</comment>
                            <comment id="13028744" author="jeason" created="Wed, 4 May 2011 13:13:29 +0000"  >&lt;p&gt;I added two new method:&lt;br/&gt;
1.checkFileSystemWritable() &lt;br/&gt;
  Checks to see if the specified file system is writable&lt;br/&gt;
2.checkDfsSafeMode()&lt;br/&gt;
  Use it to check whether the dfs is on safemode.&lt;br/&gt;
When execute the splitLog(), check the available of dfs. If it&apos;s on safemode,just wait.If we say dfs is available , I think it could be read and writable,so I modified the method of checkFileSystem(). &lt;/p&gt;</comment>
                            <comment id="13028918" author="stack" created="Wed, 4 May 2011 19:47:11 +0000"  >&lt;p&gt;Here is some feedback on the patch Jieshan:&lt;/p&gt;

&lt;p&gt;You change the test in MasterFileSystem to test if filesystem is Writable, as opposed to available but the message you throw is &quot;File system is not available&quot;.  Actually, you create an IOE but you do not throw it.  You just pass it to abort.&lt;/p&gt;

&lt;p&gt;Why remove the try/catch from MasterFileSystem#checkFileSystem?  You can only do that because you discard any IOEs the come up when you do this check &apos;if (dfs.exists(new Path(&quot;/&quot;)) &amp;amp;&amp;amp; !checkDfsSafeMode(conf)) {&apos;.  That does not seem wise (You are hiding information on why the FS is not available/writable).&lt;/p&gt;

&lt;p&gt;The method you add to FSUtils is called checkFileSystemWritable yet it does not write the FS; it tests existence of &apos;/&apos; and checks for safe mode.&lt;/p&gt;

&lt;p&gt;Do we want to abort the master if in safe mode?  Would it not be better for the master to just wait on expiration of fs safe mode (You do it in HLogSplitter but you only wait ten seconds which seems short).&lt;/p&gt;</comment>
                            <comment id="13028919" author="stack" created="Wed, 4 May 2011 19:47:39 +0000"  >&lt;p&gt;Moving out of 0.90.3.  Still a bit of work to do on this one.&lt;/p&gt;</comment>
                            <comment id="13029066" author="jeason" created="Thu, 5 May 2011 00:14:34 +0000"  >&lt;p&gt;&quot;dfs.exist(new Path(&quot;/&quot;))&quot; checks the dfs is available, at least, the dfs can be read.&lt;br/&gt;
&quot;!checkDfsSafeMode(conf)&quot; checks the dfs is not in safemode. because only in safemode, it can&apos;t be written.&lt;br/&gt;
So I think we can make it as an indirect way to check whether the dfs is writable.&lt;br/&gt;
Is that correct?&lt;br/&gt;
If not,what about do a test of writing a temp file to check whether the dfs is writable? &lt;/p&gt;


</comment>
                            <comment id="13029071" author="jeason" created="Thu, 5 May 2011 00:31:32 +0000"  >&lt;p&gt;About the HLogSplitter, it doesn&apos;t only wait ten seconds. ten seconds is just an waiting-interval. If the dfs is in safemode, it will wait 10 seconds, and after that checkagain.......&lt;br/&gt;
I think, if the dfs can&apos;t be writable, whether dfs is in safemode or any other reasons cause the dfs can&apos;t be written while splitLog(), it&apos;s fetal. so let the master abort.&lt;/p&gt;</comment>
                            <comment id="13029735" author="jeason" created="Fri, 6 May 2011 04:27:27 +0000"  >&lt;p&gt;stack, can you review my comments, and give out your suggestion? so I can modify the patch according to that. Thanks!&lt;/p&gt;</comment>
                            <comment id="13029748" author="stack" created="Fri, 6 May 2011 04:50:09 +0000"  >&lt;p&gt;Sure.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;dfs.exist(new Path(&quot;/&quot;))&quot; checks the dfs is available, at least, the dfs can be read.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That is true, but this is being done in a method named &apos;isFSWritable&apos; (of some such thing)... we&apos;re testing exists but the method says we are testing its writable which we are not doing.  Its misleading.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;!checkDfsSafeMode(conf)&quot; checks the dfs is not in safemode. because only in safemode, it can&apos;t be written&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is true.  But this is not the only reason fs becomes unwriteable.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If not,what about do a test of writing a temp file to check whether the dfs is writable?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think this a good idea.  This call is made often.  Doing this check will put a big load on the fs, at least I think it will.&lt;/p&gt;

&lt;p&gt;Why not just use the method that was there previous and add the is safe mode.  Should we even check safe mode though?  This is a trip to the NN (IIUC).  Maybe we should just deal with the safe mode exception going into a holding pattern if we get one checking the fs (Will we get a safe mode exception if we do an exists check?  i don&apos;t know).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;About the HLogSplitter, it doesn&apos;t only wait ten seconds. ten seconds is just an waiting-interval. If the dfs is in safemode, it will wait 10 seconds, and after that checkagain.......&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok.  Pardon me.  My misunderstanding.  Thanks for clarifying.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think, if the dfs can&apos;t be writable, whether dfs is in safemode or any other reasons cause the dfs can&apos;t be written while splitLog(), it&apos;s fetal. so let the master abort.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If its not writeable, it would be nice if we could go into a holding pattern especially if its actually in safe mode &amp;#8211; would be nice to ride out a safe mode if that was possible.  But I think that that is a pretty big problem to solve; will take some work.&lt;/p&gt;

&lt;p&gt;Maybe you should narrow the scope of this issue to deal with safe mode while splitting?  Or making the Master hold until fs exits safe mode?&lt;/p&gt;

&lt;p&gt;Thanks Jieshan for looking into this issue.&lt;/p&gt;</comment>
                            <comment id="13031044" author="jeason" created="Tue, 10 May 2011 06:11:39 +0000"  >&lt;p&gt;To narrow the scope of this issue, I modified the patch:&lt;br/&gt;
1.Remain the new adding method to check the dfs safemode.&lt;br/&gt;
2.Before the splitting, make sure the dfs is not in safemode. If it&apos;s in safemode, just wait till it out of that.&lt;br/&gt;
3.Maybe,the dfs would translate into safemode while splitting, an IOException will throwed out. HMaster will catch that. Then checks dfs again.&lt;/p&gt;</comment>
                            <comment id="13036039" author="jeason" created="Thu, 19 May 2011 07:33:01 +0000"  >&lt;p&gt;Stack, if you have some time available, can you review the patch again? so I could know whether something still exist which I need to do about the patch...Thanks a lot &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13036472" author="stack" created="Thu, 19 May 2011 21:15:35 +0000"  >&lt;p&gt;Applied to trunk and branch.  Thanks for the patch Jieshan.&lt;/p&gt;</comment>
                            <comment id="13037175" author="hudson" created="Sat, 21 May 2011 00:04:26 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #1930 (See &lt;a href=&quot;https://builds.apache.org/hudson/job/HBase-TRUNK/1930/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/hudson/job/HBase-TRUNK/1930/&lt;/a&gt;)&lt;/p&gt;
</comment>
                            <comment id="15017375" author="lars_francke" created="Fri, 20 Nov 2015 12:42:53 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12478671" name="HBASE-3820-90-V3.patch" size="2179" author="jeason" created="Tue, 10 May 2011 06:11:39 +0000"/>
                            <attachment id="12478158" name="HBASE-3820-MFSFix-90-V2.patch" size="3860" author="jeason" created="Wed, 4 May 2011 13:06:22 +0000"/>
                            <attachment id="12477627" name="HBASE-3820-MFSFix-90.patch" size="2775" author="jeason" created="Thu, 28 Apr 2011 08:25:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 26 Apr 2011 03:23:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>27041</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ho1r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101158</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>