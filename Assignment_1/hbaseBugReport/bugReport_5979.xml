<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:32:42 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5979/HBASE-5979.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5979] Non-pread DFSInputStreams should be associated with scanners, not HFile.Readers</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5979</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently, every HFile.Reader has a single DFSInputStream, which it uses to service all gets and scans. For gets, we use the positional read API (aka &quot;pread&quot;) and for scans we use a synchronized block to seek, then read. The advantage of pread is that it doesn&apos;t hold any locks, so multiple gets can proceed at the same time. The advantage of seek+read for scans is that the datanode starts to send the entire rest of the HDFS block, rather than just the single hfile block necessary. So, in a single thread, pread is faster for gets, and seek+read is faster for scans since you get a strong pipelining effect.&lt;/p&gt;

&lt;p&gt;However, in a multi-threaded case where there are multiple scans (including scans which are actually part of compactions), the seek+read strategy falls apart, since only one scanner may be reading at a time. Additionally, a large amount of wasted IO is generated on the datanode side, and we get none of the earlier-mentioned advantages.&lt;/p&gt;

&lt;p&gt;In one test, I switched scans to always use pread, and saw a 5x improvement in throughput of the YCSB scan-only workload, since it previously was completely blocked by contention on the DFSIS lock.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12554581">HBASE-5979</key>
            <summary>Non-pread DFSInputStreams should be associated with scanners, not HFile.Readers</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                    </labels>
                <created>Wed, 9 May 2012 22:32:30 +0000</created>
                <updated>Mon, 25 Jan 2016 19:52:25 +0000</updated>
                                                                            <component>Performance</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>24</watches>
                                                                <comments>
                            <comment id="13271890" author="tlipcon" created="Wed, 9 May 2012 22:37:12 +0000"  >&lt;p&gt;My thinking is that the solution is something like this:&lt;/p&gt;

&lt;p&gt;When any scanner starts, it begins by using the &quot;pread&quot; API for the first N hfile blocks it reads. This allows short scans, which can often fall entirely within one or two HFile blocks, to avoid the read amplification of doing a DFSInputStream seek.&lt;/p&gt;

&lt;p&gt;After a scanner has read several blocks from an HFile, it switches over to the seek+read mode. However, it does this with its &lt;b&gt;own&lt;/b&gt; input stream. This way, all of the pre-buffering that happens through the HDFS layer will benefit it, and it doesn&apos;t have to contend with other scans. This should improve performance of long scans in the presence of contention (eg scans + compactions or multiple longer scans within the same region). The actual input streams would thus become owned by the individual HFileScanners.&lt;/p&gt;

&lt;p&gt;Not sure if I&apos;ll have time to prototype a patch for this any time soon, but happy to help review ideas.&lt;/p&gt;</comment>
                            <comment id="13275996" author="kannanm" created="Tue, 15 May 2012 17:14:35 +0000"  >&lt;p&gt;Todd: Nice catch! Your suggestion makes sense.&lt;/p&gt;</comment>
                            <comment id="13276018" author="tlipcon" created="Tue, 15 May 2012 17:28:40 +0000"  >&lt;p&gt;Kannan: I tried to work on this a bit in my spare time, but didn&apos;t get very far. So if FB folks have cycles to work on it, that would be awesome!&lt;/p&gt;

&lt;p&gt;I think one route is to do like I suggested above and have the StoreFileScanners hold a DFSInputStream. Another option would be to make a wrapper FileSystem (or FSReader) which pools a few streams. Then change the scanners to always issue positional reads, and have the wrapper code look for any stream which is already seeked to the right position (or just before the right position). The advantage of this technique is that we&apos;d end up getting the same sequential read benefit, even if the user was issuing normal get() calls in ascending row order.&lt;/p&gt;</comment>
                            <comment id="13280634" author="kannanm" created="Mon, 21 May 2012 23:58:20 +0000"  >&lt;p&gt;Todd: If we always use positional reads, we don&apos;t the benefit of HDFS sending the rest of the HDFS block, correct? So I didn&apos;t quite catch your recent suggestion. Did you mean, issue positional reads, but explicitly read a much larger chunk (in the Scan case) than just   the current block?&lt;/p&gt;</comment>
                            <comment id="13280640" author="tlipcon" created="Tue, 22 May 2012 00:16:09 +0000"  >&lt;p&gt;Hey Kannan,&lt;/p&gt;

&lt;p&gt;Sorry, let me elaborate on that suggestion:&lt;/p&gt;

&lt;p&gt;The idea is to make a new FSReader implementation, which only has one API. That API would look like the current positional read call (i.e take a position and length).&lt;/p&gt;

&lt;p&gt;Internally, it would have a pool of cached DFSInputStreams, and remember the position for each of them. Each of the input streams would be referencing the same file. When a read request comes in, it is matched against the pooled streams: if it is within N bytes forward from the current position of one of the streams, then a seek and read would be issued, synchronized on that stream. Otherwise, any random stream would be chosen and a position read would be chosen. Separately, we can track the last N positional reads: if we detect a sequential pattern in the position reads, we can take one of the pooled input streams and seek to the next predicted offset, so that future reads get the sequential benefit.&lt;/p&gt;</comment>
                            <comment id="13531690" author="lhofhansl" created="Fri, 14 Dec 2012 00:25:34 +0000"  >&lt;p&gt;Can we use a scan&apos;s cacheBlocks flag as an indicator for whether it would benefit from its own input stream? Presumably only large scans would have caching disabled.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; has a simple adhoc fix for the truly terrible read performance when two long running scanners scan the same store file.&lt;/p&gt;</comment>
                            <comment id="13532743" author="lhofhansl" created="Fri, 14 Dec 2012 22:40:32 +0000"  >&lt;p&gt;I think the most important aspect is to allow the OS to do its disc scheduling. Right now only one thread can do seek+read on the same file, and hence other threads need to wait (before &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7336&quot; title=&quot;HFileBlock.readAtOffset does not work well with multiple threads&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7336&quot;&gt;&lt;del&gt;HBASE-7336&lt;/del&gt;&lt;/a&gt; at least), which in turn leads to somewhat of a worst case behavior... The head is moved to one location, when that request is done the next threads comes in moved it a different location, then another thread comes in, etc, etc. In the end each threads eats the latency of the seek time.&lt;br/&gt;
If these request work in parallel the OS can do its job (elevator or whatever is configured) to optimize head movements.&lt;/p&gt;</comment>
                            <comment id="13532781" author="stack" created="Fri, 14 Dec 2012 23:23:25 +0000"  >&lt;p&gt;The nice thing about the original Todd suggestion is that we can be preading while we are opening the scanner&apos;s own file.  Once a successful open, we can then switch to read from the scanner&apos;s own reader.&lt;/p&gt;

&lt;p&gt;Scanner will more often than not have to open multiple files &amp;#8211; as many as there are under the store/column family.&lt;/p&gt;

&lt;p&gt;Things get interesting around flush and compaction.  Scanner could listen for changes and adjust accordingly.  Might have to slow to pread speeds for a while it did new opens.&lt;/p&gt;
</comment>
                            <comment id="14050511" author="vrodionov" created="Wed, 2 Jul 2014 18:19:36 +0000"  >&lt;blockquote&gt;
&lt;p&gt; The advantage of pread is that it doesn&apos;t hold any locks, so multiple gets can proceed at the same time. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Interesting .. This is th code snippet from FSInputStream (Hadoop 2.2)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; read(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] buffer, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; offset, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; length)
    &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; oldPos = getPos();
      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; nread = -1;
      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        seek(position);
        nread = read(buffer, offset, length);
      } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
        seek(oldPos);
      }
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; nread;
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Positional read is implemented with a lock&lt;/b&gt;. DFSInputStream extends the above class and does not override the default implementation. You have no parallelism even for simple gets.&lt;/p&gt;

</comment>
                            <comment id="14050591" author="tlipcon" created="Wed, 2 Jul 2014 19:21:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;DFSInputStream extends the above class and does not override the default implementation. You have no parallelism even for simple gets.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s not true &amp;#8211; DFSInputStream definitely overrides the positional read method and provides parallelism.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; read(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] buffer, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; offset, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; length)
    &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-comment&quot;&gt;// sanity checks
&lt;/span&gt;    dfsClient.checkOpen();
    ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(and it has since at least 5 years ago when I started working on Hadoop, as far as I can remember)&lt;/p&gt;</comment>
                            <comment id="14050690" author="vrodionov" created="Wed, 2 Jul 2014 20:44:20 +0000"  >&lt;p&gt;My bad. You are right. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12623791">HBASE-7347</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12783345">HBASE-13291</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 15 May 2012 17:14:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>238831</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 24 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02fin:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12115</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>