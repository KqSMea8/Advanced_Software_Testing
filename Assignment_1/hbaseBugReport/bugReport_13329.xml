<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:42:10 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-13329/HBASE-13329.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-13329] ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray</title>
                <link>https://issues.apache.org/jira/browse/HBASE-13329</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;While trying to benchmark my opentsdb cluster, I&apos;ve created a script that sends to hbase always the same value (in this case 1). After a few minutes, the whole region server crashes and the region itself becomes impossible to open again (cannot assign or unassign). After some investigation, what I saw on the logs is that when a Memstore flush is called on a large region (128mb) the process errors, killing the regionserver. On restart, replaying the edits generates the same error, making the region unavailable. Tried to manually unassign, assign or close_region. That didn&apos;t work because the code that reads/replays it crashes.&lt;br/&gt;
From my investigation this seems to be an overflow issue. The logs show that the function getMinimumMidpointArray tried to access index -32743 of an array, extremely close to the minimum short value in Java. Upon investigation of the source code, it seems an index short is used, being incremented as long as the two vectors are the same, probably making it overflow on large vectors with equal data. Changing it to int should solve the problem.&lt;br/&gt;
Here follows the hadoop logs of when the regionserver went down. Any help is appreciated. Any other information you need please do tell me:&lt;br/&gt;
2015-03-24 18:00:56,187 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;regionserver//10.2.0.73:16020.logRoller&amp;#93;&lt;/span&gt; wal.FSHLog: Rolled WAL /hbase/WALs/10.2.0.73,16020,1427216382590/10.2.0.73%2C16020%2C1427216382590.default.1427220018516 with entries=143, filesize=134.70 MB; new WAL /hbase/WALs/10.2.0.73,16020,1427216382590/10.2.0.73%2C16020%2C1427216382590.default.1427220056140&lt;br/&gt;
2015-03-24 18:00:56,188 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;regionserver//10.2.0.73:16020.logRoller&amp;#93;&lt;/span&gt; wal.FSHLog: Archiving hdfs://10.2.0.74:8020/hbase/WALs/10.2.0.73,16020,1427216382590/10.2.0.73%2C16020%2C1427216382590.default.1427219987709 to hdfs://10.2.0.74:8020/hbase/oldWALs/10.2.0.73%2C16020%2C1427216382590.default.1427219987709&lt;br/&gt;
2015-03-24 18:04:35,722 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.0&amp;#93;&lt;/span&gt; regionserver.HRegion: Started memstore flush for tsdb,,1427133969325.52bc1994da0fea97563a4a656a58bec2., current region memstore size 128.04 MB&lt;br/&gt;
2015-03-24 18:04:36,154 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.0&amp;#93;&lt;/span&gt; regionserver.HRegionServer: ABORTING region server 10.2.0.73,16020,1427216382590: Replay of WAL required. Forcing server shutdown&lt;br/&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: tsdb,,1427133969325.52bc1994da0fea97563a4a656a58bec2.&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1999)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1770)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1702)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:445)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:407)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:69)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:225)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.lang.ArrayIndexOutOfBoundsException: -32743&lt;br/&gt;
	at org.apache.hadoop.hbase.CellComparator.getMinimumMidpointArray(CellComparator.java:478)&lt;br/&gt;
	at org.apache.hadoop.hbase.CellComparator.getMidpoint(CellComparator.java:448)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.finishBlock(HFileWriterV2.java:165)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.checkBlockBoundary(HFileWriterV2.java:146)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.append(HFileWriterV2.java:263)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV3.append(HFileWriterV3.java:87)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:932)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:121)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:71)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:879)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2128)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1953)&lt;br/&gt;
	... 7 more&lt;br/&gt;
2015-03-24 18:04:36,156 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.0&amp;#93;&lt;/span&gt; regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: &lt;span class=&quot;error&quot;&gt;&amp;#91;org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint&amp;#93;&lt;/span&gt;&lt;/p&gt;</description>
                <environment>&lt;p&gt;linux-debian-jessie&lt;br/&gt;
ec2 - t2.micro instances&lt;/p&gt;</environment>
        <key id="12785274">HBASE-13329</key>
            <summary>ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="r.aguiar">Ruben Aguiar</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Mar 2015 19:15:15 +0000</created>
                <updated>Mon, 31 Aug 2015 22:39:48 +0000</updated>
                            <resolved>Sun, 5 Jul 2015 19:32:50 +0000</resolved>
                                    <version>1.0.1</version>
                                    <fixVersion>2.0.0</fixVersion>
                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                    <fixVersion>1.1.2</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                <comments>
                            <comment id="14379875" author="stack" created="Wed, 25 Mar 2015 13:44:58 +0000"  >&lt;p&gt;Thanks for hunting this one down. Which int are you referring to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt; Thanks.&lt;/p&gt;</comment>
                            <comment id="14379909" author="r.aguiar" created="Wed, 25 Mar 2015 14:18:37 +0000"  >&lt;p&gt;On CellComparator, this piece of code:&lt;/p&gt;

&lt;p&gt;short diffIdx = 0;&lt;br/&gt;
     while (diffIdx &amp;lt; minLength &amp;amp;&amp;amp;&lt;br/&gt;
         leftArray&lt;span class=&quot;error&quot;&gt;&amp;#91;leftOffset + diffIdx&amp;#93;&lt;/span&gt; == rightArray&lt;span class=&quot;error&quot;&gt;&amp;#91;rightOffset + diffIdx&amp;#93;&lt;/span&gt;) &lt;/p&gt;
{
       diffIdx++;
     }

&lt;p&gt;It&apos;s possible for diffIdx to overflow. Additionally, you treat index of this array as int before (both rightOffset and leftOffset). This seems to me that, on some special conditions (both vectors present equal values), diffIdx can overflow.&lt;/p&gt;</comment>
                            <comment id="14380214" author="stack" created="Wed, 25 Mar 2015 16:52:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt; Do you have a patch?&lt;/p&gt;</comment>
                            <comment id="14380232" author="r.aguiar" created="Wed, 25 Mar 2015 17:01:24 +0000"  >&lt;p&gt;Simply making diffIdx should solve the issue, or at least not present it on such small vectors. However, I haven&apos;t tested it. In my case, being that I simply wanted to benchmark openTSDB with my current cluster, I simply deleted all test data and changed my test script to send random values (instead of repeting the value).&lt;br/&gt;
Another option is to check on the condition for the maximum short value. That seems a bad way to do it though.&lt;br/&gt;
If you need anything else let me know.&lt;/p&gt;</comment>
                            <comment id="14380259" author="r.aguiar" created="Wed, 25 Mar 2015 17:13:34 +0000"  >&lt;p&gt;*making diffIdx an int should&lt;/p&gt;</comment>
                            <comment id="14380260" author="r.aguiar" created="Wed, 25 Mar 2015 17:13:35 +0000"  >&lt;p&gt;*making diffIdx an int should&lt;/p&gt;</comment>
                            <comment id="14380350" author="r.aguiar" created="Wed, 25 Mar 2015 17:51:47 +0000"  >&lt;p&gt;It seems this is not an error due to the data, but probably related to the metrics/tags in openTSDB. After changing the script to run by sending random data between 1 and 10, and even upping the region server itself (ran into some out of heap space errors) the error still persists. Probably because I&apos;m still writing to the same metric. Note however, that this time I&apos;ve noticed some further behaviours. First of all, on the process of flushing the region, it continued to say running without ever timing out or finishing. During this behaviour, a file in /hbase/data/default/tsdb/317da7fabf9ea9b15de80377bb792cd8/.tmp kept increasing in size until I killed the region server. On a stop-hbase command however, the logs repeatedly showed this error:&lt;/p&gt;

&lt;p&gt;2015-03-25 17:22:55,731 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;regionserver//10.2.0.73:16020&amp;#93;&lt;/span&gt; regionserver.HRegionServer: Received CLOSE for the region: 317da7fabf9ea9b&lt;br/&gt;
15de80377bb792cd8, which we are already trying to CLOSE, but not completed yet&lt;br/&gt;
2015-03-25 17:22:55,731 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;regionserver//10.2.0.73:16020&amp;#93;&lt;/span&gt; regionserver.HRegionServer: Failed to close tsdb,,1427300108453.317da7fabf&lt;br/&gt;
9ea9b15de80377bb792cd8. - ignoring and continuing&lt;br/&gt;
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 317da7fabf9ea9b15de80377bb792cd8 was already closing&lt;br/&gt;
. New CLOSE request is ignored.&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2635)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2561)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2219)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:869)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;I then issued a kill command on the region server and restarted the cluster. It behaved normally, and even deleted the huge tmp file previously generated. Until after a while (2-3 minutes) this error appeared on the region server logs:&lt;/p&gt;

&lt;p&gt;2015-03-25 17:31:04,752 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;regionserver//10.2.0.73:16020-shortCompactions-1427304663929&amp;#93;&lt;/span&gt; regionserver.CompactSplitThread: Compaction failed Request = regionName=tsdb,,1427300108453.317da7fabf9ea9b15de80377bb792cd8., storeName=t, fileCount=6, fileSize=228.1 M (107.9 M, 11.9 M, 30.8 M, 25.0 M, 44.2 M, 8.5 M), priority=4, time=9704521299920&lt;br/&gt;
java.lang.ArrayIndexOutOfBoundsException: -12190&lt;br/&gt;
        at org.apache.hadoop.hbase.CellComparator.getMinimumMidpointArray(CellComparator.java:478)&lt;br/&gt;
        at org.apache.hadoop.hbase.CellComparator.getMidpoint(CellComparator.java:448)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.finishBlock(HFileWriterV2.java:165)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.checkBlockBoundary(HFileWriterV2.java:146)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.append(HFileWriterV2.java:263)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV3.append(HFileWriterV3.java:87)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:932)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:254)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:102)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:110)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1167)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1610)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:511)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;This made the region server crash after a while (no writings were occuring at the time):&lt;/p&gt;

&lt;p&gt;2015-03-25 17:35:42,379 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RS_CLOSE_REGION-10.2.0.73:16020-2&amp;#93;&lt;/span&gt; regionserver.DefaultMemStore: Snapshot called again without clearing previous. Doing nothing. Another ongoing flush or did we fail last attempt?&lt;br/&gt;
2015-03-25 17:35:42,379 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;B.defaultRpcServer.handler=9,queue=0,port=16020&amp;#93;&lt;/span&gt; ipc.RpcServer: (responseTooSlow): &lt;/p&gt;
{&quot;processingtimems&quot;:23059,&quot;call&quot;:&quot;Scan(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ScanRequest)&quot;,&quot;client&quot;:&quot;10.2.0.74:38861&quot;,&quot;starttimems&quot;:1427304919320,&quot;queuetimems&quot;:0,&quot;class&quot;:&quot;HRegionServer&quot;,&quot;responsesize&quot;:95,&quot;method&quot;:&quot;Scan&quot;}
&lt;p&gt;2015-03-25 17:35:42,701 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;RS_CLOSE_REGION-10.2.0.73:16020-2&amp;#93;&lt;/span&gt; regionserver.HRegionServer: ABORTING region server 10.2.0.73,16020,1427304618843: Unrecoverable exception while closing region tsdb,,1427300108453.317da7fabf9ea9b15de80377bb792cd8., still finishing close&lt;br/&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: tsdb,,1427300108453.317da7fabf9ea9b15de80377bb792cd8.&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1999)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1770)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1266)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1198)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:138)&lt;br/&gt;
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.lang.ArrayIndexOutOfBoundsException&lt;/p&gt;

&lt;p&gt;I&apos;m still very new to the whole hbase environment but it seems to me the problem is the same as I reported previously, but in this case happened on a Compaction. The first time it showed unresponsive, the same probably happened while flushing, and it kept retrying (probably generating and increasing that tmp). After the kill, the error happened on a compaction. If I can help in any way to debug this problem please let me know. Any help is very appreciated.&lt;/p&gt;</comment>
                            <comment id="14380391" author="r.aguiar" created="Wed, 25 Mar 2015 18:14:23 +0000"  >&lt;p&gt;Another follow up. After a complete restart of the cluster, the region itself failed while opening, the same java.lang.ArrayIndexOutOfBoundsException error occurs. HMaster reports on the its interface that the region has failed to open:&lt;br/&gt;
tsdb,,1427300108453.317da7fabf9ea9b15de80377bb792cd8. state=FAILED_OPEN, ts=Wed Mar 25 18:03:44 UTC 2015 (369s ago), server=10.2.0.73,16020,1427306588788&lt;/p&gt;

&lt;p&gt;Additionally, if this region fails, and a restart is issued, 3 new files are generated in /hbase/data/default/tsdb/317da7fabf9ea9b15de80377bb792cd8/.tmp . Probably due to the opening failing and not cleaning these temporary files. &lt;/p&gt;</comment>
                            <comment id="14381804" author="r.aguiar" created="Thu, 26 Mar 2015 12:38:05 +0000"  >&lt;p&gt;After further testing and tweaking, I&apos;m starting to doubt this is related to the data being written itself. At the moment, I have 4 different servers sending random data, each one of these sending to a random metric between its range of 10 possible ones. This means writes are never repeated constantly, either the data or the metrics itself. Even regarding tags, I&apos;m constantly changing between two of them. However, after deleting the whole database and starting the whole cluster from a clean sheet, after a few minutes a similar problem arises. This time, it fails a bit further on the code with a negative array size exception:&lt;br/&gt;
2015-03-26 11:59:42,597 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.1&amp;#93;&lt;/span&gt; regionserver.HStore: Added hdfs://10.2.0.74:8020/hbase/data/default/tsdb/59f6a2c16cd9c&lt;br/&gt;
51677efa96ddf038fe8/t/d999a9dee66c4948862440ba1459a826, entries=806262, sequenceid=16116, filesize=6.8 M&lt;br/&gt;
2015-03-26 11:59:42,599 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.1&amp;#93;&lt;/span&gt; regionserver.HRegion: Finished memstore flush of ~129.72 MB/136019416, currentsize=1.7&lt;br/&gt;
5 MB/1837224 for region tsdb,,1427368142097.59f6a2c16cd9c51677efa96ddf038fe8. in 717ms, sequenceid=16116, compaction requested=false&lt;br/&gt;
2015-03-26 12:02:15,957 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.0&amp;#93;&lt;/span&gt; regionserver.HRegion: Started memstore flush for tsdb,,1427368142097.59f6a2c16cd9c5167&lt;br/&gt;
7efa96ddf038fe8., current region memstore size 128.06 MB&lt;br/&gt;
2015-03-26 12:02:16,077 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;MemStoreFlusher.0&amp;#93;&lt;/span&gt; regionserver.HRegionServer: ABORTING region server 10.2.0.73,16020,1427368055017: Repl&lt;br/&gt;
ay of WAL required. Forcing server shutdown&lt;br/&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: tsdb,,1427368142097.59f6a2c16cd9c51677efa96ddf038fe8.&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1999)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1770)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1702)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:445)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:407)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:69)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:225)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.lang.NegativeArraySizeException&lt;br/&gt;
        at org.apache.hadoop.hbase.CellComparator.getMinimumMidpointArray(CellComparator.java:490)&lt;br/&gt;
        at org.apache.hadoop.hbase.CellComparator.getMidpoint(CellComparator.java:448)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.finishBlock(HFileWriterV2.java:165)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.checkBlockBoundary(HFileWriterV2.java:146)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.append(HFileWriterV2.java:263)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFileWriterV3.append(HFileWriterV3.java:87)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:932)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:121)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:71)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:879)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2128)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1953)&lt;br/&gt;
        ... 7 more&lt;/p&gt;

&lt;p&gt;After some investigation, I ran a hdfs fsck and it reported healthy. However, with the flag -openforwrite (include files opened for writes) I get corrupted blocks that refer to the WALS on the other slave machines. This might be due to the region server crashing unexpectedly. The fsck output:&lt;br/&gt;
/hbase/WALs/10.2.0.171,16020,1427368055792/10.2.0.171%2C16020%2C1427368055792.default.1427368062105 83 bytes, 1 block(s), OPENFORWRITE: &lt;br/&gt;
/hbase/WALs/10.2.0.171,16020,1427368055792/10.2.0.171%2C16020%2C1427368055792.default.1427368062105: MISSING 1 blocks of total size 83 B../hbase/WALs/10.2.0.224,16020,1427368062011-splitting/10.2.0.224%2C16020%2C1427368062011.default.1427368068287 83 bytes, 1 block(s), OPENFORWRITE: &lt;br/&gt;
/hbase/WALs/10.2.0.224,16020,1427368062011-splitting/10.2.0.224%2C16020%2C1427368062011.default.1427368068287: MISSING 1 blocks of total size 83 B.....................................Status: CORRUPT&lt;br/&gt;
 Total size:	105297956 B&lt;br/&gt;
 Total dirs:	54&lt;br/&gt;
 Total files:	39&lt;br/&gt;
 Total symlinks:		0&lt;br/&gt;
 Total blocks (validated):	33 (avg. block size 3190847 B)&lt;br/&gt;
  ********************************&lt;br/&gt;
  CORRUPT FILES:	2&lt;br/&gt;
  MISSING BLOCKS:	2&lt;br/&gt;
  MISSING SIZE:		166 B&lt;br/&gt;
  ********************************&lt;br/&gt;
 Minimally replicated blocks:	31 (93.93939 %)&lt;br/&gt;
 Over-replicated blocks:	0 (0.0 %)&lt;br/&gt;
 Under-replicated blocks:	0 (0.0 %)&lt;br/&gt;
 Mis-replicated blocks:		0 (0.0 %)&lt;br/&gt;
 Default replication factor:	3&lt;br/&gt;
 Average block replication:	2.8181818&lt;br/&gt;
 Corrupt blocks:		0&lt;br/&gt;
 Missing replicas:		0 (0.0 %)&lt;br/&gt;
 Number of data-nodes:		3&lt;br/&gt;
 Number of racks:		1&lt;br/&gt;
FSCK ended at Thu Mar 26 12:22:51 UTC 2015 in 21 milliseconds&lt;/p&gt;


&lt;p&gt;The filesystem under path &apos;/&apos; is CORRUPT&lt;/p&gt;

&lt;p&gt;Again, any help or guidance is very much appreciated.&lt;/p&gt;

</comment>
                            <comment id="14382131" author="r.aguiar" created="Thu, 26 Mar 2015 16:15:55 +0000"  >&lt;p&gt;So, after having the error every time I restarted the cluster (because it tried to replay the edits), I&apos;ve manually build hbase with the change I proposed above (changing diffIdx from short to int). After restarting the region server, the region was sucessfully flushed. So the fix does solve the problem. I&apos;ll keep benchmarking my cluster and see if this error continues to happen.&lt;/p&gt;</comment>
                            <comment id="14382204" author="apurtell" created="Thu, 26 Mar 2015 16:51:31 +0000"  >&lt;p&gt;Added fix version for branch-1.0. Not an issue in 0.98&lt;/p&gt;</comment>
                            <comment id="14390097" author="enis" created="Wed, 1 Apr 2015 06:52:11 +0000"  >&lt;p&gt;I have tried to reproduce this with putting the same value to a table, but it successfully flushed. Looking at the code for CellComparator.getMinimumMidpointArray(), the diffIdx assumes that the arrays are not longer than short or there is a diff. &lt;/p&gt;

&lt;p&gt;If you see the error in CellComparator.getMinimumMidpointArray(), then it maybe that individual cells are very big (byte[] representation bigger than short?). Can this be possible? What is your max key size? &lt;/p&gt;

&lt;p&gt;In any case, it maybe needed to change the short to be an int to be on the safe side. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt; do you want to attach a patch for that? &lt;/p&gt;</comment>
                            <comment id="14390363" author="r.aguiar" created="Wed, 1 Apr 2015 10:45:37 +0000"  >&lt;p&gt;Individual cells are not that big I think. AFAIK, I use 1 metric and 2 tags on OpenTSDB so that would mean something like 3*3=9bytes. Anyway, the patch is simply to change diffIdx type from short to int. I&apos;ve done that and it solved my problem. At the moment I have some internet issues so it&apos;s very hard for me to submit a patch (took me 10 minutes to actually get this page), but being how simple it is I don&apos;t think it&apos;s necessary.&lt;/p&gt;</comment>
                            <comment id="14516357" author="ndimiduk" created="Tue, 28 Apr 2015 04:51:03 +0000"  >&lt;p&gt;Bumping from 1.1.0. Please update if there&apos;s a patch ASAP.&lt;/p&gt;</comment>
                            <comment id="14576315" author="yuzhihong@gmail.com" created="Sun, 7 Jun 2015 15:50:36 +0000"  >&lt;p&gt;@Ruben:&lt;br/&gt;
Please generate patch from the root of your workspace. Here is a sample command:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
git diff &amp;gt; 13329-v1.patch
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then attach to this JIRA.&lt;/p&gt;</comment>
                            <comment id="14577441" author="r.aguiar" created="Mon, 8 Jun 2015 16:34:10 +0000"  >&lt;p&gt;I can&apos;t do it at the moment. Travelling from Portugal to the UK.&lt;br/&gt;
I can only do it tomorrow when I get to work.&lt;/p&gt;</comment>
                            <comment id="14579196" author="r.aguiar" created="Tue, 9 Jun 2015 16:43:52 +0000"  >&lt;p&gt;Done&lt;/p&gt;</comment>
                            <comment id="14579205" author="yuzhihong@gmail.com" created="Tue, 9 Jun 2015 16:53:37 +0000"  >&lt;p&gt;lgtm&lt;/p&gt;</comment>
                            <comment id="14579434" author="hadoopqa" created="Tue, 9 Jun 2015 19:22:52 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12738609/13329-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12738609/13329-v1.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 6cc42c8cd16d01cded9936bf53bf35e6e2ff5b66.&lt;br/&gt;
  ATTACHMENT ID: 12738609&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14345//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14579511" author="ndimiduk" created="Tue, 9 Jun 2015 20:21:38 +0000"  >&lt;p&gt;I&apos;d like this fix for 1.1.1 but would feel better about it if there was a test along with it.&lt;/p&gt;</comment>
                            <comment id="14580328" author="r.aguiar" created="Wed, 10 Jun 2015 09:58:16 +0000"  >&lt;p&gt;I won&apos;t make any tests because I&apos;m not certain of the conditions that make this error appear. Also, this is an inconsistency on the code, I&apos;m simply treating all indexes with the same data type. As I said earlier:&lt;br/&gt;
&quot;It&apos;s possible for diffIdx to overflow. Additionally, you treat index of this array as int before (both rightOffset and leftOffset). This seems to me that, on some special conditions (both vectors present equal values), diffIdx can overflow.&quot;&lt;/p&gt;</comment>
                            <comment id="14585362" author="ndimiduk" created="Mon, 15 Jun 2015 01:26:47 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt;. I&apos;ve spent some time looking at this today, trying to reproduce the bug in unit tests. I&apos;ve been unsuccessful. Any chance you can apply this patch (without your s/short/int patch) and show me what it prints? Attaching an HFile that results in the error would also be helpful.&lt;/p&gt;

&lt;p&gt;I think I&apos;m okay with committing your s/short/int/ patch because we have other checks for asserting the rowkey length invariant (this is the invariant I keep running up against in variations of a unit test), though I&apos;d appreciate a second opinion on that from the likes of &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14585363" author="hadoopqa" created="Mon, 15 Jun 2015 01:39:25 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12739535/13329-asserts.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12739535/13329-asserts.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 714668a40dff6d7aa9207a0846d6f8ed800276ee.&lt;br/&gt;
  ATTACHMENT ID: 12739535&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14409//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14409//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14585430" author="lhofhansl" created="Mon, 15 Jun 2015 04:57:41 +0000"  >&lt;p&gt;Hmmm... We compare against &lt;tt&gt;minLength&lt;/tt&gt;, which is a short, so we cannot grow beyond the short range (and if the data is corrupted and minLenth itself overflew, than - since diffIdx starts at 0 - we&apos;d overflow immediately.&lt;br/&gt;
I also agree that this compares bytes in the row key itself (not keys).&lt;/p&gt;

&lt;p&gt;Here&apos;s the scenario that can go wrong... Later in the code we do this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (diffIdx &amp;gt;= minLength) {
         &lt;span class=&quot;code-comment&quot;&gt;// leftKey&apos;s row is prefix of rightKey&apos;s.
&lt;/span&gt;         newRowKey = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[diffIdx + 1];
         &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.arraycopy(rightKey, ROW_LENGTH_SIZE, newRowKey, 0, diffIdx + 1);
       } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So what if minLength was exactly Short.MAX_VALUE? In that case &lt;tt&gt;diffIdx&lt;/tt&gt; can overflow (and we&apos;d get the negative array size exception). But note that in that case it is &lt;em&gt;not&lt;/em&gt; OK to have it grow by one, as we&apos;d create a rowkey array &amp;gt; Short.MAX_VALUE. It seems in that case we&apos;d have to not do the getShortMidpointKey optimization...?&lt;/p&gt;

&lt;p&gt;It seems to me that can only happen when the keys are identical &lt;em&gt;and&lt;/em&gt; of size Short.MAX_VALUE. In case we can either take the left or the right key, right? There &lt;em&gt;is&lt;/em&gt; no mid key in that case.&lt;/p&gt;</comment>
                            <comment id="14585433" author="lhofhansl" created="Mon, 15 Jun 2015 05:02:50 +0000"  >&lt;p&gt;TL; DR: I do not think this patch is correct. It&apos;s lead to a KV with a rowkey with length &amp;gt; Short.MAX_VALUE, which - when encoded - will lead to a short overflow at that point.&lt;br/&gt;
Are these midpoint keys ever stored? If not it might accidentally be OK.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt;, any chance you test whether minLength or diffIdx happen to be equal to Short.MAX_VALUE, and then return either the left or the right key? (and not change diffIdx into an int)&lt;/p&gt;</comment>
                            <comment id="14585739" author="r.aguiar" created="Mon, 15 Jun 2015 10:14:48 +0000"  >&lt;p&gt;I&apos;m sorry but I cannot provide any test for this matter. This issue occurred 3 months ago and I&apos;ve moved to a different project long ago. The machines that had information regarding the cluster have been terminated. I have no way to reproduce the problem. All I can say is that the change I made did corrected the problem I was having. After I did the change, the region successfully flushed. Take that information whoever you want it, but that&apos;s all I can provide you with.&lt;/p&gt;</comment>
                            <comment id="14586456" author="apurtell" created="Mon, 15 Jun 2015 18:33:39 +0000"  >&lt;p&gt;In which case I will close this as Cannot Reproduce. We can reopen it later if there&apos;s some way to reproduce this and test a fix.&lt;/p&gt;</comment>
                            <comment id="14587408" author="lhofhansl" created="Tue, 16 Jun 2015 03:39:30 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt;, sorry it took so long fix.&lt;/p&gt;

&lt;p&gt;I think we do have an issue.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;, not sure you have still time and willingness to test this more, but I think this would happen if we:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;have row keys of the maximum length Short.MAX_VALUE, and&lt;/li&gt;
	&lt;li&gt;all rows keys in an HFile block are identical&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In that case there &lt;em&gt;is no&lt;/em&gt; prefix and the code with incorrectly create a row key of length Short.MAX_VALUE+1, which will lead to the overflow.&lt;br/&gt;
So a test would insert many row keys of this form - enough to fill an hfile block - and then attempt to flush.&lt;/p&gt;</comment>
                            <comment id="14587437" author="ndimiduk" created="Tue, 16 Jun 2015 04:25:39 +0000"  >&lt;p&gt;I was working on just such a test this morning... got side-tracked. Let me finish the experiment tomorrow.&lt;/p&gt;</comment>
                            <comment id="14588793" author="ndimiduk" created="Tue, 16 Jun 2015 21:19:44 +0000"  >&lt;p&gt;Here&apos;s the test I&apos;ve been working from, parking it for now. rowkey + column family:qualifier should be much larger than hfile.index.block.max.size. It gets me into &lt;tt&gt;CellComparator#getMinimumMidpointArray&lt;/tt&gt;, but the rows are never different.&lt;/p&gt;</comment>
                            <comment id="14588795" author="ndimiduk" created="Tue, 16 Jun 2015 21:21:00 +0000"  >&lt;p&gt;Reopening since we&apos;re still poking at this one.&lt;/p&gt;</comment>
                            <comment id="14613911" author="duong_dajgja" created="Sat, 4 Jul 2015 15:27:18 +0000"  >&lt;p&gt;I have experienced exactly the same problem. I reported this issue as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14018&quot; title=&quot;RegionServer is aborted when flushing memstore.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14018&quot;&gt;&lt;del&gt;HBASE-14018&lt;/del&gt;&lt;/a&gt; (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14018?jql=project%20%3D%20HBASE#&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-14018?jql=project%20%3D%20HBASE#&lt;/a&gt;) and on stackoverflow (&lt;a href=&quot;http://stackoverflow.com/questions/31164505/hbase-regionserver-is-aborted-and-can-never-be-brought-up-after-that&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/31164505/hbase-regionserver-is-aborted-and-can-never-be-brought-up-after-that&lt;/a&gt;). Please help fix this.&lt;/p&gt;</comment>
                            <comment id="14614102" author="lhofhansl" created="Sun, 5 Jul 2015 00:44:49 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=duong_dajgja&quot; class=&quot;user-hover&quot; rel=&quot;duong_dajgja&quot;&gt;Dinh Duong Mai&lt;/a&gt;, do you remember what exactly you did. From looking at the code I think we have an issue when exactly these two happen:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;We we have a row key of length Short.MAX_VALUE&lt;/li&gt;
	&lt;li&gt;All row keys in an HFile block are identical&lt;br/&gt;
(i.e. we repeatedly insert Cells with the same key and that key is exactly Short.MAX_VALUE in size).&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Did that happen here.&lt;/p&gt;</comment>
                            <comment id="14614103" author="lhofhansl" created="Sun, 5 Jul 2015 00:46:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=duong_dajgja&quot; class=&quot;user-hover&quot; rel=&quot;duong_dajgja&quot;&gt;Dinh Duong Mai&lt;/a&gt;, I linked the two issues together. Thank you reporting the issue.&lt;/p&gt;</comment>
                            <comment id="14614167" author="duong_dajgja" created="Sun, 5 Jul 2015 06:52:27 +0000"  >&lt;p&gt;I run a python script as below to send data to OpenTSDB:&lt;/p&gt;

&lt;p&gt;s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)&lt;br/&gt;
s.connect((&quot;192.168.56.101&quot;, 4242))&lt;/p&gt;

&lt;p&gt;start_epoch = 1300000000;&lt;/p&gt;

&lt;p&gt;for epoch_in_sec in range(start_epoch, start_epoch + 2001): # 2000 seconds&lt;br/&gt;
	for epoch_msec_offset in xrange(0, 1000, 100):		# time resolution of 100 milliseconds&lt;br/&gt;
		epoch_in_msec = epoch_in_sec + epoch_msec_offset;&lt;/p&gt;

&lt;p&gt;		for tag in xrange(1, 101, 10):		# 100 metrics, from TAG_1 to TAG_100&lt;br/&gt;
			tag1 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 1, epoch_in_msec)&lt;br/&gt;
			tag2 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 2, epoch_in_msec)&lt;br/&gt;
			tag3 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 3, epoch_in_msec)&lt;br/&gt;
			tag4 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 4, epoch_in_msec)&lt;br/&gt;
			tag5 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 5, epoch_in_msec)&lt;br/&gt;
			tag6 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 6, epoch_in_msec)&lt;br/&gt;
			tag7 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 7, epoch_in_msec)&lt;br/&gt;
			tag8 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 8, epoch_in_msec)&lt;br/&gt;
			tag9 = &quot;put TAG_%d %d 12.9 stt=good\n&quot; % (tag + 9, epoch_in_msec)&lt;br/&gt;
			tag10 = &quot;put TAG_10 %d 12.9 stt=good\n&quot; % (tag + 10, epoch_in_msec)&lt;/p&gt;

&lt;p&gt;			str = tag1 + tag2 + tag3 + tag4 + tag5 + tag6 + tag7 + tag8 + tag9 + tag10&lt;br/&gt;
			s.send(str)&lt;br/&gt;
	sleep (1) # every 1 second&lt;/p&gt;</comment>
                            <comment id="14614289" author="duong_dajgja" created="Sun, 5 Jul 2015 15:28:17 +0000"  >&lt;p&gt;sorry, this &quot;epoch_in_msec = epoch_in_sec + epoch_msec_offset&quot; should be &quot;epoch_in_msec = epoch_in_sec * 1000 + epoch_msec_offset&quot;&lt;/p&gt;</comment>
                            <comment id="14614318" author="lhofhansl" created="Sun, 5 Jul 2015 17:08:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=duong_dajgja&quot; class=&quot;user-hover&quot; rel=&quot;duong_dajgja&quot;&gt;Dinh Duong Mai&lt;/a&gt; Hmm... I don&apos;t know enough about the details of OpenTSDB. You have the ability to run with a modified HBase, if I gave you a patch?&lt;/p&gt;

&lt;p&gt;Maybe Mr. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tsuna&quot; class=&quot;user-hover&quot; rel=&quot;tsuna&quot;&gt;Benoit Sigoure&lt;/a&gt; is still listening in... Any ideas?&lt;/p&gt;</comment>
                            <comment id="14614320" author="lhofhansl" created="Sun, 5 Jul 2015 17:17:44 +0000"  >&lt;p&gt;-32743 is Short.MAX_VALUE+26. It&apos;s interesting that it&apos;s the same 26 both here and in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14018&quot; title=&quot;RegionServer is aborted when flushing memstore.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14018&quot;&gt;&lt;del&gt;HBASE-14018&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14614342" author="lhofhansl" created="Sun, 5 Jul 2015 18:04:38 +0000"  >&lt;p&gt;The caller is this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] midRow = getMinimumMidpointArray(left.getQualifierArray(), left.getQualifierOffset(),
          left.getQualifierLength(),
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So this has nothing to do with rowLength! I was mistaken there.&lt;br/&gt;
The qualifier length is indeed an int, hence this would happen with any qualifier longer than Short.MAX_VALUE, and so I now think that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=r.aguiar&quot; class=&quot;user-hover&quot; rel=&quot;r.aguiar&quot;&gt;Ruben Aguiar&lt;/a&gt;&apos;s patch was correct after all.&lt;/p&gt;</comment>
                            <comment id="14614343" author="lhofhansl" created="Sun, 5 Jul 2015 18:05:43 +0000"  >&lt;p&gt;In fact I am sure of that. I&apos;m going to commit this change unless I hear objections.&lt;/p&gt;</comment>
                            <comment id="14614347" author="stack" created="Sun, 5 Jul 2015 18:14:11 +0000"  >&lt;p&gt;Go for it &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Would be sweet though if &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=duong_dajgja&quot; class=&quot;user-hover&quot; rel=&quot;duong_dajgja&quot;&gt;Dinh Duong Mai&lt;/a&gt; could try it too.&lt;/p&gt;</comment>
                            <comment id="14614356" author="lhofhansl" created="Sun, 5 Jul 2015 18:37:21 +0000"  >&lt;p&gt;Patch with test. Test fails always without patch, but passes with patch.&lt;br/&gt;
Unless I hear objections I am going to commit this.&lt;/p&gt;</comment>
                            <comment id="14614371" author="lhofhansl" created="Sun, 5 Jul 2015 19:32:51 +0000"  >&lt;p&gt;Committed to 2.0, 1.3, 1.2, 1.1, and 1.0. (0.98 does not have this issue)&lt;/p&gt;</comment>
                            <comment id="14614401" author="hudson" created="Sun, 5 Jul 2015 21:06:41 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.2-IT #37 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.2-IT/37/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.2-IT/37/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev e3f0705f19638ff9e98e36b3eaf0c0b2463bcaf6)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614402" author="hudson" created="Sun, 5 Jul 2015 21:07:11 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.0 #985 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.0/985/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.0/985/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev 4b934b5734238675e27aaf426e4236e61c57d538)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614409" author="hudson" created="Sun, 5 Jul 2015 21:24:47 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3-IT #20 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3-IT/20/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3-IT/20/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev 29969dcf5c3f128a89318f55e952e154a2bac26e)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614413" author="hudson" created="Sun, 5 Jul 2015 21:45:21 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.1 #573 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.1/573/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.1/573/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev 53a22c9ce5f79d36f0943c83fb57fb6165c63d08)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614414" author="hudson" created="Sun, 5 Jul 2015 21:47:26 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.2 #51 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.2/51/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.2/51/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev e3f0705f19638ff9e98e36b3eaf0c0b2463bcaf6)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614422" author="hudson" created="Sun, 5 Jul 2015 22:15:42 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.3 #35 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3/35/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3/35/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev 29969dcf5c3f128a89318f55e952e154a2bac26e)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614428" author="hudson" created="Sun, 5 Jul 2015 22:32:09 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6628 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6628/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6628/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13329&quot; title=&quot;ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13329&quot;&gt;&lt;del&gt;HBASE-13329&lt;/del&gt;&lt;/a&gt; ArrayIndexOutOfBoundsException in CellComparator#getMinimumMidpointArray. (larsh: rev 1f9bf419c1c9040504de1b36fb85d0be7163eadf)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14614453" author="duong_dajgja" created="Sun, 5 Jul 2015 23:59:39 +0000"  >&lt;p&gt;I will run some tests today.&lt;/p&gt;</comment>
                            <comment id="14614459" author="lhofhansl" created="Mon, 6 Jul 2015 00:12:11 +0000"  >&lt;p&gt;I also realize that trunk the Subject is not correct. There the logic is in HFileWriterImpl. Oh well.&lt;/p&gt;</comment>
                            <comment id="14614604" author="duong_dajgja" created="Mon, 6 Jul 2015 06:31:45 +0000"  >&lt;p&gt;I did a test with 2 independent servers, one used the patch and the other did not use the patch. A client sent the same data to both servers for 2000 seconds. The server with the patch worked perfectly but the one without the patch got crashed with this issue. I think the patch is correct. Thank you guys very much!&lt;/p&gt;</comment>
                            <comment id="14626820" author="lhofhansl" created="Tue, 14 Jul 2015 18:29:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;, did you remove the 1.3.0 target on purpose?&lt;/p&gt;</comment>
                            <comment id="14626891" author="busbey" created="Tue, 14 Jul 2015 19:11:17 +0000"  >&lt;p&gt;yes. I had accounted for it in my staged 1.2.0 release notes. see the discussion on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14025&quot; title=&quot;Update CHANGES.txt for 1.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14025&quot;&gt;&lt;del&gt;HBASE-14025&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14627056" author="tsuna" created="Tue, 14 Jul 2015 21:21:01 +0000"  >&lt;p&gt;I&apos;m kinda late to the party but yeah OpenTSDB compactions might cause long column qualifiers.  OpenTSDB doesn&apos;t generally use long row keys though, so that makes total sense.  Thanks for getting to the bottom of this one!&lt;/p&gt;</comment>
                            <comment id="14627980" author="lhofhansl" created="Wed, 15 Jul 2015 12:38:55 +0000"  >&lt;p&gt;I see. Makes sense. Thanks.&lt;/p&gt;</comment>
                            <comment id="14628236" author="lhofhansl" created="Wed, 15 Jul 2015 15:28:52 +0000"  >&lt;p&gt;Still a bit confusing, though. If 1.2.1 was out already, this jira &lt;em&gt;would&lt;/em&gt; have needed to be tagged with 1.3.0 (since 1.2.x and 1.3.x are in diverging branches).&lt;/p&gt;

&lt;p&gt;We also have to make the 1.2.0 release part in CHANGES.txt is present in 1.3.0, followed by the new 1.3.x features.&lt;/p&gt;</comment>
                            <comment id="14706821" author="xorlev" created="Fri, 21 Aug 2015 14:50:03 +0000"  >&lt;p&gt;In 1.x.x at least, this same change needs to be applied in both KeyValue.java (13329-v1.patch does this change) as well as CellComparator#getMinimumMidpointArray.&lt;/p&gt;

&lt;p&gt;Ran into this issue with HBase 1.0.0 (CDH5.4.0). It&apos;s unclear what originally caused the issue (after weeks of stable operation), but it would cause RSes to abort. At this point, no RS was able to open the region until I applied the patch from this issue as well as making the same change in CellComparator.&lt;/p&gt;

&lt;p&gt;With original patch applied even:&lt;/p&gt;

&lt;p&gt;slave3.xxx.xxx.xxx,60020,1440131603772: Replay of WAL required. Forcing server shutdown&lt;br/&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: deduplication,P\xDFt\x10\x053e73ceff5a2717d2ba76887ea21a2a8e353d1372\xFE,1438362391124.2bb6a602be6b1bfcea0508af4ba42235.&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2243)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1972)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1935)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1833)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:452)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:413)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:70)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:229)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.lang.NegativeArraySizeException&lt;br/&gt;
	at org.apache.hadoop.hbase.CellComparator.getMinimumMidpointArray(CellComparator.java:494)&lt;br/&gt;
	at org.apache.hadoop.hbase.CellComparator.getMidpoint(CellComparator.java:448)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.finishBlock(HFileWriterV2.java:165)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.checkBlockBoundary(HFileWriterV2.java:146)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.append(HFileWriterV2.java:263)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:949)&lt;/p&gt;


&lt;p&gt;Was this an accidental omission? If so, should I open a new issue for this?&lt;/p&gt;</comment>
                            <comment id="14706836" author="busbey" created="Fri, 21 Aug 2015 15:02:36 +0000"  >&lt;p&gt;looks like it. Please open a new issue, since this one has been in a release already.&lt;/p&gt;</comment>
                            <comment id="14706901" author="xorlev" created="Fri, 21 Aug 2015 15:49:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14281&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-14281&lt;/a&gt; follow-on&lt;/p&gt;</comment>
                            <comment id="14724271" author="enis" created="Mon, 31 Aug 2015 22:39:48 +0000"  >&lt;p&gt;Closing this issue after 1.0.2 release.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12842524">HBASE-14018</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12857875">HBASE-14281</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12739535" name="13329-asserts.patch" size="1065" author="ndimiduk" created="Mon, 15 Jun 2015 01:26:47 +0000"/>
                            <attachment id="12738609" name="13329-v1.patch" size="742" author="r.aguiar" created="Tue, 9 Jun 2015 16:43:30 +0000"/>
                            <attachment id="12743634" name="13329.txt" size="2332" author="lhofhansl" created="Sun, 5 Jul 2015 18:37:21 +0000"/>
                            <attachment id="12739975" name="HBASE-13329.test.00.branch-1.1.patch" size="3111" author="ndimiduk" created="Tue, 16 Jun 2015 21:19:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 25 Mar 2015 13:44:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 15 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i27ao7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>