<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:28:57 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5568/HBASE-5568.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5568] Multi concurrent flushcache() for one region could cause data loss</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5568</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We could call HRegion#flushcache() concurrently now through HRegionServer#splitRegion or HRegionServer#flushRegion by HBaseAdmin.&lt;br/&gt;
However, we find if HRegion#internalFlushcache() is called concurrently by multi thread, HRegion.memstoreSize will be calculated wrong.&lt;br/&gt;
At the end of HRegion#internalFlushcache(), we will do this.addAndGetGlobalMemstoreSize(-flushsize), but the flushsize may not the actual memsize which flushed to hdfs. It cause HRegion.memstoreSize is negative and prevent next flush if we close this region.&lt;/p&gt;

&lt;p&gt;Logs in RS for region e9d827913a056e696c39bc569ea3&lt;/p&gt;

&lt;p&gt;2012-03-11 16:31:36,690 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for writetest1,,1331454657410.e9d827913a056e696c39bc569ea3&lt;br/&gt;
f99f., current region memstore size 128.0m&lt;br/&gt;
2012-03-11 16:31:37,999 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://dw74.kgb.sqa.cm4:9700/hbase-func1/writetest1/e9d827913a056e696c39bc569e&lt;br/&gt;
a3f99f/cf1/8162481165586107427, entries=153106, sequenceid=619316544, memsize=59.6m, filesize=31.2m&lt;br/&gt;
2012-03-11 16:31:38,830 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for writetest1,,1331454657410.e9d827913a056e696c39bc569ea3&lt;br/&gt;
f99f., current region memstore size 134.8m&lt;br/&gt;
2012-03-11 16:31:39,458 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://dw74.kgb.sqa.cm4:9700/hbase-func1/writetest1/e9d827913a056e696c39bc569e&lt;br/&gt;
a3f99f/cf2/3425971951499794221, entries=230183, sequenceid=619316544, memsize=68.5m, filesize=26.6m&lt;br/&gt;
2012-03-11 16:31:39,459 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~128.1m for region writetest1,,1331454657410.e9d827913a&lt;br/&gt;
056e696c39bc569ea3f99f. in 2769ms, sequenceid=619316544, compaction requested=false&lt;br/&gt;
2012-03-11 16:31:39,459 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for writetest1,,1331454657410.e9d827913a056e696c39bc569ea3&lt;br/&gt;
f99f., current region memstore size 6.8m&lt;br/&gt;
2012-03-11 16:31:39,529 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://dw74.kgb.sqa.cm4:9700/hbase-func1/writetest1/e9d827913a056e696c39bc569e&lt;br/&gt;
a3f99f/cf1/1811012969998104626, entries=8002, sequenceid=619332759, memsize=3.1m, filesize=1.6m&lt;br/&gt;
2012-03-11 16:31:39,640 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://dw74.kgb.sqa.cm4:9700/hbase-func1/writetest1/e9d827913a056e696c39bc569e&lt;br/&gt;
a3f99f/cf2/770333473623552048, entries=12231, sequenceid=619332759, memsize=3.6m, filesize=1.4m&lt;br/&gt;
2012-03-11 16:31:39,641 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~134.8m for region writetest1,,1331454657410.e9d827913a&lt;br/&gt;
056e696c39bc569ea3f99f. in 811ms, sequenceid=619332759, compaction requested=true&lt;br/&gt;
2012-03-11 16:31:39,707 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://dw74.kgb.sqa.cm4:9700/hbase-func1/writetest1/e9d827913a056e696c39bc569e&lt;br/&gt;
a3f99f/cf1/5656568849587368557, entries=119, sequenceid=619332979, memsize=47.4k, filesize=25.6k&lt;br/&gt;
2012-03-11 16:31:39,775 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://dw74.kgb.sqa.cm4:9700/hbase-func1/writetest1/e9d827913a056e696c39bc569e&lt;br/&gt;
a3f99f/cf2/794343845650987521, entries=157, sequenceid=619332979, memsize=47.8k, filesize=19.3k&lt;br/&gt;
2012-03-11 16:31:39,777 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~6.8m for region writetest1,,1331454657410.e9d827913a05&lt;br/&gt;
6e696c39bc569ea3f99f. in 318ms, sequenceid=619332979, compaction requested=true&lt;/p&gt;</description>
                <environment></environment>
        <key id="12546183">HBASE-5568</key>
            <summary>Multi concurrent flushcache() for one region could cause data loss</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zjushch">chunhui shen</assignee>
                                    <reporter username="zjushch">chunhui shen</reporter>
                        <labels>
                    </labels>
                <created>Tue, 13 Mar 2012 04:03:11 +0000</created>
                <updated>Tue, 26 Feb 2013 08:12:50 +0000</updated>
                            <resolved>Mon, 19 Mar 2012 22:23:47 +0000</resolved>
                                                    <fixVersion>0.94.0</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13228192" author="lhofhansl" created="Tue, 13 Mar 2012 04:34:50 +0000"  >&lt;p&gt;Hi Chunhui. You patch only moves the synchronized block out of the try block. Could you explain why this fixes the issue?&lt;/p&gt;</comment>
                            <comment id="13228198" author="zjushch" created="Tue, 13 Mar 2012 04:40:04 +0000"  >&lt;p&gt;@Lars&lt;br/&gt;
In current flushcache() logic, we consider three continuous call flushcache().&lt;br/&gt;
1.The first, call internalFlushcache(status) successfully.&lt;br/&gt;
2.The second, because writestate.flushing=true, so it will return false, but it will set writestate.flushing = false finally.&lt;br/&gt;
3.The third, will call internalFlushcache(status) successfully again.&lt;/p&gt;</comment>
                            <comment id="13228215" author="lhofhansl" created="Tue, 13 Mar 2012 05:07:35 +0000"  >&lt;p&gt;Thanks Chunhui. In that case, wouldn&apos;t a better solution be to pull &amp;lt;result&amp;gt; out of the try block and then only set flushing to false if internalFlushCache returned true?&lt;/p&gt;</comment>
                            <comment id="13228229" author="zjushch" created="Tue, 13 Mar 2012 05:38:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;only set flushing to false if internalFlushCache returned true?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;internalFlushCache() may throws IOException, If we only flushing to false in the case internalFlushCache() returned true, I think no flushcache could happen if throws IOException.&lt;/p&gt;</comment>
                            <comment id="13228995" author="ram_krish" created="Wed, 14 Mar 2012 05:48:57 +0000"  >&lt;p&gt;@Chunhui&lt;/p&gt;

&lt;p&gt;Is this some how related with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5312&quot; title=&quot;Closed parent region present in Hlog.lastSeqWritten&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5312&quot;&gt;&lt;del&gt;HBASE-5312&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13229013" author="ram_krish" created="Wed, 14 Mar 2012 06:19:17 +0000"  >&lt;p&gt;As per the comments on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5312&quot; title=&quot;Closed parent region present in Hlog.lastSeqWritten&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5312&quot;&gt;&lt;del&gt;HBASE-5312&lt;/del&gt;&lt;/a&gt; i feel the patch makes sense.&lt;br/&gt;
I am +1 on it. It is needed in 0.90 also?&lt;/p&gt;
</comment>
                            <comment id="13229019" author="lhofhansl" created="Wed, 14 Mar 2012 06:33:24 +0000"  >&lt;p&gt;@chunhui: looked at the patch again. Makes sense now. +1&lt;/p&gt;</comment>
                            <comment id="13229020" author="lhofhansl" created="Wed, 14 Mar 2012 06:34:08 +0000"  >&lt;p&gt;I think we want this in at least 0.92, 0.94, and 0.96.&lt;/p&gt;</comment>
                            <comment id="13229031" author="zjushch" created="Wed, 14 Mar 2012 06:49:47 +0000"  >&lt;p&gt;Submit a patch for 90 version&lt;/p&gt;</comment>
                            <comment id="13229036" author="ram_krish" created="Wed, 14 Mar 2012 06:54:42 +0000"  >&lt;p&gt;Updated 0.90.7 also in fix versions.&lt;/p&gt;</comment>
                            <comment id="13229341" author="zhihyu@ebaysf.com" created="Wed, 14 Mar 2012 16:58:24 +0000"  >&lt;p&gt;Re-attaching Chunhui&apos;s patch&lt;/p&gt;</comment>
                            <comment id="13229425" author="hadoopqa" created="Wed, 14 Mar 2012 17:46:21 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12518339/HBASE-5568.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12518339/HBASE-5568.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 161 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestStore&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationPeer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13229469" author="ram_krish" created="Wed, 14 Mar 2012 18:28:57 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
hdfs_out=org.apache.hadoop.fs.FSDataOutputStream@61736e
java.lang.NoSuchMethodException: org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.getNumCurrentReplicas()
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.getDeclaredMethod(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:1937)
	at org.apache.hadoop.hbase.regionserver.wal.HLog.getGetNumCurrentReplicas(HLog.java:460)
	at org.apache.hadoop.hbase.regionserver.wal.HLog.&amp;lt;init&amp;gt;(HLog.java:443)
	at org.apache.hadoop.hbase.regionserver.wal.HLog.&amp;lt;init&amp;gt;(HLog.java:341)
	at org.apache.hadoop.hbase.regionserver.TestStore.init(TestStore.java:147)
	at org.apache.hadoop.hbase.regionserver.TestStore.testDeleteExpiredStoreFiles(TestStore.java:162)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In TestStore failures i saw above exception traces.  Its not related to this fix but just wanted to ensure is this expected? or are we missing something?&lt;/p&gt;</comment>
                            <comment id="13229478" author="zhihyu@ebaysf.com" created="Wed, 14 Mar 2012 18:36:09 +0000"  >&lt;p&gt;In getGetNumCurrentReplicas():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;getNumCurrentReplicas--HDFS-826 not available; hdfs_out=&quot;&lt;/span&gt; +
        os, exception);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think we should omit exception if exception is instanceof NoSuchMethodException because the log is at info level.&lt;/p&gt;</comment>
                            <comment id="13229495" author="zhihyu@ebaysf.com" created="Wed, 14 Mar 2012 18:49:25 +0000"  >&lt;p&gt;I can reproduce TestStore failure on my laptop.&lt;/p&gt;</comment>
                            <comment id="13229843" author="zjushch" created="Thu, 15 Mar 2012 02:38:45 +0000"  >&lt;p&gt;I have run org.apache.hadoop.hbase.regionserver.TestStore many times on my local pc, all passed.&lt;br/&gt;
Is there any other problem?&lt;/p&gt;</comment>
                            <comment id="13229861" author="lhofhansl" created="Thu, 15 Mar 2012 03:47:32 +0000"  >&lt;p&gt;@Ted: You see the failure only with this patch applied?&lt;/p&gt;</comment>
                            <comment id="13229865" author="zhihyu@ebaysf.com" created="Thu, 15 Mar 2012 03:54:12 +0000"  >&lt;p&gt;Yes.&lt;/p&gt;</comment>
                            <comment id="13229894" author="zjushch" created="Thu, 15 Mar 2012 05:05:58 +0000"  >&lt;p&gt;I think it&apos;s the problem of test case TestStore#testDeleteExpiredStoreFiles.&lt;br/&gt;
See its code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; storeFileNum = 4;
&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ttl = 1;
...    
hcd.setTimeToLive(ttl);
init(getName(), conf, hcd);

    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; sleepTime = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.scanInfo.getTtl() / storeFileNum;
    ...
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 1; i &amp;lt;= storeFileNum; i++) {
      LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Adding some data &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the store file #&quot;&lt;/span&gt; + i);
      timeStamp = EnvironmentEdgeManager.currentTimeMillis();
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, family, qf1, timeStamp, (&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;));
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, family, qf2, timeStamp, (&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;));
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue(row, family, qf3, timeStamp, (&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;));
      flush(i);
      &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(sleepTime);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Because ttl=1, so sleepTime=250ms, so for the 4 store files , the maxExpiredTimeStamp discrepancy is only 250ms.&lt;/p&gt;

&lt;p&gt;so they may be expired at the same time if you run slowly and then CompactionRequest cr = this.store.requestCompaction(); cr.getFiles().size() return 3.&lt;br/&gt;
We can ensure this from the logs:&lt;br/&gt;
&lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//testReport/org.apache.hadoop.hbase.regionserver/TestStore/testDeleteExpiredStoreFiles/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1187//testReport/org.apache.hadoop.hbase.regionserver/TestStore/testDeleteExpiredStoreFiles/&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2012-03-14 17:19:14,672 INFO  [pool-1-thread-1] regionserver.Store(1002): Completed compaction of 1 file(s) in family of table,,1331745551742.011a93cc4f763307dc36f577662db4b1. into none, size=none; total size &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; store is 2.4k
2012-03-14 17:19:14,923 INFO  [pool-1-thread-1] compactions.CompactSelection(104): Deleting the expired store file by compaction: /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/target/test-data/4d75667a-f352-40cc-978a-f36fec71baf2/TestStoretestDeleteExpiredStoreFiles/011a93cc4f763307dc36f577662db4b1/family/489673e6568241c6bb500b34d7ff29ad whose maxTimeStamp is 1331745552397 &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; the max expired timestamp is 1331745553923
2012-03-14 17:19:14,923 INFO  [pool-1-thread-1] compactions.CompactSelection(104): Deleting the expired store file by compaction: /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/target/test-data/4d75667a-f352-40cc-978a-f36fec71baf2/TestStoretestDeleteExpiredStoreFiles/011a93cc4f763307dc36f577662db4b1/family/7ac26f52fd214aca88bd555f3c82dd91 whose maxTimeStamp is 1331745552671 &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; the max expired timestamp is 1331745553923
2012-03-14 17:19:14,923 INFO  [pool-1-thread-1] compactions.CompactSelection(104): Deleting the expired store file by compaction: /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/target/test-data/4d75667a-f352-40cc-978a-f36fec71baf2/TestStoretestDeleteExpiredStoreFiles/011a93cc4f763307dc36f577662db4b1/family/7ebf7908f5044fcab65a7327d3e19405 whose maxTimeStamp is 1331745552939 &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; the max expired timestamp is 1331745553923
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 1; i &amp;lt;= storeFileNum; i++) {
      &lt;span class=&quot;code-comment&quot;&gt;// verify the expired store file.
&lt;/span&gt;      CompactionRequest cr = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.requestCompaction();
      assertEquals(1, cr.getFiles().size());
      assertTrue(cr.getFiles().get(0).getReader().getMaxTimestamp() &amp;lt; 
          (&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis() - &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.scanInfo.getTtl()));
      &lt;span class=&quot;code-comment&quot;&gt;// Verify that the expired the store has been deleted.
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.compact(cr);
      assertEquals(storeFileNum - i, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.getStorefiles().size());

      &lt;span class=&quot;code-comment&quot;&gt;// Let the next store file expired.
&lt;/span&gt;      &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(sleepTime);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;after the first compaction,&lt;br/&gt;
the next call this.store.requestCompaction(), the other three store files are  all expired at one time.&lt;/p&gt;</comment>
                            <comment id="13230895" author="zjushch" created="Fri, 16 Mar 2012 04:55:28 +0000"  >&lt;p&gt;patch v2 for test case:&lt;br/&gt;
change TestStore#testDeleteExpiredStoreFiles#ttl from 1 to 4 &lt;/p&gt;</comment>
                            <comment id="13230910" author="hadoopqa" created="Fri, 16 Mar 2012 05:48:00 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12518615/HBASE-5568v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12518615/HBASE-5568v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 161 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestAdmin&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1197//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1197//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1197//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1197//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1197//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1197//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13230940" author="hadoopqa" created="Fri, 16 Mar 2012 06:57:19 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12518621/HBASE-5568v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12518621/HBASE-5568v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 161 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1198//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1198//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1198//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1198//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1198//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1198//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13231318" author="zhihyu@ebaysf.com" created="Fri, 16 Mar 2012 16:07:06 +0000"  >&lt;p&gt;Patch v2 looks good.&lt;br/&gt;
Will integrate if there is no objection.&lt;/p&gt;</comment>
                            <comment id="13231324" author="zhihyu@ebaysf.com" created="Fri, 16 Mar 2012 16:15:14 +0000"  >&lt;p&gt;@Chunhui:&lt;br/&gt;
A patch for 0.92 is needed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
p0 HBASE-5568v2.patch
...
Hunk #1 FAILED at 152.
1 out of 1 hunk FAILED -- saving rejects to file src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java.rej
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please also update patch for 0.90 as well.&lt;/p&gt;</comment>
                            <comment id="13231361" author="zhihyu@ebaysf.com" created="Fri, 16 Mar 2012 16:40:35 +0000"  >&lt;p&gt;Integrated to TRUNK.&lt;/p&gt;

&lt;p&gt;Thanks for the patch Chunhui.&lt;/p&gt;

&lt;p&gt;Thanks for the review Ramkrishna and Lars.&lt;/p&gt;</comment>
                            <comment id="13231464" author="hudson" created="Fri, 16 Mar 2012 18:04:27 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2684 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2684/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5568&quot; title=&quot;Multi concurrent flushcache() for one region could cause data loss&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5568&quot;&gt;&lt;del&gt;HBASE-5568&lt;/del&gt;&lt;/a&gt; Multi concurrent flushcache() for one region could cause data loss (Chunhui) (Revision 1301639)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13231467" author="zhihyu@ebaysf.com" created="Fri, 16 Mar 2012 18:07:44 +0000"  >&lt;p&gt;Integrated to 0.94 as well.&lt;/p&gt;</comment>
                            <comment id="13231499" author="lhofhansl" created="Fri, 16 Mar 2012 18:36:39 +0000"  >&lt;p&gt;Thanks Ted.&lt;/p&gt;</comment>
                            <comment id="13231507" author="stack" created="Fri, 16 Mar 2012 18:42:35 +0000"  >&lt;p&gt;+1 Good find Chunhui.&lt;/p&gt;</comment>
                            <comment id="13231517" author="zhihyu@ebaysf.com" created="Fri, 16 Mar 2012 18:58:31 +0000"  >&lt;p&gt;Integrated to 0.90 branch as well.&lt;/p&gt;</comment>
                            <comment id="13231540" author="hudson" created="Fri, 16 Mar 2012 19:15:56 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #34 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/34/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/34/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5568&quot; title=&quot;Multi concurrent flushcache() for one region could cause data loss&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5568&quot;&gt;&lt;del&gt;HBASE-5568&lt;/del&gt;&lt;/a&gt; Multi concurrent flushcache() for one region could cause data loss (Chunhui) (Revision 1301676)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13231802" author="zjushch" created="Sat, 17 Mar 2012 02:09:40 +0000"  >&lt;p&gt;patch for 92 version&lt;/p&gt;</comment>
                            <comment id="13231804" author="hadoopqa" created="Sat, 17 Mar 2012 02:11:58 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12518769/HBASE-5568-92v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12518769/HBASE-5568-92v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1215//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1215//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13231859" author="hudson" created="Sat, 17 Mar 2012 05:56:27 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #140 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/140/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/140/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5568&quot; title=&quot;Multi concurrent flushcache() for one region could cause data loss&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5568&quot;&gt;&lt;del&gt;HBASE-5568&lt;/del&gt;&lt;/a&gt; Multi concurrent flushcache() for one region could cause data loss (Chunhui) (Revision 1301639)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13232438" author="ram_krish" created="Mon, 19 Mar 2012 04:49:39 +0000"  >&lt;p&gt;Resolving as committed to all versions.&lt;/p&gt;</comment>
                            <comment id="13232442" author="zhihyu@ebaysf.com" created="Mon, 19 Mar 2012 04:54:43 +0000"  >&lt;p&gt;Patch for 0.92 hasn&apos;t been integrated.&lt;/p&gt;</comment>
                            <comment id="13232444" author="ram_krish" created="Mon, 19 Mar 2012 04:56:56 +0000"  >&lt;p&gt;Sorry Ted.  I did not notice that. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13232446" author="zhihyu@ebaysf.com" created="Mon, 19 Mar 2012 05:00:56 +0000"  >&lt;p&gt;Integrated 0.92 patch to 0.92 branch.&lt;/p&gt;</comment>
                            <comment id="13232488" author="hudson" created="Mon, 19 Mar 2012 07:17:23 +0000"  >&lt;p&gt;Integrated in HBase-0.92 #329 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92/329/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92/329/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5568&quot; title=&quot;Multi concurrent flushcache() for one region could cause data loss&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5568&quot;&gt;&lt;del&gt;HBASE-5568&lt;/del&gt;&lt;/a&gt; Multi concurrent flushcache() for one region could cause data loss (Chunhui) (Revision 1302270)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
tedyu : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13232965" author="yuzhihong@gmail.com" created="Mon, 19 Mar 2012 22:23:47 +0000"  >&lt;p&gt;Integrated to 0.92&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12540682">HBASE-5312</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12538374">HBASE-5199</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12518299" name="HBASE-5568-90.patch" size="2900" author="zjushch" created="Wed, 14 Mar 2012 06:49:45 +0000"/>
                            <attachment id="12518769" name="HBASE-5568-92v2.patch" size="1765" author="zjushch" created="Sat, 17 Mar 2012 02:09:40 +0000"/>
                            <attachment id="12518339" name="HBASE-5568.patch" size="1765" author="zhihyu@ebaysf.com" created="Wed, 14 Mar 2012 16:58:23 +0000"/>
                            <attachment id="12518147" name="HBASE-5568.patch" size="1765" author="zjushch" created="Tue, 13 Mar 2012 04:06:17 +0000"/>
                            <attachment id="12518621" name="HBASE-5568v2.patch" size="2337" author="zjushch" created="Fri, 16 Mar 2012 06:02:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 13 Mar 2012 04:34:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>231341</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 39 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0694f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34409</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>