<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:24:30 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5074/HBASE-5074.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5074] support checksums in HBase block cache</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5074</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The current implementation of HDFS stores the data in one block file and the metadata(checksum) in another block file. This means that every read into the HBase block cache actually consumes two disk iops, one to the datafile and one to the checksum file. This is a major problem for scaling HBase, because HBase is usually bottlenecked on the number of random disk iops that the storage-hardware offers.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12535789">HBASE-5074</key>
            <summary>support checksums in HBase block cache</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dhruba">dhruba borthakur</assignee>
                                    <reporter username="dhruba">dhruba borthakur</reporter>
                        <labels>
                    </labels>
                <created>Tue, 20 Dec 2011 06:12:31 +0000</created>
                <updated>Tue, 15 Oct 2013 04:46:41 +0000</updated>
                            <resolved>Fri, 9 Mar 2012 00:32:12 +0000</resolved>
                                                    <fixVersion>0.94.0</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>20</watches>
                                                                <comments>
                            <comment id="13172967" author="dhruba" created="Tue, 20 Dec 2011 06:15:16 +0000"  >&lt;p&gt;The corresponding HDFS jira is &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2699&quot; title=&quot;Store data and checksums together in block file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2699&quot;&gt;HDFS-2699&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another alternative proposal is to store store a checksum in the block header of every hbase block. HBase will make a pread(noChecksumVerify) call to hdfs for random reads. Once the block is read into the hbase cache, it will verify the checksum and if not valid, have to use a new HDFS api to read in contents from another hdfs replica.&lt;/p&gt;</comment>
                            <comment id="13172994" author="tlipcon" created="Tue, 20 Dec 2011 07:22:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;Once the block is read into the hbase cache, it will verify the checksum and if not valid, have to use a new HDFS api to read in contents from another hdfs replica&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Rather than adding a new API to read from another replica, HBase could instead just trigger a second pread from HDFS &lt;em&gt;with&lt;/em&gt; the verifyChecksum flag set. This would cause HDFS to notice the checksum error based on its own checksums, and do the &quot;right thing&quot; (ie report the bad replica, fix it up, etc).&lt;/p&gt;</comment>
                            <comment id="13173006" author="dhruba" created="Tue, 20 Dec 2011 07:54:43 +0000"  >&lt;p&gt;Todd: you are right. that would make life easy.&lt;/p&gt;

&lt;p&gt;I am proposing that HBase disk format V3 have a 4 byte checksum for every hbase block. This will not require checksums and data to be stored inline in HDFS while at the same-time allow hbase to do additional iops. One minor disadvantage of this approach is that checksums would be computed twice, once by the hbase regionserver and once by the hdfs client. How bad is this cpu overhead?&lt;/p&gt;

&lt;p&gt;BTW, I got this idea while chatting with Nicolas Spiegelberg. Credits to him for this elegant idea.&lt;/p&gt;</comment>
                            <comment id="13173007" author="dhruba" created="Tue, 20 Dec 2011 07:55:51 +0000"  >&lt;p&gt;s/allow hbase to do additional iops/allow hbase to avoid additional iops/g&lt;/p&gt;</comment>
                            <comment id="13173012" author="tlipcon" created="Tue, 20 Dec 2011 08:04:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;One minor disadvantage of this approach is that checksums would be computed twice, once by the hbase regionserver and once by the hdfs client. How bad is this cpu overhead?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean on write? The native CRC32C implementation in HDFS trunk right now can do somewhere around 6GB/sec - I clocked it at about 16% overhead compared to the non-checksummed path a while ago. So I think overhead is fairly minimal.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I am proposing that HBase disk format V3 have a 4 byte checksum for every hbase block&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;4 byte checksum for 64KB+ of data seems pretty low. IMO we should continue to do &quot;chunked checksums&quot; - maybe a CRC32 for every 1KB in the block. This allows people to use larger block sizes without compromising checksum effectiveness. The reason to choose chunked CRC32 over a wider hash is that CRC32 has a very efficient hardware implementation in SSE4.2. Plus, we can share all the JNI code already developed for Hadoop to calculate and verify these style of checksums &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13173373" author="apurtell" created="Tue, 20 Dec 2011 18:22:05 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13173385" author="jdcryans" created="Tue, 20 Dec 2011 18:27:39 +0000"  >&lt;p&gt;This jira&apos;s title make it sound like you want to checksum when reading from the block cache.&lt;/p&gt;</comment>
                            <comment id="13173388" author="stack" created="Tue, 20 Dec 2011 18:29:48 +0000"  >&lt;p&gt;Where in the read pipeline would we verify the checksum?  Down in hfile?  Where would we do the exception processing forcing reread with checksum=on?  Also down in hfile?&lt;/p&gt;

&lt;p&gt;(Nice idea BTW)&lt;/p&gt;</comment>
                            <comment id="13173461" author="dhruba" created="Tue, 20 Dec 2011 19:50:19 +0000"  >&lt;p&gt;Yes, the verification of the checksums would happen when the hfile block is loaded into the block cache. it will be entirely in hfile code. also, the exception processing would happen in hfile too.&lt;/p&gt;</comment>
                            <comment id="13195710" author="phabricator@reviews.facebook.net" created="Sun, 29 Jan 2012 08:02:08 +0000"  >&lt;p&gt;dhruba requested code review of &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  HFile is enhanced to store a checksum for each block. HDFS checksum verification is avoided while reading data into the block cache. On a checksum verification failure, we retry the file system read request with hdfs checksums switched on (thanks Todd).&lt;/p&gt;

&lt;p&gt;  I have a benchmark that shows that it reduces iops on the disk by about 40%. In this experiment, the entire memory on the regionserver is allocated to the regionserver&apos;s jvm and the OS buffer cache size is negligible. I also measured  negligible (&amp;lt;5%) additional cpu usage while using hbase-level checksums.&lt;/p&gt;

&lt;p&gt;  The salient points of this patch:&lt;/p&gt;

&lt;p&gt;  1. Each hfile&apos;s trailer used to have a 4 byte version number. I enhanced this so that these 4 bytes can be interpreted as a (major version number, minor version). Pre-existing hfiles have a minor version of 0. The new hfile format has a minor version of 1 (thanks Mikhail). The hfile major version remains unchanged at 2. The reason I did not introduce a new major version number is because the code changes needed to store/read checksums do not differ much from existing V2 writers/readers.&lt;/p&gt;

&lt;p&gt;  2. Introduced a HFileSystem object which is a encapsulates the FileSystem objects needed to access data from hfiles and hlogs.  HDFS FileSystem objects already had the ability to switch off checksum verifications for reads.&lt;/p&gt;

&lt;p&gt;  3. The majority of the code changes are located in hbase.io.hfie package. The retry of a read on an initial checksum failure occurs inside the hbase.io.hfile package itself.  The code changes to hbase.regionserver package are minor.&lt;/p&gt;

&lt;p&gt;  4. The format of a hfileblock is the header followed by the data followed by the checksum(s). Each 16 K (configurable) size of data has a 4 byte checksum.  The hfileblock header has two additional fields: a 4 byte value to store the bytesPerChecksum and a 4 byte value to store the size of the user data (excluding the checksum data). This is well explained in the associated javadocs.&lt;/p&gt;

&lt;p&gt;  5. I added a test to test backward compatibility. I will be writing more unit tests that triggers checksum verification failures aggressively. I have left a few redundant log messages in the code (just for easier debugging) and will remove them in later stage of this patch. I will also be adding metrics on number of checksum verification failures/success in a later version of this diff.&lt;/p&gt;

&lt;p&gt;  6. By default, hbase-level checksums are switched on and hdfs level checksums are switched off for hfile-reads. No changes to Hlog code path here.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  The default setting is to switch on hbase checksums for hfile-reads, thus all existing tests actually validate the new code pieces. I will be writing more unit tests for triggering checksum verification failures.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/3171/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/3171/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tip: use the X-Herald-Rules header to filter Herald messages in your client.&lt;/p&gt;</comment>
                            <comment id="13195711" author="phabricator@reviews.facebook.net" created="Sun, 29 Jan 2012 08:02:10 +0000"  >&lt;p&gt;dhruba requested code review of &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  HFile is enhanced to store a checksum for each block. HDFS checksum verification is avoided while reading data into the block cache. On a checksum verification failure, we retry the file system read request with hdfs checksums switched on (thanks Todd).&lt;/p&gt;

&lt;p&gt;  I have a benchmark that shows that it reduces iops on the disk by about 40%. In this experiment, the entire memory on the regionserver is allocated to the regionserver&apos;s jvm and the OS buffer cache size is negligible. I also measured  negligible (&amp;lt;5%) additional cpu usage while using hbase-level checksums.&lt;/p&gt;

&lt;p&gt;  The salient points of this patch:&lt;/p&gt;

&lt;p&gt;  1. Each hfile&apos;s trailer used to have a 4 byte version number. I enhanced this so that these 4 bytes can be interpreted as a (major version number, minor version). Pre-existing hfiles have a minor version of 0. The new hfile format has a minor version of 1 (thanks Mikhail). The hfile major version remains unchanged at 2. The reason I did not introduce a new major version number is because the code changes needed to store/read checksums do not differ much from existing V2 writers/readers.&lt;/p&gt;

&lt;p&gt;  2. Introduced a HFileSystem object which is a encapsulates the FileSystem objects needed to access data from hfiles and hlogs.  HDFS FileSystem objects already had the ability to switch off checksum verifications for reads.&lt;/p&gt;

&lt;p&gt;  3. The majority of the code changes are located in hbase.io.hfie package. The retry of a read on an initial checksum failure occurs inside the hbase.io.hfile package itself.  The code changes to hbase.regionserver package are minor.&lt;/p&gt;

&lt;p&gt;  4. The format of a hfileblock is the header followed by the data followed by the checksum(s). Each 16 K (configurable) size of data has a 4 byte checksum.  The hfileblock header has two additional fields: a 4 byte value to store the bytesPerChecksum and a 4 byte value to store the size of the user data (excluding the checksum data). This is well explained in the associated javadocs.&lt;/p&gt;

&lt;p&gt;  5. I added a test to test backward compatibility. I will be writing more unit tests that triggers checksum verification failures aggressively. I have left a few redundant log messages in the code (just for easier debugging) and will remove them in later stage of this patch. I will also be adding metrics on number of checksum verification failures/success in a later version of this diff.&lt;/p&gt;

&lt;p&gt;  6. By default, hbase-level checksums are switched on and hdfs level checksums are switched off for hfile-reads. No changes to Hlog code path here.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  The default setting is to switch on hbase checksums for hfile-reads, thus all existing tests actually validate the new code pieces. I will be writing more unit tests for triggering checksum verification failures.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/3171/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/3171/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tip: use the X-Herald-Rules header to filter Herald messages in your client.&lt;/p&gt;</comment>
                            <comment id="13195773" author="phabricator@reviews.facebook.net" created="Sun, 29 Jan 2012 15:57:08 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Good job, Dhruba.&lt;/p&gt;

&lt;p&gt;  I like this comment from HFileSystem:&lt;/p&gt;

&lt;p&gt;  + * In future, if we want to make hlogs be in a different filesystem,&lt;br/&gt;
  + * this is the place to make it happen.&lt;/p&gt;

&lt;p&gt;  I only see one setVerifyChecksum() call in the HFileSystem ctor.&lt;br/&gt;
  The readfs is used by createReaderWithEncoding().&lt;/p&gt;

&lt;p&gt;  Shall we give readfs more flexibility where checksum verification can be configured dynamically ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13195940" author="zhihyu@ebaysf.com" created="Mon, 30 Jan 2012 05:34:53 +0000"  >&lt;p&gt;In HFileBlock.readBlockData(), once useHBaseChecksum is set to false, I don&apos;t see where it would be set to true again.&lt;br/&gt;
At line 1613, if HDFS checksum verification was able to correct the problem,&lt;br/&gt;
1. should we re-enable useHBaseChecksum ?&lt;br/&gt;
2. I think we should log the fact that HDFS checksum verification worked.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
     * @param pread whether to use HBase checksums. If HBase checksum is
     *          switched off, then use HDFS checksum.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please correct the name of parameter above.&lt;/p&gt;</comment>
                            <comment id="13195952" author="dhruba" created="Mon, 30 Jan 2012 06:12:25 +0000"  >&lt;p&gt;Thanks Ted/Zhihong for the review comments.&lt;/p&gt;

&lt;p&gt;ted: The thinking is that HFileSystem.readfs should be used only by StoreFiles for reading hfile. That is the reason that this code path uses readfs. This is the only place we want to avoid using hdfs checksums. All other code paths are unchanged.&lt;/p&gt;

&lt;p&gt;Zhihong: If hbase checksum validation fails once, I switch back to using hdfs-level checksums for that instance of the Reader. For each block that have hbase-checksums mismatch we retry the operation, thus it actually &lt;b&gt;doubles&lt;/b&gt; the iops. I was trying to avoid the scenario where most hbase level checksums fail, and each io is retried twice. But if people feel otherwise, I can set the useHBaseChecksum after a few successful ios.&lt;/p&gt;

&lt;p&gt;I will log the fact the hdfs checksum verification worked and will also add metrics counters to record these events (next version of the patch). &lt;/p&gt;
</comment>
                            <comment id="13195958" author="dhruba" created="Mon, 30 Jan 2012 06:31:52 +0000"  >&lt;p&gt;This patch is not yet ready for submission. It needs enhancement with a unit test and metrics collection.&lt;/p&gt;</comment>
                            <comment id="13196606" author="phabricator@reviews.facebook.net" created="Tue, 31 Jan 2012 01:05:10 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Added CCs: dhruba&lt;/p&gt;

&lt;p&gt;  @Dhruba: The &quot;checksum at the end of block&quot; approach seems reasonable and the implementation looks good! Specific comments inline.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 What is the purpose of the hfs parameter here?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:49 s/preceeding/preceding/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:50 s/deermines/determines/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:51 s/does not need/do not need/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:119 s/major/minor/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:260 Rename the existing expectVersion to expectMajorVersion for clarity.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:343 Rename to expectMajorVersion for clarity.&lt;/p&gt;

&lt;p&gt;  Also, does the version field of this class now only contain the major version? If so, rename it to majorVersion.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:345 Add the word &quot;major&quot; to the error message.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:462 Rename to getMajorVersion&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:402 Can we modify the parameter type and get rid of this cast?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:415 This is not a constructor, but a factory method.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:417 Add &quot;ForTest&quot; to method name for clarity.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:91 s/has/have/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:95 Consider replacing the &quot;_V0&quot; suffix with something more meaningful like &quot;_NO_CHECKSUM&quot;.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:102 Consider using a suffix &quot;_WITH_CHECKSUM&quot;.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:123 When the number of bytes per checksum becomes configurable, will that require a persistent data format change? What will the upgrade procedure be in that case?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:138 It is not clear from this call that 0 is minor version. Create a constant with a meaningful name (e.g. MINOR_VERSION_NO_CHECKSUM).&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:149 Consider adding &quot;WithChecksum&quot; to variable name.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:395-398 This is becoming bulky. Factor out the common term (uncompressedSizeWithoutHeader + headerSize() + cksumBytes) into a local variable. Also avoid evaluating headerSize() twice.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:400-402 Reuse the new local variables from the above comments here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:441-442 Update this comment, since the meaning of &quot;extraBytes&quot; has changed from just being the room for the next block&apos;s header to a much more complex role.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:757-758 Should we throw an IOException instead since this method already throws it?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:771-772 tmp is a particularly bad variable name. Combine these two lines and get rid of tmp.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:808-809 Get rid of tmp and combine these two lines.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:788 This method and the above one seem to share a lot of code. Is it possible to get rid of code duplication?&lt;/p&gt;

&lt;p&gt;  Also, these two methods seem isolated enough to be moved to another class, maybe even as static methods.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:866-870 Do we need this in case of minorVersion = 0? Or do we always write new files with checksums?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:973-975 Somehow the fact that checksum format is different for compressed and uncompressed blocks has escaped me halfway through the review. Maybe it is worth explicitly mentioning that in javadoc.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:999-1011 Use System.arraycopy instead of loops.&lt;/p&gt;

&lt;p&gt;  Add &quot;ForTest&quot; to method name to discourage its use in production.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1202 Nice! Thanks for locking down these internal base classes and methods.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1389-1390 Delete one of these lines.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1520-1527 Does it make sense to move this checksum instantiation code to a function and reuse it everywhere we call ChecksumFactory.newInstance()?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1786 Remove this and other debug output statements.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1871 As I mentioned, it is probably better to move checksum computation and validation code to a separate utility class.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java:220 Use a constant to indicate that this is a minor version without checksum support instead of just 0.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:56 Is this necessary? Does not Java call default constructors automatically?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java:70 This is for testing only, right?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java:225 Long line.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:1 A lot in this file appears to be copy-paste from TestHFileBlock, so it very difficult to see the real changes. Please reuse the appropriate code instead.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13197153" author="zhihyu@ebaysf.com" created="Tue, 31 Jan 2012 19:39:28 +0000"  >&lt;p&gt;When FS_CHECKSUM_VERIFICATION carries value of false, would it still make sense that we retry the operation if hbase-checksums mismatch ?&lt;br/&gt;
Meaning, would getStreamWithChecksum() return a stream which does checksum validation inside the FileSystem ?&lt;/p&gt;</comment>
                            <comment id="13198081" author="phabricator@reviews.facebook.net" created="Wed, 1 Feb 2012 19:36:57 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Thanks for the excellent and detailed review Mikhail. I am making most of the changes you proposed and will post a new patch very soon. Really appreciate your time with the huge review.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 The Reader would need to reopen a file with chesksums switched on/off if needed (on checksum failure). Hence the filessytem object is needed here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:402 This is messy, because there are 100001 places where FileSystem type is being used in HBase. This will make this patch immensely large and difficult to merge with every new change in trunk. does this sound reasonable? If not, I can change all mention of FileSystem to HFileSystem in a succeeding patch perhaps?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:123 It does not need a disk format change if we decide to make it configurable. Each disk block has a 4 byte field to store the bytes-per-checksum. In the current code, the value that is stored in this field is 16K.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:417 This is a code cleanup but not related to this patch. I would like to defer this for later.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:149 I did not do this because it makes the variable names very very long-winded. Instead, I wrote more comments to describe each variable. Let me know if you think that this is not enough for documentation.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:441-442 The meaning of extrabytes has not changed. It still means that we need to allocate space for the next header.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:788 I put the creation of the checksum object in a common method. The remainder of the two methods are quite similar but unfortunately one operates on a byte buffer while the other operates directly on the ByteBuffer. One way to merge these two methods is to incur a buffer copy which I am trying to avoid. Also, these two methods are very specific to how the header in the HBlockFile is laid out, so I kept them as instance methods rather than static methods. If you feel strongly about this, then I will be happy yo move them to a different file.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:866-870 All new files always have checksums. But the log line was for debugging, so I will get rid of it.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:973-975 Good point. I enhanced the javadocs where the variable onDiskChecksum is declared.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1520-1527 This code piece maybe done be a different helper thread. So I am throwing RunTime exception here so that the RegionServer shuts down if it is unable to instantiate a Checksum class. Is there something better I can do here?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1871 I actually made this a protected method so that I can override it in the unit test to simulate checksum failure.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13198082" author="phabricator@reviews.facebook.net" created="Wed, 1 Feb 2012 19:36:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Thanks for the excellent and detailed review Mikhail. I am making most of the changes you proposed and will post a new patch very soon. Really appreciate your time with the huge review.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 The Reader would need to reopen a file with chesksums switched on/off if needed (on checksum failure). Hence the filessytem object is needed here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:402 This is messy, because there are 100001 places where FileSystem type is being used in HBase. This will make this patch immensely large and difficult to merge with every new change in trunk. does this sound reasonable? If not, I can change all mention of FileSystem to HFileSystem in a succeeding patch perhaps?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:123 It does not need a disk format change if we decide to make it configurable. Each disk block has a 4 byte field to store the bytes-per-checksum. In the current code, the value that is stored in this field is 16K.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:417 This is a code cleanup but not related to this patch. I would like to defer this for later.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:149 I did not do this because it makes the variable names very very long-winded. Instead, I wrote more comments to describe each variable. Let me know if you think that this is not enough for documentation.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:441-442 The meaning of extrabytes has not changed. It still means that we need to allocate space for the next header.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:788 I put the creation of the checksum object in a common method. The remainder of the two methods are quite similar but unfortunately one operates on a byte buffer while the other operates directly on the ByteBuffer. One way to merge these two methods is to incur a buffer copy which I am trying to avoid. Also, these two methods are very specific to how the header in the HBlockFile is laid out, so I kept them as instance methods rather than static methods. If you feel strongly about this, then I will be happy yo move them to a different file.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:866-870 All new files always have checksums. But the log line was for debugging, so I will get rid of it.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:973-975 Good point. I enhanced the javadocs where the variable onDiskChecksum is declared.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1520-1527 This code piece maybe done be a different helper thread. So I am throwing RunTime exception here so that the RegionServer shuts down if it is unable to instantiate a Checksum class. Is there something better I can do here?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1871 I actually made this a protected method so that I can override it in the unit test to simulate checksum failure.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13198280" author="phabricator@reviews.facebook.net" created="Wed, 1 Feb 2012 22:43:01 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  I&apos;m a little skeptical of pushing HFileSystem in at the createHRegion level - can&apos;t we construct it lower down and have fewer sweeping changes across the codebase?&lt;/p&gt;

&lt;p&gt;  Otherwise I&apos;m pretty psyched about this feature! Should be a great speed boost.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:598 I think this could be clarified a bit... I am at the top of the diff so don&apos;t have context, so not sure whether it means that &lt;em&gt;no&lt;/em&gt; checksums will be verified, or if checksums will be verified but only when the HFile checksum isn&apos;t present or can&apos;t be verified?&lt;/p&gt;

&lt;p&gt;  I&apos;d expect the config to have several different modes, rather than a boolean:&lt;/p&gt;

&lt;p&gt;  FS_ONLY: always verify the FS checksum, ignore the HFile checksum&lt;br/&gt;
  BOTH: always verify the FS checksum and the HFile checksum (when available)&lt;br/&gt;
  OPTIMIZED: verify the HFile checksum. If it fails or not present, fall back to the FS checksum  (this would be the default)&lt;br/&gt;
  NONE: don&apos;t verify any checksums (for those who like to live on the edge!)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 This is sort of working around a deficiency in the Hadoop input stream APIs, right? I think this is a decent workaround for now, but do you think it would be a good idea to add a new interface like &quot;Checksummed&quot; to Hadoop, which would add a setVerifyChecksum() call?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:123-127 do we need this extra ctor? considering this is a private API seems like we could just update the call sites to add a &apos;, 0&apos;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:93 may be worth adding a constant here like VERSION_CURRENT = VERSION_WITH_CHECKSUM.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:102 or HEADER_SIZE_V1 = ...&lt;br/&gt;
  static final int HEADER_SIZE = HEADER_SIZE_V1;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:132 why is this a warning?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:175 this takes a parameter minorVersion - is it unused?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:190 typo: @param minorVersion&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:205-208 confused about this - see above... if this constructor is only meant for minor version 0 blocks, shouldn&apos;t we have Preconditions.checkArgument(minorVersion == 0) or something?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:229 Skeptical of this line &amp;#8211; why isn&apos;t it onDiskDataSizeWithoutHeader + HEADER_SIZE_V0?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:252 a little confused why this doesn&apos;t use the onDiskDataSizeWithHeader member...&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:629 typo: incudes&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:751 It would be nice to reuse the code in Hadoop trunk here - see DataChecksum.verifyChunkedSums for example. The benefit is that we have JNI implementations using SSE code there. Only downside is that the JNI code requires direct byte buffers, which I guess we aren&apos;t using here... perhaps punt to a future improvement.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:774 I assume this will move to a trace level debug or something?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1634 I think rather than returning null it makes more sense to throw a ChecksumException here&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1401-1402 I don&apos;t know this area of the code well &amp;#8211; is it supposed to be thread-safe? This lazy-initialization pattern is not.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1605 can we just recurse here?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1896 it&apos;s not possible to get at the file path from this context, is it?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1888 would be nice to reuse Hadoop code here if possible for performance&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java:206-207 this might result in &quot;Wrong FS&quot; if the default FS doesn&apos;t match the path provided&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java:1072 can you include the path in the msg?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3546-3547 this code should be passing the path as well to avoid &quot;Wrong FS&quot;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3597 same - default FS may not match the hbase rootdir FS. Maybe RegionServerServices should expose a getHFilesystem() call?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java:335 this downcast would be avoided by adding getFileSystem to RegionServerServices above&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java:31 could you reuse o.a.h.io.DataOutputBuffer instead of making a new class?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:39 I&apos;d strongly recommend starting with an implementation of CRC32C (castagnioli polynomial) instead of the Zip polynomial - reason being that there is a hardware implementation in SSE4.2. You can rip the pure-java implementation from Hadoop trunk (PureJavaCrc32C) into HBase.&lt;/p&gt;

&lt;p&gt;  Failing that, we need to add hfile metadata which specifies the checksum algorithm in addition to the checksum type.&lt;br/&gt;
  You could reuse the DataChecksum class from Hadoop there - it encapsulates (type, bytesPerChecksum, checksumSize)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:65-67 this reflection based method is going to be horribly slow&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:59 typo, operation.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:54 the ctor should take a Path or URI indicating the filesystem, rather than always using the default - same &quot;wrong fs&quot; issue as above&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:67 typo: in-&amp;gt;is&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:132-133 this is rarely the right call&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13198281" author="phabricator@reviews.facebook.net" created="Wed, 1 Feb 2012 22:43:09 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  I&apos;m a little skeptical of pushing HFileSystem in at the createHRegion level - can&apos;t we construct it lower down and have fewer sweeping changes across the codebase?&lt;/p&gt;

&lt;p&gt;  Otherwise I&apos;m pretty psyched about this feature! Should be a great speed boost.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:598 I think this could be clarified a bit... I am at the top of the diff so don&apos;t have context, so not sure whether it means that &lt;em&gt;no&lt;/em&gt; checksums will be verified, or if checksums will be verified but only when the HFile checksum isn&apos;t present or can&apos;t be verified?&lt;/p&gt;

&lt;p&gt;  I&apos;d expect the config to have several different modes, rather than a boolean:&lt;/p&gt;

&lt;p&gt;  FS_ONLY: always verify the FS checksum, ignore the HFile checksum&lt;br/&gt;
  BOTH: always verify the FS checksum and the HFile checksum (when available)&lt;br/&gt;
  OPTIMIZED: verify the HFile checksum. If it fails or not present, fall back to the FS checksum  (this would be the default)&lt;br/&gt;
  NONE: don&apos;t verify any checksums (for those who like to live on the edge!)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 This is sort of working around a deficiency in the Hadoop input stream APIs, right? I think this is a decent workaround for now, but do you think it would be a good idea to add a new interface like &quot;Checksummed&quot; to Hadoop, which would add a setVerifyChecksum() call?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:123-127 do we need this extra ctor? considering this is a private API seems like we could just update the call sites to add a &apos;, 0&apos;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:93 may be worth adding a constant here like VERSION_CURRENT = VERSION_WITH_CHECKSUM.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:102 or HEADER_SIZE_V1 = ...&lt;br/&gt;
  static final int HEADER_SIZE = HEADER_SIZE_V1;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:132 why is this a warning?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:175 this takes a parameter minorVersion - is it unused?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:190 typo: @param minorVersion&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:205-208 confused about this - see above... if this constructor is only meant for minor version 0 blocks, shouldn&apos;t we have Preconditions.checkArgument(minorVersion == 0) or something?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:229 Skeptical of this line &amp;#8211; why isn&apos;t it onDiskDataSizeWithoutHeader + HEADER_SIZE_V0?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:252 a little confused why this doesn&apos;t use the onDiskDataSizeWithHeader member...&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:629 typo: incudes&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:751 It would be nice to reuse the code in Hadoop trunk here - see DataChecksum.verifyChunkedSums for example. The benefit is that we have JNI implementations using SSE code there. Only downside is that the JNI code requires direct byte buffers, which I guess we aren&apos;t using here... perhaps punt to a future improvement.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:774 I assume this will move to a trace level debug or something?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1634 I think rather than returning null it makes more sense to throw a ChecksumException here&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1401-1402 I don&apos;t know this area of the code well &amp;#8211; is it supposed to be thread-safe? This lazy-initialization pattern is not.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1605 can we just recurse here?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1896 it&apos;s not possible to get at the file path from this context, is it?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1888 would be nice to reuse Hadoop code here if possible for performance&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java:206-207 this might result in &quot;Wrong FS&quot; if the default FS doesn&apos;t match the path provided&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java:1072 can you include the path in the msg?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3546-3547 this code should be passing the path as well to avoid &quot;Wrong FS&quot;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3597 same - default FS may not match the hbase rootdir FS. Maybe RegionServerServices should expose a getHFilesystem() call?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java:335 this downcast would be avoided by adding getFileSystem to RegionServerServices above&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java:31 could you reuse o.a.h.io.DataOutputBuffer instead of making a new class?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:39 I&apos;d strongly recommend starting with an implementation of CRC32C (castagnioli polynomial) instead of the Zip polynomial - reason being that there is a hardware implementation in SSE4.2. You can rip the pure-java implementation from Hadoop trunk (PureJavaCrc32C) into HBase.&lt;/p&gt;

&lt;p&gt;  Failing that, we need to add hfile metadata which specifies the checksum algorithm in addition to the checksum type.&lt;br/&gt;
  You could reuse the DataChecksum class from Hadoop there - it encapsulates (type, bytesPerChecksum, checksumSize)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:65-67 this reflection based method is going to be horribly slow&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:59 typo, operation.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:54 the ctor should take a Path or URI indicating the filesystem, rather than always using the default - same &quot;wrong fs&quot; issue as above&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:67 typo: in-&amp;gt;is&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:132-133 this is rarely the right call&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13198472" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 02:15:52 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: thanks for the update! See my replies inline.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 I don&apos;t see any overrides of this method in HFileReaderV&lt;/p&gt;
{1,2}
&lt;p&gt; in the patch, and this particular method looks really confusing, since it takes a parameter, ignores it, and returns this.hfs instead. Did you mean to override it in a way that does use the parameter? In that case, could you please add a javadoc here explaining why the argument is being ignored?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:402 Agreed. Perhaps we should avoid replacing all occurrences of FileSystem with HFileSystem. One class cast is much simpler.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:417 OK.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:123 How much more work is it to make it configurable? Otherwise we would be storing the bytes-per-checksum field but not actually using it, which would be really confusing.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:149 Sounds good. Could you replace comments with javadocs? That seems to be the convention in HBase code even for private fields.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:441-442 OK, sounds good. I probably just misread the code.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:788 It is fine to leave duplicate code between DataInputStream and ByteBuffer implementations for performance reasons. However, I still think it is better to move these into a separate utility class, e.g. ByteBufferUtils.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:866-870 Sounds good.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1525 This is probably an error, not a warning, as we are about to shut down the regionserver.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1520-1527 This constructor will be called in the same thread that tries to read the block (see ThreadLocal.get() implementation). I am not sure if throwing a RuntimeException will shut down the regionserver. But this type of error definitely too serious to recover from gracefully, so this is probably fine.&lt;/p&gt;

&lt;p&gt;  Just to make sure: are we planning to swap checksum implementations in production? In that case, most RPC threads will still keep their associated PrefetchedHeader instance with the wrong checksum class.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1871 Sounds good. In that case it is probably better to add a method call to an external utility method here, instead of putting checksum calculation inline.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13198473" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 02:15:54 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: thanks for the update! See my replies inline.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:357 I don&apos;t see any overrides of this method in HFileReaderV&lt;/p&gt;
{1,2}
&lt;p&gt; in the patch, and this particular method looks really confusing, since it takes a parameter, ignores it, and returns this.hfs instead. Did you mean to override it in a way that does use the parameter? In that case, could you please add a javadoc here explaining why the argument is being ignored?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:402 Agreed. Perhaps we should avoid replacing all occurrences of FileSystem with HFileSystem. One class cast is much simpler.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:417 OK.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:123 How much more work is it to make it configurable? Otherwise we would be storing the bytes-per-checksum field but not actually using it, which would be really confusing.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:149 Sounds good. Could you replace comments with javadocs? That seems to be the convention in HBase code even for private fields.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:441-442 OK, sounds good. I probably just misread the code.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:788 It is fine to leave duplicate code between DataInputStream and ByteBuffer implementations for performance reasons. However, I still think it is better to move these into a separate utility class, e.g. ByteBufferUtils.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:866-870 Sounds good.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1525 This is probably an error, not a warning, as we are about to shut down the regionserver.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1520-1527 This constructor will be called in the same thread that tries to read the block (see ThreadLocal.get() implementation). I am not sure if throwing a RuntimeException will shut down the regionserver. But this type of error definitely too serious to recover from gracefully, so this is probably fine.&lt;/p&gt;

&lt;p&gt;  Just to make sure: are we planning to swap checksum implementations in production? In that case, most RPC threads will still keep their associated PrefetchedHeader instance with the wrong checksum class.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1871 Sounds good. In that case it is probably better to add a method call to an external utility method here, instead of putting checksum calculation inline.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13199072" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 18:42:52 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java:206-207 will fix&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java:1072 sure&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:598 I will make this part of the code cleaner. I still am hoping to keep only one knob: whether to verify hbase checksums or not. If hbase checksums is switched on, then hdfs checksums will automatically be switched off. If hbase checksums is configured &apos;off&apos;, then it will automatically switch on hdfs checksums. I feel that the other knobs (e.g. no checksums at all or use both checksums) are not very interesting in &lt;b&gt;any&lt;/b&gt; production environment and I would like to keep the code complexity a little lower by avoiding those two combinations. Hope that is ok with you.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3597 Good idea, will do&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java:31 It tried this, but it needs a few changes, so I anyway landed up with needing my own object wrapper over DataOutputBuffer.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:39 I too feel that we should add the checksum type to the hfileblock header. That will make us future proof to try new checksum algorithms in the future. Will make this change.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:132-133 This is equivalent to the existing FileSystem.get() and many places in hbase uses this.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:80 I will make this public so that users can create a HFileSystem object on a non-default path&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:102 I am making changes here based on mikhial&apos;s suggestion too.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:229 as you would see, the existing code path that create a HFileBlock usin g this constructor uses it for only in-memory caching, so it never fills up or uses the onDiskDataSizeWithHeader field. But I will set it to what you propose.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:252 ondisksizewithheader = ondiskdatasizewithheader + checksum bytes&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:751 I am in complete agreement with you. I wish I could have used the hadoop trunk code here. Unfortunately, hbase pulls in hadoop 1.0 which does not have this implementation. Another option is to make a copy of this code from hadoop into hbase code, but this has its own set of problems for maintainability. I am hoping that hbase will move to hadoop 2.0 very soon and then we can start the more optimal checksum implementation. Hope that is ok with you.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1401-1402 This needs to be thread safe.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1634 This is an internal method and this error is handled by upper layers (by switching off hbase checksums). So, I am following the paradigm of using Exceptions only when true errors happen; I would like to avoid writing code that generates exceptions  in one layer catches them in another layer and handles them. The discussion with Doug Cutting on the hdfs-symlink patch is etched in my mind&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1888 I will work (in a later patch) to use bulk checksum verifications, using native code, etc (from hadoop) in a later patch. I would like to keep this patch smaller that what it already is by focussing on the disk format change, compatibility with older versions, etc. The main reason is that most of the hadoop checksum optimizations are only in hadoop 2.0. I am hoping that it is ok with you.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13199073" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 18:42:53 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java:206-207 will fix&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java:1072 sure&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:598 I will make this part of the code cleaner. I still am hoping to keep only one knob: whether to verify hbase checksums or not. If hbase checksums is switched on, then hdfs checksums will automatically be switched off. If hbase checksums is configured &apos;off&apos;, then it will automatically switch on hdfs checksums. I feel that the other knobs (e.g. no checksums at all or use both checksums) are not very interesting in &lt;b&gt;any&lt;/b&gt; production environment and I would like to keep the code complexity a little lower by avoiding those two combinations. Hope that is ok with you.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3597 Good idea, will do&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java:31 It tried this, but it needs a few changes, so I anyway landed up with needing my own object wrapper over DataOutputBuffer.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:39 I too feel that we should add the checksum type to the hfileblock header. That will make us future proof to try new checksum algorithms in the future. Will make this change.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:132-133 This is equivalent to the existing FileSystem.get() and many places in hbase uses this.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:80 I will make this public so that users can create a HFileSystem object on a non-default path&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:102 I am making changes here based on mikhial&apos;s suggestion too.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:229 as you would see, the existing code path that create a HFileBlock usin g this constructor uses it for only in-memory caching, so it never fills up or uses the onDiskDataSizeWithHeader field. But I will set it to what you propose.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:252 ondisksizewithheader = ondiskdatasizewithheader + checksum bytes&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:751 I am in complete agreement with you. I wish I could have used the hadoop trunk code here. Unfortunately, hbase pulls in hadoop 1.0 which does not have this implementation. Another option is to make a copy of this code from hadoop into hbase code, but this has its own set of problems for maintainability. I am hoping that hbase will move to hadoop 2.0 very soon and then we can start the more optimal checksum implementation. Hope that is ok with you.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1401-1402 This needs to be thread safe.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1634 This is an internal method and this error is handled by upper layers (by switching off hbase checksums). So, I am following the paradigm of using Exceptions only when true errors happen; I would like to avoid writing code that generates exceptions  in one layer catches them in another layer and handles them. The discussion with Doug Cutting on the hdfs-symlink patch is etched in my mind&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1888 I will work (in a later patch) to use bulk checksum verifications, using native code, etc (from hadoop) in a later patch. I would like to keep this patch smaller that what it already is by focussing on the disk format change, compatibility with older versions, etc. The main reason is that most of the hadoop checksum optimizations are only in hadoop 2.0. I am hoping that it is ok with you.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13199082" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 18:46:54 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Addressed first-level comments from Todd and Mikhail.&lt;br/&gt;
  All awesome feedback, thanks a lot folks!&lt;/p&gt;

&lt;p&gt;  There are three main things that are not in this patch yet:&lt;br/&gt;
  make bytesPerChecksum configurable, add &apos;checksum type&apos; to the header,&lt;br/&gt;
  and work on making AbstractFSReader.getStream()&lt;br/&gt;
  thread safe. I will post these three fixes in a day or so.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13199083" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 18:46:56 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Addressed first-level comments from Todd and Mikhail.&lt;br/&gt;
  All awesome feedback, thanks a lot folks!&lt;/p&gt;

&lt;p&gt;  There are three main things that are not in this patch yet:&lt;br/&gt;
  make bytesPerChecksum configurable, add &apos;checksum type&apos; to the header,&lt;br/&gt;
  and work on making AbstractFSReader.getStream()&lt;br/&gt;
  thread safe. I will post these three fixes in a day or so.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13201164" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 09:17:57 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Many new goodies, thanks to the feedback from Mikhail and Todd. This completes&lt;br/&gt;
  my addressing all the current set of review comments. If somebody can re-review it&lt;br/&gt;
  again, that will be great.&lt;/p&gt;

&lt;p&gt;  1. The bytesPerChecksum is configurable. One can set hbase.hstore.bytes.per.checksum&lt;br/&gt;
  in the config to set this. The default value is 16K. Similarly, one can set&lt;br/&gt;
  hbase.hstore.checksum.name to either CRC32 or CRC32C. The default is CRC32. If&lt;br/&gt;
  PureJavaCRC32 algoritm is available in the classpath, then it is used, otherwise it falls back to using java.util.zip.CRC32. Each checksum value is assumed to be 4 bytes,&lt;br/&gt;
  it is currently not configurable (any comments here?). The reflection-method of&lt;br/&gt;
  creating checksum objects is reworked to incur much lower overhead.&lt;/p&gt;

&lt;p&gt;  2. If a hbase-level crc check fails, then it falls back to using hdfs-level&lt;br/&gt;
  checksums for the next few reads (defalts to 100). After that, it will retry&lt;br/&gt;
  using hbase-level checksums. I picked 100 as the default so that even in the case&lt;br/&gt;
  of continuous hbase-checksum failures, the overhead for additionals iops is limited&lt;br/&gt;
  to 1%. Enahnced unit test to validate this behaviour.&lt;/p&gt;

&lt;p&gt;  3. Enhanced unit tests to test different sizes of bytesPerChecksum. Also, added&lt;br/&gt;
  JMX metrics to record the number of times hbase-checksum verification failures occur.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13201165" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 09:17:58 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Many new goodies, thanks to the feedback from Mikhail and Todd. This completes&lt;br/&gt;
  my addressing all the current set of review comments. If somebody can re-review it&lt;br/&gt;
  again, that will be great.&lt;/p&gt;

&lt;p&gt;  1. The bytesPerChecksum is configurable. One can set hbase.hstore.bytes.per.checksum&lt;br/&gt;
  in the config to set this. The default value is 16K. Similarly, one can set&lt;br/&gt;
  hbase.hstore.checksum.name to either CRC32 or CRC32C. The default is CRC32. If&lt;br/&gt;
  PureJavaCRC32 algoritm is available in the classpath, then it is used, otherwise it falls back to using java.util.zip.CRC32. Each checksum value is assumed to be 4 bytes,&lt;br/&gt;
  it is currently not configurable (any comments here?). The reflection-method of&lt;br/&gt;
  creating checksum objects is reworked to incur much lower overhead.&lt;/p&gt;

&lt;p&gt;  2. If a hbase-level crc check fails, then it falls back to using hdfs-level&lt;br/&gt;
  checksums for the next few reads (defalts to 100). After that, it will retry&lt;br/&gt;
  using hbase-level checksums. I picked 100 as the default so that even in the case&lt;br/&gt;
  of continuous hbase-checksum failures, the overhead for additionals iops is limited&lt;br/&gt;
  to 1%. Enahnced unit test to validate this behaviour.&lt;/p&gt;

&lt;p&gt;  3. Enhanced unit tests to test different sizes of bytesPerChecksum. Also, added&lt;br/&gt;
  JMX metrics to record the number of times hbase-checksum verification failures occur.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13201200" author="hadoopqa" created="Mon, 6 Feb 2012 10:29:11 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12513416/D1521.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12513416/D1521.3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 76 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -133 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 161 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTool&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestInstantSchemaChangeSplit&lt;br/&gt;
                  org.apache.hadoop.hbase.io.hfile.TestHFileBlock&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/907//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/907//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/907//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/907//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/907//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/907//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13201401" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 17:07:58 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:425 This cast is not safe. See &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/907//testReport/org.apache.hadoop.hbase.mapreduce/TestLoadIncrementalHFiles/testSimpleLoad/:&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/907//testReport/org.apache.hadoop.hbase.mapreduce/TestLoadIncrementalHFiles/testSimpleLoad/:&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Caused by: java.lang.ClassCastException: org.apache.hadoop.hdfs.DistributedFileSystem cannot be cast to org.apache.hadoop.hbase.util.HFileSystem&lt;br/&gt;
  	at org.apache.hadoop.hbase.io.hfile.HFile.createReaderWithEncoding(HFile.java:425)&lt;br/&gt;
  	at org.apache.hadoop.hbase.io.hfile.HFile.createReader(HFile.java:433)&lt;br/&gt;
  	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.groupOrSplit(LoadIncrementalHFiles.java:407)&lt;br/&gt;
  	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:328)&lt;br/&gt;
  	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:326)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 Should we default to CRC32C ?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:2 No year is needed.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:59 Shall we name this variable ctor ?&lt;/p&gt;

&lt;p&gt;  Similar comment applies to other meth variables in this patch.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201527" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 20:05:57 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  I haven&apos;t thought about it quite enough, but is there any way to do this without leaking the HFileSystem out to the rest of the code? As Ted pointed out, there are some somewhat public interfaces that will probably get touched by that, and the number of places it has required changes in unrelated test cases seems like a &quot;code smell&quot; to me.&lt;/p&gt;

&lt;p&gt;  Maybe this could be a static cache somewhere, that given a FileSystem instance, it maintains the un-checksumed equivalents thereof as weak references? Then the concept would be self-contained within the HFile code, which up til now has been a fairly standalone file format.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201529" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 20:05:59 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  I haven&apos;t thought about it quite enough, but is there any way to do this without leaking the HFileSystem out to the rest of the code? As Ted pointed out, there are some somewhat public interfaces that will probably get touched by that, and the number of places it has required changes in unrelated test cases seems like a &quot;code smell&quot; to me.&lt;/p&gt;

&lt;p&gt;  Maybe this could be a static cache somewhere, that given a FileSystem instance, it maintains the un-checksumed equivalents thereof as weak references? Then the concept would be self-contained within the HFile code, which up til now has been a fairly standalone file format.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201569" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 20:48:58 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba; thanks for the fixes! Here are some more comments (I still have to go through the last 25% of the new version of the patch).&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:119 Please address this comment. The javadoc says &quot;major&quot; and the variable name says &quot;minor&quot;.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:49 Please correct the misspelling.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:352 I think this function needs to be renamed to expectAtLeastMajorVersion for clarity&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:287 I think we should either consistently use the onDiskSizeWithHeader field or get rid of it.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java:220 Please do use a constant instead of &quot;0&quot; here for the minor version.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3551 Long line&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:60 This lazy initialization is not thread-safe. This also applies to other enum members below. Can the meth field be initialized on the enum constructor, or do we rely on some classes being loaded by the time this initialization is invoked?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:63-67 Avoid repeating &quot;org.apache.hadoop.util.PureJavaCrc32&quot; three times in string form&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:74-75 Avoid repeating the &quot;java.util.zip.CRC32&quot; string&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:98-99 Avoid repeating the string&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:132 Fix indentation&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:174 Fix indentation&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:71 Inconsistent formatting: &quot;1024   +980&quot;.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201570" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 20:48:59 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba; thanks for the fixes! Here are some more comments (I still have to go through the last 25% of the new version of the patch).&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:119 Please address this comment. The javadoc says &quot;major&quot; and the variable name says &quot;minor&quot;.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:49 Please correct the misspelling.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:352 I think this function needs to be renamed to expectAtLeastMajorVersion for clarity&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:287 I think we should either consistently use the onDiskSizeWithHeader field or get rid of it.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java:220 Please do use a constant instead of &quot;0&quot; here for the minor version.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3551 Long line&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:60 This lazy initialization is not thread-safe. This also applies to other enum members below. Can the meth field be initialized on the enum constructor, or do we rely on some classes being loaded by the time this initialization is invoked?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:63-67 Avoid repeating &quot;org.apache.hadoop.util.PureJavaCrc32&quot; three times in string form&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:74-75 Avoid repeating the &quot;java.util.zip.CRC32&quot; string&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:98-99 Avoid repeating the string&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:132 Fix indentation&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:174 Fix indentation&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:71 Inconsistent formatting: &quot;1024   +980&quot;.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201614" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 21:26:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Todd: I agree with you. It is messy that the HFileSystem interface is leaking out to the unit tests. Instead, inside HFile, I can do something like this when a Reader is created:&lt;/p&gt;

&lt;p&gt;  if (!fs instanceof HFileSystem) &lt;/p&gt;
{
    fs = new HFileSystem(fs);
  }

&lt;p&gt;  what this means is that users of HFile that already passes in a HFileSystem will get the new behaviour while. HReginServer anyways voluntarily creates HFileSystem before invoking HFile, so it work.&lt;/p&gt;

&lt;p&gt;  I did not do this earlier because I thought that &apos;using reflection&apos; is costly, but on second thoughts the cost is not much because it will be done only once when a new reader is created for the first time. what do you think?&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201615" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 21:26:59 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Todd: I agree with you. It is messy that the HFileSystem interface is leaking out to the unit tests. Instead, inside HFile, I can do something like this when a Reader is created:&lt;/p&gt;

&lt;p&gt;  if (!fs instanceof HFileSystem) &lt;/p&gt;
{
    fs = new HFileSystem(fs);
  }

&lt;p&gt;  what this means is that users of HFile that already passes in a HFileSystem will get the new behaviour while. HReginServer anyways voluntarily creates HFileSystem before invoking HFile, so it work.&lt;/p&gt;

&lt;p&gt;  I did not do this earlier because I thought that &apos;using reflection&apos; is costly, but on second thoughts the cost is not much because it will be done only once when a new reader is created for the first time. what do you think?&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201618" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 21:32:58 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Yea, I think the instanceof check and confining HFileSystem to be only within the hfile package is much better.&lt;/p&gt;

&lt;p&gt;  I don&apos;t think it should be costly &amp;#8211; as you said, it&apos;s only when the reader is created, which isn&apos;t on the hot code path, and instanceof checks are actually quite fast. They turn into a simple compare of the instance&apos;s klassid header against a constant, if I remember correctly.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201619" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 21:32:59 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Yea, I think the instanceof check and confining HFileSystem to be only within the hfile package is much better.&lt;/p&gt;

&lt;p&gt;  I don&apos;t think it should be costly &amp;#8211; as you said, it&apos;s only when the reader is created, which isn&apos;t on the hot code path, and instanceof checks are actually quite fast. They turn into a simple compare of the instance&apos;s klassid header against a constant, if I remember correctly.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201678" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 22:14:57 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Some more comments. I am still concerned about the copy-paste stuff in backwards-compatibility checking. Is there a way to minimize that?&lt;/p&gt;

&lt;p&gt;  I also mentioned this in the comments below, but it would probably make sense to add more &quot;canned&quot; files in the no-checksum format generated by the old writer and read them with the new reader, the same way HFile v1 compatibility is ensured. I don&apos;t mind keeping the old writer code around in the unit test, but I think it is best to remove as much code from that legacy writer as possible (e.g. versatile API, toString, etc.) and only leave the parts necessary to generate the file for testing.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:164 Long line&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:83 Can this be made private if it is not accessed outside of this class?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:78 Use ALL_CAPS for constants&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:76 There seems to be a lot of copy-and-paste from the old HFileBlock code here. Is there a way to reduce that?&lt;/p&gt;

&lt;p&gt;  I think we also need to create some canned old-format HFiles (using the old code) and read them with the new reader code as part of the test.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:365 Make this class final.&lt;/p&gt;

&lt;p&gt;  Also, it would make sense to strip this class down as much as possible to maintain the bare minimum of code required to test compatibility (if you have not done that already).&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:800 Do we ever use this function?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java:188 Is 0 the minor version with no checksums? If so, please replace it with a constant for readability.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java:356 Is 0 the minor version with no checksums? If so, please replace it with a constant for readability.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java:300 Is 0 the minor version with no checksums? If so, please replace it with a constant for readability.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201679" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 22:14:58 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Some more comments. I am still concerned about the copy-paste stuff in backwards-compatibility checking. Is there a way to minimize that?&lt;/p&gt;

&lt;p&gt;  I also mentioned this in the comments below, but it would probably make sense to add more &quot;canned&quot; files in the no-checksum format generated by the old writer and read them with the new reader, the same way HFile v1 compatibility is ensured. I don&apos;t mind keeping the old writer code around in the unit test, but I think it is best to remove as much code from that legacy writer as possible (e.g. versatile API, toString, etc.) and only leave the parts necessary to generate the file for testing.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:164 Long line&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:83 Can this be made private if it is not accessed outside of this class?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:78 Use ALL_CAPS for constants&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:76 There seems to be a lot of copy-and-paste from the old HFileBlock code here. Is there a way to reduce that?&lt;/p&gt;

&lt;p&gt;  I think we also need to create some canned old-format HFiles (using the old code) and read them with the new reader code as part of the test.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:365 Make this class final.&lt;/p&gt;

&lt;p&gt;  Also, it would make sense to strip this class down as much as possible to maintain the bare minimum of code required to test compatibility (if you have not done that already).&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:800 Do we ever use this function?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java:188 Is 0 the minor version with no checksums? If so, please replace it with a constant for readability.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java:356 Is 0 the minor version with no checksums? If so, please replace it with a constant for readability.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java:300 Is 0 the minor version with no checksums? If so, please replace it with a constant for readability.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201983" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 01:58:59 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:287 can you pl elaborate more on this comment?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:76 I think it is better to keep the compatibility code separate from existing live-test code. That way, it is guaranteed to never change.&lt;/p&gt;

&lt;p&gt;  is there any other existing unit test that keeps a version1 file to run unit tests against?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:365 I did not strip it down, just so that it remains as it was earlier. This is for backward-compatibility, so isn&apos;t it better to keep as it was?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:800 Was useful while testing, but I will get rid of it.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201988" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 02:00:57 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:287 can you pl elaborate more on this comment?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:76 I think it is better to keep the compatibility code separate from existing live-test code. That way, it is guaranteed to never change.&lt;/p&gt;

&lt;p&gt;  is there any other existing unit test that keeps a version1 file to run unit tests against?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:365 I did not strip it down, just so that it remains as it was earlier. This is for backward-compatibility, so isn&apos;t it better to keep as it was?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:800 Was useful while testing, but I will get rid of it.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201990" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 02:02:57 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 But CRC32C is not installed by default.  You would need hadoop 2.0 (not yet released) to get that.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13201991" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 02:02:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 But CRC32C is not installed by default.  You would need hadoop 2.0 (not yet released) to get that.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202024" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 02:44:57 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 I don&apos;t see PureJavaCrc32 in hadoop 1.0 either.&lt;br/&gt;
  I think it would be nice to default to the best checksum class.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:257 Would hbase.hstore.checksum.algo be a better name for this config parameter ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202025" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 02:44:58 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 I don&apos;t see PureJavaCrc32 in hadoop 1.0 either.&lt;br/&gt;
  I think it would be nice to default to the best checksum class.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:257 Would hbase.hstore.checksum.algo be a better name for this config parameter ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202096" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 05:48:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 my choice would be to make java&apos;s crc32 be the default. PureJavacrc32 is compatible with java&apos;s crc32. However, purejavacrc32C is not compatible with either of these.&lt;/p&gt;

&lt;p&gt;  Although PureJavaCRC32 is not part of 1.0, if and when you move to hadoop 2.0, you will automatically get the better performant algorithm via Purejavacrc32.&lt;/p&gt;

&lt;p&gt;  For the adventurous, one can manually pull in PureJavaCRC32C inot one&apos;s own hbase deployment by explicitly setting hbase.hstore.checksum.algorithm to be &quot;CRC32C&quot;.&lt;/p&gt;

&lt;p&gt;  Does that sound reasonable?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:257 sounds good, will make this change.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202097" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 05:48:59 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:160 my choice would be to make java&apos;s crc32 be the default. PureJavacrc32 is compatible with java&apos;s crc32. However, purejavacrc32C is not compatible with either of these.&lt;/p&gt;

&lt;p&gt;  Although PureJavaCRC32 is not part of 1.0, if and when you move to hadoop 2.0, you will automatically get the better performant algorithm via Purejavacrc32.&lt;/p&gt;

&lt;p&gt;  For the adventurous, one can manually pull in PureJavaCRC32C inot one&apos;s own hbase deployment by explicitly setting hbase.hstore.checksum.algorithm to be &quot;CRC32C&quot;.&lt;/p&gt;

&lt;p&gt;  Does that sound reasonable?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:257 sounds good, will make this change.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202099" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 05:52:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Ted:I forgot to state that one can change the default checksum algorithm anytime. No disk format upgrade is necessary. Each hfile stores the checksum algorithm that is used to store data inside it. If today u use CRC32 and the tomorrow you change the configuration setting to CRC32C, then new files that are generated (as part of memstore flushes and compactions) will start using CRC32C while older files will continue to be verified via CRC32 algorithm.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202100" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 05:52:59 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Ted:I forgot to state that one can change the default checksum algorithm anytime. No disk format upgrade is necessary. Each hfile stores the checksum algorithm that is used to store data inside it. If today u use CRC32 and the tomorrow you change the configuration setting to CRC32C, then new files that are generated (as part of memstore flushes and compactions) will start using CRC32C while older files will continue to be verified via CRC32 algorithm.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202213" author="zhihyu@ebaysf.com" created="Tue, 7 Feb 2012 10:12:51 +0000"  >&lt;p&gt;@Dhruba:&lt;br/&gt;
Your explanation of CRC algorithm selection makes sense. &lt;/p&gt;</comment>
                            <comment id="13202488" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 15:56:57 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  PureJavaCrc32C is marked with @InterfaceStability.Stable and it only depends on java.util.zip.Checksum&lt;br/&gt;
  Does it make sense to port it from hadoop trunk ?&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202490" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 15:56:59 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  PureJavaCrc32C is marked with @InterfaceStability.Stable and it only depends on java.util.zip.Checksum&lt;br/&gt;
  Does it make sense to port it from hadoop trunk ?&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202734" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 20:20:58 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:287 It looks like onDiskDataSizeWithHeader does not include checksum but what this function returns does. Could you please mention that this includes checksum in the javadoc, and preferably also add a comment clarifying how this is different from onDiskDataSizeWithHeader? Otherwise it would be confusing, since the method and the field have very similar names.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java:763 Could you please use a constant instead of 0 for minor version?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202735" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 20:20:59 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:287 It looks like onDiskDataSizeWithHeader does not include checksum but what this function returns does. Could you please mention that this includes checksum in the javadoc, and preferably also add a comment clarifying how this is different from onDiskDataSizeWithHeader? Otherwise it would be confusing, since the method and the field have very similar names.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java:763 Could you please use a constant instead of 0 for minor version?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202954" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:32:57 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated most of Mikhail&apos;s, Ted&apos;s and Todd&apos;s feedback.&lt;/p&gt;

&lt;p&gt;  1. Removed leak of HFileObject from all places outside of hbase.io.hfile.&lt;br/&gt;
     Instead use instanceOf inside HFile.createReaderWithEncoding()&lt;br/&gt;
     to dynamically decide which filesystem to use.&lt;/p&gt;

&lt;p&gt;  2. constructor for ChecksumType is threadsafe&lt;/p&gt;

&lt;p&gt;  One un-answered question: I still kept the backward compatibility test&lt;br/&gt;
  with the original HFileBlock.Writer. If anybody can point me to an&lt;br/&gt;
  existing unit test that tests reading older files, I can do that instead.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13202955" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:33:00 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated most of Mikhail&apos;s, Ted&apos;s and Todd&apos;s feedback.&lt;/p&gt;

&lt;p&gt;  1. Removed leak of HFileObject from all places outside of hbase.io.hfile.&lt;br/&gt;
     Instead use instanceOf inside HFile.createReaderWithEncoding()&lt;br/&gt;
     to dynamically decide which filesystem to use.&lt;/p&gt;

&lt;p&gt;  2. constructor for ChecksumType is threadsafe&lt;/p&gt;

&lt;p&gt;  One un-answered question: I still kept the backward compatibility test&lt;br/&gt;
  with the original HFileBlock.Writer. If anybody can point me to an&lt;br/&gt;
  existing unit test that tests reading older files, I can do that instead.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13202958" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:36:57 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: keeping the compatibility test is fine with me. We can add a test that reads a &quot;canned&quot; HFile in the old format later.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202959" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:36:59 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: keeping the compatibility test is fine with me. We can add a test that reads a &quot;canned&quot; HFile in the old format later.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202988" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:56:57 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:64 Constants are normally spelled in upper cases.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:66 Should this be lifted to line 38 ?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:73 e should be included in message.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:111 We should share the LOG with CRC32.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:2 Year is not needed.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java:2 Year is not needed.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:2 Year is not needed.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13202989" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:56:58 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:64 Constants are normally spelled in upper cases.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:66 Should this be lifted to line 38 ?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:73 e should be included in message.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:111 We should share the LOG with CRC32.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:2 Year is not needed.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java:2 Year is not needed.&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java:2 Year is not needed.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13203015" author="hadoopqa" created="Wed, 8 Feb 2012 00:20:47 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12513715/D1521.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12513715/D1521.4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -133 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 160 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.hfile.TestHFileBlock&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestClassLoading&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/917//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/917//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/917//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/917//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/917//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/917//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13203040" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 00:42:58 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:72 There is no such parameter now.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:55 Would newConstructor be better name ?&lt;br/&gt;
  This method doesn&apos;t really create a new instance.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:36 Should read &apos;An encapsulation&apos;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:61 Using this.fs would be cleaner.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:122 Can we make the method name and field name consistent in terms of plurality ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13203041" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 00:42:59 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:72 There is no such parameter now.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java:55 Would newConstructor be better name ?&lt;br/&gt;
  This method doesn&apos;t really create a new instance.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:36 Should read &apos;An encapsulation&apos;&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:61 Using this.fs would be cleaner.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:122 Can we make the method name and field name consistent in terms of plurality ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13203368" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 08:30:00 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated review comments from Ted.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13203369" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 08:30:01 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated review comments from Ted.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumByteArrayOutputStream.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13203372" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 08:33:57 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Todd: can you pl re-review this one more time (at least to ensure that your earlier concerns are addressed).&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13203373" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 08:33:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Todd: can you pl re-review this one more time (at least to ensure that your earlier concerns are addressed).&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13203399" author="hadoopqa" created="Wed, 8 Feb 2012 09:09:42 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12513780/D1521.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12513780/D1521.5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 58 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -132 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 160 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.hfile.TestHFileBlock&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/923//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/923//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/923//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/923//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/923//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/923//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13204106" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 23:26:57 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:598 typo: verification&lt;/p&gt;

&lt;p&gt;  and still not sure what true/false means here... would be better to clarify either here or in src/main/resources/hbase-default.xml if you anticipate users ever changing this.&lt;/p&gt;

&lt;p&gt;  If I set it to false does that mean I get no checksumming? or hdfs checksumming as before? please update the comment&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:41-43 I think this API would be cleaner with the following changes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;rather than use the constant HFileBlock.HEADER_SIZE below, make the API:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  appendChecksums(ChecksumByteArrayOutputStream baos,&lt;br/&gt;
    int dataOffset, int dataLen,&lt;br/&gt;
    ChecksumType checksumType,&lt;br/&gt;
    int bytesPerChecksum) {&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  where it would checksum the data between dataOffset and dataOffset + dataLen, and append it to the baos&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:73 same here, I think it&apos;s better to take the offset as a parameter instead of assume HFileBlock.HEADER_SIZE&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 if this is performance critical, use DataOutputBuffer, presized to right size, and then return its underlying buffer directly to avoid a copy and realloc&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:123 seems strange that this is inconsistent with the above &amp;#8211; if the block desn&apos;t have a checksum, why is that differently handled than if the block is from a prior version which doesn&apos;t have a checksum?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:100 typo re-enable&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:79-80 should clarify which part of the data is checksummed.&lt;br/&gt;
  As I read the code, only the non-header data (ie the &quot;user data&quot;) is checksummed. Is this correct?&lt;br/&gt;
  It seems to me like this is potentially dangerous &amp;#8211; eg a flipped bit in an hfile block header might cause the &quot;compressedDataSize&quot; field to be read as 2GB or something, in which case the faulty allocation could cause the server to OOME. I think we need a checksum on the hfile block header as well.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:824 rename to doCompressionAndChecksumming, and update javadoc&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:815 I was a bit confused by this at first - I think it would be nice to add a comment here saying:&lt;br/&gt;
  // set the header for the uncompressed bytes (for cache-on-write)&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:852 this weird difference between compressed and uncompressed case could be improved, I think:&lt;br/&gt;
  Why not make the uncompressedBytesWithHeader leave free space for the checksums at the end of the array, and have it generate the checksums into that space?&lt;br/&gt;
  Or change generateChecksums to take another array as an argument, rather than having it append to the same &apos;baos&apos;?&lt;/p&gt;

&lt;p&gt;  It&apos;s currently quite confusing that &quot;onDiskChecksum&quot; ends up empty in the compressed case, even though we &lt;em&gt;did&lt;/em&gt; write a checksum lumped in with the onDiskBytesWithHeader.&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1375-1379 Similar to above comment about the block headers, I think we need to do our own checksumming on the hfile metadata itself &amp;#8211; what about a corruption in the file header? Alternatively we could always use the checksummed stream when loading the file-wide header which is probably much simpler&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1545 confused by this - if we dn&apos;t have an HFileSystem, then wouldn&apos;t we assume that the checksumming is done by the underlying dfs, and not use hbase checksums?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1580 s/it never changes/because it is marked final/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1588-1590 this isn&apos;t thread-safe: multiple threads might decrement and skip -1, causing it to never get re-enabled.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1599 add comment here // checksum verification failed&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1620-1623 msg should include file path&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:53 typo: delegate&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3620 Given we have rsServices.getFileSystem, why do we need to also pass this in?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13204107" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 23:27:00 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:598 typo: verification&lt;/p&gt;

&lt;p&gt;  and still not sure what true/false means here... would be better to clarify either here or in src/main/resources/hbase-default.xml if you anticipate users ever changing this.&lt;/p&gt;

&lt;p&gt;  If I set it to false does that mean I get no checksumming? or hdfs checksumming as before? please update the comment&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:41-43 I think this API would be cleaner with the following changes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;rather than use the constant HFileBlock.HEADER_SIZE below, make the API:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;  appendChecksums(ChecksumByteArrayOutputStream baos,&lt;br/&gt;
    int dataOffset, int dataLen,&lt;br/&gt;
    ChecksumType checksumType,&lt;br/&gt;
    int bytesPerChecksum) {&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  where it would checksum the data between dataOffset and dataOffset + dataLen, and append it to the baos&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:73 same here, I think it&apos;s better to take the offset as a parameter instead of assume HFileBlock.HEADER_SIZE&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 if this is performance critical, use DataOutputBuffer, presized to right size, and then return its underlying buffer directly to avoid a copy and realloc&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:123 seems strange that this is inconsistent with the above &amp;#8211; if the block desn&apos;t have a checksum, why is that differently handled than if the block is from a prior version which doesn&apos;t have a checksum?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:100 typo re-enable&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:79-80 should clarify which part of the data is checksummed.&lt;br/&gt;
  As I read the code, only the non-header data (ie the &quot;user data&quot;) is checksummed. Is this correct?&lt;br/&gt;
  It seems to me like this is potentially dangerous &amp;#8211; eg a flipped bit in an hfile block header might cause the &quot;compressedDataSize&quot; field to be read as 2GB or something, in which case the faulty allocation could cause the server to OOME. I think we need a checksum on the hfile block header as well.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:824 rename to doCompressionAndChecksumming, and update javadoc&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:815 I was a bit confused by this at first - I think it would be nice to add a comment here saying:&lt;br/&gt;
  // set the header for the uncompressed bytes (for cache-on-write)&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:852 this weird difference between compressed and uncompressed case could be improved, I think:&lt;br/&gt;
  Why not make the uncompressedBytesWithHeader leave free space for the checksums at the end of the array, and have it generate the checksums into that space?&lt;br/&gt;
  Or change generateChecksums to take another array as an argument, rather than having it append to the same &apos;baos&apos;?&lt;/p&gt;

&lt;p&gt;  It&apos;s currently quite confusing that &quot;onDiskChecksum&quot; ends up empty in the compressed case, even though we &lt;em&gt;did&lt;/em&gt; write a checksum lumped in with the onDiskBytesWithHeader.&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1375-1379 Similar to above comment about the block headers, I think we need to do our own checksumming on the hfile metadata itself &amp;#8211; what about a corruption in the file header? Alternatively we could always use the checksummed stream when loading the file-wide header which is probably much simpler&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1545 confused by this - if we dn&apos;t have an HFileSystem, then wouldn&apos;t we assume that the checksumming is done by the underlying dfs, and not use hbase checksums?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1580 s/it never changes/because it is marked final/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1588-1590 this isn&apos;t thread-safe: multiple threads might decrement and skip -1, causing it to never get re-enabled.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1599 add comment here // checksum verification failed&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1620-1623 msg should include file path&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:53 typo: delegate&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3620 Given we have rsServices.getFileSystem, why do we need to also pass this in?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13204134" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 23:59:58 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1588-1590 It would be nice to make this part of logic (re-enabling HBase checksumming) pluggable.&lt;br/&gt;
  Can be done in a follow-on JIRA.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1600 Assertion may be disabled in production.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13204135" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 23:59:59 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1588-1590 It would be nice to make this part of logic (re-enabling HBase checksumming) pluggable.&lt;br/&gt;
  Can be done in a follow-on JIRA.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1600 Assertion may be disabled in production.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13204335" author="phabricator@reviews.facebook.net" created="Thu, 9 Feb 2012 07:34:57 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Took a look at a little piece of the patch.  It looks great.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:601 It looks like this feature will be on by default.  Good.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 Should this class be in an fs package rather than in util?&lt;/p&gt;

&lt;p&gt;  Nit.  HFileSystem seems overly generic.  Should it be HBaseFileSystem?&lt;/p&gt;

&lt;p&gt;  Out of interest, is there a performance penalty that you know of going via FilterFileSystem?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:40 How would this happen?   We&apos;d look at the path for the object and do a different fs in here based off that?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:49 Won&apos;t the master use this fs too?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:50 configuration&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:74 cool&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:107 Who would want this?  Can we shut it down?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:112 Its not the &apos;default&apos; fs, it IS the fs?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:167 cool&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:172 So we&apos;ll have nonrecursive w/ this method?  I&apos;m not sure I follow.  This method will go away when filterfilesystem supports nonrecursive create?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13204336" author="phabricator@reviews.facebook.net" created="Thu, 9 Feb 2012 07:34:58 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Took a look at a little piece of the patch.  It looks great.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:601 It looks like this feature will be on by default.  Good.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 Should this class be in an fs package rather than in util?&lt;/p&gt;

&lt;p&gt;  Nit.  HFileSystem seems overly generic.  Should it be HBaseFileSystem?&lt;/p&gt;

&lt;p&gt;  Out of interest, is there a performance penalty that you know of going via FilterFileSystem?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:40 How would this happen?   We&apos;d look at the path for the object and do a different fs in here based off that?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:49 Won&apos;t the master use this fs too?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:50 configuration&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:74 cool&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:107 Who would want this?  Can we shut it down?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:112 Its not the &apos;default&apos; fs, it IS the fs?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:167 cool&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:172 So we&apos;ll have nonrecursive w/ this method?  I&apos;m not sure I follow.  This method will go away when filterfilesystem supports nonrecursive create?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13205317" author="phabricator@reviews.facebook.net" created="Fri, 10 Feb 2012 09:47:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1545 This is the initialization code in the constructor that assumes that we always verify hbase checksums. In the next line, it will be set to false if the minor version is an old one. Similarly, If there is a HFileSystem and the called has voluntarily cleared hfs.useHBaseChecksum, then we respect the caller&apos;s wishes&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 I do not know of nay performance penalty. For hbase code, this wrapper is traversed only once when an HFile is opened of an HLog is created. Since the number of times we open/create a file is miniscule compared to the number of reads/writes to those files, the overhead (if any) should not show up in any benchmark. I will validate this on my cluster and report if I see any.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 I do not yet see a package o.apache.hadoop.hbase.fs Do you want m to create it? There is a pre-exising class o.a.h.h.utils.FSUtils, that&apos;s why I created HFileSystem inside that package.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:40 We would create a method HFileSystem.getLogFs(). The implementation of this method can open a new filesystem object (for storing transaction logs) Then, HRegionServer will pass in HFileSystem.getLogFs() into the constructor of HLog().&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:49 Currently, the only place HFileSystem is created is inside HRegionServer&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:107 You would see that readfs is the filesystem object that will be used to avoid checksum verification inside of hdfs.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:172 The hadoop code base recently introduced the method FileSystem.createNonRecursive. But whoever added it to FileSystem forgot to add it to FilterFileSystem. Apache hadoop trunk should roll out a patch for this one soon.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13205318" author="phabricator@reviews.facebook.net" created="Fri, 10 Feb 2012 09:47:58 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1545 This is the initialization code in the constructor that assumes that we always verify hbase checksums. In the next line, it will be set to false if the minor version is an old one. Similarly, If there is a HFileSystem and the called has voluntarily cleared hfs.useHBaseChecksum, then we respect the caller&apos;s wishes&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 I do not know of nay performance penalty. For hbase code, this wrapper is traversed only once when an HFile is opened of an HLog is created. Since the number of times we open/create a file is miniscule compared to the number of reads/writes to those files, the overhead (if any) should not show up in any benchmark. I will validate this on my cluster and report if I see any.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 I do not yet see a package o.apache.hadoop.hbase.fs Do you want m to create it? There is a pre-exising class o.a.h.h.utils.FSUtils, that&apos;s why I created HFileSystem inside that package.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:40 We would create a method HFileSystem.getLogFs(). The implementation of this method can open a new filesystem object (for storing transaction logs) Then, HRegionServer will pass in HFileSystem.getLogFs() into the constructor of HLog().&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:49 Currently, the only place HFileSystem is created is inside HRegionServer&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:107 You would see that readfs is the filesystem object that will be used to avoid checksum verification inside of hdfs.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:172 The hadoop code base recently introduced the method FileSystem.createNonRecursive. But whoever added it to FileSystem forgot to add it to FilterFileSystem. Apache hadoop trunk should roll out a patch for this one soon.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13207421" author="phabricator@reviews.facebook.net" created="Tue, 14 Feb 2012 01:06:58 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 I&apos;d suggest yes creating an fs package.  Maybe FSUtils would move over but an fs package would seem to be a better location for a new FileSystem implementation than util.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:49 Interesting.  How does the master bootstrap the cluster then?  It writes into the fs the root and meta regions?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13207422" author="phabricator@reviews.facebook.net" created="Tue, 14 Feb 2012 01:06:59 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:1 I&apos;d suggest yes creating an fs package.  Maybe FSUtils would move over but an fs package would seem to be a better location for a new FileSystem implementation than util.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/HFileSystem.java:49 Interesting.  How does the master bootstrap the cluster then?  It writes into the fs the root and meta regions?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13209130" author="phabricator@reviews.facebook.net" created="Thu, 16 Feb 2012 05:56:58 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated review feedback from Todd, Stack and TedYu.&lt;/p&gt;

&lt;p&gt;  I made HFileBlock.readBlockData() thread-safe (still without using any&lt;br/&gt;
  locks because it is just a heuristic).I made the checksum encompass&lt;br/&gt;
  the values in the block header. HFileSystem is now in its own fs package.&lt;/p&gt;

&lt;p&gt;  If any of you can review it one more time, that will be much appreciated.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13209131" author="phabricator@reviews.facebook.net" created="Thu, 16 Feb 2012 05:56:59 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated review feedback from Todd, Stack and TedYu.&lt;/p&gt;

&lt;p&gt;  I made HFileBlock.readBlockData() thread-safe (still without using any&lt;br/&gt;
  locks because it is just a heuristic).I made the checksum encompass&lt;br/&gt;
  the values in the block header. HFileSystem is now in its own fs package.&lt;/p&gt;

&lt;p&gt;  If any of you can review it one more time, that will be much appreciated.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13209132" author="todd@lipcon.org" created="Thu, 16 Feb 2012 05:58:59 +0000"  >&lt;p&gt;Hey Dhruba,&lt;/p&gt;

&lt;p&gt;I didn&apos;t look at the new rev yet, but does it also do checksums on the&lt;br/&gt;
HFile header itself? ie the parts of the HFile that don&apos;t fall inside any&lt;br/&gt;
block? If not, we should continue to use the checksummed FS when we open&lt;br/&gt;
the hfile.&lt;/p&gt;

&lt;p&gt;-Todd&lt;/p&gt;

&lt;p&gt;On Wed, Feb 15, 2012 at 9:55 PM, dhruba (Dhruba Borthakur) &amp;lt;&lt;/p&gt;
</comment>
                            <comment id="13209153" author="hadoopqa" created="Thu, 16 Feb 2012 06:49:37 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12514759/D1521.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12514759/D1521.6.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -132 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 161 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/969//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/969//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/969//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/969//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/969//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/969//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13209181" author="dhruba" created="Thu, 16 Feb 2012 07:15:31 +0000"  >&lt;p&gt;Hi Todd, thanks for continuing to review this patch. Yes, the latest version that I uploaded uses hdfs checksum verifications while reading the Hfile trailer.&lt;/p&gt;</comment>
                            <comment id="13210716" author="phabricator@reviews.facebook.net" created="Sat, 18 Feb 2012 01:05:58 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  I got about 15% through.  Will do rest later.  This stuff is great.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:605 Nice doc.  Lets hoist up into the reference manual on commit.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:1 Good.  I think its better having it in here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 I see we use this writing the WAL. Reading we&apos;ll use whatever the readfs?   Do we need to expose this?  Or the getReadRS even?&lt;/p&gt;

&lt;p&gt;  Or is it that you want different fs&apos;s for read and write?  If so, should this method be called getWriteFS?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:129 Post creation, invoking this method would have no effect?  If so, remove, and make this data member final?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:44 Why change this comment?  Do we care how it does checksumming?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:49 Yeah, I wonder if upper tiers need worry about this stuff?  Whether its checksummed or not?  Should they just be talking about readfs vs writefs?  And then its up to the configuration as to what the underlying fs does (in this case its just turning off hdfs checksumming).  Looks like actual checksumming is over in HFileBlock... maybe HFile itself doesn&apos;t need to be concerned w/ checksumming?&lt;/p&gt;

&lt;p&gt;  No biggie.  Just a comment.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13210717" author="phabricator@reviews.facebook.net" created="Sat, 18 Feb 2012 01:05:59 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  I got about 15% through.  Will do rest later.  This stuff is great.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java:605 Nice doc.  Lets hoist up into the reference manual on commit.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:1 Good.  I think its better having it in here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 I see we use this writing the WAL. Reading we&apos;ll use whatever the readfs?   Do we need to expose this?  Or the getReadRS even?&lt;/p&gt;

&lt;p&gt;  Or is it that you want different fs&apos;s for read and write?  If so, should this method be called getWriteFS?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:129 Post creation, invoking this method would have no effect?  If so, remove, and make this data member final?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:44 Why change this comment?  Do we care how it does checksumming?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:49 Yeah, I wonder if upper tiers need worry about this stuff?  Whether its checksummed or not?  Should they just be talking about readfs vs writefs?  And then its up to the configuration as to what the underlying fs does (in this case its just turning off hdfs checksumming).  Looks like actual checksumming is over in HFileBlock... maybe HFile itself doesn&apos;t need to be concerned w/ checksumming?&lt;/p&gt;

&lt;p&gt;  No biggie.  Just a comment.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13211167" author="phabricator@reviews.facebook.net" created="Sun, 19 Feb 2012 00:35:57 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Got to the 20% stage.&lt;/p&gt;

&lt;p&gt;  Whats the status of this patch Dhruba?  Are you running it anywhere?&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:46 Great comments&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 The value returned is a long.  Why convert to an int?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:18 I think its good that this utility is in this pacage since it seems particular to this package.  At first I thought it general utility... there is some but mostly its about this feature it seems.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:205 Do you want to doc that a get resets count to zero?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:462 Yeah, its hard to contain the checksumming feature to just a few places; it leaks out all over io.hfile.  Thats fine.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13211168" author="phabricator@reviews.facebook.net" created="Sun, 19 Feb 2012 00:35:59 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Got to the 20% stage.&lt;/p&gt;

&lt;p&gt;  Whats the status of this patch Dhruba?  Are you running it anywhere?&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:46 Great comments&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 The value returned is a long.  Why convert to an int?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:18 I think its good that this utility is in this pacage since it seems particular to this package.  At first I thought it general utility... there is some but mostly its about this feature it seems.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:205 Do you want to doc that a get resets count to zero?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:462 Yeah, its hard to contain the checksumming feature to just a few places; it leaks out all over io.hfile.  Thats fine.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13213448" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 08:14:48 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 ideally, we need two different fs. The first fs is for writing and reading-with-hdfs-checksums. The other fs is for reading-without-hdfs.&lt;/p&gt;


&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:129 done&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:49 The HFile layer is the one that is responsible for opening a file for reading. Then the multi-threaded HFileBlockLayer uses those FSDataInputStream to pread data from HDFS. So, I need to make the HFile layer open two file descriptors for the same file, both for reading purposes... one which checksum and the other without checksums&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:44 This is a protected member, so users of this class are not concerned on what this is.  If you have a better structure on how to organize this one, please do let me know&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 The Checksum API returns a long. But actual implementations like CRC32, CRC32C, etc all return an int.&lt;/p&gt;

&lt;p&gt;  Also, the Hadoop checksum implementation also uses a 4 byte value. If you think that we should store 8 byte checksums, I can do that. But for the common case, we will be wasting 4 bytes in the header for every checksum chunk&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:205 done&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13213449" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 08:16:46 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated Stacks&apos;s review comments.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13213450" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 08:16:49 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Incorporated Stacks&apos;s review comments.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13213451" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 08:16:51 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 ideally, we need two different fs. The first fs is for writing and reading-with-hdfs-checksums. The other fs is for reading-without-hdfs.&lt;/p&gt;


&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:129 done&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:49 The HFile layer is the one that is responsible for opening a file for reading. Then the multi-threaded HFileBlockLayer uses those FSDataInputStream to pread data from HDFS. So, I need to make the HFile layer open two file descriptors for the same file, both for reading purposes... one which checksum and the other without checksums&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:44 This is a protected member, so users of this class are not concerned on what this is.  If you have a better structure on how to organize this one, please do let me know&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 The Checksum API returns a long. But actual implementations like CRC32, CRC32C, etc all return an int.&lt;/p&gt;

&lt;p&gt;  Also, the Hadoop checksum implementation also uses a 4 byte value. If you think that we should store 8 byte checksums, I can do that. But for the common case, we will be wasting 4 bytes in the header for every checksum chunk&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:205 done&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13213470" author="hadoopqa" created="Wed, 22 Feb 2012 09:04:18 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12515551/D1521.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12515551/D1521.7.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -132 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 155 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.util.TestFSUtils&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplication&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1006//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1006//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1006//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1006//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1006//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1006//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13213883" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 19:19:47 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Answering Dhruba.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 Seems like we could have better names for these methods, ones that give more of a clue as to what they are about.  getBackingFS, getNoChecksumFS?&lt;/p&gt;

&lt;p&gt;  Maybe you are keepign them generic like this because you will be back in this area again soon doing another beautiful speedup on top of this checksumming fix (When we going to do read-ahead?  Would that speed scanning?)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:44 ok. np.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:49 Ok.  So, two readers.  Our file count is going to go up?  We should release note this as side effect of enabling this feature (previous you may have been well below xceivers limit but now you could go over the top?)  I didn&apos;t notice this was going on.  Need to foreground it I&apos;d say.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 I figured.  Its fine as is.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13213884" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 19:19:49 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Answering Dhruba.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 Seems like we could have better names for these methods, ones that give more of a clue as to what they are about.  getBackingFS, getNoChecksumFS?&lt;/p&gt;

&lt;p&gt;  Maybe you are keepign them generic like this because you will be back in this area again soon doing another beautiful speedup on top of this checksumming fix (When we going to do read-ahead?  Would that speed scanning?)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:44 ok. np.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:49 Ok.  So, two readers.  Our file count is going to go up?  We should release note this as side effect of enabling this feature (previous you may have been well below xceivers limit but now you could go over the top?)  I didn&apos;t notice this was going on.  Need to foreground it I&apos;d say.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:84 I figured.  Its fine as is.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13213952" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 20:09:47 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Changed names of HFileSystem methods/varibales to better reflect&lt;br/&gt;
  reality.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13213953" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 20:09:49 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Changed names of HFileSystem methods/varibales to better reflect&lt;br/&gt;
  reality.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13213957" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 20:11:47 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  &amp;gt; Ok. So, two readers. Our file count is going to go up?&lt;/p&gt;

&lt;p&gt;  The file count should not go up. We still do the same number of ios to hdfs, so the number of concurrent IOs on a datanode should still be the same, so the number of xceivers on the datanode should not be adversely affected by this patch. Please let me know if I am missing something here.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13213959" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 20:11:49 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  &amp;gt; Ok. So, two readers. Our file count is going to go up?&lt;/p&gt;

&lt;p&gt;  The file count should not go up. We still do the same number of ios to hdfs, so the number of concurrent IOs on a datanode should still be the same, so the number of xceivers on the datanode should not be adversely affected by this patch. Please let me know if I am missing something here.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214002" author="hadoopqa" created="Wed, 22 Feb 2012 20:53:41 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12515642/D1521.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12515642/D1521.8.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1014//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1014//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13214073" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 22:45:46 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 Please ignore my previous comment on renaming these methods.  On reread, I think they are plenty clear enough as they are.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:120 Nit: Change this to be an @return javadoc so its clear we are returning current state of this flag?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:164 Does mean that this feature is on by default?  Should we read configuration to figure whether its on or not?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:73 Is this threadsafe?  This looks like a shared object?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214075" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 22:45:49 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:115 Please ignore my previous comment on renaming these methods.  On reread, I think they are plenty clear enough as they are.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:120 Nit: Change this to be an @return javadoc so its clear we are returning current state of this flag?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:164 Does mean that this feature is on by default?  Should we read configuration to figure whether its on or not?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:73 Is this threadsafe?  This looks like a shared object?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214106" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 23:39:47 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Dhruba, have you been running this patch anywhere?&lt;/p&gt;

&lt;p&gt;  I&apos;m +1 on commit if tests pass.  If its not been run anywhere, i can test it local before committing.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 Is it odd that we only take in the minor version here and not major too?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:861 Why WARN?  This is a &apos;normal&apos; operation?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1235 So, yeah, aren&apos;t we doubling the FDs when we do this?  The iops may be the same but the threads floating in the datanode for reading will double?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1244 I&apos;m not getting why no major version in here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1584 So, again we are defaulting true (though it seems that if no checksums in hfiles, we&apos;ll flip this flag to off pretty immediately)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1589 Smile.  Like now.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1630 Extreme nit: Should we close the nochecksumistream if its not going to be used?&lt;/p&gt;


&lt;p&gt;  Hmm... now I see we can flip back to using them again later in the stream&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:961 Now we have our own filesystem, we can dump a bunch of crud in there !  We can add things like the hbase.version check, etc. (joke &amp;#8211; sortof).&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java:86 I&apos;m reluctant adding stuff to this Interface but I think this method qualifies as important enough to be allowed in.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:70 Great&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214107" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 23:39:47 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Dhruba, have you been running this patch anywhere?&lt;/p&gt;

&lt;p&gt;  I&apos;m +1 on commit if tests pass.  If its not been run anywhere, i can test it local before committing.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 Is it odd that we only take in the minor version here and not major too?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:861 Why WARN?  This is a &apos;normal&apos; operation?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1235 So, yeah, aren&apos;t we doubling the FDs when we do this?  The iops may be the same but the threads floating in the datanode for reading will double?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1244 I&apos;m not getting why no major version in here.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1584 So, again we are defaulting true (though it seems that if no checksums in hfiles, we&apos;ll flip this flag to off pretty immediately)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1589 Smile.  Like now.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1630 Extreme nit: Should we close the nochecksumistream if its not going to be used?&lt;/p&gt;


&lt;p&gt;  Hmm... now I see we can flip back to using them again later in the stream&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:961 Now we have our own filesystem, we can dump a bunch of crud in there !  We can add things like the hbase.version check, etc. (joke &amp;#8211; sortof).&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java:86 I&apos;m reluctant adding stuff to this Interface but I think this method qualifies as important enough to be allowed in.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:70 Great&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214112" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 00:03:47 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1646 Since doVerify is an internal boolean variable, we should give it better name.&lt;br/&gt;
  How about &apos;doVerificationThruHBaseChecksum&apos; ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214113" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 00:03:48 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1646 Since doVerify is an internal boolean variable, we should give it better name.&lt;br/&gt;
  How about &apos;doVerificationThruHBaseChecksum&apos; ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13214402" author="dhruba" created="Thu, 23 Feb 2012 07:08:38 +0000"  >&lt;p&gt;@Stack: I am running it on a very small cluster, but will deploy it on a larger cluster next week. Please hold off committing this one till my larger-cluster-tests pass.&lt;/p&gt;

&lt;p&gt;I will also address Stack&apos;s and Ted&apos;s review comments in the next version of my patch&lt;/p&gt;</comment>
                            <comment id="13215083" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 21:39:46 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:73 Actually, a new checksum object is created by every invocation of ChecksumType.getChecksumObject(), so it should be thread-safe&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:120 doing it&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:164 will restructure the comment, this feature is  switched on by default.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215084" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 21:39:49 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:73 Actually, a new checksum object is created by every invocation of ChecksumType.getChecksumObject(), so it should be thread-safe&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:120 doing it&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:164 will restructure the comment, this feature is  switched on by default.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215108" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:11:46 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 This constructor is used only for V2, hence the major number is not a parameter.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1235 I think there won;t be any changes to the number of threads in the datanode. A datanode thread is not tied up with a client FileSystem object. Instead, a global pool of threads in the datanode are free to serve any read-requests from any client&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1244 The minor version indicates disk-format changes inside an HFileBlock. The major version indicates disk-format changes within a entire HFile. Since the AbstractFSReader only reads HFileBlocks, so it is logical that it contains the minorVersion, is it not?&lt;/p&gt;

&lt;p&gt;  But I can put in the majorVersion in it as well, if you so desire.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1584 Yes, the default it to enable hbase-checksum verification. And you are right that if the hfile is of the older type, then we will quickly flip this back to false (in the next line)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1630 I think we should keep both streams active till the HFile itself is closed.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1646 done&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:961 Yes, precisely. Going forward, I would like to see if we can make HLogs go to a filesystem object that is different from the filesystem used for hfiles.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java:86 I agree with you completely. This is an interface that should not change often.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215109" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:11:48 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 This constructor is used only for V2, hence the major number is not a parameter.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1235 I think there won;t be any changes to the number of threads in the datanode. A datanode thread is not tied up with a client FileSystem object. Instead, a global pool of threads in the datanode are free to serve any read-requests from any client&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1244 The minor version indicates disk-format changes inside an HFileBlock. The major version indicates disk-format changes within a entire HFile. Since the AbstractFSReader only reads HFileBlocks, so it is logical that it contains the minorVersion, is it not?&lt;/p&gt;

&lt;p&gt;  But I can put in the majorVersion in it as well, if you so desire.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1584 Yes, the default it to enable hbase-checksum verification. And you are right that if the hfile is of the older type, then we will quickly flip this back to false (in the next line)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1630 I think we should keep both streams active till the HFile itself is closed.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1646 done&lt;/p&gt;

&lt;p&gt;  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:961 Yes, precisely. Going forward, I would like to see if we can make HLogs go to a filesystem object that is different from the filesystem used for hfiles.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java:86 I agree with you completely. This is an interface that should not change often.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215111" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:13:47 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Pulled in review comments from Stack and Ted.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13215112" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:13:49 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Pulled in review comments from Stack and Ted.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13215114" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:15:46 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: going through the diff once again. Since you&apos;ve updated the revision, submitting existing comments against the previous version, and continuing with the new version.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:131 Misspelling: &quot;Minimun&quot; -&amp;gt; Minimum&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:44-45 Can these two be made final too?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:145 s/chuck/chunk/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:48 Fix javadoc: do do -&amp;gt; do&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:38 Make this final, rename to DUMMY_VALUE, because this is a constant, and make the length a factor of 16 to take advantage of alignment.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:532 s/manor/major/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:157 This comment is misleading. This is not something that defaults to the 16 K, but the default value itself. I think this should say something about how a non-default value is specified.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:265-271 The additional constructor should not be needed when &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5442&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-5442&lt;/a&gt; goes in.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:409 Is it possible to obtain the filesystem from the input stream rather than pass it as an additional parameter? Or is the underlying filesystem of the input stream a regular one, as opposed to an HFileSystem?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215115" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:15:47 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: going through the diff once again. Since you&apos;ve updated the revision, submitting existing comments against the previous version, and continuing with the new version.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:131 Misspelling: &quot;Minimun&quot; -&amp;gt; Minimum&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java:44-45 Can these two be made final too?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:145 s/chuck/chunk/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:48 Fix javadoc: do do -&amp;gt; do&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java:38 Make this final, rename to DUMMY_VALUE, because this is a constant, and make the length a factor of 16 to take advantage of alignment.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java:532 s/manor/major/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:157 This comment is misleading. This is not something that defaults to the 16 K, but the default value itself. I think this should say something about how a non-default value is specified.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:265-271 The additional constructor should not be needed when &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5442&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-5442&lt;/a&gt; goes in.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:409 Is it possible to obtain the filesystem from the input stream rather than pass it as an additional parameter? Or is the underlying filesystem of the input stream a regular one, as opposed to an HFileSystem?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215148" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:49:46 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 What will happen after HFileV3 is introduced ?&lt;br/&gt;
  I would expect HFileV3 starts with minorVersion of 0.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:961 HLog goes to fs on SSD ?&lt;br/&gt;
  Nice.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215149" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:49:49 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 What will happen after HFileV3 is introduced ?&lt;br/&gt;
  I would expect HFileV3 starts with minorVersion of 0.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:961 HLog goes to fs on SSD ?&lt;br/&gt;
  Nice.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215150" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:51:47 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Good w/ your comebacks Dhruba... just minor one below for your next rev.&lt;/p&gt;

&lt;p&gt;  Let us know how the cluster testing goes.  This patch applies fine.  Might try it out over here too..&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 I don&apos;t understand.  I think this means the fact that we have a minor version unaccompanied by a major needs docing here in a comment?  No hurry.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215151" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:51:48 +0000"  >&lt;p&gt;stack has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  Good w/ your comebacks Dhruba... just minor one below for your next rev.&lt;/p&gt;

&lt;p&gt;  Let us know how the cluster testing goes.  This patch applies fine.  Might try it out over here too..&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 I don&apos;t understand.  I think this means the fact that we have a minor version unaccompanied by a major needs docing here in a comment?  No hurry.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215152" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:51:49 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: some more comments inline.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:451-452 Assign headerSize() to a local variable instead of calling it twice.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:529-530 Call headerSize() once and store in a local variable.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1232 do do -&amp;gt; do&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1642-1644 Store and reuse part of the previous error message.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1636 Check if WARN level messages are enabled and only generate the message string in that case.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1848 double semicolon (does not matter)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java:424 What if istream != istreamNoFsChecksum but istreamNoFsChecksum == null?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3610-3612 Not sure how this is related to HBase-level checksum checking&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:265 Make this conf key a constant in HConstants&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:275 conf key -&amp;gt; HConstants&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:40-43 This is unnecessary because the default toString would do the same.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:57-60 This is unnecessary because the default toString would do the same.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:103-106 This is unnecessary because the default toString would do the same.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:143-144 It looks like toString would to this.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:179 Would not the built-in enum method valueOf do what this function is doing?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:1 This file still seems to contain a lot of copy-and-paste from TestHFileBlock. Are you planning to address that?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215153" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:51:50 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: some more comments inline.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:451-452 Assign headerSize() to a local variable instead of calling it twice.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:529-530 Call headerSize() once and store in a local variable.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1232 do do -&amp;gt; do&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1642-1644 Store and reuse part of the previous error message.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1636 Check if WARN level messages are enabled and only generate the message string in that case.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1848 double semicolon (does not matter)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java:424 What if istream != istreamNoFsChecksum but istreamNoFsChecksum == null?&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3610-3612 Not sure how this is related to HBase-level checksum checking&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:265 Make this conf key a constant in HConstants&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java:275 conf key -&amp;gt; HConstants&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:40-43 This is unnecessary because the default toString would do the same.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:57-60 This is unnecessary because the default toString would do the same.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:103-106 This is unnecessary because the default toString would do the same.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:143-144 It looks like toString would to this.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:179 Would not the built-in enum method valueOf do what this function is doing?&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:1 This file still seems to contain a lot of copy-and-paste from TestHFileBlock. Are you planning to address that?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13215184" author="hadoopqa" created="Thu, 23 Feb 2012 23:17:29 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12515829/D1521.9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12515829/D1521.9.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -132 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 157 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1032//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1032//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1032//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1032//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1032//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1032//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13217057" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 06:06:46 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:409 as far as I know, it is not possible to obtain a FileSystem object from a FSDataInputStream&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 Yes, if we bump the major version to V3, then we can restart minorVersions from 0.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217058" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 06:06:48 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java:409 as far as I know, it is not possible to obtain a FileSystem object from a FSDataInputStream&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:235 Yes, if we bump the major version to V3, then we can restart minorVersions from 0.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217091" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 07:50:52 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:451-452 I think it is better to not add another 4 bytes to the HFileBlock (increases heapSize), instead just compute it when needed, especially since this method is used only for debugging.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:529-530 shall we avoid increasing the HeapSize vs computing headerSize? It should be really cheap to compute headerSize(), especially since it is likely to be inlined.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1636 I think we should always print this. This follows the precedence in other parts of the HBase code. And this code path is the exception and not the norm&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1642-1644 I am pretty sure that it is better to construct this message only if there is a checksum mismatch.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3610-3612 The secret is to pass in a HFileSystem to HRegion.newHRegion(). This HFileSystem is extracted from the RegionServerServices, if it is not-null. Otherwise, a default file system object is created and passed into HRegion.newHRegion&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:57-60 getName() is better because it allows annotating the name differently from what Java does vi toString (especially if we add new crc algorithms in the future)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:143-144 I would like to keep getName() because it allows us to not change the API if  we decide to override java&apos;s toString convention, especially if we add new checksum algorithms in the future. (Similar to why there are two separate methods Enum.name and Enum.toString)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:179 That&apos;s right. But the existence of this API allows us to do own own names in the future. (Also, when there are only two or three values, this might be better than looking into a map)&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:1 I am not planning to change that, this code is what was there in HFileBlock, so it is good to carry it over in a unit test to be able to generate  files in the older format. This is used by unit tests alone.&lt;/p&gt;

&lt;p&gt;  JUst replacing it with a pre-created file(s) is not very cool, especially because the pre-created file(s) will test only that file whereas if we keep this code here, we can write more and more unit tests in the future that can generate  different files in the older format and test backward compatibility.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217092" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 07:55:33 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Addressed most of Stack/Ted/Mikails&apos; comments.&lt;/p&gt;

&lt;p&gt;  Mikhail: I did not change the interfaces of ChecksumType, just because I think&lt;br/&gt;
  what we got is more generic and flexible.&lt;/p&gt;

&lt;p&gt;  Stack: I have been running it successfully with load on a 5 node test cluster for&lt;br/&gt;
  more than 72 hours. Will it be possible for you to take it for a basic sanity test?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13217094" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 07:58:19 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:451-452 I think it is better to not add another 4 bytes to the HFileBlock (increases heapSize), instead just compute it when needed, especially since this method is used only for debugging.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:529-530 shall we avoid increasing the HeapSize vs computing headerSize? It should be really cheap to compute headerSize(), especially since it is likely to be inlined.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1636 I think we should always print this. This follows the precedence in other parts of the HBase code. And this code path is the exception and not the norm&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1642-1644 I am pretty sure that it is better to construct this message only if there is a checksum mismatch.&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java:3610-3612 The secret is to pass in a HFileSystem to HRegion.newHRegion(). This HFileSystem is extracted from the RegionServerServices, if it is not-null. Otherwise, a default file system object is created and passed into HRegion.newHRegion&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:57-60 getName() is better because it allows annotating the name differently from what Java does vi toString (especially if we add new crc algorithms in the future)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:143-144 I would like to keep getName() because it allows us to not change the API if  we decide to override java&apos;s toString convention, especially if we add new checksum algorithms in the future. (Similar to why there are two separate methods Enum.name and Enum.toString)&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java:179 That&apos;s right. But the existence of this API allows us to do own own names in the future. (Also, when there are only two or three values, this might be better than looking into a map)&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:1 I am not planning to change that, this code is what was there in HFileBlock, so it is good to carry it over in a unit test to be able to generate  files in the older format. This is used by unit tests alone.&lt;/p&gt;

&lt;p&gt;  JUst replacing it with a pre-created file(s) is not very cool, especially because the pre-created file(s) will test only that file whereas if we keep this code here, we can write more and more unit tests in the future that can generate  different files in the older format and test backward compatibility.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217095" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 07:58:30 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Addressed most of Stack/Ted/Mikails&apos; comments.&lt;/p&gt;

&lt;p&gt;  Mikhail: I did not change the interfaces of ChecksumType, just because I think&lt;br/&gt;
  what we got is more generic and flexible.&lt;/p&gt;

&lt;p&gt;  Stack: I have been running it successfully with load on a 5 node test cluster for&lt;br/&gt;
  more than 72 hours. Will it be possible for you to take it for a basic sanity test?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13217112" author="hadoopqa" created="Mon, 27 Feb 2012 08:46:03 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12516146/D1521.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12516146/D1521.10.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -127 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1052//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1052//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1052//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1052//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1052//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1052//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13217269" author="stack" created="Mon, 27 Feb 2012 16:44:34 +0000"  >&lt;p&gt;Reattach to rerun via hadoopqa&lt;/p&gt;</comment>
                            <comment id="13217319" author="hadoopqa" created="Mon, 27 Feb 2012 17:40:56 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12516181/D1521.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12516181/D1521.10.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -127 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplication&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1054//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1054//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1054//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1054//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1054//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1054//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13217330" author="stack" created="Mon, 27 Feb 2012 17:51:37 +0000"  >&lt;p&gt;try again though different test apart from the usual three failed this time&lt;/p&gt;</comment>
                            <comment id="13217378" author="hadoopqa" created="Mon, 27 Feb 2012 18:45:33 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12516189/D1521.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12516189/D1521.10.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -127 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1055//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1055//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1055//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1055//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1055//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1055//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13217593" author="hadoopqa" created="Mon, 27 Feb 2012 21:45:09 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12516208/D1521.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12516208/D1521.10.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -127 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1056//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1056//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1056//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1056//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1056//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1056//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13217598" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 21:49:46 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 Should we consider majorVersion ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217599" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 21:49:47 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 Should we consider majorVersion ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217603" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 21:53:47 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 In my opinion, we do not need a majorVersion in the in-memory HFileBlock object. Adding it will add to heap-space (albeit not much), but we can always add it later when needed... especially because it is only in-memory and not a disk-format change. Ted: do you agree?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217604" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 21:53:48 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 In my opinion, we do not need a majorVersion in the in-memory HFileBlock object. Adding it will add to heap-space (albeit not much), but we can always add it later when needed... especially because it is only in-memory and not a disk-format change. Ted: do you agree?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217614" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 21:59:47 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 Quoting Dhruba&apos;s reply:&lt;br/&gt;
  Yes, if we bump the major version to V3, then we can restart minorVersions from 0.&lt;/p&gt;

&lt;p&gt;  So how do we support major version 3, minor version 0 with checksum feature ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217615" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 21:59:48 +0000"  >&lt;p&gt;tedyu has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 Quoting Dhruba&apos;s reply:&lt;br/&gt;
  Yes, if we bump the major version to V3, then we can restart minorVersions from 0.&lt;/p&gt;

&lt;p&gt;  So how do we support major version 3, minor version 0 with checksum feature ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217618" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 22:01:46 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 maybe we can add a static final int majorVersion = 2; in this class, so the version checks are there, but it doesn&apos;t take up heap space? Then when/if we add a v3, we can make it non-final non-static without having to hunt down all the places where we might have major-version assumptions? The JIT will happily optimize out any if-statements against the constant.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217619" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 22:01:48 +0000"  >&lt;p&gt;todd has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:257 maybe we can add a static final int majorVersion = 2; in this class, so the version checks are there, but it doesn&apos;t take up heap space? Then when/if we add a v3, we can make it non-final non-static without having to hunt down all the places where we might have major-version assumptions? The JIT will happily optimize out any if-statements against the constant.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13217728" author="stack" created="Tue, 28 Feb 2012 00:27:04 +0000"  >&lt;p&gt;I see these in the logs when I run the patch; its a little odd because it says not using PureJavaCrc32 but will use CRC32 but then prints out stacktrace anyways:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2012-02-27 23:34:20,911 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: TestTable,0000150828,1330380684339.ebb37d5d0e2c1f4a8b111830a46e7cbc.
2012-02-27 23:34:20,914 INFO org.apache.hadoop.hbase.regionserver.Store: time to purge deletes set to 0ms in store &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2012-02-27 23:34:20,930 INFO org.apache.hadoop.hbase.util.ChecksumType: org.apache.hadoop.util.PureJavaCrc32 not available.
2012-02-27 23:34:20,930 INFO org.apache.hadoop.hbase.util.ChecksumType: Checksum using java.util.zip.CRC32
2012-02-27 23:34:20,931 WARN org.apache.hadoop.hbase.util.ChecksumType: org.apache.hadoop.util.PureJavaCrc32C not available.
java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.util.PureJavaCrc32C
        at org.apache.hadoop.hbase.util.ChecksumFactory.newConstructor(ChecksumFactory.java:65)
        at org.apache.hadoop.hbase.util.ChecksumType$3.initialize(ChecksumType.java:113)
        at org.apache.hadoop.hbase.util.ChecksumType.&amp;lt;init&amp;gt;(ChecksumType.java:148)
        at org.apache.hadoop.hbase.util.ChecksumType.&amp;lt;init&amp;gt;(ChecksumType.java:37)
        at org.apache.hadoop.hbase.util.ChecksumType$3.&amp;lt;init&amp;gt;(ChecksumType.java:100)
        at org.apache.hadoop.hbase.util.ChecksumType.&amp;lt;clinit&amp;gt;(ChecksumType.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile.&amp;lt;clinit&amp;gt;(HFile.java:163)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.&amp;lt;init&amp;gt;(StoreFile.java:1252)
        at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:516)
        at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:606)
        at org.apache.hadoop.hbase.regionserver.Store$1.call(Store.java:375)
        at org.apache.hadoop.hbase.regionserver.Store$1.call(Store.java:370)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:662)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.PureJavaCrc32C
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:306)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:247)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:247)
        at org.apache.hadoop.hbase.util.ChecksumFactory.getClassByName(ChecksumFactory.java:97)
        at org.apache.hadoop.hbase.util.ChecksumFactory.newConstructor(ChecksumFactory.java:60)
        ... 19 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m not sure on whats happening.  It would seem we&apos;re using default CRC32 but then I&apos;m not sure how I get the above exception reading code.&lt;/p&gt;

&lt;p&gt;Also, not sure if I have this facility turned on. Its on by default but I don&apos;t see anything in logs saying its on (and I don&apos;t have metrics on this cluster, nor do I have a good handle on before and after regards whether this feature makes a difference).&lt;/p&gt;

&lt;p&gt;I caught this in a heap dump:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;IPC Server handler 0 on 7003&quot;&lt;/span&gt; daemon prio=10 tid=0x00007f4a1410c800 nid=0x24b2 runnable [0x00007f4a20487000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
        at java.util.zip.CRC32.updateBytes(Native Method)
        at java.util.zip.CRC32.update(CRC32.java:45)
        at org.apache.hadoop.util.DataChecksum.update(DataChecksum.java:223)
        at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:240)
        at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
        at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
        - locked &amp;lt;0x00000006fc68e9d8&amp;gt; (a org.apache.hadoop.hdfs.BlockReaderLocal)
        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1457)
        - locked &amp;lt;0x00000006fc68e9d8&amp;gt; (a org.apache.hadoop.hdfs.BlockReaderLocal)
        at org.apache.hadoop.hdfs.BlockReaderLocal.read(BlockReaderLocal.java:326)
        - locked &amp;lt;0x00000006fc68e9d8&amp;gt; (a org.apache.hadoop.hdfs.BlockReaderLocal)
        at org.apache.hadoop.fs.FSInputChecker.readFully(FSInputChecker.java:384)
        at org.apache.hadoop.hdfs.DFSClient$BlockReader.readAll(DFSClient.java:1760)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchBlockByteRange(DFSClient.java:2330)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2397)
        at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:46)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.readAtOffset(HFileBlock.java:1333)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1769)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1633)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:328)
        at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.seekToDataBlock(HFileBlockIndex.java:213)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:462)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:482)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:226)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.enforceSeek(StoreFileScanner.java:351)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.pollRealKV(KeyValueHeap.java:333)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:291)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.requestSeek(KeyValueHeap.java:256)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:518)
        - locked &amp;lt;0x00000006fc67cd70&amp;gt; (a org.apache.hadoop.hbase.regionserver.StoreScanner)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:401)
        - locked &amp;lt;0x00000006fc67cd70&amp;gt; (a org.apache.hadoop.hbase.regionserver.StoreScanner)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:127)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3388)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3344)
        - locked &amp;lt;0x00000006fc67cc50&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3361)
        - locked &amp;lt;0x00000006fc67cc50&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4145)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4035)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1957)
        at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1344)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Maybe its not on?  Thanks Dhruba.&lt;/p&gt;</comment>
                            <comment id="13217749" author="zhihyu@ebaysf.com" created="Tue, 28 Feb 2012 00:43:30 +0000"  >&lt;p&gt;The exception about org.apache.hadoop.util.PureJavaCrc32C not found should be normal - it was WARN.&lt;br/&gt;
It was produced by ChecksumType ctor for this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  CRC32C((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)2) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Metrics should be collected on the cluster to see the difference.&lt;/p&gt;</comment>
                            <comment id="13217927" author="stack" created="Tue, 28 Feb 2012 05:50:04 +0000"  >&lt;p&gt;Hey Ted.  Comment was not for you, it was for the patch author.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The exception about org.apache.hadoop.util.PureJavaCrc32C not found should be normal - it was WARN.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The above makes no sense.  You have WARN and &apos;normal&apos; in the same sentence.&lt;/p&gt;

&lt;p&gt;If you look at the log, it says:&lt;/p&gt;

&lt;p&gt;1. 2012-02-27 23:34:20,930 INFO org.apache.hadoop.hbase.util.ChecksumType: org.apache.hadoop.util.PureJavaCrc32 not available.&lt;br/&gt;
2. 2012-02-27 23:34:20,930 INFO org.apache.hadoop.hbase.util.ChecksumType: Checksum using java.util.zip.CRC32&lt;br/&gt;
3. It spews a thread dump saying AGAIN that org.apache.hadoop.util.PureJavaCrc32C not available.&lt;/p&gt;

&lt;p&gt;That is going to confuse.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Metrics should be collected on the cluster to see the difference.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Go easy on telling folks what they should do.  It tends to piss them off.&lt;/p&gt;
</comment>
                            <comment id="13218003" author="zhihyu@ebaysf.com" created="Tue, 28 Feb 2012 08:38:12 +0000"  >&lt;p&gt;I wish I had been more prudent before making the previous comments.&lt;/p&gt;</comment>
                            <comment id="13218423" author="dhruba" created="Tue, 28 Feb 2012 18:18:09 +0000"  >&lt;p&gt;@Stack: I am pretty sure that the feature is on by default (but let me check and get back to you). Regarding the exception message about CRC32C, the Enum is trying to create this object but failing to do so because the Hadoop library in Hadoop 1.0 does not have support for this one (Hadop 2.0 supports CRC32C). The reason I kept that is because people who might already be experimenting with Hadoop 2.0 will get this support out-of-the-box. But I agree that it will be good to get rid of this exception message at startup. Do you have any suggestions on this one?&lt;/p&gt;

&lt;p&gt;@Todd: will take your excellent suggestion and make the majorVersion inside HFileBlock as a &quot;static&quot;. Thanks.&lt;/p&gt;

&lt;p&gt;@Ted: Thanks for your comments. Will try to gather metrics in my cluster and post to this JIRA.&lt;/p&gt;</comment>
                            <comment id="13218470" author="stack" created="Tue, 28 Feb 2012 18:56:27 +0000"  >&lt;p&gt;@Dhruba Its good trying for PureJavaCrc32 first.  Get rid of the WARN w/ thread dump I&apos;d say especially as is where it comes after reporting we&apos;re not going to use PureJavaCrc32.  The feature does seem to be on by default but it would be nice to know it w/o having to go to ganglia graphs to figure my i/o loading to see whether or not this feature is enabled &amp;#8211; going to ganglia would be useless anyways in case where I&apos;ve no history w/ an hbase read load &amp;#8211; so some kind of log output might be useful?  Good on you D.&lt;/p&gt;</comment>
                            <comment id="13218546" author="zhihyu@ebaysf.com" created="Tue, 28 Feb 2012 20:02:03 +0000"  >&lt;p&gt;I first mentioned porting PureJavaCrc32C to HBase here: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074?focusedCommentId=13202490&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13202490&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-5074?focusedCommentId=13202490&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13202490&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Is that something worth trying ?&lt;/p&gt;</comment>
                            <comment id="13220756" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 07:43:08 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  1. I modified the ChecksumType code to not dum an exception stack trace to the output if CRC32C is not&lt;br/&gt;
     available. Ted&apos;s suggestion of pulling CRC32C into hbase code sounds reasonable, but I would like&lt;br/&gt;
     to do it as part of another jira. Also, if hbase moves to hadoop 2.0, then it will automatically&lt;br/&gt;
     get CRC32C.&lt;br/&gt;
  2. I added a &quot;minorVersion=&quot; to the output of HFilePrettyPrinter.&lt;br/&gt;
     Stack, will you be able to run &quot;bin/hbase hfile -m -f filename on your cluster to verify that this&lt;br/&gt;
     checksum feature is switched on. If it prints minorVersion=1, then you are using this feature.&lt;br/&gt;
     Do you still need a print somewhere saying that this feature in on? The older files that were&lt;br/&gt;
     pre-created before that patch was deployed will still use hdfs-checksum verification, so you&lt;br/&gt;
     could possible see hdfs-checksum-verification on stack traces on a live regionserver.&lt;br/&gt;
  3. I did some thinking (again) on the semantics of major version and minor version. The major version&lt;br/&gt;
     represents a new file format, e.g. suppose we add a new thing to the file&apos;s triailer, then we&lt;br/&gt;
     might need to bump up the major version. The minor version indicates the format of data inside a&lt;br/&gt;
     HFileBlock.&lt;br/&gt;
     In the current code, major versions 1 and 2 share the same HFileFormat (indicated by minor version&lt;br/&gt;
     of 0). In this patch, we have a new minorVersion 1 because the data contents inside a HFileBlock&lt;br/&gt;
     has changed. Tecnically, both major version 1 and 2 could have either minorVerion 0 or 1.&lt;br/&gt;
     Now, suppose we want to add a new field to the trailer of the HFile. We can bump the majorVersion&lt;br/&gt;
     to 3 but do not change the minorVersion because we did not change the internal format of an&lt;br/&gt;
     HFileBlock.&lt;br/&gt;
     Given the above, does it make sense to say that HFileBlock is independent of the majorVersion?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13220757" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 07:43:15 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  1. I modified the ChecksumType code to not dum an exception stack trace to the output if CRC32C is not&lt;br/&gt;
     available. Ted&apos;s suggestion of pulling CRC32C into hbase code sounds reasonable, but I would like&lt;br/&gt;
     to do it as part of another jira. Also, if hbase moves to hadoop 2.0, then it will automatically&lt;br/&gt;
     get CRC32C.&lt;br/&gt;
  2. I added a &quot;minorVersion=&quot; to the output of HFilePrettyPrinter.&lt;br/&gt;
     Stack, will you be able to run &quot;bin/hbase hfile -m -f filename on your cluster to verify that this&lt;br/&gt;
     checksum feature is switched on. If it prints minorVersion=1, then you are using this feature.&lt;br/&gt;
     Do you still need a print somewhere saying that this feature in on? The older files that were&lt;br/&gt;
     pre-created before that patch was deployed will still use hdfs-checksum verification, so you&lt;br/&gt;
     could possible see hdfs-checksum-verification on stack traces on a live regionserver.&lt;br/&gt;
  3. I did some thinking (again) on the semantics of major version and minor version. The major version&lt;br/&gt;
     represents a new file format, e.g. suppose we add a new thing to the file&apos;s triailer, then we&lt;br/&gt;
     might need to bump up the major version. The minor version indicates the format of data inside a&lt;br/&gt;
     HFileBlock.&lt;br/&gt;
     In the current code, major versions 1 and 2 share the same HFileFormat (indicated by minor version&lt;br/&gt;
     of 0). In this patch, we have a new minorVersion 1 because the data contents inside a HFileBlock&lt;br/&gt;
     has changed. Tecnically, both major version 1 and 2 could have either minorVerion 0 or 1.&lt;br/&gt;
     Now, suppose we want to add a new field to the trailer of the HFile. We can bump the majorVersion&lt;br/&gt;
     to 3 but do not change the minorVersion because we did not change the internal format of an&lt;br/&gt;
     HFileBlock.&lt;br/&gt;
     Given the above, does it make sense to say that HFileBlock is independent of the majorVersion?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13220774" author="hadoopqa" created="Fri, 2 Mar 2012 08:41:00 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12516798/D1521.11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12516798/D1521.11.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -125 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.hfile.TestFixedFileTrailer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1079//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1079//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1079//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1079//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1079//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1079//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13220792" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 09:11:56 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Fixed failed unit test TestFixedFileTrailer&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13220810" author="hadoopqa" created="Fri, 2 Mar 2012 10:05:32 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12516807/D1521.12.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12516807/D1521.12.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -125 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 159 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestDrainingServer&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1080//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1080//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1080//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1080//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1080//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1080//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13221059" author="zhihyu@ebaysf.com" created="Fri, 2 Mar 2012 17:05:16 +0000"  >&lt;p&gt;Adding CRC32C in another JIRA is fine. Hadoop 2.0 isn&apos;t released. It would be nice to give users CRC32C early.&lt;/p&gt;

&lt;p&gt;The current formation w.r.t. minor version means that HFileV3 would start with minor version of 1.&lt;/p&gt;</comment>
                            <comment id="13221124" author="tlipcon" created="Fri, 2 Mar 2012 18:13:57 +0000"  >&lt;p&gt;There&apos;s no benefit to CRC32C over CRC32 unless you can use the JNI code. I don&apos;t think copy-pasting all of the JNI stuff into HBase is a good idea. And, besides, this patch is not yet equipped to do the JNI-based checksumming (which requires direct buffers, etc)&lt;/p&gt;</comment>
                            <comment id="13221158" author="dhruba" created="Fri, 2 Mar 2012 19:00:00 +0000"  >&lt;p&gt;The reason I kept the definition of CRC32C in the ChecksumType is essentially to reserve an ordinal in the enum for this checksum algorithm in the future. We should just wait for Hadoop 2.0 to be released to get this feature (instead of copying it to hbase).&lt;/p&gt;

&lt;p&gt;&amp;gt;  means that HFileV3 would start with minor version of 1.&lt;/p&gt;

&lt;p&gt;I am suggesting that HFileV3 has nothing to do with minorVersions. HFileV3 can decide to support minor version 0 or 1 or both. HFileV3 might not even use the HFileBlock format as we know it, in which case the question is moot.&lt;/p&gt;</comment>
                            <comment id="13222096" author="dhruba" created="Mon, 5 Mar 2012 01:05:10 +0000"  >&lt;p&gt;This has been running successfully for days-on-end in my clusters. Stack: pl let me know if your testing showed anything amiss. Thanks.&lt;/p&gt;</comment>
                            <comment id="13222183" author="lhofhansl" created="Mon, 5 Mar 2012 06:41:34 +0000"  >&lt;p&gt;Marking this for 0.94&lt;/p&gt;</comment>
                            <comment id="13222898" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 01:53:55 +0000"  >&lt;p&gt;mbautin has accepted the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: looks good! A few minor comments inline.&lt;/p&gt;

&lt;p&gt;  Also, I still think there is some code duplication between TestHFileBlock and TestHFileBlockCompatibility that we could get rid of, but we can do that in a separate patch.&lt;/p&gt;

&lt;p&gt;  Could you please attach the final patch to the JIRA and run it on Hadoop QA?&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:48 s/do do/do/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1242 do do -&amp;gt; do&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:161-174 It would be great to factor out the common part of this hard-coded gzip blob so that it is not repeated in TestHFileBlock and here.&lt;/p&gt;

&lt;p&gt;  This is an example of what I meant in my comment regarding code duplication.&lt;/p&gt;

&lt;p&gt;  Alternatively, we can remove code duplication in a follow-up patch.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13222899" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 01:53:55 +0000"  >&lt;p&gt;mbautin has accepted the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;  @dhruba: looks good! A few minor comments inline.&lt;/p&gt;

&lt;p&gt;  Also, I still think there is some code duplication between TestHFileBlock and TestHFileBlockCompatibility that we could get rid of, but we can do that in a separate patch.&lt;/p&gt;

&lt;p&gt;  Could you please attach the final patch to the JIRA and run it on Hadoop QA?&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java:48 s/do do/do/&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java:1242 do do -&amp;gt; do&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:161-174 It would be great to factor out the common part of this hard-coded gzip blob so that it is not repeated in TestHFileBlock and here.&lt;/p&gt;

&lt;p&gt;  This is an example of what I meant in my comment regarding code duplication.&lt;/p&gt;

&lt;p&gt;  Alternatively, we can remove code duplication in a follow-up patch.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223064" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 07:48:54 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:161-174 This blob is not repeated in TestHFileBlock, because the blob in TestHFileBlock has a 4 byte checksum at the end while there is no checksum in the blob here. But since you feel strongly about this, I opened another JIRA to address it in a followup patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5530&quot; title=&quot;Create a framework to test backward compatibility of various HFileBlock disk formats&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5530&quot;&gt;&lt;del&gt;HBASE-5530&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223065" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 07:48:59 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Fixed comments as suggested by Mikhail.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13223066" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 07:49:03 +0000"  >&lt;p&gt;dhruba has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:161-174 This blob is not repeated in TestHFileBlock, because the blob in TestHFileBlock has a 4 byte checksum at the end while there is no checksum in the blob here. But since you feel strongly about this, I opened another JIRA to address it in a followup patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5530&quot; title=&quot;Create a framework to test backward compatibility of various HFileBlock disk formats&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5530&quot;&gt;&lt;del&gt;HBASE-5530&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223067" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 07:51:04 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Fixed comments as suggested by Mikhail.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13223092" author="hadoopqa" created="Tue, 6 Mar 2012 08:41:22 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12517204/D1521.13.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12517204/D1521.13.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -125 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 158 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestMasterObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1113//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1113//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1113//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1113//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1113//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1113//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13223564" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 19:13:55 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:161-174 What I meant by repeated blob was everything but the last four bytes. We can create a string constant for that part in TestHFileBlock and reuse it here.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223565" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 19:13:56 +0000"  >&lt;p&gt;mbautin has commented on the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java:161-174 What I meant by repeated blob was everything but the last four bytes. We can create a string constant for that part in TestHFileBlock and reuse it here.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223567" author="mikhail" created="Tue, 6 Mar 2012 19:14:20 +0000"  >&lt;p&gt;@Dhruba:&lt;/p&gt;

&lt;p&gt;could you please rerun the failed tests locally, as well as check the test reports?&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hbase.coprocessor.TestMasterObserver&lt;br/&gt;
org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;/p&gt;</comment>
                            <comment id="13223586" author="dhruba" created="Tue, 6 Mar 2012 19:38:35 +0000"  >&lt;p&gt;I ran all four of them individually (manually), and all four of them pass.&lt;/p&gt;

&lt;p&gt;Looking at the Hudson test results, it appears that all the failures are related to some map-reduce problem, but not really sure the precise cause. But I think that these failures are somehow related to this patch, especially because the Hudson tests for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5399&quot; title=&quot;Cut the link between the client and the zookeeper ensemble&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5399&quot;&gt;&lt;del&gt;HBASE-5399&lt;/del&gt;&lt;/a&gt; just passed successfully. Will investigate more (but if you have any clues, please do let me know). &lt;/p&gt;</comment>
                            <comment id="13223705" author="stack" created="Tue, 6 Mar 2012 22:01:10 +0000"  >&lt;p&gt;@Dhruba Try resubmitting your patch too.  We regularly see three of these mr tests fail.  Fixed in hadoop 1.0.2 apparently.&lt;/p&gt;</comment>
                            <comment id="13223900" author="phabricator@reviews.facebook.net" created="Wed, 7 Mar 2012 01:43:55 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Updated patch to to latest trunk. Also, trigger rerun of HadoopQA&lt;br/&gt;
  unit tests.&lt;/p&gt;

&lt;p&gt;  The four unit tests that failed in an earlier version of this patch&lt;br/&gt;
  is not related to this patch. The same set of unit tests also failed&lt;br/&gt;
  for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4608&quot; title=&quot;HLog Compression&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4608&quot;&gt;&lt;del&gt;HBASE-4608&lt;/del&gt;&lt;/a&gt;, see&lt;br/&gt;
  &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1103//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1103//testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13223901" author="phabricator@reviews.facebook.net" created="Wed, 7 Mar 2012 01:43:57 +0000"  >&lt;p&gt;dhruba updated the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;br/&gt;
Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;  Updated patch to to latest trunk. Also, trigger rerun of HadoopQA&lt;br/&gt;
  unit tests.&lt;/p&gt;

&lt;p&gt;  The four unit tests that failed in an earlier version of this patch&lt;br/&gt;
  is not related to this patch. The same set of unit tests also failed&lt;br/&gt;
  for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4608&quot; title=&quot;HLog Compression&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4608&quot;&gt;&lt;del&gt;HBASE-4608&lt;/del&gt;&lt;/a&gt;, see&lt;br/&gt;
  &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1103//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1103//testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;br/&gt;
  src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;br/&gt;
  src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/p&gt;</comment>
                            <comment id="13223921" author="hadoopqa" created="Wed, 7 Mar 2012 02:35:15 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12517351/D1521.14.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12517351/D1521.14.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 55 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -125 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 158 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestMasterObserver&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationPeer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1125//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1125//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1125//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1125//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/1125//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/1125//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13225058" author="dhruba" created="Thu, 8 Mar 2012 07:04:02 +0000"  >&lt;p&gt;Can some kind committer please look at this one once again? The same unit tests are failing for most other JIRA submissions too.&lt;/p&gt;</comment>
                            <comment id="13225278" author="ram_krish" created="Thu, 8 Mar 2012 16:11:22 +0000"  >&lt;p&gt;@Dhruba&lt;br/&gt;
Most of the times the 4 test cases keep failing.  I think it should be ok.&lt;br/&gt;
If TestMasterObserver is running locally then it should be fine i think. &lt;/p&gt;</comment>
                            <comment id="13225528" author="zhihyu@ebaysf.com" created="Thu, 8 Mar 2012 21:18:32 +0000"  >&lt;p&gt;I ran TestMasterObserver 5 times and it passed.&lt;br/&gt;
TestReplicationPeer fails easily with or without the patch.&lt;/p&gt;

&lt;p&gt;Failures for TestTableMapReduce and TestHFileOutputFormat should be fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-3583&quot; title=&quot;ProcfsBasedProcessTree#constructProcessInfo() may throw NumberFormatException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-3583&quot;&gt;&lt;del&gt;MAPREDUCE-3583&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13225640" author="phabricator@reviews.facebook.net" created="Thu, 8 Mar 2012 22:57:55 +0000"  >&lt;p&gt;mbautin has committed the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;COMMIT&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/rHBASE1298641&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/rHBASE1298641&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13225641" author="phabricator@reviews.facebook.net" created="Thu, 8 Mar 2012 22:57:56 +0000"  >&lt;p&gt;mbautin has committed the revision &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&quot;.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;COMMIT&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/rHBASE1298641&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/rHBASE1298641&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13225654" author="stack" created="Thu, 8 Mar 2012 23:09:04 +0000"  >&lt;p&gt;Wahoo!!&lt;/p&gt;

&lt;p&gt;Lars, you want to pull it into 0.94? (Does this mean 0.94 is good to go?  Should we put up an RC?)&lt;/p&gt;</comment>
                            <comment id="13225655" author="lhofhansl" created="Thu, 8 Mar 2012 23:10:56 +0000"  >&lt;p&gt;Yes sir. Still waiting for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4608&quot; title=&quot;HLog Compression&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4608&quot;&gt;&lt;del&gt;HBASE-4608&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
And &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5541&quot; title=&quot;Avoid holding the rowlock during HLog sync in HRegion.mutateRowWithLocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5541&quot;&gt;&lt;del&gt;HBASE-5541&lt;/del&gt;&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13225658" author="lhofhansl" created="Thu, 8 Mar 2012 23:12:10 +0000"  >&lt;p&gt;and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5526&quot; title=&quot;Configurable file and directory based umask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5526&quot;&gt;&lt;del&gt;HBASE-5526&lt;/del&gt;&lt;/a&gt;, but that&apos;s it from my side.&lt;/p&gt;</comment>
                            <comment id="13225686" author="lhofhansl" created="Thu, 8 Mar 2012 23:53:14 +0000"  >&lt;p&gt;Is &quot;D1521.14.patch&quot; the that was applied to trunk?&lt;/p&gt;</comment>
                            <comment id="13225703" author="mikhail" created="Fri, 9 Mar 2012 00:14:34 +0000"  >&lt;p&gt;@Lars: yes. I have also re-run unit tests one more time.&lt;/p&gt;</comment>
                            <comment id="13225704" author="lhofhansl" created="Fri, 9 Mar 2012 00:15:20 +0000"  >&lt;p&gt;Thanks I&apos;ll apply and commit the patch to 0.94.&lt;/p&gt;

&lt;p&gt;Thanks for the great work guys!!&lt;/p&gt;</comment>
                            <comment id="13225713" author="lhofhansl" created="Fri, 9 Mar 2012 00:29:37 +0000"  >&lt;p&gt;Here&apos;s the 0.94 version.&lt;br/&gt;
Applied mostly with some offsets, just had to fix up some imports.&lt;/p&gt;</comment>
                            <comment id="13225716" author="lhofhansl" created="Fri, 9 Mar 2012 00:32:13 +0000"  >&lt;p&gt;Comitted to 0.94 as well.&lt;/p&gt;</comment>
                            <comment id="13225733" author="hudson" created="Fri, 9 Mar 2012 00:43:25 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2674 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2674/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2674/&lt;/a&gt;)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&lt;/p&gt;

&lt;p&gt;Author: Dhruba&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
HFile is enhanced to store a checksum for each block. HDFS checksum verification&lt;br/&gt;
is avoided while reading data into the block cache. On a checksum verification&lt;br/&gt;
failure, we retry the file system read request with hdfs checksums switched on&lt;br/&gt;
(thanks Todd).&lt;/p&gt;

&lt;p&gt;I have a benchmark that shows that it reduces iops on the disk by about 40%. In&lt;br/&gt;
this experiment, the entire memory on the regionserver is allocated to the&lt;br/&gt;
regionserver&apos;s jvm and the OS buffer cache size is negligible. I also measured&lt;br/&gt;
negligible (&amp;lt;5%) additional cpu usage while using hbase-level checksums.&lt;/p&gt;

&lt;p&gt;The salient points of this patch:&lt;/p&gt;

&lt;p&gt;1. Each hfile&apos;s trailer used to have a 4 byte version number. I enhanced this so&lt;br/&gt;
that these 4 bytes can be interpreted as a (major version number, minor&lt;br/&gt;
version). Pre-existing hfiles have a minor version of 0. The new hfile format&lt;br/&gt;
has a minor version of 1 (thanks Mikhail). The hfile major version remains&lt;br/&gt;
unchanged at 2. The reason I did not introduce a new major version number is&lt;br/&gt;
because the code changes needed to store/read checksums do not differ much from&lt;br/&gt;
existing V2 writers/readers.&lt;/p&gt;

&lt;p&gt;2. Introduced a HFileSystem object which is a encapsulates the FileSystem&lt;br/&gt;
objects needed to access data from hfiles and hlogs.  HDFS FileSystem objects&lt;br/&gt;
already had the ability to switch off checksum verifications for reads.&lt;/p&gt;

&lt;p&gt;3. The majority of the code changes are located in hbase.io.hfie package. The&lt;br/&gt;
retry of a read on an initial checksum failure occurs inside the hbase.io.hfile&lt;br/&gt;
package itself.  The code changes to hbase.regionserver package are minor.&lt;/p&gt;

&lt;p&gt;4. The format of a hfileblock is the header followed by the data followed by the&lt;br/&gt;
checksum(s). Each 16 K (configurable) size of data has a 4 byte checksum.  The&lt;br/&gt;
hfileblock header has two additional fields: a 4 byte value to store the&lt;br/&gt;
bytesPerChecksum and a 4 byte value to store the size of the user data&lt;br/&gt;
(excluding the checksum data). This is well explained in the associated&lt;br/&gt;
javadocs.&lt;/p&gt;

&lt;p&gt;5. I added a test to test backward compatibility. I will be writing more unit&lt;br/&gt;
tests that triggers checksum verification failures aggressively. I have left a&lt;br/&gt;
few redundant log messages in the code (just for easier debugging) and will&lt;br/&gt;
remove them in later stage of this patch. I will also be adding metrics on&lt;br/&gt;
number of checksum verification failures/success in a later version of this&lt;br/&gt;
diff.&lt;/p&gt;

&lt;p&gt;6. By default, hbase-level checksums are switched on and hdfs level checksums&lt;br/&gt;
are switched off for hfile-reads. No changes to Hlog code path here.&lt;/p&gt;

&lt;p&gt;Test Plan: The default setting is to switch on hbase checksums for hfile-reads,&lt;br/&gt;
thus all existing tests actually validate the new code pieces. I will be writing&lt;br/&gt;
more unit tests for triggering checksum verification failures.&lt;/p&gt;

&lt;p&gt;Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;Reviewed By: mbautin&lt;/p&gt;

&lt;p&gt;CC: JIRA, tedyu, mbautin, dhruba, todd, stack&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt; (Revision 1298641)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
mbautin : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/fs&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13225765" author="hudson" created="Fri, 9 Mar 2012 01:10:41 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #21 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/21/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/21/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache (Dhruba) (Revision 1298666)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/fs&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13225862" author="hudson" created="Fri, 9 Mar 2012 05:48:35 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #132 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/132/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/132/&lt;/a&gt;)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; Support checksums in HBase block cache&lt;/p&gt;

&lt;p&gt;Author: Dhruba&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
HFile is enhanced to store a checksum for each block. HDFS checksum verification&lt;br/&gt;
is avoided while reading data into the block cache. On a checksum verification&lt;br/&gt;
failure, we retry the file system read request with hdfs checksums switched on&lt;br/&gt;
(thanks Todd).&lt;/p&gt;

&lt;p&gt;I have a benchmark that shows that it reduces iops on the disk by about 40%. In&lt;br/&gt;
this experiment, the entire memory on the regionserver is allocated to the&lt;br/&gt;
regionserver&apos;s jvm and the OS buffer cache size is negligible. I also measured&lt;br/&gt;
negligible (&amp;lt;5%) additional cpu usage while using hbase-level checksums.&lt;/p&gt;

&lt;p&gt;The salient points of this patch:&lt;/p&gt;

&lt;p&gt;1. Each hfile&apos;s trailer used to have a 4 byte version number. I enhanced this so&lt;br/&gt;
that these 4 bytes can be interpreted as a (major version number, minor&lt;br/&gt;
version). Pre-existing hfiles have a minor version of 0. The new hfile format&lt;br/&gt;
has a minor version of 1 (thanks Mikhail). The hfile major version remains&lt;br/&gt;
unchanged at 2. The reason I did not introduce a new major version number is&lt;br/&gt;
because the code changes needed to store/read checksums do not differ much from&lt;br/&gt;
existing V2 writers/readers.&lt;/p&gt;

&lt;p&gt;2. Introduced a HFileSystem object which is a encapsulates the FileSystem&lt;br/&gt;
objects needed to access data from hfiles and hlogs.  HDFS FileSystem objects&lt;br/&gt;
already had the ability to switch off checksum verifications for reads.&lt;/p&gt;

&lt;p&gt;3. The majority of the code changes are located in hbase.io.hfie package. The&lt;br/&gt;
retry of a read on an initial checksum failure occurs inside the hbase.io.hfile&lt;br/&gt;
package itself.  The code changes to hbase.regionserver package are minor.&lt;/p&gt;

&lt;p&gt;4. The format of a hfileblock is the header followed by the data followed by the&lt;br/&gt;
checksum(s). Each 16 K (configurable) size of data has a 4 byte checksum.  The&lt;br/&gt;
hfileblock header has two additional fields: a 4 byte value to store the&lt;br/&gt;
bytesPerChecksum and a 4 byte value to store the size of the user data&lt;br/&gt;
(excluding the checksum data). This is well explained in the associated&lt;br/&gt;
javadocs.&lt;/p&gt;

&lt;p&gt;5. I added a test to test backward compatibility. I will be writing more unit&lt;br/&gt;
tests that triggers checksum verification failures aggressively. I have left a&lt;br/&gt;
few redundant log messages in the code (just for easier debugging) and will&lt;br/&gt;
remove them in later stage of this patch. I will also be adding metrics on&lt;br/&gt;
number of checksum verification failures/success in a later version of this&lt;br/&gt;
diff.&lt;/p&gt;

&lt;p&gt;6. By default, hbase-level checksums are switched on and hdfs level checksums&lt;br/&gt;
are switched off for hfile-reads. No changes to Hlog code path here.&lt;/p&gt;

&lt;p&gt;Test Plan: The default setting is to switch on hbase checksums for hfile-reads,&lt;br/&gt;
thus all existing tests actually validate the new code pieces. I will be writing&lt;br/&gt;
more unit tests for triggering checksum verification failures.&lt;/p&gt;

&lt;p&gt;Reviewers: mbautin&lt;/p&gt;

&lt;p&gt;Reviewed By: mbautin&lt;/p&gt;

&lt;p&gt;CC: JIRA, tedyu, mbautin, dhruba, todd, stack&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D1521&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1521&lt;/a&gt; (Revision 1298641)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
mbautin : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/fs&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/ChecksumUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/io/hfile/NoOpDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/util/ChecksumFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/util/ChecksumType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/util/CompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/CacheTestUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderV1.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/CreateRandomStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompoundBloomFilter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/test/java/org/apache/hadoop/hbase/util/MockRegionServerServices.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13226438" author="lhofhansl" created="Fri, 9 Mar 2012 20:49:31 +0000"  >&lt;p&gt;Actually &lt;br/&gt;
svn diff -r r1298574:r1298641 &lt;br/&gt;
gives me a diff of size different from the attached D1521.14.patch (I can&apos;t diff the patch files easily, as files are reordered)&lt;/p&gt;

&lt;p&gt;Mikhail, are you sure D1521.14.patch is the exact committed patch?&lt;/p&gt;</comment>
                            <comment id="13227737" author="mikhail" created="Mon, 12 Mar 2012 18:18:41 +0000"  >&lt;p&gt;@Lars: what I committed was based on D1521.14.patch, but it will not be exactly the same patch, because I used &quot;arc patch&quot; to apply the patch from Differential, fixed some minor indentation problem, and committed using the git-svn bridge. I also re-ran all the unit tests before the commit. Sorry for a delay in replying.&lt;/p&gt;</comment>
                            <comment id="13227871" author="lhofhansl" created="Mon, 12 Mar 2012 20:38:51 +0000"  >&lt;p&gt;Thanks Mikhail just making sure &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13247014" author="lhofhansl" created="Thu, 5 Apr 2012 04:42:48 +0000"  >&lt;p&gt;Looks like this introduced bug with pre 0.94 HFiles.&lt;br/&gt;
@Dhruba: Could you have a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5720&quot; title=&quot;HFileDataBlockEncoderImpl uses wrong header size when reading HFiles with no checksums&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5720&quot;&gt;&lt;del&gt;HBASE-5720&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13461289" author="lhofhansl" created="Sat, 22 Sep 2012 23:19:47 +0000"  >&lt;p&gt;Can you fellas take a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6868&quot; title=&quot;Skip checksum is broke; are we double-checksumming by default?&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6868&quot;&gt;&lt;del&gt;HBASE-6868&lt;/del&gt;&lt;/a&gt;?&lt;br/&gt;
We&apos;re worried about not checksumming HLog (but I think this works correctly), and about double checksumming if the block is not local&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12549604">HBASE-5720</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12552287">HBASE-5864</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12608728">HBASE-6868</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12535560">HDFS-2699</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12517648" name="5074-0.94.txt" size="219204" author="lhofhansl" created="Fri, 9 Mar 2012 00:29:37 +0000"/>
                            <attachment id="12512350" name="ASF.LICENSE.NOT.GRANTED--D1521.1.patch" size="158522" author="phabricator@reviews.facebook.net" created="Sun, 29 Jan 2012 08:02:10 +0000"/>
                            <attachment id="12512349" name="ASF.LICENSE.NOT.GRANTED--D1521.1.patch" size="158522" author="phabricator@reviews.facebook.net" created="Sun, 29 Jan 2012 08:02:09 +0000"/>
                            <attachment id="12516146" name="ASF.LICENSE.NOT.GRANTED--D1521.10.patch" size="214792" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 07:58:31 +0000"/>
                            <attachment id="12516145" name="ASF.LICENSE.NOT.GRANTED--D1521.10.patch" size="214792" author="phabricator@reviews.facebook.net" created="Mon, 27 Feb 2012 07:55:34 +0000"/>
                            <attachment id="12516798" name="ASF.LICENSE.NOT.GRANTED--D1521.11.patch" size="217975" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 07:43:17 +0000"/>
                            <attachment id="12516797" name="ASF.LICENSE.NOT.GRANTED--D1521.11.patch" size="217975" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 07:43:12 +0000"/>
                            <attachment id="12516807" name="ASF.LICENSE.NOT.GRANTED--D1521.12.patch" size="218397" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 09:11:57 +0000"/>
                            <attachment id="12516806" name="ASF.LICENSE.NOT.GRANTED--D1521.12.patch" size="218397" author="phabricator@reviews.facebook.net" created="Fri, 2 Mar 2012 09:09:57 +0000"/>
                            <attachment id="12517204" name="ASF.LICENSE.NOT.GRANTED--D1521.13.patch" size="218394" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 07:51:05 +0000"/>
                            <attachment id="12517203" name="ASF.LICENSE.NOT.GRANTED--D1521.13.patch" size="218394" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 07:49:00 +0000"/>
                            <attachment id="12517351" name="ASF.LICENSE.NOT.GRANTED--D1521.14.patch" size="218394" author="phabricator@reviews.facebook.net" created="Wed, 7 Mar 2012 01:43:58 +0000"/>
                            <attachment id="12517350" name="ASF.LICENSE.NOT.GRANTED--D1521.14.patch" size="218394" author="phabricator@reviews.facebook.net" created="Wed, 7 Mar 2012 01:43:55 +0000"/>
                            <attachment id="12513016" name="ASF.LICENSE.NOT.GRANTED--D1521.2.patch" size="192601" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 18:46:57 +0000"/>
                            <attachment id="12513015" name="ASF.LICENSE.NOT.GRANTED--D1521.2.patch" size="192601" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 18:46:55 +0000"/>
                            <attachment id="12513416" name="ASF.LICENSE.NOT.GRANTED--D1521.3.patch" size="223561" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 09:17:59 +0000"/>
                            <attachment id="12513415" name="ASF.LICENSE.NOT.GRANTED--D1521.3.patch" size="223561" author="phabricator@reviews.facebook.net" created="Mon, 6 Feb 2012 09:17:58 +0000"/>
                            <attachment id="12513715" name="ASF.LICENSE.NOT.GRANTED--D1521.4.patch" size="209332" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:33:00 +0000"/>
                            <attachment id="12513714" name="ASF.LICENSE.NOT.GRANTED--D1521.4.patch" size="209332" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 23:32:58 +0000"/>
                            <attachment id="12513780" name="ASF.LICENSE.NOT.GRANTED--D1521.5.patch" size="210129" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 08:30:02 +0000"/>
                            <attachment id="12513779" name="ASF.LICENSE.NOT.GRANTED--D1521.5.patch" size="210129" author="phabricator@reviews.facebook.net" created="Wed, 8 Feb 2012 08:30:01 +0000"/>
                            <attachment id="12514759" name="ASF.LICENSE.NOT.GRANTED--D1521.6.patch" size="214426" author="phabricator@reviews.facebook.net" created="Thu, 16 Feb 2012 05:57:00 +0000"/>
                            <attachment id="12514758" name="ASF.LICENSE.NOT.GRANTED--D1521.6.patch" size="214426" author="phabricator@reviews.facebook.net" created="Thu, 16 Feb 2012 05:56:58 +0000"/>
                            <attachment id="12515551" name="ASF.LICENSE.NOT.GRANTED--D1521.7.patch" size="214500" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 08:16:49 +0000"/>
                            <attachment id="12515550" name="ASF.LICENSE.NOT.GRANTED--D1521.7.patch" size="214500" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 08:16:47 +0000"/>
                            <attachment id="12515642" name="ASF.LICENSE.NOT.GRANTED--D1521.8.patch" size="214337" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 20:09:54 +0000"/>
                            <attachment id="12515641" name="ASF.LICENSE.NOT.GRANTED--D1521.8.patch" size="214337" author="phabricator@reviews.facebook.net" created="Wed, 22 Feb 2012 20:09:48 +0000"/>
                            <attachment id="12515829" name="ASF.LICENSE.NOT.GRANTED--D1521.9.patch" size="214560" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:13:50 +0000"/>
                            <attachment id="12515828" name="ASF.LICENSE.NOT.GRANTED--D1521.9.patch" size="214560" author="phabricator@reviews.facebook.net" created="Thu, 23 Feb 2012 22:13:48 +0000"/>
                            <attachment id="12516208" name="D1521.10.patch" size="214792" author="stack" created="Mon, 27 Feb 2012 20:54:16 +0000"/>
                            <attachment id="12516189" name="D1521.10.patch" size="214792" author="stack" created="Mon, 27 Feb 2012 17:51:11 +0000"/>
                            <attachment id="12516181" name="D1521.10.patch" size="214792" author="stack" created="Mon, 27 Feb 2012 16:44:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 20 Dec 2011 07:22:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>221472</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 12 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08r3b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48989</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Adds hbase.regionserver.checksum.verify.  If hbase.regionserver.checksum.verify is set to true, then hbase will read data and then verify checksums. Checksum verification inside hdfs will be switched off.  If the hbase-checksum verification fails, then it will switch back to using hdfs checksums for verifiying data that is being read from storage.  Also adds hbase.hstore.bytes.per.checksum -- number of bytes in a newly created checksum chunk -- and hbase.hstore.checksum.algorithm, name of an algorithm that is used to compute checksums.&lt;br/&gt;
&lt;br/&gt;
You will currently only see benefit if you have the local read short-circuit enabled -- see &lt;a href=&quot;http://hbase.apache.org/book.html#perf.hdfs.configs&quot;&gt;http://hbase.apache.org/book.html#perf.hdfs.configs&lt;/a&gt; -- while &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3429&quot; title=&quot;DataNode reads checksums even if client does not need them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3429&quot;&gt;&lt;strike&gt;HDFS-3429&lt;/strike&gt;&lt;/a&gt; goes unfixed.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.96notable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>