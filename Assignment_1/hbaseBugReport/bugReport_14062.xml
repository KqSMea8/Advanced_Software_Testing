<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:49:22 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-14062/HBASE-14062.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-14062] RpcServer.Listener.doAccept get blocked by LinkedList.remove</title>
                <link>https://issues.apache.org/jira/browse/HBASE-14062</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We saw these blocked info in our jstack output:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;RpcServer.listener,port=60020&quot; daemon prio=10 tid=0x00007f158097b800 nid=0x2cd05 waiting for monitor entry [0x0000000046374000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doAccept(RpcServer.java:833)
        - waiting to lock &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
        at org.apache.hadoop.hbase.ipc.RpcServer$Listener.run(RpcServer.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And the owner of the lock is LinkedList.remove:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;RpcServer.reader=9,port=60020&quot; daemon prio=10 tid=0x00007f1580394000 nid=0x2cc19 runnable [0x0000000043b4c000]
   java.lang.Thread.State: RUNNABLE
        at java.util.LinkedList.remove(LinkedList.java:363)
        at java.util.Collections$SynchronizedCollection.remove(Collections.java:1639)
        - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
        at org.apache.hadoop.hbase.ipc.RpcServer.closeConnection(RpcServer.java:1992)
        - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
        at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:867)
        at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:645)
        - locked &amp;lt;0x00000002bae09a30&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
        at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:620)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This issue blocked RS once in a while and I had to restart it whenever it happens. It seems like a bug. Any suggestions?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12844515">HBASE-14062</key>
            <summary>RpcServer.Listener.doAccept get blocked by LinkedList.remove</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="victorunique">Victor Xu</reporter>
                        <labels>
                    </labels>
                <created>Sun, 12 Jul 2015 23:27:21 +0000</created>
                <updated>Tue, 14 Jul 2015 06:36:42 +0000</updated>
                                            <version>0.98.12</version>
                                                    <component>IPC/RPC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="14624064" author="victorunique" created="Sun, 12 Jul 2015 23:30:23 +0000"  >&lt;p&gt;Attach the raw jstack output.&lt;/p&gt;</comment>
                            <comment id="14624354" author="chenheng" created="Mon, 13 Jul 2015 08:25:58 +0000"  >&lt;p&gt;your threads are blocked when acquiring connectionList lock in closeConnection of doRead function&#12290;&lt;/p&gt;

&lt;p&gt;but in doRead function,  closeConnection() called when read return -1 or read throw exception&#12290; &lt;/p&gt;

&lt;p&gt;can you post your regionserver&apos;s log ?&lt;/p&gt;


&lt;p&gt;PS:  this is doRead function below:&lt;br/&gt;
    void doRead(SelectionKey key) throws InterruptedException {&lt;br/&gt;
      int count = 0;&lt;br/&gt;
      Connection c = (Connection)key.attachment();&lt;br/&gt;
      if (c == null) &lt;/p&gt;
{
        return;
      }
&lt;p&gt;      c.setLastContact(System.currentTimeMillis());&lt;br/&gt;
      try &lt;/p&gt;
{
        count = c.readAndProcess();
      }
&lt;p&gt; catch (InterruptedException ieo) &lt;/p&gt;
{
        throw ieo;
      }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
        LOG.warn(getName() + &quot;: count of bytes read: &quot; + count, e);
        count = -1; //so that the (count &amp;lt; 0) block is executed
      }
&lt;p&gt;      if (count &amp;lt; 0) {&lt;br/&gt;
        if (LOG.isDebugEnabled()) &lt;/p&gt;
{
          LOG.debug(getName() + &quot;: DISCONNECTING client &quot; + c.toString() +
            &quot; because read count=&quot; + count +
            &quot;. Number of active connections: &quot; + numConnections);
        }
&lt;p&gt;        closeConnection(c);&lt;br/&gt;
        // c = null;&lt;br/&gt;
      } else &lt;/p&gt;
{
        c.setLastContact(System.currentTimeMillis());
      }
&lt;p&gt;    }&lt;/p&gt;

</comment>
                            <comment id="14625383" author="victorunique" created="Mon, 13 Jul 2015 21:28:53 +0000"  >&lt;p&gt;Attach the last 10M region server&apos;s log.&lt;/p&gt;</comment>
                            <comment id="14625408" author="victorunique" created="Mon, 13 Jul 2015 21:36:28 +0000"  >&lt;p&gt;Thanks. What confused me most is the lock is blocked by java.util.LinkedList.remove method and never be released, because I got another two jstack outputs several minutes after the first one, and I still found the same lock id(&amp;lt;0x00000002bb094ac8&amp;gt;) which means the LinkedList.remove never finished. Maybe a bug in JVM?&lt;/p&gt;</comment>
                            <comment id="14625792" author="chenheng" created="Tue, 14 Jul 2015 04:29:33 +0000"  >&lt;p&gt;in another two jstack outputs,  the thread&apos;s id which hold the lock is same with the jstack which you post ?&lt;/p&gt;


&lt;p&gt;I notice in your region server&apos;s log,  there are a lot of exceptions throwed by doRead function&#12290; &lt;br/&gt;
This exception is catched, and set the count=-1,  so  It will close this connection in closeConnection function&#12290; &lt;br/&gt;
And in closeConnection,  It will acquire the lock of connectionList&#12290; &lt;/p&gt;


&lt;p&gt;PS:  The exception is below,  it seems the client close connection during read process,  is it correct?&lt;/p&gt;

&lt;p&gt;2015-07-13 05:42:12,735 WARN org.apache.hadoop.ipc.RpcServer: RpcServer.listener,port=60020: count of bytes read: 0&lt;br/&gt;
java.io.IOException: Connection reset by peer&lt;br/&gt;
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)&lt;br/&gt;
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)&lt;br/&gt;
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)&lt;br/&gt;
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)&lt;br/&gt;
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.RpcServer.channelRead(RpcServer.java:2310)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1480)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:854)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:645)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:620)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:744)&lt;/p&gt;</comment>
                            <comment id="14625860" author="victorunique" created="Tue, 14 Jul 2015 05:47:08 +0000"  >&lt;p&gt;Yes, you are right. Different threads held the same lock in different jstack outputs:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;jstack.log-&quot;RpcServer.reader=9,port=60020&quot; daemon prio=10 tid=0x00007f1580394000 nid=0x2cc19 runnable [0x0000000043b4c000]
jstack.log-   java.lang.Thread.State: RUNNABLE
jstack.log-     at java.util.LinkedList.remove(LinkedList.java:363)
jstack.log-     at java.util.Collections$SynchronizedCollection.remove(Collections.java:1639)
jstack.log:     - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
jstack.log-     at org.apache.hadoop.hbase.ipc.RpcServer.closeConnection(RpcServer.java:1992)
jstack.log:     - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
--
jstack.log.1-&quot;RpcServer.reader=0,port=60020&quot; daemon prio=10 tid=0x00007f1580263000 nid=0x2cc10 runnable [0x0000000043243000]
jstack.log.1-   java.lang.Thread.State: RUNNABLE
jstack.log.1-   at java.util.LinkedList.remove(LinkedList.java:363)
jstack.log.1-   at java.util.Collections$SynchronizedCollection.remove(Collections.java:1639)
jstack.log.1:   - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
jstack.log.1-   at org.apache.hadoop.hbase.ipc.RpcServer.closeConnection(RpcServer.java:1992)
jstack.log.1:   - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
--
jstack.log.2-&quot;RpcServer.reader=6,port=60020&quot; daemon prio=10 tid=0x00007f1580342800 nid=0x2cc16 runnable [0x0000000043849000]
jstack.log.2-   java.lang.Thread.State: RUNNABLE
jstack.log.2-   at java.util.LinkedList.remove(LinkedList.java:363)
jstack.log.2-   at java.util.Collections$SynchronizedCollection.remove(Collections.java:1639)
jstack.log.2:   - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
jstack.log.2-   at org.apache.hadoop.hbase.ipc.RpcServer.closeConnection(RpcServer.java:1992)
jstack.log.2:   - locked &amp;lt;0x00000002bb094ac8&amp;gt; (a java.util.Collections$SynchronizedList)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14625877" author="victorunique" created="Tue, 14 Jul 2015 05:59:36 +0000"  >&lt;p&gt;There might be lots of requests coming together and only 10 readers are there to handler them. Whenever a reader starts to read the data, the client quits. All readers are busy repeating these read/fail loop so the lock seems to be always held, and other normal requests are blocked(or served slowly). Am I right? &lt;/p&gt;</comment>
                            <comment id="14625882" author="chenheng" created="Tue, 14 Jul 2015 06:02:36 +0000"  >&lt;p&gt;So i think the lock is hold  due to a lot of exceptions throwed  by doRead&#12290; &lt;/p&gt;

&lt;p&gt;When exception throw, doRead will call closeConnection,  and closeConnection will hold the lock.&lt;/p&gt;

&lt;p&gt;And when having too many exceptions, the lock is always acquired by closeConnection, so the lock is always waited by doAccept&lt;/p&gt;


&lt;p&gt;Why the exception is throwed? &lt;/p&gt;</comment>
                            <comment id="14625896" author="chenheng" created="Tue, 14 Jul 2015 06:17:03 +0000"  >&lt;p&gt;I think so.&lt;/p&gt;

&lt;p&gt;what is your Hbase client logic? &lt;/p&gt;</comment>
                            <comment id="14625897" author="chenheng" created="Tue, 14 Jul 2015 06:17:05 +0000"  >&lt;p&gt;I think so.&lt;/p&gt;

&lt;p&gt;what is your Hbase client logic? &lt;/p&gt;</comment>
                            <comment id="14625898" author="chenheng" created="Tue, 14 Jul 2015 06:17:08 +0000"  >&lt;p&gt;I think so.&lt;/p&gt;

&lt;p&gt;what is your Hbase client logic? &lt;/p&gt;</comment>
                            <comment id="14625902" author="victorunique" created="Tue, 14 Jul 2015 06:18:11 +0000"  >&lt;p&gt;We can see from the rs log that META table located on that rs. I guess maybe some applications use very short client rpc timeout or have requests cached locally before actually sending to this rs, and when the requests reach the rs, they almost exceed the timeout immediately. When the clients retry, this request-and-fail loop continues. This could happen when some big job (tens of thousands of maps using TableInputFormat) starts.&lt;/p&gt;</comment>
                            <comment id="14625914" author="victorunique" created="Tue, 14 Jul 2015 06:30:18 +0000"  >&lt;p&gt;A variety of applications are using this hbase cluster, and they do not share the same client configurations and retry logic. I&apos;ll use tcpdump to find the guilty application when I come across this issue next time. Thanks for your help, Heng Chen!&lt;/p&gt;</comment>
                            <comment id="14625918" author="chenheng" created="Tue, 14 Jul 2015 06:36:42 +0000"  >&lt;p&gt;you are welcome&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12745130" name="hbase.log" size="10485760" author="victorunique" created="Mon, 13 Jul 2015 21:28:53 +0000"/>
                            <attachment id="12744967" name="jstack.log" size="326365" author="victorunique" created="Sun, 12 Jul 2015 23:30:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Jul 2015 08:25:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 22 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2h5p3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>