<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:47:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7668/HBASE-7668.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7668] I have a hbase problem</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7668</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I have a problem that I have been trap weeks, can somebody can help me?&lt;br/&gt;
 With full of appreciate&lt;br/&gt;
The problem is below:&lt;br/&gt;
I have writed about 1G data to the hbase ,then it does not work.&lt;br/&gt;
when I set the  hadoop dfsadmin -safemode leave ,then the hbase can use &quot;list&quot; command,but when i use &quot;count &apos;tableTest&apos; or get ,put and so on ,finaly ,It tell me below&#65306;&lt;/p&gt;

&lt;p&gt;hbase(main):002:0&amp;gt; count &apos;zsfTest&apos;&lt;/p&gt;

&lt;p&gt;ERROR: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: &lt;del&gt;ROOT&lt;/del&gt;,,0&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2862)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1768)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1336)&lt;/p&gt;

&lt;p&gt;Here is some help for this command:&lt;br/&gt;
Courows in a table. This operation may take a LONG&lt;br/&gt;
time (Run &apos;$HADOOP_HOME/bin/hadoop jar hbase.jar rowcount&apos; to run a&lt;br/&gt;
counting mapreduce job). Current count is shown every 1000 rows by&lt;br/&gt;
default. Count interval may be optionally specified. Scan caching&lt;br/&gt;
is enabled on count scans by default. Default cache size is 10 rows.&lt;br/&gt;
If your rows are small in size, you may want to increase this&lt;br/&gt;
parameter. Examples:&lt;/p&gt;

&lt;p&gt; hbase&amp;gt; count &apos;t1&apos;&lt;br/&gt;
 hbase&amp;gt; count &apos;t1&apos;, INTERVAL =&amp;gt; 100000&lt;br/&gt;
 hbase&amp;gt; count &apos;t1&apos;, CACHE =&amp;gt; 1000&lt;br/&gt;
 hbase&amp;gt; count &apos;t1&apos;, INTERVAL =&amp;gt; 10, CACHE =&amp;gt; 1000&lt;/p&gt;


&lt;p&gt;hbase(main):003:0&amp;gt; &lt;/p&gt;</description>
                <environment></environment>
        <key id="12629205">HBASE-7668</key>
            <summary>I have a hbase problem</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="zsflove">&#24352;&#21452;&#31119;</reporter>
                        <labels>
                    </labels>
                <created>Fri, 25 Jan 2013 01:47:47 +0000</created>
                <updated>Fri, 25 Jan 2013 05:45:38 +0000</updated>
                            <resolved>Fri, 25 Jan 2013 05:45:38 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13562270" author="zsflove" created="Fri, 25 Jan 2013 01:54:22 +0000"  >&lt;p&gt;the log:hbase-root-regionserver-yun1.c******ft.com.cn.log &lt;br/&gt;
2 IOException, will wait for 5281.083434829379 msec.&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:351)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:113)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:266)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:197)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:165)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;/p&gt;

&lt;p&gt;and :&lt;br/&gt;
 at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:644)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:437)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:577)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at java.io.DataInputStream.readFully(DataInputStream.java:178)&lt;br/&gt;
        at java.io.DataInputStream.readFully(DataInputStream.java:152)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1781)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1746)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1695)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1709)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader.&amp;lt;init&amp;gt;(SequenceFileLogReader.java:58)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.init(SequenceFileLogReader.java:166)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog.getReader(HLog.java:659)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:846)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:759)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:384)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:351)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:113)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:266)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:197)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:165)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;/p&gt;

&lt;p&gt;and:&lt;br/&gt;
2013-01-25 09:53:14,261 DEBUG org.apache.hadoop.hbase.regionserver.SplitLogWorker: tasks arrived or departed&lt;/p&gt;
</comment>
                            <comment id="13562272" author="zsflove" created="Fri, 25 Jan 2013 02:00:21 +0000"  >&lt;p&gt;the master log :hbase-root-master-yun1.***.com.cn.log&lt;br/&gt;
2013-01-24 09:19:39,979 INFO org.apache.hadoop.hbase.master.ActiveMasterManager: Master=172.17.32.81,60000,1358990379321&lt;br/&gt;
2013-01-24 09:19:40,509 WARN org.apache.hadoop.conf.Configuration: fs.default.name is deprecated. Instead, use fs.defaultFS&lt;br/&gt;
2013-01-24 09:19:40,513 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: timeout = 25000&lt;br/&gt;
2013-01-24 09:19:40,513 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: unassigned timeout = 180000&lt;br/&gt;
2013-01-24 09:19:40,517 INFO org.apache.hadoop.hbase.master.SplitLogManager: found 0 orphan tasks and 0 rescan nodes&lt;br/&gt;
2013-01-24 09:19:40,591 INFO org.apache.hadoop.hbase.util.FSUtils: Waiting for dfs to exit safe mode...&lt;br/&gt;
2013-01-24 09:19:50,593 INFO org.apache.hadoop.hbase.util.FSUtils: Waiting for dfs to exit safe mode...&lt;br/&gt;
2013-01-24 09:20:00,595 INFO org.apache.hadoop.hbase.util.FSUtils: Waiting for dfs to exit safe mode...&lt;/p&gt;

&lt;p&gt;But&#65281;&#65281;&#65281;&#65281;&#65281;&#65281;&#65281;&#65281;&#65281;&#65281;I have choose leave the safe model &lt;br/&gt;
2013-01-24 09:19:39,979 INFO org.apache.hadoop.hbase.master.ActiveMasterManager: Master=172.17.32.81,60000,1358990379321&lt;br/&gt;
2013-01-24 09:19:40,509 WARN org.apache.hadoop.conf.Configuration: fs.default.name is deprecated. Instead, use fs.defaultFS&lt;br/&gt;
2013-01-24 09:19:40,513 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: timeout = 25000&lt;br/&gt;
2013-01-24 09:19:40,513 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: unassigned timeout = 180000&lt;br/&gt;
2013-01-24 09:19:40,517 INFO org.apache.hadoop.hbase.master.SplitLogManager: found 0 orphan tasks and 0 rescan nodes&lt;br/&gt;
2013-01-24 09:19:40,591 INFO org.apache.hadoop.hbase.util.FSUtils: Waiting for dfs to exit safe mode...&lt;br/&gt;
2013-01-24 09:19:50,593 INFO org.apache.hadoop.hbase.util.FSUtils: Waiting for dfs to exit safe mode...&lt;br/&gt;
2013-01-24 09:20:00,595 INFO org.apache.hadoop.hbase.util.FSUtils: Waiting for dfs to exit safe mode...&lt;/p&gt;

&lt;p&gt;I have commit the :hadoop dfsadmin -safemode leave&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;root@yun1 logs&amp;#93;&lt;/span&gt;#  hadoop dfsadmin -safemode get&lt;br/&gt;
DEPRECATED: Use of this script to execute hdfs command is deprecated.&lt;br/&gt;
Instead use the hdfs command for it.&lt;/p&gt;

&lt;p&gt;Safe mode is OFF&lt;/p&gt;

&lt;p&gt;Can anyone tell me ,with  full of appreciate,&lt;br/&gt;
god bless you. &lt;sup&gt;_&lt;/sup&gt;&lt;/p&gt;</comment>
                            <comment id="13562309" author="yuzhihong@gmail.com" created="Fri, 25 Jan 2013 02:47:45 +0000"  >&lt;p&gt;JIRA is not the place to discuss such problems, unless we identify deficiency in the code.&lt;/p&gt;

&lt;p&gt;Please provide a summary, including versions of hadoop and HBase you&apos;re using, and post on user@hbase.apache.org&lt;br/&gt;
You can put log snippet on pastebin and refer to the URL so that people get to know the overall problem.&lt;/p&gt;</comment>
                            <comment id="13562445" author="stack" created="Fri, 25 Jan 2013 05:45:38 +0000"  >&lt;p&gt;Please ask your question up on the mailing list as Ted says.  More folks will see your question if you put it there.  Resolving as invalid.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 25 Jan 2013 02:47:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>309049</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 47 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1dyn3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>289709</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>