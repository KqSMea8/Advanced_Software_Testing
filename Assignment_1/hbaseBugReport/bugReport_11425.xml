<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:23:06 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-11425/HBASE-11425.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-11425] Cell/DBB end-to-end on the read-path</title>
                <link>https://issues.apache.org/jira/browse/HBASE-11425</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Umbrella jira to make sure we can have blocks cached in offheap backed cache. In the entire read path, we can refer to this offheap buffer and avoid onheap copying.&lt;br/&gt;
The high level items I can identify as of now are&lt;br/&gt;
1. Avoid the array() call on BB in read path.. (This is there in many classes. We can handle class by class)&lt;br/&gt;
2. Support Buffer based getter APIs in cell.  In read path we will create a new Cell with backed by BB. Will need in CellComparator, Filter (like SCVF), CPs etc.&lt;br/&gt;
3. Avoid KeyValue.ensureKeyValue() calls in read path - This make byte copy.&lt;br/&gt;
4. Remove all CP hooks (which are already deprecated) which deal with KVs.  (In read path)&lt;/p&gt;

&lt;p&gt;Will add subtasks under this.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12724166">HBASE-11425</key>
            <summary>Cell/DBB end-to-end on the read-path</summary>
                <type id="14" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Umbrella</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="anoopsamjohn">Anoop Sam John</assignee>
                                    <reporter username="anoop.hbase">Anoop Sam John</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Jun 2014 17:19:19 +0000</created>
                <updated>Fri, 11 Nov 2016 05:16:16 +0000</updated>
                            <resolved>Thu, 28 Jan 2016 05:21:38 +0000</resolved>
                                    <version>0.99.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>regionserver</component>
                    <component>Scanners</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>27</watches>
                                                                                                            <comments>
                            <comment id="14046164" author="anoop.hbase" created="Fri, 27 Jun 2014 17:19:50 +0000"  >&lt;p&gt;Now one related Q is we go with BR rather than BB for APIs.&lt;/p&gt;</comment>
                            <comment id="14046224" author="apurtell" created="Fri, 27 Jun 2014 18:20:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Now one related Q is we go with BR rather than BB for APIs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;We need BR instead of BB to work around issues with BB API issues: inlining pessimism, range checking and index compensations that cannot be skipped for performance, and related. &lt;/p&gt;</comment>
                            <comment id="14046726" author="ram_krish" created="Sat, 28 Jun 2014 05:08:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;Avoid KeyValue.ensureKeyValue() calls in read path - This make byte copy.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is the idea for changing to Cells in the read path.  Still there are some places which this was not achieved.  I will those tasks to this.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We need BR instead of BB to work around issues with BB API issues&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.  +1 on t his.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10772&quot; title=&quot;Use ByteRanges instead of ByteBuffers in BlockCache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10772&quot;&gt;&lt;del&gt;HBASE-10772&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10773&quot; title=&quot;Make use of ByteRanges in HFileBlock instead of ByteBuffers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10773&quot;&gt;&lt;del&gt;HBASE-10773&lt;/del&gt;&lt;/a&gt; are all those related to this. I can link the related tasks to this JIRA to have a clear picture on the subtasks.&lt;/p&gt;</comment>
                            <comment id="14046730" author="ram_krish" created="Sat, 28 Jun 2014 05:12:19 +0000"  >&lt;p&gt;All the subtasks under &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7320&quot; title=&quot;Remove KeyValue.getBuffer()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7320&quot;&gt;HBASE-7320&lt;/a&gt; are in some way helping this.  Few more may be needed here.&lt;/p&gt;</comment>
                            <comment id="14047396" author="stack" created="Mon, 30 Jun 2014 05:36:44 +0000"  >&lt;p&gt;Thanks for filing this one and yeah lets finish up the Cell convertions.&lt;/p&gt;

&lt;p&gt;How we thinking to back Cells w/ bytes that are back in the block cache?  Currently we copy the block cache bytes onheap to guard against the blocks being evicted out from under us.  We&apos;ll do reference counting?&lt;/p&gt;

&lt;p&gt;Any idea of how much slower an offheap merge sort will be doing BB#get (or BR#get)?  I&apos;m up for doing a bit of measuring....&lt;/p&gt;
</comment>
                            <comment id="14047590" author="ram_krish" created="Mon, 30 Jun 2014 12:02:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;Currently we copy the block cache bytes onheap to guard against the blocks being evicted out from under us. We&apos;ll do reference counting?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think this is one major area where we may have to work. If a block is currently getting scanned set a reference and do not evict them.  On what basis should we select the next block that can be evicted ? Need to do some more analysis on this.&lt;br/&gt;
Interesting!!.&lt;/p&gt;</comment>
                            <comment id="14050050" author="anoop.hbase" created="Wed, 2 Jul 2014 15:37:55 +0000"  >&lt;p&gt;Yes we need ref counting.  The MemstoreSlab chunk pool is having a similar need and doing the ref counting way.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Any idea of how much slower an offheap merge sort will be doing BB#get (or BR#get)? I&apos;m up for doing a bit of measuring....&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not done any compare test.  Will do some plain test doing just key compare(millions of times) reading from DBB and HBB(This will use the unsafe compare).  Got into some bug fixes on visibility.  Will start again next week.  That will be great if u can measure boss.&lt;/p&gt;</comment>
                            <comment id="14073043" author="anoop.hbase" created="Thu, 24 Jul 2014 09:44:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;We need BR instead of BB to work around issues with BB API issues: inlining pessimism, range checking and index compensations that cannot be skipped for performance, and related. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. So we will have our own written HeapBB/DirectBB stuff than just wrapping the nio objects.&lt;/p&gt;</comment>
                            <comment id="14077656" author="anoop.hbase" created="Tue, 29 Jul 2014 12:17:34 +0000"  >&lt;p&gt;Testing with a 2 million Cells with single cell per row.&lt;br/&gt;
Writing all cells to a BB/DBB and trying a seek with to last kv. (To make compare across all cells in BB/DBB)&lt;br/&gt;
Seek code is like what we have in ScannerV3#blockSeek&lt;/p&gt;

&lt;p&gt;with RK length 17 bytes (1st 13 bytes are same) Getting almost same  result.&lt;br/&gt;
With RK length 117 bytes (1st 113 bytes are same) the DBB based read is ~3% degrade.&lt;/p&gt;</comment>
                            <comment id="14077868" author="apurtell" created="Tue, 29 Jul 2014 15:54:03 +0000"  >&lt;p&gt;This is with BB or BR? How about 1kb RKs?&lt;/p&gt;</comment>
                            <comment id="14077898" author="anoop.hbase" created="Tue, 29 Jul 2014 16:10:53 +0000"  >&lt;p&gt;BB only.  And not the actual read perf number. Just the seek part and so reads from BB vs DBB&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;How about 1kb RKs?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Will test more cases.&lt;/p&gt;</comment>
                            <comment id="14077940" author="apurtell" created="Tue, 29 Jul 2014 16:33:20 +0000"  >&lt;p&gt;Does it make a difference if using the BR API instead?&lt;/p&gt;</comment>
                            <comment id="14077991" author="stack" created="Tue, 29 Jul 2014 17:11:07 +0000"  >&lt;p&gt;Nice &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; Mind posting your little test tool so can run local?&lt;/p&gt;</comment>
                            <comment id="14184075" author="anoop.hbase" created="Sat, 25 Oct 2014 12:25:21 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Testing with a 2 million Cells with single cell per row.&lt;br/&gt;
Writing all cells to a BB/DBB and trying a seek with to last kv. (To make compare across all cells in BB/DBB)&lt;br/&gt;
Seek code is like what we have in ScannerV3#blockSeek&lt;br/&gt;
with RK length 17 bytes (1st 13 bytes are same) Getting almost same result.&lt;br/&gt;
With RK length 117 bytes (1st 113 bytes are same) the DBB based read is ~3% degrade&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Well in this test, the read and compare were from HBB and DBB and those are almost same. &lt;br/&gt;
In case of our CellComparator we have Unsafe based optimization. In my old test this was not in use.  With Unsafe based read from HBB#array() &lt;span class=&quot;error&quot;&gt;&amp;#91;this is what happens in HFileReaderV2/V3&amp;#93;&lt;/span&gt; there is a significant perf diff with DBB. Here RK length of 117 bytes and 2 millions cells and we seek to last cell, the DBB test is 50% slower. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I am thinking of doing Unsafe based compares for data in DBB as well.&lt;/p&gt;

&lt;p&gt;Just done Unsafe based access from DBB/HBB and then we are in a better shape. The DBB based above test is ~12% slower than old HBB.array() based compares. Will raise a subtask and attach the approach there.&lt;/p&gt;</comment>
                            <comment id="14352889" author="ram_krish" created="Mon, 9 Mar 2015 12:34:26 +0000"  >&lt;p&gt;A document explaining the motive, the design considerations, the reason for arriving at BB and the Cell level APIS changes required for supporting offheap memory in HBase&apos;s read path.&lt;br/&gt;
We will be uploading a patch ported to trunk shortly by the end of this week or early next week. Along with some perf results. &lt;br/&gt;
Request feedback/comments on the doc and the approach.&lt;/p&gt;</comment>
                            <comment id="14352989" author="apache9" created="Mon, 9 Mar 2015 13:54:11 +0000"  >&lt;p&gt;I&apos;m still a little worried about the ref counting part as I said before.&lt;br/&gt;
Sometimes it could be a disaster for later developers because it is easy to miss a decrement but very hard to know a problem is caused by missing a decrement, and even we know, it is hard to find where we miss it...&lt;br/&gt;
Let&apos;s see the code, maybe we could find a way to handle it cleanly.&lt;/p&gt;

&lt;p&gt;BTW, it should be a typo, you mean &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13142&quot; title=&quot;[PERF] Reuse the IPCUtil#buildCellBlock buffer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13142&quot;&gt;&lt;del&gt;HBASE-13142&lt;/del&gt;&lt;/a&gt; at the end of the document? We do not have &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13412&quot; title=&quot;Region split decisions should have jitter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13412&quot;&gt;&lt;del&gt;HBASE-13412&lt;/del&gt;&lt;/a&gt; yet.&lt;/p&gt;</comment>
                            <comment id="14352996" author="anoop.hbase" created="Mon, 9 Mar 2015 13:58:51 +0000"  >&lt;p&gt;The ref count and increment/decrement happens in one place.  You can get more when seeing code.&lt;br/&gt;
Yes it should be &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13412&quot; title=&quot;Region split decisions should have jitter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13412&quot;&gt;&lt;del&gt;HBASE-13412&lt;/del&gt;&lt;/a&gt; yet. Thanks for correcting.&lt;/p&gt;</comment>
                            <comment id="14353001" author="apache9" created="Mon, 9 Mar 2015 14:02:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopsamjohn&quot; class=&quot;user-hover&quot; rel=&quot;anoopsamjohn&quot;&gt;Anoop Sam John&lt;/a&gt; increment/decrement in one place sounds good to be.&lt;/p&gt;</comment>
                            <comment id="14355297" author="stack" created="Tue, 10 Mar 2015 17:47:54 +0000"  >&lt;p&gt;Thanks for the writeup. Makes it easier discussing this new dev.&lt;/p&gt;

&lt;p&gt;&quot;Typical used value for max heap size is 32-48 GB.&quot;&lt;/p&gt;

&lt;p&gt;This ain&apos;t right, is it? Usually we have folks hover just below 32G so can do compressed pointers.&lt;/p&gt;

&lt;p&gt;&quot;Each bucket&#8217;s size is fixed to 4KB.&quot;&lt;/p&gt;

&lt;p&gt;Should bucket size be same as the hfile block size?&lt;/p&gt;

&lt;p&gt;Can MBB be developed in isolation with tests and refcounting tests apart from main code base? Is that being done?&lt;/p&gt;

&lt;p&gt;High-level, general question: So eviction was easy before. When memory pressure just evict until needed memory is made available. The eviction is now made more complicated because have to check for non-zero refcount? And what if can&apos;t find necessary memory? What happens?&lt;/p&gt;

&lt;p&gt;&quot;Note that the LRU Cache does not have this block reference counting happening as that does not deal with BBs and deals with the HFileblock objects directly.&quot;&lt;/p&gt;

&lt;p&gt;Why not? We copy from the LRU blocks to Cell arrays? Couldn&apos;t Cells go against the LRU blocks directly too? Or I have it wrong?&lt;/p&gt;

&lt;p&gt;I don&apos;t see a downside listing that we&apos;ll be doubling the objects made when offheap reading. Is that right?&lt;/p&gt;

&lt;p&gt;&quot;Please note that the Cells in the memstore are still KV based (byte [] backed)&quot; ... this is because you are only doing read-path in this JIRA, right? Then again, reading, we have to read from the MemStore so this means that read path can be a mix of onheap and offheap results?&lt;/p&gt;

&lt;p&gt;On adding new methods to Cell, are there &apos;holes&apos;? We talked about this in the past and it seemed like there could be strange areas in the Cell API if you did certain calls. If you don&apos;t know what I am on about, I&apos;ll dig up the old discussion (I think it was on mailing list... Ram you asked for input).&lt;/p&gt;

&lt;p&gt;... or maybe the holes have been plugged by &apos;Using getXXXArray() would throw UnSupportedOperationException. &apos;?  And....&lt;br/&gt;
&quot;This will make so many short living objects creation also. That is why we decided to go with usage of getXXXOffset() and getXXXLength() API usage also along with buffer based APIs&quot;&lt;/p&gt;

&lt;p&gt;So, you might want to underline this point. Its BB but WE are managing the position and length to save on object creation and to bypass BB range checking, etc.&lt;/p&gt;

&lt;p&gt;What does that mean for the &apos;client&apos;?  When you give out a BB, its position, etc., is not to be relied upon.  That will be disorientating.  Pity you couldn&apos;t throw unsupportedexception if they tried use position, etc. So you need BB AND the Cell to get at content. BB for the array and then Cell for the offset and length...&lt;/p&gt;

&lt;p&gt;So, this API is for users on client-side? It is going to confuse them when they have a BB but the position and limit are duds. In client, when would they be doing BB? Never? Client won&apos;t be offheaping? If so, could the BB APIs be mixed in to Cell on the server only?&lt;/p&gt;

&lt;p&gt;So, why have the switch at all? The hasArray switch? Why not BB it all the time? It would simplify the read path.  Disadvantage would be it&apos;d be extra objects?&lt;/p&gt;

&lt;p&gt;When you say this: &quot;Note that even if the HFileBlock is on heap BB we do not support getXXXArray() APIs. &quot; This is only if hasArray returns false, right?&lt;/p&gt;

&lt;p&gt;Yeah, looks like 2.0.&lt;/p&gt;

&lt;p&gt;Tell us more about the unsafe manipulation of BBs? How&apos;s that work?&lt;/p&gt;

&lt;p&gt;Nice writeup.&lt;/p&gt;</comment>
                            <comment id="14355360" author="vrodionov" created="Tue, 10 Mar 2015 18:13:37 +0000"  >&lt;p&gt;I am quite skeptical to all this idea ... Here is why:&lt;/p&gt;

&lt;p&gt;Off heap cache can store blocks in a compressed form. It means that you won&apos;t be able to back HFileBlock by a such compressed block - you have to decompress it first. From performance point of view it does not matter whether you do this into direct BB (new approach) or into a byte array-backed BB (existing).&lt;/p&gt;

&lt;p&gt;Am I missing anything?  &lt;/p&gt;
</comment>
                            <comment id="14355376" author="anoop.hbase" created="Tue, 10 Mar 2015 18:17:49 +0000"  >&lt;p&gt;Having block data in compressed form in the BC is optional thing. In such a case, yes, have to decompress first and at that time, it can be to a byte array backed BB. We are not trying to change that.&lt;br/&gt;
The change is when the data is cached in the non compressed form (But can be in the DBE form). Then avoiding need for copy. The block can be backed by N offheap buckets.  Cells are made out of that. And cells are backed by buffers rather than byte[] then&lt;/p&gt;</comment>
                            <comment id="14355463" author="anoop.hbase" created="Tue, 10 Mar 2015 18:53:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;This ain&apos;t right, is it? Usually we have folks hover just below 32G so can do compressed pointers.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think I have seen in mails some users have 48G also. At least some users who were trying some PoCs.(Offline I met).. Any way can change to ~32G.  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Should bucket size be same as the hfile block size?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I wanted to come to this topic. This is hard coded now. Can this be made configurable? If this can be larger value,like block size, better as per our changes&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Can MBB be developed in isolation with tests and refcounting tests apart from main code base? Is that being done?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yep. When put patches, we can make sure to do this way. Those in sub tasks.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The eviction is now made more complicated because have to check for non-zero refcount? And what if can&apos;t find necessary memory? What happens?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The eviction try evict some unused blocks. If all are like in read (worst case), the new block can not be cached. May be that should be tried after a delay? &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Why not? We copy from the LRU blocks to Cell arrays? Couldn&apos;t Cells go against the LRU blocks directly too? Or I have it wrong?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In the LRU we cache the block object itself. It has its own underlying memory. Even if an in read progress block is evicted, the memory area it refers to , is not freed. Only thing is that after this read, that block will not be referenced and so the block data area too. Am I making it clear?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I don&apos;t see a downside listing that we&apos;ll be doubling the objects made when offheap reading. Is that right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In read say we deal with N HFileBlock, we will be having extra objects MBB objects created for each block.  But per cell we wont create any new objects. In comparators etc, we check hasArray() and based on that use the buffer/array based APIs.   When creating BB backed cells from an HFileBlock which is backed by MBB, we try best to refer to original BB (and item in MBB) and not create/duplicate extra BBs.  But  yes some etra objects will be there. (duplicated BBs)  I can give a count based on a test scenario Stack. Was in middle of some thing else and missed doing this.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;have to read from the MemStore so this means that read path can be a mix of onheap and offheap results?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;or maybe the holes have been plugged by &apos;Using getXXXArray() would throw UnSupportedOperationException. &apos;? And....&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yep.  If the Cell impl is backed by a BB (on heap/off heap) its getXXXArray APIs will throw UnSupportedOperationException&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So, you might want to underline this point. Its BB but WE are managing the position and length to save on object creation and to bypass BB range checking, etc&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. correct&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Client won&apos;t be offheaping? If so, could the BB APIs be mixed in to Cell on the server only?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Some thing like a ServerCell which extend Cell? Sounds reasonable..  Have some discuss like this also. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So, why have the switch at all? The hasArray switch? Why not BB it all the time? It would simplify the read path. Disadvantage would be it&apos;d be extra objects?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes the extra BB wrapper which has to be created every time one calls getXXXArray().  It is an extra obj creation and some ops (like limit, pos checks) which happens in the BB classes. That is bit costly only. Had done some Unit tests. Ram have the numbers or so?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;When you say this: &quot;Note that even if the HFileBlock is on heap BB we do not support getXXXArray() APIs. &quot; This is only if hasArray returns false, right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes when hasArray return false. The point is when the Cell is backed by a buffer then we will have hasArray as false. (whether DBB/HBB)&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Tell us more about the unsafe manipulation of BBs? How&apos;s that work?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It reads data from BB bypassing the BB APIs. Directly read from memory. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12345&quot; title=&quot;Unsafe based ByteBuffer Comparator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12345&quot;&gt;&lt;del&gt;HBASE-12345&lt;/del&gt;&lt;/a&gt; having a patch which add Unsafe based compare for data in BB.  Similar way added for reading int/long etc.  Same we do for bytes in Bytes.java&lt;/p&gt;</comment>
                            <comment id="14355465" author="stack" created="Tue, 10 Mar 2015 18:53:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sortof.&lt;/p&gt;

&lt;p&gt;This effort takes us further along a couple of paths. There is the foreground being able to have most of the data offheap when reading. An ancillary is proving an alternate Cell implementation is possible, one that is other than KeyValue.&lt;/p&gt;

&lt;p&gt;After the lads have the above behind us, we can move to the next interesting challenges. For example, a PrefixTree Cell implementation that keeps the key and value encoded/compressed as we traverse the read path.&lt;/p&gt;

&lt;p&gt;Regards the particular point you raise, yeah, would have to decompress currently do put this read-path on top of it. Would be cool if decompress could be done with native code before we the brought the block into BC.&lt;/p&gt;

&lt;p&gt;TODO&lt;/p&gt;
</comment>
                            <comment id="14355478" author="vrodionov" created="Tue, 10 Mar 2015 18:59:52 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The change is when the data is cached in the non compressed form (But can be in the DBE form)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, if the goal of this JIRA performance improvement, have you estimate the following scenarios:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;DBE - ON, block compression - OFF (byte array end-to-end  - BA)&lt;/li&gt;
	&lt;li&gt;DBE - OFF, block compression - OFF (BA)&lt;/li&gt;
	&lt;li&gt;DBE - ON, block compression - ON (BA)&lt;/li&gt;
	&lt;li&gt;DBE - OFF, block compression - ON (BA)&lt;/li&gt;
	&lt;li&gt;DBE - ON, block compression - OFF (byte buffer end-to-end  - BB)&lt;/li&gt;
	&lt;li&gt;DBE - OFF, block compression - OFF (BB)&lt;/li&gt;
	&lt;li&gt;DBE - ON, block compression - ON (BB)&lt;/li&gt;
	&lt;li&gt;DBE - OFF, block compression - ON (BB)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;You optimize No 5 use case only. Do you think its going to be faster than any of first four (BA)? People like compression, especially if it does not affect benchmark performance too much and helps them with their application. Essentially, you advise users not to use compression and use only DBE, but all scan operations and get/multi get take performance hit with DBE enabled. I think No. 4 (DBE - OFF, block compression ON, byte array backed) is going to be faster than No. 5 (DBE - ON, block compression OFF , byte buffer - backed) in any benchmark.&lt;/p&gt;

&lt;p&gt;These are my words of caution ... before you start such a large project - make sure that benefits you are hoping for are really possible.&lt;/p&gt;</comment>
                            <comment id="14355484" author="vrodionov" created="Tue, 10 Mar 2015 19:05:01 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Would be cool if decompress could be done with native code before we the brought the block into BC.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;bigbase.org does that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Block Cache compression is all native.  Unfortunately, do not have time to continue working on this project now, may be in a near future.&lt;/p&gt;</comment>
                            <comment id="14355488" author="vrodionov" created="Tue, 10 Mar 2015 19:07:10 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think No. 4 (DBE - OFF, block compression ON, byte array backed) is going to be faster than No. 5 (DBE - ON, block compression OFF , byte buffer - backed) in any benchmark.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;in &lt;b&gt;almost&lt;/b&gt; any. Scan with lots of skips will be faster when block compression is off, I think.&lt;/p&gt;</comment>
                            <comment id="14355497" author="stack" created="Tue, 10 Mar 2015 19:10:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;I wanted to come to this topic. This is hard coded now. Can this be made configurable? If this can be larger value,like block size, better as per our changes&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, configurable sounds right but thinking on it more, rare will be the case that the fuzzy hfile block will fit into the BC hard-coded block.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;May be that should be tried after a delay?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Would this be a new block type? One that is not backed by BC?  No on delay.  Flag its happening and move on. It&apos;d be an offheap allocation I suppose so will be delay enough (smlie).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Am I making it clear?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Some thing like a ServerCell which extend Cell? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We can&apos;t give users an API that has you get data from a BB but you need to use the enclosing Cell to figure where to read from and how much. Users will kick us out!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yes the extra BB wrapper which has to be created every time one calls getXXXArray().&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Would be interesting to see cost. Would be sweet if only one readpath... but I&apos;d imagine the perf difference will be too great so we&apos;ll have to have two.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It reads data from BB bypassing the BB APIs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Add this to doc.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;



</comment>
                            <comment id="14355502" author="stack" created="Tue, 10 Mar 2015 19:13:22 +0000"  >&lt;p&gt;I like &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; &apos;s grid. If only for illustration of where you are focused, suggest you add to the doc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; Would be good to get some answers on his questions too.&lt;/p&gt;

&lt;p&gt;BigBase open source Vladimir?&lt;/p&gt;</comment>
                            <comment id="14355518" author="vrodionov" created="Tue, 10 Mar 2015 19:20:48 +0000"  >&lt;blockquote&gt;
&lt;p&gt;BigBase open source Vladimir?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, but is not Apache. yet .&lt;/p&gt;</comment>
                            <comment id="14356182" author="ram_krish" created="Wed, 11 Mar 2015 03:36:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should bucket size be same as the hfile block size?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. that would be better in many cases how ever the odd blocks may go beyond the hfile block size.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Can MBB be developed in isolation with tests and refcounting tests apart from main code base? Is that being done?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We need some tests for the refcounting part. Apart from that they can be individual tasks as Anoop says.&lt;/p&gt;

&lt;p&gt;Reg the BB and comparators having two paths, that would be the ideal way as per the profiler reports.  That is because for all the KVs that is coming from the HHFiles we have Buffer backed cells. But for the cells in memstore is byte[]. So as mentioned in the doc, if we try to create only BB based rows, families and qualifiers, we may have to do wrapping of these byte[]. That is a costlier operation.  Also in cases of creating fake keys it is always better to create fake keys in byte[] rather than in BB because for BB&apos;s we have to do some allocation and then copy the contents. All these are costlier.&lt;br/&gt;
Hence when we create a fake key and compare it against a key from HFile we have two version of cells. One backed by byte[] and another  by BB. So it would be better if/else based comparisons.  &lt;/p&gt;


&lt;p&gt;Reg the Unsafe comparators,&lt;br/&gt;
They are just the same as in byte[] array now.  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So, you might want to underline this point. Its BB but WE are managing the position and length to save on object creation and to bypass BB range checking, etc.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. That is the important decision that we had to make.  One objective is to reduce the objects creation and another is to use the same APIs for offset and length.  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Client won&apos;t be offheaping? If so, could the BB APIs be mixed in to Cell on the server only?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We discussed on that ServerCell concepts. But I would argue not do that because then the user would have two types of Cells - one on the write path and the other cell on the read path.  I would say that would make things more complex and not much ease of use too.&lt;/p&gt;

&lt;p&gt;I would try to make a trunk based patch and upload for reference.&lt;/p&gt;</comment>
                            <comment id="14356184" author="ram_krish" created="Wed, 11 Mar 2015 03:39:34 +0000"  >&lt;p&gt;Adding to what Anoop says, we are not trying to focus on where we do compression. That part remains the same.  It is only after we start using an Hfileblock we tend to use it in a offheap mode and particularly avoid the copy that happens in the BucketCache every time a block needs to be used. (In this case it is going to be a decompressed block only).&lt;br/&gt;
But one point to note here is that in the case of DBE it is an encoded block - and we still go on with the encoded block only and the existing logic of decoding the block still works the same way.&lt;br/&gt;
In the existing code there are two copies that happen here - one from the BucketCache and other in the DBE algo.&lt;br/&gt;
Now we try to avoid the first one.&lt;/p&gt;
</comment>
                            <comment id="14356187" author="ram_krish" created="Wed, 11 Mar 2015 03:41:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would be good to get some answers on his questions too.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I could take that IA.  Get some tests in this area to be more clear on this.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;If only for illustration of where you are focused, suggest you add to the doc&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure. Would also ensure the other points that were specifically discussed gets added to the doc.&lt;/p&gt;</comment>
                            <comment id="14356281" author="anoop.hbase" created="Wed, 11 Mar 2015 04:41:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;We discussed on that ServerCell concepts. But I would argue not do that because then the user would have two types of Cells - one on the write path and the other cell on the read path. I would say that would make things more complex and not much ease of use too.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No here what I mean is the Cell interface wont change and at client side, the user will still interact with Cell. ServerCell is an extension for Cell which is only at server side. Both in read and write paths. Only thing is that the CP and Filter will get a new type then. ServerCell instead of Cell.&lt;/p&gt;</comment>
                            <comment id="14356290" author="stack" created="Wed, 11 Mar 2015 04:48:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;On this &quot;But I would argue not do that because then the user would have two types of Cells - one on the write path and the other cell on the read path.&quot;, expecting clients to use BB in a wonky way is not on (smile). I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; cleaned up what is meant.&lt;/p&gt;</comment>
                            <comment id="14356459" author="anoop.hbase" created="Wed, 11 Mar 2015 08:01:50 +0000"  >&lt;p&gt;You say about this case hbase.block.data.cachecompressed = true right?   Yes this recently added feature allow to keep block data in compressed form in BC. When this block is read from BC, these happens&lt;br/&gt;
 Step 1 : We create a new on heap buffer and copy compressed data from buckets into it. Make an HFileBlock backed by this compressed data&lt;br/&gt;
 Step 2 : Unpack this block. Then we will create a new byte[] with size equal to the uncompresed data size for this block. The Compress algo will do uncompress of the block data into this new buffer&lt;/p&gt;

&lt;p&gt;As in our changes we avoid this step 1 new buffer and copy need. We create a block backed by MBB. We have new InputStream over MBB and pass that for uncomress.  Yes Step 2 will be still there.&lt;br/&gt;
So adv here also. Make some sense?&lt;/p&gt;</comment>
                            <comment id="14356461" author="anoop.hbase" created="Wed, 11 Mar 2015 08:03:17 +0000"  >&lt;p&gt;You mean for all these case, the data is already cached and come from BC? Or direct read from DFS?&lt;/p&gt;</comment>
                            <comment id="14366911" author="anoop.hbase" created="Wed, 18 Mar 2015 10:08:09 +0000"  >&lt;p&gt;Attaching an E2E patch for reference. Still some more cleanups we are doing.  Also avoiding some code duplication still in patch.&lt;/p&gt;</comment>
                            <comment id="14367500" author="ram_krish" created="Wed, 18 Mar 2015 17:18:19 +0000"  >&lt;p&gt;Not able to add to RB.  The RB tool hangs when we try to add a patch.&lt;/p&gt;</comment>
                            <comment id="14380193" author="ram_krish" created="Wed, 25 Mar 2015 16:41:57 +0000"  >&lt;p&gt;Any comments/suggestions on the E2E patch attached.  We are working on refining the patch such that some more cases where we need to clearly distinguish the getXXXArray and getXXXBB methods.  Suggestions on the above patch would help us greatly.&lt;/p&gt;</comment>
                            <comment id="14388353" author="ram_krish" created="Tue, 31 Mar 2015 10:41:23 +0000"  >&lt;p&gt;Updated patch handling cases of ByteBuffers and byte[] through out read the path and some refactoring also done.  Still may not be the final patch. But more suitable for reviews.&lt;/p&gt;</comment>
                            <comment id="14388355" author="ram_krish" created="Tue, 31 Mar 2015 10:45:57 +0000"  >&lt;p&gt;RB link &lt;a href=&quot;https://reviews.apache.org/r/32687/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/32687/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14388541" author="hadoopqa" created="Tue, 31 Mar 2015 13:42:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12708404/HBASE-11425.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12708404/HBASE-11425.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit f1f4b6618334767d0da0f47965309b21676e7e9f.&lt;br/&gt;
  ATTACHMENT ID: 12708404&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 246 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 63 javac compiler warnings (more than the master&apos;s current 46 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 14 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 2050 checkstyle errors (more than the master&apos;s current 1926 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +    ByteBufferUtils.copyFromBufferToByteArray(val, getValueBuffer(), getValueOffset(), 0, getValueLength());&lt;br/&gt;
+    ByteBufferUtils.copyFromBufferToByteArray(fam, getFamilyBuffer(), getFamilyOffset(), 0, getFamilyLength());&lt;br/&gt;
+    ByteBufferUtils.copyFromBufferToByteArray(qual, getQualifierBuffer(), getQualifierOffset(), 0, getQualifierLength());&lt;br/&gt;
+    ByteBufferUtils.copyFromBufferToByteArray(row, getRowBuffer(), getRowOffset(), 0, getRowLength());&lt;br/&gt;
+      ByteBufferUtils.copyFromBufferToByteArray(minimumMidpointArray, right, rightOffset, 0, diffIdx + 1);&lt;br/&gt;
+        ByteBufferUtils.copyFromBufferToByteArray(minimumMidpointArray, left, leftOffset, 0, diffIdx);&lt;br/&gt;
+        ByteBufferUtils.copyFromBufferToByteArray(minimumMidpointArray, right, rightOffset, 0, diffIdx + 1);&lt;br/&gt;
+    return matchingFamily(left, left.getFamilyOffset(), left.getFamilyLength(), buf, offset, length);&lt;br/&gt;
+          cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength(), cell.getQualifierArray(),&lt;br/&gt;
+  public static int findCommonPrefixInQualifierPart(Cell left, Cell right, int qualifierCommonPrefix) {&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13505//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14390984" author="stack" created="Wed, 1 Apr 2015 17:02:34 +0000"  >&lt;p&gt;The patch is too big. I&apos;m 7 pages in on a 13 page review. Could we piecemeal it?&lt;/p&gt;</comment>
                            <comment id="14391000" author="anoop.hbase" created="Wed, 1 Apr 2015 17:10:40 +0000"  >&lt;p&gt;Basically we have to split it into Sub patches..  This we posted so that&lt;br/&gt;
there can be a look and understanding on the general approach..  I think&lt;br/&gt;
you got to that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Any way we got some good feedback..  We are working on&lt;br/&gt;
that..  The ServerCell stuff am doing. In a day more I can put up some&lt;br/&gt;
thing so that we can know what is the changes...  Pls stay tuned..&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Anoop&lt;/del&gt;&lt;/p&gt;

</comment>
                            <comment id="14391030" author="ram_krish" created="Wed, 1 Apr 2015 17:26:03 +0000"  >&lt;p&gt;Yes Stack. We have plans to split up the patch. But the most challenging part is how to split it up and in what order?  &lt;br/&gt;
Few tasks like Cell API changes, Ref Counting, MultiByteBuffer class can all be added individually. But the rest are all inter wined.  We can think of a strategy to do it.&lt;/p&gt;

&lt;p&gt;Thanks for having a look.  We are parallel\y working on the review comments too.&lt;/p&gt;</comment>
                            <comment id="14391033" author="ram_krish" created="Wed, 1 Apr 2015 17:26:57 +0000"  >&lt;p&gt;Also this patch would need certain public facing APIs to be deprecated and new ones to be added. That can be done as a seperate task too.&lt;/p&gt;</comment>
                            <comment id="14483658" author="stack" created="Tue, 7 Apr 2015 18:11:09 +0000"  >&lt;p&gt;So, what is going on with this patch now? You want the CellComparator patch in first &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10800&quot; title=&quot;Use CellComparator instead of KVComparator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10800&quot;&gt;&lt;del&gt;HBASE-10800&lt;/del&gt;&lt;/a&gt;? Let me look at ServerCell patch too.&lt;/p&gt;</comment>
                            <comment id="14484678" author="anoop.hbase" created="Wed, 8 Apr 2015 04:07:37 +0000"  >&lt;p&gt;Yes, I would say we deal with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10800&quot; title=&quot;Use CellComparator instead of KVComparator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10800&quot;&gt;&lt;del&gt;HBASE-10800&lt;/del&gt;&lt;/a&gt; first and then the ServerCell and then come to this Jira.&lt;/p&gt;</comment>
                            <comment id="14493712" author="stack" created="Tue, 14 Apr 2015 07:19:59 +0000"  >&lt;p&gt;Took another read of the doc (and above comments on it).&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;(Continuing from comments above), suggest adding to the doc estimation of how many extra objects will be made going this route and  Vladimir&apos;s grid to show what you are focused on.&lt;/li&gt;
	&lt;li&gt;Did you fellas have a look at how others do offheaping or if there were libs you could have made use of? Would have been good to include notes on your findings in here.&lt;/li&gt;
	&lt;li&gt;The section on hasArray (if hasArray is false, it seems to imply hasByteBuffer is true) and the discussion of added APIs and when they come into effect and when they throw unsupported exceptions will need a rewrite in light of feedback above and review of recent patches (API method names I think we&apos;ve cleaned up too).&lt;/li&gt;
	&lt;li&gt;Sounds like you fellas looked at netty ByteBuf too. Add in your findings I&apos;d say.&lt;/li&gt;
	&lt;li&gt;Would have liked to have more detail around the RPC findings. You think it could be different now we have buffer reuse? We could save making a cellblock?&lt;/li&gt;
	&lt;li&gt;Looking at diagrams for perf, I can&apos;t tell if more is better or not. Suggest you write up a summary of what the diagrams are showing.&lt;/li&gt;
	&lt;li&gt;This feature when on, will be for whole server, right? Can&apos;t do by table or region, right?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Thanks lads.&lt;/p&gt;



</comment>
                            <comment id="14493832" author="ram_krish" created="Tue, 14 Apr 2015 09:19:44 +0000"  >&lt;p&gt;We will update all the other things as you have said in the doc.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;You think it could be different now we have buffer reuse? We could save making a cellblock?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We can try once again with buffers reuse.  But still writing multiple cells individually to the socket was the time taking factor which was reduced when we were creating a cell block.&lt;br/&gt;
Will come back to the other comments shortly. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14523448" author="stack" created="Fri, 1 May 2015 16:58:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; The write up is excellent &amp;#8211; especially the bit where you dumb it down listing out conclusion at end of each test and do up the table with all results.  Suggest you do an edit, add a conclusion, and post the jmh files on this issue (I could not open them from the doc) rather than in the doc, and then post a note to dev list pointing at these findings since we are going to build on top of them going forward (we should put it on hbase blog?). Very nice.&lt;/p&gt;

&lt;p&gt;Here are some comments on the doc that might help w/ the edit.&lt;/p&gt;

&lt;p&gt;Suggest you add sentence after first on why we want to go offheap (this will make the doc &apos;standalone&apos;)&lt;/p&gt;

&lt;p&gt;Change: &quot;When we support E2E off heap support and in turn support Cell also backed by off heap memory, we have to make sure to select the best performing data structure/framework for this off heap storage.&quot;&lt;/p&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;p&gt;&quot;When we implement E2E off heap support, we have to make sure to select the best performing data structure/framework.&quot;&lt;/p&gt;

&lt;p&gt;s/below test is/below tests are/&lt;/p&gt;

&lt;p&gt;s/pros like, our PRC layer/pros such as our RPC layer already/&lt;/p&gt;

&lt;p&gt;s/HDFS/an HDFS/&lt;/p&gt;

&lt;p&gt;Change &quot;But the NIO Buffer APIs have complaints over its performance and methods not inlineable&quot;&lt;/p&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;p&gt;But NIO ByteBuffers can be slow (boundary checks and/or some methods may not inline).&lt;/p&gt;

&lt;p&gt;Change: &quot;This make us to think for netty also as it seems better performing. (Really? We have test results below)&quot;&lt;/p&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;p&gt;&quot;This makes us look to Netty ByteBuf as a possibly better performing alternative.&quot;&lt;/p&gt;

&lt;p&gt;On first test, add sentence comparing difference between onheap and offheap runs (onheap looks 30% slower compared to onheap?) Do same comparing jdk8 to jdk7? (Hmm... yeah, would like to see the code... smile)&lt;/p&gt;

&lt;p&gt;s/Similar way/Similarly/&lt;/p&gt;

&lt;p&gt;s/The next test cmopare/The next test compares/&lt;/p&gt;

&lt;p&gt;s/come almost/come out almost/&lt;/p&gt;

&lt;p&gt;s/test what I/test that I/&lt;/p&gt;







</comment>
                            <comment id="14584761" author="stack" created="Sat, 13 Jun 2015 18:29:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopsamjohn&quot; class=&quot;user-hover&quot; rel=&quot;anoopsamjohn&quot;&gt;Anoop Sam John&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; as per chat this morning, post the original word doc and I&apos;ll stick it up in a shared google doc so we can all comment/bang on it... or if you are able, you post it as a google doc. Thanks lads.&lt;/p&gt;</comment>
                            <comment id="14585129" author="anoop.hbase" created="Sun, 14 Jun 2015 17:18:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/1WHLYmccHw28itox4qdeXRgH5SZkt_zruSzngcmmBiUs/edit?usp=sharing&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://docs.google.com/document/d/1WHLYmccHw28itox4qdeXRgH5SZkt_zruSzngcmmBiUs/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14660142" author="hudson" created="Thu, 6 Aug 2015 15:07:24 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6701 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6701/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6701/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14188&quot; title=&quot;Read path optimizations after HBASE-11425 profiling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14188&quot;&gt;&lt;del&gt;HBASE-14188&lt;/del&gt;&lt;/a&gt; - Read path optimizations after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11425&quot; title=&quot;Cell/DBB end-to-end on the read-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11425&quot;&gt;&lt;del&gt;HBASE-11425&lt;/del&gt;&lt;/a&gt; profiling (Ram) (ramkrishna: rev 7a9e10dc11877420c53245c403897d746bebc077)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/OffheapKeyValue.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/test/java/org/apache/hadoop/hbase/TestOffheapKeyValue.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/FilterAllFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/SizeCachedNoTagsKeyValue.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/SizeCachedKeyValue.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/nio/MultiByteBuff.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14693077" author="hudson" created="Wed, 12 Aug 2015 07:52:48 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6717 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6717/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6717/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14188&quot; title=&quot;Read path optimizations after HBASE-11425 profiling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14188&quot;&gt;&lt;del&gt;HBASE-14188&lt;/del&gt;&lt;/a&gt;- Read path optimizations after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11425&quot; title=&quot;Cell/DBB end-to-end on the read-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11425&quot;&gt;&lt;del&gt;HBASE-11425&lt;/del&gt;&lt;/a&gt; profiling- (ramkrishna: rev aa3538f80278f5c0ba1bc8ca903066fa02ac79ec)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/FilterAllFilter.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14957295" author="stack" created="Wed, 14 Oct 2015 17:10:07 +0000"  >&lt;p&gt;Some coarse graphs that run YCSB workload c (total random read) running for an hour with 100 clients against a dataset that is totally cached hosted on one server. The first run is against a RS that is using default, onheap memcache. The second is using bucketcache.&lt;/p&gt;

&lt;p&gt;I see that the work here makes it so using the bucketcache has the same latency and throughput (perhaps a little less throughput) as serving all from onheap (recall that in tests, buckecache as best if there were cache misses... if you could serve all from heap, onheap had a much nicer profile). To me, this makes it possible to run with the bucketcache all the time whether serving all from heap or when cache misses (recall, bucketcache did better when there were cache misses &amp;#8211; I have not looked to see if this work improves on what we saw previous).&lt;/p&gt;

&lt;p&gt;More testing to follow (a redo of our block cache comparisions post might be in order).&lt;/p&gt;

&lt;p&gt;The graphs are gc basic profile (this is CMS), gets per second, the median (the 75th and 95th percentiles weren&apos;t showing up for some reason... need to dig in... hopefully its because their incidence was low...), and overall loading and seeks.&lt;/p&gt;

&lt;p&gt;Offheap puts al little more load on the system, has a better GC profile, and is slightly less throughput.&lt;/p&gt;
</comment>
                            <comment id="14958042" author="stack" created="Thu, 15 Oct 2015 00:00:17 +0000"  >&lt;p&gt;Have you fellas run this for a while? I seem to OOME easy enough. I tried with a small heap, 4G, but it OOME&apos;d then had to keep going back up to 16G again though I had a big offheap.  I tried to capture the increasing use of heap but this diagram is best I got... I&apos;ve not done heap analysis.. but in the diagram you can see heap use start to rise and then plummet... now I am crawling doing Full GCs every couple of seconds.&lt;/p&gt;

&lt;p&gt;The last meaningful log was this in regionserver log:&lt;/p&gt;

&lt;p&gt;2015-10-14 16:51:10,058 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;main-BucketCacheWriter-2&amp;#93;&lt;/span&gt; bucket.BucketCache: This block 3f0157e7daee45fdb25202c496c95c46_1649898813 is still referred by 1 readers. Can not be freed now&lt;/p&gt;

&lt;p&gt;It started complaining 50minutes ago...&lt;/p&gt;


</comment>
                            <comment id="14958230" author="ram_krish" created="Thu, 15 Oct 2015 03:04:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;Have you fellas run this for a while? I seem to OOME easy enough. I tried with a small heap, 4G, but it OOME&apos;d then had to keep going back up to 16G again though I had a big offheap. I tried to capture the increasing use of heap but this diagram is best I got... I&apos;ve not done heap analysis.. but in the diagram you can see heap use start to rise and then plummet... now I am crawling doing Full GCs every couple of seconds.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Argh!! We have run some read related workloads for an hour or so but did not observe any OOMEs. But our heap size was set at 32G. This is the case with YCSB and did not observe any full GCs.&lt;br/&gt;
In case of PE tool we only used 9G heap size and 16G offheap size.  But did not observe any fluctuations in the heap usage. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;2015-10-14 16:51:10,058 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;main-BucketCacheWriter-2&amp;#93;&lt;/span&gt; bucket.BucketCache: This block 3f0157e7daee45fdb25202c496c95c46_1649898813 is still referred by 1 readers. Can not be freed now&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;May be because of OOME some error handling is not done. Let us internally install a cluster to test this. &lt;/p&gt;</comment>
                            <comment id="14958244" author="ram_krish" created="Thu, 15 Oct 2015 03:35:48 +0000"  >&lt;p&gt;BTW - this behaviour are you seeing while doing pure read workload? ie. YCSB workload c?&lt;/p&gt;</comment>
                            <comment id="14958253" author="stack" created="Thu, 15 Oct 2015 03:53:10 +0000"  >&lt;p&gt;Workload c. Try 4g. I don&apos;t see why 4g should not be enough when 7//regions and 8g of offheap and all cache hits. I could be wrong. I have not dug in...&lt;/p&gt;</comment>
                            <comment id="14958406" author="ram_krish" created="Thu, 15 Oct 2015 06:28:46 +0000"  >&lt;p&gt;Tried out the experiments in a new cluster with single node. &lt;br/&gt;
Loaded around 15G of data with 10 regions. &lt;br/&gt;
Initially configured 4G as heap space, offheap space as 5G and the bucket cache size as 4G.&lt;br/&gt;
Ran a pure read workload c for 30 mins.  With 50 threads.  I am not running into OOME and also the block eviction part is fine.  The bigger GCs are around 450ms to 500ms.  Repeated the same experiment with 10 G of heap space also.  With this configuration we are sure that evictions are happening from the bucket cache. Attaching a GC snapshot for 5 mins captured during the workload test. &lt;br/&gt;
Stack, &lt;br/&gt;
Also in your experiment I think your data does not fit into the bucket cache and hence it is trying to evict. Or if it is fitting into the bucket cache, probably that was a file that was trying to get compacted and there was a reader referencing to it and due to the OOME the ref count decrement did not happen and the forceful eviction was failing. Will keep checking this.  Any logs can you attach when this happened?  Easier to debug (hopefully).&lt;/p&gt;</comment>
                            <comment id="14958409" author="ram_krish" created="Thu, 15 Oct 2015 06:32:40 +0000"  >&lt;p&gt;Just checking the code &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Or if it is fitting into the bucket cache, probably that was a file that was trying to get compacted and there was a reader referencing to it and due to the OOME the ref count decrement did not happen and the forceful eviction was failing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This should not be the case. Any way logs will be better. Trying to reproduce this case if possible.&lt;/p&gt;</comment>
                            <comment id="14958505" author="carp84" created="Thu, 15 Oct 2015 08:27:52 +0000"  >&lt;p&gt;From the &quot;Offheap reads in HBase using BBs_V2.pdf&quot; doc, we could see a kind of big perf gap between BucketCache and LRUCache, excerpt as below:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Multiple Gets with 25 threads

                AvgRT     95th   99th
BucketCache     111.81    130    133
LRUCache        23.49     34     39
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But from the latest comments here it seems this data is out of date, right? Mind update the doc with latest perf data? Thanks.&lt;/p&gt;</comment>
                            <comment id="14958587" author="ram_krish" created="Thu, 15 Oct 2015 09:40:24 +0000"  >&lt;p&gt;Yes. We can . We will test once with LRU and bucket cache and see how much diff we have. Thanks.&lt;/p&gt;</comment>
                            <comment id="14958674" author="ram_krish" created="Thu, 15 Oct 2015 10:18:14 +0000"  >&lt;p&gt;I could run with even 2G of heap without OOME. &lt;/p&gt;</comment>
                            <comment id="14958968" author="anoop.hbase" created="Thu, 15 Oct 2015 14:20:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carp84&quot; class=&quot;user-hover&quot; rel=&quot;carp84&quot;&gt;Yu Li&lt;/a&gt;&lt;br/&gt;
I have done a quick multi get test using PE tool default settings (ie. 1 GB data)&lt;br/&gt;
Multi get with 100 rows and 25 client threads and each doing the op 100000 times. &lt;br/&gt;
Avg completion time for each thread&lt;br/&gt;
On heap LRU  Cache (L1)   :  9492ms&lt;br/&gt;
Off heap Bucket Cache (L2):  9596ms&lt;br/&gt;
So it is almost same.&lt;/p&gt;</comment>
                            <comment id="14959007" author="carp84" created="Thu, 15 Oct 2015 14:46:41 +0000"  >&lt;p&gt;Thanks for the update &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, the number looks great and nice work!&lt;/p&gt;

&lt;p&gt;It&apos;s a pity that we have to wait until 2.0 released to take this advantage, maybe months away... &lt;/p&gt;</comment>
                            <comment id="14961322" author="stack" created="Fri, 16 Oct 2015 20:32:57 +0000"  >&lt;p&gt;Seems easy for me to reproduce. Just happened again. Here is the  log.&lt;/p&gt;</comment>
                            <comment id="14961351" author="stack" created="Fri, 16 Oct 2015 20:58:02 +0000"  >&lt;p&gt;The log is not that interesting. It does not even have the eviction issue.  Just shows us struggling w/ GC.  Finally we OOME here:&lt;/p&gt;

&lt;p&gt;2015-10-16T13:16:42.032-0700: [Full GC (Allocation Failure) 2015-10-16T13:16:42.032-0700: &lt;span class=&quot;error&quot;&gt;&amp;#91;CMS: 15276447K-&amp;gt;15276422K(15276480K), 4.9700400 secs&amp;#93;&lt;/span&gt; 16273215K-&amp;gt;16273119K(16273280K), &lt;span class=&quot;error&quot;&gt;&amp;#91;Metaspace: 48934K-&amp;gt;48934K(1093632K)&amp;#93;&lt;/span&gt;, 4.9774537 secs] &lt;span class=&quot;error&quot;&gt;&amp;#91;Times: user=4.97 sys=0.00, real=4.98 secs&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-10-16T13:16:47.012-0700: [Full GC (Allocation Failure) 2015-10-16T13:16:47.012-0700: &lt;span class=&quot;error&quot;&gt;&amp;#91;CMS: 15276422K-&amp;gt;15276422K(15276480K), 1.2150090 secs&amp;#93;&lt;/span&gt; 16273204K-&amp;gt;16273186K(16273280K), &lt;span class=&quot;error&quot;&gt;&amp;#91;Metaspace: 48901K-&amp;gt;48901K(1093632K)&amp;#93;&lt;/span&gt;, 1.2151393 secs] &lt;span class=&quot;error&quot;&gt;&amp;#91;Times: user=1.21 sys=0.00, real=1.22 secs&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-10-16T13:16:48.227-0700: [Full GC (Allocation Failure) 2015-10-16T13:16:48.227-0700: &lt;span class=&quot;error&quot;&gt;&amp;#91;CMS: 15276422K-&amp;gt;15276422K(15276480K), 1.2185531 secs&amp;#93;&lt;/span&gt; 16273186K-&amp;gt;16273186K(16273280K), &lt;span class=&quot;error&quot;&gt;&amp;#91;Metaspace: 48901K-&amp;gt;48901K(1093632K)&amp;#93;&lt;/span&gt;, 1.2186671 secs] &lt;span class=&quot;error&quot;&gt;&amp;#91;Times: user=1.22 sys=0.00, real=1.21 secs&amp;#93;&lt;/span&gt;&lt;br/&gt;
#&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;java.lang.OutOfMemoryError: Java heap space&lt;/li&gt;
	&lt;li&gt;-XX:OnOutOfMemoryError=&quot;kill -9 %p&quot;&lt;/li&gt;
	&lt;li&gt;Executing /bin/sh -c &quot;kill -9 16941&quot;...&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Configs are this:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The maximum amount of heap to use, in MB. Default is 1000.&lt;br/&gt;
export HBASE_HEAPSIZE=16000&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;export HBASE_OPTS=&quot;$HBASE_OPTS -XX:MaxDirectMemorySize=16g&quot;&lt;/p&gt;


&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hbase.bucketcache.ioengine&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;offheap&amp;lt;/value&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;br/&gt;
&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hbase.bucketcache.size&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;8196&amp;lt;/value&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;br/&gt;
&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hfile.block.cache.size&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;0.1&amp;lt;/value&amp;gt;&lt;br/&gt;
    &amp;lt;/property&amp;gt;&lt;br/&gt;
&amp;lt;/configuration&amp;gt;&lt;/p&gt;

&lt;p&gt;Looking at UI, hardly any meta blocks in L1... a couple of hundred.&lt;/p&gt;</comment>
                            <comment id="14961355" author="stack" created="Fri, 16 Oct 2015 21:00:46 +0000"  >&lt;p&gt;My master branch is at this stage:&lt;/p&gt;

&lt;p&gt;commit 1458798eb593358fe5415596b2958f2f7e451ea5&lt;br/&gt;
Author: stack &amp;lt;stack@apache.org&amp;gt;&lt;br/&gt;
Date:   Tue Oct 13 15:16:57 2015 -0700&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14600&quot; title=&quot;Make #testWalRollOnLowReplication looser still&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14600&quot;&gt;&lt;del&gt;HBASE-14600&lt;/del&gt;&lt;/a&gt; Make #testWalRollOnLowReplication looser still&lt;/p&gt;</comment>
                            <comment id="14961356" author="stack" created="Fri, 16 Oct 2015 21:00:46 +0000"  >&lt;p&gt;My master branch is at this stage:&lt;/p&gt;

&lt;p&gt;commit 1458798eb593358fe5415596b2958f2f7e451ea5&lt;br/&gt;
Author: stack &amp;lt;stack@apache.org&amp;gt;&lt;br/&gt;
Date:   Tue Oct 13 15:16:57 2015 -0700&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14600&quot; title=&quot;Make #testWalRollOnLowReplication looser still&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14600&quot;&gt;&lt;del&gt;HBASE-14600&lt;/del&gt;&lt;/a&gt; Make #testWalRollOnLowReplication looser still&lt;/p&gt;</comment>
                            <comment id="14961568" author="stack" created="Sat, 17 Oct 2015 00:16:34 +0000"  >&lt;p&gt;Does this help? Looks like 7.5G retained by HFileScannerImpl in arraylist.&lt;/p&gt;</comment>
                            <comment id="14961733" author="anoop.hbase" created="Sat, 17 Oct 2015 04:30:12 +0000"  >&lt;p&gt;Is the log at the time of workload C (pure reads alone)?  Because I can see lot of flushes and compaction logs in it.   Exact steps to reproduce can u give boss? Will help us to reproduce and fix.&lt;/p&gt;

&lt;p&gt;What we do is&lt;br/&gt;
Start the cluster and pump in whole data.  Then stopping the cluster so that whole data is flushed and in disk&lt;br/&gt;
Now start cluster again.  Make a full table scan so that the entire data is read once and getting cached to BC&lt;br/&gt;
Now run the YCSB workload C&lt;/p&gt;</comment>
                            <comment id="14961735" author="stack" created="Sat, 17 Oct 2015 04:36:16 +0000"  >&lt;p&gt;This is a different loading. This is me trying to run a suite of ycsb load and workloads but I&apos;d forgotten to disable bucketcache.&lt;/p&gt;

&lt;p&gt;It should not OOME. If it does, its broke?&lt;/p&gt;

&lt;p&gt;See the attached image for what is holding objects.&lt;/p&gt;</comment>
                            <comment id="14961738" author="ram_krish" created="Sat, 17 Oct 2015 04:46:21 +0000"  >&lt;p&gt;In the latest tests that we did, ensured that after the loading was done we try to simply run the ycsb read workloads and ensure that we load the block cache and at the same time there is lot of evicitons as the bucket cache configured is lesser in size than the available data.&lt;/p&gt;</comment>
                            <comment id="14961753" author="anoop.hbase" created="Sat, 17 Oct 2015 05:21:58 +0000"  >&lt;p&gt;One doubt after seeing the logs...  The OOME comes during a time when some compaction happens?&lt;br/&gt;
There was one open item we discussed after the shipped() call during the compaction..    This API gets called during the scan flow after we ship a set of rows back to client..  So all the blocks other than the cur block we came across during this scan, can get released.  (Ref count decrements).&lt;br/&gt;
But during compaction this call is not at all happening and only at the end one close happens.   We can correct this.. I have a quick patch for that.  U will be interested to see it and test it with once boss?&lt;/p&gt;</comment>
                            <comment id="14961754" author="anoop.hbase" created="Sat, 17 Oct 2015 05:23:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;It should not OOME. If it does, its broke?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agree fully..  We need fix this and it is a critical bug. Was just trying to understand flow so that we can reproduce it easily here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15120779" author="ram_krish" created="Thu, 28 Jan 2016 05:21:38 +0000"  >&lt;p&gt;Moved out the Dictionary (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14841&quot; title=&quot;Allow Dictionary to work with BytebufferedCells&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14841&quot;&gt;&lt;del&gt;HBASE-14841&lt;/del&gt;&lt;/a&gt;) and Prefix Tree (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14842&quot; title=&quot;PrefixTree write path should work with BytebufferedCells (during compaction)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14842&quot;&gt;&lt;del&gt;HBASE-14842&lt;/del&gt;&lt;/a&gt;) to work with ByteBuffer to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15179&quot; title=&quot;Cell/DBB end-to-end on the write-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15179&quot;&gt;HBASE-15179&lt;/a&gt; as it is mostly concerned with writes. Hence resolving this parent JIRA as fixed. &lt;/p&gt;</comment>
                            <comment id="15121247" author="stack" created="Thu, 28 Jan 2016 11:21:38 +0000"  >&lt;p&gt;Hurray!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12953093">HBASE-15525</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13004565">HBASE-16626</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12925190">HBASE-15063</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12925208">HBASE-15064</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12946053">HBASE-15379</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13004108">HBASE-16609</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12919674">HBASE-14940</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13010136">HBASE-16783</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12738194">HBASE-11871</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12701877">HBASE-10772</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12701878">HBASE-10773</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12702557">HBASE-10801</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12623342">HBASE-7320</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12708331">HBASE-10974</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12702556">HBASE-10800</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12729928" name="BenchmarkTestCode.zip" size="10140" author="anoop.hbase" created="Sat, 2 May 2015 05:59:26 +0000"/>
                            <attachment id="12730466" name="Benchmarks_Tests.docx" size="46790" author="anoop.hbase" created="Tue, 5 May 2015 10:08:08 +0000"/>
                            <attachment id="12766735" name="GC pics with evictions_4G heap.png" size="56634" author="ram_krish" created="Thu, 15 Oct 2015 06:28:46 +0000"/>
                            <attachment id="12705318" name="HBASE-11425-E2E-NotComplete.patch" size="857013" author="anoop.hbase" created="Wed, 18 Mar 2015 10:08:09 +0000"/>
                            <attachment id="12708404" name="HBASE-11425.patch" size="999924" author="ram_krish" created="Tue, 31 Mar 2015 10:41:23 +0000"/>
                            <attachment id="12705317" name="Offheap reads in HBase using BBs_V2.pdf" size="117785" author="anoop.hbase" created="Wed, 18 Mar 2015 10:06:53 +0000"/>
                            <attachment id="12703419" name="Offheap reads in HBase using BBs_final.pdf" size="96636" author="ram_krish" created="Mon, 9 Mar 2015 12:34:26 +0000"/>
                            <attachment id="12767167" name="Screen Shot 2015-10-16 at 5.13.22 PM.png" size="452645" author="stack" created="Sat, 17 Oct 2015 00:16:34 +0000"/>
                            <attachment id="12766585" name="gc.png" size="31325" author="stack" created="Wed, 14 Oct 2015 17:10:07 +0000"/>
                            <attachment id="12766587" name="gets.png" size="20321" author="stack" created="Wed, 14 Oct 2015 17:10:07 +0000"/>
                            <attachment id="12766684" name="heap.png" size="25759" author="stack" created="Thu, 15 Oct 2015 00:00:17 +0000"/>
                            <attachment id="12766586" name="load.png" size="31604" author="stack" created="Wed, 14 Oct 2015 17:10:07 +0000"/>
                            <attachment id="12766584" name="median.png" size="42363" author="stack" created="Wed, 14 Oct 2015 17:10:07 +0000"/>
                            <attachment id="12767140" name="ram.log" size="8875675" author="stack" created="Fri, 16 Oct 2015 20:58:02 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12740539">HBASE-11934</subtask>
                            <subtask id="12746674">HBASE-12202</subtask>
                            <subtask id="12746935">HBASE-12213</subtask>
                            <subtask id="12747190">HBASE-12224</subtask>
                            <subtask id="12748817">HBASE-12282</subtask>
                            <subtask id="12749099">HBASE-12288</subtask>
                            <subtask id="12749100">HBASE-12289</subtask>
                            <subtask id="12749111">HBASE-12290</subtask>
                            <subtask id="12749148">HBASE-12295</subtask>
                            <subtask id="12749150">HBASE-12296</subtask>
                            <subtask id="12749168">HBASE-12297</subtask>
                            <subtask id="12749169">HBASE-12298</subtask>
                            <subtask id="12749466">HBASE-12305</subtask>
                            <subtask id="12749601">HBASE-12313</subtask>
                            <subtask id="12750531">HBASE-12345</subtask>
                            <subtask id="12751033">HBASE-12358</subtask>
                            <subtask id="12751050">HBASE-12360</subtask>
                            <subtask id="12751310">HBASE-12374</subtask>
                            <subtask id="12758200">HBASE-12593</subtask>
                            <subtask id="12787599">HBASE-13387</subtask>
                            <subtask id="12819378">HBASE-13429</subtask>
                            <subtask id="12827926">HBASE-13641</subtask>
                            <subtask id="12827929">HBASE-13642</subtask>
                            <subtask id="12829536">HBASE-13679</subtask>
                            <subtask id="12834937">HBASE-13827</subtask>
                            <subtask id="12836392">HBASE-13871</subtask>
                            <subtask id="12838078">HBASE-13916</subtask>
                            <subtask id="12838485">HBASE-13926</subtask>
                            <subtask id="12844545">HBASE-14063</subtask>
                            <subtask id="12845881">HBASE-14116</subtask>
                            <subtask id="12846102">HBASE-14120</subtask>
                            <subtask id="12846774">HBASE-14144</subtask>
                            <subtask id="12854046">HBASE-14202</subtask>
                            <subtask id="12863022">HBASE-14395</subtask>
                            <subtask id="12863051">HBASE-14398</subtask>
                            <subtask id="12896056">HBASE-14480</subtask>
                            <subtask id="12902358">HBASE-14550</subtask>
                            <subtask id="12904085">HBASE-14590</subtask>
                            <subtask id="12905703">HBASE-14636</subtask>
                            <subtask id="12914137">HBASE-14832</subtask>
                            <subtask id="12928359">HBASE-15077</subtask>
                            <subtask id="12963778">HBASE-15735</subtask>
                            <subtask id="12965563">HBASE-15785</subtask>
                            <subtask id="12995578">HBASE-16372</subtask>
                            <subtask id="13005775">HBASE-16651</subtask>
                            <subtask id="13008869">HBASE-16738</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Jun 2014 18:20:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>402351</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            46 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1x947:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>402414</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>