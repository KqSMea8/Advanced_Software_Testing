<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:01:21 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-15240/HBASE-15240.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-15240] Go Big BucketCache Fixes</title>
                <link>https://issues.apache.org/jira/browse/HBASE-15240</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Umbrella issue to which we will attach issues that prevent bucketcache going big; there&apos;s a few.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12938047">HBASE-15240</key>
            <summary>Go Big BucketCache Fixes</summary>
                <type id="14" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Umbrella</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Wed, 10 Feb 2016 00:30:34 +0000</created>
                <updated>Thu, 1 Dec 2016 13:56:27 +0000</updated>
                                                                            <component>BucketCache</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                                                            <comments>
                            <comment id="15140117" author="stack" created="Wed, 10 Feb 2016 00:50:06 +0000"  >&lt;p&gt;hbase.ui.blockcache.by.file.max is defaulted to 100000. Means 100000 blocks from a file only. If cache is backed by a big SSD and you want to cache all data, this 100000 cuts in we stop loading more from the file without emission in the log. It also seems like this 100000 limit is max on all blocks in the cache. According to the UI it is at least. Dig.&lt;/p&gt;

&lt;p&gt;UI gets hosed when I have 2M+ blocks (though we are no longer trying to draw them)&lt;/p&gt;

&lt;p&gt;When using prefetch, &apos;wait&apos; on the queue to write out blocks to cache is hardcoded false so we will skip out warming cache at startup.&lt;/p&gt;

&lt;p&gt;Neither can we set the time to wait around. Currently it is hardcoded at 50ms.&lt;/p&gt;
</comment>
                            <comment id="15140843" author="stack" created="Wed, 10 Feb 2016 14:18:47 +0000"  >&lt;p&gt;The 100000 upper limit per file has been in there since we first did reporting on blockcache:   &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4089&quot; title=&quot;blockCache contents report&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4089&quot;&gt;&lt;del&gt;HBASE-4089&lt;/del&gt;&lt;/a&gt; blockCache contents report&quot;&lt;/p&gt;

&lt;p&gt;Prefetch is too slow. Takes ages to warm a big cache.&lt;/p&gt;

&lt;p&gt;There is an NPE the odd time here abouts. Need to investigate:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java
index 4ada262..834588e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java
@@ -1502,7 +1502,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class HFileBlock &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; Cacheable {
       &lt;span class=&quot;code-comment&quot;&gt;// guaranteed to use hdfs checksum verification.
&lt;/span&gt;       &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; doVerificationThruHBaseChecksum = streamWrapper.shouldUseHBaseChecksum();
       FSDataInputStream is = streamWrapper.getStream(doVerificationThruHBaseChecksum);
-
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (is == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; NullPointerException(toString());
       HFileBlock blk = readBlockDataInternal(is, offset,
                          onDiskSizeWithHeaderL,
                          uncompressedSize, pread,
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Need below to be able to load a bunch into cache by prefetching:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
index f9d8167..c6fceea 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
@@ -154,11 +154,11 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class BucketCache &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; BlockCache, HeapSize {
   /** Cache access count (sequential ID) */
   &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AtomicLong accessCount = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AtomicLong(0);

-  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; DEFAULT_CACHE_WAIT_TIME = 50;
+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; DEFAULT_CACHE_WAIT_TIME = 5000;
   &lt;span class=&quot;code-comment&quot;&gt;// Used in test now. If the flag is &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; and the cache speed is very fast,
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;// bucket cache will skip some blocks when caching. If the flag is &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, we
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;// will wait blocks flushed to IOEngine &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; some time when caching
&lt;/span&gt;-  &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; wait_when_cache = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
+  &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; wait_when_cache = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;

   &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; BucketCacheStats cacheStats = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BucketCacheStats();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Need to think about it.&lt;/p&gt;

&lt;p&gt;Also needed these conffigs to do more work serializing into bucketcache.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;name&amp;gt;hbase.ui.blockcache.by.file.max
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;2147483640&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hbase.bucketcache.writer.queuelength
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;256&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hbase.bucketcache.writer.threads
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;16&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we ask that blocks be 4k in configs but we are writing out 4.2k &amp;#8211; the header of following block too. On the other end, fetching a block seems to be making for two seeks. Investigate&lt;/p&gt;</comment>
                            <comment id="15140849" author="stack" created="Wed, 10 Feb 2016 14:21:03 +0000"  >&lt;p&gt;Profiling (after getting java crc out of the way which took a while), we are doing loads of String slinging &amp;#8211; parse of the hfile path &amp;#8211; when going in and out of bucketcache. Looks like some easy wins to be had here. Investigate&lt;/p&gt;</comment>
                            <comment id="15140866" author="stack" created="Wed, 10 Feb 2016 14:29:09 +0000"  >&lt;p&gt;With above configs, patches, and time, I was able to warm up my cache w/ my dataset; 45G and almost 12M blocks.&lt;/p&gt;</comment>
                            <comment id="15140868" author="ram_krish" created="Wed, 10 Feb 2016 14:30:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;parse of the hfile path &#8211; when going in and out of bucketcache. Looks like some easy wins to be had here. Investigate&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I can check this if you are not looking into it.&lt;br/&gt;
Does this JIRA also plan to add fixing BucketCache in filemode? If so I have this JIRA&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14046&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-14046&lt;/a&gt;.  I have seen this happening in some of my test runs. It occurs randomly and not very easy to reproduce.&lt;br/&gt;
Also this JIRa&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13320&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-13320&lt;/a&gt;. This is just a way how we can fine tune the config. &lt;/p&gt;</comment>
                            <comment id="15140873" author="ram_krish" created="Wed, 10 Feb 2016 14:31:55 +0000"  >&lt;p&gt;Okie your screen shot is for FileMode and we can even think of committing &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13259&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-13259&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15140952" author="stack" created="Wed, 10 Feb 2016 15:11:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;I can check this if you are not looking into it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;d be sweet &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Let me paste a profile here later this morning.... if it will help.&lt;/p&gt;

&lt;p&gt;File mode is what folks doing SSD will use so let me review your two issues. Thanks boss.&lt;/p&gt;
</comment>
                            <comment id="15145151" author="stack" created="Fri, 12 Feb 2016 19:37:21 +0000"  >&lt;p&gt;Messing some more, prefetch needs the above hack where we wait to get our blocks into cache... otherwise we skip a bunch.... silently.  Need some metric in here, some indicator on how well prefetch is doing. Could we set &apos;wait on cache&apos; if prefetching because defaults of not waiting and 50ms seem good as defaults... though they should be configurable. I can imagine folks finding 50ms too long to wait.&lt;/p&gt;

&lt;p&gt;Need to fix the &apos;full&apos; indicator. Prefetch is erroring out early when full.. and it queues files to read though block cache may be full... FIX.&lt;/p&gt;</comment>
                            <comment id="15145260" author="stack" created="Fri, 12 Feb 2016 20:40:18 +0000"  >&lt;p&gt;Doing quick profile on prefetch &amp;#8211; it takes a long time to load the block cache &amp;#8211; I see the attached when we are prefetching one big file. We are mostly in readBlockDataInternal, which is no surprise. Then there is the usual suspects, compares. For context, perf top shows readBlockDataInternal doing &amp;lt; 1% of total CPU so pepper the JMC 25% with that knowledge. Looking at inlining, I see:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl::readBlockData (354 bytes)   too big&lt;/p&gt;

&lt;p&gt;readBlockDataInternal is likely the same but inlining reports it being zombified.. so maybe we should make it final but if I were to guess, inlining would again report it too big.&lt;/p&gt;

&lt;p&gt;I thought I was seeing parse of path Strings but must have been imagining it... Need to make prefetch go faster.&lt;/p&gt;

&lt;p&gt;(Matteo and I were looking at something else last night slightly related.... readBlock in blockSeek from HFileReaderImpl... it was taking 10%+ of CPU when YCSB doing mostly writes. It was reported as too big to inline too. Need to fix. And then there are all the compares both here and what we were looking at last night. We need to work on those &amp;#8211; avoid some (e.g. Matteo asked why we are doing family parse and compares when below a Store at all?) &amp;#8211; and study/profile/fix up the reset. Just saying.)&lt;/p&gt;
</comment>
                            <comment id="15145468" author="apurtell" created="Fri, 12 Feb 2016 22:45:58 +0000"  >&lt;p&gt;Not saying it shouldn&apos;t be improved, but prefetch is only supposed to be used for IN_MEMORY or equivalent use cases where you want it all or just about all preloaded and you know there&apos;s enough room (or in memory doesn&apos;t make sense then either)&lt;/p&gt;</comment>
                            <comment id="15145477" author="apurtell" created="Fri, 12 Feb 2016 22:48:06 +0000"  >&lt;p&gt;And best effort / background fetch is intended, so even though we want preloading we are not overrunning IO bandwidth with that activity along with other reading and writing. I think some of this is discussed on the issue that introduced it, in the discussion there &lt;/p&gt;</comment>
                            <comment id="15145499" author="stack" created="Fri, 12 Feb 2016 23:01:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Not saying it shouldn&apos;t be improved, but prefetch is only supposed to be used for IN_MEMORY or equivalent use cases where you want it all or just about all preloaded and you know there&apos;s enough room (or in memory doesn&apos;t make sense then either)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So, even for above, needs a bit of work. Cuts off at 100blocks from each file... perhaps from all files... and then it keeps reading the file even after it has gone past the limit. No harm. Will put up some patches.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;And best effort / background fetch is intended, so even though we want preloading we are not overrunning IO bandwidth with that activity along with other reading and writing. I think some of this is discussed on the issue that introduced it, in the discussion there&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sure to this but looks like with current configs, it is easy to overwhelm prefetch; the no-wait on cache and 50ms to get something into the cache are good (maybe even high) for low latency serving but for prefetch, it means we load a few hundred MB only from the 20GB file.... Maybe I need to make queues bigger and add more serializing threads. We probably want to do better than that at least for the case where a fella is trying to test bucketcache at scale.... Should be switches so they can get the cache loaded fast.  Or even for the production in-memory case... we don&apos;t want it to flake out too easily when prefetch is set.&lt;/p&gt;

&lt;p&gt;Will put some patches....&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15145629" author="apurtell" created="Sat, 13 Feb 2016 00:44:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Cuts off at 100 blocks from each file... perhaps from all files... and then keeps reading from the file even after it has gone past the limit &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes that is not good&lt;/p&gt;</comment>
                            <comment id="15145662" author="stack" created="Sat, 13 Feb 2016 01:09:09 +0000"  >&lt;p&gt;That should be 100k and the 100k is actually configuable... to be clear. But yeah, seems to be total upper bound and we keep reading... Let me fix these.&lt;/p&gt;</comment>
                            <comment id="15145909" author="ram_krish" created="Sat, 13 Feb 2016 09:47:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe I need to make queues bigger and add more serializing threads.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Usually if I have data of 100 G and try to load this to a file mode bucket cache it takes quite some time. I have infact configured the Writer Threads in Bucket cache upto 200. Still you can see a stats saying failedblockAdditions. Exceptation is that in case of PCIe SSD this failure should be comparatively lesser but in HDD they are more. I can help with this JIRA in what ever way I can. &lt;/p&gt;</comment>
                            <comment id="15160217" author="ram_krish" created="Wed, 24 Feb 2016 05:57:21 +0000"  >&lt;p&gt;Does it makes sense to add MultiTiered caching also into this as a subtask?  Where Bucket cache will operate both on offheap and file mode?&lt;/p&gt;</comment>
                            <comment id="15160265" author="stack" created="Wed, 24 Feb 2016 06:36:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;Where Bucket cache will operate both on offheap and file mode?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What you thinking &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We&apos;d have to copy between tiers dependent on hotness. Thats hard. I think point of this issue is being able to go big; fast cache warming, being able to use all installed SSDs for cache, etc. Tiering would be orthogonal, another effort?&lt;/p&gt;</comment>
                            <comment id="15160286" author="ram_krish" created="Wed, 24 Feb 2016 06:55:29 +0000"  >&lt;p&gt;My intention was just to see if this parent JIRA is appropriate since we are talking about bigger sized bucket caches. Ya tiered cache needs policy for placement of blocks and considering the hotness, etc.  Hence thought can be part of this parent JIRA.&lt;br/&gt;
If you want that to be a seperate one, am fine with it too. &lt;/p&gt;</comment>
                            <comment id="15163201" author="stack" created="Wed, 24 Feb 2016 15:36:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Yeah, do separate issue. Tiering is hard. Too hard for my small brain.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="13024377">HBASE-17204</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12787270" name="Screen Shot 2016-02-10 at 6.27.26 AM.png" size="196519" author="stack" created="Wed, 10 Feb 2016 14:29:09 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12937973">HBASE-15238</subtask>
                            <subtask id="12938050">HBASE-15241</subtask>
                            <subtask id="12938259">HBASE-15248</subtask>
                            <subtask id="12941438">HBASE-15314</subtask>
                            <subtask id="12945631">HBASE-15361</subtask>
                            <subtask id="12945739">HBASE-15366</subtask>
                            <subtask id="12946548">HBASE-15386</subtask>
                            <subtask id="12946902">HBASE-15392</subtask>
                            <subtask id="12947835">HBASE-15416</subtask>
                            <subtask id="12947902">HBASE-15421</subtask>
                            <subtask id="12951311">HBASE-15477</subtask>
                            <subtask id="12958301">HBASE-15640</subtask>
                            <subtask id="12961487">HBASE-15691</subtask>
                            <subtask id="12962665">HBASE-15713</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 10 Feb 2016 14:30:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            42 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2sn5r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>