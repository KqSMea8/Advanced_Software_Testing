<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:13:04 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3779/HBASE-3779.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3779] Allow split regions to be placed on different region servers</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3779</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently daughter regions are placed on the same region server where the parent region was.&lt;br/&gt;
Stanislav Barton mentioned the idea that load information should be considered when placing the daughter regions.&lt;br/&gt;
The rationale is that the daughter regions tend to receive more writes. So it would be beneficial to place at least one daughter region on a different region server.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12504228">HBASE-3779</key>
            <summary>Allow split regions to be placed on different region servers</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="yuzhihong@gmail.com">Ted Yu</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 14 Apr 2011 04:54:31 +0000</created>
                <updated>Tue, 10 Nov 2015 18:47:56 +0000</updated>
                            <resolved>Tue, 10 Nov 2015 18:47:56 +0000</resolved>
                                    <version>0.90.2</version>
                                                    <component>master</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13019931" author="jdcryans" created="Thu, 14 Apr 2011 17:38:26 +0000"  >&lt;p&gt;This shouldn&apos;t be done inline with the split tho as it will take that whole key space offline for even longer. The way it&apos;s currently working is actually an optimization in that regard.&lt;/p&gt;

&lt;p&gt;What could be done tho is moving the region with the less load after the dust settles but even then, you might want a different behavior for the heavy import scenario and the realtime serving one. In the former, if the import is even across the regions, the region servers should all be splitting as much as the others so moving regions does no good.&lt;/p&gt;</comment>
                            <comment id="13021396" author="zhoushuaifeng" created="Tue, 19 Apr 2011 03:23:12 +0000"  >&lt;p&gt;This is a problem shoud be considered. When one region is spliting, it&apos;s usually heavy loaded. So, the daughter region usually heavy loaded too. Case became even worse when the same situation happened on the daughters. If the daughter are all opened on the same server, this server may become overload and the performance of the system may become worse. &lt;br/&gt;
It&apos;s better to consider the load information when placing the daughter regions. Simply, randomly assign the daughter regions is a good choice.&lt;/p&gt;</comment>
                            <comment id="13021398" author="yuzhihong@gmail.com" created="Tue, 19 Apr 2011 03:55:08 +0000"  >&lt;p&gt;I think we can introduce new config parameter, hbase.daughter.region.placement&lt;br/&gt;
Suppose we name the current daughter placement policy as SAME_HOST and use it as default.&lt;/p&gt;

&lt;p&gt;We can add another policy, ONE_ON_LEAST_LOADED, where one of the daughters is placed on least loaded region server.&lt;br/&gt;
AssignmentManager.getAssignments() can remember the most recent assignments.&lt;br/&gt;
AssignmentManager.handleSplitReport() makes use of this information and assigned one daughter to least loaded server. &lt;/p&gt;</comment>
                            <comment id="13021507" author="sunnygao" created="Tue, 19 Apr 2011 09:19:52 +0000"  >&lt;p&gt;I agree. It needs add a new config parameter and be beneficial to write heavily.&lt;/p&gt;</comment>
                            <comment id="13021584" author="yuzhihong@gmail.com" created="Tue, 19 Apr 2011 13:42:14 +0000"  >&lt;p&gt;First version introduces &quot;hbase.daughter.region.placement&quot; parameter.&lt;/p&gt;</comment>
                            <comment id="13021616" author="msegel" created="Tue, 19 Apr 2011 14:57:00 +0000"  >&lt;p&gt;Just a silly question... how do you determine the load on a region server? How does a regionserver track the loads of other region servers? How often is the load recalculated? Is it also a weighted load based on load over time?&lt;/p&gt;

&lt;p&gt;A random placement would be a start and maybe that&apos;s all that one needs... trying to calculate which region server to place a split on may be too costly. &lt;/p&gt;

&lt;p&gt;Also with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3586&quot; title=&quot;Improve the selection of regions to balance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3586&quot;&gt;&lt;del&gt;HBASE-3586&lt;/del&gt;&lt;/a&gt; - Improve the selection of regions to balance, wouldn&apos;t this kind of be redundant? I mean do a random transfer and then let HBase rebalance over time?&lt;/p&gt;

&lt;p&gt;Sorry to jump in at the end of this... &lt;/p&gt;</comment>
                            <comment id="13021640" author="yuzhihong@gmail.com" created="Tue, 19 Apr 2011 16:18:59 +0000"  >&lt;p&gt;Please refer to my blog &lt;a href=&quot;http://zhihongyu.blogspot.com/2011/04/load-balancer-in-hbase-090.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://zhihongyu.blogspot.com/2011/04/load-balancer-in-hbase-090.html&lt;/a&gt;&lt;br/&gt;
One of the design guidelines I follow is to not introduce randomness where possible.&lt;/p&gt;

&lt;p&gt;The load is currently determined by the number of regions on the region server. There&apos;re plans for improving this measure toward weighted load based on load over time.&lt;br/&gt;
Master runs balancer every &quot;hbase.balancer.period&quot; milliseconds, default 5 minutes.&lt;br/&gt;
My patch latches onto the most recent run of balancer where the least loaded server was recorded. If ONE_ON_LEAST_LOADED policy is chosen, one daughter region is offloaded to that server.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3586&quot; title=&quot;Improve the selection of regions to balance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3586&quot;&gt;&lt;del&gt;HBASE-3586&lt;/del&gt;&lt;/a&gt; has been improved though &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3609&quot; title=&quot;Improve the selection of regions to balance; part 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3609&quot;&gt;&lt;del&gt;HBASE-3609&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
The goal for this JIRA is to fulfill part of balancer&apos;s job at minimal cost.&lt;/p&gt;</comment>
                            <comment id="13021650" author="stack" created="Tue, 19 Apr 2011 16:40:38 +0000"  >&lt;p&gt;So, as per J-D, opening daughters on same regionserver is an improvement over how things used work; it makes it so regions come back on line the faster (Previous, a region would split and we&apos;d tell the master about the new daughters and it managed their &amp;#8211; random &amp;#8211; assignment; the involvement of this extra master agent would often result it longer outages across splits).&lt;/p&gt;

&lt;p&gt;Ted, I&apos;ll look at your patch in a second but 1., why doesn&apos;t your new balancing improvements take care of this case?  The daughter regions are &apos;new&apos; so they should be candidates for moving when the balancer next runs? And 2., it&apos;d be grand if we could tend toward less config.  if that is at all possible.&lt;/p&gt;</comment>
                            <comment id="13021652" author="stack" created="Tue, 19 Apr 2011 16:47:41 +0000"  >&lt;p&gt;Needs tests to prove it does as advertised&lt;/p&gt;

&lt;p&gt;The HMaster change is cleanup of drudge left over from your last balancer improvement?&lt;/p&gt;

&lt;p&gt;Does this work?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    regionOnline(b, hsi);
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (daughterPlacement == DaughterPlacement.SAME_HOST) {
+      regionOnline(b, hsi);
+    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (daughterPlacement == DaughterPlacement.ONE_ON_LEAST_LOADED) {
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (leastLoadedServer != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+        LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;placing &quot;&lt;/span&gt; + b + &lt;span class=&quot;code-quote&quot;&gt;&quot; on &quot;&lt;/span&gt; + leastLoadedServer);
+        regionOnline(b, leastLoadedServer);
+      }
+      &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; regionOnline(b, hsi);
+    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;IIRC, this code is tickled when we get report of split.  We are noting in the Master&apos;s memory that the daughters are up on host &apos;hsi&apos;.  In the above, if ONE_ON_LEAST_LOADED, you are saying the region is on the least loaded server.  Writing this into Master memory state does not make it so; the region is still going to be out on the regionserver where the split happened?  Right?&lt;/p&gt;
</comment>
                            <comment id="13021656" author="yuzhihong@gmail.com" created="Tue, 19 Apr 2011 16:52:55 +0000"  >&lt;p&gt;The improvement from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3609&quot; title=&quot;Improve the selection of regions to balance; part 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3609&quot;&gt;&lt;del&gt;HBASE-3609&lt;/del&gt;&lt;/a&gt; doesn&apos;t cover this JIRA in the following scenario:&lt;br/&gt;
Region server A isn&apos;t overloaded in terms of number of regions on it. One of the regions of table B is actively written to and is split. Still, there is no guarantee that number of regions on A is above the sloppiness introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3681&quot; title=&quot;Check the sloppiness of the region load before balancing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3681&quot;&gt;&lt;del&gt;HBASE-3681&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The introduction of new parameter is mostly due to different opinions on how the daughters should be handled.&lt;/p&gt;</comment>
                            <comment id="13021664" author="stack" created="Tue, 19 Apr 2011 17:02:54 +0000"  >&lt;p&gt;OK. Thanks Ted.  That makes sense.  Patch doesn&apos;t work though, right?  And regards config., I&apos;d say, if you&apos;ve come up w/ a means of figuring overloaded daughters post-split, then I&apos;d say default would be to have it enabled rather than disabled.&lt;/p&gt;</comment>
                            <comment id="13021762" author="yuzhihong@gmail.com" created="Tue, 19 Apr 2011 20:17:44 +0000"  >&lt;p&gt;Second attempt.&lt;/p&gt;</comment>
                            <comment id="13021967" author="yuzhihong@gmail.com" created="Wed, 20 Apr 2011 05:24:46 +0000"  >&lt;p&gt;I tested patch version 2 on our staging cluster. It works:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2011-04-20 05:09:48,328 INFO org.apache.hadoop.hbase.master.AssignmentManager: placing REGION =&amp;gt; {NAME =&amp;gt; &apos;GRID-GRIDSQL-STAGING-THREEGPPSPEECHCALLS-1303255874782,69812FFB7A81D555FE61CA80130A81B5,1303276182555.79c4ba0610797cfdadec17c14a692a59.&apos;, STARTKEY =&amp;gt; &apos;69812FFB7A81D555FE61CA80130A81B5&apos;, ENDKEY =&amp;gt; &apos;6V\xBEp\xAA\xFF@\x0Fs\xE8\x91\x12\xB1zc\xB4\xB7\xF5\x87Y\xFC\x02}\xA1F\x8A\x97\x8D\xD5\x1F\xA7\xB8&apos;, ... on serverName=us01-ciqps1-grid07.carrieriq.com,60020,1303275849244, load=(requests=0, regions=325, usedHeap=23, maxHeap=3973) from serverName=us01-ciqps1-grid02.carrieriq.com,60020,1303275849713, load=(requests=0, regions=341, usedHeap=2118, maxHeap=3973)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;From table.jsp, I verified that the above region was indeed on grid07.&lt;/p&gt;</comment>
                            <comment id="13022293" author="stack" created="Wed, 20 Apr 2011 18:53:31 +0000"  >&lt;p&gt;I took a look at the patch.   So, whats going to happen is that if we enable the move off of one daughter is that we&apos;ll split, open the regions on the parent regions&apos; regionserver, then the master will be notified and we will immediately run the balancer and move the top half of the split (a close of a just opened region).  Is this what we want really? The poor old clients will be doing a bunch of lookups in here to try and figure the new location; they will have to recalibrate for the new daughter region&apos;s location twice in a short amount of time.  They could timeout before they find its new location?&lt;/p&gt;


</comment>
                            <comment id="13022330" author="yuzhihong@gmail.com" created="Wed, 20 Apr 2011 19:36:55 +0000"  >&lt;p&gt;Regionserver splitter needs to be changed for more effective transition of daughter region off of parent region&apos;s region server.&lt;/p&gt;</comment>
                            <comment id="13455463" author="lhofhansl" created="Thu, 13 Sep 2012 23:55:41 +0000"  >&lt;p&gt;@Ted: Do you want to keep this open?&lt;/p&gt;</comment>
                            <comment id="13455478" author="yuzhihong@gmail.com" created="Fri, 14 Sep 2012 00:11:33 +0000"  >&lt;p&gt;Please keep this open.&lt;br/&gt;
We just need to find a good approach for this issue.&lt;/p&gt;</comment>
                            <comment id="13458214" author="stack" created="Tue, 18 Sep 2012 21:50:05 +0000"  >&lt;p&gt;Closing.  This issue introduces a regression.  We did a load of work to change splitting so both came up on same server improving MTTR.  Why would we go back to the old system?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12476832" name="3779-v2.patch" size="6111" author="yuzhihong@gmail.com" created="Wed, 20 Apr 2011 05:22:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 14 Apr 2011 17:38:26 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33204</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 13 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hnuv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101127</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>