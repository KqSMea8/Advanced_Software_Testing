<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:58:26 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8778/HBASE-8778.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8778] Region assigments scan table directory making them slow for huge tables</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8778</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;On a table with 130k regions it takes about 3 seconds for a region server to open a region once it has been assigned.&lt;/p&gt;

&lt;p&gt;Watching the threads for a region server running 0.94.5 that is opening many such regions shows the thread opening the reigon in code like this:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;PRI IPC Server handler 4 on 60020&quot; daemon prio=10 tid=0x00002aaac07e9000 nid=0x6566 runnable [0x000000004c46d000]
   java.lang.Thread.State: RUNNABLE
        at java.lang.String.indexOf(String.java:1521)
        at java.net.URI$Parser.scan(URI.java:2912)
        at java.net.URI$Parser.parse(URI.java:3004)
        at java.net.URI.&amp;lt;init&amp;gt;(URI.java:736)
        at org.apache.hadoop.fs.Path.initialize(Path.java:145)
        at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:126)
        at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:50)
        at org.apache.hadoop.hdfs.protocol.HdfsFileStatus.getFullPath(HdfsFileStatus.java:215)
        at org.apache.hadoop.hdfs.DistributedFileSystem.makeQualified(DistributedFileSystem.java:252)
        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:311)
        at org.apache.hadoop.fs.FilterFileSystem.listStatus(FilterFileSystem.java:159)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:842)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:867)
        at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1168)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableInfoPath(FSTableDescriptors.java:269)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableInfoPath(FSTableDescriptors.java:255)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableInfoModtime(FSTableDescriptors.java:368)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:155)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:126)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:2834)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:2807)
        at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:320)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1426)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To open the region, the region server first loads the latest HTableDescriptor.  Since &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4553&quot; title=&quot;The update of .tableinfo is not atomic; we remove then rename&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4553&quot;&gt;&lt;del&gt;HBASE-4553&lt;/del&gt;&lt;/a&gt; HTableDescriptor&apos;s are stored in the file system at &quot;/hbase/&amp;lt;tableDir&amp;gt;/.tableinfo.&amp;lt;sequenceNum&amp;gt;&quot;.  The file with the largest sequenceNum is the current descriptor.  This is done so that the current descirptor is updated atomically.  However, since the filename is not known in advance FSTableDescriptors it has to do a FileSystem.listStatus operation which has to list all files in the directory to find it.  The directory also contains all the region directories, so in our case it has to load 130k FileStatus objects.  Even using a globStatus matching function still transfers all the objects to the client before performing the pattern matching.  Furthermore HDFS uses a default of transferring 1000 directory entries in each RPC call, so it requires 130 roundtrips to the namenode to fetch all the directory entries.&lt;/p&gt;

&lt;p&gt;Consequently, to reassign all the regions of a table (or a constant fraction thereof) requires time proportional to the square of the number of regions.&lt;/p&gt;

&lt;p&gt;In our case, if a region server fails with 200 such regions, it takes 10+ minutes for them all to be reassigned, after the zk expiration and log splitting.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12654040">HBASE-8778</key>
            <summary>Region assigments scan table directory making them slow for huge tables</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davelatham">Dave Latham</assignee>
                                    <reporter username="davelatham">Dave Latham</reporter>
                        <labels>
                    </labels>
                <created>Thu, 20 Jun 2013 23:35:32 +0000</created>
                <updated>Fri, 31 Jul 2015 06:58:27 +0000</updated>
                            <resolved>Tue, 6 Aug 2013 14:44:41 +0000</resolved>
                                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.95.2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="13689851" author="davelatham" created="Thu, 20 Jun 2013 23:36:18 +0000"  >&lt;p&gt;One solution is to instead keep the table descriptor files in a subdirectory of the table directory so that only that subdirectory needs a scan.  The attached patch is one from 0.94.5 that implements this scheme.  In order to be applicable in a rolling restart scenario, the new descriptor is written to both the table directory and the subdirectory.  Readers first read the subdirectory, then fall back to the table directory.  In order to be robust against failures or races, a lock file is used in the subdirectory during writes.  The patch also refactors the FSTableDescriptors class to require a Configuration (to determine lock wait duration) as well as updates so that it more uniformly enforces the fsreadonly flag (RegionServers never do writes) and stick with using instance methods rather than static methods.  We are proceeding with this and hope to roll it out to our cluster.  To update to this patch once the writers (HBase Master, tools like hbck, merge, compact) are upgraded then old writers should not be used.&lt;/p&gt;

&lt;p&gt;I would love to hear the opinion of the HBase community regarding this issue.  Some questions:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Is it worth fixing? (I strongly believe so as it has a big impact on MTTR for large clusters)&lt;/li&gt;
	&lt;li&gt;What&apos;s the best approach to fixing?&lt;/li&gt;
	&lt;li&gt;Some other possibilities:&lt;/li&gt;
	&lt;li&gt;Using a lock file and well known table descriptor file rather than sequence ids&lt;/li&gt;
	&lt;li&gt;Relying on more descriptor caching rather than hitting hdfs on every region assignment (as bulk assignment already does).&lt;/li&gt;
	&lt;li&gt;Move table descriptors to a different location in hdfs (single location for all tables?)&lt;/li&gt;
	&lt;li&gt;Move table descriptors out of hdfs to ZK&lt;/li&gt;
	&lt;li&gt;How and when can we migrate to that approach?&lt;/li&gt;
	&lt;li&gt;For the patch above once the cluster has been upgraded and updated the location of the descriptor files to have a copy in the subdirectory it would be easy to have the next version use only those files.&lt;/li&gt;
	&lt;li&gt;Alternatively, for the singularity there could be a one-time piece of migration code that just moved the files there.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13692159" author="davelatham" created="Mon, 24 Jun 2013 17:23:59 +0000"  >&lt;p&gt;Here&apos;s an updated patch with a bit of cleanup.  We&apos;ve begun rolling this out to one of our production clusters, and it is showing about a 5x speedup in assignments during the rolling restart.&lt;/p&gt;</comment>
                            <comment id="13692205" author="sershe" created="Mon, 24 Jun 2013 18:15:26 +0000"  >&lt;p&gt;Can you please post on RB (&lt;a href=&quot;https://reviews.apache.org/r/)?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/)?&lt;/a&gt; The patch is relatively large&lt;/p&gt;</comment>
                            <comment id="13692206" author="sershe" created="Mon, 24 Jun 2013 18:17:11 +0000"  >&lt;p&gt;Actually on an entirely unrelated note it would be interesting to learn how you run with so many regions (200+ memstores per server?). Are you coming to Hadoop summit? Was there an HBaseCon talk I missed &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13692210" author="ianfriedman" created="Mon, 24 Jun 2013 18:21:28 +0000"  >&lt;p&gt;Actually Dave was on the panel at the HBase Operations session at HBaseCon, so if you went to that you might have heard about it. Also FYI looks like we have something like 258 regions per server nowadays. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13692434" author="davelatham" created="Mon, 24 Jun 2013 22:04:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;Thanks for taking a look.  I haven&apos;t used the review board before.  I registered and tried to post up the patch there, but it gives me a 500 error when trying to post to the &quot;hbase&quot; repository.  I also didn&apos;t see anywhere to choose what branch the patch is against, so perhaps it is because this patch is not for trunk.  Feel free to post it up if you know how or point me in the right direction.&lt;/p&gt;

&lt;p&gt;I&apos;m more interested at first for what people think is the best general strategy for dealing with this.  If some consensus is reached on that can put forward reasonable effort to push it through.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;OT&amp;#93;&lt;/span&gt; I&apos;ll probably be at the Hadoop summit on Thursday, or feel free to email me directly.&lt;/p&gt;</comment>
                            <comment id="13692443" author="enis" created="Mon, 24 Jun 2013 22:13:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;it gives me a 500 error when trying to post to the &quot;hbase&quot; repository&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You can use the hbase-git repository instead of the hbase repository. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m more interested at first for what people think is the best general strategy for dealing with this&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Putting tabledesc in a subdir only solves the problem for region opening. But other tools, which does an ls on directory will still run into this. &lt;br/&gt;
Namespaces issue changes the directory layout on hdfs, so maybe we should rethink how we are organizing region dirs as well. Datanodes have a multi-level hierarchical directory layout structure for managing the block files. We can implement something like that. &lt;/p&gt;</comment>
                            <comment id="13692444" author="sershe" created="Mon, 24 Jun 2013 22:14:23 +0000"  >&lt;p&gt;use hbase-git one&lt;/p&gt;

&lt;p&gt;As for the general approach, it seems like HDFS issue should be raised to be able to do scanning more efficiently in this scenario (doing pattern matching on the server). The subdirectory approach is a reasonable workaround&lt;/p&gt;</comment>
                            <comment id="13692448" author="davelatham" created="Mon, 24 Jun 2013 22:21:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;use hbase-git one&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I had tried the hbase-git one too, but it complains about that the files are not in the repo, for example &quot;The file &apos;src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&apos; (rec0bd62) could not be found in the repository&quot;.  I assume that this is because there is no option to specify a branch and the code was reorganized in master into modules.&lt;/p&gt;

&lt;p&gt;If we wanted to go with this direction, I will do the work to port changes up to trunk and 0.95, but I&apos;d prefer to avoid that if another direction is preferred.&lt;/p&gt;</comment>
                            <comment id="13692454" author="davelatham" created="Mon, 24 Jun 2013 22:24:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Putting tabledesc in a subdir only solves the problem for region opening. But other tools, which does an ls on directory will still run into this. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It would solve it for any tools loading the table descriptor information.  It would not solve it for any tools which want to scan the table directory, but not the full directory.  However, I&apos;m not aware of any other cases where you want only some data from the table directory, but don&apos;t know it&apos;s name.  Either you want a single region, or all the regions in which case even if they are organized hierarchically you are still reading all of them.&lt;/p&gt;</comment>
                            <comment id="13692484" author="enis" created="Mon, 24 Jun 2013 22:36:03 +0000"  >&lt;p&gt;I think it is not just doing a (partial) list on directory for region names, but for opening any file inside the region, you have to locate the regionDir&apos;s inode from it&apos;s parent directory. If parent contains 1000&apos;s of entries, then this search becomes slower and slower. NN keeps Inodes in memory, but that can change in the future. &lt;/p&gt;</comment>
                            <comment id="13692498" author="davelatham" created="Mon, 24 Jun 2013 22:53:30 +0000"  >&lt;p&gt;So to open a region file you need to locate the inode for the regionDir which means a binary search of the parent&apos;s list.  If we make that list into a hierarchical tree that still requires log(N) steps, right?  But now some of the steps would require round trips between dfs client and namenode.  I have a feeling that I&apos;m missing something here.&lt;/p&gt;</comment>
                            <comment id="13692500" author="davelatham" created="Mon, 24 Jun 2013 22:57:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;As for the general approach, it seems like HDFS issue should be raised to be able to do scanning more efficiently in this scenario (doing pattern matching on the server).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s an approach I hadn&apos;t considered.  However, it seems we&apos;d still be pushing a lot of work on to a single NameNode as it would still need to apply the pattern to every inode or else be very intelligent about pattern processing.&lt;/p&gt;</comment>
                            <comment id="13692516" author="enis" created="Mon, 24 Jun 2013 23:06:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;So to open a region file you need to locate the inode for the regionDir which means a binary search of the parent&apos;s list.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, currently NN does a binary search for this, but I am not sure we should rely on that. Having 100K entries in a single directory does not seem right. &lt;/p&gt;</comment>
                            <comment id="13693060" author="davelatham" created="Tue, 25 Jun 2013 14:12:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yes, currently NN does a binary search for this, but I am not sure we should rely on that. Having 100K entries in a single directory does not seem right. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I can&apos;t image HDFS would revert looking up an inode to linear or anything slower than log time.  That would be a major regression.  Still, if you think having all the region directories in the same table directory is just not right, let&apos;s open another issue and discuss the merits there.  For this one, do you propose waiting for that change and in that case leaving the descriptor files to sit in the top level table dir alongside the first level of region subdirectories?  Even with a hierarchy it would seem to be that descriptor files would be better off in their own table metadata directory.&lt;/p&gt;</comment>
                            <comment id="13693142" author="davelatham" created="Tue, 25 Jun 2013 16:08:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; Since I haven&apos;t been able to make review board cooperate if you want to view the patch in a more friendly format I made it visible on GitHub too:&lt;br/&gt;
&lt;a href=&quot;https://github.com/ddlatham/hbase/pull/1/files&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/ddlatham/hbase/pull/1/files&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13695786" author="enis" created="Fri, 28 Jun 2013 20:58:51 +0000"  >&lt;p&gt;Thinking again about this, maybe we should go with the table of tables approach instead of keeping tableinfos on hdfs. That has been proposed in some other jira. With namespaces (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8015&quot; title=&quot;Support for Namespaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8015&quot;&gt;HBASE-8015&lt;/a&gt;), we will have a table for namespaces. We already have a table for regions (ROOT and META). Having a table table makes sense to me. &lt;/p&gt;</comment>
                            <comment id="13695873" author="davelatham" created="Fri, 28 Jun 2013 22:28:19 +0000"  >&lt;p&gt;A table descriptor table is an interesting approach I had not thought of.  I like that it pulls the NameNode out of the path and can take advantage of atomic row operations for modifications.  A couple questions come to my mind:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Where does this table&apos;s descriptor information get stored?&lt;/li&gt;
	&lt;li&gt;What does the bootstrap look like?  Need to load the META table descriptor from this table to open the META table but need to look up this table&apos;s location in META to lookup the META table descriptor?&lt;/li&gt;
	&lt;li&gt;What happens if this table is corrupted somehow?  Currently, hbck can recreate META entries if they are lost, but is there any other place to recover table descriptor information?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13695882" author="enis" created="Fri, 28 Jun 2013 22:40:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Where does this table&apos;s descriptor information get stored?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t know of any design plan for this yet. But I imagine we can store them in serialized form in some column. Table name becomes the row key, and info:tableInfo column contains serialized table info. This can mimic the META structure. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;What does the bootstrap look like? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;META&apos;s HTD is already hardcoded in the source code. We can do the same for TABLE table, just hardcoding the HTD in source code. Make sure that it is assigned first before accepting any changes to table metadata. I guess we have to assign META first, then TABLE table, then user regions. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;What happens if this table is corrupted somehow? Currently, hbck can recreate META entries if they are lost, but is there any other place to recover table descriptor information?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We keep regionInfo&apos;s serialized in hdfs and in META. HBCK can repair the META regionInfos from hdfs. Maybe we can do the same here for tableinfos as well. We can keep the current logic in hdfs tableInfos, but serialize them in TABLE table as well.  I think having multiple sources of truth hurts us though. Ideally, we should not need to keep this data in multiple places. &lt;/p&gt;</comment>
                            <comment id="13711745" author="davelatham" created="Wed, 17 Jul 2013 22:40:42 +0000"  >&lt;p&gt;I would really like to see a resolution of this for 0.96 so that 0.96 can handle huge tables with reasonable performance.  For 0.94 I&apos;m content to rely on the patch posted here.  Other users can grab it if they find it helpful.&lt;/p&gt;

&lt;p&gt;I&apos;m still most comfortable with simply moving the table descriptor files to a well known subdirectory of the tabledir in HDFS.  If done as part of the 0.96 migration then it can be a simple change without concern for supporting readers or writers using the old location and new location simultaneously.  I&apos;d like to make the trunk patch to do this migration and operate in the new location.&lt;/p&gt;

&lt;p&gt;I like Enis&apos;s proposal of using a system table (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7999&quot; title=&quot;Add &amp;#39;system&amp;#39; tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7999&quot;&gt;&lt;del&gt;HBASE-7999&lt;/del&gt;&lt;/a&gt;) for table descriptors as well, but am not as comfortable trying to pull that off correctly in a short time frame as we&apos;re looking for a 0.96 release.  That presents a couple possibilites.  One, we can first change the table dir locaiton in hdfs but create a new JIRA to work on transitioning it into a system table.  Or if someone who is more comfortable with that work wants to dive in and work on it together with me now and thinks we can get it done for the 0.96 then I&apos;ll give it a shot with them.  Does this sound reasonable?  If I hear no objections, I&apos;ll work on a trunk patch later this week or next week.&lt;/p&gt;</comment>
                            <comment id="13713887" author="enis" created="Fri, 19 Jul 2013 18:03:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;One, we can first change the table dir locaiton in hdfs but create a new JIRA to work on transitioning it into a system table.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed, we can do that as a follow up, and possibly after 0.96 comes out. &lt;br/&gt;
There is already some migration and re-shuffling going on for hdfs directories, so please take a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8015&quot; title=&quot;Support for Namespaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8015&quot;&gt;HBASE-8015&lt;/a&gt; to see whether you can piggy back on that. &lt;/p&gt;</comment>
                            <comment id="13714336" author="lhofhansl" created="Sat, 20 Jul 2013 05:12:08 +0000"  >&lt;p&gt;Skimmed the patch. Looks OK. Will do a closer soon.&lt;/p&gt;

&lt;p&gt;&amp;#43;1 on doing the known-subdir approach in 0.94 and a tables-table in 0.96+.&lt;/p&gt;

&lt;p&gt;Could you run the full test suite with the patch attached? Have you been using this patch in any production environment, yet?&lt;/p&gt;</comment>
                            <comment id="13714337" author="ianfriedman" created="Sat, 20 Jul 2013 05:15:23 +0000"  >&lt;p&gt;Yes Lars, we have been running this patch in both of our production clusters for a few weeks now and it&apos;s been performing admirably. &lt;/p&gt;</comment>
                            <comment id="13714338" author="lhofhansl" created="Sat, 20 Jul 2013 05:16:01 +0000"  >&lt;p&gt;Also, with 130k regions @ 10GB each, do you have a 1.3PB table?!&lt;/p&gt;</comment>
                            <comment id="13714340" author="ianfriedman" created="Sat, 20 Jul 2013 05:25:43 +0000"  >&lt;p&gt;No, the regions are not 10GB each.&lt;/p&gt;</comment>
                            <comment id="13714342" author="ianfriedman" created="Sat, 20 Jul 2013 05:31:09 +0000"  >&lt;p&gt;The 130k+ region table in question is more like 159 TB&lt;/p&gt;</comment>
                            <comment id="13714343" author="lhofhansl" created="Sat, 20 Jul 2013 05:34:50 +0000"  >&lt;p&gt;Shame &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  I would have like to see that.&lt;/p&gt;

&lt;p&gt;As for the patch. Four questions:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Is there a minimal version of the patch? It seems to include some extra clean up.&lt;/li&gt;
	&lt;li&gt;There are some extra exceptions thrown now, that might throw off existing code. Could do this in 0.96+.&lt;/li&gt;
	&lt;li&gt;Why do we need the lock file approach now? Could we use the previous logic of creating files with unique names instead? Might also need to delete old tableinfo first, etc.&lt;/li&gt;
	&lt;li&gt;Are the pom changes needed?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13714344" author="lhofhansl" created="Sat, 20 Jul 2013 05:37:26 +0000"  >&lt;p&gt;159TB is nothing to cough at either.&lt;/p&gt;</comment>
                            <comment id="13714446" author="davelatham" created="Sat, 20 Jul 2013 14:55:10 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, for taking a look.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&lt;ins&gt;1 on doing the known-subdir approach in 0.94 and a tables-table in 0.96&lt;/ins&gt;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually what I was proposing in my comment on 17/Jul/13 was to not commit for 0.94, commit a known-subdir for 0.96 and opening a new tables-table JIRA for 0.96+.  A couple reasons behind that.  First - the patch is not purely rolling compatible.  Break the code down into writers (Master, tools like hbck, merge, compact) and readers (everything).  If one writer is updated and writes in the new way, then an old writer does an update in the old location only, then new readers will miss that update.  So the requirement is to make no writes from old writers once you upgrade to a new writer - I&apos;m not sure if we can/should make that a requirement for a rolling upgrade to 0.94.  I&apos;m not sure if there&apos;s a way around that.  Also as you noted the patch involved additional cleanup and refactoring.  If you want to see it go into 0.94 I&apos;m game to explore it further, but I&apos;m also content to push for 0.96 and leave the 0.94 patch here for interested parties.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Could you run the full test suite with the patch attached? Have you been using this patch in any production environment, yet?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, the tests pass for 0.94.5 + &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;-0.94.5-v2.patch.  And as Ian noted we&apos;ve seen great results in production.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is there a minimal version of the patch? It seems to include some extra clean up.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Don&apos;t currently have a minimal version of the patch.  Because there is now a wait for a lock, I introduced a Configuration to be able to adjust the lock wait time.  Also as I was putting this together I noticed that some clients are accessing static methods and others using instance methods, without much reason, that there is a fsreadonly field intended to prevent file system changes when set but that is not (cannot) be checked by the static methods and even some instance methods call those static methods which then ignore the field thus losing the guarantee.  The patch changes everything to require an instance, correctly enforces the fsreadonly flag everywhere and can use the instance&apos;s Configuration.  It also adds a great deal more commenting to make things more clear for the next maintainer.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;There are some extra exceptions thrown now, that might throw off existing code. Could do this in 0.96+.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Examining them - FSTableDescriptors.add now throws NotImplementedException if in fsreadonly mode instead of silently failing to add the descriptor.  It&apos;s not called by any current code that sets fsreadonly (RegionServer) but I believe if new code is added that does call it that failing loudly is better than failing silently.  Likewise for updateHTableDescriptor,  deleteTableDescriptorIfExists and createTableDescriptor.  Those are the only cases of new exceptions that I can find.  I&apos;ll grant that if there is third-party code (CPs?) that is calling these and is currently failing silently it is possible this change would break that.  Though that code would have to update for the new method signatures anyway.  Do we provide guarantees about compatibility on internal classes?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why do we need the lock file approach now? Could we use the previous logic of creating files with unique names instead? Might also need to delete old tableinfo first, etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It was the only way I could find to make this work with a rolling upgrade (old readers and new readers simultaneously) and guarantee atomic updates in the presence of failures.  If you can flesh out your approach a bit more and it works better, I&apos;d love to lose the locks.  If we proceed with 0.96 only then we can do the migration once and don&apos;t need the locks.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Are the pom changes needed?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nope, sorry.  That was just to get Eclipse to compile the thing.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, with 130k regions @ 10GB each, do you have a 1.3PB table?!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, definitely wish this table had fewer smaller regions.  Been watching the online merge discussions.  This is an old table from when the default region sizes were much smaller.  We are looking at we grow to migrate to a newer table with fatter regions or merge this one down at some point.  However, this issue will still be important even at that size (and the data keeps growing!)&lt;/p&gt;

&lt;p&gt;Thanks again for your thoughts.&lt;/p&gt;</comment>
                            <comment id="13714448" author="davelatham" created="Sat, 20 Jul 2013 15:01:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;There is already some migration and re-shuffling going on for hdfs directories, so please take a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8015&quot; title=&quot;Support for Namespaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8015&quot;&gt;HBASE-8015&lt;/a&gt; to see whether you can piggy back on that. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;, for the tip.  I read through the latest patch there and looked at the code up on GitHub.  It looks to me like it should be fairly easy to combine the updates.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8015&quot; title=&quot;Support for Namespaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8015&quot;&gt;HBASE-8015&lt;/a&gt; moves the tabledir and uses a new FullyQualifiedTableName.  The same changes can be done to the updated FSTableDescriptors to use FullyQualifiedTableName and call FSUtil as this patch doesn&apos;t care where the tabledir is as long as it can get to it.&lt;/p&gt;</comment>
                            <comment id="13714617" author="lhofhansl" created="Sun, 21 Jul 2013 02:54:48 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davelatham&quot; class=&quot;user-hover&quot; rel=&quot;davelatham&quot;&gt;Dave Latham&lt;/a&gt;. Yeah, need to think through the upgrade issues in 0.94.&lt;br/&gt;
It just puts a limit on HBase&apos;s scalability. But in any case anything more 10000 regions per cluster is probably an extreme case.&lt;br/&gt;
Could make is a config option. That way one could rolling upgrade the cluster, then flip the option on, and roll the cluster again. Would have to think through the details.&lt;/p&gt;</comment>
                            <comment id="13714646" author="lhofhansl" created="Sun, 21 Jul 2013 05:14:58 +0000"  >&lt;p&gt;Looking at the code. If the modtime of the tabledescriptor has changed after the cached version, we do what Dave described twice! First getTableInfoModtime is called, if that determines that the cache was changed, getTableDescriptorModtime is called, which does the same work of stat&apos;ing the dir all over again.&lt;/p&gt;

&lt;p&gt;I can think of a few ways to make this better:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;When the table descriptor is cached, check the mod time of the table directory first; if that mod time is &amp;lt;= the cached descriptor&apos;s mod time we&apos;re good and do not need to stat the table directory. In a high churn table that might not help much, though, as new region dirs are constantly added.&lt;/li&gt;
	&lt;li&gt;Record the sequence number of a table descriptor when cached. Instead of checking mod time, we can check whether next highest sequence number exists. If so, we need to reload (but no need to check the mod time by stat&apos;ing the dir). Can there be gaps in the sequence numbers?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13714814" author="davelatham" created="Sun, 21 Jul 2013 21:47:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;Could make is a config option. That way one could rolling upgrade the cluster, then flip the option on, and roll the cluster again. Would have to think through the details.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeah I think it&apos;s still tricky to get the second roll correct - if you&apos;re supporting having some writers that write only to the old dir and some readers who are trying to read from the new location.  I think you may be able to pull it off by two passes - first upgrade all the writers to write to both places but keep everything reading from the old location, then do a second rolling pass to move the readers to the new location.  Then you could do a third pass to have writers only write to the new location.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Looking at the code. If the modtime of the tabledescriptor has changed after the cached version, we do what Dave described twice! First getTableInfoModtime is called, if that determines that the cache was changed, getTableDescriptorModtime is called, which does the same work of stat&apos;ing the dir all over again.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.  I wasn&apos;t too concerned about this case as normally the descriptors are not changed often so this would only happen once per table.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When the table descriptor is cached, check the mod time of the table directory first; if that mod time is &amp;lt;= the cached descriptor&apos;s mod time we&apos;re good and do not need to stat the table directory. In a high churn table that might not help much, though, as new region dirs are constantly added.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s an interesting approach I hadn&apos;t considered.  I wasn&apos;t aware that HDFS maintained directory mod times.  Sounds like a pretty simple change for 0.94 to me.  In our case it would solve the issue for one of our huge tables that doesn&apos;t have much split activity and make a huge difference for the other that has splits every few minutes or so.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Record the sequence number of a table descriptor when cached. Instead of checking mod time, we can check whether next highest sequence number exists. If so, we need to reload (but no need to check the mod time by stat&apos;ing the dir). Can there be gaps in the sequence numbers?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Don&apos;t think this approach would work as the table could be modified many times since the last check so the reader couldn&apos;t know which sequence number to check.&lt;/p&gt;</comment>
                            <comment id="13714835" author="lhofhansl" created="Sun, 21 Jul 2013 23:29:40 +0000"  >&lt;p&gt;Yeah, the 2nd roll would essentially still have he same problem. Maybe we can just generally make this configurable, then an admin can enable this at a convenient time (and we&apos;d document in the release notes and hbase-defaults.xml that rolling upgrades are broken when this is enabled for the first time).&lt;/p&gt;

&lt;p&gt;Maybe we can do the directory mod-time unconditionally and a simplified patch behind a config option.&lt;/p&gt;</comment>
                            <comment id="13715521" author="lhofhansl" created="Mon, 22 Jul 2013 18:49:44 +0000"  >&lt;p&gt;Trivial patch that does the table dir modtime check before the table dir is enumerated.&lt;/p&gt;</comment>
                            <comment id="13715523" author="lhofhansl" created="Mon, 22 Jul 2013 18:49:59 +0000"  >&lt;p&gt;Let&apos;s get a test run with that.&lt;/p&gt;</comment>
                            <comment id="13715575" author="hadoopqa" created="Mon, 22 Jul 2013 19:58:27 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12593576/8778-dirmodtime.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12593576/8778-dirmodtime.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6424//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13715608" author="davelatham" created="Mon, 22 Jul 2013 20:29:02 +0000"  >&lt;p&gt;I began working on a trunk/0.96 patch that would move the table descriptor files to a known sub directory as well as take the refactoring, cleanup and documentation from the 0.94.5 patch above but adding a one time migration instead of the locking or rolling upgrade support.  One issue I ran into is support for snapshots.  The snapshot code calls into FSTableDescriptors to write a table descriptor file in the snapshot directory.  How should this work when FSTableDescriptors is putting descriptors into a known subdir?&lt;/p&gt;

&lt;p&gt;Options I see:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Snapshots behave just like actual table directories and put their descriptors into a known subdir.  During migration, snapshots are migrated to move their descriptor into their known subdir.&lt;/li&gt;
	&lt;li&gt;New snapshots put table descriptors into known subdir.  Reading snapshots support finding the table descriptor in the subdir or the orig directory so no migration of snapshots are needed.&lt;/li&gt;
	&lt;li&gt;Snapshots continue to store table descriptors directly in the snapshot directory and FSTableDescriptors is refactored to share code to write sequenced descriptors in any directory.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thoughts?  I&apos;m leaning toward the last option.&lt;/p&gt;</comment>
                            <comment id="13715656" author="lhofhansl" created="Mon, 22 Jul 2013 21:04:08 +0000"  >&lt;p&gt;Either #1 or #3. If the layout is the same between table and snapshot, maybe #1 makes the most sense.&lt;/p&gt;

&lt;p&gt;What about the directory modtime check, should we just commit this to 0.94 (provided it solves your problem as you said)?&lt;/p&gt;</comment>
                            <comment id="13715673" author="davelatham" created="Mon, 22 Jul 2013 21:15:09 +0000"  >&lt;p&gt;The directory modtime check looks good to me.  For us we will probably stick with the patch I have above for awhile, but I think the modtime would help others.&lt;/p&gt;

&lt;p&gt;For snapshots I can&apos;t find a good reference for their actual hdfs layout, but from a brief look at the code I think it tries to mirror an actual table directory except for using hfile refs.  For #1 I wonder if there are guarantees that would make sure we can find all snapshots during a migration.&lt;/p&gt;</comment>
                            <comment id="13715790" author="davelatham" created="Mon, 22 Jul 2013 22:38:05 +0000"  >&lt;p&gt;Actually, one thought about the directory mod time.  The descriptor files are normally written to a tmp dir and then renamed into place.  In this case I&apos;m thinking the directory mod time may end up greater than the cached descriptor mod time and the extra check wouldn&apos;t help.  So may need to cache the directory mod time directly.&lt;/p&gt;</comment>
                            <comment id="13715810" author="lhofhansl" created="Mon, 22 Jul 2013 22:57:46 +0000"  >&lt;p&gt;Hmm... In that case, take the modtime of the temp dir? Getting a bit fragile.&lt;/p&gt;</comment>
                            <comment id="13715814" author="lhofhansl" created="Mon, 22 Jul 2013 23:00:04 +0000"  >&lt;p&gt;Or just cache the dir time, as you say.&lt;/p&gt;</comment>
                            <comment id="13715927" author="lhofhansl" created="Tue, 23 Jul 2013 00:41:28 +0000"  >&lt;p&gt;Of course the .tmp directory will also be newer, since the tableinfo file was removed from it. Well, it was a good try.&lt;/p&gt;</comment>
                            <comment id="13718824" author="davelatham" created="Wed, 24 Jul 2013 21:05:24 +0000"  >&lt;p&gt;Attached &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;.patch which is a patch for trunk.  Up at reviewboard at:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/12920/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/12920/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This patch is similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;-0.94.5-v2 but because it is for trunk only it does not keep two copies (one in tabledir another in .tabledesc subdir) - it only keeps table info files in the known subdir.  As a result it also does not use any locking.&lt;/p&gt;

&lt;p&gt;The patch still includes some cleanup and refactoring of FSTableDescriptors to consistently enforce the fsreadonly flag and use more instance methods than static methods in order to do so.&lt;/p&gt;

&lt;p&gt;It also changes snapshots to likewise store their table descriptors in the .tabledesc subdirectory so they continue to share code and look just like table directories (option #1 from the previous comment.)&lt;/p&gt;

&lt;p&gt;It also adds a migration step to HMaster.finishInitialization which migrates existing snapshot directories, user tables, and system tables to store descriptors in the .tabledesc subdirectory.&lt;/p&gt;

&lt;p&gt;Going to run it by Hadoop QA and welcome review and comment.&lt;/p&gt;</comment>
                            <comment id="13718935" author="hadoopqa" created="Wed, 24 Jul 2013 22:23:41 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594033/HBASE-8778.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594033/HBASE-8778.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 30 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6456//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13719925" author="davelatham" created="Thu, 25 Jul 2013 19:19:24 +0000"  >&lt;p&gt;Attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;-v2.patch&lt;/p&gt;

&lt;p&gt;This patch addresses a couple comments from Ted on reviewboard (include license, added missing early return on migrating table info that doesn&apos;t need it) as well as the Hadoop QA notes (license, a few lines &amp;gt;100 characters, a few javadoc warnings, and fixed the test failures)&lt;/p&gt;</comment>
                            <comment id="13720212" author="davelatham" created="Thu, 25 Jul 2013 23:15:01 +0000"  >&lt;p&gt;Resubmitting to give Hadoop QA another chance now that trunk was fixed.&lt;/p&gt;</comment>
                            <comment id="13720238" author="davelatham" created="Thu, 25 Jul 2013 23:33:54 +0000"  >&lt;p&gt;Reattaching since changing issue status didn&apos;t seem to trigger Hadoop QA.&lt;/p&gt;</comment>
                            <comment id="13720327" author="hadoopqa" created="Fri, 26 Jul 2013 01:08:24 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594293/HBASE-8778-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594293/HBASE-8778-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 30 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6472//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13720350" author="davelatham" created="Fri, 26 Jul 2013 02:05:37 +0000"  >&lt;p&gt;Attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;-v3.patch.&lt;/p&gt;

&lt;p&gt;Only change from v2 is fixing one javadoc warning.  Don&apos;t know why Hadoop QA said that tests failed for v2 when all passed.&lt;/p&gt;</comment>
                            <comment id="13720389" author="hadoopqa" created="Fri, 26 Jul 2013 04:23:05 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12594312/HBASE-8778-v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12594312/HBASE-8778-v3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 30 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6476//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13720400" author="lhofhansl" created="Fri, 26 Jul 2013 04:48:36 +0000"  >&lt;p&gt;Thanks Dave. I&apos;ll have a look at RB tomorrow (sorry for the lack of response).&lt;/p&gt;</comment>
                            <comment id="13723474" author="lhofhansl" created="Tue, 30 Jul 2013 06:30:49 +0000"  >&lt;p&gt;Removing 0.94 tag; not likely that we&apos;ll fix it there.&lt;/p&gt;</comment>
                            <comment id="13723765" author="jmspaggi" created="Tue, 30 Jul 2013 11:55:29 +0000"  >&lt;p&gt;One thing about this patch. If the content or the directory itself get corrupted, is there a way to fix that? Is it possible to update fsck to check this directory/file content/format and fix it if it&apos;s corrupted?&lt;/p&gt;</comment>
                            <comment id="13724018" author="davelatham" created="Tue, 30 Jul 2013 16:25:35 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt; for taking a look.&lt;/p&gt;

&lt;p&gt;This change doesn&apos;t alter the ability to repair or recreate wrong or missing table descriptor information.  hbck&apos;s fixOrphanTables still works with the new location.&lt;/p&gt;</comment>
                            <comment id="13724063" author="yuzhihong@gmail.com" created="Tue, 30 Jul 2013 17:04:16 +0000"  >&lt;p&gt;Patch v3 needs slight rebasing:&lt;/p&gt;

&lt;p&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java.rej&lt;/p&gt;</comment>
                            <comment id="13724233" author="yuzhihong@gmail.com" created="Tue, 30 Jul 2013 18:34:30 +0000"  >&lt;p&gt;It turns out that TestMetaMigrationConvertingToPB hung.&lt;/p&gt;

&lt;p&gt;In its test output, I saw:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-07-30 18:19:26,137 ERROR [RS_OPEN_REGION-kiyo:57646-1] handler.OpenRegionHandler(475): Failed open of region=TestTable,row1,1344396119749.bdb336540cb3959f86178d3a83c94394., starting to roll back the global memstore size.
java.lang.IllegalStateException: Could not instantiate a region instance.
        at org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:3821)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:4077)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:4031)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:3982)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:459)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:137)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:130)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:662)
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:3818)
        ... 9 more
Caused by: java.lang.IllegalArgumentException: Need table descriptor
        at org.apache.hadoop.hbase.regionserver.HRegion.&amp;lt;init&amp;gt;(HRegion.java:458)
        at org.apache.hadoop.hbase.regionserver.HRegion.&amp;lt;init&amp;gt;(HRegion.java:434)
        ... 14 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13724268" author="davelatham" created="Tue, 30 Jul 2013 19:03:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;-v4.patch - rebased to the latest trunk.&lt;/p&gt;

&lt;p&gt;Ted, what is that result from?  The line numbers don&apos;t match up for me from trunk and I haven&apos;t seen that failure.&lt;/p&gt;</comment>
                            <comment id="13724303" author="hadoopqa" created="Tue, 30 Jul 2013 19:34:41 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12595022/HBASE-8778-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12595022/HBASE-8778-v4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 30 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6524//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6524//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13724338" author="yuzhihong@gmail.com" created="Tue, 30 Jul 2013 20:00:56 +0000"  >&lt;p&gt;@Dave:&lt;br/&gt;
Trunk changes very fast.&lt;br/&gt;
By running TestMetaMigrationConvertingToPB, you should be able to find it in test output.&lt;/p&gt;</comment>
                            <comment id="13724528" author="yuzhihong@gmail.com" created="Tue, 30 Jul 2013 22:35:00 +0000"  >&lt;p&gt;Patch v3 only had one hunk which needs to be resolved.&lt;br/&gt;
I noticed the following in test output of TestMetaMigrationConvertingToPB which was responsible for the IllegalArgumentException mentioned above:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-07-30 15:27:59,630 DEBUG [RpcServer.handler=0,port=51198] util.FSTableDescriptors(189): Exception during readTableDecriptor. Current table name = TestTable
org.apache.hadoop.hbase.TableInfoMissingException: No table descriptor file under hdfs:&lt;span class=&quot;code-comment&quot;&gt;//localhost:51139/user/tyu/hbase/TestTable
&lt;/span&gt;	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorAndModtime(FSTableDescriptors.java:506)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorAndModtime(FSTableDescriptors.java:499)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:184)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:144)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:3450)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:14390)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is due to FSTableDescriptors#getTableInfoPath() only checking in the new tableinfo dir which didn&apos;t exist in the tar ball that is used by the test:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; FileStatus getTableInfoPath(FileSystem fs, Path tableDir, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; removeOldFiles)
  &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    Path tableInfoDir = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(tableDir, TABLEINFO_DIR);
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; getCurrentTableInfoStatus(fs, tableInfoDir, removeOldFiles);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13727813" author="stack" created="Fri, 2 Aug 2013 17:11:34 +0000"  >&lt;p&gt;Any chance of more review on this?&lt;/p&gt;</comment>
                            <comment id="13727841" author="davelatham" created="Fri, 2 Aug 2013 17:29:41 +0000"  >&lt;p&gt;Yes, trunk indeed moves fast.&lt;br/&gt;
Thanks, Ted, for the review and help with the test.&lt;/p&gt;

&lt;p&gt;Here&apos;s &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt;-v5.patch which solves the issue revealed by the test.  I will also update it on review board.&lt;/p&gt;</comment>
                            <comment id="13727953" author="hadoopqa" created="Fri, 2 Aug 2013 18:48:55 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12595634/HBASE-8778-v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12595634/HBASE-8778-v5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 30 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6574//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13728113" author="yuzhihong@gmail.com" created="Fri, 2 Aug 2013 21:03:07 +0000"  >&lt;p&gt;+1 from me.&lt;/p&gt;</comment>
                            <comment id="13728150" author="stack" created="Fri, 2 Aug 2013 21:34:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; You want to have a look at this one boss?&lt;/p&gt;</comment>
                            <comment id="13729505" author="mbertozzi" created="Mon, 5 Aug 2013 13:30:44 +0000"  >&lt;p&gt;+1, v5 looks good to me&lt;/p&gt;</comment>
                            <comment id="13730142" author="stack" created="Mon, 5 Aug 2013 23:38:50 +0000"  >&lt;p&gt;I scanned the patch.  LGTM.  Will apply after namespaces goes in.  I can do the necessary shoe horning on commit.&lt;/p&gt;</comment>
                            <comment id="13730177" author="davelatham" created="Tue, 6 Aug 2013 00:03:54 +0000"  >&lt;p&gt;Thanks, Stack.  Let me know if you want me to do merging when namespaces goes in.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, I created a new JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9132&quot; title=&quot;Use table dir modtime to avoid scanning table dir to check cached table descriptor in 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9132&quot;&gt;&lt;del&gt;HBASE-9132&lt;/del&gt;&lt;/a&gt; and put up a patch for 0.94 to use the directory modtime to reduce these directory scans for 0.94.  Thanks for the idea.  Let me know what you think.&lt;/p&gt;</comment>
                            <comment id="13730832" author="stack" created="Tue, 6 Aug 2013 14:44:41 +0000"  >&lt;p&gt;Committed to trunk and 0.95 (ns needs another revision anyways).  Thanks D.&lt;/p&gt;</comment>
                            <comment id="13730835" author="stack" created="Tue, 6 Aug 2013 14:47:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davelatham&quot; class=&quot;user-hover&quot; rel=&quot;davelatham&quot;&gt;Dave Latham&lt;/a&gt; Mind adding a release note?  Just high level on what gets moved where?  Thanks boss...&lt;/p&gt;</comment>
                            <comment id="13730856" author="hudson" created="Tue, 6 Aug 2013 15:16:26 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.95 #407 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/407/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/407/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt; Region assigments scan table directory making them slow for huge tables (stack: rev 1510978)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/MasterSnapshotVerifier.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TableInfoCopyTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptorMigrationToSubdir.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/Merge.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13730870" author="hudson" created="Tue, 6 Aug 2013 15:51:09 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.95-on-hadoop2 #221 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/221/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/221/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt; Region assigments scan table directory making them slow for huge tables (stack: rev 1510978)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/MasterSnapshotVerifier.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TableInfoCopyTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptorMigrationToSubdir.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/util/Merge.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13731005" author="hudson" created="Tue, 6 Aug 2013 17:43:09 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4347 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4347/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4347/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt; Region assigments scan table directory making them slow for huge tables (stack: rev 1510977)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/MasterSnapshotVerifier.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TableInfoCopyTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptorMigrationToSubdir.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/Merge.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13731558" author="hudson" created="Wed, 7 Aug 2013 01:40:58 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #655 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/655/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/655/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt; Region assigments scan table directory making them slow for huge tables (stack: rev 1510977)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/MasterSnapshotVerifier.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/TableInfoCopyTask.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptorMigrationToSubdir.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/Merge.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestFlushSnapshotFromClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSTableDescriptors.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14646464" author="lars_francke" created="Wed, 29 Jul 2015 17:30:38 +0000"  >&lt;p&gt;I know this has been long closed but it introduced the FSTableDescriptorMigrationToSubdir class which handles the migration from the old to the new style.&lt;/p&gt;

&lt;p&gt;The comment says it &quot;will be removed for the major release after 0.96&quot;.&lt;/p&gt;

&lt;p&gt;Are you okay with this being removed now?&lt;/p&gt;

&lt;p&gt;If so any suggestions on how to handle this now:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Make sure the meta region directory exists!
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!FSUtils.metaRegionExists(fs, rd)) {
      bootstrap(rd, c);
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;code-comment&quot;&gt;// Migrate table descriptor files &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; necessary
&lt;/span&gt;      org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir
        .migrateFSTableDescriptorsIfNecessary(fs, rd);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ll create a new JIRA when/if you think it&apos;s time to remove this now.&lt;/p&gt;</comment>
                            <comment id="14648815" author="davelatham" created="Fri, 31 Jul 2015 06:34:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lars_francke&quot; class=&quot;user-hover&quot; rel=&quot;lars_francke&quot;&gt;Lars Francke&lt;/a&gt;, thanks for bringing it up.  The code needs to be in any version where we want to support a direct upgrade from 0.94.  At &lt;a href=&quot;https://hbase.apache.org/book.html#upgrade1.0.from.0.94&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hbase.apache.org/book.html#upgrade1.0.from.0.94&lt;/a&gt; it indicates a direct (but not rolling) upgrade is supported from 0.94 to 1.0, so the code needs to survive for the 1.0 line.  I don&apos;t know, but am guessing that would be extended to any 1.x.  I have no idea if there has been a decision to support or not direct upgrades from 0.94 to 2.0 or higher.  If it has been decided not to support that, then it would finally be safe to remove `FSTableDescriptorMigrationToSubdir` from the 2.0 code (master, I believe).  I suppose the javadoc you quoted is wrong and would likely better read &quot;will be removed after upgrade from 0.94 is no longer supported.&quot; Once it&apos;s safe to remove, simply remove the `else` clause you quoted as well as the `FSTableDescriptorMigrationToSubdir` class itself.&lt;/p&gt;</comment>
                            <comment id="14648843" author="lars_francke" created="Fri, 31 Jul 2015 06:58:27 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davelatham&quot; class=&quot;user-hover&quot; rel=&quot;davelatham&quot;&gt;Dave Latham&lt;/a&gt;. I&apos;ll bring it up on the mailing list and will submit a JIRA that fixes wording and deprecation tags.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12642630">HBASE-8348</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12662000">HBASE-9132</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12593576" name="8778-dirmodtime.txt" size="1405" author="lhofhansl" created="Mon, 22 Jul 2013 18:49:44 +0000"/>
                            <attachment id="12589442" name="HBASE-8778-0.94.5-v2.patch" size="78800" author="davelatham" created="Mon, 24 Jun 2013 17:25:28 +0000"/>
                            <attachment id="12588970" name="HBASE-8778-0.94.5.patch" size="78516" author="davelatham" created="Thu, 20 Jun 2013 23:36:18 +0000"/>
                            <attachment id="12594293" name="HBASE-8778-v2.patch" size="83289" author="davelatham" created="Thu, 25 Jul 2013 23:33:54 +0000"/>
                            <attachment id="12594312" name="HBASE-8778-v3.patch" size="83289" author="davelatham" created="Fri, 26 Jul 2013 02:05:37 +0000"/>
                            <attachment id="12595022" name="HBASE-8778-v4.patch" size="83265" author="davelatham" created="Tue, 30 Jul 2013 19:03:44 +0000"/>
                            <attachment id="12595634" name="HBASE-8778-v5.patch" size="83833" author="davelatham" created="Fri, 2 Aug 2013 17:29:41 +0000"/>
                            <attachment id="12594033" name="HBASE-8778.patch" size="82343" author="davelatham" created="Wed, 24 Jul 2013 21:05:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 24 Jun 2013 18:15:26 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>334317</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 20 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1lo5j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>334643</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Table descriptors are now moved inside hdfs from residing directly in the table directory (alongside region directories) to being in a well known subdirectory called &amp;quot;.tabledesc&amp;quot;.  For example, instead of /hbase/exampleTable/.tableinfo.0000000003 the file would be /hbase/exampleTable/.tabledesc/.tableinfo.0000000003 after this release.  The same will be true for snapshots.  The first active master to be started up will move these files for existing tables and snapshots.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.96notable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>