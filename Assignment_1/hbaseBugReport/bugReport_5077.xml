<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:24:33 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5077/HBASE-5077.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5077] SplitLogWorker fails to let go of a task, kills the RS</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5077</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I hope I didn&apos;t break spacetime continuum, I got this while testing 0.92.0:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2011-12-20 03:06:19,838 FATAL org.apache.hadoop.hbase.regionserver.SplitLogWorker: logic error - end task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 done failed because task doesn&apos;t exist&lt;br/&gt;
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)&lt;br/&gt;
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)&lt;br/&gt;
        at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1228)&lt;br/&gt;
        at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.setData(RecoverableZooKeeper.java:372)&lt;br/&gt;
        at org.apache.hadoop.hbase.zookeeper.ZKUtil.setData(ZKUtil.java:654)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.endTask(SplitLogWorker.java:372)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:280)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:197)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:165)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll post more logs in a moment. What I can see is that the master shuffled that task around a bit and one of the region servers died on this stack trace while the others were able to interrupt themselves.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12535910">HBASE-5077</key>
            <summary>SplitLogWorker fails to let go of a task, kills the RS</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jdcryans">Jean-Daniel Cryans</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Tue, 20 Dec 2011 22:00:11 +0000</created>
                <updated>Fri, 20 Nov 2015 11:53:32 +0000</updated>
                            <resolved>Wed, 21 Dec 2011 04:06:16 +0000</resolved>
                                    <version>0.92.0</version>
                                    <fixVersion>0.92.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13173548" author="jdcryans" created="Tue, 20 Dec 2011 22:06:22 +0000"  >&lt;p&gt;This is from the master&apos;s POV:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2011-12-20 02:59:42,086 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: put up splitlog task at znode /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 02:59:42,089 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: task not yet acquired /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 ver = 0&lt;br/&gt;
2011-12-20 02:59:42,113 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 acquired by sv4r13s38,62023,1324345934996&lt;br/&gt;
2011-12-20 03:00:09,244 INFO org.apache.hadoop.hbase.master.SplitLogManager: resubmitting task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 03:00:09,302 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: task not yet acquired /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 ver = 3&lt;br/&gt;
2011-12-20 03:02:53,072 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 acquired by sv4r28s44,62023,1324345934970&lt;br/&gt;
2011-12-20 03:03:21,117 INFO org.apache.hadoop.hbase.master.SplitLogManager: resubmitting task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 03:03:21,136 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: task not yet acquired /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 ver = 6&lt;br/&gt;
2011-12-20 03:04:40,421 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 acquired by sv4r6s38,62023,1324345935082&lt;br/&gt;
2011-12-20 03:05:09,133 INFO org.apache.hadoop.hbase.master.SplitLogManager: resubmitting task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 03:05:09,144 DEBUG org.apache.hadoop.hbase.master.SplitLogManager: task not yet acquired /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 ver = 9&lt;br/&gt;
2011-12-20 03:05:09,193 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 acquired by sv4r30s44,62023,1324345935039&lt;br/&gt;
2011-12-20 03:05:36,137 INFO org.apache.hadoop.hbase.master.SplitLogManager: Skipping resubmissions of task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 because threshold 3 reached&lt;br/&gt;
...&lt;br/&gt;
2011-12-20 03:05:47,139 INFO org.apache.hadoop.hbase.master.SplitLogManager: Skipping resubmissions of task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 because threshold 3 reached&lt;br/&gt;
2011-12-20 03:05:50,320 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 entered state done sv4r30s44,62023,1324345935039&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The one that died is sv4r6s38, the 3rd one to acquire the task. Here&apos;s its log:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2011-12-20 03:04:40,418 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: worker sv4r6s38,62023,1324345935082 acquired task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 03:04:43,574 DEBUG org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter: Path=hdfs://sv4r11s38:9100/hbase/splitlog/sv4r6s38,62023,1324345935082_hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814/TestTable/18010aed747eeb11d1a95427731bb136/recovered.edits/0000000000000031373.temp, syncFs=true, hflush=false&lt;br/&gt;
...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then it sees someone else takes the task but moves on:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2011-12-20 03:05:09,182 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 preempted from sv4r6s38,62023,1324345935082, current task state and owner=unassigned sv4r11s38,62003,1324340331847&lt;br/&gt;
2011-12-20 03:05:09,194 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 preempted from sv4r6s38,62023,1324345935082, current task state and owner=owned sv4r30s44,62023,1324345935039&lt;br/&gt;
2011-12-20 03:05:10,841 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 preempted from sv4r6s38,62023,1324345935082, current task state and owner=owned sv4r30s44,62023,1324345935039&lt;br/&gt;
2011-12-20 03:05:15,089 DEBUG org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter: Path=hdfs://sv4r11s38:9100/hbase/splitlog/sv4r6s38,62023,1324345935082_hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814/TestTable/e710a55d352791b42ea6d588ed38e934/recovered.edits/0000000000000031401.temp, syncFs=true, hflush=false&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This happens another time until it fails to assert ownership of the znode:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2011-12-20 03:06:17,256 WARN org.apache.hadoop.hbase.regionserver.SplitLogWorker: NONODE failed to assert ownership for /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 03:06:17,256 WARN org.apache.hadoop.hbase.regionserver.SplitLogWorker: Failed to heartbeat the task/hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814&lt;br/&gt;
2011-12-20 03:06:17,302 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed hdfs://sv4r11s38:9100/hbase/splitlog/sv4r6s38,62023,1324345935082_hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814/TestTable/12c66fe6163486f5d1d1b6a2b7a5a474/recovered.edits/0000000000000031403.temp&lt;br/&gt;
...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Like a honey badger it doesn&apos;t really care and continues closing files until it reaches a point where it dies with the stack posted in this jira&apos;s description.&lt;/p&gt;</comment>
                            <comment id="13173569" author="zhihyu@ebaysf.com" created="Tue, 20 Dec 2011 22:28:13 +0000"  >&lt;p&gt;After preemption log, the following code should have run:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  void stopTask() {
    LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Sending interrupt to stop the worker thread&quot;&lt;/span&gt;);
    worker.interrupt(); &lt;span class=&quot;code-comment&quot;&gt;// TODO interrupt often gets swallowed, &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; what &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;?
&lt;/span&gt;  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the following method should have been called instead:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void stop() {
    exitWorker = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
    stopTask();
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13173574" author="jdcryans" created="Tue, 20 Dec 2011 22:33:05 +0000"  >&lt;p&gt;Won&apos;t exitWorker kill the SplitLogWorker fully? Like not just the task, but the RS will actually stop serving log splitting.&lt;/p&gt;</comment>
                            <comment id="13173575" author="jdcryans" created="Tue, 20 Dec 2011 22:35:08 +0000"  >&lt;p&gt;One problem I see is that in HLogSplitter.splitLogFileToTemp we do this in the finally:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((progress_failed == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) &amp;amp;&amp;amp; (reporter != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &amp;amp;&amp;amp;
    (reporter.progress() == &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)) {
  progress_failed = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But at this point progress_failed isn&apos;t taken into account so the method returns true. Looking at other parts of that method it seems it&apos;s missing a &quot;return false&quot; which would be correctly handled by SplitLogWorker.&lt;/p&gt;</comment>
                            <comment id="13173577" author="zhihyu@ebaysf.com" created="Tue, 20 Dec 2011 22:40:23 +0000"  >&lt;p&gt;To answer J-D&apos;s question, let me reference the following code from taskLoop():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException e) {
            LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;SplitLogWorker interrupted &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; task,&quot;&lt;/span&gt; +
              &lt;span class=&quot;code-quote&quot;&gt;&quot; exiting: &quot;&lt;/span&gt; + e.toString());
            &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt; exitWorker == &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
          }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where exitWorker was expected to be true. I think the assertion wasn&apos;t triggered at runtime.&lt;/p&gt;</comment>
                            <comment id="13173592" author="jdcryans" created="Tue, 20 Dec 2011 23:02:03 +0000"  >&lt;p&gt;I now understand how I got all the way to closing the files without aborting the splitting, the interrupt is being retried by the DFSClient:&lt;/p&gt;

&lt;blockquote&gt;

&lt;p&gt;2011-12-20 03:05:09,194 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A9100%2Fhbase%2F.logs%2Fsv4r14s38%2C62023%2C1324345935047-splitting%2Fsv4r14s38%252C62023%252C1324345935047.1324349363814 preempted from sv4r6s38,62023,1324345935082, current task state and owner=owned sv4r30s44,62023,1324345935039&lt;br/&gt;
2011-12-20 03:05:09,194 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: Sending interrupt to stop the worker thread&lt;br/&gt;
2011-12-20 03:05:09,214 INFO org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.4.28.44:51010, add to deadNodes and continue&lt;br/&gt;
java.nio.channels.ClosedByInterruptException&lt;br/&gt;
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)&lt;br/&gt;
        at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:511)&lt;br/&gt;
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)&lt;br/&gt;
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:408)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.getBlockReader(DFSClient.java:2354)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:2033)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.seekToBlockSource(DFSClient.java:2483)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2119)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2150)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at java.io.DataInputStream.readFully(DataInputStream.java:178)&lt;br/&gt;
        at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:63)&lt;br/&gt;
        at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:101)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1945)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1845)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1891)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.next(SequenceFileLogReader.java:198)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.next(SequenceFileLogReader.java:172)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getNextLogLine(HLogSplitter.java:764)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:402)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:351)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:113)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:266)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:197)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:165)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;br/&gt;
2011-12-20 03:05:09,216 INFO org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.4.12.38:51010, add to deadNodes and continue&lt;br/&gt;
java.nio.channels.ClosedByInterruptException&lt;br/&gt;
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)&lt;br/&gt;
...&lt;br/&gt;
2011-12-20 03:05:09,220 INFO org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.4.14.38:51010, add to deadNodes and continue&lt;br/&gt;
java.nio.channels.ClosedByInterruptException&lt;br/&gt;
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)&lt;br/&gt;
...&lt;br/&gt;
2011-12-20 03:05:09,223 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_2118163224139708562_43382 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13173660" author="jdcryans" created="Wed, 21 Dec 2011 00:20:45 +0000"  >&lt;p&gt;Adds the missing &quot;return false&quot; (I saw it was already fixed in 0.89-fb) and removed progress_failed since it doesn&apos;t do anything.&lt;/p&gt;</comment>
                            <comment id="13173664" author="zhihyu@ebaysf.com" created="Wed, 21 Dec 2011 00:24:43 +0000"  >&lt;p&gt;Patch looks good.&lt;/p&gt;</comment>
                            <comment id="13173682" author="stack" created="Wed, 21 Dec 2011 00:33:29 +0000"  >&lt;p&gt;Chatting w/ J-D, we shouldn&apos;t return out of middle of finally &amp;#8211; should go through to end via the file closes.&lt;/p&gt;</comment>
                            <comment id="13173685" author="hadoopqa" created="Wed, 21 Dec 2011 00:34:39 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12508163/HBASE-5077.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12508163/HBASE-5077.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -152 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 76 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.TestHeapSize&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/558//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/558//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/558//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/558//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/558//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/558//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13173690" author="jdcryans" created="Wed, 21 Dec 2011 00:38:56 +0000"  >&lt;p&gt;Forgot about the finally block, changing it again to basically add the correct return and print if process_failed is false.&lt;/p&gt;</comment>
                            <comment id="13173705" author="hadoopqa" created="Wed, 21 Dec 2011 00:57:01 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12508167/HBASE-5077-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12508167/HBASE-5077-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated -152 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 76 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.TestHeapSize&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/560//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/560//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/560//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/560//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/560//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/560//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13173832" author="stack" created="Wed, 21 Dec 2011 03:57:40 +0000"  >&lt;p&gt;+1 on patch for branch and trunk.&lt;/p&gt;</comment>
                            <comment id="13173838" author="stack" created="Wed, 21 Dec 2011 04:06:16 +0000"  >&lt;p&gt;Committed branch and trunk.&lt;/p&gt;</comment>
                            <comment id="13173841" author="stack" created="Wed, 21 Dec 2011 04:17:54 +0000"  >&lt;p&gt;This patch actually compiles.&lt;/p&gt;</comment>
                            <comment id="13173879" author="hudson" created="Wed, 21 Dec 2011 06:00:39 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #2565 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/2565/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/2565/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS &amp;#8211; fix compile error&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS&lt;/p&gt;

&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13173933" author="hudson" created="Wed, 21 Dec 2011 07:56:41 +0000"  >&lt;p&gt;Integrated in HBase-0.92 #205 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92/205/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92/205/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS &amp;#8211; fix compile error&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS&lt;/p&gt;

&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13173981" author="hudson" created="Wed, 21 Dec 2011 09:50:26 +0000"  >&lt;p&gt;Integrated in HBase-0.92-security #47 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.92-security/47/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.92-security/47/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS &amp;#8211; fix compile error&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS&lt;/p&gt;

&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.92/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.92/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13174035" author="hudson" created="Wed, 21 Dec 2011 12:21:24 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-security #39 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-security/39/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-security/39/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS &amp;#8211; fix compile error&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5077&quot; title=&quot;SplitLogWorker fails to let go of a task, kills the RS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5077&quot;&gt;&lt;del&gt;HBASE-5077&lt;/del&gt;&lt;/a&gt; SplitLogWorker fails to let go of a task, kills the RS&lt;/p&gt;

&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15016007" author="lars_francke" created="Fri, 20 Nov 2015 11:53:32 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12508167" name="HBASE-5077-v2.patch" size="827" author="jdcryans" created="Wed, 21 Dec 2011 00:38:56 +0000"/>
                            <attachment id="12508196" name="HBASE-5077-v4.txt" size="840" author="stack" created="Wed, 21 Dec 2011 04:17:54 +0000"/>
                            <attachment id="12508163" name="HBASE-5077.patch" size="1410" author="jdcryans" created="Wed, 21 Dec 2011 00:20:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 20 Dec 2011 22:28:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>221593</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i05i3j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>30029</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>