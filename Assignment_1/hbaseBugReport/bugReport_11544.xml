<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:24:12 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-11544/HBASE-11544.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-11544] [Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME</title>
                <link>https://issues.apache.org/jira/browse/HBASE-11544</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Running some tests, I set hbase.client.scanner.caching=1000.  Dataset has large cells.  I kept OOME&apos;ing.&lt;/p&gt;

&lt;p&gt;Serverside, we should measure how much we&apos;ve accumulated and return to the client whatever we&apos;ve gathered once we pass out a certain size threshold rather than keep accumulating till we OOME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12728285">HBASE-11544</key>
            <summary>[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jonathan.lawlor">Jonathan Lawlor</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Fri, 18 Jul 2014 21:54:36 +0000</created>
                <updated>Fri, 18 Mar 2016 13:13:20 +0000</updated>
                            <resolved>Wed, 8 Apr 2015 21:05:31 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>27</watches>
                                                                                                            <comments>
                            <comment id="14066947" author="mantonov" created="Fri, 18 Jul 2014 21:58:51 +0000"  >&lt;p&gt;That seems similar to what we had about RowTooBigException? Is that another side of the same issues?&lt;/p&gt;</comment>
                            <comment id="14066948" author="mantonov" created="Fri, 18 Jul 2014 21:59:22 +0000"  >&lt;p&gt;Oh, you mean - here it&apos;s scanning across the rows, I guess.&lt;/p&gt;</comment>
                            <comment id="14066958" author="mantonov" created="Fri, 18 Jul 2014 22:06:38 +0000"  >&lt;p&gt;I can take this one. Is that server OOME-ing, or client, just to confirm?&lt;/p&gt;</comment>
                            <comment id="14066968" author="lhofhansl" created="Fri, 18 Jul 2014 22:14:37 +0000"  >&lt;ol&gt;
	&lt;li&gt;Or better, server sends reasonable chunks of data, clients requests (or awaits) more data as needed for the API (for example to present a complete row). Anything from 1k to 128k should be good as chunk size. 64k seems fine.&lt;/li&gt;
	&lt;li&gt;Even better: Server streams data to client, client passes data up to caller when it makes sense (i.e. enough data was received to fill a row) and continues to stream if there&apos;s more data. That would keep the network pipe full even for a single client.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This whole affair is about latency vs bandwidth. It has nothing to do with number of rows (that is bad a proxy to fix the issue), but only with how many bytes get sent per RPC request. Too few: bad performance as RTT starts to dominate. Too much: OOM as to much data has to be materialized per RPC request.&lt;/p&gt;

&lt;p&gt;#1 is a good start. Eventually we need to get to #2.&lt;/p&gt;</comment>
                            <comment id="14067262" author="stack" created="Sat, 19 Jul 2014 00:19:14 +0000"  >&lt;p&gt;Server OOMEs &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mantonov&quot; class=&quot;user-hover&quot; rel=&quot;mantonov&quot;&gt;Mikhail Antonov&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14067355" author="anoop.hbase" created="Sat, 19 Jul 2014 02:41:38 +0000"  >&lt;p&gt;Scan#setMaxResultSize(long) and/or  conf &quot;hbase.client.scanner.max.result.size&quot; should help in this right?  We seems handling this in HRS with help of these 2 settings.  By default there is no cap. So setting an appropriate value here should help us to not OOM at HRS &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14067370" author="stack" created="Sat, 19 Jul 2014 04:03:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopsamjohn&quot; class=&quot;user-hover&quot; rel=&quot;anoopsamjohn&quot;&gt;Anoop Sam John&lt;/a&gt; Yes, at least as a first cut.&lt;/p&gt;</comment>
                            <comment id="14067434" author="lhofhansl" created="Sat, 19 Jul 2014 07:56:33 +0000"  >&lt;p&gt;Scan#setMaxResultSize is 1/2 of my #1. When the results do not fit into that size the client will deliver partial rows to the caller, which the caller then has to deal with. Since it can randomly (from the viewpoint of the caller) happen all callers then have to prepared to get multiple results for the same row for different columns, or simply never see a cell if it is too big to fit into this size.&lt;/p&gt;</comment>
                            <comment id="14069614" author="ndimiduk" created="Tue, 22 Jul 2014 00:46:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;It has nothing to do with number of rows (that is bad a proxy to fix the issue), but only with how many bytes get sent per RPC request&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Absolutely right. I don&apos;t want to configure the number of row (changes based on schema). Instead I want hbase to fill the pipe by default. If anything, let me throttle it to a maximum mbps for sharing a network.&lt;/p&gt;</comment>
                            <comment id="14069807" author="enis" created="Tue, 22 Jul 2014 04:35:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;Scan#setMaxResultSize is 1/2 of my #1. When the results do not fit into that size the client will deliver partial rows to the caller, which the caller then has to deal with&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This, and getMaxResultsPerColumnFamily() might actually break the atomicity of edits visibility today. We do not send the mvcc read point to the client, so it can result in partially observing single-row atomic updates. I am just raising this because we have to design for client-side read point tracking if we end up doing streaming, etc. &lt;/p&gt;</comment>
                            <comment id="14074175" author="mantonov" created="Fri, 25 Jul 2014 07:43:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;Anything from 1k to 128k should be good as chunk size. 64k seems fine.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;or simply never see a cell if it is too big to fit into this size.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; as the max cell size now is 10mb IIRC, for the robust solution sounds like we should be able to split the cell and pass the portion of byte array, representing the cell value?&lt;/p&gt;

&lt;p&gt;Thinking on &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;&apos;s note about mvcc readpoint i think yeah, sending partial rows might be much bigger change (though controlling throttling at bytes level would be definitely more efficient than at row level).&lt;/p&gt;

&lt;p&gt;To address the issue with OOM, as a first cut may be we can have 2 thresholds on HRS side, one is for total amount of memory (% of HRS heap size?) which scanner buffers may take (across all clients), and second threshold for max cache size for individual scanners?&lt;/p&gt;

&lt;p&gt;The first threshold would be used to reject new scanners if HRS feels it&apos;s about to OOM, if too many clients try to connect, and second one to prevent one client from eating up all memory by opening scanners for big rows/cells? Thoughts?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; - could you give some details on what was avg/max size of row/cell in your tests, just to estimate of what those thresholds might be in their default values?&lt;/p&gt;
</comment>
                            <comment id="14074806" author="lhofhansl" created="Fri, 25 Jul 2014 19:33:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;as the max cell size now is 10mb IIRC, for the robust solution sounds like we should be able to split the cell and pass the portion of byte array, representing the cell value?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think so. We need to decouple the optimal RPC size from the response size.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;mvcc readpoint i think yeah, sending partial rows might be much bigger change&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why? The readpoint is known/fixed by/for the scanner. We already allow sending partial rows (see Scan.setBatch(...) or the mentioned Scan.setMaxResultSize()). The &quot;only&quot; new part is hat we&apos;d assemble on the client what is expected by the API. Of course that means that we can OOM the client when a &lt;b&gt;single&lt;/b&gt; row gets really large.&lt;/p&gt;

&lt;p&gt;So what I am saying is that we:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;get rid of scanner caching&lt;/li&gt;
	&lt;li&gt;get rid of max result size&lt;/li&gt;
	&lt;li&gt;define an rpcChunkSize (or something). We&apos;d default that to a useful value (maybe 128k), the user can then optimize that depending on the network topology (faster networks would need a larger value)&lt;/li&gt;
	&lt;li&gt;the server would gather data until at least one chunk is filled and then sends the chunk to the client&lt;/li&gt;
	&lt;li&gt;the client would gather chunks until it has enough data to send a row up to the caller&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It would be better to even have a full streaming protocol, but that&apos;s be a bigger change and not fit well into RPC/Protobuf.&lt;/p&gt;

&lt;p&gt;As usually... Just my $0.02 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14075363" author="tianq" created="Sat, 26 Jul 2014 12:16:55 +0000"  >&lt;p&gt;good discussion!&lt;/p&gt;

&lt;p&gt;If I understand correctly, there are 3 concerns here:&lt;br/&gt;
1)OOME error due to big scan cache size.&lt;br/&gt;
most users might not set Scan#setMaxResultSize, or configure &lt;tt&gt;&quot;hbase.client.scanner.max.result.size&quot;&lt;/tt&gt;,&lt;br/&gt;
As Anoop mentioned, there is no cap by default(Long.MAX_VALUE). It looks a bug that we can fix now. adding &quot;total amount of memory threshold to reject new scanners&quot; as Mikhail mentioned, make it more robust .&lt;/p&gt;

&lt;p&gt;2)partial row - cell size is very big&lt;br/&gt;
when we could hit it?&lt;br/&gt;
from my observation of code(0.98.2), if user set Scan.setBatch/Scan.setMaxResultSize, HRegion#nextRaw/HRegionServer#scan use it to limit the number of rows, but not create partial row?&lt;/p&gt;

&lt;p&gt;3)bytes send per RPC request, network bandwidth &lt;br/&gt;
cool.&lt;br/&gt;
my understanding is, hbase can definitely control how to send data, but user still has rights to set how many rows they want to get for a scan?  so they are things at differnt layer, the former at RPC layer, the latter at scan semantics layer? &lt;br/&gt;
if server gather data until at least one chunk is filled and then sends the chunk to the client..what if response data size is smaller than a chunk? in current code the responder send data per call response per socket...but we do can control the write size when it is bigger than the chunk size, since BufferChain#write write to channel as many as possible..&lt;/p&gt;

&lt;p&gt;just my $0.002&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;




</comment>
                            <comment id="14075782" author="lhofhansl" created="Sun, 27 Jul 2014 22:55:09 +0000"  >&lt;p&gt;The user just wants to call scanner.next(), which returns a row. That&apos;s it. Everything else is leaking performance concerns that HBase should handle automatically into the API.&lt;/p&gt;

&lt;p&gt;In the past we mixed the performance concern (too many RPCs for small rows) in with the API (set number of rows). That was obviously a quick fix (mistake). The optimal bytes/RPC ratio is a function of the network bandwidth and latency.&lt;/p&gt;

&lt;p&gt;The only extra API needed on the client is setBatch() so that a client application has a way to deal with rows too large for &lt;b&gt;it&lt;/b&gt; to handle.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;what if response data size is smaller than a chunk?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It just sends what it has.&lt;/p&gt;

&lt;p&gt;I am really not proposing anything different from networking protocols have been doing for 30 years &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14303786" author="jonathan.lawlor" created="Tue, 3 Feb 2015 19:12:21 +0000"  >&lt;p&gt;I have started to look into this issue this past week. I have begun by investigating how &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&apos;s solution #1 could be implemented (solution #2 would be the natural next step afterwards). As discussed above, the currently implementations of setBatch and setMaxResultSize seem to reveal how we could develop a solution for #1:&lt;/p&gt;

&lt;p&gt;Currently, if a user uses the setBatch method on their scan, they will receive partial rows (assuming the batch size is less than the number of columns in the row) on each call to next(). As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; has called out above, this does not break edit atomicity because the scanner maintains the readpoint state on the server. This is an important workflow that we could mimic in the implementation of solution #1: In the event that the entire row does not fit into a chunk, we would be returning partial rows in a manner similar to how batching returns partial rows. &lt;/p&gt;

&lt;p&gt;The implementation of setMaxResultSize is a good starting point for the logic behind rpcChunkSize but it is currently at too high of a level. The current implementation evaluates the limit on the result size after each row&apos;s worth of cells is retrieved. Specifically, in the event that the limit has been set, the server will run through a loop and on each iteration it will retrieve all the cells for one row. The loop will continue until the requested number of rows has been retrieved OR the limit on the result size has been reached. &lt;/p&gt;

&lt;p&gt;The reason why we would need to modify this in the case of rpcChunkSize is because we want the limit to be at the cell level rather than at the row level. If the row has many large cells, the result size limit won&apos;t matter because it will OOME when retrieving the cells for single row. &lt;/p&gt;

&lt;p&gt;In the case that we return a partial row due to the limits of the chunk size, we would want to indicate that the result is indeed a partial with some flag in the returned results. The flag would be necessary so that the client could recognize whether or not it would need to make another RPC request to finish the API call before delivering the results to the caller.&lt;/p&gt;

&lt;p&gt;A couple issues that come to mind with the move to this new rpcChunkSize architecture are highlighted below:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Currently, filters are not always compatible with partial rows (as in the case of setBatch) because sometimes all of the cells within a row are needed to make a decision as to whether or not the row will be filtered. With the introduction of rpcChunkSize, the logic behind evaluating filters may need to be revised. Does anyone have any comments with respect to how this could be handled?&lt;/li&gt;
	&lt;li&gt;The solution #1 would not be able to prevent OOME that result from a single cell being too large (in the same way that the current implementation of setMaxResultSize cannot prevent OOME that result from a single row being too large). The issue of Cells that are too large would need to be addressed with the move to the full streaming protocol of solution #2.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In summary, the approach that I am thinking of taking for solution #1 is:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Remove setMaxResultSize and replace it with a limit that we will call rpcChunkSize&lt;/li&gt;
	&lt;li&gt;Move the logic for rpcChunkSize down into the Cell level so that we can prevent OOME that result from trying to fetch an entire row&apos;s worth of cells&lt;/li&gt;
	&lt;li&gt;Add a flag to Results that allows the client to determine if the Result is a partial (and they need to make more RPC requests to finish off the API call)&lt;/li&gt;
	&lt;li&gt;Add logic on the client side to recognize when they need to make more RPC requests to finish the API call&lt;/li&gt;
	&lt;li&gt;Add a method to combine partial results into a single result before delivering to caller.&lt;/li&gt;
	&lt;li&gt;Still brainstorming how to handle the application of filters server side (any advice here would be much appreciated).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Any feedback on my thought process, the issues I raised, and proposed approach would be greatly appreciated!&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14303810" author="stack" created="Tue, 3 Feb 2015 19:27:38 +0000"  >&lt;p&gt;Excellent &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Speak up &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt; or anyone else interested in this &amp;#8211; would be great to have your input lads.&lt;/p&gt;</comment>
                            <comment id="14306648" author="lhofhansl" created="Thu, 5 Feb 2015 05:12:29 +0000"  >&lt;p&gt;Awesome. That&apos;s exactly what I had in mind.&lt;/p&gt;

&lt;p&gt;Long text and questions follows:&lt;/p&gt;

&lt;p&gt;In the meanwhile we have been doing this: Set Scan.caching to a very high value, and set hbase.client.scanner.max.result.size to 2mb.&lt;br/&gt;
(64k is way too small for 1ge or faster networks, takes only 0.5ms to send of 1ge, and is the ballpark of latency which is at least 0.1-1ms typically, 2mb take 16ms and that&apos;s nice to amortize the latency, i.e. for each 16ms we pay 0.1-1ms of latency, which is acceptable)&lt;/p&gt;

&lt;p&gt;When we stream we only need to fill the bandwidth x latency product. With above number that be only 12.5k (125mb/s bandwidth and 0.1ms roundtrip, if the latency was 1ms it would 125k, and so on). That&apos;s for later.&lt;/p&gt;

&lt;p&gt;So I do take back my statement about chunk sizes between 1-128k. Since we&apos;re &lt;b&gt;not&lt;/b&gt; streaming we need to amortize the latency incurred by each RPC request, and that means at large of chunk size that we can get away with. I found that 2mb is good compromise.&lt;/p&gt;

&lt;p&gt;I think hbase.client.scanner.max.result.size should be the default setting! That will already go a long way. We should do this &lt;b&gt;now&lt;/b&gt;, in all branches.&lt;/p&gt;

&lt;p&gt;With that we always get batches of max 2mb shipped from the server to the client. In the extreme this will only send a single row back per next() RPC if that row is &amp;gt; 2mb.&lt;/p&gt;

&lt;p&gt;So we only have a problem when a single row is &amp;gt; 2mb. So that&apos;s already pretty good.&lt;/p&gt;

&lt;p&gt;Now we need to deal with single large rows. Scanner caching is useless there, that&apos;s why we have batching. That&apos;s a bit more tricky, since it&apos;s not clear to me what the client should do. Should it always wait until it has a whole row as I said above? What if that is too large for &lt;b&gt;it&lt;/b&gt; handle. It seems we always have to at least allow for optional batching of partial rows.&lt;br/&gt;
Single cells are even worse. I like your proposal because it handles even that, at least on the server side. The client will still need to materialize the cell.&lt;/p&gt;

&lt;p&gt;Now, given that we can solve the chunk size problem for many rows by setting hbase.client.scanner.max.result.size, and that we probably need to allow the option to handle partial result at the client anyway, is it worth engaging in this... Unless we do real streaming?&lt;/p&gt;</comment>
                            <comment id="14306663" author="stack" created="Thu, 5 Feb 2015 05:32:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;... and that we probably need to allow the option to handle partial result at the client anyway, is it worth engaging in this... &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Are you suggesting that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;&apos;s list under &quot;...the approach that I am thinking of taking for solution #1 is&quot; above is not needed? His list seems pretty critical.  Could add your making a 2mb rpcChunkSize/max.result.size default as a sub-issue and add another to do the work letting out partial rows if clients configure the scanner to say they are up for handling it.&lt;/p&gt;</comment>
                            <comment id="14306686" author="lhofhansl" created="Thu, 5 Feb 2015 05:45:34 +0000"  >&lt;p&gt;I nutshell I was saying:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;For small rows we&apos;re good if we set existing hbase.client.scanner.max.result.size config correctly. We can do that right now as default.&lt;/li&gt;
	&lt;li&gt;For large rows we need to allow for batching if the client wants to limit its buffer size&lt;/li&gt;
	&lt;li&gt;For large cells we need streaming, if the client wants to limit its buffer size&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;&apos;s approach will get us much further on the way. Just saying that the most important part is streaming.&lt;/p&gt;

&lt;p&gt;I&apos;ll file an issue for #1 - just set that config in hbase-defaults.xml. Then we can concentrate on the other issues here.&lt;/p&gt;</comment>
                            <comment id="14306696" author="lhofhansl" created="Thu, 5 Feb 2015 05:51:33 +0000"  >&lt;p&gt;Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
(By the way that is recent realization I had when testing garbage collection vs. network performance)&lt;/p&gt;</comment>
                            <comment id="14306768" author="mazafir@gmail.com" created="Thu, 5 Feb 2015 07:03:41 +0000"  >&lt;p&gt;We are running HBASE 0.96 and &lt;br/&gt;
hbase.client.scanner.max.result.size is set to default and after reading this thread I set HBASE scanner caching value to 1000 from initial value of 100 . My queries are running are now taking 1000 seconds more . In this case caching is slowing the read performance ? Can you please explain that &lt;/p&gt;

</comment>
                            <comment id="14308054" author="jonathan.lawlor" created="Thu, 5 Feb 2015 21:46:18 +0000"  >&lt;p&gt;Thanks for the feedback &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Setting 2mb as the default maxResultSize definitely makes sense in the current workflow where caching is set very high. In cases where the size limit is hit before the caching limit this will almost be equivalent to how I was thinking of implementing solution #1.&lt;/p&gt;

&lt;p&gt;Certainly the move to a full streaming protocol (solution #2) would be the best solution. However, the implementation of solution #1 seems like it would fix the major pain point of running out of memory on the server and may even help us improve the current paradigm of how the network is used. &lt;/p&gt;

&lt;p&gt;In the move to solution #1 we could improve network usage by reworking the semantics behind Scan#setCaching() (as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; has called out in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt;). Rather than looking to fetch a certain number of rows from an RPC request we woud instead try to ensure that we always fill the maxResultSize in the RPC response sent back (if the chunk cannot be filled, just send back what we have). The rework of the caching could then instead change caching into more of a row limit concept where by default the limit is Long.MAX. Then, in the default case we could service RPC requests on the basis of Batch and MaxResultSize alone. We would no longer need to see if we had accumulated enough rows to meet the caching limit. Instead we would do the following:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;While the maxResultSize has not been reached, accumulate results. If Scan#setBatch() is not set, each Result will represent a row. If Scan#setBatch() is set, each Result will represent a group of cells from a row.&lt;/li&gt;
	&lt;li&gt;The maxResultSize would be checked at the cell level rather than the row level like it currently is. What this means is that rather than fetching a row and seeing if we have met our maxResultSize cap, we would be fetching a cell and seeing if we have hit our maxResultSize cap. This finer grain size check means it will be possible for us to retrieve rows that would otherwise cause OOME exceptions. Thus, the RPC response would be returning a list of Results where the last Result will likely be a partial result (i.e. will not contain all of the cells for its rows) since the maxResultSize limit would be triggered after fetching a cell.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Then on the client side we can determine, maybe based on a new Scan setting, whether or not the caller will be okay with receiving the results for a row in parts (similar to batching). If the caller expects each Result to contain all of the cells for a single row, then we can accumulate the partial results for a row on the client side and then combine them into a single result before adding them to our client side cache (note that as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; has mentioned, this presents the possibility that the client may OOME when reading large rows because the entire row would need to be constructed client side).&lt;/p&gt;

&lt;p&gt;In summary, what the implementation of solution #1 does for us is:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Reduce the likelihood of OOME on the server. OOME may still occur if a single cell is too large for the server to handle. This issue could be fixed with the move to a full streaming protocol (solution #2)&lt;/li&gt;
	&lt;li&gt;Allows the client to retrieve rows that they may otherwise be unable to retrieve currently due to RowTooBigExceptions&lt;/li&gt;
	&lt;li&gt;Provides a finer grained restriction on the ResultSize on the server &amp;#8211; Since the limit on the result size is checked on a cell by cell basis, we will no longer overshoot the result size limit by large amounts when the rows are large&lt;/li&gt;
	&lt;li&gt;Addresses points #1 and #2 of &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&apos;s list above. #3 would be addressed by an implementation of streaming&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The implementation details would be as in my previous comment, but with the addition of changing the semantics behind caching to act more as a limit on the number of rows. Once again, any feedback is greatly appreciated.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14308185" author="lhofhansl" created="Thu, 5 Feb 2015 22:57:05 +0000"  >&lt;p&gt;+1 to everything you said&lt;br/&gt;
And +1 to defer streaming for now, that will be somewhat tricky.&lt;/p&gt;

&lt;p&gt;I think this is implicit but just to be sure: Are planning to keep the caching setting on Scan (maybe names rowLimit now, or whatever)? (So a client who only wants to see the first N rows can avoid downloading an entire batch)&lt;/p&gt;</comment>
                            <comment id="14308200" author="jonathan.lawlor" created="Thu, 5 Feb 2015 23:02:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Yes absolutely, the setting will remain in some form so that the use case you described can be controlled.&lt;/p&gt;</comment>
                            <comment id="14310373" author="lhofhansl" created="Sat, 7 Feb 2015 01:08:37 +0000"  >&lt;p&gt;Somewhat related: RPC is inefficient because it keeps the network idle while the client is producing the request and the server the response.&lt;br/&gt;
Scanning in HBase is particularly dumb about it with caching. We fetch a buffer worth of results, then the client works through that buffer, and as we reach the end the client says &quot;Oh shit&quot; and requests the next buffer. We can start to load the next buffer from the server while the client is working through the current one. (sort of a poor-mans streaming)&lt;/p&gt;

&lt;p&gt;Not sure that fits into this work, but thought I&apos;d mention it.&lt;/p&gt;</comment>
                            <comment id="14310528" author="stack" created="Sat, 7 Feb 2015 03:50:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; Could we do as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; suggests in a follow-on issue?&lt;/p&gt;</comment>
                            <comment id="14312533" author="jonathan.lawlor" created="Mon, 9 Feb 2015 17:58:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; I see what you mean, that definitely seems like it could be improved. I have logged the issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12994&quot; title=&quot;Improve network utilization for scanning RPC requests by preloading the next set of results on the server&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12994&quot;&gt;HBASE-12994&lt;/a&gt; as it seems like it would be dealt with better separately rather than grouped into this change.&lt;/p&gt;</comment>
                            <comment id="14326835" author="jonathan.lawlor" created="Thu, 19 Feb 2015 00:55:54 +0000"  >&lt;p&gt;Hey folks,&lt;/p&gt;

&lt;p&gt;I&apos;ve been working on this issue and I am attaching a patch of what I have so far. Below I have included some discussion points that would be great to get some feedback on:&lt;/p&gt;

&lt;p&gt;A few issues were encountered while implementing a solution for this problem. The issues, as well as their current solutions, are outlined below (any feedback on alternative ways to solve these problems would be appreciated):&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In some cases, the concept of partial results doesn&apos;t seem appropriate. In these cases, I ensured that partial results would not be created as it would only hurt performance or cause confusion. The cases where I felt partial results should be avoided were:
	&lt;ul&gt;
		&lt;li&gt;When the client has defined a filter for their scan that requires the entire row to be read.&lt;/li&gt;
		&lt;li&gt;When the client has specified that the scan is a Small scan. Small scans are designed to execute in a single RPC request and so the idea of having to make multiple RPC requests to form the complete Result seems inappropriate&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;When I changed the default value of caching to Integer.MAX_VALUE I was running into OOME on the server since caching is used to presize the ArrayList that holds results. A simple solution to this is to simply not set an initial size on the array list. However, this solution may still run into memory issues if the ArrayList must expand the underlying array many times (e.g. if the table being scanned has many small rows leading to a large amount of Results in the array list). I was wondering what everyone thought of the simple solution. If a more sophisticated solution is required it may be best to move the caching change into its own JIRA.&lt;/li&gt;
	&lt;li&gt;When combining the partial results into a single complete result on the client side, an exception will be thrown from within ResultScanner#next() if it is found that the partial results belong to different rows. This is a corner case issue that should never show up since sequence numbers are already used in each RPC request to ensure proper ordering of request/responses but I figured it is worth mentioning&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The fine grained details of implementation can be seen in the patch, but I thought it would be worth highlighting  how this new partial result workflow can be used to avoid OOME on the server:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The setting of Scan#setMaxResultSize will now operate at the cell level rather than the row level. This allows a client to retrieve very large rows in fragments/partials that would previously cause the server to OOME. By default, the entire complete result will only be formed on the client side, whereas the server will only ever see partial Results for very large rows.&lt;/li&gt;
	&lt;li&gt;A new option (Scan#setAllowPartials) has been added to Scans to allow the client to see the partial results returned by the server. This setting will be useful in cases where the client would OOME if they were forced to reconstruct the complete result.&lt;/li&gt;
	&lt;li&gt;If clients want to utilize this partial result workflow, they should use non-filtered, non-small scans (see issues above for reasoning).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Areas for future improvement:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; has pointed out, RPC is inefficient and could be improved by prefetching results server side. This issue has been raised in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12994&quot; title=&quot;Improve network utilization for scanning RPC requests by preloading the next set of results on the server&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12994&quot;&gt;HBASE-12994&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;As called out in the issues above, the initial sizing of the ArrayList on the server side seems like it could be improved to avoid resizing of the underlying array&lt;/li&gt;
	&lt;li&gt;Streaming is the most ideal workflow for RPC requests but will require a large rework&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Any feedback on the patch would be greatly appreciated. I am expecting the QA run to come back with some test failures which I will address in a subsequent patch. I&apos;m pinging &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; as we were discussing this solution above, but if anyone else has any feedback it would be appreciated as well!&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14326878" author="stack" created="Thu, 19 Feb 2015 01:51:08 +0000"  >&lt;p&gt;Nice.&lt;/p&gt;

&lt;p&gt;A few quick comments.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When the client has defined a filter for their scan that requires the entire row to be read.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So, even if in excess of the requested size, we&apos;ll still return the full row in this case?&lt;/p&gt;

&lt;p&gt;You set some flag on the scanner when it has to do full-row regardless?&lt;/p&gt;

&lt;p&gt;Your handling of small scan, not doing partials, makes sense.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When I changed the default value of caching to Integer.MAX_VALUE I was running into OOME on the server since caching is used to presize the ArrayList that holds results.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats kinda dumb (smile).&lt;/p&gt;

&lt;p&gt;Simple solution is fine I&apos;d say. There is no way to know up front how many Results will be returned.&lt;/p&gt;

&lt;p&gt;Otherwise, all sounds great.... let me look at the patch....&lt;/p&gt;



</comment>
                            <comment id="14326909" author="jonathan.lawlor" created="Thu, 19 Feb 2015 02:20:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;So, even if in excess of the requested size, we&apos;ll still return the full row in this case?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Correct, the maxResultSize would work in the same way that it works rights now (i.e. after each full row is retrieved, the accumulated result size is checked against the maxResultSize). This means the requested size may be significantly exceeded if there is a very large row (e.g. a row whose net size is many times larger than the requested size). &lt;/p&gt;

&lt;p&gt;I should note that not all filters will trigger this behavior, but rather only those filters that have Filter#hasFilterRow() return true.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You set some flag on the scanner when it has to do full-row regardless?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A flag hasn&apos;t been added to the scanner but rather the decision to do full-rows is made by looking at Filter#hasFilterRow and using an appropriate value of remainingResultSize (-1 indicates no limit on the result size, and thus entire rows will be returned).&lt;/p&gt;</comment>
                            <comment id="14326930" author="hadoopqa" created="Thu, 19 Feb 2015 02:56:13 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12699582/HBASE-11544-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12699582/HBASE-11544-v1.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 31f17b17f0e2d12550b97098ec45ab59c5d98d58.&lt;br/&gt;
  ATTACHMENT ID: 12699582&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 20 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000002) == 0x00000002) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;PartialFlagPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, }
&lt;p&gt;);&lt;br/&gt;
+  public boolean next(List&amp;lt;Cell&amp;gt; outResult, int limit, long remainingResultSize) throws IOException {&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.TestAcidGuarantees.testScanAtomicity(TestAcidGuarantees.java:354)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12903//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14327060" author="lhofhansl" created="Thu, 19 Feb 2015 07:05:47 +0000"  >&lt;p&gt;Excellent. Minor comments:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When I changed the default value of caching to Integer.MAX_VALUE I was running into OOME on the server since caching is used to presize the ArrayList that holds results. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Meh &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Sorry I missed that when I did the simple change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
Yeah, simple solution is good. I&apos;d actually like to change that size in all branches now, even before we finish this. Any objections?&lt;/p&gt;

&lt;p&gt;Quick note on small scans: They do not necessarily finish in one RPC. The difference is that they do not hold any state on the server, which means each RPC needs to re-setup the scanner stack, which is expensive, they also do p-reads by default. But you&apos;re absolutely right, when need partial results you sure-as-hell do not want to use a small scan.&lt;/p&gt;

&lt;p&gt;This: &quot;The setting of Scan#setMaxResultSize will now operate at the cell level rather than the row level. &quot; does not compute with this: &quot;whereas the server will only ever see partial Results for very large rows.&quot;&lt;/p&gt;

&lt;p&gt;Is the limit per cell or per row?&lt;/p&gt;</comment>
                            <comment id="14327722" author="jonathan.lawlor" created="Thu, 19 Feb 2015 16:53:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; thanks for the comments&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is the limit per cell or per row?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, let me be clear in what I mean when I say cell level and row level:&lt;/p&gt;

&lt;p&gt;Partitioning at the row level (the current behavior):&lt;br/&gt;
Currently, the maxResultSize operates at the row level on the server. What I mean by this is that the result size limit is checked after each row&apos;s worth of cells is fetched. This presented the problem of running into OOME for large rows because a single row may be many times larger than the maxResultSize. Thus, when trying to retrieve all the cells for a single large row we would continue to traverse the row even when we had already passed the result size limit, and only realize we had exceeded the limit once the entire row&apos;s worth of cells had been retrieved.&lt;/p&gt;

&lt;p&gt;Partitioning at the cell level (the new behavior):&lt;br/&gt;
The solution that has been implemented above moves the concept of maxResultSize down from the row level to the cell level. What this means is that the result size limit is checked after each cell/keyValue is fetched. This is nice because it provides a more precise size restriction on result size than the current solution. When the result size limit is reached while fetching the cells/keyValues for a particular row, that row will be returned as partial results that must be reconstructed client-side (i.e. the server will never contain the entire row&apos;s worth of cells in memory at once).&lt;/p&gt;

&lt;p&gt;So when I said the server will only ever see partial results for very large rows, what I mean is: if the row is very large, the server will be returning partial results for that row in separate RPC responses, and thus, will never hold the entire row in memory but rather parts of it at different points in time.&lt;/p&gt;</comment>
                            <comment id="14328259" author="stack" created="Thu, 19 Feb 2015 22:53:47 +0000"  >&lt;p&gt;Put the patch on review board &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14328274" author="jonathan.lawlor" created="Thu, 19 Feb 2015 23:02:33 +0000"  >&lt;p&gt;New patch to address javadoc and line length issues; test failure looks unrelated. Will post now to reviewboard&lt;/p&gt;</comment>
                            <comment id="14328405" author="hadoopqa" created="Fri, 20 Feb 2015 01:10:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12699762/HBASE-11544-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12699762/HBASE-11544-v2.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 365054c110467d0628019761791281875631f4be.&lt;br/&gt;
  ATTACHMENT ID: 12699762&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 20 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000002) == 0x00000002) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;PartialFlagPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.quotas.TestQuotaThrottle&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.coprocessor.TestMasterObserver.testRegionTransitionOperations(TestMasterObserver.java:1604)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12917//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14328516" author="lhofhansl" created="Fri, 20 Feb 2015 03:49:13 +0000"  >&lt;p&gt;Sounds good.&lt;br/&gt;
I&apos;ll fix the array size issues tonight.&lt;/p&gt;</comment>
                            <comment id="14329592" author="jonathan.lawlor" created="Fri, 20 Feb 2015 21:33:46 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Cleanup a bunch of whitepace&lt;/li&gt;
	&lt;li&gt;Configure the scans in failing TestAcidGuarantees to use previous default configuration of caching=100 and maxResultSize=Long.Max_Value&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14329769" author="hadoopqa" created="Fri, 20 Feb 2015 23:40:31 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12699942/HBASE-11544-v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12699942/HBASE-11544-v3.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 9a311303a88d355f8c982d2f3cc77bd6427dfb80.&lt;br/&gt;
  ATTACHMENT ID: 12699942&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 24 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000002) == 0x00000002) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;PartialFlagPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.TestAcidGuarantees.testScanAtomicity(TestAcidGuarantees.java:354)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12929//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14329780" author="jonathan.lawlor" created="Fri, 20 Feb 2015 23:50:44 +0000"  >&lt;p&gt;Going to investigate this issue further&lt;/p&gt;</comment>
                            <comment id="14337367" author="jonathan.lawlor" created="Wed, 25 Feb 2015 22:40:44 +0000"  >&lt;p&gt;New patch to reflect the most recent feedback from ReviewBoard. &lt;/p&gt;

&lt;p&gt;The failures that have been seen with respect the TestAcidGuarantees seem to be unrelated and have been called out in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13097&quot; title=&quot;Use same EventLoopGroup for different AsyncRpcClients if possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13097&quot;&gt;&lt;del&gt;HBASE-13097&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the more significant changes that this patch introduces is a rework of the return type of InternalScanner#next(). Rather than simply return a boolean, a state object is now returned. This allows callers of InternalScanner#next() determine important state information about the scanner. It also helps us avoid unnecessary replication of size calculations.&lt;/p&gt;</comment>
                            <comment id="14337384" author="jonathan.lawlor" created="Wed, 25 Feb 2015 22:47:57 +0000"  >&lt;p&gt;Whoops, wrong patch posted before... correct one here&lt;/p&gt;</comment>
                            <comment id="14337491" author="hadoopqa" created="Wed, 25 Feb 2015 23:45:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12700890/HBASE-11544-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12700890/HBASE-11544-v4.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit c651271f5759f39f282099999a50ab88a62d86b7.&lt;br/&gt;
  ATTACHMENT ID: 12700890&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 5 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1944 checkstyle errors (more than the master&apos;s current 1938 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;br/&gt;
+                  joinedHeapState != null &amp;amp;&amp;amp; joinedHeapState.hasResultSizeEstimate() ? joinedHeapState&lt;br/&gt;
+   * @return state where &lt;/p&gt;
{@link NextState#hasMoreValues()} is true if more rows exist after this one,&lt;br/&gt;
+   * @return state where {@link NextState#hasMoreValues()}
&lt;p&gt; is true if more rows exist after this one,&lt;br/&gt;
+   * @return a state where &lt;/p&gt;
{@link NextState#hasMoreValues()}
&lt;p&gt; is true when more rows exist, false when&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.encoding.TestPrefixTree&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12968//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14337545" author="jonathan.lawlor" created="Thu, 26 Feb 2015 00:18:03 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fix line lengths&lt;/li&gt;
	&lt;li&gt;Fix test failure of TestPrefixTree to recognize new return type&lt;/li&gt;
	&lt;li&gt;Throw exceptions in the case that a NextState is observed to be invalid&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14337713" author="hadoopqa" created="Thu, 26 Feb 2015 02:16:12 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12700917/HBASE-11544-v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12700917/HBASE-11544-v5.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 7195f62114ce68dfa94115443d2b27cd2d7df01c.&lt;br/&gt;
  ATTACHMENT ID: 12700917&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 5 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestHRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestStoreScanner&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12970//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14338707" author="jonathan.lawlor" created="Thu, 26 Feb 2015 17:05:07 +0000"  >&lt;p&gt;New patch to fix the tests that were failing due to the new return type from InteralScanner&lt;/p&gt;</comment>
                            <comment id="14338767" author="jonathan.lawlor" created="Thu, 26 Feb 2015 17:42:47 +0000"  >&lt;p&gt;Forgot to include these javadoc fixes in last patch&lt;/p&gt;</comment>
                            <comment id="14338941" author="hadoopqa" created="Thu, 26 Feb 2015 19:14:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12701119/HBASE-11544-v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12701119/HBASE-11544-v6.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 49b4f3737eb0dd7c5d88d6dcbe8b5d4f167c6a2b.&lt;br/&gt;
  ATTACHMENT ID: 12701119&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 5 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestFullLogReconstruction&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.testRegionMerge(TestNamespaceAuditor.java:308)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12980//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14338960" author="jonathan.lawlor" created="Thu, 26 Feb 2015 19:25:50 +0000"  >&lt;p&gt;This is the QA run for the patch without the javadoc corrections. Still waiting for next run&lt;/p&gt;</comment>
                            <comment id="14339025" author="hadoopqa" created="Thu, 26 Feb 2015 19:46:13 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12701130/HBASE-11544-v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12701130/HBASE-11544-v6.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 49b4f3737eb0dd7c5d88d6dcbe8b5d4f167c6a2b.&lt;br/&gt;
  ATTACHMENT ID: 12701130&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12981//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14339046" author="jonathan.lawlor" created="Thu, 26 Feb 2015 19:56:32 +0000"  >&lt;p&gt;Test passes locally, retry&lt;/p&gt;</comment>
                            <comment id="14339267" author="hadoopqa" created="Thu, 26 Feb 2015 22:04:15 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12701159/HBASE-11544-v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12701159/HBASE-11544-v6.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 49b4f3737eb0dd7c5d88d6dcbe8b5d4f167c6a2b.&lt;br/&gt;
  ATTACHMENT ID: 12701159&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12984//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14339271" author="jonathan.lawlor" created="Thu, 26 Feb 2015 22:06:13 +0000"  >&lt;p&gt;Line length violations are in the auto generated protobuf classes&lt;/p&gt;</comment>
                            <comment id="14339380" author="stack" created="Thu, 26 Feb 2015 23:09:18 +0000"  >&lt;p&gt;Let me run this on cluster and get some pretty pictures before we check in.&lt;/p&gt;</comment>
                            <comment id="14341378" author="stack" created="Sat, 28 Feb 2015 06:30:39 +0000"  >&lt;p&gt;Currently run cluster test to ensure no breakage and to look for perf degradation (hopefully we see opposite).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; which of the tests in TestPartialResultsFromClientSide verifies that a client who is getting partial results has same view as a client who is asking for full rows at a time; i.e. which tests readpoint is not changed under a scanner that is returning a wide row in multiple partials? Thanks boss.&lt;/p&gt;</comment>
                            <comment id="14341826" author="stack" created="Sat, 28 Feb 2015 23:22:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; For testing, can I have a backport to branch-1.0? Thanks boss.&lt;/p&gt;</comment>
                            <comment id="14343426" author="jonathan.lawlor" created="Mon, 2 Mar 2015 17:31:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; testEquivalenceOfScanResults is what you&apos;re looking for &amp;#8211; the test takes two Scans and verifies that the Results returned from both are equivalent&lt;/p&gt;</comment>
                            <comment id="14343540" author="jonathan.lawlor" created="Mon, 2 Mar 2015 18:27:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; Attaching a patch for branch-1.0. Compiles and passes all tests in TestPartialResultsFromClientSide so it should be okay.&lt;/p&gt;</comment>
                            <comment id="14343544" author="hadoopqa" created="Mon, 2 Mar 2015 18:32:38 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12701932/HBASE-11544-branch_1_0-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12701932/HBASE-11544-branch_1_0-v1.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 7b5c9eabacf5019d5b6aba95ba5a4fcb7dc8d8e5.&lt;br/&gt;
  ATTACHMENT ID: 12701932&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13036//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13036//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14346056" author="jonathan.lawlor" created="Wed, 4 Mar 2015 00:08:25 +0000"  >&lt;p&gt;Recent changes pushed to branch-1.0 prevents a clean apply of the previous patch. Attaching an updated branch-1.0 patch for testing&lt;/p&gt;</comment>
                            <comment id="14346063" author="hadoopqa" created="Wed, 4 Mar 2015 00:14:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12702311/HBASE-11544-branch_1_0-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12702311/HBASE-11544-branch_1_0-v2.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 883d6fd8e512b14c967d2f7acf78d2b1d40e40fe.&lt;br/&gt;
  ATTACHMENT ID: 12702311&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13073//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13073//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14346642" author="stack" created="Wed, 4 Mar 2015 09:29:31 +0000"  >&lt;p&gt;Here&apos;s some pictures. I ran three profiles:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Current branch-1.0&lt;/li&gt;
	&lt;li&gt;Branch-1.0 with the 1.0 patch from here&lt;/li&gt;
	&lt;li&gt;Above but I set configuration so size was such that maybe 10-20% of the returns required partials.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Dataset was 100M rows of ten columns zipfian sized between 0 and 8k. Avg row size somewhere between 160 and 220.&lt;/p&gt;

&lt;p&gt;For each set up, did two tests: one with many clients and one with just two clients.&lt;/p&gt;

&lt;p&gt;Looks like patch doesn&apos;t change general profile.  With config in place, a bit more GC probably because a bit more work was done &amp;#8211; extra rpcs &amp;#8211; but hit rate seems a bit higher... more throughput.  One odd thing is that the mean time seems to have gone up a little when partials going on.&lt;/p&gt;

&lt;p&gt;Patch looking good. Let me commit tomorrow. I suppose its fine to start w/ 2MB as default size.&lt;/p&gt;

&lt;p&gt;Need a release note &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14347317" author="jonathan.lawlor" created="Wed, 4 Mar 2015 18:25:20 +0000"  >&lt;p&gt;Attaching patch that has been rebased to master&lt;/p&gt;

&lt;p&gt;While investigating potential causes of increased mean time I noticed a small bug where NextState.NO_MORE_VALUES was being returned from KeyValueHeap#next() inappropriately (didn&apos;t cause issues because users of this state weren&apos;t actually using this state, just the Results returns from the call). This bug has been corrected in this patch but will not provide any performance increase. &lt;/p&gt;

&lt;p&gt;Let&apos;s put it through a final QA run to make sure this fix hasn&apos;t created any new issues. I will fill out the release notes shortly&lt;/p&gt;</comment>
                            <comment id="14347547" author="hadoopqa" created="Wed, 4 Mar 2015 20:42:01 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12702571/HBASE-11544-v7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12702571/HBASE-11544-v7.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 883d6fd8e512b14c967d2f7acf78d2b1d40e40fe.&lt;br/&gt;
  ATTACHMENT ID: 12702571&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13082//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14347629" author="jonathan.lawlor" created="Wed, 4 Mar 2015 21:53:26 +0000"  >&lt;p&gt;Javadoc warnings are unrelated. The lines with warnings were not modified by this patch&lt;/p&gt;</comment>
                            <comment id="14347701" author="jonathan.lawlor" created="Wed, 4 Mar 2015 22:34:13 +0000"  >&lt;p&gt;Attaching new rebased patch. Previous one no longer applies cleanly to master &lt;/p&gt;</comment>
                            <comment id="14347857" author="hadoopqa" created="Thu, 5 Mar 2015 00:51:05 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12702626/HBASE-11544-v8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12702626/HBASE-11544-v8.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit d1ca560ff72bd97faa94fce025bf126702bbdd1b.&lt;br/&gt;
  ATTACHMENT ID: 12702626&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 4 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hdfs.TestDecommission.testRecommission(TestDecommission.java:643)&lt;br/&gt;
	at org.apache.hadoop.hdfs.TestDecommission.testRecommission(TestDecommission.java:415)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13084//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14347896" author="jonathan.lawlor" created="Thu, 5 Mar 2015 01:21:02 +0000"  >&lt;p&gt;javadoc warnings are unrelated. Looks like these javadoc warnings were caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13109&quot; title=&quot;Make better SEEK vs SKIP decisions during scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13109&quot;&gt;&lt;del&gt;HBASE-13109&lt;/del&gt;&lt;/a&gt;. Running findHangingTests reveals that TestMasterObserver is the hanging test which is being investigated over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13150&quot; title=&quot;TestMasterObserver failing disable table at end of test&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13150&quot;&gt;&lt;del&gt;HBASE-13150&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14347919" author="stack" created="Thu, 5 Mar 2015 01:36:20 +0000"  >&lt;p&gt;Pushed to master.&lt;/p&gt;</comment>
                            <comment id="14347929" author="jonathan.lawlor" created="Thu, 5 Mar 2015 01:43:43 +0000"  >&lt;p&gt;Attaching patch for branch-1&lt;/p&gt;</comment>
                            <comment id="14347967" author="stack" created="Thu, 5 Mar 2015 02:05:13 +0000"  >&lt;p&gt;Pushed to branch-1+. Thank you for the very sweet building block &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; fixing a long-standing issue.&lt;/p&gt;</comment>
                            <comment id="14348027" author="hadoopqa" created="Thu, 5 Mar 2015 02:41:37 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12702662/HBASE-11544-v8-branch-1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12702662/HBASE-11544-v8-branch-1.patch&lt;/a&gt;&lt;br/&gt;
  against branch-1 branch at commit de9791e91e83005712cd276fce99f354a62c467a.&lt;br/&gt;
  ATTACHMENT ID: 12702662&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 148 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 4 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 3814 checkstyle errors (more than the master&apos;s current 3811 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +              if (!((mutable_bitField0_ &amp;amp; 0x00000040) == 0x00000040) &amp;amp;&amp;amp; input.getBytesUntilLimit() &amp;gt; 0) {&lt;br/&gt;
+      private java.util.List&amp;lt;java.lang.Boolean&amp;gt; partialFlagPerResult_ = java.util.Collections.emptyList();&lt;br/&gt;
+      &quot; \001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007&quot; +&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Cell&quot;, &quot;AssociatedCellCount&quot;, &quot;Exists&quot;, &quot;Stale&quot;, &quot;Partial&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;Region&quot;, &quot;Scan&quot;, &quot;ScannerId&quot;, &quot;NumberOfRows&quot;, &quot;CloseScanner&quot;, &quot;NextCallSeq&quot;, &quot;ClientHandlesPartials&quot;, }
&lt;p&gt;);&lt;br/&gt;
+              new java.lang.String[] &lt;/p&gt;
{ &quot;CellsPerResult&quot;, &quot;ScannerId&quot;, &quot;MoreResults&quot;, &quot;Ttl&quot;, &quot;Results&quot;, &quot;Stale&quot;, &quot;PartialFlagPerResult&quot;, }
&lt;p&gt;);&lt;br/&gt;
+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 3b6145e... &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt;: &lt;span class=&quot;error&quot;&gt;&amp;#91;Ergonomics&amp;#93;&lt;/span&gt; hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.encoding.TestPrefixTree&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13087//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14348032" author="hudson" created="Thu, 5 Mar 2015 02:50:56 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.1 #249 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.1/249/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.1/249/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt;: &lt;span class=&quot;error&quot;&gt;&amp;#91;Ergonomics&amp;#93;&lt;/span&gt; hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME (stack: rev 0c64a57e529d591a96d56721a1ae538167a03a11)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointWithErrors.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallableWithReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java&lt;/li&gt;
	&lt;li&gt;hbase-protocol/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ReversedClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/RowCountEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMajorCompaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ResponseConverter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlusher.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestReversibleScanners.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultMemStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/InternalScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMultiColumnScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestBlocksScanned.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeCompactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestStripeCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointNullResponse.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestPartialResultsFromClientSide.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSeekOptimizations.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestColumnSeeking.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/BulkDeleteEndpoint.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14348064" author="hudson" created="Thu, 5 Mar 2015 03:31:52 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #6207 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6207/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6207/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt;: &lt;span class=&quot;error&quot;&gt;&amp;#91;Ergonomics&amp;#93;&lt;/span&gt; hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME (stack: rev de9791e91e83005712cd276fce99f354a62c467a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;hbase-protocol/src/main/protobuf/Client.proto&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeCompactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointNullResponse.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlusher.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMajorCompaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;/li&gt;
	&lt;li&gt;hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointWithErrors.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/BulkDeleteEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestReversibleScanners.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestColumnSeeking.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestPartialResultsFromClientSide.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestBlocksScanned.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/InternalScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallableWithReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMultiColumnScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestStripeCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ReversedClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ResponseConverter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultMemStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSeekOptimizations.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/RowCountEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14370147" author="lhofhansl" created="Thu, 19 Mar 2015 21:26:14 +0000"  >&lt;p&gt;With &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; reverted, this will have to be reverted until we can think of a proper fix. Doing that now. Sorry.&lt;/p&gt;</comment>
                            <comment id="14370154" author="lhofhansl" created="Thu, 19 Mar 2015 21:28:01 +0000"  >&lt;p&gt;And of course it does not revert cleanly because I reverted &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; first. Crap... Working on the merge now.&lt;/p&gt;</comment>
                            <comment id="14370164" author="stack" created="Thu, 19 Mar 2015 21:33:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Hey, whats the plan? Want to bring it up on dev list so we can follow along?&lt;/p&gt;</comment>
                            <comment id="14370180" author="jonathan.lawlor" created="Thu, 19 Mar 2015 21:41:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; I believe simply rolling back the change made to the default value of caching would be sufficient (it should no longer be Integer.MAX_VALUE if the maxResultSize default is no longer 2mb). It was changed from 100 to Integer.MAX_VALUE. This could be performed in a separate JIRA I think, similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13292&quot; title=&quot;Undo parent from 0.98 and 1.0: setting hbase.client.scanner.max.result.size is considered harmful&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13292&quot;&gt;&lt;del&gt;HBASE-13292&lt;/del&gt;&lt;/a&gt;. Partial results will continue to work as expected even with the revert of the caching default.&lt;/p&gt;</comment>
                            <comment id="14370182" author="lhofhansl" created="Thu, 19 Mar 2015 21:41:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, Have a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13262&quot; title=&quot;ResultScanner doesn&amp;#39;t return all rows in Scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13262&quot;&gt;&lt;del&gt;HBASE-13262&lt;/del&gt;&lt;/a&gt;. It&apos;s pretty messed up.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; needed to be reverted due to what we found in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12362&quot; title=&quot;Interim documentation of important master and regionserver metrics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12362&quot;&gt;&lt;del&gt;HBASE-12362&lt;/del&gt;&lt;/a&gt;, this one relies on it (otherwise most scans will now OOM).&lt;/p&gt;

&lt;p&gt;I can leave this one in, since we do not have a release for 1.1 or 2.0, but I assume many tests will now fail with OOMs. Or I can put &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; for 1.1 and 2.0 for the same reason. (maybe I was a bit hasty with the revert in those branches).&lt;/p&gt;

&lt;p&gt;I don&apos;t think a dev-list discussion will help. The revert for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; is a blocker for 0.98.&lt;/p&gt;</comment>
                            <comment id="14370183" author="lhofhansl" created="Thu, 19 Mar 2015 21:42:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;... I see. Makes sense, lemme do that. The other option is to keep 2mb size limit in 1.1 and 2.0, assuming we&apos;ll work out the tricky parts before we release those.&lt;/p&gt;</comment>
                            <comment id="14370184" author="lhofhansl" created="Thu, 19 Mar 2015 21:44:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, the gist is if the client does not also see a 2mb size limit in its configuration it will silently ignore all data past the first 2mb of a region and simply skip to the next one. Not good &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14370186" author="lhofhansl" created="Thu, 19 Mar 2015 21:45:45 +0000"  >&lt;p&gt;OK. What&apos;s the verdict? Reset the limit to 100 here, or keep &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; in 1.1 and 2.0? I&apos;m actually inclined towards the latter.&lt;/p&gt;</comment>
                            <comment id="14370200" author="lhofhansl" created="Thu, 19 Mar 2015 21:53:45 +0000"  >&lt;p&gt;Lemme just &quot;unrevert&quot; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;del&gt;HBASE-12976&lt;/del&gt;&lt;/a&gt; from 1.1 and 2.0. Sorry for the noise here, it&apos;s just important to avoid unexpected behavior.&lt;/p&gt;</comment>
                            <comment id="14370612" author="enis" created="Fri, 20 Mar 2015 02:54:06 +0000"  >&lt;p&gt;There is one more issue here. We are changing the RegionScanner interface which is marked Stable for coprocessors which we also say that we will not break (see the book). Phoenix have a lot of &lt;tt&gt;RegionScanner&lt;/tt&gt;&apos;s which does not compile anymore.&lt;/p&gt;

&lt;p&gt;Can we do an internal-shim here? &lt;/p&gt;</comment>
                            <comment id="14370652" author="stack" created="Fri, 20 Mar 2015 03:33:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; This patch is in branch-1 and master only.  We say in our semvar: &quot;At this point, HBase only guarantees source and binary compatibility for these interfaces between patch versions.&quot; Do I have an incorrect understanding?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Lets see what the root cause of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12362&quot; title=&quot;Interim documentation of important master and regionserver metrics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12362&quot;&gt;&lt;del&gt;HBASE-12362&lt;/del&gt;&lt;/a&gt; is before taking action?  If doing size-based scans, it &apos;worked&apos; for multiple versions if I am not mistaken;  or have you confirmed the issue in 0.98?&lt;/p&gt;</comment>
                            <comment id="14371824" author="enis" created="Fri, 20 Mar 2015 18:39:15 +0000"  >&lt;p&gt;I was referring to &quot;Server-Side Limited API Compatibility, sub section Stable&quot; in &lt;a href=&quot;https://hbase.apache.org/book.html#hbase.versioning&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hbase.apache.org/book.html#hbase.versioning&lt;/a&gt;. RegionScanner is marked Stable, we should at least change it to Evolving to reflect reality then. &lt;/p&gt;</comment>
                            <comment id="14371896" author="stack" created="Fri, 20 Mar 2015 19:18:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; Our semvar internally conflicts!&lt;/p&gt;

&lt;p&gt;Our &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; suggests new issue to change to Evolving as per your above. This is a long-standing bug/improvement that will make the world a better place.&lt;/p&gt;</comment>
                            <comment id="14371948" author="jonathan.lawlor" created="Fri, 20 Mar 2015 19:45:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; Apologies for not catching this one during initial implementation. I have filed a follow on issue here: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13306&quot; title=&quot;Change RegionScanner interface from stable to evolving&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13306&quot;&gt;HBASE-13306&lt;/a&gt;, thanks for catching this one!&lt;/p&gt;</comment>
                            <comment id="14371953" author="lhofhansl" created="Fri, 20 Mar 2015 19:46:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;Our semvar internally conflicts!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It does? If so, we should fix it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;or have you confirmed the issue in 0.98?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, if you have a client with a different (larger) value for hbase.client.scanner.max.result.size compared to the server you&apos;ll run into this issue. This can easily happen if the two do not share the exact same hbase-site.xml file.&lt;/p&gt;</comment>
                            <comment id="14371959" author="lhofhansl" created="Fri, 20 Mar 2015 19:49:19 +0000"  >&lt;p&gt;Sorry accidentally, somehow changed the assignee to me. That was unintended, just changed it back to Jonathan.&lt;/p&gt;</comment>
                            <comment id="14374828" author="lhofhansl" created="Sun, 22 Mar 2015 07:28:19 +0000"  >&lt;p&gt;Did anybody perf-test this before it committed? Looking at the patch, it creates a lot of new object is many of the hot code paths. I do not have a good test-rig for trunk code right now.&lt;/p&gt;</comment>
                            <comment id="14376125" author="jonathan.lawlor" created="Mon, 23 Mar 2015 16:23:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; We did run some perf tests on this patch prior to committing, see stack&apos;s comment above (search for: comment - 04/Mar/15 01:29). Seems that the general profile did not change much. We noticed a slight increase in GC activity likely due to increased RPC and creation of new objects and a slight increase in throughput.&lt;/p&gt;</comment>
                            <comment id="14376788" author="apurtell" created="Mon, 23 Mar 2015 22:31:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;We noticed a slight increase in GC activity likely due to increased RPC and creation of new objects&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If scanning millions of rows, millions of objects? &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; and I were discussing this and both of us wonder if we need NextState at all. The size estimations are done up in RSRpcServices, where the RS can directly tag Result protobuf with flags on why it broke out of the scanner loop and is returning Results now. NextState can do more but do we need it? &lt;/p&gt;</comment>
                            <comment id="14376919" author="jonathan.lawlor" created="Mon, 23 Mar 2015 23:39:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Thanks for bringing up these discussion points, I have included some discussion below about the design decisions made here and it would be great to hear your thoughts on them.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If scanning millions of rows, millions of objects?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ya&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The size estimations are done up in RSRpcServices&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;To avoid out of memory errors that resulted from very large rows, the size calculation was pushed all the way down into StoreScanner to be performed between cells (rather than between rows in RSRpcServices). This meant that we may reach the size limit in the middle of a row and form a partial result.&lt;/p&gt;

&lt;p&gt;With the size calculation pushed all the way down to StoreScanner, we needed some way of communicating upwards to the RegionScanner and RSRpcServices when a partial result is formed (i.e. we reach the size limit in the middle of a row). At first, the intention was to NOT change the return type from boolean. However, the implementation with the boolean return type ended up requiring many repetitions of the size calculation. &lt;/p&gt;

&lt;p&gt;With the boolean return type, the RegionScanner and RSRpcServices both needed to calculate the result size (in addition to the calculation that had been pushed down to StoreScanner). RegionScanner and RSRpcServices needed to do this in order to check whether or not the size limit had been reached since there was no way to communicate this understanding upwards with a boolean that indicates more values exists. The problems with this approach were:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The size calculation was being repeated too much&lt;/li&gt;
	&lt;li&gt;The state was not explicit enough. Cells were being returned from StoreScanner and it was up to the caller of StoreScanner#next to figure out why these were the cells being returned (size limit reached? batch limit reached?). The only way for the state to bubble up from the StoreScanner was to repeat all of the logic that made the StoreScanner return those Cells.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;NextState was introduced to make this communication more explicit and avoid replication of size calculations. &lt;/p&gt;

&lt;p&gt;Any alternative approaches are welcomed. If there is a way to keep the boolean return type and avoid replication of the size calculation, we could certainly try that alternative. Or, if repeating the size calculation is less costly than the NextState, perhaps we should go down that route.&lt;/p&gt;</comment>
                            <comment id="14376940" author="apurtell" created="Mon, 23 Mar 2015 23:54:33 +0000"  >&lt;p&gt;Is allocating a ton of NextState objects in hot code either confirmably not a problem by allocation profiling and/or inspection of generated Hotspot code, or is the chance of very large rows so severe that pushing this all the way down into the scanner is absolutely necessary? I don&apos;t think we have an answer for the first part. The second part is opinion, and could be valid, but may need more discussion.&lt;/p&gt;

&lt;p&gt;As for the accounting, I don&apos;t find the accounting for result size limits in RSRpcServices that big of a deal. I also think we are still not accounting for size correctly (or maybe the latest patches do... not sure I&apos;m totally up to date): In order to guarantee a uniform view of what &quot;size&quot; is a cell, we should count the bytes in the key, the bytes in the value, and the bytes in tags, and that&apos;s it. Avoid things like heapSize which factors in magic constants, internal data structure details, and padding/alignment which can vary by JVM, platform type, and CLI parameters (on JRE 8+). &lt;/p&gt;</comment>
                            <comment id="14376949" author="apurtell" created="Mon, 23 Mar 2015 23:59:56 +0000"  >&lt;p&gt;Also, for branch-1.0 and 0.98, I think we should try to improve this, and really cannot change the RegionScanner interface there. We will need something like a PB-only backwards compatible wire protocol change that can be driven from RSRpcServices. &lt;/p&gt;</comment>
                            <comment id="14376961" author="apurtell" created="Tue, 24 Mar 2015 00:08:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;Avoid things like heapSize &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For this, I think we&apos;re stuck waiting for 2.0.&lt;/p&gt;</comment>
                            <comment id="14377104" author="stack" created="Tue, 24 Mar 2015 02:03:58 +0000"  >&lt;p&gt;bq ...or is the chance of very large rows so severe that pushing this all the way down into the scanner is absolutely necessary&lt;/p&gt;

&lt;p&gt;Up for discussion any time but to echo Jonathan, we need the accounting at a lowest levels so we trigger the crossing of the size threshold closer to where it actually happens. Ain&apos;t sure how else we&apos;d do it. All ears though. Multiple benefits when trigger happens the sooner: avoid the subjects&apos; OOME if the cells that make up a row are beyond heap capacity, but also A. in Lars&apos;s A+B list above.&lt;/p&gt;

&lt;p&gt;Any tests you lot think I should run?  No problem. Just say. I do like the zeroing in on object creation. No harm undoing this if we can (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; and I will give a looke see)....&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="14377222" author="lhofhansl" created="Tue, 24 Mar 2015 03:47:19 +0000"  >&lt;p&gt;Lemme see if I can run some tests with trunk HBase. I&apos;d run it on a local machine, while scanning a few dozen million rows or so and then use jvisualvm or equivalent to look for object allocations.&lt;br/&gt;
If we create a new object per row that&apos;d kinda go against a lot of things I had been fixing in the past. But let&apos;s see, if it&apos;s an object per RPC, then who cares?&lt;/p&gt;</comment>
                            <comment id="14377306" author="stack" created="Tue, 24 Mar 2015 05:18:08 +0000"  >&lt;p&gt;Reran my loading tests. In this test scans are down some but if I look in the hot methods listing, I see that a profile that does NOT have my small methods change cutting in (I see HBB._get as a &apos;hot method&apos; though all it is doing is an array lookup &amp;#8211; bogus).&lt;/p&gt;

&lt;p&gt;There is some GC&apos;ing going on it seems (the mean response time is erratic but seems latency about same).&lt;/p&gt;

&lt;p&gt;Flight recorder only shows objects that occupy &amp;gt; .5% of the heap so all I see is bytes. Let me try and hookup another profiler instead, one that gives better view on heap content.&lt;/p&gt;</comment>
                            <comment id="14377347" author="stack" created="Tue, 24 Mar 2015 05:58:31 +0000"  >&lt;p&gt;jprofiler allows you get report on heap. It don&apos;t look too good. There is a NextState for every three KVs it seems.  See attached report. Did it a few times and proportion is about constant.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; and I will huddle on the morrow.  We&apos;ll be back.&lt;/p&gt;

&lt;p&gt;Thanks for the review that these allocations could be problematic. They don&apos;t seem to impinge upon throughput going by my little measurements, though they do make for some more GC so probably short-lived, but yeah, lets not take step backward on long-term project for getting object creation out of the scan line.&lt;/p&gt;</comment>
                            <comment id="14377355" author="lhofhansl" created="Tue, 24 Mar 2015 06:10:23 +0000"  >&lt;p&gt;3 is strange. Do your rows happen to have 3 columns?&lt;/p&gt;</comment>
                            <comment id="14377370" author="stack" created="Tue, 24 Mar 2015 06:16:01 +0000"  >&lt;p&gt;No. Ten columns.&lt;/p&gt;</comment>
                            <comment id="14378286" author="apurtell" created="Tue, 24 Mar 2015 18:07:07 +0000"  >&lt;p&gt;Strange indeed. Maybe some are elided by EA and others are not? Just a shot in the dark.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Thanks for the review that these allocations could be problematic. They don&apos;t seem to impinge upon throughput going by my little measurements, though they do make for some more GC so probably short-lived, but yeah, lets not take step backward on long-term project for getting object creation out of the scan line.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed. Let&apos;s take another look.&lt;/p&gt;</comment>
                            <comment id="14378569" author="enis" created="Tue, 24 Mar 2015 20:52:02 +0000"  >&lt;p&gt;So what is the decision here? Are we reverting this in the mean time, or will do an addendum? Asking because of &lt;a href=&quot;https://issues.apache.org/jira/browse/PHOENIX-1763&quot; title=&quot;Support building with HBase-1.1.0 &quot; class=&quot;issue-link&quot; data-issue-key=&quot;PHOENIX-1763&quot;&gt;&lt;del&gt;PHOENIX-1763&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14378613" author="apurtell" created="Tue, 24 Mar 2015 21:06:17 +0000"  >&lt;p&gt;IMHO, a temporary revert wouldn&apos;t hurt, this may have been committed a bit early. Sounds like hopefully we&apos;ll see improvements forthcoming regarding object allocations. &lt;a href=&quot;https://issues.apache.org/jira/browse/PHOENIX-1763&quot; title=&quot;Support building with HBase-1.1.0 &quot; class=&quot;issue-link&quot; data-issue-key=&quot;PHOENIX-1763&quot;&gt;&lt;del&gt;PHOENIX-1763&lt;/del&gt;&lt;/a&gt; suggests we try to avoid changing RegionScanner interfaces if we can get away with it, but certainly points to the committed solution not being viable for branch-1.0 or 0.98. &lt;/p&gt;</comment>
                            <comment id="14378625" author="jonathan.lawlor" created="Tue, 24 Mar 2015 21:10:25 +0000"  >&lt;p&gt;Spoke offline with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;. An idea of a solution to the extra object creations that is outlined below:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;NextState should not be an object, but instead an enum. This is what it was initially but it was changed into an object to avoid repeated calculation of size&lt;/li&gt;
	&lt;li&gt;A ScannerContext or ScannerTracker class can be introduced. A single ScannerContext/ScannerTracker instance would be instantiated per call to RSRpcServices#scan (so only one object creation per batch versus potentially millions of object creations)
	&lt;ul&gt;
		&lt;li&gt;ScannerContext would encapsulate all limits to be enforced during the server side scan and would also encapsulate all limit tracking&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The result would be that the RegionScanner interface would look something like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
NextState nextRaw(List&amp;lt;Cell&amp;gt; result) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
NextState nextRaw(List&amp;lt;Cell&amp;gt; result, ScannerContext context) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where the second call would be used when limits on the row need to be enforced.&lt;/p&gt;

&lt;p&gt;This would allow us to communicate state explicitly, avoid excessive object creation, and avoid repeated size calculations. How does this sound? I assume this would be implemented as an addendum to this issue. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, please correct me if any details were missed here.&lt;/p&gt;</comment>
                            <comment id="14378641" author="apurtell" created="Tue, 24 Mar 2015 21:19:03 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The result would be that the RegionScanner interface would look something like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
NextState nextRaw(List&amp;lt;Cell&amp;gt; result) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
NextState nextRaw(List&amp;lt;Cell&amp;gt; result, ScannerContext context) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;Can we amend this with backwards compatible changes regarding RegionScanner?  For example, ScannerContext can have a getter and setter for NextState, there&apos;s no need to return it. We could introduce an enhanced interface, leaving RegionScanner alone, and use an instanceof check and cast for the new nextRaw alternative. Hotspot is pretty good about determining if instanceof/casts always receive one type in practice and emitting optimized code for a monomorphic call site (with a deopt guard) .&lt;/p&gt;</comment>
                            <comment id="14378696" author="stack" created="Tue, 24 Mar 2015 21:39:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can we amend this with backwards compatible changes regarding RegionScanner?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Chatting we thought nextRaw would actually return ScannerContext &amp;#8211; the above suggestion is a little off here (NextState is actually purged).&lt;/p&gt;

&lt;p&gt;Please sketch a non-breaking change &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; and we&apos;ll take a looksee. The ScannerContext instance per rpc session will do what NextState did but &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; will also use it in subsequent patches to carry timings for the heartbeating feature (he has a &lt;b&gt;plan&lt;/b&gt;!)&lt;/p&gt;

&lt;p&gt;Adding ScannerContext as a param will be breaking change.  You are suggesting somehow we&apos;d have override to take ScannerContext?&lt;/p&gt;

&lt;p&gt;Can revert. Would like to see what non-breaking looks like first (and why wouldn&apos;t Phoenix want to make use of these amazing newness anyways?  Ain&apos;t Region Interface coming in in 1.1.0 too so its going to have some work to do anyways?&lt;/p&gt;</comment>
                            <comment id="14378710" author="apurtell" created="Tue, 24 Mar 2015 21:47:33 +0000"  >&lt;p&gt;The idea would be to leave RegionScanner alone, introduce a new interface like ExtendedRegonScanner extending RegionScanner (but please... a better name, I know that sucks), put just the new nextRaw into the new interface, and do an instanceof check and cast if the check passes, fall back if it doesn&apos;t since we won&apos;t get ScannerContexts passed down through via implementors of plain RegionScanner. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ain&apos;t Region Interface coming in in 1.1.0 too so its going to have some work to do anyways?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep. I&apos;m thinking about branch-1.0 and 0.98. Or they&apos;ll remain susceptible to OOME. That could be ok. They would still be susceptible if intermediaries like Phoenix wrap the extended RegionScanner with plain RegionScanners. OTOH, we&apos;d be source and binary compatible such that this fix can be slotted in to patch releases. &lt;/p&gt;</comment>
                            <comment id="14378726" author="stack" created="Tue, 24 Mar 2015 21:54:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m thinking about branch-1.0 and 0.98. Or they&apos;ll remain susceptible to OOME.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok. That helps. This patch is branch-1 and master only. Not 0.98 and 1.0.  The latter two will not get benefit of this change.  That ok &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; or you still want a patch that goes your route &amp;#8211; would be weird doing special casing when other changes coming in in 1.1 cause breakage (not interested in bringing this back in a patch release).&lt;/p&gt;</comment>
                            <comment id="14378740" author="enis" created="Tue, 24 Mar 2015 22:01:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would like to see what non-breaking looks like first (and why wouldn&apos;t Phoenix want to make use of these amazing newness anyways? Ain&apos;t Region Interface coming in in 1.1.0 too so its going to have some work to do anyways?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The patch at  &lt;a href=&quot;https://issues.apache.org/jira/browse/PHOENIX-1763&quot; title=&quot;Support building with HBase-1.1.0 &quot; class=&quot;issue-link&quot; data-issue-key=&quot;PHOENIX-1763&quot;&gt;&lt;del&gt;PHOENIX-1763&lt;/del&gt;&lt;/a&gt; already contains some fixes on top of changes related to this patch. I think I can do the necessary changes after the addendum lands if the mapping is clear. If we have the ScannerContext, even the results should go in there, no?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;and why wouldn&apos;t Phoenix want to make use of these amazing newness anyways?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Phoenix right now does not make use of limit (in some cases) and remainingResultSize. Some of the Phoenix&apos;s scanners are transforming the data completely (group by aggregate scanner) which drives the underlying scan, and buffers in memory (with optional spill), but ignores remainingResultSize because it is not incorporated yet. It should be doable, but will require some work. &lt;/p&gt;</comment>
                            <comment id="14378758" author="apurtell" created="Tue, 24 Mar 2015 22:06:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;not interested in bringing this back in a patch release&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;A bit odd considering we won&apos;t be fixing this issue in any active release, but I can&apos;t ask anyone to work on something they&apos;re not interested in (smile). It&apos;s also true the alternative I suggest is both more work and less clean from a coding perspective.&lt;/p&gt;</comment>
                            <comment id="14384226" author="jonathan.lawlor" created="Fri, 27 Mar 2015 17:44:46 +0000"  >&lt;p&gt;Work in progress update:&lt;/p&gt;

&lt;p&gt;I&apos;ve been working on an addendum that includes the ScannerContext changes described above and would like to get some feedback. I am attaching the patch but I would like to highlight the following point given the discussion above:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The intention was to modify the RegionScanner/InternalScanner interfaces as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; and I described above. Specifically, I wanted to have the following signatures in RegionScanner (and equivalent ones in InternalScanner):
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ScannerContext nextRaw(List&amp;lt;Cell&amp;gt; result) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
ScannerContext nextRaw(List&amp;lt;Cell&amp;gt; result, ScannerContext scannerContext)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
	&lt;ul&gt;
		&lt;li&gt;As far as I can tell, the proposed interface change has two problems: In the event that the first method is called, a ScannerContext object would need to be created (object creations are what we want to avoid). Also, if the second method is called, we are simply returning the same object that the caller passed in, so the return value is redundant&lt;/li&gt;
		&lt;li&gt;Instead I made NextState an enum and I return that. A NextState enum was used instead of the previous boolean return type because it allows the caller to determine when a partial result has been formed. An argument could be made that the return type should be boolean and we should just put NextState inside the context, but I didn&apos;t do that because it would make the code messier (would have to call scannerContext.setState() before every return statement and opens up the potential to miss setting the state when really we just want to return it).&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;This way ScannerContext simply holds the limits and tracks the progress towards those limits&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So with this patch what we get is:&lt;br/&gt;
The good:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;One object creation per session/rpc instead of potentially millions in the case of large batch scans&lt;/li&gt;
	&lt;li&gt;Much more explicit state information is returned from RegionScanner/InternalScanner&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The bad:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;An object is being passed around between scanners whereas we had a primitive per limit before.
	&lt;ul&gt;
		&lt;li&gt;However, note that the drawback of having a primitive per limit is that it does not tell us about the progress that has been made towards those limits and thus any progress must be recalculated by the caller&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;The RegionScanner interface is changed from Stable to Evolving due to the changes necessary in the interface (this change was noted over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13306&quot; title=&quot;Change RegionScanner interface from stable to evolving&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13306&quot;&gt;HBASE-13306&lt;/a&gt; but given that we are filing an addendum it makes more sense to address it here).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As this is a work in progress the docs could still use a little love, but at the very least this patch lets us see the way that Scan RPC&apos;s would look server side in the event that ScannerContext is introduced.&lt;/p&gt;</comment>
                            <comment id="14387222" author="jonathan.lawlor" created="Mon, 30 Mar 2015 19:02:25 +0000"  >&lt;p&gt;Attaching a rebased version of the patch since recent changes on master prevented a clean apply. Anyone have any thoughts on how ScannerContexts fits into the scanner RPC workflow? Questions, ideas for improvement, alternative approaches?&lt;/p&gt;</comment>
                            <comment id="14387497" author="jonathan.lawlor" created="Mon, 30 Mar 2015 21:56:57 +0000"  >&lt;p&gt;Adding reviewboard link&lt;/p&gt;</comment>
                            <comment id="14484343" author="jonathan.lawlor" created="Tue, 7 Apr 2015 23:36:11 +0000"  >&lt;p&gt;Filed sub-task &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13421&quot; title=&quot;Reduce the number of object creations introduced by HBASE-11544 in scan RPC hot code paths&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13421&quot;&gt;&lt;del&gt;HBASE-13421&lt;/del&gt;&lt;/a&gt; to address the fix to reduce the number of objects being created.&lt;/p&gt;</comment>
                            <comment id="14485528" author="hudson" created="Wed, 8 Apr 2015 16:56:16 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6357 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6357/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6357/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Ergonomics&amp;#93;&lt;/span&gt; hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME (stack: rev 26ba621e47e886fb3b1336f2201b8efbda86ff91)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallableWithReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMajorCompaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/InternalScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointWithErrors.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSeekOptimizations.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestBlocksScanned.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NoLimitScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlusher.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestColumnSeeking.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeCompactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestPartialResultsFromClientSide.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestStripeCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMultiColumnScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/RowCountEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestReversibleScanners.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultMemStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointNullResponse.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/BulkDeleteEndpoint.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14485618" author="hudson" created="Wed, 8 Apr 2015 17:41:47 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6358 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6358/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6358/&lt;/a&gt;)&lt;br/&gt;
Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Ergonomics&amp;#93;&lt;/span&gt; hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; (stack: rev 8cd3001f817915df20a4d209c450ac9b69b915d7)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointNullResponse.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestColumnSeeking.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestReversibleScanners.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/InternalScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NoLimitScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/BulkDeleteEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestStripeCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointWithErrors.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultMemStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMajorCompaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeCompactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallableWithReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestBlocksScanned.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSeekOptimizations.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMultiColumnScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestPartialResultsFromClientSide.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/RowCountEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlusher.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14486037" author="stack" created="Wed, 8 Apr 2015 21:05:31 +0000"  >&lt;p&gt;Addendum undoing mass object creation done as a subissue of this one by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt;. Re-resolving.&lt;/p&gt;</comment>
                            <comment id="14486121" author="hudson" created="Wed, 8 Apr 2015 21:44:01 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6359 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6359/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6359/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13421&quot; title=&quot;Reduce the number of object creations introduced by HBASE-11544 in scan RPC hot code paths&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13421&quot;&gt;&lt;del&gt;HBASE-13421&lt;/del&gt;&lt;/a&gt; Reduce the number of object creations introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; in scan RPC hot code paths (stack: rev 62d47e175c7c36dc2bd6b225d03978cd6303fc59)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestStripeCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointWithErrors.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointNullResponse.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestReversibleScanners.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestBlocksScanned.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/RowCountEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/InternalScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMultiColumnScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultMemStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeCompactor.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/BulkDeleteEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSeekOptimizations.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NoLimitScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallableWithReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlusher.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestColumnSeeking.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestPartialResultsFromClientSide.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMajorCompaction.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14486313" author="hudson" created="Wed, 8 Apr 2015 23:24:41 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.1 #380 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.1/380/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.1/380/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13421&quot; title=&quot;Reduce the number of object creations introduced by HBASE-11544 in scan RPC hot code paths&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13421&quot;&gt;&lt;del&gt;HBASE-13421&lt;/del&gt;&lt;/a&gt; Reduce the number of object creations introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; in scan RPC hot code paths (stack: rev 408b9161754966af80be5046fea657769b24f6a0)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanWithBloomError.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestBlocksScanned.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeCompactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestPartialResultsFromClientSide.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMultiColumnScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NoLimitScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMajorCompaction.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallableWithReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestStripeCompactionPolicy.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointNullResponse.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestColumnSeeking.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/BulkDeleteEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSeekOptimizations.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScannerContext.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/ColumnAggregationEndpointWithErrors.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransaction.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDefaultMemStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlusher.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestReversibleScanners.java&lt;/li&gt;
	&lt;li&gt;hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example/RowCountEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/InternalScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14486718" author="lhofhansl" created="Thu, 9 Apr 2015 05:13:15 +0000"  >&lt;p&gt;We should rename scanner &quot;caching&quot; to &quot;limit&quot; now, no? That&apos;s what it is now, a limit in case you happen to know a max number of row you want to look at ahead of time. Can do in another jira of course.&lt;/p&gt;</comment>
                            <comment id="14488140" author="jonathan.lawlor" created="Thu, 9 Apr 2015 19:56:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; good point. I have filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13441&quot; title=&quot;Scan API improvements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13441&quot;&gt;HBASE-13441&lt;/a&gt; as an umbrella issue for discussion regarding potential improvements to the Scan API. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13442&quot; title=&quot;Rename scanner caching to a more semantically correct term such as row limit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13442&quot;&gt;&lt;del&gt;HBASE-13442&lt;/del&gt;&lt;/a&gt; deals specifically with the rename to rowLimit.&lt;/p&gt;</comment>
                            <comment id="14571147" author="ndimiduk" created="Wed, 3 Jun 2015 15:29:17 +0000"  >&lt;p&gt;Closing issues released in 1.1.0.&lt;/p&gt;</comment>
                            <comment id="14973195" author="kairs" created="Sun, 25 Oct 2015 11:44:08 +0000"  >&lt;p&gt;I&apos;m unable to get partial results in mapreduce mapper jobs.&lt;/p&gt;

&lt;p&gt;I set setAllowPartialResults(true) for scan, but job still fails with OOME on large rows.&lt;/p&gt;

&lt;p&gt;I found that a Scan copy constructor does not bring field &quot;allowPartialResults&quot; to a new Scan objects and it is possibly the reason.&lt;/p&gt;

&lt;p&gt;I have also tried to run pure Scan client which scans all rows succesfully when using setAllowPartialResults(true).&lt;br/&gt;
But fails if I use a Scan object constructed from a previous one by a copy constructor (new Scan(originalScan)).&lt;/p&gt;</comment>
                            <comment id="14973336" author="kairs" created="Sun, 25 Oct 2015 17:12:28 +0000"  >&lt;p&gt;And i also see that there is an issue with TableMapReduceUtil methods convertStringToScan and convertScanToString which also lose the field allowPartialResults.&lt;/p&gt;

&lt;p&gt;And perhaps it would be good to have a config property (hbase.mapreduce.scan.partialrows ?) for specifying this feature for a jobs.&lt;/p&gt;</comment>
                            <comment id="14988358" author="stack" created="Tue, 3 Nov 2015 22:54:29 +0000"  >&lt;p&gt;This seems like a bug. File an issue please &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mindaugas.genutis%40nomagic.com&quot; class=&quot;user-hover&quot; rel=&quot;mindaugas.genutis@nomagic.com&quot;&gt;Mindaugas Genutis&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14988359" author="stack" created="Tue, 3 Nov 2015 22:55:17 +0000"  >&lt;p&gt;I think the Scan setting needs to be propagated regardless.  Config won&apos;t work for those who want the partials on a per-scan basis. Thanks.&lt;/p&gt;</comment>
                            <comment id="14988360" author="stack" created="Tue, 3 Nov 2015 22:55:21 +0000"  >&lt;p&gt;I think the Scan setting needs to be propagated regardless.  Config won&apos;t work for those who want the partials on a per-scan basis. Thanks.&lt;/p&gt;</comment>
                            <comment id="14988688" author="apurtell" created="Wed, 4 Nov 2015 01:33:59 +0000"  >&lt;p&gt;I think the above mentioned bug has been fixed on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14694&quot; title=&quot;Scan copy constructor doesn&amp;#39;t handle allowPartialResults&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14694&quot;&gt;&lt;del&gt;HBASE-14694&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14696&quot; title=&quot;Support setting allowPartialResults in mapreduce Mappers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14696&quot;&gt;&lt;del&gt;HBASE-14696&lt;/del&gt;&lt;/a&gt;. OTOH, I see on those issues the fix wasn&apos;t committed to any releaseable branch. Let me do that now.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12780934">HBASE-13193</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12783731">HBASE-13306</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12782590">HBASE-13262</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12776140">HBASE-13071</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12777230">HBASE-13090</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12951497">HBASE-15484</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12944392">HBASE-15325</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12947023">HBASE-15398</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12706838" name="Allocation_Hot_Spots.html" size="4553589" author="stack" created="Tue, 24 Mar 2015 05:58:31 +0000"/>
                            <attachment id="12707818" name="HBASE-11544-addendum-v1.patch" size="85865" author="jonathan.lawlor" created="Fri, 27 Mar 2015 17:44:46 +0000"/>
                            <attachment id="12708216" name="HBASE-11544-addendum-v2.patch" size="89799" author="jonathan.lawlor" created="Mon, 30 Mar 2015 19:02:25 +0000"/>
                            <attachment id="12701932" name="HBASE-11544-branch_1_0-v1.patch" size="309263" author="jonathan.lawlor" created="Mon, 2 Mar 2015 18:27:55 +0000"/>
                            <attachment id="12702311" name="HBASE-11544-branch_1_0-v2.patch" size="307910" author="jonathan.lawlor" created="Wed, 4 Mar 2015 00:08:25 +0000"/>
                            <attachment id="12699582" name="HBASE-11544-v1.patch" size="190697" author="jonathan.lawlor" created="Thu, 19 Feb 2015 00:55:54 +0000"/>
                            <attachment id="12699762" name="HBASE-11544-v2.patch" size="190751" author="jonathan.lawlor" created="Thu, 19 Feb 2015 23:02:33 +0000"/>
                            <attachment id="12699942" name="HBASE-11544-v3.patch" size="192000" author="jonathan.lawlor" created="Fri, 20 Feb 2015 21:33:46 +0000"/>
                            <attachment id="12700890" name="HBASE-11544-v4.patch" size="290566" author="jonathan.lawlor" created="Wed, 25 Feb 2015 22:47:57 +0000"/>
                            <attachment id="12700917" name="HBASE-11544-v5.patch" size="291506" author="jonathan.lawlor" created="Thu, 26 Feb 2015 00:18:03 +0000"/>
                            <attachment id="12701159" name="HBASE-11544-v6.patch" size="300751" author="jonathan.lawlor" created="Thu, 26 Feb 2015 19:56:32 +0000"/>
                            <attachment id="12701130" name="HBASE-11544-v6.patch" size="300751" author="jonathan.lawlor" created="Thu, 26 Feb 2015 17:42:47 +0000"/>
                            <attachment id="12701119" name="HBASE-11544-v6.patch" size="300791" author="jonathan.lawlor" created="Thu, 26 Feb 2015 17:05:07 +0000"/>
                            <attachment id="12702571" name="HBASE-11544-v7.patch" size="300751" author="jonathan.lawlor" created="Wed, 4 Mar 2015 18:25:20 +0000"/>
                            <attachment id="12702662" name="HBASE-11544-v8-branch-1.patch" size="300891" author="jonathan.lawlor" created="Thu, 5 Mar 2015 01:43:43 +0000"/>
                            <attachment id="12702626" name="HBASE-11544-v8.patch" size="300837" author="jonathan.lawlor" created="Wed, 4 Mar 2015 22:34:13 +0000"/>
                            <attachment id="12702425" name="gc.j.png" size="23188" author="stack" created="Wed, 4 Mar 2015 09:29:31 +0000"/>
                            <attachment id="12706829" name="h.png" size="10883" author="stack" created="Tue, 24 Mar 2015 05:18:08 +0000"/>
                            <attachment id="12702426" name="hits.j.png" size="13702" author="stack" created="Wed, 4 Mar 2015 09:29:31 +0000"/>
                            <attachment id="12706830" name="m.png" size="11054" author="stack" created="Tue, 24 Mar 2015 05:18:08 +0000"/>
                            <attachment id="12702427" name="mean.png" size="25845" author="stack" created="Wed, 4 Mar 2015 09:29:31 +0000"/>
                            <attachment id="12702424" name="net.j.png" size="16627" author="stack" created="Wed, 4 Mar 2015 09:29:31 +0000"/>
                            <attachment id="12706831" name="q (2).png" size="14261" author="stack" created="Tue, 24 Mar 2015 05:18:08 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12819121">HBASE-13421</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 18 Jul 2014 21:58:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>406390</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 6 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1xxlr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>406410</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Results returned from RPC calls may now be returned as partials&lt;br/&gt;
&lt;br/&gt;
When is a Result marked as a partial? &lt;br/&gt;
When the server must stop the scan because the max size limit has been reached. Means that the LAST Result returned within the ScanResult&amp;#39;s Result array may be marked as a partial if the scan&amp;#39;s max size limit caused it to stop in the middle of a row.&lt;br/&gt;
&lt;br/&gt;
Incompatible Change: The return type of InternalScanners#next and RegionScanners#nextRaw has been changed to NextState from boolean&lt;br/&gt;
The previous boolean return value can be accessed via NextState#hasMoreValues()&lt;br/&gt;
Provides more context as to what happened inside the scanner&lt;br/&gt;
&lt;br/&gt;
Scan caching default has been changed to Integer.Max_Value &lt;br/&gt;
This value works together with the new maxResultSize value from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12976&quot; title=&quot;Set default value for hbase.client.scanner.max.result.size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12976&quot;&gt;&lt;strike&gt;HBASE-12976&lt;/strike&gt;&lt;/a&gt; (defaults to 2MB) &lt;br/&gt;
Results returned from server on basis of size rather than number of rows&lt;br/&gt;
Provides better use of network since row size varies amongst tables&lt;br/&gt;
&lt;br/&gt;
Protobuf models have changed for Result, ScanRequest, and ScanResponse to support new partial Results&lt;br/&gt;
&lt;br/&gt;
Partial Results should be invisible to application layer unless Scan#setAllowPartials is set&lt;br/&gt;
&lt;br/&gt;
Scan#setAllowPartials has been added to allow the application to request to see the partial Results returned by the server rather than have the ClientScanner form the complete Result prior to returning it to the application&lt;br/&gt;
&lt;br/&gt;
To disable the use of partial Results on the server, set ScanRequest.Builder#setClientHandlesPartials() to be false in the ScanRequest issued to server&lt;br/&gt;
&lt;br/&gt;
Partial Results should allow the server to return large rows in parts rather than accumulate all the cells for that particular row and run out of memory</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>beginner</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>