<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:26:57 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5349/HBASE-5349.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5349] Automagically tweak global memstore and block cache sizes based on workload</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5349</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Hypertable does a neat thing where it changes the size given to the CellCache (our MemStores) and Block Cache based on the workload. If you need an image, scroll down at the bottom of this link: &lt;a href=&quot;http://www.hypertable.com/documentation/architecture/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.hypertable.com/documentation/architecture/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That&apos;d be one less thing to configure.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12541706">HBASE-5349</key>
            <summary>Automagically tweak global memstore and block cache sizes based on workload</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="anoopsamjohn">Anoop Sam John</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 Feb 2012 22:36:30 +0000</created>
                <updated>Sat, 21 Feb 2015 23:35:20 +0000</updated>
                            <resolved>Wed, 11 Dec 2013 07:05:23 +0000</resolved>
                                    <version>0.92.0</version>
                                    <fixVersion>0.99.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>26</watches>
                                                                <comments>
                            <comment id="13204070" author="zhihyu@ebaysf.com" created="Wed, 8 Feb 2012 22:41:42 +0000"  >&lt;p&gt;We currently don&apos;t maintain moving average of read/write requests per region server.&lt;br/&gt;
What should be an effective measure for determining read vs. write heavy workload ?&lt;/p&gt;</comment>
                            <comment id="13204078" author="zhihyu@ebaysf.com" created="Wed, 8 Feb 2012 22:48:16 +0000"  >&lt;p&gt;w.r.t. the measure for determining workload, should the measure be computed solely based on one region server ?&lt;br/&gt;
Or should this measure be relative to the workload on other region servers ?&lt;/p&gt;</comment>
                            <comment id="13204087" author="jdcryans" created="Wed, 8 Feb 2012 22:54:41 +0000"  >&lt;p&gt;Good question, I don&apos;t think looking at requests is good enough... instead we could look at how both are used and if there&apos;s adjustment to be made. For example, if you have a read heavy workload then the memstores would not see a lot of usage... same with write heavy, the block cache would be close to empty.&lt;/p&gt;

&lt;p&gt;Those two are clear cuts, now for those workloads in between it gets a bit harder. Maybe at first we shouldn&apos;t even try to optimize them.&lt;/p&gt;

&lt;p&gt;I think it should also be done incrementally, move like 3-5% of the heap from one place to the other every few minutes until it settles.&lt;/p&gt;</comment>
                            <comment id="13204325" author="zhihyu@ebaysf.com" created="Thu, 9 Feb 2012 07:27:12 +0000"  >&lt;p&gt;I am thinking of introducing rolling counters (using circular buffer) for both MemStore and LruBlockCache.&lt;br/&gt;
We record the number of flushes (for MemStore) and evictions (for LruBlockCache), respectively.&lt;br/&gt;
Every 1 (configurable) minute, we roll the counters.&lt;br/&gt;
It should be straight forward to observe whether MemStore or LruBlockCache is under pressure by looking at the trend of the rolling counters.&lt;br/&gt;
Once we determine the one under pressure, we can utilize what J-D described above to shift heap among the two.&lt;/p&gt;

&lt;p&gt;We can also introduce weights between MemStore and LruBlockCache for the rolling counters. &lt;/p&gt;</comment>
                            <comment id="13204740" author="mubarakseyed" created="Thu, 9 Feb 2012 18:57:59 +0000"  >&lt;p&gt;For reference:&lt;br/&gt;
Cassandra 1.0.0 supports self-tunes memtable sizes (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2787&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;CASSANDRA-2787&lt;/a&gt;). It uses Java agent (&lt;a href=&quot;https://github.com/jbellis/jamm&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Jamm&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="13214944" author="jdcryans" created="Thu, 23 Feb 2012 19:08:12 +0000"  >&lt;p&gt;@Mubarak&lt;/p&gt;

&lt;p&gt;We already have that through HeapSize, it&apos;s really just a matter of knowing what to auto-tune and when.&lt;/p&gt;</comment>
                            <comment id="13215220" author="stack" created="Thu, 23 Feb 2012 23:55:57 +0000"  >&lt;p&gt;Chatting w/ J-D about a phenomenon where we do not use memory when we are taking on a bunch of writes w/ a low region count.&lt;/p&gt;

&lt;p&gt;The few regions we have grow to their max of 128M or so and then we flush but in his case he had gigs of free memory still.  The notion is that we should let memstores grow to fill all available space and then flush when they hit the low-water global mem mark for the memstore.&lt;/p&gt;

&lt;p&gt;The problem then becomes we&apos;ll flush lots of massive files and will overwhelm compactions.  We&apos;ll need a push-back, something like a flush-merge where we flush by rewriting an existing store file interleaving the contents of memory or some such to slow down the flush but also to make for less compaction to do.&lt;/p&gt;</comment>
                            <comment id="13215228" author="jdcryans" created="Fri, 24 Feb 2012 00:02:14 +0000"  >&lt;p&gt;And by waiting to reach the lower barrier with a constant heavy load, you&apos;ll always run into &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5161&quot; title=&quot;Compaction algorithm should prioritize reference files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5161&quot;&gt;&lt;del&gt;HBASE-5161&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13234583" author="lhofhansl" created="Wed, 21 Mar 2012 17:46:56 +0000"  >&lt;p&gt;Moving out of 0.94.&lt;/p&gt;</comment>
                            <comment id="13257085" author="enis" created="Wed, 18 Apr 2012 23:31:40 +0000"  >&lt;p&gt;I have been thinking about this, and I think we can have a shot at a simple implementation. Let me summarize what I have in mind before starting the implementation: &lt;br/&gt;
Goals: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Provide min - max heap percentages for block cache (memstore kind of has it). I think we should keep max-min sanity bounds, and if they are equal, disable auto-tuning.&lt;/li&gt;
	&lt;li&gt;enable optimizing the available memory for adaptive workloads (mostly writes during the day, a lot of reads once MR job starts, etc). For example, when a large write job is started after ~10 minutes, region servers should tune for write workload.&lt;br/&gt;
Non-goals: &lt;/li&gt;
	&lt;li&gt;find the optimum mem-utilization algorithm&lt;/li&gt;
	&lt;li&gt;introduce a bunch of other parameters, to get rid of the current ones&lt;/li&gt;
	&lt;li&gt;make it very experimental so that nobody enables it in production.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Ideally, to optimize the usage of the available memory, we should predict the future workload (possibly from past workload), and devise a model capturing all the costs associated with block cache hits / misses, flushes, compactions, etc. But this model will be very complex to do it properly.&lt;/p&gt;

&lt;p&gt;I have checked Hypertable&apos;s implementation, and it seems that they check whether the load is read/write heavy by some hard coded values for the counters, and increment/decrement the mem limits, much like what Zhihong proposes above. I also want to start with something similar. &lt;/p&gt;

&lt;p&gt;Implementation layer: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Currently global memstore limit is a soft limit, we may have to make it a hard limit (blocking writes)&lt;/li&gt;
	&lt;li&gt;we should enable incrementing / decrementing and setting global memstore and block cache maximum limits. We do not have live configuration changes, but regardless of auto-tuning, we should be able to manually set those online.&lt;/li&gt;
	&lt;li&gt;Periodically we should check past workload (like past 10 min), and depending on whether it is write heavy or read heavy (from metrics), adjust the mem limits in small intervals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What do you guys think? Still worth pursuing?&lt;/p&gt;</comment>
                            <comment id="13257103" author="zhihyu@ebaysf.com" created="Thu, 19 Apr 2012 00:06:40 +0000"  >&lt;p&gt;This is a plan worth pursuing.&lt;/p&gt;</comment>
                            <comment id="13257219" author="stack" created="Thu, 19 Apr 2012 04:22:40 +0000"  >&lt;p&gt;I wouldn&apos;t mind more detail.&lt;/p&gt;

&lt;p&gt;Can our LRU be resized?&lt;/p&gt;

&lt;p&gt;Memstore upper bound can vary but there are interesting effects like if its too big, flushing can take so long, the memstore fills before we get around to flushing it again so we block.&lt;/p&gt;

&lt;p&gt;Nit: 10 minutes seems like too coarse a granularity?&lt;/p&gt;

&lt;p&gt;Good stuff Enis.&lt;/p&gt;</comment>
                            <comment id="13467192" author="stack" created="Mon, 1 Oct 2012 21:03:13 +0000"  >&lt;p&gt;Moving out of 0.96.0&lt;/p&gt;</comment>
                            <comment id="13648756" author="jdcryans" created="Fri, 3 May 2013 20:18:17 +0000"  >&lt;p&gt;If anyone is looking for a good jira to solve, this is one.&lt;/p&gt;</comment>
                            <comment id="13662819" author="anoopsamjohn" created="Tue, 21 May 2013 08:52:51 +0000"  >&lt;p&gt;Looks to be great for us. Will start working on this.&lt;/p&gt;</comment>
                            <comment id="13738522" author="anoop.hbase" created="Tue, 13 Aug 2013 17:29:08 +0000"  >&lt;p&gt;Working on a proto type now. Will come up with the low level impl details soon. &lt;/p&gt;</comment>
                            <comment id="13744064" author="anoop.hbase" created="Mon, 19 Aug 2013 17:56:48 +0000"  >&lt;p&gt;Configurations&lt;br/&gt;
--------------&lt;br/&gt;
For on heap block cache there is a config value. ie. what is the max heap space and defaults to 40%. Now we need to have a config item to read a min heap space for block cache. In fact this is not the min heap space which at least will be always reserved for the block cache.   This is the min value the auto tuner can turn down the block cache size up to.&lt;/p&gt;

&lt;p&gt;hfile.block.cache.size -&amp;gt; Current config to specify the Percentage of maximum heap (-Xmx setting) to allocate to block cache&lt;br/&gt;
Now we need 2 more configs to specify a range for this above value. And the above config item will continue to be there.&lt;br/&gt;
hfile.block.cache.size.max.range&lt;br/&gt;
hfile.block.cache.size.min.range&lt;br/&gt;
By default when HBase starts, the block cache will be allocated a size of hfile.block.cache.size (As current way).  Later the auto tuner can change this btw the max range and min range values.&lt;br/&gt;
If hfile.block.cache.size.max.range=hfile.block.cache.size.min.range=hfile.block.cache.size auto tuning for block cache will be turned off. (And thus for memstore also)&lt;/p&gt;


&lt;p&gt;Memstore having a higher and lower water mark now.  Higher water mark is a max heap size now itself.  But lower water mark is not. This is the heap size when it reached, we will start flushes to prevent the memstore reaching the higher water mark. &lt;br/&gt;
Once the memstore size reaches higher water mark, we will block all updates.&lt;br/&gt;
Now we need a min heap size also&lt;br/&gt;
The current configs are hbase.regionserver.global.memstore.upperLimit  and hbase.regionserver.global.memstore.lowerLimit&lt;br/&gt;
We need to introduce 2 new configs hbase.regionserver.global.memstore.size.max.range and hbase.regionserver.global.memstore.size.min.range Also we can rename hbase.regionserver.global.memstore.upperLimit to hbase.regionserver.global.memstore.size  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
By default when HBase starts it will allocate a global memstore size = hbase.regionserver.global.memstore.size as now (BC with old config name also will be provided). The auto tuner can change this btw the max and min range.&lt;/p&gt;

&lt;p&gt;And the lower watermark can no longer be a % of the total heap size. This needs to be a % of the max heap size(Higher water mark ie. hbase.regionserver.global.memstore.size). At any point in time the actual heap space will be having some value btw max and min range. The lower water mark % should result to a heap space lesser than the actual max heap space for global memstore and we should start the flushes at this point of time (as we do today).&lt;br/&gt;
So we should rename this config name also. -&amp;gt; hbase.regionserver.global.memstore.size.lower.limit -&amp;gt; % of the hbase.regionserver.global.memstore.size at which we will start flushes to avoid stop the world flushes. For BC we will continue to support hbase.regionserver.global.memstore.lowerLimit which is a % of the total JVM heap space. On init we can convert this value to a % of the  hbase.regionserver.global.memstore.size. The default value for this lower limit can be 95% of the global memstore size. (Default values for hbase.regionserver.global.memstore.upperLimit  and hbase.regionserver.global.memstore.lowerLimit are 40% and 38% respectively)&lt;/p&gt;


&lt;p&gt;Init check now is   block cache size + higher water mark &amp;lt;=80%&lt;br/&gt;
This should become&lt;br/&gt;
hbase.regionserver.global.memstore.size + hfile.block.cache.size &amp;lt;= 80%&lt;br/&gt;
AND&lt;br/&gt;
hbase.regionserver.global.memstore.size.max.range + hfile.block.cache.size.min.range &amp;lt;= 80%  &lt;br/&gt;
AND&lt;br/&gt;
hbase.regionserver.global.memstore.size.min.range + hfile.block.cache.size.max.range &amp;lt;= 80%&lt;br/&gt;
At any time  the heap size of the block cache + that of memstore &amp;lt;=80%&lt;/p&gt;


&lt;p&gt;We can have a HeapMemoryManager&lt;br/&gt;
	On HRS start, this also can be started. This Manager can track the block cache evictions (Can get from CacheStats). Also the memstore flushes can be tracked.&lt;br/&gt;
	MemstoreFlusher should support changing the global memstore size. Also the BlockCache can be resizable. This manager should support a pluggable HeapMemoryBalancer using which the new value for memstore and block cache sizes can be determined.&lt;br/&gt;
        When there is a change in the heap size, those can be set on MemstoreFlusher/BlockCache&lt;/p&gt;

&lt;p&gt;HeapMemoryBalancer&lt;br/&gt;
	A custom implementation for this can be plugged using config param. &quot;hbase.regionserver.memory.balancer.class&quot;&lt;br/&gt;
	The default impl can do the checks for the memory adjustment by comparing the block cache evictions against the flushes for memstores due to global heap pressure.&lt;br/&gt;
        Normal flushes due to one memstore reaching the flush size is a normal op and should not get accounted in the above checks. Only the flushes because of global heap pressure (blocked or no blocked) should get accounted&lt;br/&gt;
        Also a configurable time interval in which this tuner will check the condition. The config name can be &quot;hbase.regionserver.heapmemory.autotuner.period&quot; which default to 5 mns.&lt;br/&gt;
	Depending on the check it can increase/decrease the size of block cache or memstore global size in steps. The step value can be something like 2% of &#8211;Xmx. This also can be configurable.&lt;/p&gt;

&lt;p&gt;There should be way to support MemoryTuner to turn ON/OFF the tuner facility.&lt;/p&gt;</comment>
                            <comment id="13744072" author="anoop.hbase" created="Mon, 19 Aug 2013 18:02:03 +0000"  >&lt;p&gt;Subtask identified as of now&lt;br/&gt;
1. Support MemstoreFLush listener&lt;br/&gt;
	Listeners should be able to be registered. When the flush happens, the listeners should get notified. The notification may include on which region the flush happened and the flush type. The types can be like whether a normal flush or a flush due to global pressure (unblocked or blocked)&lt;/p&gt;

&lt;p&gt;2. Support resizable BlockCache&lt;br/&gt;
	Resizing can be supported for all BlockCache types which are on heap cache. LRUBlockCache is onheap type. Also DoubleBlockCache having onheap LRUCache along with off heap cache. So DoubleBlockCache also can be resizable.&lt;/p&gt;

&lt;p&gt;3. Support specifying global memstore lower watermark as a % of global memstore upper limit&lt;br/&gt;
	Now memstore lower watermark is specified as a % of the max heap size and defaults to 38%.(Default upper water mark memstore size is 40%) We need to change this behavior so as to specify lower water mark as a % of the upper water mark limit. (The default can be 95% (ie. 0.38/0.4 * 100)&lt;/p&gt;

&lt;p&gt;4. Support size range for memstore size and block cache size&lt;br/&gt;
	Support min and max values for memstore size and block cache size. The auto tuner can adjust the cache size to a value in btw these ranges.&lt;/p&gt;

&lt;p&gt;5. Support pluggable auto tuner&lt;br/&gt;
	There should be an interface based auto tuner impl. Configuring the FQCN of the impl in hbase-site.xml allows user to provide a custom impl for the auto tuner. Also provide a default impl which will decide the cache sizes based on the memstore flushes (due to global heap pressure) and block cache evictions&lt;/p&gt;

&lt;p&gt;6. Support turn ON/OFF the memory tuner at run time.&lt;/p&gt;</comment>
                            <comment id="13753963" author="anoop.hbase" created="Thu, 29 Aug 2013 19:33:38 +0000"  >&lt;p&gt;WIP patch. Review on the direction and framework welcome.&lt;/p&gt;</comment>
                            <comment id="13753978" author="yuzhihong@gmail.com" created="Thu, 29 Aug 2013 19:50:10 +0000"  >&lt;p&gt;There were 6 subtasks identified above.&lt;/p&gt;

&lt;p&gt;How many were addressed by the WIP patch ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13754363" author="anoop.hbase" created="Fri, 30 Aug 2013 04:34:20 +0000"  >&lt;p&gt;Ted&lt;br/&gt;
Other than 6 all are addressed.&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="13760641" author="yuzhihong@gmail.com" created="Fri, 6 Sep 2013 21:20:22 +0000"  >&lt;p&gt;There&apos;re ^M&apos;s at the end of each line. Please generate patch on Linux.&lt;br/&gt;
It would be nice to put the patch on review board.&lt;/p&gt;

&lt;p&gt;For HeapMemoryAutoTuner:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      AutoTunerContext context = createTunerContext();^M
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Do we need to create new context for each iteration of the chore ? Can one instance be reused ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        LOG.debug(&lt;span class=&quot;code-quote&quot;&gt;&quot;From HeapMemoryBalancer &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; memstoreSize: &quot;&lt;/span&gt; + memstoreSize + &lt;span class=&quot;code-quote&quot;&gt;&quot;%. &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; blockCacheSize: &quot;&lt;/span&gt; + blockCacheSize + &lt;span class=&quot;code-quote&quot;&gt;&quot;%&quot;&lt;/span&gt;);^M
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the percent sign is not needed.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (1 - (memstoreSize + blockCacheSize) &amp;lt; HConstants.HBASE_CLUSTER_MINIMUM_MEMORY_THRESHOLD) {^M
+          LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Current heap configuration from HeapMemoryBalancer exceeds &quot;&lt;/span&gt;^M
+              + &lt;span class=&quot;code-quote&quot;&gt;&quot;the threshold required &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; successful cluster operation. &quot;&lt;/span&gt;^M
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should some action be taken for the above case ? Otherwise tuning is effectively disabled.&lt;/p&gt;

&lt;p&gt;Since memstoreSize and blockCacheSize are local variables, I would expect some action when result.needsTuning() returns true.&lt;/p&gt;

&lt;p&gt;For DefaultHeapMemoryBalancerImpl, please add javadoc and audience annotation.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      result.setMemstoreSize(context.getCurMemStoreSize() - step);^M
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should we check that the decrement would not produce negative result ?&lt;/p&gt;

&lt;p&gt;Please add unit tests for the new classes.&lt;/p&gt;</comment>
                            <comment id="13760836" author="stack" created="Sat, 7 Sep 2013 01:07:04 +0000"  >&lt;p&gt;I can see making the Interface public but do the implementations have to be public too?&lt;/p&gt;

&lt;p&gt;-public class LruBlockCache implements BlockCache, HeapSize {&lt;br/&gt;
+public class LruBlockCache implements ResizableBlockCache, HeapSize {&lt;/p&gt;

&lt;p&gt;They are not instantiated outside of the hfile package?&lt;/p&gt;

&lt;p&gt;Call it DefaultHeapMemoryBalancer instead of DefaultHeapMemoryBalancerImpl I would say.&lt;/p&gt;

&lt;p&gt;It looks like you change configuration names but you handle the case where users still have the old names; that is good.&lt;/p&gt;

&lt;p&gt;Nit: does the context need both blocked and unblocked? +    boolean memstoreSufficient = blockedFlushCount == 0 &amp;amp;&amp;amp; unblockedFlushCount == 0;&lt;/p&gt;

&lt;p&gt;You have this comment twice &apos;// Increase the block cache size and corresponding decrease in memstore size&apos;  One must be wrong (smile)&lt;/p&gt;

&lt;p&gt;Reading DefaultHeapMemoryBalancerImpl, we keep stepping w/o regard for a max. Is max enforced elsewhere?  If so, will DefaultHeapMemoryBalancerImpl keep asking to step though we are against the max?  Maybe this is fine.  It makes the implementation &apos;easier&apos; which is good.  Should we log when we want to &apos;step&apos;?  Or is that done outside of DefaultHeapMemoryBalancerImpl (which would probably be better... again keep it simple)&lt;/p&gt;

&lt;p&gt;Does the HeapMemoryManager have to have these two members?&lt;/p&gt;

&lt;p&gt;+  private final MemStoreFlusher memStoreFlusher;&lt;br/&gt;
+  private final HRegionServer hrs;&lt;/p&gt;

&lt;p&gt;Can it not take Interface that has just what it needs?  Else makes it hard to test this new code in isolation.  At a minimum the HRS can be replaces by Service or RegionServerService Interface?  Is that possible?  And FlushRequester instead of MemStoreFlusher?&lt;/p&gt;

&lt;p&gt;Perhaps drop the &apos;Auto&apos; prefix from AutoTunerContext and AutoTunerResult.  The users of these Interfaces don&apos;t care if it Auto or not.  Ditto  here: HeapMemoryAutoTuner... call it HeapMemoryTuner.&lt;/p&gt;

&lt;p&gt;These should be private since server side?&lt;/p&gt;

&lt;p&gt;+@InterfaceAudience.Public&lt;br/&gt;
+@InterfaceStability.Evolving&lt;br/&gt;
+public interface HeapMemoryBalancer&lt;/p&gt;


&lt;p&gt;Should there be a kill switch for the tuner?  You pass in absolute values and once set, it stops balancing (for the case were the tuner turns pathological and an operator wants to turn it off while the server is online).  We could do that in another issue np.&lt;/p&gt;

&lt;p&gt;Should there be a &apos;damping&apos; facility?  That is, should we run the check more often and only make changes if we have been called ten times and on 8 or the 10 times, we judged we should &apos;step&apos;?  That could be a different implementation I suppose?  Or conversely, do you think there should be an &apos;emergency&apos; chain that can be pulled when we need to change the configs now?  (This latter is probably not a good idea &amp;#8211; at least not yet).&lt;/p&gt;

&lt;p&gt;We need to get rid of Chore and have one thread only that does all these tasks &amp;#8211; we have a load of them running now on each server &amp;#8211; or do them via executor... but that is out of scope of this issue.&lt;/p&gt;

&lt;p&gt;These do not need to be public classes +  public static final class AutoTunerContext { and AutoTunerResult?&lt;/p&gt;

&lt;p&gt;This seems like informational rather than a warn?&lt;/p&gt;

&lt;p&gt;+          LOG.warn(&quot;Current heap configuration from HeapMemoryBalancer exceeds &quot;&lt;br/&gt;
+              + &quot;the threshold required for successful cluster operation. &quot;&lt;br/&gt;
+              + &quot;The combined value cannot exceed 0.8. &quot; + MemStoreFlusher.MEMSTORE_SIZE_KEY&lt;br/&gt;
+              + &quot; is &quot; + memstoreSize + &quot; and &quot; + HConstants.HFILE_BLOCK_CACHE_SIZE_KEY + &quot; is &quot;&lt;br/&gt;
+              + blockCacheSize);&lt;/p&gt;

&lt;p&gt;Make one log rather than two since they change in lockstep:&lt;/p&gt;

&lt;p&gt;+          LOG.info(&quot;Setting block cache heap size to &quot; + newBlockCacheSize);&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;+          LOG.info(&quot;Setting memstore heap size to &quot; + newMemstoreSize);&lt;/p&gt;

&lt;p&gt;Do you need to shut it down?  +      startHeapMemoryManager();  Or it doesn&apos;t matter?&lt;/p&gt;

&lt;p&gt;Does the interface need to be public&lt;/p&gt;

&lt;p&gt;+public interface MemstoreFlushListener {&lt;/p&gt;

&lt;p&gt;(Lars Francke went through and cleaned the public from all our Interface methods... etc., so would be nice not to undo his work).&lt;/p&gt;

&lt;p&gt;Needs tests.  Hopefully you can change the above references to MemstoreFlusher and RegionServer to be Interfaces so you do not need to spin up a cluster to test (you are almost there).&lt;/p&gt;

&lt;p&gt;I am a big fan of this patch.  Good work Anoop.  Thanks for doing this.&lt;/p&gt;
</comment>
                            <comment id="13761642" author="anoop.hbase" created="Mon, 9 Sep 2013 06:14:04 +0000"  >&lt;p&gt;Stack &amp;amp; Ted thanks for the review..  Working on the comments and also adding tests. Will update the patch soon.&lt;/p&gt;</comment>
                            <comment id="13789120" author="anoop.hbase" created="Tue, 8 Oct 2013 11:25:38 +0000"  >&lt;p&gt;Patch addressing comments&lt;/p&gt;</comment>
                            <comment id="13789131" author="anoop.hbase" created="Tue, 8 Oct 2013 11:35:14 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I can see making the Interface public but do the implementations have to be public too?&lt;br/&gt;
-public class LruBlockCache implements BlockCache, HeapSize {&lt;br/&gt;
+public class LruBlockCache implements ResizableBlockCache, HeapSize {&lt;br/&gt;
They are not instantiated outside of the hfile package?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You mean LruBlockCache to be public or not right? It was already public.  I can see it is being referred in some test cases outside hfile package&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Call it DefaultHeapMemoryBalancer instead of DefaultHeapMemoryBalancerImpl I would say.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Nit: does the context need both blocked and unblocked? + boolean memstoreSufficient = blockedFlushCount == 0 &amp;amp;&amp;amp; unblockedFlushCount == 0;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current impl of the Tuner does not distinguish this. But Why I added it as 2 counts is to support more Tuner impl work (later?) Right now when both memstore and block cache is under preassure we wont do any tuning. May be there also some tuning can be done if blockedFlushCount is large. Blocked flush blocks the writes to memstore.. Just to keep the door open I made this way &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You have this comment twice &apos;// Increase the block cache size and corresponding decrease in memstore size&apos; One must be wrong (smile)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Copy paste.. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Corrected&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Reading DefaultHeapMemoryBalancerImpl, we keep stepping w/o regard for a max. Is max enforced elsewhere? If so, will DefaultHeapMemoryBalancerImpl keep asking to step though we are against the max? Maybe this is fine. It makes the implementation &apos;easier&apos; which is good. Should we log when we want to &apos;step&apos;? Or is that done outside of DefaultHeapMemoryBalancerImpl (which would probably be better... again keep it simple)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes I was intended to add check in HeapMemoryTuner#chore(). (The logging also). Adding it now. Also added check in DefaultHeapMemoryBalancer itself. When the HeapMemoryBalancer asks for step but the max limit is reached, I am making a warn log now. May be I can change this to INFO level &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; IMO logging is enough no other action is needed. Any suggestion? ( This is there in Ted&apos;s comment also)&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;Does the HeapMemoryManager have to have these two members?&lt;br/&gt;
+ private final MemStoreFlusher memStoreFlusher;&lt;br/&gt;
+ private final HRegionServer hrs;&lt;br/&gt;
Can it not take Interface that has just what it needs? Else makes it hard to test this new code in isolation. At a minimum the HRS can be replaces by Service or RegionServerService Interface? Is that possible? And FlushRequester instead of MemStoreFlusher?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Good point. Thanks I am making hrs to be of type Server which is enough.&lt;br/&gt;
private final Server server;&lt;br/&gt;
private final FlushRequester memStoreFlusher;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;Perhaps drop the &apos;Auto&apos; prefix from AutoTunerContext and AutoTunerResult. The users of these Interfaces don&apos;t care if it Auto or not. Ditto here: HeapMemoryAutoTuner... call it HeapMemoryTuner.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;These should be private since server side?&lt;br/&gt;
+@InterfaceAudience.Public&lt;br/&gt;
+@InterfaceStability.Evolving&lt;br/&gt;
+public interface HeapMemoryBalancer&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I wanted the impl of this balancer to be pluggable so that users can impl there own way like LoadBalancer. LoadBalancer marked as @InterfaceAudience.Public.  Just followed that. As it is server side we need to make private?  I am not sure of the guideline for this. If this is to be private I can change NP.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should there be a kill switch for the tuner? You pass in absolute values and once set, it stops balancing (for the case were the tuner turns pathological and an operator wants to turn it off while the server is online). We could do that in another issue np.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes very much. This is needed. I have identified it as a subtask in my earlier comment (6. Support turn ON/OFF the memory tuner at run time.) This is not done yet. May be once this is done, as another issue or sub task this can be done.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;These do not need to be public classes + public static final class AutoTunerContext { and AutoTunerResult?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This Context is passed to the HeapMemoryBalancer impl (which can be pluggable) and it needs to return the result. Making the class non public will force the impl can be to in the same package. Is that fine? That is why I kept it public&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This seems like informational rather than a warn?&lt;br/&gt;
+ LOG.warn(&quot;Current heap configuration from HeapMemoryBalancer exceeds &quot;&lt;br/&gt;
+ + &quot;the threshold required for successful cluster operation. &quot;&lt;br/&gt;
+ + &quot;The combined value cannot exceed 0.8. &quot; + MemStoreFlusher.MEMSTORE_SIZE_KEY&lt;br/&gt;
+ + &quot; is &quot; + memstoreSize + &quot; and &quot; + HConstants.HFILE_BLOCK_CACHE_SIZE_KEY + &quot; is &quot;&lt;br/&gt;
+ + blockCacheSize);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Fine. INFO&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do you need to shut it down? + startHeapMemoryManager(); Or it doesn&apos;t matter?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It doen&apos;t matter as of now as the balancer thread is daemon. But I will add shutdown also and call from HRS. May be latter when this is necessary it will a place holder to add those shutdown logic. You fine with such a place holder? (Only some log will be there as of now)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Does the interface need to be public&lt;br/&gt;
+public interface MemstoreFlushListener {&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Needs tests. Hopefully you can change the above references to MemstoreFlusher and RegionServer to be Interfaces so you do not need to spin up a cluster to test (you are almost there).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Added tests&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I am a big fan of this patch. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Me too wanted this feature. Atleast some people asked me regarding this. What they wanted was during some time, the cluster will be write heavy but no reads. And later only reads but no writes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Make one log rather than two since they change in lockstep:&lt;br/&gt;
+ LOG.info(&quot;Setting block cache heap size to &quot; + newBlockCacheSize);&lt;br/&gt;
...&lt;br/&gt;
+ LOG.info(&quot;Setting memstore heap size to &quot; + newMemstoreSize);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should there be a &apos;damping&apos; facility? That is, should we run the check more often and only make changes if we have been called ten times and on 8 or the 10 times, we judged we should &apos;step&apos;? That could be a different implementation I suppose? Or conversely, do you think there should be an &apos;emergency&apos; chain that can be pulled when we need to change the configs now? (This latter is probably not a good idea &#8211; at least not yet).	&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thought abt that Stack. Some thing like a rule based decision making. The 1st impl wanted to make simple. That is why making the decision maker pluggable so that we can give better impls like what we have done in LoadBalancer.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;There&apos;re ^M&apos;s at the end of each line. Please generate patch on Linux.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Hope it is fine now&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For HeapMemoryAutoTuner:&lt;br/&gt;
+      AutoTunerContext context = createTunerContext();^M&lt;br/&gt;
Do we need to create new context for each iteration of the chore ? Can one instance be reused ?&lt;br/&gt;
	We need the the context as state var. Ya it should be okey. Done&lt;/p&gt;

&lt;p&gt;+        if (1 - (memstoreSize + blockCacheSize) &amp;lt; HConstants.HBASE_CLUSTER_MINIMUM_MEMORY_THRESHOLD) {^M&lt;br/&gt;
+          LOG.warn(&quot;Current heap configuration from HeapMemoryBalancer exceeds &quot;^M&lt;br/&gt;
+              + &quot;the threshold required for successful cluster operation. &quot;^M&lt;br/&gt;
Should some action be taken for the above case ? Otherwise tuning is effectively disabled.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We can not turn beyond this level as it will affect the normal functioning of the RS. What action you think? Actions like abort and all like over kill.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;+        LOG.debug(&quot;From HeapMemoryBalancer new memstoreSize: &quot; + memstoreSize + &quot;%. new blockCacheSize: &quot; + blockCacheSize + &quot;%&quot;);^M&lt;br/&gt;
I think the percent sign is not needed.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Converting to % for correct comparison now. So adding % is fine?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For DefaultHeapMemoryBalancerImpl, please add javadoc and audience annotation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;+      result.setMemstoreSize(context.getCurMemStoreSize() - step);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Should we check that the decrement would not produce negative result ?&lt;br/&gt;
Done.&lt;/p&gt;</comment>
                            <comment id="13789136" author="anoop.hbase" created="Tue, 8 Oct 2013 11:40:40 +0000"  >&lt;p&gt;Will put in RB soon.&lt;/p&gt;</comment>
                            <comment id="13789268" author="anoop.hbase" created="Tue, 8 Oct 2013 15:05:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/14533/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/14533/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13842933" author="hadoopqa" created="Mon, 9 Dec 2013 06:25:11 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12617779/HBASE-5349_V3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12617779/HBASE-5349_V3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8095//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13842938" author="anoop.hbase" created="Mon, 9 Dec 2013 06:45:34 +0000"  >&lt;p&gt;Correcting one javadoc warn in the patch.&lt;br/&gt;
The test failure seems not related. It is fine locally !&lt;br/&gt;
I can not see any new findbugs in this patched code. (In report) the increase in number may be because of some other recent commits?&lt;/p&gt;</comment>
                            <comment id="13842961" author="hadoopqa" created="Mon, 9 Dec 2013 08:04:52 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12617789/HBASE-5349_V4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12617789/HBASE-5349_V4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestSplitLogWorker&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8097//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13844062" author="anoop.hbase" created="Tue, 10 Dec 2013 07:55:50 +0000"  >&lt;p&gt;Fixing comments from Sergey&lt;/p&gt;</comment>
                            <comment id="13844155" author="hadoopqa" created="Tue, 10 Dec 2013 09:58:43 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12618009/HBASE-5349_V5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12618009/HBASE-5349_V5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8119//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13844418" author="apurtell" created="Tue, 10 Dec 2013 17:04:41 +0000"  >&lt;p&gt;+1 for trunk&lt;/p&gt;</comment>
                            <comment id="13844583" author="sershe" created="Tue, 10 Dec 2013 19:31:52 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13844857" author="yuzhihong@gmail.com" created="Wed, 11 Dec 2013 00:15:20 +0000"  >&lt;p&gt;Anoop:&lt;br/&gt;
Can you update release notes ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13845029" author="anoop.hbase" created="Wed, 11 Dec 2013 03:12:11 +0000"  >&lt;p&gt;Thanks for the reviews. I have to make a next version addressing few comments from Ram. Sure Ted I will add the release notes.  Any more comments &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; ?&lt;/p&gt;</comment>
                            <comment id="13845030" author="anoop.hbase" created="Wed, 11 Dec 2013 03:15:39 +0000"  >&lt;p&gt;The pending comment from Ram is a minor one. I will fix it on commit Ram. &lt;/p&gt;</comment>
                            <comment id="13845075" author="stack" created="Wed, 11 Dec 2013 05:13:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; I am good on commit to trunk.  Go for it.&lt;/p&gt;</comment>
                            <comment id="13845086" author="lhofhansl" created="Wed, 11 Dec 2013 05:24:57 +0000"  >&lt;p&gt;Nice milestone towards 1.0. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;br/&gt;
+1&lt;/p&gt;</comment>
                            <comment id="13845130" author="ram_krish" created="Wed, 11 Dec 2013 06:32:53 +0000"  >&lt;p&gt;+1 on commit.&lt;/p&gt;</comment>
                            <comment id="13845141" author="anoop.hbase" created="Wed, 11 Dec 2013 07:05:23 +0000"  >&lt;p&gt;Committed to Trunk. Thanks all for the reviews..&lt;/p&gt;</comment>
                            <comment id="13845495" author="apurtell" created="Wed, 11 Dec 2013 15:55:04 +0000"  >&lt;p&gt;Nice work&lt;/p&gt;</comment>
                            <comment id="13845832" author="hudson" created="Wed, 11 Dec 2013 23:22:53 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-1.1 #4 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-1.1/4/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-1.1/4/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5349&quot; title=&quot;Automagically tweak global memstore and block cache sizes based on workload&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5349&quot;&gt;&lt;del&gt;HBASE-5349&lt;/del&gt;&lt;/a&gt; Automagically tweak global memstore and block cache sizes based on workload (anoopsamjohn: rev 1550059)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/DoubleBlockCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ResizableBlockCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultHeapMemoryTuner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/FlushRequestListener.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/FlushRequester.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HeapMemoryManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HeapMemoryTuner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreChunkPool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHeapMemoryManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13846111" author="xieliang007" created="Thu, 12 Dec 2013 07:09:07 +0000"  >&lt;p&gt;seems if we tweak block cache dynamically, it&apos;s more prone to trigger a gc that moment, right?&lt;/p&gt;</comment>
                            <comment id="13846176" author="hudson" created="Thu, 12 Dec 2013 09:09:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4720 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4720/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4720/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5349&quot; title=&quot;Automagically tweak global memstore and block cache sizes based on workload&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5349&quot;&gt;&lt;del&gt;HBASE-5349&lt;/del&gt;&lt;/a&gt; Automagically tweak global memstore and block cache sizes based on workload (anoopsamjohn: rev 1550059)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/DoubleBlockCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ResizableBlockCache.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultHeapMemoryTuner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/FlushRequestListener.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/FlushRequester.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HeapMemoryManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HeapMemoryTuner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreChunkPool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHeapMemoryManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13846393" author="stack" created="Thu, 12 Dec 2013 16:05:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;seems if we tweak block cache dynamically, it&apos;s more prone to trigger a gc that moment, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Makes sense.  We will be disturbing whatever equilibrium that may have been in place.  But if the workload has changed such that it has us changing configs., would that alone bring on a GC?  I suppose we should have a high friction on the tweaks.&lt;/p&gt;</comment>
                            <comment id="13846474" author="ndimiduk" created="Thu, 12 Dec 2013 17:26:35 +0000"  >&lt;p&gt;&lt;a href=&quot;http://www.amazon.com/Feedback-Control-Computer-Systems-Philipp/dp/1449361692/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Feedback Control&lt;/a&gt; seems like good reading.&lt;/p&gt;</comment>
                            <comment id="13846947" author="apurtell" created="Fri, 13 Dec 2013 00:06:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;seems if we tweak block cache dynamically, it&apos;s more prone to trigger a gc that moment, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is largely out of our control, until and unless the JVM exposes some knobs for GC and early warning signals. Between memstore and blockcache we can&apos;t just look at JVM heap occupancy, we will be keeping it pretty full. &lt;/p&gt;

&lt;p&gt;We can provide a null tuner to remove this as a factor when getting to the bottom of excessive GCs though.&lt;/p&gt;</comment>
                            <comment id="13847058" author="xieliang007" created="Fri, 13 Dec 2013 02:12:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;We can provide a null tuner to remove this as a factor when getting to the bottom of excessive GCs though.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;thanks Andrew, i definitely like this feature, and still, if one production cluster has a lower enough 99th latency requirement considering gc factor,  a null tuner probably must be provided? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                            <comment id="13847111" author="apurtell" created="Fri, 13 Dec 2013 03:22:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;if one production cluster has a lower enough 99th latency requirement considering gc factor, a null tuner probably must be provided?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You bet &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;, see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10151&quot; title=&quot;No-op HeapMemoryTuner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10151&quot;&gt;&lt;del&gt;HBASE-10151&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13847167" author="anoop.hbase" created="Fri, 13 Dec 2013 05:03:39 +0000"  >&lt;p&gt;By default the auto tuning is turned off. One need to give the below 4 configs so as to define the range of heap %.  &lt;br/&gt;
&quot;hbase.regionserver.global.memstore.size.max.range&quot; and &quot;hbase.regionserver.global.memstore.size.min.range&quot; using which one can specify the total heap % within which the memstore size can vary. &lt;br/&gt;
&quot;hfile.block.cache.size.max.range&quot; and &quot;hfile.block.cache.size.min.range&quot; using which one can specify the total heap % within which the block cache size can vary. &lt;br/&gt;
There is no default values for these and so by default there wont be automatic tuning happening.&lt;/p&gt;

&lt;p&gt;Is that good enough &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13847196" author="xieliang007" created="Fri, 13 Dec 2013 06:01:30 +0000"  >&lt;p&gt;Ok,  my concern is gone now. thanks all for reply&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I haven&apos;t learned the code yet, but the idea/feature is pretty cool absolutely !&lt;/p&gt;</comment>
                            <comment id="13847621" author="stack" created="Fri, 13 Dec 2013 16:24:53 +0000"  >&lt;p&gt;I think this feature should be on by default.  If it is off no one will enable it because they&apos;ll be afraid of what it might do.  It should be on because it takes away a need to twiddle knobs.  Regards what happens to GC&apos;ing profile when there is a seismic shift in size of blockcache/memstore, the point &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; raises, its a valid concern; can we flag it as concern in doc (&quot;If GC&apos;ing sensitive....&quot; or &quot;If low-latency serving...&quot;) and release note it and then spend some time seeing how bad it is in action?  Any way we could have a shift in config balance out?  i.e. block cache allocations some subset of memstore allocations so no more fragmentation....&lt;/p&gt;</comment>
                            <comment id="14091003" author="stack" created="Fri, 8 Aug 2014 17:36:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; I think we should enable by default, at least in master branch. What you think?  A policy that sizes the blockcache so there are no evictions OR we hit maxsize would be sweet.  I could add that.&lt;/p&gt;</comment>
                            <comment id="14091061" author="lhofhansl" created="Fri, 8 Aug 2014 18:05:47 +0000"  >&lt;p&gt;+1 to always enable. This is important for HBase and that way we&apos;ll issues if any.&lt;/p&gt;</comment>
                            <comment id="14331309" author="enis" created="Sat, 21 Feb 2015 23:35:20 +0000"  >&lt;p&gt;Closing this issue after 0.99.0 release. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12466663">HBASE-2706</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12607347" name="HBASE-5349_V2.patch" size="65175" author="anoop.hbase" created="Tue, 8 Oct 2013 11:25:38 +0000"/>
                            <attachment id="12617779" name="HBASE-5349_V3.patch" size="65254" author="anoop.hbase" created="Mon, 9 Dec 2013 05:08:48 +0000"/>
                            <attachment id="12617789" name="HBASE-5349_V4.patch" size="65366" author="anoop.hbase" created="Mon, 9 Dec 2013 06:45:34 +0000"/>
                            <attachment id="12618009" name="HBASE-5349_V5.patch" size="66013" author="anoop.hbase" created="Tue, 10 Dec 2013 08:03:57 +0000"/>
                            <attachment id="12600639" name="WIP_HBASE-5349.patch" size="38252" author="anoop.hbase" created="Thu, 29 Aug 2013 19:33:38 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Feb 2012 22:41:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>226993</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 42 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ht7j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>101994</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Both memstore heap size and on heap block cache sizes can be tuned automatically within the RS life time. The algorithm to be used for this tuning is also pluggable.&lt;br/&gt;
This feature adds the below new config&lt;br/&gt;
&amp;quot;hbase.regionserver.global.memstore.size.max.range&amp;quot; and &amp;quot;hbase.regionserver.global.memstore.size.min.range&amp;quot; using which one can specify the total heap % within which the memstore size can vary.&lt;br/&gt;
&amp;quot;hfile.block.cache.size.max.range&amp;quot; and &amp;quot;hfile.block.cache.size.min.range&amp;quot; using which one can specify the total heap % within which the block cache size can vary.&lt;br/&gt;
Using &amp;quot;hbase.regionserver.heapmemory.tuner.class&amp;quot; one can plugin an impl for the tuner algorithm. Pass the FQCN of the tuner impl class which implements org.apache.hadoop.hbase.regionserver.HeapMemoryTuner&lt;br/&gt;
The period within which the tuner checks for a possible tune can be adjusted with &amp;quot;hbase.regionserver.heapmemory.tuner.period&amp;quot;. This defaults to 300000 (5 mins)&lt;br/&gt;
The tuner algorithm receives a TunerContext in which we pass the number of block cache evictions (happened within that time) and the memstore flushes happened (Forced due to global heap pressure and normal flushes as separate items)&lt;br/&gt;
&lt;br/&gt;
Config changes&lt;br/&gt;
------------------&lt;br/&gt;
Changed the config name &amp;quot;hbase.regionserver.global.memstore.upperLimit&amp;quot; to &amp;quot;hbase.regionserver.global.memstore.size&amp;quot;&lt;br/&gt;
This will be the initial memstore size allocated (default value as 40%).&lt;br/&gt;
Also changed &amp;quot;hbase.regionserver.global.memstore.lowerLimit&amp;quot; to &amp;quot;hbase.regionserver.global.memstore.size.lower.limit&amp;quot;&lt;br/&gt;
There is a semantic change also here. &amp;quot;hbase.regionserver.global.memstore.lowerLimit&amp;quot; represented the total heap % upon which we start force flushes for memstores and defaults to 38% of total heap space.&lt;br/&gt;
The new one is the % of memstore max heap size (Represented by hbase.regionserver.global.memstore.size). This defaults to 95% of hbase.regionserver.global.memstore.size value.&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>