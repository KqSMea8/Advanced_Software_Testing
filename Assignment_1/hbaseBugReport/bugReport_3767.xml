<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:12:57 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3767/HBASE-3767.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3767] Improve how HTable handles threads used for multi actions</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3767</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;When creating a new HTable we have to query ZK to learn about the number of region servers in the cluster. That is done for every single one of them, I think instead we should do it once per JVM and then reuse that number for all the others.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12504000">HBASE-3767</key>
            <summary>Improve how HTable handles threads used for multi actions</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jdcryans">Jean-Daniel Cryans</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Tue, 12 Apr 2011 00:41:37 +0000</created>
                <updated>Fri, 20 Nov 2015 12:40:45 +0000</updated>
                            <resolved>Mon, 18 Apr 2011 21:00:59 +0000</resolved>
                                    <version>0.90.2</version>
                                    <fixVersion>0.90.3</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13018716" author="stack" created="Tue, 12 Apr 2011 05:00:05 +0000"  >&lt;p&gt;And if the number of region servers changes, are there repercussions?&lt;/p&gt;

&lt;p&gt;I wonder why we need to know about regionservers at all on construction?  Can we not learn about them lazily as Client figures it needs a region on said host?&lt;/p&gt;</comment>
                            <comment id="13018726" author="yuzhihong@gmail.com" created="Tue, 12 Apr 2011 05:21:46 +0000"  >&lt;p&gt;The number of region servers in the cluster is used in the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; nrThreads = conf.getInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.htable.threads.max&quot;&lt;/span&gt;, getCurrentNrHRS());
...
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.pool = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ThreadPoolExecutor(nrThreads, nrThreads,
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can we default the value for hbase.htable.threads.max using a multiple of the available processors ?&lt;/p&gt;</comment>
                            <comment id="13018863" author="stack" created="Tue, 12 Apr 2011 15:21:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can we default the value for hbase.htable.threads.max using a multiple of the available processors ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats better than doing getCurrentNrHRS.  Maybe 2* number of processors.  We&apos;d have to do a call outside of java to figure system characteristics?  &lt;/p&gt;</comment>
                            <comment id="13018872" author="yuzhihong@gmail.com" created="Tue, 12 Apr 2011 15:32:42 +0000"  >&lt;p&gt;The following call would end up in native code and give us the answer:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.getRuntime().availableProcessors()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13018969" author="jdcryans" created="Tue, 12 Apr 2011 18:24:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;And if the number of region servers changes, are there repercussions?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Currently once the HTable is created its ThreadPoolExecutor will stay the same size disregard the changing number of region servers. Caching it here has the same behavior. Where it changes is if a HTable is created later after the number of region server changes, but running with less threads than the total number of region server is only less efficient under bulk load situations where you need to insert into all of them at the same time (which I believe isn&apos;t frequent when uploading, usually you create the HTables up front). That&apos;s the only repercussion I see, and it&apos;s still less bad than the following:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Thats better than doing getCurrentNrHRS. Maybe 2* number of processors&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So the reason we use the number of RS is to be able to insert into all the region servers at the same time in a bulk upload case. Using the number of CPUs by itself isn&apos;t particularly useful since uploading isn&apos;t CPU intensive on the client (it&apos;s just threads waiting on region servers) and the fact that you usually have many HTables per JVM kinda defeats the purpose of limiting the number of executors.&lt;/p&gt;

&lt;p&gt;I personally like the fact that we try to learn how many RS there is in order to tune the TPE, but it&apos;s just that calling it every time is rather expensive and mostly useless. I still believe we should just cache it.&lt;/p&gt;</comment>
                            <comment id="13018982" author="yuzhihong@gmail.com" created="Tue, 12 Apr 2011 18:38:22 +0000"  >&lt;p&gt;We can set core pool size to be the number of available processors and set max pool size to be (large) multiple of the number of available processors.&lt;br/&gt;
ThreadPoolExecutor is able to dynamically shrink thread count when appropriate.&lt;/p&gt;</comment>
                            <comment id="13019125" author="jdcryans" created="Wed, 13 Apr 2011 00:06:12 +0000"  >&lt;p&gt;@Ted, I guess the improvement provided by setting the core pool size is minimal... I think I wouldn&apos;t even bother going all the way to using the number of CPUs and just start with 1. Cleaner code.&lt;/p&gt;</comment>
                            <comment id="13019149" author="nspiegelberg" created="Wed, 13 Apr 2011 00:51:47 +0000"  >&lt;p&gt;We were talking about this exact issue last week.  I think caching the RS count per cluster is the correct way to go.  I hacked together a Map&amp;lt;Configuration, Integer&amp;gt; but never finished it&lt;/p&gt;</comment>
                            <comment id="13019174" author="stack" created="Wed, 13 Apr 2011 03:37:20 +0000"  >&lt;p&gt;So if we create an HTable with one RegionServer in the cluster and then add ten nodes, we&apos;ll have cached 1 rather than 10.  That&apos;s going to be a pain to debug why upload is slow.&lt;/p&gt;

&lt;p&gt;Oversize the executor pool and have it shrink back down when unused (as per Ted above)?&lt;/p&gt;</comment>
                            <comment id="13019178" author="jdcryans" created="Wed, 13 Apr 2011 03:43:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;So if we create an HTable with one RegionServer in the cluster and then add ten nodes, we&apos;ll have cached 1 rather than 10&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If the HTable is already created, currently you still have just 1 thread in the TPE.&lt;/p&gt;</comment>
                            <comment id="13019180" author="stack" created="Wed, 13 Apr 2011 03:49:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;If the HTable is already created, currently you still have just 1 thread in the TPE.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But because we are not caching, the next HTable creation will have a right-sized TPE.&lt;/p&gt;

&lt;p&gt;If we had oversized TPE it&apos;d grow as servers grew.&lt;/p&gt;

&lt;p&gt;Aside: Whose idea was the passing of an ExecutorService from HTable down into HCM for it to use?  Thats a little perverse&lt;/p&gt;</comment>
                            <comment id="13019183" author="jdcryans" created="Wed, 13 Apr 2011 03:56:13 +0000"  >&lt;p&gt;My expectation is that in a long living JVM the HTables are created early rather than later, for example with our Thrift servers once you served each table from each thread you already got all your HTables.&lt;/p&gt;

&lt;p&gt;In the case of a bulk upload, the processes are usually MR tasks and are short lived and the HTable is created up front.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we had oversized TPE it&apos;d grow as servers grew.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;d actually prefer that to setting the max to CPU times some number. Default max to 1000 and lower bound at 1?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Aside: Whose idea was the passing of an ExecutorService from HTable down into HCM for it to use? Thats a little perverse&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Your favorite Canadian, guess which one &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13019593" author="jdcryans" created="Wed, 13 Apr 2011 23:11:51 +0000"  >&lt;p&gt;So the current way we handle the TPE is called &quot;unbounded queues&quot;, from the javadoc:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Unbounded queues. Using an unbounded queue (for example a LinkedBlockingQueue without a predefined capacity) will cause new tasks to wait in the queue when all corePoolSize threads are busy. Thus, no more than corePoolSize threads will ever be created. (And the value of the maximumPoolSize therefore doesn&apos;t have any effect.) This may be appropriate when each task is completely independent of others, so tasks cannot affect each others execution; for example, in a web page server. While this style of queuing can be useful in smoothing out transient bursts of requests, it admits the possibility of unbounded work queue growth when commands continue to arrive on average faster than they can be processed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The important part is that no more than corePoolSize threads will ever be created, maxPoolSize isn&apos;t used, and the rest is just queued. This is why it&apos;s important in that context to know the number of region servers since you want maximum parallelism.&lt;/p&gt;

&lt;p&gt;Instead, using the &quot;direct handoff&quot; strategy, new threads are created as soon as they start being queued meaning that the number of threads will go up to the number of region servers naturally, even if it changes. From the javadoc:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Direct handoffs. A good default choice for a work queue is a SynchronousQueue that hands off tasks to threads without otherwise holding them. Here, an attempt to queue a task will fail if no threads are immediately available to run it, so a new thread will be constructed. This policy avoids lockups when handling sets of requests that might have internal dependencies. Direct handoffs generally require unbounded maximumPoolSizes to avoid rejection of new submitted tasks. This in turn admits the possibility of unbounded thread growth when commands continue to arrive on average faster than they can be processed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We will never suffer from what is described in that last sentence since HCM will only create as many Runnables as there are RS that contain the regions that we need to talk to.&lt;/p&gt;</comment>
                            <comment id="13019684" author="yuzhihong@gmail.com" created="Thu, 14 Apr 2011 04:23:23 +0000"  >&lt;p&gt;The javadoc fragment doesn&apos;t mention allowCoreThreadTimeOut.&lt;/p&gt;

&lt;p&gt;From &lt;a href=&quot;http://fuseyism.com/classpath/doc/java/util/concurrent/ThreadPoolExecutor-source.html:&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://fuseyism.com/classpath/doc/java/util/concurrent/ThreadPoolExecutor-source.html:&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; 494:     Runnable getTask() {&lt;br/&gt;
 495:         for (;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; {&lt;br/&gt;
 496:             try {&lt;br/&gt;
 497:                 switch (runState) {&lt;br/&gt;
 498:                 case RUNNING: &lt;/p&gt;
{
 499:                     // untimed wait if core and not allowing core timeout
 500:                     if (poolSize &amp;lt;= corePoolSize &amp;amp;&amp;amp; !allowCoreThreadTimeOut)
 501:                         return workQueue.take();
 502: 
 503:                     long timeout = keepAliveTime;
 504:                     if (timeout &amp;lt;= 0) // die immediately for 0 timeout
 505:                         return null;
 506:                     Runnable r = workQueue.poll(timeout, TimeUnit.NANOSECONDS);
 507:                     if (r != null)
 508:                         return r;
 509:                     if (poolSize &amp;gt; corePoolSize || allowCoreThreadTimeOut)
 510:                         return null; // timed out
 511:                     // Else, after timeout, the pool shrank. Retry
 512:                     break;
 513:                 }
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In HTable(), allowCoreThreadTimeOut is set to true. So we&apos;re not bounded by corePoolSize threads.&lt;/p&gt;</comment>
                            <comment id="13019685" author="yuzhihong@gmail.com" created="Thu, 14 Apr 2011 04:24:57 +0000"  >&lt;p&gt;Re-pasting source code due to garbled display above:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 497:                 &lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt; (runState) {
 498:                 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; RUNNING: {
 499:                     &lt;span class=&quot;code-comment&quot;&gt;// untimed wait &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; core and not allowing core timeout
&lt;/span&gt; 500:                     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (poolSize &amp;lt;= corePoolSize &amp;amp;&amp;amp; !allowCoreThreadTimeOut)
 501:                         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; workQueue.take();
 502: 
 503:                     &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timeout = keepAliveTime;
 504:                     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (timeout &amp;lt;= 0) &lt;span class=&quot;code-comment&quot;&gt;// die immediately &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 0 timeout
&lt;/span&gt; 505:                         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
 506:                     &lt;span class=&quot;code-object&quot;&gt;Runnable&lt;/span&gt; r = workQueue.poll(timeout, TimeUnit.NANOSECONDS);
 507:                     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (r != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
 508:                         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; r;
 509:                     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (poolSize &amp;gt; corePoolSize || allowCoreThreadTimeOut)
 510:                         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// timed out
&lt;/span&gt; 511:                     &lt;span class=&quot;code-comment&quot;&gt;// Else, after timeout, the pool shrank. Retry
&lt;/span&gt; 512:                     &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
 513:                 }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13020251" author="stack" created="Fri, 15 Apr 2011 09:28:20 +0000"  >&lt;p&gt;Patch looks good to me.  Would feel more comfortable if there was a unit test proving the pool works as we expect (the code pasted above by Ted only provokes to me to ask questions about how it actually works).&lt;/p&gt;</comment>
                            <comment id="13021173" author="jdcryans" created="Mon, 18 Apr 2011 18:45:47 +0000"  >&lt;p&gt;This patch does two thing on top of the last one:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It adds a package protected method to get access to the pool.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It adds a new test to verify the behavior of the TPE. The method&apos;s comments describe what it does.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13021176" author="stack" created="Mon, 18 Apr 2011 18:50:03 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13021258" author="jdcryans" created="Mon, 18 Apr 2011 21:00:59 +0000"  >&lt;p&gt;Committed to branch and trunk, thanks for the review Stack. &lt;/p&gt;</comment>
                            <comment id="13021282" author="davelatham" created="Mon, 18 Apr 2011 21:39:49 +0000"  >&lt;p&gt;RegionSplitter and TestAdmin both reference HTable.getCurrentNrHRS() which this patch has removed.&lt;/p&gt;</comment>
                            <comment id="13021285" author="jdcryans" created="Mon, 18 Apr 2011 21:42:15 +0000"  >&lt;p&gt;Yep, Ted noticed that earlier and I just committed the fix.&lt;/p&gt;

&lt;p&gt;For 0.90 I just readded the method in HTable.&lt;/p&gt;

&lt;p&gt;For trunk I moved it to HConnection instead.&lt;/p&gt;</comment>
                            <comment id="13021289" author="davelatham" created="Mon, 18 Apr 2011 21:46:00 +0000"  >&lt;p&gt;That was quick, thanks!&lt;/p&gt;</comment>
                            <comment id="13163116" author="nspiegelberg" created="Mon, 5 Dec 2011 22:35:49 +0000"  >&lt;p&gt;@JD: From your description of the SynchronousQueue&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Direct handoffs generally require unbounded maximumPoolSizes to avoid rejection of &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; submitted tasks.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems like we should either add rejected task handling or not allow the user to specify &quot;hbase.htable.threads.max&quot; anymore, correct?&lt;/p&gt;</comment>
                            <comment id="13163227" author="jdcryans" created="Tue, 6 Dec 2011 00:55:04 +0000"  >&lt;p&gt;Yeah, maybe deprecate it first and print a WARN message then eventually remove.&lt;/p&gt;</comment>
                            <comment id="15016792" author="lars_francke" created="Fri, 20 Nov 2015 12:40:45 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12532547">HBASE-4859</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12531405">HBASE-4787</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12476644" name="HBASE-3767-v2.patch" size="6791" author="jdcryans" created="Mon, 18 Apr 2011 18:45:46 +0000"/>
                            <attachment id="12476287" name="HBASE-3767.patch" size="3182" author="jdcryans" created="Wed, 13 Apr 2011 23:11:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 12 Apr 2011 05:00:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33195</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i015yf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4734</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hbase.htable.threads.max now defaults to Integer.MAX_VALUE. Setting this below the number of region servers can result into RejectedExecutionException.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>noob</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>