<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:54:46 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-14613/HBASE-14613.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-14613] Remove MemStoreChunkPool?</title>
                <link>https://issues.apache.org/jira/browse/HBASE-14613</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I just stumbled across MemStoreChunkPool. The idea behind is to reuse chunks of allocations rather than letting the GC handle this.&lt;/p&gt;

&lt;p&gt;Now, it&apos;s off by default, and it seems to me to be of dubious value. I&apos;d recommend just removing it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12905100">HBASE-14613</key>
            <summary>Remove MemStoreChunkPool?</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12954202">HBASE-15555</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Thu, 15 Oct 2015 05:58:28 +0000</created>
                <updated>Fri, 7 Oct 2016 04:26:55 +0000</updated>
                            <resolved>Fri, 7 Oct 2016 04:26:55 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                <comments>
                            <comment id="14958382" author="lhofhansl" created="Thu, 15 Oct 2015 06:06:00 +0000"  >&lt;p&gt;Trivial patch. Simply remove the chunk pool and all its uses. Also allow a slight clean up of MemStoreLAB, as we no longer need to reference count chunks for how many scanner use &apos;em.&lt;/p&gt;</comment>
                            <comment id="14958387" author="stack" created="Thu, 15 Oct 2015 06:08:22 +0000"  >&lt;p&gt;I was going to give it a run on the rig w/ it enabled to see if it helps... worth the bother?&lt;/p&gt;</comment>
                            <comment id="14958401" author="lhofhansl" created="Thu, 15 Oct 2015 06:22:15 +0000"  >&lt;p&gt;More data is always good. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
I doubt it&apos;ll make a difference, but if it does I learned something new.&lt;/p&gt;</comment>
                            <comment id="14959381" author="enis" created="Thu, 15 Oct 2015 18:36:39 +0000"  >&lt;p&gt;Echoing my comments from the other thread: &lt;/p&gt;

&lt;p&gt;Do we know why is this off by default? Chunks are always equal in size, so re-using the chunks makes a lot of sense. Otherwise every new chunk allocation has to go through the eden space until it is tenured causing un-necessary work for the GC. Should we look into enabling the chunk pool by default instead? &lt;/p&gt;

&lt;p&gt;Todd and Lars G pointed out that the allocation may already be happening from the tenured space, so no extra work for the GC. &lt;a href=&quot;https://github.com/fpavageau/tenured-allocation&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/fpavageau/tenured-allocation&lt;/a&gt; says that it is &amp;gt;2MB for CMS and 2MB for G1. I did not run the test myself. &lt;/p&gt;</comment>
                            <comment id="14959810" author="stack" created="Thu, 15 Oct 2015 23:04:20 +0000"  >&lt;p&gt;Nice link &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Looks like 8M in CMS ... or somewhere between 4M and 8M. And 1M for G1.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[stack@c2020 tenured-allocation]$ ~/bin/jdk1.7.0_67/bin/java  -XX:+PrintCommandLineFlags -Xmn16m -Xmx1g -jar  target/tenured-allocation-1.0-SNAPSHOT.jar
-XX:InitialHeapSize=790664512 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=16777216 -XX:NewSize=16777216 -XX:+PrintCommandLineFlags -XX:+UseCompressedOops -XX:+UseParallelGC
Tracking memory usage with PS Eden Space and PS Old Gen
Allocation in Eden: 65536 (capacity: 12582912)
Allocation in Eden: 131072 (capacity: 12582912)
Allocation in Eden: 262144 (capacity: 12582912)
Allocation in Eden: 524288 (capacity: 12582912)
Allocation in Eden: 1048576 (capacity: 12582912)
Allocation in Eden: 2097152 (capacity: 12582912)
Allocation in Eden: 4194304 (capacity: 12582912)
Direct allocation in Tenured: 8388608 (Eden capacity: 12582912)
Direct allocation in Tenured: 16777216 (Eden capacity: 12582912)
Allocation size (16777216) greater than Eden capacity (12582912)
[stack@c2020 tenured-allocation]$
[stack@c2020 tenured-allocation]$ ~/bin/jdk1.7.0_67/bin/java -XX:+UseG1GC -XX:+PrintCommandLineFlags -Xmn16m -Xmx1g -jar  target/tenured-allocation-1.0-SNAPSHOT.jar
-XX:InitialHeapSize=790664512 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=16777216 -XX:NewSize=16777216 -XX:+PrintCommandLineFlags -XX:+UseCompressedOops -XX:+UseG1GC
Tracking memory usage with G1 Eden Space and G1 Old Gen
Allocation in Eden: 65536 (capacity: 17825792)
Allocation in Eden: 131072 (capacity: 17825792)
Allocation in Eden: 262144 (capacity: 17825792)
Allocation in Eden: 524288 (capacity: 17825792)
Direct allocation in Tenured: 1048576 (Eden capacity: 17825792)
Direct allocation in Tenured: 2097152 (Eden capacity: 17825792)
Direct allocation in Tenured: 4194304 (Eden capacity: 17825792)
Direct allocation in Tenured: 8388608 (Eden capacity: 17825792)
Direct allocation in Tenured: 16777216 (Eden capacity: 17825792)
Direct allocation in Tenured: 33554432 (Eden capacity: 17825792)
Allocation size (33554432) greater than Eden capacity (17825792)
[stack@c2020 tenured-allocation]$ ~/bin/jdk1.8.0_60/bin/java -XX:+PrintCommandLineFlags -Xmn16m -Xmx1g -jar  target/tenured-allocation-1.0-SNAPSHOT.jar
-XX:InitialHeapSize=790664512 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=16777216 -XX:NewSize=16777216 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC
Tracking memory usage with PS Eden Space and PS Old Gen
Allocation in Eden: 65536 (capacity: 12582912)
Allocation in Eden: 131072 (capacity: 12582912)
Allocation in Eden: 262144 (capacity: 12582912)
Allocation in Eden: 524288 (capacity: 12582912)
Allocation in Eden: 1048576 (capacity: 12582912)
Allocation in Eden: 2097152 (capacity: 12582912)
Allocation in Eden: 4194304 (capacity: 12582912)
Direct allocation in Tenured: 8388608 (Eden capacity: 12582912)
Direct allocation in Tenured: 16777216 (Eden capacity: 12582912)
Allocation size (16777216) greater than Eden capacity (12582912)
[stack@c2020 tenured-allocation]$ ~/bin/jdk1.8.0_60/bin/java  -XX:+UseG1GC -XX:+PrintCommandLineFlags -Xmn16m -Xmx1g -jar  target/tenured-allocation-1.0-SNAPSHOT.jar
-XX:InitialHeapSize=790664512 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=16777216 -XX:NewSize=16777216 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC
Tracking memory usage with G1 Eden Space and G1 Old Gen
Allocation in Eden: 65536 (capacity: 17825792)
Allocation in Eden: 131072 (capacity: 17825792)
Allocation in Eden: 262144 (capacity: 17825792)
Allocation in Eden: 524288 (capacity: 17825792)
Direct allocation in Tenured: 1048576 (Eden capacity: 17825792)
Direct allocation in Tenured: 2097152 (Eden capacity: 17825792)
Direct allocation in Tenured: 4194304 (Eden capacity: 17825792)
Direct allocation in Tenured: 8388608 (Eden capacity: 17825792)
Direct allocation in Tenured: 16777216 (Eden capacity: 17825792)
Direct allocation in Tenured: 33554432 (Eden capacity: 17825792)
Allocation size (33554432) greater than Eden capacity (17825792)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14960206" author="lhofhansl" created="Fri, 16 Oct 2015 05:38:45 +0000"  >&lt;p&gt;I am always dubious about trying to be smarter than the GC. Extra management, the requirement to get the number of chunks right to be useful but not wasteful, etc.&lt;/p&gt;</comment>
                            <comment id="14961041" author="stack" created="Fri, 16 Oct 2015 17:22:50 +0000"  >&lt;p&gt;Now I don&apos;t trust what this program is showing us. I wanted to find where exactly the boundary between allocate in old gen and allocate in eden is for CMS so I just kept adding 256k to the size and this is what the program spewed:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Allocation in Eden: 62652416 (capacity: 282066944)
Allocation in Eden: 62914560 (capacity: 282066944)
Allocation in Eden: 63176704 (capacity: 282066944)
GC in PS Scavenge
Allocation in Eden: 63438848 (capacity: 274202624)
Allocation in Eden: 63700992 (capacity: 274202624)
Allocation in Eden: 63963136 (capacity: 274202624)
GC in PS Scavenge
Allocation in Eden: 64225280 (capacity: 266338304)
Allocation in Eden: 64487424 (capacity: 266338304)
Allocation in Eden: 64749568 (capacity: 266338304)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... and so on.... Let me look at src&lt;/p&gt;</comment>
                            <comment id="14961462" author="apurtell" created="Fri, 16 Oct 2015 22:32:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;I am always dubious about trying to be smarter than the GC. Extra management, the requirement to get the number of chunks right to be useful but not wasteful, etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Generally agreed. Given that there&apos;s unnecessary complexity in this code. &lt;/p&gt;

&lt;p&gt;If we ever do direct offheap allocation in memstore, with all that implies, then we&apos;d want to use pooling and refcounting. Until then? &lt;/p&gt;</comment>
                            <comment id="14968101" author="stack" created="Wed, 21 Oct 2015 22:38:32 +0000"  >&lt;p&gt;Here are some diagrams. 25 clients YCSB writing a single regionserver. I ran four test runs. The first and last were WITHOUT memstorechunkpool.  The second and third were WITH memstorechunkpool enabled. I set it to be .25 the size of memstore and I set initial size to 0.&lt;/p&gt;

&lt;p&gt;The diagrams are GC and write rates (the fourth write run is missing from the diagram...)&lt;/p&gt;

&lt;p&gt;So, high-level, write rates are same with or without patch. No surprise.&lt;/p&gt;

&lt;p&gt;The CMS GCs are less when the pool is in place. No surprise given we are not recreating chunks but reusing them.&lt;/p&gt;

&lt;p&gt;What is surprising is that the new gen seems to be doing more collections. I&apos;d have to dig in why.... (Guess would be that this pool is throwing off the ergonomic sizing of new vs old... would have to check).&lt;/p&gt;

&lt;p&gt;The pool prints stats and the stats look nice:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2015-10-21 11:04:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=9,created chunk count=39,reused chunk count=3170,reuseRatio=98.78%
2015-10-21 11:09:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=8,created chunk count=39,reused chunk count=3322,reuseRatio=98.84%
2015-10-21 11:14:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=14,created chunk count=39,reused chunk count=3584,reuseRatio=98.92%
2015-10-21 11:19:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=30,created chunk count=39,reused chunk count=3829,reuseRatio=98.99%
2015-10-21 11:24:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=37,created chunk count=39,reused chunk count=4092,reuseRatio=99.06%
2015-10-21 11:29:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=12,created chunk count=39,reused chunk count=4352,reuseRatio=99.11%
2015-10-21 11:34:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=14,created chunk count=39,reused chunk count=4609,reuseRatio=99.16%
2015-10-21 11:39:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=20,created chunk count=39,reused chunk count=4865,reuseRatio=99.20%
2015-10-21 11:44:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=17,created chunk count=39,reused chunk count=5128,reuseRatio=99.25%
2015-10-21 11:49:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=20,created chunk count=39,reused chunk count=5377,reuseRatio=99.28%
2015-10-21 11:54:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=17,created chunk count=39,reused chunk count=5630,reuseRatio=99.31%
2015-10-21 11:59:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=23,created chunk count=39,reused chunk count=5871,reuseRatio=99.34%
2015-10-21 12:04:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=22,created chunk count=39,reused chunk count=6122,reuseRatio=99.37%
2015-10-21 12:09:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=36,created chunk count=39,reused chunk count=6216,reuseRatio=99.38%
2015-10-21 12:14:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=36,created chunk count=39,reused chunk count=6216,reuseRatio=99.38%
2015-10-21 12:19:07,026 DEBUG [StoreOpener-590f2ef9a43c9fe507f0f1fb415ca50e-1-MemStoreChunkPool Statistics] regionserver.MemStoreChunkPool: Stats: current pool size=36,created chunk count=39,reused chunk count=6216,reuseRatio=99.38%
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The reuse is impressive.&lt;/p&gt;

&lt;p&gt;So, the pool could be good. I&apos;d change it so the stats ran out of an executor rather than as a dedicated thread as a Chore. We&apos;d have to figure the sizing too. The initial sizing can be zero. Thats fine.  Let it ramp up even if it means chunks have to traverse survivor space a few times.... (would be sweet if could allocated direct on old gen but that seems hard to do reliably &amp;#8211; could spend some more time digging in on this).   What for the max size?  Currently it is a proportion of memstore size.  Could study running machine to see how many chunks are outstanding when a write load going on.  Could then set the pool to be this size.  But, we need to have a pool that can grow and shrink.  There is the ergonomic resize of the memstore that will resize memstore if we are doing many more writes than reads. The pool should adjust accordingly. The pool should also adjust if it has not been accessed in a long time. We do not want the case where we have all memstores holding on to big pools because we just underwent a furious write load but now it has abated... &lt;/p&gt;</comment>
                            <comment id="14968181" author="enis" created="Wed, 21 Oct 2015 23:43:35 +0000"  >&lt;p&gt;Nice analysis. &lt;br/&gt;
Would it help to simplify the code by abstracting the Allocator interface and have an Allocator always on? A pooling heap allocator will be current MemStoreChunkPool while a HeapAllocator just allocates from heap. This was we will still have the ref counting injection points, but no more null checks all over the code. Then we can look into how we can default to pooling allocator. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Could then set the pool to be this size. But, we need to have a pool that can grow and shrink. There is the ergonomic resize of the memstore that will resize memstore if we are doing many more writes than reads. The pool should adjust accordingly&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The pool&apos;s max size should be always the (memstore limit - total memstore size) / chunkSize&lt;/p&gt;</comment>
                            <comment id="14970461" author="stack" created="Fri, 23 Oct 2015 05:18:03 +0000"  >&lt;p&gt;Yeah, I think we should keep memstorechunkpool &amp;#8211; not reallocating is always good... (let me check synchronize) &amp;#8211; but make it work in new context:  use chore and make it resizeable. Can do the &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; suggestion of Allocator Interface NP. Let me also try offheaping the slabs (presuming that it access of offheap is same as onheap, its just the offheap allocation that is slow).&lt;/p&gt;

&lt;p&gt;Tell me more about your equation &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;? Ideally, the pool is the size that the memstore will grow too in the next N seconds &amp;#8211; we want to minimize allocations &amp;#8211; but then what to do in case where pool == memstore size, we flush, and then we don&apos;t get any more writes? When do we let the pool go?  Thanks.&lt;/p&gt;</comment>
                            <comment id="14972390" author="lhofhansl" created="Sat, 24 Oct 2015 05:01:53 +0000"  >&lt;p&gt;Hmm... Nothing in this thread represented a convincing argument that we should keep it. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Reuse is no indication that the GC would not do better (and the increase young collections indicate an issue), and performance was unaffected as I had predicted.&lt;/p&gt;

&lt;p&gt;Anyway, we can leave it in as long as it remains default off.&lt;/p&gt;

&lt;p&gt;-1 on turning this always on by default, though.&lt;/p&gt;</comment>
                            <comment id="14972393" author="stack" created="Sat, 24 Oct 2015 05:06:23 +0000"  >&lt;p&gt;Smile.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Nothing in this thread represented a convincing argument that we should keep it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There is a marked drop in CMS GC time.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;... and the increase young collections indicate an issue&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Need to figure it out.  Turn on more flags to see they why. My guess is my aggressive up-sizing of the pool. TBD.&lt;/p&gt;

&lt;p&gt;Was going to poke at this some more in a while...&lt;/p&gt;
</comment>
                            <comment id="15091531" author="lhofhansl" created="Mon, 11 Jan 2016 07:11:20 +0000"  >&lt;p&gt;Should I close this one?&lt;/p&gt;

&lt;p&gt;Lately I&apos;ve also been debating trying G1 without &lt;em&gt;any&lt;/em&gt; SLAB allocation and see how that&apos;s doing. It would save us copying the backing data for every single Cell upon writing into the memstore. (all in to the tune of &quot;Don&apos;t try to outsmart the GC&quot; - imagine a Beachboys tune to this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;</comment>
                            <comment id="15207369" author="vrodionov" created="Tue, 22 Mar 2016 21:43:11 +0000"  >&lt;p&gt;In other words, let us do more garbage, GC will take care of it. Yeah, this is why people still hate Java. Even if HotSpot allocates 2MB directly in tenured space, reusing these buffers decreases OldGen GC frequency, which is rather good than bad, I presume. &lt;/p&gt;</comment>
                            <comment id="15207401" author="eclark" created="Tue, 22 Mar 2016 22:05:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;Lately I&apos;ve also been debating trying G1 without any SLAB allocation and see how that&apos;s doing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Other than block cache sometimes being a pain to have in heap that config is doing well.&lt;/p&gt;</comment>
                            <comment id="15207441" author="stack" created="Tue, 22 Mar 2016 22:32:06 +0000"  >&lt;p&gt;You run G1 and no MSLAB?&lt;/p&gt;

&lt;p&gt;What is the block cache issue? Is it L1 or L2 or you just do onheap BC?&lt;/p&gt;</comment>
                            <comment id="15207460" author="eclark" created="Tue, 22 Mar 2016 22:44:50 +0000"  >&lt;p&gt;Yeah g1 no mslab.&lt;/p&gt;

&lt;p&gt;G1 really really loves having a balance of new and old gen. It holds off on a mixed gen collection as long as possible. So when we have a significant amount of memory basically pinned in old gen forever, it skews that balance pretty badly. That means that if you&apos;re promoting a decent amount of objects but not getting enough mixed gen collections, it&apos;s possible to get pauses even though there is a lot of memory left.&lt;/p&gt;

&lt;p&gt;To combat this we have just used more of the L2 cache offheap. This means that we can keep the young and old gens more balanced and don&apos;t risk having promotion stalls.&lt;/p&gt;</comment>
                            <comment id="15207463" author="eclark" created="Tue, 22 Mar 2016 22:47:05 +0000"  >&lt;p&gt;We&apos;ve actually found that everything that tries to keep objects around longer has been a detriment because of this. With G1 deciding how many regions for each type, there&apos;s very little benefit to trying to fight the GC.&lt;/p&gt;</comment>
                            <comment id="15207757" author="lhofhansl" created="Wed, 23 Mar 2016 02:21:57 +0000"  >&lt;p&gt;Not sure what you are referring to. SLAB making more garbage, or absence of SLAB generating more garbage?&lt;/p&gt;</comment>
                            <comment id="15207781" author="anoop.hbase" created="Wed, 23 Mar 2016 02:45:27 +0000"  >&lt;p&gt;Thanks for sharing the details on what you see with MSLAB with G1GC.&lt;br/&gt;
But we are trying for off heap memstore (Off heap write path after the read path).   So there will be MSLAB impl backed by off heap BBs.  Then we need a pool of BBs and reuse them. On demand creation and throw away of DBBs may not be a good choice.  And also it is DBBs, the actual size of the Java objects are small.   So we should not be removing this pool feature IMO.&lt;/p&gt;</comment>
                            <comment id="15207901" author="lhofhansl" created="Wed, 23 Mar 2016 05:41:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vik.karma&quot; class=&quot;user-hover&quot; rel=&quot;vik.karma&quot;&gt;Vikas Vishwakarma&lt;/a&gt;, FYI. Interesting bit here about disabling the memstore SLAB allocator when using G1.&lt;/p&gt;</comment>
                            <comment id="15207933" author="anoop.hbase" created="Wed, 23 Mar 2016 06:02:23 +0000"  >&lt;p&gt;When working with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15180&quot; title=&quot;Reduce garbage created while reading Cells from Codec Decoder&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15180&quot;&gt;&lt;del&gt;HBASE-15180&lt;/del&gt;&lt;/a&gt;,  discussed abt the check to know whether the MSLAB is enabled or not. In fact I made an initial patch with this check..  Now the Cells in the requests are decoded with sharing the same byte[] where the RPC reads the requests.  This is with assumption that any way the cells will be again copied to MSLAB area just before adding it to Memstore.   So when MSLAB is not enabled, we should continue with old way of decoding which allocated new byte[] just for one Cells content.&lt;br/&gt;
With CMS, with out using MSLAB was not good..  Saw this in tests.&lt;br/&gt;
I believe with G1GC, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingcheng.du%40intel.com&quot; class=&quot;user-hover&quot; rel=&quot;jingcheng.du@intel.com&quot;&gt;Jingcheng Du&lt;/a&gt; did some tests with MSLAB disabled, MSLAB on but no pool and MSLAB on with pool.  Mind sharing those results?&lt;/p&gt;</comment>
                            <comment id="15207955" author="jingcheng.du@intel.com" created="Wed, 23 Mar 2016 06:32:29 +0000"  >&lt;p&gt;I did some similar tests (YCSB, 1TB dataset, 1 HMaster and 3 Region servers) and post the result in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15180&quot; title=&quot;Reduce garbage created while reading Cells from Codec Decoder&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15180&quot;&gt;&lt;del&gt;HBASE-15180&lt;/del&gt;&lt;/a&gt;. We can see GC got improved a lot when chunk pool is enabled.&lt;/p&gt;


&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  mslab-pool-on &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; mslab-on &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; mslab-off &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; throughput&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  242801  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 240464  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 225679  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; latency(us)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  486  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 483  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 704  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; gc pause(ms)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  8440 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12837  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17131  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I used 2MB for the chunk size during the test.&lt;/p&gt;

&lt;p&gt;Speaking of G1GC, G1GC splits the heap into 2000 regions. In my test (the heap size is 64GB), each region will be 32MB. &lt;br/&gt;
If the chunk pool is off, there might be fragments after minor gc (2MB is a fragment comparing to 32MB, and the fragments are compacted in mixed gc and full gc).&lt;br/&gt;
If the chunk size is increased to 16MB or larger, I believe the performance can be improved comparing to 2MB chunk size&lt;/p&gt;</comment>
                            <comment id="15207958" author="jingcheng.du@intel.com" created="Wed, 23 Mar 2016 06:35:22 +0000"  >&lt;p&gt;Supplement some more information. The gc is measured as per minute.&lt;/p&gt;</comment>
                            <comment id="15208248" author="ram_krish" created="Wed, 23 Mar 2016 11:13:58 +0000"  >&lt;p&gt;I conducted a simple set of tests with G1GC. Max heap size is 40G and 50 regions&lt;br/&gt;
single node tests - with YCSB client and 55 threads. Also I did some tweaks such that the flush from memstore will not write to a file and just discard the memstore snapshot. SKIP_WAL is also enabled. &lt;br/&gt;
Thro put ops/sec&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MSLAB without chunkpool&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;with mslab and with Chunkpool&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;without mslab and without chunkpool&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1920.0463846930513&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1471.2768168302587&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2196.79151655224&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;In my YCSB set up I have 1000 columns each of 100 byte length (100KB cells).&lt;/p&gt;

&lt;p&gt;Coming to the GC pauses in sec&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MSLAB without chunkpool&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;with mslab and with Chunkpool&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;without mslab and without chunkpool&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;72.11s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;85.91s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;87.44s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I think Elliot&apos;s point is valid here. We get better through put with G1GC in trunk without MSLAB and without chunk pool.&lt;br/&gt;
 In our case where we are trying to use Offheap memstore and doing a chunk pool of that offheap memstore is definitely performing better than the trunk version of using MSLAB and with chunkpool (with G1GC enabled).&lt;br/&gt;
The through put is slightly  better 2261.0680948982304 ops/sec than the trunk (no MSLAB and no chunk pool case).&lt;/p&gt;</comment>
                            <comment id="15208316" author="ram_krish" created="Wed, 23 Mar 2016 12:14:28 +0000"  >&lt;p&gt;bqThat means that if you&apos;re promoting a decent amount of objects but not getting enough mixed gen collections, it&apos;s possible to get pauses even though there is a lot of memory left.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt;&lt;br/&gt;
I repeated the experiment and I can see that the case where we have No MSLAB and no chunk pool the GC pause is infact more and the case where we have only MSLAB and no chunk pool the GC pause is lesser but the through put is higher in case the NO MSLAB case. What could be the reason for that?  Does your results also go with this justification? &lt;/p&gt;</comment>
                            <comment id="15208690" author="eclark" created="Wed, 23 Mar 2016 16:17:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;What could be the reason for that?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We did a lot of investigation to figure out why we needed the off heap block cache even. After that I didn&apos;t do a whole lot of investigation. I just got the numbers and took what worked better. However I am pretty sure that it&apos;s something to do with the fact that putting data in the older regions necessitates more mixed collections which are much more expensive.&lt;/p&gt;</comment>
                            <comment id="15209719" author="ram_krish" created="Thu, 24 Mar 2016 04:23:20 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt;.  I think it would be worth spending time here before deciding on using the offheap BBPool and offheap memstore chunking for the offheap write path POC, considering that it should work with G1GC. &lt;/p&gt;</comment>
                            <comment id="15209735" author="vrodionov" created="Thu, 24 Mar 2016 04:37:15 +0000"  >&lt;p&gt;I am curios have anybody tried to run HBase with heap &amp;gt; 100GB? The server with 1TB RAM can be found today for less than 10K. &lt;/p&gt;</comment>
                            <comment id="15211455" author="ywang261" created="Fri, 25 Mar 2016 05:47:13 +0000"  >&lt;p&gt;Jingcheng, pointed this JIRA to me. I am kind of curious, have you guys tried to tune G1GC for that &quot;significant amount of memory basically pinned in old gen forever&quot; case?&lt;br/&gt;
For example: by default in JDK8, the -XX:InitiatingHeapOccupancyPercent is 45% that means G1 is trying to keep the &quot;balance&quot; around 45% heap full when starts concurrent marking cycle for Mixed GC.&lt;br/&gt;
if the &quot;significant amount of memory pinned in old gen forever&quot; caused heap Occupancy Percent more than 45% of total heap, then G1 will sure start concurrent marking cycle one after another, which I know it is mostly not that necessary and hurt throughput. in that case, I tried to increase -XX:InitiatingHeapOccupancyPercent=65 depends on how much (significant amount of memory pinned in old gen forever) vs. total heap ratio. we can calculate that actually based on test cases.&lt;/p&gt;

&lt;p&gt;also notice since we increased the &quot;balance&quot; point up, we have to increase the speed of concurrent marking cycle so it can finish faster to let Mixed GC to start clean up the rest of heap without causing full GC. to do that, I also increase -XX:ConcGCThreads to be 2/3 of parallelGC threads (default is 1/4).&lt;/p&gt;

&lt;p&gt;I ran HBase with 100GB and 120GB heap before with G1GC, it worked fine. &lt;br/&gt;
The good news is: jdk9 will have automatic InitiatingHeapOccupancyPercent adjustment based on its runtime heap profiling data, so it can detect the live forever objects size and InitiatingHeapOccupancyPercent on fly.&lt;/p&gt;</comment>
                            <comment id="15211463" author="stack" created="Fri, 25 Mar 2016 05:55:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ywang261&quot; class=&quot;user-hover&quot; rel=&quot;ywang261&quot;&gt;Yanping Wang&lt;/a&gt; Thank you for jumping in. You figured the back-to-back marking cycle just be looking at G1GC log emissions? What G1GC configs were working for you at 120G heap? Thanks.&lt;/p&gt;</comment>
                            <comment id="15211464" author="ywang261" created="Fri, 25 Mar 2016 05:56:00 +0000"  >&lt;p&gt;Hi, Ram, The max size for a G1 region is 32MB, if you don&apos;t specify the region size for 40GB, G1 will give you 1280 pieces of 32MB sized regions.&lt;/p&gt;</comment>
                            <comment id="15211482" author="ywang261" created="Fri, 25 Mar 2016 06:22:39 +0000"  >&lt;p&gt;Yes, I worked on Jave runtime and GC performance for many years before I plugged myself in Mnemonic project.&lt;br/&gt;
I can figure out what we can do to turn G1GC by looking at G1GC logs after run following 5 print flags:&lt;br/&gt;
-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintReferenceGC -XX:+PrintAdaptiveSizePolicy -XX:+PrintFlagsFinal&lt;/p&gt;

&lt;p&gt;Basic G1 parameters:&lt;br/&gt;
-XX:+UseG1GC &#8211;Xms? &#8211;Xmx? (don&apos;t specify -Xmn)&lt;br/&gt;
-XX:MaxGCPauseMillis (default 200ms, for HBase, set to 100)&lt;br/&gt;
-XX:ParallelGCThreads=&#65311; calculate 8+(#of logical processors-8)(5/8)&lt;br/&gt;
-XX:+ParallelRefProcEnabled&lt;/p&gt;

&lt;p&gt;normal G1GC turning flags:&lt;br/&gt;
-XX:G1HeapWastePercent (default 5, I changed to 10-20 for HBase, 5% is too hyper)&lt;br/&gt;
-XX:InitiatingHeapOccupancyPercent (default 45%, change to 65 based on pined old object size)&lt;br/&gt;
-XX:ConcGCThreads (default ~1/4 of parallel threads, increase to 2/3, so concurrent marking can finish faster before cause full gc)&lt;br/&gt;
-XX:G1MixedGCCountTarget (default 8, some time I reduced it to 6, as I don&apos;t want to have expensive mixed GCs to cause long mixed gc pauses)&lt;br/&gt;
-XX:G1NewSizePercent=? -XX:G1MaxNewSizePercent=? ( the default is 5% and 65%, used 1% and 10% for 100GB+ heap size, so I don&apos;t get crazy long young GC pauses to kill HBase response time)&lt;/p&gt;





</comment>
                            <comment id="15212023" author="vrodionov" created="Fri, 25 Mar 2016 16:30:25 +0000"  >&lt;p&gt;That was my first guess too - G1GC with default settings. &lt;/p&gt;</comment>
                            <comment id="15212076" author="eclark" created="Fri, 25 Mar 2016 16:57:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Jingcheng, pointed this JIRA to me. I am kind of curious, have you guys tried to tune G1GC for that &quot;significant amount of memory basically pinned in old gen forever&quot; case?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Extensively.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;-XX:+ParallelRefProcEnabled&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Always have this on.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;-XX:InitiatingHeapOccupancyPercent &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Setting it lower doesn&apos;t help since this is all about the promotion from young to old an g1 preferring not to do mixed. But we tried it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;-XX:ConcGCThreads&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Setting this higher helped a lot but we have enough happening on these boxes that it started to hurt performance.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;-XX:G1MixedGCCountTarget&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Setting this lower just moved what caused the long gc&apos;s.&lt;/p&gt;</comment>
                            <comment id="15212078" author="stack" created="Fri, 25 Mar 2016 16:57:55 +0000"  >&lt;p&gt;Excellent.&lt;/p&gt;

&lt;p&gt;Woud you mind  making a JIRA with a patch with your suggested turnings with a bit of your explanation and we&apos;ll commit as first pass at suggested G1GC settings? We currently have none. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ywang261&quot; class=&quot;user-hover&quot; rel=&quot;ywang261&quot;&gt;Yanping Wang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15212795" author="ram_krish" created="Sat, 26 Mar 2016 04:39:51 +0000"  >&lt;p&gt;Even mine was a default setting. I will try out your suggestion some time next week and will report back here.&lt;/p&gt;</comment>
                            <comment id="15212814" author="ywang261" created="Sat, 26 Mar 2016 05:27:16 +0000"  >&lt;p&gt;Hi, Elliott&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;-XX:InitiatingHeapOccupancyPercent &lt;br/&gt;
&amp;gt;&amp;gt;Setting it lower doesn&apos;t help since this is all about the promotion from young to old an g1 preferring not to do mixed. But we tried it.&lt;/p&gt;

&lt;p&gt;No, no, not set to lower, instead, calculate the size of pinned in Old and set this number higher.&lt;br/&gt;
for example, if you have 100GB heap, you calculate those &quot;pinned old forever&quot; are about 30GB, then most likely the default 45% (45GB) will cause trouble for you. if after Mixed GC completes, the heap  Occupancy is above 45GB, concurrent marking cycle will start immediately to prepare next series of Mixed GC, which gives you the symptom of  &quot;get pauses even though there is a lot of memory left.&quot; &lt;br/&gt;
so if for 100GB heap and 30GB pinned Old, you might have to increase -XX:InitiatingHeapOccupancyPercent  to 60 or 65. so you are able to use more heap memory.  you can find those info by using -XX:+PrintAdaptiveSizePolicy flag.&lt;/p&gt;


&lt;p&gt;&amp;gt;&amp;gt;-XX:ConcGCThreads&lt;br/&gt;
&amp;gt;&amp;gt;Setting this higher helped a lot but we have enough happening on these boxes that it started to hurt performance.&lt;/p&gt;

&lt;p&gt;after you let more heap to be used, the total number of Mixed GC is likely will be reduced, which could cause full GC if we are not careful. so increase ConcGCThread helps concurrent marking completes faster. just consider which one will hurt performance more? (1) take risk of Full GC (2) 80 Mixed GCs using 4 concurrent threads to do 10 concurrent marking each last 12 seconds (3) 40 Mixed GCs with 12 concurrent threads to do 5 concurrent marking each last 4 seconds.&lt;/p&gt;


&lt;p&gt;&amp;gt;&amp;gt;-XX:G1MixedGCCountTarget&lt;br/&gt;
&amp;gt;&amp;gt; Setting this lower just moved what caused the long gc&apos;s&lt;/p&gt;

&lt;p&gt;The most expensive steps in GC are scrub the remember set and COPY live objects from one place to another. after each concurrent marking cycle completes, by default G1 will try to do 8 mixed GC, first 1-5 might be easy for G1 so takes less time to complete, but the deeper it goes, the harder it gets, the longer it takes. so I&apos;d recommend HBase don&apos;t need to go that deep. The reason is other than pinned forever objects, most HBase objects are short lived. if this group of mixed GC find too hard to clean and copy some regions, maybe wait a while, in next cycle of mixed GC, some objects will die and makes their regions easy to clean up (no need copy any more). &lt;/p&gt;



</comment>
                            <comment id="15212845" author="lhofhansl" created="Sat, 26 Mar 2016 06:45:29 +0000"  >&lt;p&gt;Didn&apos;t think my musing about G1 and MSLAB would lead to a long a useful discussion &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Should we set InitiatingHeapOccupancyPercent based on configuration? By default we allow 40% of the heap for block cache and 40% for the memstore. When configured such, should we set InitiatingHeapOccupancyPercent to 80? Or maybe if we assume the memstores are on average 1/2 filled maybe this reasoning would lead to 60% as a good default...?&lt;/p&gt;</comment>
                            <comment id="15212846" author="lhofhansl" created="Sat, 26 Mar 2016 06:46:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vik.karma&quot; class=&quot;user-hover&quot; rel=&quot;vik.karma&quot;&gt;Vikas Vishwakarma&lt;/a&gt;, maybe we should redo our G1 testing with this in mind.&lt;/p&gt;</comment>
                            <comment id="15214984" author="eclark" created="Mon, 28 Mar 2016 22:08:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;No, no, not set to lower, instead, calculate the size of pinned in Old and set this number higher.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeah sorry that&apos;s what I meant. If we upped it then we were not initiating fast enough. Too low and things were getting promoted before mixed gens. We run our regionservers pretty much at the edge of what the gc seems capable.&lt;/p&gt;</comment>
                            <comment id="15219386" author="jingcheng.du@intel.com" created="Thu, 31 Mar 2016 05:37:39 +0000"  >&lt;p&gt;Supplement the G1GC settings used when I did the test in case some one needs it.&lt;br/&gt;
-XX:+UseG1GC -Xms64g -Xmx64g -XX:+AlwaysPreTouch -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:MaxGCPauseMillis=100 -XX:ParallelGCThreads=38 -XX:ConcGCThreads=22 -XX:G1HeapWastePercent=20 -XX:G1NewSizePercent=2 -XX:G1MaxNewSizePercent=20 -XX:+ParallelRefProcEnabled -XX:+PrintAdaptiveSizePolicy -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=19090 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.autodiscovery=true -Xloggc:/xxx/gc.log&lt;/p&gt;</comment>
                            <comment id="15381960" author="lhofhansl" created="Mon, 18 Jul 2016 09:15:34 +0000"  >&lt;p&gt;What do we do with this? Either we do something or I&apos;ll close.&lt;/p&gt;</comment>
                            <comment id="15382387" author="anoop.hbase" created="Mon, 18 Jul 2016 14:49:06 +0000"  >&lt;p&gt;As part of the off heaping effort, we have added support for DBB based MSLAB chunk pool. This seems working fine and we can work with much lesser sized heap size and better avg GC pause and net GC pause. So IMO we should not remove MSLAB chunk pool.&lt;/p&gt;</comment>
                            <comment id="15382553" author="stack" created="Mon, 18 Jul 2016 16:40:28 +0000"  >&lt;p&gt;What about the CMS vs G1GC discussion above? You think it no longer pertains given the chunk pool is offheap?&lt;/p&gt;</comment>
                            <comment id="15383601" author="ram_krish" created="Tue, 19 Jul 2016 05:29:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;What about the CMS vs G1GC discussion above? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;With pool we were able to tune the CMS and were able to see better performance. In case of G1GC, because we have offheap now and having a Buffer pool helps reduce the heap that is required and the tuning of G1GC helps to have a much predictable throughput. Will try out the same option with onheap and pooling.  Will get back on that here. &lt;/p&gt;</comment>
                            <comment id="15384229" author="anoop.hbase" created="Tue, 19 Jul 2016 14:33:02 +0000"  >&lt;p&gt;Ya with CMS, the pooling was any way helpful only.  With G1GC and on heap BB MSLAB pool, there were not much diff? (Ram?)&lt;br/&gt;
As this pool gives an effective way for having an off heap kind of memstore, I +1 we continue to have it.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12952284">HBASE-15513</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12766730" name="14613-0.98.txt" size="23906" author="lhofhansl" created="Thu, 15 Oct 2015 06:06:00 +0000"/>
                            <attachment id="12767902" name="gc.png" size="53472" author="stack" created="Wed, 21 Oct 2015 22:38:32 +0000"/>
                            <attachment id="12767903" name="writes.png" size="29050" author="stack" created="Wed, 21 Oct 2015 22:38:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 15 Oct 2015 06:08:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            21 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2n1mv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>