<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:13:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-16417/HBASE-16417.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-16417] In-Memory MemStore Policy for Flattening and Compactions</title>
                <link>https://issues.apache.org/jira/browse/HBASE-16417</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description></description>
                <environment></environment>
        <key id="12997265">HBASE-16417</key>
            <summary>In-Memory MemStore Policy for Flattening and Compactions</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12917935">HBASE-14918</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="eshcar">Eshcar Hillel</assignee>
                                    <reporter username="anastas">Anastasia Braginsky</reporter>
                        <labels>
                    </labels>
                <created>Mon, 15 Aug 2016 10:25:53 +0000</created>
                <updated>Wed, 7 Dec 2016 08:17:37 +0000</updated>
                                                            <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="15420823" author="anastas" created="Mon, 15 Aug 2016 10:29:06 +0000"  >&lt;p&gt;This JIRA is opened as a continuation for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14921&quot; title=&quot;Inmemory Compaction Optimizations; Segment Structure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14921&quot;&gt;&lt;del&gt;HBASE-14921&lt;/del&gt;&lt;/a&gt; and it is planned to add here the policy, deciding whether to flat/compact/merge the compacting pipeline segments. Please use this JIRA to discuss all those issues.&lt;/p&gt;</comment>
                            <comment id="15426121" author="anastas" created="Thu, 18 Aug 2016 09:00:06 +0000"  >&lt;p&gt;Answering &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14921&quot; title=&quot;Inmemory Compaction Optimizations; Segment Structure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14921&quot;&gt;&lt;del&gt;HBASE-14921&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14921&quot; title=&quot;Inmemory Compaction Optimizations; Segment Structure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14921&quot;&gt;&lt;del&gt;HBASE-14921&lt;/del&gt;&lt;/a&gt;, we run YCSB small just to ensure the correctness. In this JIRA we&#8217;ll resolve the performance issues.&lt;/p&gt;

&lt;p&gt;So in YCSB we did: 10 cols, 20 threads, only writes.  1G data, but very small heap - 1G, so in the sense of garbage collection we should be the same. The GC is Concurrent Mark &amp;amp; Sweep and we do not see GC pauses. We run with duplications and without. I will give a run now with more data.&lt;/p&gt;</comment>
                            <comment id="15426129" author="anoop.hbase" created="Thu, 18 Aug 2016 09:04:58 +0000"  >&lt;p&gt;That is very light load test. FYI , in your perf test pls make sure to run it for at least 10+ mns so that we can know the implication of all things in the system like compaction.  Also like 50+ threads. This can be done later once 14921 is in&lt;/p&gt;</comment>
                            <comment id="15426163" author="anastas" created="Thu, 18 Aug 2016 09:37:26 +0000"  >&lt;p&gt;We run much longer then 10 minutes and we see in-memory flattening and in-memory compaction, all together with flushes to disk and on-disk compaction. Even RS split happens. But as I said we will continue to stress the test.&lt;/p&gt;

&lt;p&gt;BTW, the instrumentation for the time it takes to run the speculative scan, finally convinced me it is too much &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
So we will resolve it in some other way &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15426179" author="anoop.hbase" created="Thu, 18 Aug 2016 09:49:26 +0000"  >&lt;p&gt;Thanks for the update. Ya from the code read perspective I was saying &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  And when we have CellChunkMap and the read happens from it for the compaction decision, the overhead will be much more. Ok let us handle it in follow up&lt;/p&gt;</comment>
                            <comment id="15429724" author="ebortnik" created="Sun, 21 Aug 2016 13:37:58 +0000"  >&lt;p&gt;Suggestion for Flush Policy, feel free to comment (smile). &lt;/p&gt;

&lt;p&gt;A new configuration parameter, IN_MEMORY_FLUSH_POLICY, will encompass three levels of managing memory flush at the store (CF) level. &lt;/p&gt;

&lt;p&gt;1. &#8220;none&#8221;. Semantics: no in-memory flush - status quo before the project started. &lt;/p&gt;

&lt;p&gt;2. &#8220;compact_index&#8221; (default). Semantics: &lt;br/&gt;
     a. When a MemStore overflows, it is transformed into an immutable segment. Namely, its index is flattened into a sorted array. &lt;br/&gt;
     b. The new segment is pushed into the segment pipeline (list of immutable segments, sorted by creation time). The pipeline segments are used for serving reads, along with the new MemStore and the block cache. &lt;br/&gt;
     c. A MemStore (disk) flush writes the oldest in-memory segment to a file. &lt;br/&gt;
     d. When too many segments accumulate in the pipeline (e.g., above 3), their indices are merged to reduce the number of files created by disk flushes. The threshold is not available for end-user tuning. Implementation details: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;No copy happens below the index level - neither the Cell objects nor the binary data are relocated.&lt;/li&gt;
	&lt;li&gt;No redundant cells are eliminated, to avoid the costly SQM scan.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;3. &#8220;compact_data&#8221;. This mode is targeted to use cases with high churn/locality of writes. Semantics (difference from 2d): &lt;br/&gt;
     a. When too many segments accumulate in the pipeline, their indices and data are merged, to reduce the memory footprint and postpone the future I/O. &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Redundant cells are eliminated (SQM scan is applied).&lt;/li&gt;
	&lt;li&gt;If MSLAB storage is used for binary data, then the data in the new segment created by merge is relocated to new chunks.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15429726" author="ebortnik" created="Sun, 21 Aug 2016 13:43:14 +0000"  >&lt;p&gt;Notes to the suggested definition: &lt;br/&gt;
1. Speculative scans have been eliminated as merge trigger - turn to be to costly. With option 3 (compact_data), the user takes the responsibility for what he&apos;s doing. &lt;/p&gt;

&lt;p&gt;2. The default implementation for immutable sorted index is CellArrayMap (an array of references to Cell objects). The CellChunkMap implementation embeds the Cell objects into the sorted index array, and saves some space by doing so. The index implementation is orthogonal to in-memory flush policy. The CellChunkMap index only works with MSLAB data storage. The use cases for it are TBD. For example, if it is only planned to work with off-heap data, no separate configuration is required. Let&apos;s follow this up separately on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16421&quot; title=&quot;Introducing the CellChunkMap as a new additional index variant in the MemStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16421&quot;&gt;HBASE-16421&lt;/a&gt;. &lt;/p&gt;
</comment>
                            <comment id="15430054" author="anoop.hbase" created="Mon, 22 Aug 2016 05:10:59 +0000"  >&lt;p&gt;Mostly looks good.  Though on the general use case (where not many updates/deletes) why cannot we flush all the segments in pipeline together when a flush to disk arise? In that case also, doing an in memory compaction for segments in pipeline (eg: You say when segments# &amp;gt;3) is to reduce #files flushed to disk.  So another way for that is flush whole pipeline together. In fact I feel at flush to file comes, we should be flushing all segments in pipeline + active.   So it is just like default memstore other than the in btw flush to in memory flattened structure.  When MSLAB in place, CellChunkMap would be ideal.  For off heap, any way we must need it,   As a first step, CellArrayMap being default is fine.&lt;br/&gt;
And good to see that ur tests reveal the overhead of scan for compact decision. And ya we should be doing that with out any compaction based test. And ya it is upto the user to know the pros and cons of in memory compaction and select that wisely. We should be well documenting that..   &lt;br/&gt;
Great.. We are mostly in sync now &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15432215" author="ebortnik" created="Tue, 23 Aug 2016 06:21:53 +0000"  >&lt;p&gt;Theoretically okay with having the pre-flush trigger too. In practice, it may be covered by the #segments trigger but we could experiment with this one as well. Please note that we also need to keep the # of segments low, to reduce the read time .. We&apos;ll figure this all out together. Looking forward to complete this piece. &lt;/p&gt;</comment>
                            <comment id="15432217" author="ebortnik" created="Tue, 23 Aug 2016 06:26:23 +0000"  >&lt;p&gt;Could some committer please assign this issue to Anastasia - I don&apos;t have permission to. &lt;/p&gt;</comment>
                            <comment id="15432418" author="ram_krish" created="Tue, 23 Aug 2016 08:53:47 +0000"  >&lt;p&gt;I tried doing it but some how not able to assign JIRA to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anastas&quot; class=&quot;user-hover&quot; rel=&quot;anastas&quot;&gt;Anastasia Braginsky&lt;/a&gt;.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; - I tried your method of adding the name ignoring JIRA warnings but some how it does not work for me. Can you or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; be able to assign this to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anastas&quot; class=&quot;user-hover&quot; rel=&quot;anastas&quot;&gt;Anastasia Braginsky&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15443151" author="anastas" created="Sun, 28 Aug 2016 09:40:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Though on the general use case (where not many updates/deletes) why cannot we flush all the segments in pipeline together when a flush to disk arise? In that case also, doing an in memory compaction for segments in pipeline (eg: You say when segments# &amp;gt;3) is to reduce #files flushed to disk. So another way for that is flush whole pipeline together.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ebortnik&quot; class=&quot;user-hover&quot; rel=&quot;ebortnik&quot;&gt;Edward Bortnikov&lt;/a&gt; has said, having long list of small segments in the pipeline affects the read path. We indeed see that this list might me very long, i.e. tens of segments. This list should be managed before flushing to disk. Please note, that the merge that we are suggesting doesn&apos;t includes data copying or SQM.&lt;/p&gt;

&lt;p&gt;Of course, there is no problem to flush everything in the pipeline when flush to disk is requested. Actually, when flush is requested first thing is to push the active segment to pipeline. So the active is going to be flushed all together with the pipeline upon the flush to disk.&lt;/p&gt;</comment>
                            <comment id="15443170" author="anastas" created="Sun, 28 Aug 2016 09:53:06 +0000"  >&lt;p&gt;Unable to assign this JIRA to myself as well...&lt;/p&gt;</comment>
                            <comment id="15443495" author="yuzhihong@gmail.com" created="Sun, 28 Aug 2016 13:57:48 +0000"  >&lt;p&gt;I have added Anastasia as contributor.&lt;/p&gt;</comment>
                            <comment id="15443521" author="yuzhihong@gmail.com" created="Sun, 28 Aug 2016 14:15:07 +0000"  >&lt;p&gt;I don&apos;t see any metric for number of segments in the pipeline.&lt;br/&gt;
Should we add such metric ?&lt;/p&gt;</comment>
                            <comment id="15443820" author="anoop.hbase" created="Sun, 28 Aug 2016 17:33:58 +0000"  >&lt;p&gt;So with default configs how many max #segments in a pipeline?  ANy tests u did? Theory wise it is 16 ( 25% as in memory flush def size and 4 is the blocking memstore size multiplier)&lt;br/&gt;
Ya We can make sure to flush all segments in such cases.  Whether in memory compaction needed or not is another item of discussion.&lt;/p&gt;</comment>
                            <comment id="15445325" author="anastas" created="Mon, 29 Aug 2016 09:10:49 +0000"  >&lt;p&gt;Regarding the number of segments in the pipeline before the merge, this number is open for now. We didn&apos;t try specific numbers yet. But it should be set by us and we should not give it to the user&apos;s decision.&lt;/p&gt;</comment>
                            <comment id="15451200" author="ram_krish" created="Wed, 31 Aug 2016 05:32:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;Regarding the number of segments in the pipeline before the merge&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Here by merge you mean compaction into one ? or flushing them all into a single file?&lt;/p&gt;</comment>
                            <comment id="15451211" author="ram_krish" created="Wed, 31 Aug 2016 05:39:24 +0000"  >&lt;p&gt;I could not add some points here all these days. Sorry about that.&lt;br/&gt;
In your tests you were saying that the scanning of the segments was taking some time and so you felt that should be avoided.&lt;br/&gt;
In our opinion I think not only the scanning part but the compaction part of combining all segments into one is also consuming memory because till the older ones in the pipeline are discarded you have two copies of the data. So this requires you to ensure that the GC is tuned properly because the active working set is double the required one atleast till the time the original copies are removed. Have you seen this behaviour in your tests?  I think that is one reason why you were not able to run with PE with the config that we had specified. &lt;br/&gt;
Making this scan simpler will definitely help but am just saying with memory perspective and heavy GC. &lt;/p&gt;</comment>
                            <comment id="15451242" author="anoop.hbase" created="Wed, 31 Aug 2016 05:50:41 +0000"  >&lt;p&gt;No , what she says is this compaction of segments in pipeline (into one segment) will not include the Cell data copy.  (this might be happening as of now, but will get rid of that).  Ya this is kind of compaction.  The real compaction will involve scanning all segments and that might remove deleted/version expired cells. Here there will be a fresh copy of the cell data to new MSLAB chunks.  But  the other simple compaction won&apos;t do this MSLAB extra copy. That will consider all cells also. (just an iterator no StoreScanner. correct Anastatia?)  So this op aim is to reduce the #segments in pipeline in order to reduce the impact this might have on reads (scan)&lt;/p&gt;</comment>
                            <comment id="15451245" author="anoop.hbase" created="Wed, 31 Aug 2016 05:52:03 +0000"  >&lt;p&gt;We need to evaluate the impact of reads because is this more #segments in pipeline. Every read op has to read from each of the segments.  So more binary search ops.  Ya we can per test this and decide on best way.&lt;/p&gt;</comment>
                            <comment id="15451474" author="ebortnik" created="Wed, 31 Aug 2016 07:43:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, all explanations correct. One of the goals of this jira is to install some order in terminology (smile). Correct, we now distinguish between two types of compaction: index compaction, which only merges the cell arrays but does not actually copy the data, and data compaction, which also eliminates the redundant versions and copies the remaining data. We are working on benchmarks (ycsb and PE) to verify that the former is inexpensive, and can be used as default. Part of these benchmarks is fine-tuning the upper bound for the # of segments in the pipeline. &lt;/p&gt;</comment>
                            <comment id="15451492" author="anoop.hbase" created="Wed, 31 Aug 2016 07:50:35 +0000"  >&lt;p&gt;Sounds good &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ebortnik&quot; class=&quot;user-hover&quot; rel=&quot;ebortnik&quot;&gt;Edward Bortnikov&lt;/a&gt;.  Also mind doing benchmark for read op (Get/Scan) with diff #segments in pipeline.  So what if, in worst case, no index compaction is happening at all and we have 10+ segments possibly in pipeline.  Ya doing this with diff #segments in pipeline will help us to determine what should be the #segments above which an index compaction is needed. Thanks for the info.&lt;/p&gt;</comment>
                            <comment id="15451596" author="ram_krish" created="Wed, 31 Aug 2016 08:35:27 +0000"  >&lt;p&gt;Thanks for the info. Ya index compaction (flattening) and data compaction depends on the number of segments I agree. So when we decide to do index compaction only the flush will have to involve all segments in the pipeline. That will also be discussed here right?&lt;/p&gt;</comment>
                            <comment id="15451619" author="ebortnik" created="Wed, 31 Aug 2016 08:49:12 +0000"  >&lt;p&gt;Yes. This is where we&apos;ll address all the policy issues. &lt;/p&gt;</comment>
                            <comment id="15464680" author="anastas" created="Mon, 5 Sep 2016 10:18:54 +0000"  >&lt;p&gt;Hey Guys,&lt;/p&gt;

&lt;p&gt;Sorry, wasn&apos;t active on this thread for a while. By &quot;merge&quot; we mean the new ability to merge many segments just together, into one segment as a result.&lt;br/&gt;
There is no copy of the MSLAB and no SQM used. Just merging the MSLABs and the CellArrayMaps of multiple segments into the new single one.&lt;br/&gt;
The content of the CellArrayMaps is indeed copied, but not the Cells&apos; data.&lt;/p&gt;

&lt;p&gt;The new patch is going to be released tomorrow, I hope, so you will see the code and probably understand what I mean better.&lt;br/&gt;
We also believe this JIRA need to be split into two. One with the patch I am going to publish and with the merge issue and the second JIRA, which is going to truly care for the policy itself.&lt;/p&gt;</comment>
                            <comment id="15480321" author="anastas" created="Sat, 10 Sep 2016 19:39:55 +0000"  >&lt;p&gt;Hi again!&lt;/p&gt;

&lt;p&gt;As I started to explain in my previous comment, we believe this JIRA should be split into two. I have opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16608&quot; title=&quot;Introducing the ability to merge ImmutableSegments without copy-compaction or SQM usage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16608&quot;&gt;&lt;del&gt;HBASE-16608&lt;/del&gt;&lt;/a&gt; for this case. In &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16608&quot; title=&quot;Introducing the ability to merge ImmutableSegments without copy-compaction or SQM usage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16608&quot;&gt;&lt;del&gt;HBASE-16608&lt;/del&gt;&lt;/a&gt; we want to present the merge of the immutable segments of the pipeline into one new segment, while this is done without data-copy-compaction and without SQM.&lt;/p&gt;

&lt;p&gt;In this JIRA we plan to continue after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16608&quot; title=&quot;Introducing the ability to merge ImmutableSegments without copy-compaction or SQM usage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16608&quot;&gt;&lt;del&gt;HBASE-16608&lt;/del&gt;&lt;/a&gt; and finalize the tuning of the in-memory flush policy for the best performance. All the performance issues are still meant to be resolved here. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16608&quot; title=&quot;Introducing the ability to merge ImmutableSegments without copy-compaction or SQM usage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16608&quot;&gt;&lt;del&gt;HBASE-16608&lt;/del&gt;&lt;/a&gt; is for one more &quot;algorithmic issue&quot;, not so sophisticated of course, but should resolve us the issues of two many segments (and later files) in the compaction pipeline. I would like to hear your opinion about all that! For more details look on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16608&quot; title=&quot;Introducing the ability to merge ImmutableSegments without copy-compaction or SQM usage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16608&quot;&gt;&lt;del&gt;HBASE-16608&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Waiting for your fruitful thoughts!&lt;br/&gt;
Thanks!&lt;/p&gt;</comment>
                            <comment id="15509291" author="eshcar" created="Wed, 21 Sep 2016 09:06:02 +0000"  >&lt;p&gt;We&apos;ve started working on the policy patch. &lt;br/&gt;
We try to set a baseline for performance by running PE over the default memstore with the configuration settings &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; suggested in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14921&quot; title=&quot;Inmemory Compaction Optimizations; Segment Structure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14921&quot;&gt;&lt;del&gt;HBASE-14921&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
&lt;b&gt;However&lt;/b&gt; we are only able to complete the run with 2-4 threads, 10 regions (pre split)  writing 10GB.&lt;br/&gt;
Any attempt to either increase the number of threads or the amount of data results in an Out of Memory Error caused by the &lt;b&gt;GC&lt;/b&gt;.&lt;br/&gt;
(I&apos;m running with the same settings for PE, hbase and GC as you posted.)&lt;/p&gt;

&lt;p&gt;We are running on a SSD 2.9PB disk (HDD wasn&apos;t even able to complete a run even with a single thread), with 48GB RAM.&lt;/p&gt;

&lt;p&gt;Some questions &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;:&lt;br/&gt;
1. Did you run PE on an SSD or HDD?&lt;br/&gt;
2. How much memory do you have in your machine?&lt;br/&gt;
3. Can you think of any parameter that you forgot to mention that may have caused the difference in executions? &lt;/p&gt;

&lt;p&gt;I&apos;ll also try running PE with more space for the GC and will update on the result.&lt;/p&gt;</comment>
                            <comment id="15509363" author="anoop.hbase" created="Wed, 21 Sep 2016 09:32:00 +0000"  >&lt;p&gt;Machine totally having ~150GB RAM&lt;br/&gt;
RS process allocated with 32 GB of xmx.&lt;br/&gt;
50 regions. 42% as the global memstore max size.&lt;br/&gt;
G1GC we used with initial heap occupancy factor as 50%. Waste percent configured as 10%&lt;br/&gt;
Also the flusher thread count made to 10 and Blocking store files count 25 (Configs)&lt;/p&gt;

&lt;p&gt;And we have HDD only in the node.&lt;/p&gt;</comment>
                            <comment id="15509411" author="ram_krish" created="Wed, 21 Sep 2016 09:48:46 +0000"  >&lt;p&gt;I think you need to configure your GC settings. Try with G1GC. That should be very important. Let us know what you observer.&lt;/p&gt;</comment>
                            <comment id="15509464" author="eshcar" created="Wed, 21 Sep 2016 10:10:40 +0000"  >&lt;p&gt;I used the same GC settings as you mentioned&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
export HBASE_OPTS=&lt;span class=&quot;code-quote&quot;&gt;&quot;-XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:InitiatingHeapOccupancyPercent=60 -XX:G1HeapWastePercent=20 -XX:G1MixedGCCountTarget=8&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The last 2 parameters you mentioned seems critical.&lt;br/&gt;
Did you mean these two where changed?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hstore.flusher.count&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;2&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt; The number of flush threads. With fewer threads, the MemStore flushes will be
      queued. With more threads, the flushes will be executed in parallel, increasing the load on
      HDFS, and potentially causing more compactions. &amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hstore.blockingStoreFiles&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;10&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt; If more than &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; number of StoreFiles exist in any one Store (one StoreFile
     is written per flush of MemStore), updates are blocked &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; region until a compaction is
      completed, or until hbase.hstore.blockingWaitTime has been exceeded.&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15509515" author="anoop.hbase" created="Wed, 21 Sep 2016 10:32:47 +0000"  >&lt;p&gt;Yep.. Changed to 10 and 25 respectively.&lt;/p&gt;</comment>
                            <comment id="15509522" author="anoop.hbase" created="Wed, 21 Sep 2016 10:36:43 +0000"  >&lt;p&gt;Are you seeing that a long pause GC happened and so RS got killed by master decision?&lt;br/&gt;
You said RS got OOME..  That is strange.&lt;br/&gt;
Because consider 32 GB heap and 50 regions and each region having 128 MB flush size.   By default we have 4 as the blocking memstore size.  Means this 128MB can become 512 MB. After that the memstore wont receive writes.&lt;br/&gt;
50* 128 * 4 =  25 GB.   &lt;br/&gt;
So am not getting how u got OOME.   U might get long GC pause.&lt;/p&gt;</comment>
                            <comment id="15509558" author="ram_krish" created="Wed, 21 Sep 2016 10:52:43 +0000"  >&lt;p&gt;Sorry just seeing this ping.&lt;br/&gt;
G1GC things looks fine.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Are you seeing that a long pause GC happened and so RS got killed by master decision?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think this is what will be happening. &lt;br/&gt;
Also ensure  you don&apos;t write to WAL. Hope you have that setting in your PE command. &lt;/p&gt;</comment>
                            <comment id="15509576" author="eshcar" created="Wed, 21 Sep 2016 11:02:23 +0000"  >&lt;p&gt;The error message is by the GC&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Stack: [0x00007f56a85d1000,0x00007f56a86d2000],  sp=0x00007f56a86cfe10,  free space=1019k
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; code)
V  [libjvm.so+0xab97ea]  VMError::report_and_die()+0x2ba
V  [libjvm.so+0x4f9dab]  report_vm_out_of_memory(&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;*, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, VMErrorType, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;*)+0x8b
V  [libjvm.so+0x91a7c3]  os::Linux::commit_memory_impl(&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, bool)+0x103
V  [libjvm.so+0x91ac65]  os::pd_commit_memory_or_exit(&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, bool, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;*)+0x35
V  [libjvm.so+0x914d46]  os::commit_memory_or_exit(&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, bool, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt;*)+0x26
V  [libjvm.so+0x5c073f]  G1PageBasedVirtualSpace::commit_internal(unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)+0xbf
V  [libjvm.so+0x5c09cc]  G1PageBasedVirtualSpace::commit(unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)+0x11c
V  [libjvm.so+0x5c3610]  G1RegionsLargerThanCommitSizeMapper::commit_regions(unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)+0x40
V  [libjvm.so+0x625157]  HeapRegionManager::commit_regions(unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)+0x77
V  [libjvm.so+0x6263f1]  HeapRegionManager::make_regions_available(unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)+0x31
V  [libjvm.so+0x626970]  HeapRegionManager::expand_by(unsigned &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)+0xb0
V  [libjvm.so+0x597c29]  G1CollectedHeap::expand(unsigned &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)+0x199
V  [libjvm.so+0x5a3b0d]  G1CollectedHeap::do_collection_pause_at_safepoint(&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;)+0xc6d
V  [libjvm.so+0xac3c2a]  VM_G1IncCollectionPause::doit()+0x9a
V  [libjvm.so+0xac2c35]  VM_Operation::evaluate()+0x55
V  [libjvm.so+0xac100a]  VMThread::evaluate_operation(VM_Operation*)+0xba
V  [libjvm.so+0xac138e]  VMThread::loop()+0x1ce
V  [libjvm.so+0xac1800]  VMThread::run()+0x70
V  [libjvm.so+0x91cb88]  java_start(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;*)+0x108
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so the RS crashes, don&apos;t think it is killed by master.&lt;/p&gt;

&lt;p&gt;Not writing to WAL.&lt;/p&gt;</comment>
                            <comment id="15509582" author="anoop.hbase" created="Wed, 21 Sep 2016 11:06:14 +0000"  >&lt;p&gt;What is the total memory available in ur RS node?  What all other active process?  I believe u have HM and RS and client app in same node.   HM not needing 32 GB any way and client too&lt;/p&gt;</comment>
                            <comment id="15610074" author="stack" created="Wed, 26 Oct 2016 23:48:51 +0000"  >&lt;p&gt;+1 on the @anoop sam john suggestion of first/default policy that flushes all in pipeline+active to the hfile as first cut.&lt;/p&gt;</comment>
                            <comment id="15610706" author="anoop.hbase" created="Thu, 27 Oct 2016 05:19:10 +0000"  >&lt;p&gt;We need in memory merge for&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Keep the tail of the pipeline with a bigger sized Segment. This is important to avoid small sized HFiles being created at flush. We are flushing only tail of the pipeline in any case now.&lt;/li&gt;
	&lt;li&gt;To help concurrent reads. When there is only active segment and it is a Map, one seek/read of a particular cell is just a map.get() op. When there are one more segment in pipeline (This is CellArrayMap), we will need binary search (Ya it is not linear search as in case of HFile blocks) to reach to the cell.  When there are so many segments in pipeline, we will need more binary search and so compromise on the latency of the read op. Doing in btw merges of segments in pipeline reduce its number and so helps latency.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Ya #2 seems valid and merge is the only way. But for #1 merge is not a mandatory one.&lt;/p&gt;

&lt;p&gt;So IMO flush only tail of whole of the segments (pipeline + active) is not directly related to merge. Even if we are having merge, there is no issue in flushing whole of the segments.  Now we have merge with every in memory flush means we are trying keeping only one segment in pipeline.  But the policy as discussed here, is going to change that. Doing merge every time with in memory flush is very costly. All agree to that.  This means we will have 3+ segments in pipeline. There is still issue of we being flushing smaller sized files.  So IMHO, we must flush whole to disk. &lt;br/&gt;
In case of index merge, where we know there are no cell duplicates and so we avoid data compaction, there is no point at all to delay the flush of the other segments in pipeline.  In case of data compaction ya it make sense.&lt;/p&gt;

&lt;p&gt;On the data compaction use case of Y, I have some Qs.  Is it increment way?  Or they are put ops but many duplicated cells comes in?&lt;/p&gt;</comment>
                            <comment id="15610727" author="stack" created="Thu, 27 Oct 2016 05:27:15 +0000"  >&lt;p&gt;As is said elsewhere, lets see how bad lookup into a CellArrayMap using binary search is first.&lt;/p&gt;

&lt;p&gt;Agree, first, default policy should be flush all to disk.&lt;/p&gt;</comment>
                            <comment id="15611478" author="eshcar" created="Thu, 27 Oct 2016 10:32:57 +0000"  >&lt;p&gt;This jira aims to find best policy/ies for in-memory flush merge and compaction. We&apos;ll tests various workloads, large scale, to find the policy that is most beneficial under common workloads, and is not causing performance degradation in all workloads. &lt;br/&gt;
We would like to approximate real production workloads (as much as possible with the synthetic tools we have to generate workloads) and to have decisions driven by benchmarks results.&lt;br/&gt;
I hope we can agree that the default policy or the one to be recommended to the users would be the one that performs the best.&lt;/p&gt;

&lt;p&gt;I started to run benchmarks, plan to publish new results every few days here whenever completing a round of experiments, and would be happy to get suggestions for further experiments.&lt;br/&gt;
First round will be published soon.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On the data compaction use case of Y, I have some Qs.  Is it increment way?  Or they are put ops but many duplicated cells comes in?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The duplicates originates from having skewed workloads where some keys are hot and therefore are updated much more frequently than cold keys.&lt;/p&gt;</comment>
                            <comment id="15611902" author="eshcar" created="Thu, 27 Oct 2016 13:32:36 +0000"  >&lt;p&gt;The report of the first round of experiment is ready however I cannot attach it here.&lt;br/&gt;
Can anyone assign this subtask to me so I can attach files in it?&lt;br/&gt;
Meanwhile, I will attach it in the umbrella Jira.&lt;/p&gt;

&lt;p&gt;The summary of the report is as follows &amp;#8211;&lt;br/&gt;
Main difference in configuration vs previous benchmarks:&lt;br/&gt;
1. Since we run on a 48GB ram machine we allocate only 16GB to HBase (and not 32GB).&lt;br/&gt;
2. Saturation point was found when running 10 threads (and not 50); see more details in the report.&lt;br/&gt;
3. We write 50GB (and not 150GB) just to have the experiments shorter since we run many different settings.&lt;/p&gt;

&lt;p&gt;First round of experiments compares different options (no-, index-, data-compaction) under write-only workload with uniform keys distribution using PE. We see that up until the 95th percentile all options are comparable. At the 99th percentile data compaction starts to lag behind &amp;#8211; indeed in a uniform workload there is not much point in doing data compaction. The overhead might stem from running SQM to determine which versions to retain. One way to close this gap is to not run data compaction when there is no gain in it. A good policy should be able to identify this with no extra cost.&lt;br/&gt;
At the 99.999th percentile index compaction also exhibits significant overhead. This might be due to memory reclamation of temporary indices.&lt;/p&gt;</comment>
                            <comment id="15611916" author="ebortnik" created="Thu, 27 Oct 2016 13:37:43 +0000"  >&lt;p&gt; blockquote, div.yahoo_quoted &lt;/p&gt;
{ margin-left: 0 !important; border-left:1px #715FFA solid !important; padding-left:1ex !important; background-color:white !important; }
&lt;p&gt;  I created this Jira, I think I can attach. Please share this file with me.&#160;&lt;/p&gt;


&lt;p&gt;Sent from Yahoo Mail for iPhone&lt;/p&gt;


&lt;p&gt;On Thursday, October 27, 2016, 4:32 PM, Eshcar Hillel (JIRA) &amp;lt;jira@apache.org&amp;gt; wrote:&lt;/p&gt;


&lt;p&gt;&#160; &#160; [ &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16417?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=15611902#comment-15611902&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-16417?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=15611902#comment-15611902&lt;/a&gt; ] &lt;/p&gt;

&lt;p&gt;Eshcar Hillel commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16417&quot; title=&quot;In-Memory MemStore Policy for Flattening and Compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16417&quot;&gt;HBASE-16417&lt;/a&gt;:&lt;br/&gt;
---------------------------------------&lt;/p&gt;

&lt;p&gt;The report of the first round of experiment is ready however I cannot attach it here.&lt;br/&gt;
Can anyone assign this subtask to me so I can attach files in it?&lt;br/&gt;
Meanwhile, I will attach it in the umbrella Jira.&lt;/p&gt;

&lt;p&gt;The summary of the report is as follows &amp;#8211;&lt;br/&gt;
Main difference in configuration vs previous benchmarks:&lt;br/&gt;
1. Since we run on a 48GB ram machine we allocate only 16GB to HBase (and not 32GB).&lt;br/&gt;
2. Saturation point was found when running 10 threads (and not 50); see more details in the report.&lt;br/&gt;
3. We write 50GB (and not 150GB) just to have the experiments shorter since we run many different settings.&lt;/p&gt;

&lt;p&gt;First round of experiments compares different options (no-, index-, data-compaction) under write-only workload with uniform keys distribution using PE. We see that up until the 95th percentile all options are comparable. At the 99th percentile data compaction starts to lag behind &amp;#8211; indeed in a uniform workload there is not much point in doing data compaction. The overhead might stem from running SQM to determine which versions to retain. One way to close this gap is to not run data compaction when there is no gain in it. A good policy should be able to identify this with no extra cost.&lt;br/&gt;
At the 99.999th percentile index compaction also exhibits significant overhead. This might be due to memory reclamation of temporary indices.&lt;/p&gt;





&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message was sent by Atlassian JIRA&lt;br/&gt;
(v6.3.4#6332)&lt;/p&gt;


</comment>
                            <comment id="15611943" author="anoop.hbase" created="Thu, 27 Oct 2016 13:46:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;One way to close this gap is to not run data compaction when there is no gain in it. A good policy should be able to identify this with no extra cost.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya that is the default right? It should be enabled using a config for specific kind of workload. (Like Y use case explained some other place)&lt;/p&gt;</comment>
                            <comment id="15611986" author="eshcar" created="Thu, 27 Oct 2016 14:03:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;Ya that is the default right? It should be enabled using a config for specific kind of workload.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, currently the default is no compaction (default memstore) and when setting in memory compaction to true the default is index compaction (not data compaction).&lt;br/&gt;
In this Jira we plan to explore different policies and evaluate their pros and cons.&lt;br/&gt;
In my comment I was referring to a plausible policy (not implemented yet) that would allow for data compaction however would avoid it when it is not likely to incur any benefit. &lt;/p&gt;</comment>
                            <comment id="15612232" author="ebortnik" created="Thu, 27 Oct 2016 15:34:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt; - the end state you both want to reach is the same, just the ways of going there are different. Before going into any detail - the holy grail is a self-tuning policy that does the right thing in EVERY use case of interest. We&apos;d like to achieve it without any additional configuration or private solutions for specific cases. Reason is - what ends up as non-default option will never be used. &lt;/p&gt;

&lt;p&gt;Anoop - you want two things actually: (1) no compaction of any kind happen when there is no redundancy and (2) flushing everything to disk when the memstore overflows. (Note that these two can be decoupled.) Hopefully you don&apos;t mind if there&apos;s a policy that magically figures out that we&apos;re in that use case, at practically zero cost, and does exactly (1) and (2). We just disagree on marking the opposite case (many duplicates) as special and going down a different code path there - because if we leave it to the admin as non-default we know what&apos;ll happen. &lt;/p&gt;

&lt;p&gt;So we are after that magic policy. The quest won&apos;t take long but it has to be data-driven. At the moment, we&apos;ve just reproduced one microbenchmark (uniform writes, no reads), but there are many other cases that should be looked at. We have the env to run them, and we&apos;ll be producing those results over the next couple of weeks. We&apos;ll be very much transparent in the process, publishing the results frequently. Once we have the data let&apos;s decide collectively. If nothing universal we&apos;ll work we can always back off to configs but I&apos;d consider that undesirable. &lt;/p&gt;</comment>
                            <comment id="15612299" author="anoop.hbase" created="Thu, 27 Oct 2016 15:51:41 +0000"  >&lt;p&gt;In memory index merge helps in scan case, I agree to ur argument. Ya am not saying we should never do it. Ya let us experiment with diff numbers as ur current tests.  My point was that flush only tail is with the assumption that we will merge eagerly and most of the memstore size is tail of pipeline. But when we play with diff #segments for merge, (say 4) we will end up in much smaller sized segment in tail and so smaller sized flush.  Actually speaking flush all is not directly related to merge.   So my point is let us have such a mechanism so that we can better test the impact of merge alone.. Now what happens is we will avoid frequent merges (by upping the #segments for merge) so reduce merge cost but that will have an impact on flush size. So if we can avoid that we can test merge cost much in isolation.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We just disagree on marking the opposite case (many duplicates) as special and going down a different code path there - because if we leave it to the admin as non-default we know what&apos;ll happen.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is the data compaction path right?  That is config driven and is in already. you say that also u will auto tune? That will be super cool if done. Am speaking on what is available as of today.&lt;/p&gt;</comment>
                            <comment id="15612322" author="stack" created="Thu, 27 Oct 2016 15:59:52 +0000"  >&lt;p&gt;I assigned the issue to you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15612344" author="stack" created="Thu, 27 Oct 2016 16:08:53 +0000"  >&lt;p&gt;To auto-tune you need stats. We keep talking about incorporating this low-friction library, &lt;a href=&quot;https://datasketches.github.io/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://datasketches.github.io/&lt;/a&gt;, to generate stats at flush and compaction time. Could it help here?&lt;/p&gt;</comment>
                            <comment id="15614876" author="eshcar" created="Fri, 28 Oct 2016 09:18:17 +0000"  >&lt;p&gt;First I plan to experiment with what we implemented so far without any additional code, to have the full picture including mixed workloads, so we&apos;ll know what is working well and what we want to improve on. &lt;br/&gt;
This would also be a baseline for comparing enhancement that can be achieved by &quot;smart&quot; policies, including the ones you suggested that only merges segments upon flush to disk (but this would need to wait to the 3rd round of experiments &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;

&lt;p&gt;I started with PE tool &amp;#8211; nothing surprising with the results we got here. PE limits us to write only workload which is important but does not reveal the true gain of this in-memory feature. For this reason I plan to start using the YCSB tool, and as a first step to verify I can re-produce the results we got from PE for 100% writes. The only difference is that YCSB does not have an easy way to set WAL off, so I expect the absolute numbers to be different but the trends to remain the same.  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We avoid copying for the data case? Is that unreal?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;What I meant (and obviously wasn&apos;t clear enough) is that I turn off MSLAB in the &lt;b&gt;configuration&lt;/b&gt; not by changing the code to avoid MSLABs.&lt;br/&gt;
When MSLAB is on segments use chunks and whenever creating a new segment while executing data compaction the retained cells are being copied to the new chunks in the new segments, so that the GC can reclaim the old chunks.&lt;br/&gt;
When MSLAB is off, segments do not use chunks and therefore don&apos;t need to copy the data to new chunks; retained cells are being pointed by the flat index (cell array map)  and the rest are collected by the GC.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Now what happens is we will avoid frequent merges (by upping the #segments for merge) so reduce merge cost but that will have an impact on flush size.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; I agree with what you say, a bit more patient, the solution you are after can be captured as one of the policies. We&apos;ll get to that after we complete the next evaluation round.&lt;/p&gt;</comment>
                            <comment id="15614890" author="anoop.hbase" created="Fri, 28 Oct 2016 09:28:02 +0000"  >&lt;p&gt;Sorry I was not saying we need do it now &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  I mean to tell it clearly that that will be better test for the merge cost.  Ya in next rounds we can do. NP.&lt;/p&gt;

&lt;p&gt;Understood what u r doing with the data compaction case. Ya no MSLAB and no data copy while doing the data compaction.&lt;/p&gt;</comment>
                            <comment id="15615299" author="ebortnik" created="Fri, 28 Oct 2016 12:52:32 +0000"  >&lt;p&gt;Just to give a sense of what we&apos;ve been thinking as possible auto-tuning policy (smile). It&apos;s a &quot;war driving&quot; approach that is actually similar to opportunistic scans we had once but is a bit smarter.  Suppose we do full (data) compaction once in a while; a by-product is the compaction factor - how much space we saved. If the latter is small - schedule the next compaction further away, using some exponential backoff scheme. For workloads with very few duplicates - compactions will never happen, de-facto. For skewed workloads, compactions will consistently prove valuable, and will run at a constant pace. &lt;/p&gt;

&lt;p&gt;Note that the above is unrelated to whether we flush just one or all segments in the pipeline once the disk flush time comes. Personal opinion - no problem with flushing everything if this shows value. Let&apos;s wait for more benchmark results, they&apos;re just around the corner. One more personal opinion - we should strive to a generic policy, as much independent as possible on whether we use MSLAB&apos;s or not, run on-heap or off-heap, etc.; let&apos;s see if we can get there. &lt;/p&gt;

&lt;p&gt;Actually it&apos;s the most fun stage now - we have all the building blocks, the goal is connecting them right &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Stay tuned, we&apos;ll keep sharing the results and the ideas.  &lt;/p&gt;</comment>
                            <comment id="15623353" author="eshcar" created="Mon, 31 Oct 2016 20:39:55 +0000"  >&lt;p&gt;Turns out latest version of YCSB includes new features like disabling WAL and pre-split. After taking some time to familiarize with all the correct knobs I am now able to run YCSB against HBase at rates which are similar to (yet lower than) the PE rates.&lt;br/&gt;
So this is good news. &lt;br/&gt;
I hope to have new YCSB results by EOD tomorrow.&lt;/p&gt;

&lt;p&gt;I am only missing a single item &amp;#8211; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
What is number of records (key range) used by the PE? It is not given in the command line and I wasn&apos;t able to deduce it from the code. &lt;br/&gt;
Is there some default value? Is it a function of other parameters?&lt;br/&gt;
Would appreciate your help here. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_red.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15623535" author="stack" created="Mon, 31 Oct 2016 21:52:31 +0000"  >&lt;p&gt;Default is 1M rows &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is what is in the table when I do default sequentialWrite with 1 client:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
hbase(main):001:0&amp;gt; scan &apos;TestTable&apos;, {LIMIT =&amp;gt; 10}
ROW                                                 COLUMN+CELL
 00000000000000000000000000                         column=info:0, timestamp=1477950565064, value=DDDDDDDDYYYYYYYYQQQQQQQQGGGGGGGGPPPPPPPPUUUUUUUUCCCCCCCCGGGGGGGGHHHHHHHHFFFFFFFFWWWWWWWWSSSSSSSSDDDDDDDD
                                                    UUUUUUUUDDDDDDDDOOOOOOOOBBBBBBBBUUUUUUUUUUUUUUUUFFFFFFFFLLLLLLLLTTTTTTTTPPPPPPPPZZZZZZZZGGGGGGGGIIIIIIIISSSSSSSSQQQQQQQQAAAAAAAAQQQQQQQQFFFFFFFFTTTTTT
                                                    TTXXXXXXXXTTTTTTTTHHHHHHHHIIIIIIIINNNNNNNNHHHHHHHHVVVVVVVVUUUUUUUUNNNNNNNNUUUUUUUUQQQQQQQQCCCCCCCCRRRRRRRRGGGGGGGGAAAAAAAAFFFFFFFFJJJJJJJJUUUUUUUUIIII
                                                    IIIICCCCCCCCFFFFFFFFXXXXXXXXNNNNNNNNQQQQQQQQSSSSSSSSBBBBBBBBJJJJJJJJTTTTTTTTQQQQQQQQLLLLLLLLQQQQQQQQLLLLLLLLPPPPPPPPXXXXXXXXTTTTTTTTGGGGGGGGOOOOOOOOWW
                                                    WWWWWWUUUUUUUUMMMMMMMMDDDDDDDDRRRRRRRRHHHHHHHHLLLLLLLLBBBBBBBBNNNNNNNNWWWWWWWWFFFFFFFFXXXXXXXXCCCCCCCCZZZZZZZZNNNNNNNNGGGGGGGGYYYYYYYYGGGGGGGGGGGGGGGG
                                                    KKKKKKKKIIIIIIIIBBBBBBBBGGGGGGGGGGGGGGGGKKKKKKKKMMMMMMMMOOOOOOOOTTTTTTTTBBBBBBBBDDDDDDDDSSSSSSSSEEEEEEEESSSSSSSSHHHHHHHHRRRRRRRRDDDDDDDDNNNNNNNNIIIIII
                                                    IIDDDDDDDDJJJJJJJJWWWWWWWWIIIIIIIIWWWWWWWWKKKKKKKKOOOOOOOOUUUUUUUUAAAAAAAAKKKKKKKKIIIIIIIISSSSSSSSSSSSSSSSZZZZZZZZDDDDDDDDWWWWWWWWXXXXXXXXPPPPPPPP
 00000000000000000000000001                         column=info:0, timestamp=1477950565064, value=AAAAAAAACCCCCCCCHHHHHHHHDDDDDDDDWWWWWWWWTTTTTTTTWWWWWWWWZZZZZZZZMMMMMMMMHHHHHHHHZZZZZZZZXXXXXXXXNNNNNNNN
                                                    BBBBBBBBQQQQQQQQVVVVVVVVRRRRRRRRAAAAAAAAVVVVVVVVJJJJJJJJEEEEEEEEGGGGGGGGEEEEEEEEZZZZZZZZCCCCCCCCAAAAAAAAUUUUUUUUAAAAAAAAFFFFFFFFNNNNNNNNRRRRRRRRXXXXXX
                                                    XXCCCCCCCCKKKKKKKKIIIIIIIIIIIIIIIIMMMMMMMMZZZZZZZZKKKKKKKKZZZZZZZZGGGGGGGGQQQQQQQQGGGGGGGGBBBBBBBBNNNNNNNNLLLLLLLLTTTTTTTTXXXXXXXXRRRRRRRRXXXXXXXXCCCC
                                                    CCCCQQQQQQQQHHHHHHHHYYYYYYYYSSSSSSSSDDDDDDDDDDDDDDDDAAAAAAAARRRRRRRRAAAAAAAAHHHHHHHHRRRRRRRRKKKKKKKKQQQQQQQQSSSSSSSSNNNNNNNNLLLLLLLLWWWWWWWWLLLLLLLLYY
                                                    YYYYYYEEEEEEEEGGGGGGGGIIIIIIIIWWWWWWWWFFFFFFFFCCCCCCCCYYYYYYYYAAAAAAAAHHHHHHHHVVVVVVVVNNNNNNNNAAAAAAAATTTTTTTTQQQQQQQQLLLLLLLLFFFFFFFFYYYYYYYYUUUUUUUU
                                                    WWWWWWWWQQQQQQQQJJJJJJJJJJJJJJJJBBBBBBBBIIIIIIIINNNNNNNNJJJJJJJJTTTTTTTTSSSSSSSSFFFFFFFFFFFFFFFFPPPPPPPPCCCCCCCCMMMMMMMMSSSSSSSSZZZZZZZZXXXXXXXXEEEEEE
                                                    EESSSSSSSSIIIIIIIIUUUUUUUURRRRRRRRJJJJJJJJMMMMMMMMVVVVVVVVIIIIIIIIAAAAAAAAXXXXXXXXNNNNNNNNMMMMMMMMGGGGGGGGOOOOOOOOSSSSSSSSIIIIIIIIHHHHHHHHOOOOOOOO
 00000000000000000000000002                         column=info:0, timestamp=1477950565064, value=YYYYYYYYLLLLLLLLJJJJJJJJXXXXXXXXVVVVVVVVIIIIIIIIFFFFFFFFZZZZZZZZKKKKKKKKNNNNNNNNZZZZZZZZJJJJJJJJPPPPPPPP
                                                    GGGGGGGGLLLLLLLLRRRRRRRRRRRRRRRRXXXXXXXXRRRRRRRRRRRRRRRRWWWWWWWWHHHHHHHHIIIIIIIIPPPPPPPPPPPPPPPPXXXXXXXXDDDDDDDDAAAAAAAADDDDDDDDFFFFFFFFQQQQQQQQGGGGGG
                                                    GGKKKKKKKKEEEEEEEEFFFFFFFFBBBBBBBBCCCCCCCCTTTTTTTTPPPPPPPPOOOOOOOOTTTTTTTTGGGGGGGGYYYYYYYYZZZZZZZZVVVVVVVVJJJJJJJJMMMMMMMMUUUUUUUUPPPPPPPPXXXXXXXXNNNN
                                                    NNNNRRRRRRRRMMMMMMMMGGGGGGGGSSSSSSSSDDDDDDDDZZZZZZZZYYYYYYYYPPPPPPPPRRRRRRRRTTTTTTTTAAAAAAAABBBBBBBBPPPPPPPPCCCCCCCCZZZZZZZZSSSSSSSSXXXXXXXXGGGGGGGGTT
                                                    TTTTTTNNNNNNNNCCCCCCCCXXXXXXXXRRRRRRRRFFFFFFFFVVVVVVVVHHHHHHHHPPPPPPPPRRRRRRRRDDDDDDDDVVVVVVVVTTTTTTTTJJJJJJJJXXXXXXXXGGGGGGGGJJJJJJJJKKKKKKKKCCCCCCCC
                                                    BBBBBBBBIIIIIIIIPPPPPPPPEEEEEEEEIIIIIIIIUUUUUUUURRRRRRRRRRRRRRRRTTTTTTTTQQQQQQQQAAAAAAAAKKKKKKKKLLLLLLLLGGGGGGGGLLLLLLLLGGGGGGGGLLLLLLLLEEEEEEEESSSSSS
                                                    SSGGGGGGGGBBBBBBBBTTTTTTTTAAAAAAAARRRRRRRRTTTTTTTTEEEEEEEEXXXXXXXXCCCCCCCCQQQQQQQQPPPPPPPPKKKKKKKKWWWWWWWWVVVVVVVVHHHHHHHHJJJJJJJJMMMMMMMMUUUUUUUU
 00000000000000000000000003                         column=info:0, timestamp=1477950565064, value=CCCCCCCCZZZZZZZZKKKKKKKKYYYYYYYYZZZZZZZZFFFFFFFFIIIIIIIIFFFFFFFFWWWWWWWWQQQQQQQQKKKKKKKKBBBBBBBBYYYYYYYY
                                                    OOOOOOOOWWWWWWWWLLLLLLLLCCCCCCCCZZZZZZZZUUUUUUUUOOOOOOOOSSSSSSSSFFFFFFFFXXXXXXXXVVVVVVVVVVVVVVVVTTTTTTTTOOOOOOOOZZZZZZZZHHHHHHHHXXXXXXXXKKKKKKKKRRRRRR
                                                    RRMMMMMMMMLLLLLLLLOOOOOOOOLLLLLLLLJJJJJJJJGGGGGGGGDDDDDDDDAAAAAAAAPPPPPPPPKKKKKKKKQQQQQQQQXXXXXXXXIIIIIIIICCCCCCCCAAAAAAAADDDDDDDDMMMMMMMMRRRRRRRRUUUU
                                                    UUUUVVVVVVVVNNNNNNNNVVVVVVVVHHHHHHHHHHHHHHHHAAAAAAAAHHHHHHHHNNNNNNNNKKKKKKKKFFFFFFFFWWWWWWWWLLLLLLLLKKKKKKKKCCCCCCCCDDDDDDDDVVVVVVVVLLLLLLLLZZZZZZZZQQ
                                                    QQQQQQMMMMMMMMMMMMMMMMCCCCCCCCLLLLLLLLIIIIIIIIBBBBBBBBPPPPPPPPEEEEEEEEBBBBBBBBDDDDDDDDNNNNNNNNVVVVVVVVBBBBBBBBTTTTTTTTPPPPPPPPRRRRRRRRXXXXXXXXLLLLLLLL
                                                    ZZZZZZZZHHHHHHHHTTTTTTTTEEEEEEEEQQQQQQQQPPPPPPPPJJJJJJJJGGGGGGGGSSSSSSSSXXXXXXXXBBBBBBBBXXXXXXXXGGGGGGGGGGGGGGGGJJJJJJJJTTTTTTTTUUUUUUUUGGGGGGGGCCCCCC
                                                    CCPPPPPPPPFFFFFFFFXXXXXXXXQQQQQQQQEEEEEEEECCCCCCCCLLLLLLLLDDDDDDDDTTTTTTTTLLLLLLLLUUUUUUUURRRRRRRRVVVVVVVVNNNNNNNNDDDDDDDDCCCCCCCCYYYYYYYYKKKKKKKK
....


00000000000000000001048568                         column=info:0, timestamp=1477950575095, value=MMMMMMMMOOOOOOOODDDDDDDDEEEEEEEEJJJJJJJJHHHHHHHHHHHHHHHHYYYYYYYYMMMMMMMMDDDDDDDDQQQQQQQQZZZZZZZZDDDDDDDD
                                                    SSSSSSSSAAAAAAAAFFFFFFFFVVVVVVVVWWWWWWWWUUUUUUUUGGGGGGGGMMMMMMMMTTTTTTTTVVVVVVVVWWWWWWWWBBBBBBBBRRRRRRRRQQQQQQQQNNNNNNNNBBBBBBBBXXXXXXXXKKKKKKKKGGGGGG
                                                    GGWWWWWWWWTTTTTTTTPPPPPPPPGGGGGGGGGGGGGGGGUUUUUUUUWWWWWWWWCCCCCCCCAAAAAAAAWWWWWWWWNNNNNNNNBBBBBBBBQQQQQQQQDDDDDDDDOOOOOOOOLLLLLLLLFFFFFFFFSSSSSSSSVVVV
                                                    VVVVJJJJJJJJHHHHHHHHEEEEEEEEJJJJJJJJYYYYYYYYDDDDDDDDZZZZZZZZCCCCCCCCWWWWWWWWCCCCCCCCSSSSSSSSYYYYYYYYPPPPPPPPMMMMMMMMCCCCCCCCVVVVVVVVXXXXXXXXLLLLLLLLNN
                                                    NNNNNNEEEEEEEEYYYYYYYYEEEEEEEECCCCCCCCTTTTTTTTTTTTTTTTFFFFFFFFGGGGGGGGUUUUUUUUZZZZZZZZOOOOOOOOUUUUUUUUBBBBBBBBPPPPPPPPFFFFFFFFPPPPPPPPYYYYYYYYMMMMMMMM
                                                    HHHHHHHHFFFFFFFFIIIIIIIIRRRRRRRRHHHHHHHHXXXXXXXXKKKKKKKKDDDDDDDDKKKKKKKKIIIIIIIIMMMMMMMMFFFFFFFFSSSSSSSSIIIIIIIILLLLLLLLLLLLLLLLFFFFFFFFUUUUUUUUXXXXXX
                                                    XXIIIIIIIIBBBBBBBBVVVVVVVVCCCCCCCCOOOOOOOOMMMMMMMMLLLLLLLLOOOOOOOOAAAAAAAABBBBBBBBWWWWWWWWFFFFFFFFXXXXXXXXYYYYYYYYCCCCCCCCVVVVVVVVSSSSSSSSOOOOOOOO
 00000000000000000001048569                         column=info:0, timestamp=1477950575095, value=RRRRRRRRPPPPPPPPLLLLLLLLCCCCCCCCLLLLLLLLXXXXXXXXBBBBBBBBFFFFFFFFSSSSSSSSKKKKKKKKAAAAAAAAJJJJJJJJQQQQQQQQ
                                                    OOOOOOOOGGGGGGGGJJJJJJJJAAAAAAAAZZZZZZZZLLLLLLLLHHHHHHHHTTTTTTTTRRRRRRRRWWWWWWWWJJJJJJJJQQQQQQQQCCCCCCCCCCCCCCCCNNNNNNNNNNNNNNNNVVVVVVVVXXXXXXXXYYYYYY
                                                    YYXXXXXXXXKKKKKKKKUUUUUUUURRRRRRRRXXXXXXXXKKKKKKKKDDDDDDDDSSSSSSSSFFFFFFFFWWWWWWWWDDDDDDDDTTTTTTTTRRRRRRRROOOOOOOOZZZZZZZZDDDDDDDDCCCCCCCCKKKKKKKKGGGG
                                                    GGGGFFFFFFFFDDDDDDDDAAAAAAAAGGGGGGGGBBBBBBBBLLLLLLLLZZZZZZZZAAAAAAAAOOOOOOOONNNNNNNNDDDDDDDDIIIIIIIIRRRRRRRRLLLLLLLLLLLLLLLLSSSSSSSSQQQQQQQQLLLLLLLLUU
                                                    UUUUUUBBBBBBBBMMMMMMMMNNNNNNNNBBBBBBBBBBBBBBBBUUUUUUUUCCCCCCCCSSSSSSSSHHHHHHHHXXXXXXXXJJJJJJJJXXXXXXXXWWWWWWWWGGGGGGGGWWWWWWWWOOOOOOOOAAAAAAAANNNNNNNN
                                                    BBBBBBBBWWWWWWWWSSSSSSSSPPPPPPPPIIIIIIIICCCCCCCCXXXXXXXXLLLLLLLLXXXXXXXXRRRRRRRRVVVVVVVVAAAAAAAAEEEEEEEEFFFFFFFFJJJJJJJJQQQQQQQQUUUUUUUUUUUUUUUULLLLLL
                                                    LLMMMMMMMMTTTTTTTTAAAAAAAAAAAAAAAABBBBBBBBNNNNNNNNHHHHHHHHOOOOOOOOJJJJJJJJGGGGGGGGYYYYYYYYSSSSSSSSDDDDDDDDHHHHHHHHJJJJJJJJTTTTTTTTNNNNNNNNAAAAAAAA
 00000000000000000001048570                         column=info:0, timestamp=1477950575095, value=JJJJJJJJSSSSSSSSHHHHHHHHHHHHHHHHAAAAAAAAQQQQQQQQXXXXXXXXFFFFFFFFUUUUUUUULLLLLLLLJJJJJJJJHHHHHHHHOOOOOOOO
                                                    YYYYYYYYHHHHHHHHXXXXXXXXFFFFFFFFRRRRRRRRIIIIIIIIZZZZZZZZIIIIIIIICCCCCCCCSSSSSSSSQQQQQQQQRRRRRRRRVVVVVVVVLLLLLLLLFFFFFFFFLLLLLLLLHHHHHHHHJJJJJJJJJJJJJJ
                                                    JJLLLLLLLLNNNNNNNNMMMMMMMMCCCCCCCCCCCCCCCCRRRRRRRRFFFFFFFFNNNNNNNNNNNNNNNNGGGGGGGGKKKKKKKKZZZZZZZZVVVVVVVVXXXXXXXXIIIIIIIIZZZZZZZZTTTTTTTTKKKKKKKKNNNN
                                                    NNNNDDDDDDDDSSSSSSSSVVVVVVVVOOOOOOOOVVVVVVVVGGGGGGGGJJJJJJJJTTTTTTTTFFFFFFFFIIIIIIIIHHHHHHHHUUUUUUUULLLLLLLLVVVVVVVVLLLLLLLLIIIIIIIIHHHHHHHHLLLLLLLLPP
                                                    PPPPPPMMMMMMMMWWWWWWWWBBBBBBBBNNNNNNNNAAAAAAAAJJJJJJJJMMMMMMMMAAAAAAAAAAAAAAAAPPPPPPPPNNNNNNNNLLLLLLLLIIIIIIIIBBBBBBBBVVVVVVVVTTTTTTTTSSSSSSSSLLLLLLLL
                                                    NNNNNNNNIIIIIIIILLLLLLLLQQQQQQQQBBBBBBBBUUUUUUUUOOOOOOOOMMMMMMMMGGGGGGGGJJJJJJJJDDDDDDDDDDDDDDDDVVVVVVVVPPPPPPPPGGGGGGGGMMMMMMMMWWWWWWWWAAAAAAAABBBBBB
                                                    BBXXXXXXXXZZZZZZZZEEEEEEEEDDDDDDDDIIIIIIIIGGGGGGGGOOOOOOOORRRRRRRRKKKKKKKKNNNNNNNNDDDDDDDDWWWWWWWWBBBBBBBBKKKKKKKKIIIIIIIINNNNNNNNOOOOOOOOLLLLLLLL
 00000000000000000001048571                         column=info:0, timestamp=1477950575095, value=AAAAAAAAVVVVVVVVUUUUUUUUSSSSSSSSQQQQQQQQAAAAAAAAWWWWWWWWEEEEEEEEVVVVVVVVBBBBBBBBIIIIIIIIHHHHHHHHWWWWWWWW
                                                    EEEEEEEEAAAAAAAAYYYYYYYYUUUUUUUUPPPPPPPPBBBBBBBBBBBBBBBBDDDDDDDDXXXXXXXXWWWWWWWWGGGGGGGGBBBBBBBBQQQQQQQQYYYYYYYYQQQQQQQQXXXXXXXXJJJJJJJJDDDDDDDDQQQQQQ
                                                    QQGGGGGGGGSSSSSSSSYYYYYYYYPPPPPPPPYYYYYYYYVVVVVVVVLLLLLLLLGGGGGGGGUUUUUUUUQQQQQQQQIIIIIIIIOOOOOOOOKKKKKKKKRRRRRRRRLLLLLLLLWWWWWWWWRRRRRRRRBBBBBBBBRRRR
                                                    RRRRSSSSSSSSIIIIIIIITTTTTTTTPPPPPPPPOOOOOOOOVVVVVVVVJJJJJJJJUUUUUUUUPPPPPPPPPPPPPPPPPPPPPPPPJJJJJJJJZZZZZZZZRRRRRRRRWWWWWWWWYYYYYYYYYYYYYYYYOOOOOOOOQQ
                                                    QQQQQQPPPPPPPPXXXXXXXXLLLLLLLLXXXXXXXXQQQQQQQQCCCCCCCCUUUUUUUUMMMMMMMMYYYYYYYYJJJJJJJJUUUUUUUUOOOOOOOOSSSSSSSSBBBBBBBBAAAAAAAAXXXXXXXXCCCCCCCCLLLLLLLL
                                                    YYYYYYYYCCCCCCCCYYYYYYYYRRRRRRRRCCCCCCCCKKKKKKKKPPPPPPPPBBBBBBBBMMMMMMMMTTTTTTTTAAAAAAAAZZZZZZZZEEEEEEEEGGGGGGGGMMMMMMMMTTTTTTTTHHHHHHHHZZZZZZZZWWWWWW
                                                    WWWWWWWWWWJJJJJJJJIIIIIIIIRRRRRRRRSSSSSSSSSSSSSSSSCCCCCCCCDDDDDDDDFFFFFFFFZZZZZZZZFFFFFFFFNNNNNNNNXXXXXXXXCCCCCCCCNNNNNNNNHHHHHHHHDDDDDDDDFFFFFFFF
 00000000000000000001048572                         column=info:0, timestamp=1477950575095, value=UUUUUUUUKKKKKKKKQQQQQQQQCCCCCCCCHHHHHHHHRRRRRRRRMMMMMMMMQQQQQQQQCCCCCCCCAAAAAAAASSSSSSSSLLLLLLLLFFFFFFFF
                                                    BBBBBBBBZZZZZZZZCCCCCCCCZZZZZZZZAAAAAAAADDDDDDDDNNNNNNNNKKKKKKKKJJJJJJJJTTTTTTTTFFFFFFFFHHHHHHHHIIIIIIIIGGGGGGGGUUUUUUUUBBBBBBBBCCCCCCCCTTTTTTTTCCCCCC
                                                    CCZZZZZZZZJJJJJJJJQQQQQQQQQQQQQQQQNNNNNNNNIIIIIIIIOOOOOOOOGGGGGGGGYYYYYYYYXXXXXXXXGGGGGGGGCCCCCCCCFFFFFFFFYYYYYYYYSSSSSSSSJJJJJJJJMMMMMMMMTTTTTTTTYYYY
                                                    YYYYMMMMMMMMPPPPPPPPWWWWWWWWMMMMMMMMAAAAAAAASSSSSSSSPPPPPPPPWWWWWWWWYYYYYYYYBBBBBBBBJJJJJJJJSSSSSSSSVVVVVVVVOOOOOOOOMMMMMMMMDDDDDDDDTTTTTTTTMMMMMMMMGG
                                                    GGGGGGRRRRRRRRYYYYYYYYYYYYYYYYLLLLLLLLLLLLLLLLXXXXXXXXMMMMMMMMEEEEEEEEMMMMMMMMYYYYYYYYHHHHHHHHBBBBBBBBRRRRRRRRKKKKKKKKJJJJJJJJJJJJJJJJLLLLLLLLOOOOOOOO
                                                    FFFFFFFFUUUUUUUUBBBBBBBBEEEEEEEENNNNNNNNNNNNNNNNOOOOOOOOAAAAAAAAYYYYYYYYOOOOOOOOBBBBBBBBHHHHHHHHRRRRRRRROOOOOOOOCCCCCCCCCCCCCCCCAAAAAAAAZZZZZZZZVVVVVV
                                                    VVSSSSSSSSWWWWWWWWRRRRRRRRGGGGGGGGNNNNNNNNSSSSSSSSYYYYYYYYWWWWWWWWZZZZZZZZPPPPPPPPZZZZZZZZQQQQQQQQGGGGGGGGQQQQQQQQQQQQQQQQKKKKKKKKVVVVVVVVZZZZZZZZ
 00000000000000000001048573                         column=info:0, timestamp=1477950575095, value=XXXXXXXXZZZZZZZZLLLLLLLLTTTTTTTTEEEEEEEEJJJJJJJJDDDDDDDDQQQQQQQQUUUUUUUUEEEEEEEEPPPPPPPPBBBBBBBBFFFFFFFF
                                                    TTTTTTTTWWWWWWWWUUUUUUUUGGGGGGGGQQQQQQQQMMMMMMMMUUUUUUUUDDDDDDDDCCCCCCCCUUUUUUUUXXXXXXXXEEEEEEEEFFFFFFFFEEEEEEEEFFFFFFFFEEEEEEEERRRRRRRRTTTTTTTTAAAAAA
                                                    AAPPPPPPPPIIIIIIIIFFFFFFFFHHHHHHHHCCCCCCCCWWWWWWWWIIIIIIIIJJJJJJJJYYYYYYYYQQQQQQQQBBBBBBBBAAAAAAAAYYYYYYYYDDDDDDDDYYYYYYYYJJJJJJJJCCCCCCCCBBBBBBBBUUUU
                                                    UUUUGGGGGGGGWWWWWWWWPPPPPPPPNNNNNNNNTTTTTTTTJJJJJJJJTTTTTTTTKKKKKKKKDDDDDDDDOOOOOOOOPPPPPPPPHHHHHHHHDDDDDDDDAAAAAAAAHHHHHHHHEEEEEEEESSSSSSSSOOOOOOOOOO
                                                    OOOOOOVVVVVVVVBBBBBBBBLLLLLLLLTTTTTTTTMMMMMMMMRRRRRRRRAAAAAAAAIIIIIIIIGGGGGGGGMMMMMMMMZZZZZZZZHHHHHHHHTTTTTTTTCCCCCCCCXXXXXXXXEEEEEEEEGGGGGGGGFFFFFFFF
                                                    PPPPPPPPNNNNNNNNKKKKKKKKHHHHHHHHYYYYYYYYNNNNNNNNLLLLLLLLQQQQQQQQQQQQQQQQUUUUUUUUWWWWWWWWXXXXXXXXAAAAAAAAIIIIIIIIVVVVVVVVNNNNNNNNMMMMMMMMMMMMMMMMHHHHHH
                                                    HHBBBBBBBBRRRRRRRRBBBBBBBBVVVVVVVVAAAAAAAAMMMMMMMMFFFFFFFFVVVVVVVVGGGGGGGGBBBBBBBBHHHHHHHHUUUUUUUUBBBBBBBBQQQQQQQQSSSSSSSSRRRRRRRRPPPPPPPPEEEEEEEE
 00000000000000000001048574                         column=info:0, timestamp=1477950575095, value=XXXXXXXXMMMMMMMMMMMMMMMMQQQQQQQQCCCCCCCCPPPPPPPPPPPPPPPPIIIIIIIIBBBBBBBBQQQQQQQQRRRRRRRRGGGGGGGGQQQQQQQQ
                                                    PPPPPPPPQQQQQQQQKKKKKKKKYYYYYYYYRRRRRRRRZZZZZZZZMMMMMMMMRRRRRRRRAAAAAAAATTTTTTTTKKKKKKKKWWWWWWWWQQQQQQQQVVVVVVVVVVVVVVVVQQQQQQQQJJJJJJJJXXXXXXXXSSSSSS
                                                    SSQQQQQQQQNNNNNNNNGGGGGGGGWWWWWWWWCCCCCCCCTTTTTTTTGGGGGGGGTTTTTTTTPPPPPPPPLLLLLLLLHHHHHHHHWWWWWWWWWWWWWWWWUUUUUUUUKKKKKKKKZZZZZZZZGGGGGGGGYYYYYYYYZZZZ
                                                    ZZZZFFFFFFFFYYYYYYYYTTTTTTTTDDDDDDDDSSSSSSSSSSSSSSSSEEEEEEEEIIIIIIIIHHHHHHHHOOOOOOOOPPPPPPPPPPPPPPPPLLLLLLLLPPPPPPPPWWWWWWWWYYYYYYYYOOOOOOOOSSSSSSSSFF
                                                    FFFFFFKKKKKKKKMMMMMMMMPPPPPPPPJJJJJJJJTTTTTTTTQQQQQQQQXXXXXXXXJJJJJJJJCCCCCCCCEEEEEEEEAAAAAAAAXXXXXXXXAAAAAAAACCCCCCCCQQQQQQQQQQQQQQQQBBBBBBBBTTTTTTTT
                                                    DDDDDDDDKKKKKKKKTTTTTTTTRRRRRRRRJJJJJJJJMMMMMMMMMMMMMMMMEEEEEEEEWWWWWWWWKKKKKKKKQQQQQQQQKKKKKKKKOOOOOOOOFFFFFFFFEEEEEEEEPPPPPPPPJJJJJJJJTTTTTTTTXXXXXX
                                                    XXJJJJJJJJGGGGGGGGIIIIIIIIUUUUUUUURRRRRRRRSSSSSSSSBBBBBBBBDDDDDDDDWWWWWWWWIIIIIIIIFFFFFFFFDDDDDDDDAAAAAAAASSSSSSSSKKKKKKKKVVVVVVVVXXXXXXXXQQQQQQQQ
 00000000000000000001048575                         column=info:0, timestamp=1477950575095, value=EEEEEEEEPPPPPPPPMMMMMMMMXXXXXXXXGGGGGGGGTTTTTTTTZZZZZZZZLLLLLLLLYYYYYYYYFFFFFFFFEEEEEEEEAAAAAAAAIIIIIIII
                                                    RRRRRRRRDDDDDDDDIIIIIIIIRRRRRRRRFFFFFFFFMMMMMMMMGGGGGGGGUUUUUUUUYYYYYYYYHHHHHHHHUUUUUUUUYYYYYYYYJJJJJJJJPPPPPPPPAAAAAAAAJJJJJJJJYYYYYYYYUUUUUUUUBBBBBB
                                                    BBVVVVVVVVQQQQQQQQQQQQQQQQCCCCCCCCNNNNNNNNWWWWWWWWGGGGGGGGLLLLLLLLVVVVVVVVBBBBBBBBFFFFFFFFWWWWWWWWYYYYYYYYAAAAAAAALLLLLLLLKKKKKKKKBBBBBBBBVVVVVVVVEEEE
                                                    EEEEMMMMMMMMIIIIIIIIIIIIIIIICCCCCCCCHHHHHHHHZZZZZZZZEEEEEEEEYYYYYYYYPPPPPPPPYYYYYYYYGGGGGGGGZZZZZZZZQQQQQQQQMMMMMMMMHHHHHHHHRRRRRRRRDDDDDDDDIIIIIIIILL
                                                    LLLLLLAAAAAAAAAAAAAAAAJJJJJJJJAAAAAAAAOOOOOOOOWWWWWWWWEEEEEEEEPPPPPPPPYYYYYYYYHHHHHHHHIIIIIIIIGGGGGGGGYYYYYYYYMMMMMMMMTTTTTTTTMMMMMMMMSSSSSSSSQQQQQQQQ
                                                    LLLLLLLLTTTTTTTTIIIIIIIIOOOOOOOOLLLLLLLLLLLLLLLLYYYYYYYYGGGGGGGGRRRRRRRRWWWWWWWWOOOOOOOOIIIIIIIIMMMMMMMMKKKKKKKKLLLLLLLLFFFFFFFFKKKKKKKKQQQQQQQQWWWWWW
                                                    WWUUUUUUUURRRRRRRROOOOOOOOOOOOOOOOJJJJJJJJSSSSSSSSXXXXXXXXEEEEEEEEMMMMMMMMUUUUUUUUIIIIIIIIFFFFFFFFEEEEEEEEJJJJJJJJSSSSSSSSHHHHHHHHUUUUUUUUKKKKKKKK
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15624484" author="eshcar" created="Tue, 1 Nov 2016 06:02:31 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But in the code there are these methods&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; TestOptions calculateRowsAndSize(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; TestOptions opts) {
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; rowsPerGB = getRowsPerGB(opts);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (opts.size != DEFAULT_OPTS.size) {
      &lt;span class=&quot;code-comment&quot;&gt;// total size in GB specified
&lt;/span&gt;      opts.totalRows = (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) opts.size * rowsPerGB;
      opts.perClientRunRows = opts.totalRows / opts.numClientThreads;
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      opts.totalRows = opts.perClientRunRows * opts.numClientThreads;
      opts.size = opts.totalRows / rowsPerGB;
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; opts;
  }

  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; getRowsPerGB(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; TestOptions opts) {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ONE_GB / ((opts.valueRandom? opts.valueSize/2: opts.valueSize) * opts.getColumns());
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So does this mean that with 50 threads the range is 50M rows (2nd option in calculateRowsAndSize) or some other calculation which depends on the value size * #columns&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Also, another question, in PE, when we run with &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
--columns=50 --valueSize=200
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Does this mean the value is of size 200B or each column is of size 200B and the value size is of size 50*200B&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
I thought the first option was correct but from looking at the getRowsPerGB method it seems the second one (50*200B) is the answer&lt;/p&gt;</comment>
                            <comment id="15626398" author="stack" created="Tue, 1 Nov 2016 19:16:48 +0000"  >&lt;p&gt;Smile. On the answer to the first, yeah, per client we&apos;ll do 1M rows.&lt;/p&gt;

&lt;p&gt;On second question, answer is the second option.... value is per column.&lt;/p&gt;

&lt;p&gt;See below:&lt;/p&gt;

&lt;p&gt;I ran ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation sequentialWrite 2&lt;/p&gt;


&lt;p&gt;... and when I did a count I got:&lt;/p&gt;

&lt;p&gt;....&lt;br/&gt;
Current count: 2094000, row: 00000000000000000002093999&lt;br/&gt;
Current count: 2095000, row: 00000000000000000002094999&lt;br/&gt;
Current count: 2096000, row: 00000000000000000002095999&lt;br/&gt;
Current count: 2097000, row: 00000000000000000002096999&lt;br/&gt;
2097146 row(s)&lt;br/&gt;
Took 61.3450 seconds&lt;/p&gt;


&lt;p&gt;And after dropping above table, I did this:&lt;/p&gt;

&lt;p&gt;$ ./bin/hbase pe  --rows=10 --columns=2 --valueSize=3 sequentialWrite 3&lt;/p&gt;

&lt;p&gt;... then scanning in shell:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
....
 00000000000000000000000025                                                          column=info:0, timestamp=1478027694055, value=YYY
 00000000000000000000000025                                                          column=info:1, timestamp=1478027694055, value=AAA
 00000000000000000000000026                                                          column=info:0, timestamp=1478027695245, value=XXX
 00000000000000000000000026                                                          column=info:1, timestamp=1478027695245, value=CCC
 00000000000000000000000027                                                          column=info:0, timestamp=1478027695658, value=XXX
 00000000000000000000000027                                                          column=info:1, timestamp=1478027695658, value=HHH
 00000000000000000000000028                                                          column=info:0, timestamp=1478027694647, value=KKK
 00000000000000000000000028                                                          column=info:1, timestamp=1478027694647, value=PPP
 00000000000000000000000029                                                          column=info:0, timestamp=1478027694949, value=BBB
 00000000000000000000000029                                                          column=info:1, timestamp=1478027694949, value=UUU
30 row(s)
Took 15.4920 seconds
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15626631" author="eshcar" created="Tue, 1 Nov 2016 20:47:52 +0000"  >&lt;p&gt;Some new results in the attached file - initial experiments with YCSB; still read only workload.&lt;br/&gt;
In an experiment with smaller values (1KB instead of 10KB) index-compaction performs slightly better than no compaction since flattening the index has more weight than with bigger values. As the value size reduces we expect the performance gap to increase.&lt;/p&gt;

&lt;p&gt;Next experiment round will focus on mixed workload. &lt;/p&gt;</comment>
                            <comment id="15655444" author="eshcar" created="Thu, 10 Nov 2016 22:54:01 +0000"  >&lt;p&gt;While running the benchmarks this week I realized I did a mistake when running data compaction in previous rounds. I turned off the mslab flag but did not remove the chunk pool parameters and as a result a chunk pool was allocated but not used. I re-ran these experiments this week with no mslabs and no chunk pool and indeed the performance improved. For a fair comparison I also ran no-compaction option with no mslabs and no chunk pool which turned out to be the best performing setting. (See full details in the latest report.)&lt;/p&gt;

&lt;p&gt;The focus of this week benchmarks was mixed-workload: 50% reads 50% writes. Results show that in a mixed workload running with no mslabs and no chunk pool has a significant advantage over running with chunk pool and mslabs. This is the case when running with no compaction or with data compaction.&lt;/p&gt;

&lt;p&gt;So far benchmarks do not show advantage of index-/data-compaction over no-compaction. This might be due to several reasons:&lt;br/&gt;
1. Running index-/data-compaction should reduce the amount of disk compactions - the price tag of running a disk compaction in the current system (single ssd machine) is not as high as it would be in a production cluster.&lt;br/&gt;
2. Index compaction would have greater affect as the size of the cells decreases - the values we are using now are medium size (1KB) and not small.&lt;br/&gt;
3. Index-/data-compaction should result in more reads being served from memory thereby reducing reads latency - we might be using too small a data set which is efficiently served from block cache; this is not always the case in production data sets.&lt;br/&gt;
4. Index-/data-compaction should result in more reads being served from memory thereby reducing reads latency - the current implementation of reads &lt;b&gt;always&lt;/b&gt; seeks the key in all store files that may contain it even if it resides in memory, effectively masking any memory optimization including in-memory compaction.&lt;/p&gt;

&lt;p&gt;Directions we intend to explore next:&lt;br/&gt;
1. Run benchmarks on commodity machines (namely HDD and not SSD); run cluster on more than one machine (2 RS, 3-way replication); the scale might be smaller though since our HDD machine are modest compared to the ssd machine we have.&lt;br/&gt;
2. Run with smaller values - 100B instead of 1KB&lt;br/&gt;
3. Run bigger data sets - 10-20M keys instead of 5M keys&lt;br/&gt;
4. Change read (get) implementation to first seek for the key in memstore(s) only, and only if no matching entry is found seek in all memstore segments and all relevant store files. This could be a subject of another Jira. We believe this would be beneficial also with no compaction, and even more when index-/data-compaction is employed. Any thought on this direction&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Finally a small note: a small bug was found which does not allow index-compaction to run without mslabs. This bug is about to be fixed in a new patch Anastasia is working on.&lt;/p&gt;
</comment>
                            <comment id="15656146" author="ram_krish" created="Fri, 11 Nov 2016 04:59:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;I also ran no-compaction option with no mslabs and no chunk pool which turned out to be the best performing setting. (See full details in the latest report.)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can you tell more on this. We recently found that in the default memstore case - enabling mslab and chunkpool had gains in terms of PE&apos;s latency and GC. &lt;/p&gt;</comment>
                            <comment id="15656167" author="ram_krish" created="Fri, 11 Nov 2016 05:13:08 +0000"  >&lt;p&gt;In the figure that represent Write only work load , you see more GC when there is MSLAB (with no compaction)? &lt;br/&gt;
How many region in your PE tool and YCSB?  You have only 16G memory and 0.42 of it is 6.72 G for blocking memstore. So number of regions may be important here to check other wise you can easily overload a region with lot of blocking updates. Just saying.&lt;/p&gt;</comment>
                            <comment id="15656173" author="anoop.hbase" created="Fri, 11 Nov 2016 05:16:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;I did a mistake when running data compaction in previous rounds. I turned off the mslab flag but did not remove the chunk pool parameters and as a result a chunk pool was allocated but not used.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is not fully ur mistake.  When MSLAB is turned off by config, even if there are pool related configs present, we should not init the pool. This will never get used any way.  This is the way it worked. Only in trunk this behave change happened. My bad. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16407&quot; title=&quot;Handle MemstoreChunkPool size when HeapMemoryManager tunes memory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16407&quot;&gt;&lt;del&gt;HBASE-16407&lt;/del&gt;&lt;/a&gt; is the culprit.  Raised &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17071&quot; title=&quot;Do not initialize MemstoreChunkPool when use mslab option is turned off&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17071&quot;&gt;&lt;del&gt;HBASE-17071&lt;/del&gt;&lt;/a&gt; to correct it in trunk.  Thanks for the nice find.&lt;/p&gt;</comment>
                            <comment id="15656597" author="eshcar" created="Fri, 11 Nov 2016 09:19:05 +0000"  >&lt;p&gt;Number of regions in all experiments is 50.&lt;br/&gt;
Figure 3 compares default memstore with mslabs (blue column) and without mslabs (purple column) in a PE run with write only workload uniform distribution. Here are the absolute numbers:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; write latencies &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MB/s&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;50th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;75th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;95th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;99th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;99.9th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;99.99th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;99.999th&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;no compaction&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;207.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	57.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	60.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	80.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	9608&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	55362&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	162462.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	816825&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;no compaction (no mslab)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;207.88&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	57.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	59.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	85.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	9496&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	55521&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	167699.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	933907&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Figure 6 compares default memstore with mslabs (blue column) and without mslabs (purple column) in a YCSB run with mixed workload zipfian distribution. Here are the absolute numbers:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; read latencies&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;	op/s&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;	#gc&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;	avg&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;	50th	&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;75th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;	95th&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;	99th&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;no compaction&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	5673&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	7693&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	3596.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	2109&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	3061.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	4303&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	5535.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;no compaction (no mslab)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	7900&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	6601&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	2586&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	2137&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	3027.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	4163&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;	5211.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I can re-run the benchmarks if you believe this is in contradiction with your previous findings. But the HW is different and might affect the results. &lt;/p&gt;</comment>
                            <comment id="15656617" author="ram_krish" created="Fri, 11 Nov 2016 09:28:58 +0000"  >&lt;p&gt;Can you try with Xmx=30G?&lt;/p&gt;</comment>
                            <comment id="15656626" author="ram_krish" created="Fri, 11 Nov 2016 09:33:50 +0000"  >&lt;p&gt;And one thing to say is that I have not tried read-write workload. But with 16G and with MSLAB and chunkpool on - may be we have heap reserved for it and the remaining block cache - is it sufficient ? Its good to check it out. Wil give it a try.&lt;/p&gt;</comment>
                            <comment id="15659859" author="ebortnik" created="Sat, 12 Nov 2016 15:57:40 +0000"  >&lt;p&gt;Just emphasizing the #4 point raised by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;, it looks pretty important. Does anyone see a problem with the &quot;try-to-read-from-the-memstore-first&quot; approach for scans? It seems to be pretty important for in-memory compaction. Please speak up (smile). &lt;/p&gt;</comment>
                            <comment id="15660109" author="anastas" created="Sat, 12 Nov 2016 19:08:31 +0000"  >&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;I just want you to pay attention that I have opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17081&quot; title=&quot;Flush the entire CompactingMemStore content to disk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17081&quot;&gt;HBASE-17081&lt;/a&gt; and there we want to add the ability to flush the entire content of the CompactingMemStore to disk (the active end the entire compacting pipeline). &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;, you have actually raised the preferability of this over the merge. The code will follow very soon.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Anastasia&lt;/p&gt;
</comment>
                            <comment id="15661784" author="anoop.hbase" created="Sun, 13 Nov 2016 17:07:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;4. Change read (get) implementation to first seek for the key in memstore(s) only, and only if no matching entry is found seek in all memstore segments and all relevant store files. This could be a subject of another Jira. We believe this would be beneficial also with no compaction, and even more when index-/data-compaction is employed. Any thought on this direction&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There are few issues for this. When we do a get for a row, memstore+HFiles read happens per cf wise. But how we can know all possible qualifiers in that. My Q is when we able to find an entry for the rk in memstore, how we can be sure that there are no other entries for this rk in HFiles? So suppose there are qualifiers also mentioned in the Get, (Get#addColumn(byte [] family, byte [] qualifier)) then also even if we read all qualifiers from memstore itself, how we know there are no other versions of this in other HFiles. U can see there is an InternalScan extension for Scan where one can say use memstore only or not.  But am getting what u r saying is bit diff.   So this can be done with certain hard limitations. Only version should be present and/or ts on puts are always increasing. Gets are issues with columns and/or while doing writes all columns of a CF are put together.  Just noting down whatever comes at first thought.&lt;/p&gt;</comment>
                            <comment id="15661998" author="ebortnik" created="Sun, 13 Nov 2016 19:56:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, we certainly appreciate the input, feel free to fire the first thoughts going fwd (smile). Yes, we thought about the multi-cf case. We are speaking of single-row get only. The idea was trying to fetch from the set of the memstore scanners first. If the data can be retrieved, no need to go look in HFiles - isn&apos;t it? Am I missing something here? &lt;/p&gt;</comment>
                            <comment id="15662097" author="eshcar" created="Sun, 13 Nov 2016 21:07:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;then also even if we read all qualifiers from memstore itself, how we know there are no other versions of this in other HFiles.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think I understand. So it is not enough just to check after the first (memstores scan) round that the result is not empty &amp;#8211; we need to go on and check that we retrieved data for all qualifiers in the get query, and if not do the second round which seeks the other Hfile. any problem with this?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;U can see there is an InternalScan extension for Scan where one can say use memstore only or not.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am not familiar with this internal scanner. Where/when is it being used? &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So this can be done with certain hard limitations. Only version should be present and/or ts on puts are always increasing.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, if the application manipulates ts so that it is not always increasing you have a point. Is there a way to know this for sure? I don&apos;t think so.&lt;/p&gt;

&lt;p&gt;Bottom line, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; you raise some valid concerns. So it might be that we cannot apply this optimization for all cases, however I am confident that 99.99% of the application can benefit from such optimization, it is highly unreasonable not to apply it just to allow corner cases like manipulating timestamps.&lt;br/&gt;
Could we have the application &quot;announce&quot; that it is manipulating ts so then we avoid this optimization but apply it in all other common cases &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15662618" author="anoop.hbase" created="Mon, 14 Nov 2016 03:09:57 +0000"  >&lt;p&gt;It is not just TS being applied by client issue.  (Yes that is also one and when we are sure that all TS applied by server only and it is strictly increasing some other optimizations also possible.  There is some jira around that. Forgot id. But LarsH raised that)&lt;br/&gt;
The main thing is that when we do a row get, how u will know that u have done with all the columns in that row? HBase being a CF oriented NoSQL, we don&apos;t know the columns within a CF and it can differ from row to row.  But when we know the column qualifiers always and specify in Get, and we look for only one version and we are sure abt the TS increasing nature, ya the optimization is possible. The ColumnTracker always track and allow only the given columns in Get are being selected.  And the other 2 also stands, then we can do this optimization I believe..  I did not do any code read or deep analysis..    I get ur point also.. In usecase like u described, it is some thing to really think abt&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
 * Special scanner, currently used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; increment operations to
 * allow additional server-side arguments &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Scan operations.
 * &amp;lt;p&amp;gt;
 * Rather than adding &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; options/parameters to the &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Scan API, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;
 * class has been created.
 * &amp;lt;p&amp;gt;
 * Supports adding an option to only read from the MemStore with
 * {@link #checkOnlyMemStore()} or to only read from StoreFiles with
 * {@link #checkOnlyStoreFiles()}.
 */
@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.COPROC)
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class InternalScan &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Scan {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is not public client side exposed.  Only can be used within CPs.  JFYI&lt;/p&gt;</comment>
                            <comment id="15662731" author="ram_krish" created="Mon, 14 Nov 2016 04:32:44 +0000"  >&lt;p&gt;ACtually we had a discussion around this. But as Anoop said we cannot go with first memstore and then HFiles as per the reasons stated above. &lt;br/&gt;
For a given row - if there are 100 qualifiers (single CF), you could add them in 100 different puts one by one. &lt;br/&gt;
So in this case when we say get that row - we are not sure if by this time if any flush had happened moving some of the qualifiers to the file. &lt;br/&gt;
The InternalScan is not exposed but if you want a behaviour where you are sure that you do frequent updates and fetch only the recent one (the catch is that if the recent is not in memstore - you won&apos;t get any result) then we may have to expose readOnlyMemstore type of API in scan. But am not sure how beneficial it i will be where there are more chances for missing results.&lt;/p&gt;</comment>
                            <comment id="15662732" author="ram_krish" created="Mon, 14 Nov 2016 04:33:38 +0000"  >&lt;p&gt;Is this JIRA due to this&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This bug is about to be fixed in a new patch Anastasia is working on.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="15663137" author="anastas" created="Mon, 14 Nov 2016 08:27:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;, this fix is also included there.&lt;/p&gt;</comment>
                            <comment id="15691259" author="eshcar" created="Wed, 23 Nov 2016 20:11:16 +0000"  >&lt;p&gt;Evaluation results of benchmarks on a 3 machine cluster are attached. Main points:&lt;br/&gt;
(1) in write-only workload ic2 and dc outperform no compaction (with no mslabs) by 25%. This can be attributed in part to running less GC and in part to executing less IO.&lt;br/&gt;
dc improves write amplification by 25%. &lt;br/&gt;
(2) in mixed workload All three options with no mslabs (no compaction, ic2, and dc) have comparable read latency and throughput. Avg read latency of no compaction with mslabs is 2.5x than the other options running with no mslabs. (one run in this setting even failed to complete).&lt;/p&gt;</comment>
                            <comment id="15692240" author="ram_krish" created="Thu, 24 Nov 2016 05:23:54 +0000"  >&lt;p&gt;Am more interested in that fig 8. Why do you think with MSLAB and chunk we get a much poor latency and through put? WE only have 5% reads.&lt;/p&gt;</comment>
                            <comment id="15692359" author="eshcar" created="Thu, 24 Nov 2016 06:31:54 +0000"  >&lt;p&gt;My explanation is that with 100% writes the block cache is empty and does not take any memory from the heap.&lt;br/&gt;
Whereas when there is even just 5% reads (will be the same for even less) the block cache is full taking 40% (!!!) of the heap space (or 38% to be precise in our settings). Only 62% of the heap space are left to be used by memstore, chunk pool, compactions (both from disk and memory) and also the GC which is know to take a lot of space (g1gc).&lt;br/&gt;
So at some point there is just not enough space for all these to work well, or even to work at all.&lt;/p&gt;</comment>
                            <comment id="15692398" author="ram_krish" created="Thu, 24 Nov 2016 06:50:50 +0000"  >&lt;p&gt;I agree. So this again takes back to the point that if we have L2 cache offheap then we will be benefited with MSLAB and chunkpool. Just saying.&lt;/p&gt;</comment>
                            <comment id="15692572" author="anoop.hbase" created="Thu, 24 Nov 2016 08:00:04 +0000"  >&lt;p&gt;Make sense.. Agree to points raised by Eshcar and Ram.&lt;br/&gt;
40% default size for both memstore and block cache seems not a good choice.  We should change this specially after G1GC. This makes the working memory size to be so high. The IHOP is very imp for G1GC to get a more predictable GC pause. This defaults to 45% only.&lt;br/&gt;
May be if you tune the memstore and block cache size and IHOP accordingly, you might see better results.&lt;br/&gt;
And best solution what we propose would be as Ram said. Use L2 off heap BC. The latest results shared by Alibaba , after backporting &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11425&quot; title=&quot;Cell/DBB end-to-end on the read-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11425&quot;&gt;&lt;del&gt;HBASE-11425&lt;/del&gt;&lt;/a&gt; work , reveal that we will do better with new off heap L2 cache compared to L1 cache (on heap)&lt;/p&gt;</comment>
                            <comment id="15692575" author="anoop.hbase" created="Thu, 24 Nov 2016 08:01:24 +0000"  >&lt;p&gt;Any chance for doing such a test?  We can help with config tuning &lt;/p&gt;</comment>
                            <comment id="15692764" author="eshcar" created="Thu, 24 Nov 2016 09:32:19 +0000"  >&lt;p&gt;Sorry, lost you with the acronyms ... what&apos;s IHOP?&lt;br/&gt;
What configuration do you suggest to test exactly?&lt;/p&gt;

&lt;p&gt;Also wanted to re-consider again some other settings:&lt;br/&gt;
(1) WAL - is there a reason not to run with WAL? Obviously it is easier to saturate the servers with no WAL, but this is not realistic, as almost 100% of the application use WAL, and as we&apos;ve seen different setting result in different results - lets make sure there are no surprises there.&lt;br/&gt;
(2) #flush threads (2-&amp;gt;10), #store files before blocking writes (10-&amp;gt;25) - why not use the default values? if most application use the default then we need to test with this value, and if these values are the recommended ones then why not change the default?&lt;br/&gt;
(3) memstore and blockcahce - why not just use the defaults 40%, 40%?&lt;/p&gt;</comment>
                            <comment id="15692791" author="anoop.hbase" created="Thu, 24 Nov 2016 09:40:35 +0000"  >&lt;p&gt;G1GC  - Initial Heap Occupancy percentage&lt;/p&gt;</comment>
                            <comment id="15692806" author="anoop.hbase" created="Thu, 24 Nov 2016 09:47:00 +0000"  >&lt;p&gt;1.  Ya pls turn ON wal. The configs that was put before were copied from the off heap write tests.  We had some issues to solve there to use default WAL along with offheap cells.. That is why turned OFF then. Now even our tests use WAL write.  Sorry for the mistake&lt;br/&gt;
2. Again some what related to WAL off.. The speed with which the writes were happening was more. So 2 threads are not enough for flush. Ya when the #flushThreads and/or #compactionThreads are more, the IO pressure will be more and the garbage creation rate also.. We will suffer with more GCs then.. Suggestion would be turn ON WAL and play with diff #threads and see how it is..  Blocking store files changes was also in similar lines.&lt;br/&gt;
3. We use G1GC in tests. And workload is RW. Means the heap memory of RS will be always above 80%.  This will make more GCs to happen. The initial heap occupancy factor what u have is 45% I guess.. 80% is too high.  So my suggestion was that HBase should think of making it down now. Or else we have to say when using G1GC how to tune IHOP. A large value for it dilutes the need of G1 itself. ie. predictable GC pause..&lt;br/&gt;
cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15692865" author="ram_krish" created="Thu, 24 Nov 2016 10:12:24 +0000"  >&lt;p&gt;In my opinion #2 has an impact due to xmx also. If you have 30G then you could actually have a better GC pattern with more threads and more flushes and GCs. With 16G your heap is overloaded when you have flushes/compactions happening frequently as a major garbage generator are from those two operations.&lt;/p&gt;</comment>
                            <comment id="15722264" author="eshcar" created="Mon, 5 Dec 2016 13:30:32 +0000"  >&lt;p&gt;Attached new benchmarks results.&lt;br/&gt;
This time we focus on running experiments with no chunk pool and no mslabs. We compare the three policies discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16851&quot; title=&quot;User-facing documentation for the In-Memory Compaction feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16851&quot;&gt;HBASE-16851&lt;/a&gt;: &lt;b&gt;none&lt;/b&gt; no compaction, &lt;b&gt;basic&lt;/b&gt; flattening index, merge only upon flush to disk (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17081&quot; title=&quot;Flush the entire CompactingMemStore content to disk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17081&quot;&gt;HBASE-17081&lt;/a&gt;), and &lt;b&gt;eager&lt;/b&gt; data compaction.&lt;br/&gt;
You may review the results of cluster benchmarks again as they include experiments with the new &lt;b&gt;basic&lt;/b&gt; policy (Anastasia&apos;s code).&lt;/p&gt;

&lt;p&gt;In write-only workload eager improves write amplification by 21%, while basic improves it by 15%; Basic and eager outperform no compaction by 15% and 25%, resp. &lt;br/&gt;
In read-write workload we show reduction in number of cache accesses and cache misses by basic and eager w.r.t no compaction. We show modest improvement in average read latency of basic and eager over none. With slower disks (HDD) reduction in cache misses will have more positive affect on avg and read tail latencies.&lt;/p&gt;

&lt;p&gt;We experimented with read operation optimization that speculatively scans memory-only components first and only if the result is incomplete scans both memory and disk.  We ran the mixed workload experiment for none, basic and eager with and without the optimization. &lt;br/&gt;
The optimization improves avg read latency of none and basic by 10% and avg read latency of eager by 7%. Reduction in cache accesses (70% less accesses), and cache misses (40%-45% less misses) lead to this improvement. &lt;/p&gt;

&lt;p&gt;Finally we ran write-scan workload with size of scan is chosen uniformly from 1-5000. Scan performance of all three policies are comparable with a modest improvement of basic and eager over none (5%-7%).&lt;/p&gt;



</comment>
                            <comment id="15724760" author="anoop.hbase" created="Tue, 6 Dec 2016 08:08:39 +0000"  >&lt;p&gt;Thanks for the great work..  You tried diff cases and captured all results nicely.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This might be since now the block cache is used in full capacity, leaving the gc to struggle with less free space. The chunk pool uses more space than the application can afford.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Your guess should be absolutely correct.  The inital heap occupancy percent for G1GC is configured?  Default is 45%. In write only test of ours, we put 42% for global memstore size with this factor in mind.. Now in ur tests 80% is what BC + memstore %.  In some other place also I have commented, we must revist the default for BC and memstore size considering G1GC. The working set size to be at least 80% is too much for G1GC. Against its spirit of predictable GC pause&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;and batching writes at the client side in buffer of size 10KB (vs no WAL and a buffer of size 12MB in previous experiments)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Why the batching size at client is reduced?  10 KB?  That is too too small no?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;none&#8203; no compaction,&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Here none case means what?&lt;br/&gt;
flattening index when #segments in pipeline is &amp;gt;2?&lt;/p&gt;

&lt;p&gt;So it clearly says the 1st memstore and then HFiles optimization is helping..  So you will raise it and provide ur internal patches there for initial ref?&lt;/p&gt;</comment>
                            <comment id="15724769" author="anoop.hbase" created="Tue, 6 Dec 2016 08:10:38 +0000"  >&lt;p&gt;I think there is some directly change needed now.. As per ur doc, the latest tests are with no MSLAB itself..  2.0 now defaults to even having MSLAB pool on.  As u also doubted, the G1GC initial heap occupancy factor and the BC + memstore size are the issues.   We should set IHOP say 50% and then make sure BC + memstore size is under this.  &lt;/p&gt;</comment>
                            <comment id="15724919" author="eshcar" created="Tue, 6 Dec 2016 09:28:57 +0000"  >&lt;p&gt;Thanks for the comments &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The scope of the current Jira is to explore performance of different in-memory compaction policies, and therefore all other parameters are used with their default/recommended values. &lt;br/&gt;
Finding the sweat spot for mslab and chunk pool usage vs the size allocated for memstore and BC vs the parameters for the GC should be explored in a different Jira; there are too many parameters to optimize in a single round and finding the global maximum in terms of performance (total throughput, read and write latency, etc.) may require multiple experiments.&lt;br/&gt;
IMHO, these must be explored before setting chunk pool to on by default in 2.0. Changing some parameters without re-tuning other parameters can cause major degradation in performance. But it is not the ticket of the current Jira. &lt;/p&gt;

&lt;p&gt;In my experiments IHOP is set to 60%. I can change it to 45% or 50% for future experiments but I don&apos;t think it will make much difference.&lt;/p&gt;

&lt;p&gt;The policy that is named none refers to using default memstore, no compaction whatsoever.&lt;/p&gt;

&lt;p&gt;Batching size at client side: some applications don&apos;t use any batching. Optimally to have a clean measure of the write latency the experiments should use zero batching, but this would make the experiment infinitely long. In striking the balance between valid measurements and reasonable run time having buffer of size 10KB (which is approximately 100 put operations) was the optimal point for me.&lt;/p&gt;

&lt;p&gt;Scan memstore-only first optimization: this is not a correct solution yet since it does not handle all the issues that you raised regarding TS etc. It is only for demonstrating potential gain of the optimization. I can publish the patch in a different Jira after we clean up some open Jira&apos;s we have here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;
</comment>
                            <comment id="15725126" author="ram_krish" created="Tue, 6 Dec 2016 10:42:16 +0000"  >&lt;p&gt;Thanks for the details report. Its great and well written.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;IMHO, these must be explored before setting chunk pool to on by default in 2.0. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So do you advocate reverting this change for now?&lt;br/&gt;
Interesting fact is that in eager compaction (that is data compaction) you seem to perform better  in 3 node cluster and not so well in single node cluster. Why do you think that is happening?&lt;br/&gt;
My main question is that in these results are you generating lot of duplicatest such that eager compaction is reducing the duplicates? If there are not much duplicates then the amount of flushes/compaction should be same right? &lt;/p&gt;</comment>
                            <comment id="15725746" author="eshcar" created="Tue, 6 Dec 2016 15:06:36 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;AFAIK 2.0 is not released yet.&lt;br/&gt;
I advocate to experiment with the final default configuration before releasing it, and comparing it to the previous default configuration &amp;#8211; make sure performance remains the same or improves in &lt;b&gt;all&lt;/b&gt; common workloads, including mixed workload.&lt;br/&gt;
If what is planned for 2.0 is 40% memstore, 40% BC, chunk pool on by default, and we assume G1GC will be used by many application, then yes definitely I advocate to revert. &lt;/p&gt;

&lt;p&gt;When running 3 node cluster the system pays much more for each compaction, since now network is also involved in writing new files. Having less compactions/writing less MB to HDFS with eager (and also with basic) means avoiding part of this cost. This is emphasized with SSDs, since just writing data to disk doesn&apos;t cost much. But once you also need to pay for network traffic the advantage is more pronounced.&lt;/p&gt;

&lt;p&gt;We are running zipfian distribution by YCSB. This is pretty much standard distribution for KV-stores benchmarks, which generates duplication. &lt;br/&gt;
We do plan to play a bit with the alpha parameter to check performance under less/more heavy-head distributions. A workload that accesses 10-20% of the keys 80-90% of the time is considered valid.&lt;br/&gt;
The amount of flushes depends on duplication ratio, and also on what the policy decides to flush. Currently basic flushes the entire pipeline, eager only flushes the tail. Other policies might decide differently. &lt;/p&gt;</comment>
                            <comment id="15725961" author="anoop.hbase" created="Tue, 6 Dec 2016 16:26:23 +0000"  >&lt;p&gt;Why I mentioned abt correcting the GC config and HBase config is that ur tests on data compaction was not using MSLAB where as others. (The initial compares)..  So the GC is paying the cost and it might be giving a false indication that data compaction is better.  Ya data compaction might be better depending on the key generation. More and more duplicated keys (rk+cf+q+ts+type) means in memory compaction can get rid of many (def table versions = 1)..   But I dont think by def we should enable this.&lt;br/&gt;
Yes we need to consider that more users will go to G1GC.  So as per ur tests u say disable memstore chunk pool by default but enable MSLAB is ok?  This was/is on by def from long time.&lt;br/&gt;
I strongly feel we should revisit our BC and memstore % def values.  Specially to conisder that we will ON L2 off heap now. The data blocks will go to L2.  L1 might have only index blocks.. So we dont need much size there.  Even pls note that off heap backed MSLAB pool is all ready in trunk..   We will do tests similar to urs by working with off heap.&lt;/p&gt;</comment>
                            <comment id="15728092" author="eshcar" created="Wed, 7 Dec 2016 08:17:37 +0000"  >&lt;p&gt;I am not suggesting to set eager as default.&lt;br/&gt;
We can have basic as default and if users want they can set eager on a per CF basis. Eager can be recommended to CF that have high churn, or that have a small working set at any point in time like our original sliding window scenario. For example, we can recommend all applications that used to set a CF to be IN_MEMORY to try and set it to eager. &lt;/p&gt;

&lt;p&gt;With respect to chunks, in my experiments running with MSLABS even with no chunk pool showed inferior results, however I didn&apos;t go much deeper with these parameters and didn&apos;t do full exhaustive tests. &lt;br/&gt;
I think that you guys are much more familiar with all the details regarding L2 and off-heaping and which parameters can be played with and tuned, so it would be a good idea that you will run these tests.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12836437" name="HBASE-16417-benchmarkresults-20161101.pdf" size="620904" author="eshcar" created="Tue, 1 Nov 2016 20:39:20 +0000"/>
                            <attachment id="12838451" name="HBASE-16417-benchmarkresults-20161110.pdf" size="891189" author="eshcar" created="Thu, 10 Nov 2016 22:44:21 +0000"/>
                            <attachment id="12840310" name="HBASE-16417-benchmarkresults-20161123.pdf" size="1341124" author="eshcar" created="Wed, 23 Nov 2016 20:05:46 +0000"/>
                            <attachment id="12841746" name="HBASE-16417-benchmarkresults-20161205.pdf" size="1354493" author="eshcar" created="Mon, 5 Dec 2016 13:11:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 18 Aug 2016 09:04:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 week, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32bbj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>