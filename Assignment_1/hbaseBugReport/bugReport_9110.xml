<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:01:28 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9110/HBASE-9110.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9110] Meta region edits not recovered while migrating to 0.96.0</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9110</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I was doing the migration testing from 0.94.11-snapshot to 0.95.0, and faced this issue.&lt;/p&gt;

&lt;p&gt;1) Do some edits in meta table (for eg, create a table).&lt;/p&gt;

&lt;p&gt;2) Kill the cluster.&lt;br/&gt;
(I used kill because we would be doing log splitting when upgrading anyway).&lt;/p&gt;

&lt;p&gt;3) There is some dependency on WALs. Upgrade the bits to 0.95.2-snapshot. Start the cluster.&lt;br/&gt;
Every thing comes up. I see log splitting happening as expected. But, the WAL-data for meta table is missing.&lt;/p&gt;

&lt;p&gt;I could see recovered.edits file for meta created, and placed at the right location. It is just that the new HMaster code tries to recover meta by looking at meta prefix in the log name, and if it didn&apos;t find one, just opens the meta region. So, the recovered.edits file, created afterwards, is not honored.&lt;/p&gt;

&lt;p&gt;Opening this jira to let folks give their opinions about how to tackle this migration issue.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12661156">HBASE-9110</key>
            <summary>Meta region edits not recovered while migrating to 0.96.0</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12642630">HBASE-8348</parent>
                                    <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="v.himanshu">Himanshu Vashishtha</assignee>
                                    <reporter username="v.himanshu">Himanshu Vashishtha</reporter>
                        <labels>
                    </labels>
                <created>Thu, 1 Aug 2013 16:05:46 +0000</created>
                <updated>Fri, 20 Nov 2015 11:54:15 +0000</updated>
                            <resolved>Thu, 29 Aug 2013 04:43:39 +0000</resolved>
                                    <version>0.95.2</version>
                    <version>0.94.10</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.96.0</fixVersion>
                                    <component>migration</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="13726592" author="yuzhihong@gmail.com" created="Thu, 1 Aug 2013 16:41:44 +0000"  >&lt;p&gt;Can you tell me the value for configuration hbase.regionserver.separate.hlog.for.meta ?&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8081&quot; title=&quot;Backport HBASE-7213 (separate hlog for meta tables) to 0.94&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8081&quot;&gt;&lt;del&gt;HBASE-8081&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13726599" author="v.himanshu" created="Thu, 1 Aug 2013 16:50:42 +0000"  >&lt;p&gt;Yes, thanks for reminding Ted. &lt;br/&gt;
I was using the default option for separate meta log property, i.e., it was OFF.&lt;/p&gt;</comment>
                            <comment id="13726696" author="devaraj" created="Thu, 1 Aug 2013 18:19:00 +0000"  >&lt;p&gt;Hmm.. so maybe for the migration, we should have the cluster enter into a quiet period, and flush the meta just before the cluster shutdown.&lt;/p&gt;</comment>
                            <comment id="13750782" author="v.himanshu" created="Tue, 27 Aug 2013 00:07:41 +0000"  >&lt;p&gt;It looks like hbck can help us in situation where meta is not flushed.&lt;br/&gt;
On a 0.94.x cluster, I tried migration with some unflushed meta edits (basically, create table waledits). I killed the meta server before upgrade. &lt;br/&gt;
The edits were not there in meta immediately after migration, but appears correctly after running &quot;bin/hbase hbck -fixAssignments, -fixMeta&quot;.&lt;/p&gt;

&lt;p&gt;It definitely needs some more testing.&lt;/p&gt;</comment>
                            <comment id="13750926" author="stack" created="Tue, 27 Aug 2013 03:29:58 +0000"  >&lt;p&gt;Good &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; So what you think receipe is?  Flush server w/ .META. before shutting down?  How we going to know we need the hbck trick?&lt;/p&gt;</comment>
                            <comment id="13751828" author="v.himanshu" created="Tue, 27 Aug 2013 22:45:00 +0000"  >&lt;p&gt;Yeah, hbck thing is a bit hacky (when to run, when not to)&lt;/p&gt;

&lt;p&gt;So, the root cause was .META. (i.e., hbase:meta) was opening up earlier than splitting to happen. Attached patch ensures that we hold on opening any region unless all the log-split is done. This will happen only when starting first time post-upgrade, and makes sure that we are honoring all the previous edits. &lt;br/&gt;
I tested it with creating tables, inserting data into a 0.94.x cluster and post migration, data was intact.&lt;/p&gt;

&lt;p&gt;Re: comment on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9278&quot; title=&quot;Reading Pre-namespace meta table edits kills the reader&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9278&quot;&gt;&lt;del&gt;HBASE-9278&lt;/del&gt;&lt;/a&gt; what happens if we are migrating from 0.94 with separate meta log enabled.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;If it is a 0.94 install w/ the special meta WAL, the .META. -&amp;gt; hbase:meta fix will work for this case too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I checked (and tested) the separate .META. wal in 0.94. If we migrate from a 0.94.x (with separate meta WAL), then the .meta wals are not splitted AT ALL while assigning meta, and they are ignored by the subsequent log splitting process. &lt;br/&gt;
It is because in 0.96, HMaster checks meta server znode (which doesn&apos;t point to any regionserver). If there is no entry in that znode, it assigns meta region without doing any splitting (it doesn&apos;t know which server had meta earlier).&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!rit &amp;amp;&amp;amp; !metaRegionLocation) {
      ServerName currentMetaServer = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.catalogTracker.getMetaLocation();
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (currentMetaServer != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        beingExpired = expireIfOnline(currentMetaServer);
      }
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (beingExpired) {
        splitMetaLogBeforeAssignment(currentMetaServer);
      }
      assignmentManager.assignMeta();
      &lt;span class=&quot;code-comment&quot;&gt;// Make sure a .META. location is set.
&lt;/span&gt;      enableSSHandWaitForMeta();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I tested the above patch with separate meta wal property OFF. It needs some modifications to handle that feature, but would be good to know what you think about it. Thanks.&lt;/p&gt;</comment>
                            <comment id="13751873" author="devaraj" created="Tue, 27 Aug 2013 23:24:31 +0000"  >&lt;p&gt;Nice digging, Himanshu! Not very sure but wouldn&apos;t we run into the same problem if we stop the cluster, delete ZK data and then start the cluster again?&lt;/p&gt;</comment>
                            <comment id="13751887" author="v.himanshu" created="Tue, 27 Aug 2013 23:32:41 +0000"  >&lt;p&gt;Yes, you would have the same problem. Separate meta wal feature (though very useful for MTTR) introduces a tight dependency on zk data I&apos;d say. If we delete zk data (meta server znode), then we no longer split meta logs before assigning.&lt;/p&gt;

&lt;p&gt;Do you have some use case to delete zk data (apart from 0.96 upgrade)?&lt;br/&gt;
If so, I think we can leverage the above patch: create the upgradeInprogress znode so that master splits all the logs before opening regions.&lt;/p&gt;</comment>
                            <comment id="13751964" author="stack" created="Wed, 28 Aug 2013 00:39:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; WHy not run log splitting as part of migration?  Add a new step?&lt;/p&gt;</comment>
                            <comment id="13751965" author="devaraj" created="Wed, 28 Aug 2013 00:41:20 +0000"  >&lt;p&gt;I don&apos;t have any use case where I&apos;d delete ZK data but I was just taking an example. Long term we shouldn&apos;t persist data in ZK is my thinking. &lt;br/&gt;
On the patch, I will look more closely, but why can&apos;t we blindly try to split meta-logs if the meta-location can&apos;t be found in ZK?&lt;/p&gt;</comment>
                            <comment id="13751967" author="stack" created="Wed, 28 Aug 2013 00:45:17 +0000"  >&lt;p&gt;I took a look at patch &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt;  Not bad but rather than intro new state up in zk, would suggest we just run the split logs as new upgrade step after ns migration?&lt;/p&gt;</comment>
                            <comment id="13752103" author="v.himanshu" created="Wed, 28 Aug 2013 05:02:49 +0000"  >&lt;p&gt;Stack, &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;WHy not run log splitting as part of migration? Add a new step?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Hmmm, but the namespace upgrade is done on an offline cluster. With the current approach, it is akin to adding a step in migration as when master is coming up first time after post upgrade, it does the splitting. Or, do you mean some kind of offline splitting for the current logs? The main advantage of this approach is to fully re-use the existing log splitting mechanism, and we wouldn&apos;t enforce a clean cluster shutdown as a prerequisite to upgrade.&lt;/p&gt;

&lt;p&gt;Deveraj,&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;why can&apos;t we blindly try to split meta-logs if the meta-location can&apos;t be found in ZK?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You mean for &quot;all&quot; the dead regionservers (obtained from getPreviouselyFailedMetaServersFromZK()), right? Otherwise, how will you know which server had meta logs?&lt;br/&gt;
So, split meta-logs for all regionservers when meta-location couldn&apos;t be found. That sounds right, but it will not cover migration from 0.94 (with no separate meta logs). Otherwise, I buy that idea for normal case (infact, had similar thoughts after uploading this patch).&lt;/p&gt;</comment>
                            <comment id="13752118" author="stack" created="Wed, 28 Aug 2013 05:24:00 +0000"  >&lt;p&gt;Yes, run log splitting on an offline cluster.&lt;/p&gt;

&lt;p&gt;If it was a clean shutdown, there would be no logs to split.&lt;/p&gt;

&lt;p&gt;If it was not  clean shutdown, the cluster cannot come up till after logs have split anyways &amp;#8211; and do it as part of migration, there&apos;d be no messing w/ figuring has meta been deployed or not.&lt;/p&gt;
</comment>
                            <comment id="13752742" author="v.himanshu" created="Wed, 28 Aug 2013 19:11:04 +0000"  >&lt;p&gt;Got it. Let&apos;s do offline log splitting then. &lt;br/&gt;
I used HLogSplitter to do offline splitting for each regionserver directory, and it basically works. &lt;br/&gt;
The changes are self contained in Upgrade script only. Will upload a patch for this. Thanks.&lt;/p&gt;</comment>
                            <comment id="13752752" author="stack" created="Wed, 28 Aug 2013 19:20:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; Thanks for testing.   I suppose we could end up splitting logs for servers that no longer exist but that is probably not the end of the world.&lt;/p&gt;</comment>
                            <comment id="13752809" author="devaraj" created="Wed, 28 Aug 2013 20:27:41 +0000"  >&lt;p&gt;Yeah +1 if this has been tested. &lt;/p&gt;</comment>
                            <comment id="13752821" author="v.himanshu" created="Wed, 28 Aug 2013 20:38:56 +0000"  >&lt;p&gt;Patch that does offline log splitting as part of the upgrade process (and doesn&apos;t add any new state in zk).&lt;br/&gt;
I tested this while migrating from a 0.94.11 cluster. I find it a bit tricky to unit test this.&lt;/p&gt;</comment>
                            <comment id="13752937" author="stack" created="Wed, 28 Aug 2013 22:10:36 +0000"  >&lt;p&gt;Looks good to me Himanshu... let me try it here.&lt;/p&gt;</comment>
                            <comment id="13752942" author="stack" created="Wed, 28 Aug 2013 22:15:32 +0000"  >&lt;p&gt;Changed my mind.  I think we should just commit this and try it as part of the 0.96.0RC0 testing.&lt;/p&gt;

&lt;p&gt;Here is some feedback on the patch.&lt;/p&gt;

&lt;p&gt;Will this work:&lt;/p&gt;

&lt;p&gt;+    executeTool(&quot;Namespace upgrade&quot;, new NamespaceUpgrade(),&lt;br/&gt;
+      new String[] &lt;/p&gt;
{ &quot;--upgrade&quot; }
&lt;p&gt;, 0);&lt;br/&gt;
+    executeTool(&quot;Znode upgrade&quot;, new ZKDataMigrator(), null, 0);&lt;br/&gt;
+    doOfflineLogSplitting();&lt;/p&gt;


&lt;p&gt;Does ns upgrade REMOVE &lt;del&gt;ROOT&lt;/del&gt;?&lt;/p&gt;

&lt;p&gt;Is this right?&lt;/p&gt;

&lt;p&gt;doOfflineLogSplitting&lt;/p&gt;

&lt;p&gt;It is looking for WALs in the &lt;del&gt;ROOT&lt;/del&gt; dir it seems?  Don&apos;t you want to OPEN the &lt;del&gt;ROOT&lt;/del&gt; region and read out of it the name of the server that was hosting .META. and split its logs?&lt;/p&gt;</comment>
                            <comment id="13752956" author="v.himanshu" created="Wed, 28 Aug 2013 22:30:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does ns upgrade REMOVE ROOT?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Don&apos;t you want to OPEN the ROOT region and read out of it the name of the server that was hosting .META. and split its logs?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Currently, it is looking at all region servers. Yes, I am making it to read root and see if it has meta table. Thanks.&lt;/p&gt;</comment>
                            <comment id="13753079" author="jeffreyz" created="Thu, 29 Aug 2013 00:14:15 +0000"  >&lt;p&gt;0.94 has strange setup. The ROOT table could also fail so it also needs recovery thought it only contains one row. Therefore, there could exist un-flushed changes in a wal file for ROOT. We have to split all wal files left before starting hbase0.96 master. &lt;/p&gt;

&lt;p&gt;If we want to go this route without requesting a clean shut down, we have to deal with ROOT table wal entry like hbase-9278(I pasted following code below as reference) I&apos;m thinking to ask a clean shut down is better because users have to stop traffic firstly because the singularity upgrade.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(name.equals(OLD_ROOT_STR)) {
      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IllegalArgumentException(OLD_ROOT_STR + &lt;span class=&quot;code-quote&quot;&gt;&quot; has been deprecated.&quot;&lt;/span&gt;);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;  </comment>
                            <comment id="13753111" author="v.himanshu" created="Thu, 29 Aug 2013 00:43:16 +0000"  >&lt;p&gt;Ah, another edge case... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;

&lt;p&gt;The intent was to handle improper shutdown scenarios (and make upgrade process faster in such cases). &lt;/p&gt;

&lt;p&gt;I agree, that we might have un-flushed ROOT edits. &lt;/p&gt;

&lt;p&gt;Hmmm, in that case we don&apos;t have much choice, but to split all regionserver logs (we could use the attached v1 patch then).&lt;/p&gt;</comment>
                            <comment id="13753289" author="stack" created="Thu, 29 Aug 2013 04:17:33 +0000"  >&lt;p&gt;So, if &lt;del&gt;ROOT&lt;/del&gt; got changed recently such that latest edit is in memory and not flushed out AND .META. has edits up in memory that are not flushed though we asked operator to flush .META. (and &lt;del&gt;ROOT&lt;/del&gt; I suppose too) before shutting down the cluster AND it is not a clean shutdown, yeah, this could be an issue.&lt;/p&gt;

&lt;p&gt;Downside of the migration running the log splitting is that (as Himanshu uncovered), it is not a distributed log split so will run slower which would only really be a problem if cluster totally crashed down (it could be hours before cluster could come back up &amp;#8211; in this case we&apos;d probably suggest restart 0.94 until get a clean or mostly clean shutdown).  Other minor downside is we might split logs for a server no longer online (this&apos;d probably be good though).&lt;/p&gt;

&lt;p&gt;What you have &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt;?  If you have the logsplitter, we could commit that for the RC?&lt;/p&gt;</comment>
                            <comment id="13753296" author="hv.csuoa@gmail.com" created="Thu, 29 Aug 2013 04:26:56 +0000"  >&lt;p&gt;Yes, the second patch i uploaded  today has the log splitter logic.&lt;br/&gt;
I think we can have it for the RC (i tested it on my local).&lt;/p&gt;

&lt;p&gt;(Sent from phone)&lt;/p&gt;
</comment>
                            <comment id="13753300" author="stack" created="Thu, 29 Aug 2013 04:43:39 +0000"  >&lt;p&gt;Lets try it.&lt;/p&gt;

&lt;p&gt;I put it into 0.95 and 0.98 (maybe it&apos;ll be possible to go from 0.92 to 0.98 &amp;#8211; lets see).&lt;/p&gt;

&lt;p&gt;Thanks Himanshu.&lt;/p&gt;

&lt;p&gt;A test would have been coolio but I suppose we&apos;ll be testing this over next few days.&lt;/p&gt;</comment>
                            <comment id="13753376" author="hudson" created="Thu, 29 Aug 2013 06:47:07 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.95 #503 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/503/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/503/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0 (stack: rev 1518468)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753382" author="hudson" created="Thu, 29 Aug 2013 06:53:11 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #4444 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4444/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4444/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0; PUT BACK (stack: rev 1518470)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0; REVERT (stack: rev 1518469)&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0 (stack: rev 1518467)&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753533" author="hudson" created="Thu, 29 Aug 2013 11:48:02 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.95-on-hadoop2 #277 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/277/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/277/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0 (stack: rev 1518468)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753593" author="hudson" created="Thu, 29 Aug 2013 13:07:44 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #701 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/701/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/701/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0; PUT BACK (stack: rev 1518470)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0; REVERT (stack: rev 1518469)&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9110&quot; title=&quot;Meta region edits not recovered while migrating to 0.96.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9110&quot;&gt;&lt;del&gt;HBASE-9110&lt;/del&gt;&lt;/a&gt; Meta region edits not recovered while migrating to 0.96.0 (stack: rev 1518467)&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15016179" author="lars_francke" created="Fri, 20 Nov 2015 11:54:15 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12642630">HBASE-8348</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12600280" name="HBase-9110-v0.patch" size="4119" author="v.himanshu" created="Tue, 27 Aug 2013 22:45:48 +0000"/>
                            <attachment id="12600454" name="HBase-9110-v1.patch" size="4791" author="v.himanshu" created="Wed, 28 Aug 2013 20:38:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 1 Aug 2013 16:41:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>341345</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1mvdz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>341663</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Adds a step to migration where we split any outstanding WAL files.  This process is not distributed so will be slower than the distributed version that runs on cluster startup so, make sure there are few WALs to split at this step by making sure the cluster shutdown is clean pre-upgrade.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>