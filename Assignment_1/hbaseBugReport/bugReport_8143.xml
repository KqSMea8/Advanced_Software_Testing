<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:52:26 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8143/HBASE-8143.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8143] HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM </title>
                <link>https://issues.apache.org/jira/browse/HBASE-8143</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We&apos;ve run into an issue with HBase 0.94 on Hadoop2, with SSR turned on that the memory usage of the HBase process grows to 7g, on an -Xmx3g, after some time, this causes OOM for the RSs. &lt;/p&gt;

&lt;p&gt;Upon further investigation, I&apos;ve found out that we end up with 200 regions, each having 3-4 store files open. Under hadoop2 SSR, BlockReaderLocal allocates DirectBuffers, which is unlike HDFS 1 where there is no direct buffer allocation. &lt;/p&gt;

&lt;p&gt;It seems that there is no guards against the memory used by local buffers in hdfs 2, and having a large number of open files causes multiple GB of memory to be consumed from the RS process. &lt;/p&gt;

&lt;p&gt;This issue is to further investigate what is going on. Whether we can limit the memory usage in HDFS, or HBase, and/or document the setup. &lt;/p&gt;

&lt;p&gt;Possible mitigation scenarios are: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Turn off SSR for Hadoop 2&lt;/li&gt;
	&lt;li&gt;Ensure that there is enough unallocated memory for the RS based on expected # of store files&lt;/li&gt;
	&lt;li&gt;Ensure that there is lower number of regions per region server (hence number of open files)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Stack trace:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: IntegrationTestLoadAndVerify,yC^P\xD7\x945\xD4,1363388517630.24655343d8d356ef708732f34cfe8946.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1560)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1439)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1380)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:449)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushOneForGlobalPressure(MemStoreFlusher.java:215)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$500(MemStoreFlusher.java:63)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:237)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:662)
Caused by: java.lang.OutOfMemoryError: Direct buffer memory
        at java.nio.Bits.reserveMemory(Bits.java:632)
        at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:97)
        at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:288)
        at org.apache.hadoop.hdfs.util.DirectBufferPool.getBuffer(DirectBufferPool.java:70)
        at org.apache.hadoop.hdfs.BlockReaderLocal.&amp;lt;init&amp;gt;(BlockReaderLocal.java:315)
        at org.apache.hadoop.hdfs.BlockReaderLocal.newBlockReader(BlockReaderLocal.java:208)
        at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:790)
        at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:888)
        at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
        at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:645)
        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:689)
        at java.io.DataInputStream.readFully(DataInputStream.java:178)
        at org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.readFromStream(FixedFileTrailer.java:312)
        at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:543)
        at org.apache.hadoop.hbase.io.hfile.HFile.createReaderWithEncoding(HFile.java:589)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.&amp;lt;init&amp;gt;(StoreFile.java:1261)
        at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:512)
        at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:603)
        at org.apache.hadoop.hbase.regionserver.Store.validateStoreFile(Store.java:1568)
        at org.apache.hadoop.hbase.regionserver.Store.commitFile(Store.java:845)
        at org.apache.hadoop.hbase.regionserver.Store.access$500(Store.java:109)
        at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.commit(Store.java:2209)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1541)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12637700">HBASE-8143</key>
            <summary>HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="enis">Enis Soztutar</reporter>
                        <labels>
                    </labels>
                <created>Tue, 19 Mar 2013 03:04:43 +0000</created>
                <updated>Mon, 16 Dec 2013 18:46:45 +0000</updated>
                            <resolved>Tue, 26 Nov 2013 21:43:39 +0000</resolved>
                                    <version>0.98.0</version>
                    <version>0.94.7</version>
                    <version>0.95.0</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.96.1</fixVersion>
                                    <component>hadoop2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>24</watches>
                                                                                                            <comments>
                            <comment id="13605986" author="yuzhihong@gmail.com" created="Tue, 19 Mar 2013 03:14:16 +0000"  >&lt;p&gt;Have you tried the following directive for JVM (actual value may be different from 256M) ?&lt;/p&gt;

&lt;p&gt;-XX:MaxDirectMemorySize=256M&lt;/p&gt;</comment>
                            <comment id="13605989" author="lhofhansl" created="Tue, 19 Mar 2013 03:24:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt; FYI.&lt;/p&gt;</comment>
                            <comment id="13605993" author="xieliang007" created="Tue, 19 Mar 2013 03:30:37 +0000"  >&lt;p&gt;I submitted a trivial patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4530&quot; title=&quot;return buffer into direct bufferPool in BlockReaderLocal as possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4530&quot;&gt;&lt;del&gt;HDFS-4530&lt;/del&gt;&lt;/a&gt;, both i and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin P. McCabe&lt;/a&gt; believed it&apos;s probably not a root cause, but it could reduce this risk, just for your refer.&lt;/p&gt;</comment>
                            <comment id="13605995" author="yuzhihong@gmail.com" created="Tue, 19 Mar 2013 03:38:15 +0000"  >&lt;p&gt;@Liang:&lt;br/&gt;
Thanks for the reference.&lt;/p&gt;

&lt;p&gt;Should &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4530&quot; title=&quot;return buffer into direct bufferPool in BlockReaderLocal as possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4530&quot;&gt;&lt;del&gt;HDFS-4530&lt;/del&gt;&lt;/a&gt; be a bug instead of improvement ?&lt;/p&gt;</comment>
                            <comment id="13606018" author="xieliang007" created="Tue, 19 Mar 2013 03:48:44 +0000"  >&lt;p&gt;to be honest, i am not sure which one is more suitable, i am not a native speaker and could not distinguish those two exactly...&lt;/p&gt;</comment>
                            <comment id="13606063" author="lhofhansl" created="Tue, 19 Mar 2013 04:51:47 +0000"  >&lt;p&gt;We keep a reader open for every store file. Looks like the default for MaxDirectMemorySize is 64MB.&lt;/p&gt;

&lt;p&gt;Bits.reserveMemory actually triggers a full GC if it cannot reserve enough bytes. While this is pretty terrible (IMHO), in this case it proves that these are not leftover buffers from previous invocations, but that they are actually being actively used.&lt;/p&gt;

&lt;p&gt;600-800 store files should put the direct memory consumption per reader at ~80-100k.&lt;/p&gt;

&lt;p&gt;In BlockReaderLocal the short circuit buffer size is configurable with &quot;dfs.client.read.shortcircuit.buffer.size&quot;. It does default to 1MB, so something does not quite add up.&lt;/p&gt;
</comment>
                            <comment id="13606086" author="xieliang007" created="Tue, 19 Mar 2013 05:38:42 +0000"  >&lt;p&gt;if you did not set MaxDirectMemorySize option explicitly, then it will be equal to -Xmx, that means -XX:MaxDirectMemorySize == -Xmx == 3g for Enis&apos;s case.&lt;/p&gt;</comment>
                            <comment id="13606109" author="enis" created="Tue, 19 Mar 2013 06:19:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;if you did not set MaxDirectMemorySize option explicitly, then it will be equal to -Xmx, that means -XX:MaxDirectMemorySize == -Xmx == 3g for Enis&apos;s case.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In this case, I was not even aware of Hdfs 2 allocating direct memory. I did not spend a lot of time on the hadoop 2 code base.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In BlockReaderLocal the short circuit buffer size is configurable with &quot;dfs.client.read.shortcircuit.buffer.size&quot;. It does default to 1MB, so something does not quite add up&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Let me check that code path to understand who is using that parameter and how. &lt;/p&gt;</comment>
                            <comment id="13607218" author="lhofhansl" created="Wed, 20 Mar 2013 03:30:59 +0000"  >&lt;p&gt;Here&apos;s the code from VM.java. (JDK7)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// A user-settable upper limit on the maximum amount of allocatable direct
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// buffer memory.  This value may be changed during VM initialization &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-quote&quot;&gt;&quot;java&quot;&lt;/span&gt; is launched with &lt;span class=&quot;code-quote&quot;&gt;&quot;-XX:MaxDirectMemorySize=&amp;lt;size&amp;gt;&quot;&lt;/span&gt;.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// The initial value of &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; field is arbitrary; during JRE initialization
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// it will be reset to the value specified on the command line, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; any,
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// otherwise to &lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.getRuntime.maxDirectMemory().
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; directMemory = 64 * 1024 * 1024;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;600-800 even 1M add up to 800MB only max.&lt;/p&gt;

&lt;p&gt;It seems to me that we should recommend a smaller buffer size. 1MB seems pretty large if many files are open.&lt;/p&gt;</comment>
                            <comment id="13607238" author="yuzhihong@gmail.com" created="Wed, 20 Mar 2013 03:40:46 +0000"  >&lt;p&gt;BlockReaderLocal always assumes bufferPool.getBuffer() returns ByteBuffer.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4530?focusedCommentId=13606775&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13606775&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-4530?focusedCommentId=13606775&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13606775&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13607260" author="xieliang007" created="Wed, 20 Mar 2013 04:14:20 +0000"  >&lt;p&gt;if buffer size goes smaller, then the FileChannel&apos;s read count will be invoked more frequently, seems just a trade-off ?&lt;/p&gt;</comment>
                            <comment id="13607273" author="xieliang007" created="Wed, 20 Mar 2013 04:34:36 +0000"  >&lt;p&gt;btw, indeed there&apos;s a comment bug in above jdk7 snippet:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
otherwise to &lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.getRuntime.maxDirectMemory().
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I just want to file an issue to OpenJDK mail list, but found it was fixed in JDK8 branch already, emmm...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.getRuntime().maxMemory()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13607297" author="lhofhansl" created="Wed, 20 Mar 2013 05:29:38 +0000"  >&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; In JDK I also only see a single spot where VM.directMemory is set, and it will only change its value if explicitly specified (either though the command line or as a system property - one can set this to -1 in order to have this equal to the heap size).&lt;/p&gt;

&lt;p&gt;I wonder what the rationale behind 1MB is on the Hadoop side. Typically I would have expected something 64k or even 8k.&lt;br/&gt;
The default bytes-per-checksum seems to be 512 bytes, so a 64k buffer it plenty.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;, is it possible to repeat your test with something as little as 4k and then with 64k to gauge the performance impact?&lt;/p&gt;</comment>
                            <comment id="13607314" author="xieliang007" created="Wed, 20 Mar 2013 05:54:36 +0000"  >&lt;p&gt;yes, you could find the following code in hotspot src(globals.hpp):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  product(intx, MaxDirectMemorySize, -1,                                    \
          &lt;span class=&quot;code-quote&quot;&gt;&quot;Maximum total size of NIO direct-buffer allocations&quot;&lt;/span&gt;) 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;then as you know, it will goto this code branch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (s.equals(&lt;span class=&quot;code-quote&quot;&gt;&quot;-1&quot;&lt;/span&gt;)) {
                &lt;span class=&quot;code-comment&quot;&gt;// -XX:MaxDirectMemorySize not given, take &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;
&lt;/span&gt;                directMemory = &lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.getRuntime().maxMemory();
            }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and maxMemory comes from jvm.cpp:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
JVM_ENTRY_NO_ENV(jlong, JVM_MaxMemory(void))
  JVMWrapper(&lt;span class=&quot;code-quote&quot;&gt;&quot;JVM_MaxMemory&quot;&lt;/span&gt;);
  size_t n = Universe::heap()-&amp;gt;max_capacity();
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; convert_size_t_to_jlong(n);
JVM_END
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and max_capacity == Xmx - one of the survivor spaces(per collectedHeap.hpp)&lt;/p&gt;

&lt;p&gt;Hope it&apos;s helpful, sorry for my poor english, seems it&apos;s a little far away with the original jira...&lt;/p&gt;</comment>
                            <comment id="13609707" author="enis" created="Thu, 21 Mar 2013 23:51:55 +0000"  >&lt;p&gt;I was able to repro this by using a very simple test. BlockReaderLocal just allocates 1M of direct buffer by default, and thus &amp;gt;3000 blocks open causes 3g mem allocation (assuming no checksum). &lt;/p&gt;

&lt;p&gt;These are the configurations. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; DFS_CLIENT_READ_SHORTCIRCUIT_KEY = &lt;span class=&quot;code-quote&quot;&gt;&quot;dfs.client.read.shortcircuit&quot;&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; DFS_CLIENT_READ_SHORTCIRCUIT_DEFAULT = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; DFS_CLIENT_READ_SHORTCIRCUIT_SKIP_CHECKSUM_KEY = &lt;span class=&quot;code-quote&quot;&gt;&quot;dfs.client.read.shortcircuit.skip.checksum&quot;&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; DFS_CLIENT_READ_SHORTCIRCUIT_SKIP_CHECKSUM_DEFAULT = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY = &lt;span class=&quot;code-quote&quot;&gt;&quot;dfs.client.read.shortcircuit.buffer.size&quot;&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT = 1024 * 1024;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Although the buffers are allocated in a pool with weak references, in HBase, we keep the streams open, and thus cause the inflation. There is no guard against allocating the buffers in DFSClient or BlockReaderLocal. &lt;/p&gt;

&lt;p&gt;Decreasing the size of the buffers dfs.client.read.shortcircuit.buffer.size, and not-having that many open files should help with the case. It is not clear that the extra buffering in hadoop 2 helps in case of reads coming from HBase. &lt;/p&gt;</comment>
                            <comment id="13609718" author="enis" created="Fri, 22 Mar 2013 00:00:27 +0000"  >&lt;p&gt;Attaching simple test code. If you run this against Hadoop-2.0.3-alpha, with ssr on, and -Xmx=1g, -XX:MaxDirectMemorySize=1g, you would see, &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
numFiles: 940
numFiles: 950
numFiles: 960
numFiles: 970
numFiles: 980
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;pool-2-thread-14&quot;&lt;/span&gt; java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:632)
	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:97)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:288)
	at org.apache.hadoop.hdfs.util.DirectBufferPool.getBuffer(DirectBufferPool.java:59)
	at org.apache.hadoop.hdfs.BlockReaderLocal.&amp;lt;init&amp;gt;(BlockReaderLocal.java:315)
	at org.apache.hadoop.hdfs.BlockReaderLocal.newBlockReader(BlockReaderLocal.java:208)
	at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:790)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:888)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:645)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:689)
	at java.io.DataInputStream.read(DataInputStream.java:132)
	at org.apache.hadoop.hbase.OpenFileTest.readFully(OpenFileTest.java:131)
	at org.apache.hadoop.hbase.OpenFileTest$FileCreater.createAndOpenFile(OpenFileTest.java:74)
	at org.apache.hadoop.hbase.OpenFileTest$FileCreater.run(OpenFileTest.java:57)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:680)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13609721" author="yuzhihong@gmail.com" created="Fri, 22 Mar 2013 00:03:33 +0000"  >&lt;p&gt;Apart from HBaseConfiguration, I don&apos;t see code specific to HBase.&lt;/p&gt;

&lt;p&gt;Should this test file be attached to an HDFS JIRA ?&lt;/p&gt;</comment>
                            <comment id="13609744" author="enis" created="Fri, 22 Mar 2013 00:31:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should this test file be attached to an HDFS JIRA ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am waiting for our dfs folks to discuss some options. Will create an HDFS issue after. &lt;/p&gt;</comment>
                            <comment id="13609761" author="xieliang007" created="Fri, 22 Mar 2013 00:57:26 +0000"  >&lt;p&gt;nice case, thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; for explaining, Orz&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                            <comment id="13609767" author="lhofhansl" created="Fri, 22 Mar 2013 01:08:31 +0000"  >&lt;p&gt;It is as much an HBase issue as we should have clear recommendations as to how HDFS should be configured.&lt;br/&gt;
An interesting test would be how HBase would perform if we made the buffer much smaller (like 64k, which should suffice). &lt;/p&gt;</comment>
                            <comment id="13609787" author="enis" created="Fri, 22 Mar 2013 01:31:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;It is as much an HBase issue as we should have clear recommendations as to how HDFS should be configured.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed. I intended to keep this issue open, and create a corresponding HDFS issue. After getting some resolution on the hdfs one, depending on the outcome, we can document the setup, test with smaller buffer, and maybe change the default/recommended configuration in HBase. &lt;/p&gt;</comment>
                            <comment id="13609878" author="ram_krish" created="Fri, 22 Mar 2013 03:57:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;test with smaller buffer, and maybe change the default/recommended configuration in HBase.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1.&lt;/p&gt;</comment>
                            <comment id="13621751" author="lhofhansl" created="Thu, 4 Apr 2013 04:23:48 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;, did you get a chance to repeat your tests with a smaller buffer size?&lt;/p&gt;</comment>
                            <comment id="13629814" author="lhofhansl" created="Fri, 12 Apr 2013 05:36:54 +0000"  >&lt;p&gt;Moving out to 0.94.8&lt;/p&gt;</comment>
                            <comment id="13629848" author="enis" created="Fri, 12 Apr 2013 06:37:21 +0000"  >&lt;p&gt;Not yet, but this is in my radar. We know that the issue is with the buffer size. We just have to test with a smaller size to see whether there is any performance impact. &lt;/p&gt;</comment>
                            <comment id="13648833" author="enis" created="Fri, 3 May 2013 22:06:17 +0000"  >&lt;p&gt;Raising this to critical. Will get back to this for sure. &lt;/p&gt;</comment>
                            <comment id="13659248" author="lhofhansl" created="Thu, 16 May 2013 05:36:46 +0000"  >&lt;p&gt;I will run some tests on our test cluster and report back.&lt;/p&gt;</comment>
                            <comment id="13662705" author="lhofhansl" created="Tue, 21 May 2013 05:27:47 +0000"  >&lt;p&gt;Turns out it is difficult to get hard numbers.&lt;br/&gt;
We do know that with dfs.client.read.shortcircuit.buffer.size=1m we can run into problems, so we must set it to something smaller in HBase.&lt;/p&gt;

&lt;p&gt;128k seems like a good compromise to document.&lt;/p&gt;</comment>
                            <comment id="13662707" author="lhofhansl" created="Tue, 21 May 2013 05:28:39 +0000"  >&lt;p&gt;Anyway, since there is nothing really to do on the HBase other then documenting a better default (iff short circuit reads are enabled), I&apos;m pushing this to 0.94.9/&lt;/p&gt;</comment>
                            <comment id="13692412" author="enis" created="Mon, 24 Jun 2013 21:36:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Turns out it is difficult to get hard numbers.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed. I think we suggest setting that to a multiple (1-4) of typical block sizes. this param is a client side parameter, so we can put a meaningful default in hbase-default.xml, wdyt? &lt;/p&gt;</comment>
                            <comment id="13704373" author="lhofhansl" created="Wed, 10 Jul 2013 09:47:25 +0000"  >&lt;p&gt;I like that. We can introduce a hbase.client.direct.buffer.multiplier (or something, please suggest a better name), defaulted to (say) 2. Then we use that to set dfs.client.read.shortcircuit.buffer.size automatically.&lt;/p&gt;</comment>
                            <comment id="13728728" author="lhofhansl" created="Sun, 4 Aug 2013 01:50:30 +0000"  >&lt;p&gt;The complicating factor is that each reader potentially would have a different buffer size (you&apos;ll want that larger than the HFile&apos;s block size), so it&apos;s hard to default this correctly.&lt;/p&gt;</comment>
                            <comment id="13767692" author="stack" created="Sun, 15 Sep 2013 05:27:35 +0000"  >&lt;p&gt;There is no way of getting a direct byte buffer w/o it being counted against the commit charge for the process?  Its a pity given we are just doing read-only.&lt;/p&gt;

&lt;p&gt;All of this off-heap allocation will impinge in our being able to use off heap for other purposes.&lt;/p&gt;</comment>
                            <comment id="13767693" author="lhofhansl" created="Sun, 15 Sep 2013 05:32:42 +0000"  >&lt;p&gt;With a reasonable buffer size it should be OK. 1mb is clearly counter productive.&lt;br/&gt;
It&apos;s on my (long) list of things to test with a really smaller buffer size (like 4 or 8k) and see the impact of that.&lt;/p&gt;

&lt;p&gt;At work we have this set to 128k and that has been working well.&lt;/p&gt;</comment>
                            <comment id="13767699" author="stack" created="Sun, 15 Sep 2013 05:44:27 +0000"  >&lt;p&gt;Just saying we will have to balance this sizing amongst the different needs.  4k or 8k might work for the local block reader but might not be appropriate for something like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9535&quot; title=&quot;Try a pool of direct byte buffers handling incoming ipc requests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9535&quot;&gt;&lt;del&gt;HBASE-9535&lt;/del&gt;&lt;/a&gt; (or any other feature we&apos;d want to do off-heap).&lt;/p&gt;</comment>
                            <comment id="13798257" author="stack" created="Thu, 17 Oct 2013 18:38:26 +0000"  >&lt;p&gt;I ran into this issue recently and followed Lars advice to fix it.&lt;/p&gt;

&lt;p&gt;dfs.client.read.shortcircuit.buffer.size set to 128k all around &amp;lt;name&amp;gt;dfs.client.read.shortcircuit.buffer.size&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;131072&amp;lt;/value&amp;gt; &lt;/p&gt;

&lt;p&gt;We should add this to our default configs rather than let folks run into OOMEs.&lt;/p&gt;</comment>
                            <comment id="13800225" author="lhofhansl" created="Sun, 20 Oct 2013 21:03:14 +0000"  >&lt;p&gt;Removing from 0.94.&lt;br/&gt;
Can we force HDFS default settings?&lt;/p&gt;</comment>
                            <comment id="13800285" author="stack" created="Sun, 20 Oct 2013 23:58:43 +0000"  >&lt;p&gt;Its a client-side config no?  Not for hdfs-side.&lt;/p&gt;

&lt;p&gt;Here is a bit of doc for the reference guide that recommends setting this down from its default size.  Does this do?  If so, I&apos;ll commit (I try to clean up the stale SSR section a little too).&lt;/p&gt;</comment>
                            <comment id="13800295" author="lhofhansl" created="Mon, 21 Oct 2013 01:24:26 +0000"  >&lt;p&gt;This should to be added to hdfs-site.xml as seen at the region server, right?&lt;/p&gt;</comment>
                            <comment id="13801507" author="stack" created="Tue, 22 Oct 2013 05:42:34 +0000"  >&lt;p&gt;Or just put into hbase-site.xml; that&apos;ll do.&lt;/p&gt;</comment>
                            <comment id="13801513" author="stack" created="Tue, 22 Oct 2013 05:44:39 +0000"  >&lt;p&gt;I committed the attached doc. patch; better than nothing.&lt;/p&gt;</comment>
                            <comment id="13801521" author="enis" created="Tue, 22 Oct 2013 06:00:54 +0000"  >&lt;p&gt;Doc looks fine, but we should change the default in hbase-default.xml I think. The problem last time was to perf test this, and find a meaningful default. &lt;/p&gt;</comment>
                            <comment id="13801532" author="lhofhansl" created="Tue, 22 Oct 2013 06:25:44 +0000"  >&lt;p&gt;In hbase-site.xml we&apos;d have to add a new parameter, and then set it ourselves on the DFSClient that we use, or maybe I am missing something? Can we put arbitrary HDFS params in hbase-site.xml? The DFSClient won&apos;t read that, I think.&lt;/p&gt;</comment>
                            <comment id="13801593" author="hudson" created="Tue, 22 Oct 2013 08:05:51 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4635 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4635/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4635/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8143&quot; title=&quot;HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8143&quot;&gt;&lt;del&gt;HBASE-8143&lt;/del&gt;&lt;/a&gt; HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM; DOC HOW TO AVOID (stack: rev 1534504)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/docbkx/performance.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13801778" author="hudson" created="Tue, 22 Oct 2013 12:53:17 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #803 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/803/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/803/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8143&quot; title=&quot;HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8143&quot;&gt;&lt;del&gt;HBASE-8143&lt;/del&gt;&lt;/a&gt; HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM; DOC HOW TO AVOID (stack: rev 1534504)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/docbkx/performance.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13802278" author="stack" created="Tue, 22 Oct 2013 21:18:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Seems to work for me when I try it setting the config into hbase-site.xml (previous I was getting OOME).  In HBase, we go via a HFileSystem.  When we create this in the regionserver, we pass the RS Configuration which will be laden w/ the content of the hbase*.xml files... so the dfs config read from hbase-default.xml will be present.  In DistributedFileSystem, it creates a DFSClient passing its conf on &apos;initialize&apos;.&lt;/p&gt;</comment>
                            <comment id="13802301" author="stack" created="Tue, 22 Oct 2013 21:38:02 +0000"  >&lt;p&gt;Setting dfs.client.read.shortcircuit.buffer.size in hbase-default.xml.&lt;/p&gt;

&lt;p&gt;How is this?  Should backport it too.&lt;/p&gt;</comment>
                            <comment id="13802312" author="enis" created="Tue, 22 Oct 2013 21:44:18 +0000"  >&lt;p&gt;Now thinking about it, will this override the conf set in hdfs-site.xml? If so, maybe we should custom code it in our dfs client layer. &lt;/p&gt;</comment>
                            <comment id="13803180" author="stack" created="Wed, 23 Oct 2013 19:17:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;Now thinking about it, will this override the conf set in hdfs-site.xml? If so, maybe we should custom code it in our dfs client layer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How would you suggest it work Enis?&lt;/p&gt;

&lt;p&gt;Read the configuration, if it is the default, set it to the hbase value (the hbase value would have to be named something else)?   What if it is not the default and still too large or if the default value changes (we can&apos;t read hdfs-side configs)?  There is no hdfs-site.xml on serverside in most deploys, right?&lt;/p&gt;</comment>
                            <comment id="13805718" author="enis" created="Fri, 25 Oct 2013 21:31:21 +0000"  >&lt;p&gt;For MR especially, deployments usually add the whole hadoop conf dir to the classpath, no? I think bigtop also does this. In this case, we would like to take the value from hdfs-site. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;What if it is not the default and still too large or if the default value changes (we can&apos;t read hdfs-side configs)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Luckily, dfs.client.read.shortcircuit.buffer.size is not set in hdfs-default.xml.  From the FSUtils code, can we call conf.setIfUnset(), would that work? &lt;/p&gt;</comment>
                            <comment id="13821068" author="stack" created="Wed, 13 Nov 2013 08:47:01 +0000"  >&lt;p&gt;Implement Enis&apos;s suggestion on how to set SSR buffer value.&lt;/p&gt;</comment>
                            <comment id="13821076" author="xieliang007" created="Wed, 13 Nov 2013 08:55:00 +0000"  >&lt;p&gt;FYI. i filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5461&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-5461&lt;/a&gt; which hope to alleviate this issue as well. any comments are welcome&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13821182" author="hadoopqa" created="Wed, 13 Nov 2013 10:51:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12613550/8143v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12613550/8143v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7837//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13822373" author="stack" created="Thu, 14 Nov 2013 12:28:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; A review boss please.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; Looks like Lars got you over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5461&quot; title=&quot;fallback to non-ssr(local short circuit reads) while oom detected&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5461&quot;&gt;HDFS-5461&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13830752" author="stack" created="Sat, 23 Nov 2013 19:35:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; Any chance of a revew on this one?  I&apos;d like to commit for 0.96.1.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13833100" author="eclark" created="Tue, 26 Nov 2013 21:37:38 +0000"  >&lt;p&gt;+1 lgtm should be safe and respect the dfs settings.&lt;/p&gt;</comment>
                            <comment id="13833157" author="enis" created="Tue, 26 Nov 2013 22:34:54 +0000"  >&lt;p&gt;+1. This looks good. &lt;/p&gt;</comment>
                            <comment id="13833707" author="hudson" created="Wed, 27 Nov 2013 12:02:17 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.96-hadoop2 #133 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96-hadoop2/133/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96-hadoop2/133/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8143&quot; title=&quot;HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8143&quot;&gt;&lt;del&gt;HBASE-8143&lt;/del&gt;&lt;/a&gt; HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM (stack: rev 1545853)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13833722" author="hudson" created="Wed, 27 Nov 2013 12:17:49 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #853 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/853/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/853/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8143&quot; title=&quot;HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8143&quot;&gt;&lt;del&gt;HBASE-8143&lt;/del&gt;&lt;/a&gt; HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM (stack: rev 1545852)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13833795" author="hudson" created="Wed, 27 Nov 2013 13:30:30 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.96 #205 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96/205/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96/205/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8143&quot; title=&quot;HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8143&quot;&gt;&lt;del&gt;HBASE-8143&lt;/del&gt;&lt;/a&gt; HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM (stack: rev 1545853)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13834191" author="hudson" created="Wed, 27 Nov 2013 21:42:18 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4700 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4700/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4700/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8143&quot; title=&quot;HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8143&quot;&gt;&lt;del&gt;HBASE-8143&lt;/del&gt;&lt;/a&gt; HBase on Hadoop 2 with local short circuit reads (ssr) causes OOM (stack: rev 1545852)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13848002" author="stack" created="Fri, 13 Dec 2013 22:31:03 +0000"  >&lt;p&gt;Patch for 0.94.&lt;/p&gt;</comment>
                            <comment id="13849494" author="stack" created="Mon, 16 Dec 2013 18:46:45 +0000"  >&lt;p&gt;Released in 0.96.1.  Issue closed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12628582">HBASE-7636</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12539656">HDFS-2834</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12668663">HBASE-9535</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12609726" name="8143.hbase-default.xml.txt" size="1558" author="stack" created="Tue, 22 Oct 2013 21:38:02 +0000"/>
                            <attachment id="12609348" name="8143doc.txt" size="4886" author="stack" created="Sun, 20 Oct 2013 23:58:43 +0000"/>
                            <attachment id="12618713" name="8143v2.094.txt" size="7176" author="stack" created="Fri, 13 Dec 2013 22:31:03 +0000"/>
                            <attachment id="12613550" name="8143v2.txt" size="7762" author="stack" created="Wed, 13 Nov 2013 08:47:01 +0000"/>
                            <attachment id="12574922" name="OpenFileTest.java" size="3815" author="enis" created="Fri, 22 Mar 2013 00:00:27 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12684590">HBASE-10166</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 19 Mar 2013 03:14:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>318180</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1iwgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>318521</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Committed 0.96 and trunk.  Thanks for reviews.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>