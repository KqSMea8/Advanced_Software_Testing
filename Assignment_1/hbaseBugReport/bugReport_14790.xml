<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:56:29 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-14790/HBASE-14790.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-14790] Implement a new DFSOutputStream for logging WAL only</title>
                <link>https://issues.apache.org/jira/browse/HBASE-14790</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The original &lt;tt&gt;DFSOutputStream&lt;/tt&gt; is very powerful and aims to serve all purposes. But in fact, we do not need most of the features if we only want to log WAL. For example, we do not need pipeline recovery since we could just close the old logger and open a new one. And also, we do not need to write multiple blocks since we could also open a new logger if the old file is too large.&lt;/p&gt;

&lt;p&gt;And the most important thing is that, it is hard to handle all the corner cases to avoid data loss or data inconsistency(such as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt;) when using original DFSOutputStream due to its complicated logic. And the complicated logic also force us to use some magical tricks to increase performance. For example, we need to use multiple threads to call &lt;tt&gt;hflush&lt;/tt&gt; when logging, and now we use 5 threads. But why 5 not 10 or 100?&lt;/p&gt;

&lt;p&gt;So here, I propose we should implement our own &lt;tt&gt;DFSOutputStream&lt;/tt&gt; when logging WAL. For correctness, and also for performance.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12911749">HBASE-14790</key>
            <summary>Implement a new DFSOutputStream for logging WAL only</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="Apache9">Duo Zhang</assignee>
                                    <reporter username="Apache9">Duo Zhang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Nov 2015 02:56:42 +0000</created>
                <updated>Tue, 31 May 2016 01:58:36 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>30</watches>
                                                                                                            <comments>
                            <comment id="14998312" author="chenheng" created="Tue, 10 Nov 2015 09:39:57 +0000"  >&lt;blockquote&gt;
&lt;p&gt;And the most important thing is that, it is hard to handle all the corner cases to avoid data loss or data inconsistency(such as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt;) when using original DFSOutputStream due to its complicated logic.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excuse me,  memstore rollback and RS crash cause data inconsistency in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt;,  what&apos;s the relationship with this issue, how can we avoid it after we rewrite &lt;tt&gt;DFSOutputStream&lt;/tt&gt;.  Could you explain in detail? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;  &lt;br/&gt;
Thanks!&lt;/p&gt;</comment>
                            <comment id="14998397" author="apache9" created="Tue, 10 Nov 2015 10:44:15 +0000"  >&lt;p&gt;The root reason of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; is that, HBase and HDFS may not reach an agreement on the length of WAL file. &lt;tt&gt;DFSOutputStream&lt;/tt&gt; itself does lots of thing to repair the inconsistency when error occurred, but if these approaches are all failed, then we have no idea what to do next...&lt;/p&gt;

&lt;p&gt;In fact, the simplest way to reach an agreement on file length is closing the file, and I think it is enough for logging WAL.&lt;br/&gt;
So a simple solution is, when logging failed, try closing the file(just make a call to namenode with confirmed length), if still failing, retry forever until success and set a flag to tell upper layer the WAL is broken so we could reject write request immediately to prevent OOM.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="14998403" author="chenheng" created="Tue, 10 Nov 2015 10:58:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt; try closing the file(just make a call to namenode with confirmed length)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for your explanation,  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;  I got it now.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;if still failing, retry forever until success and set a flag to tell upper layer the WAL is broken so we could reject write request immediately to prevent OOM.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As for this, IMO we can set a limit,  if exceed the limits, we can think HDFS is broken and close the RS directly.  wdyt? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14998407" author="apache9" created="Tue, 10 Nov 2015 11:01:57 +0000"  >&lt;blockquote&gt;
&lt;p&gt;As for this, IMO we can set a limit, if exceed the limits, we can think HDFS is broken and close the RS directly. wdyt? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agree. But the timeout value should be carefully chosen.&lt;/p&gt;</comment>
                            <comment id="14999330" author="busbey" created="Tue, 10 Nov 2015 20:49:20 +0000"  >&lt;p&gt;excellent! I had a first pass of this done several months ago to correct for the assumptions around write size and clean up the excessive locking done in the existing DFSOutputStream implementation.&lt;/p&gt;

&lt;p&gt;+1  and happy to review, please encapsulate this in a WAL Provider so that the existing filesystem implementation can live alongside it until we have a chance for burn in.&lt;/p&gt;

&lt;p&gt;hopefully once we have some perf numbers we can look into getting changes available upstream for more general use.&lt;/p&gt;</comment>
                            <comment id="14999910" author="carp84" created="Wed, 11 Nov 2015 03:57:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So a simple solution is, when logging failed, try closing the file&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;AFAICS, our current code base has such logic:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;FSHLog$SyncRunner#run, line 1220&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
  ...
  writer.sync();
  ...
} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
  LOG.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error syncing, request close of WAL&quot;&lt;/span&gt;, e);
  lastException = e;
} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Exception e) {
  LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;UNEXPECTED&quot;&lt;/span&gt;, e);
  lastException = e;
} &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
  ...
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (lastException != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) requestLogRoll();
  &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; checkLogRoll();
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Mind further explain the difference in the new design? Thanks.&lt;/p&gt;</comment>
                            <comment id="14999917" author="apache9" created="Wed, 11 Nov 2015 04:04:25 +0000"  >&lt;p&gt;&lt;tt&gt;DFSOutputStream&lt;/tt&gt; has pipeline recovery, so it is hard to say what is the actual state if the recovery is failed, and its &lt;tt&gt;close&lt;/tt&gt; method also does lots of things other than just calling &lt;tt&gt;completeFile&lt;/tt&gt;. So it is hard to control the behavior exactly.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15001319" author="busbey" created="Wed, 11 Nov 2015 23:20:40 +0000"  >&lt;p&gt;Other differences from when I was looking:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;current implementation copies small writes into a buffer to minimize&lt;br/&gt;
calls to native library, but with small write+flush workload we just copy&lt;br/&gt;
needlessly&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;current implementation has locking to enable partial and IMHO confusing&lt;br/&gt;
concurrency. We don&apos;t actually need multithreaded access to write pipeline&lt;br/&gt;
so we can remove some of it.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&amp;#8211; &lt;br/&gt;
Sean&lt;/p&gt;
</comment>
                            <comment id="15001665" author="carp84" created="Thu, 12 Nov 2015 04:13:20 +0000"  >&lt;p&gt;Thanks for the explanation &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;. So an optimized DFSOutputStream for small writes, make sense. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15003450" author="enis" created="Fri, 13 Nov 2015 02:44:38 +0000"  >&lt;p&gt;Sounds like a good idea to not have the pipeline recovery and single writer assumption (though we are calling sync() from different sync threads). How are we gonna maintain a custom OS for HDFS. Shouldn&apos;t this go directly to Hdfs? &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; FYI. &lt;/p&gt;</comment>
                            <comment id="15003469" author="apache9" created="Fri, 13 Nov 2015 03:03:17 +0000"  >&lt;p&gt;The new implementation will be event-driven which means we could use a callback when sync so we do not need multiple sync threads any more.&lt;/p&gt;

&lt;p&gt;So I think it is a big project if we want to implement this in HDFS since we introduce a new style of API. Even though we could only implement a new writer first, but I think it is still very important to design a good general interface first.&lt;/p&gt;

&lt;p&gt;So I think we could implement this in HBase first and collect some perf results. Then we could start talking about move it into HDFS.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15003477" author="busbey" created="Fri, 13 Nov 2015 03:15:40 +0000"  >&lt;p&gt;We don&apos;t need to sync in a different thread. That&apos;s old code I&apos;ve yet to&lt;br/&gt;
see benchmark justification for.&lt;/p&gt;

&lt;p&gt;&amp;#8211; &lt;br/&gt;
Sean&lt;/p&gt;
</comment>
                            <comment id="15003560" author="wheat9" created="Fri, 13 Nov 2015 05:09:43 +0000"  >&lt;p&gt;Making the errors in the pipeline visible to HBase allows HBase to detect failures and to recover from failures much faster. It has a lot of benefits in terms on reducing the latency of HBase.&lt;/p&gt;

&lt;p&gt;An Exokernel style writer will eventually allow HBase to write to HDFS in parallel, which further reducing the latency by 3x.&lt;/p&gt;

&lt;p&gt;I would suggest (1) implementing the writer in the HDFS project to reduce the cost of maintenance, (2) making it event-driven so that it is reusable when building today&apos;s &lt;tt&gt;DFSOutputStream&lt;/tt&gt;. It&apos;s much harder to do so today as there are a lot of synchronization happening for throttling, etc.&lt;/p&gt;

&lt;p&gt;It is relatively straightforward to implement the current client-side, pipeline protocol without handling failures. The potential issue I see is that the DN might mask the failures and introduce additional delays in the pipeline. To fully get the benefits it might require changing the protocol. That&apos;s being said, the project suddenly becomes much risker when it requires changes on the server side.&lt;/p&gt;

&lt;p&gt;A less risky route is to combine the effort with the HTTP/2 initiatives of HDFS which allows full control on both the client and the server side. Thoughts?&lt;/p&gt;</comment>
                            <comment id="15003595" author="apache9" created="Fri, 13 Nov 2015 05:53:13 +0000"  >&lt;p&gt;HTTP/2 has its own problems that we haven&apos;t finish the read path yet but the write protocol is much more complex than read protocol... And also, if we plan to do it in HDFS, I think we should make it more general, and it is better to design a good event-driven FileSystem interface at the beginning. I do not think either of them is easy...&lt;/p&gt;

&lt;p&gt;So my plan is to implement a simple version in HBase which only compatible with hadoop 2.x first, make sure it has some benefits and actually ship it with HBase. And then, we could start implementing a more general and more powerful event-driven FileSystem in HDFS. When the new FileSystem is out, we could move HBase to use the new FileSystem in HDFS and drop the old simple version.&lt;/p&gt;

&lt;p&gt;What do you think? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15003636" author="stack" created="Fri, 13 Nov 2015 07:02:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That&apos;s old code I&apos;ve yet to see benchmark justification for.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here is where having multiple syncers is first challenged: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8755?focusedCommentId=13830604&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13830604&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-8755?focusedCommentId=13830604&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13830604&lt;/a&gt; It is followed by numbers that show that throughput is better with 5. I remember playing with syncers after ringbuffer went in and arrived again at 5 syncers as best for throughput.&lt;/p&gt;

&lt;p&gt;I&apos;ll be happy to see them go. Chatting w/ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;, having a single thread start the syncs with callbacks to take care of letting blocked handlers go sounds cleaner. I&apos;m not sure how it will look just yet. We&apos;ll want to keep our group commits fat and we&apos;ll want to minimize inter-thread communication/blocking.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A less risky route is to combine the effort with the HTTP/2 initiatives of HDFS which allows full control on both the client and the server side. Thoughts?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;. Lets not broaden the scope of an already involved project by mixing in http/2. Lets also get a success here in hbase first &amp;#8211; we have a very particular need, we have tooling and mechanisms to verify perf and correct behavior &amp;#8211; using a subset of the write API in an async way.... and then move to the general case with this feather in our hat (Einstein published the special theory of relativity before he did the general).&lt;/p&gt;


</comment>
                            <comment id="15003638" author="stack" created="Fri, 13 Nov 2015 07:04:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The potential issue I see is that the DN might mask the failures and introduce additional delays in the pipeline. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I can see this project running up against this sort of a problem, yes. The DN thinking it knows better.... good point.&lt;/p&gt;</comment>
                            <comment id="15005449" author="chenheng" created="Sat, 14 Nov 2015 16:03:29 +0000"  >&lt;p&gt;IMO  we could fix &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; as the first step.&lt;br/&gt;
Before we rollback memstore, we should close WAL with some certain length.&lt;br/&gt;
If close WAL failed,  we can set a timeout,  if exceeds this limitation, RS should close.&lt;br/&gt;
If close WAL successfully,  we go  on with a new WAL.&lt;/p&gt;

&lt;p&gt;All we should do about DFSOutputStream is  a new close method just calling completeFile.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="15031479" author="apache9" created="Mon, 30 Nov 2015 08:13:38 +0000"  >&lt;p&gt;Now I&#8216;m trying to implement a fan-out async output stream first.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FanOutOneBlockDFSOutputStream.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FanOutOneBlockDFSOutputStream.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Will be back it works.&lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="15033245" author="zhz" created="Tue, 1 Dec 2015 07:15:30 +0000"  >&lt;p&gt;On the high level, the key requirements here are very similar to what we need for &lt;tt&gt;DFSOutputStream&lt;/tt&gt; in HDFS erasure coding:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;&lt;b&gt;Fanout write to multiple DNs&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Simpler logic without hairy pipeline recovery&lt;/b&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In HDFS-EC we have spent a lot of time trying to fit the above requirements with existing &lt;tt&gt;DFSOutputStream&lt;/tt&gt; and &lt;tt&gt;DataStreamer&lt;/tt&gt;. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=walter.k.su&quot; class=&quot;user-hover&quot; rel=&quot;walter.k.su&quot;&gt;Walter Su&lt;/a&gt; did a great job on &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-9040&quot; title=&quot;Erasure coding: Refactor DFSStripedOutputStream (Move Namenode RPC Requests to Coordinator)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-9040&quot;&gt;&lt;del&gt;HDFS-9040&lt;/del&gt;&lt;/a&gt; and I&apos;m working on &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-9079&quot; title=&quot;Erasure coding: preallocate multiple generation stamps and serialize updates from data streamers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-9079&quot;&gt;HDFS-9079&lt;/a&gt; to further simplify the logic. &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-9079&quot; title=&quot;Erasure coding: preallocate multiple generation stamps and serialize updates from data streamers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-9079&quot;&gt;HDFS-9079&lt;/a&gt; also tries to create a &lt;b&gt;simpler single-block writing logic&lt;/b&gt; in &lt;tt&gt;StripedDataStreamer&lt;/tt&gt;, which I guess is also a goal of this JIRA. It&apos;s actually also based on an &lt;b&gt;event-driven&lt;/b&gt; model. But I&apos;m not sure yet if the events collected by &lt;tt&gt;BlockMetadataCoordinator&lt;/tt&gt; are the same type of events needed here.&lt;/p&gt;

&lt;p&gt;I&apos;m still reading through Duo&apos;s patch and haven&apos;t fleshed out full details of how to fulfill requirements from both sides, but on the high level this looks like a potential synergy. Maybe we can consider:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;In HDFS project, implement a single-block fail-stop &lt;tt&gt;DataStreamer&lt;/tt&gt; so at the very least that part can be shared by both efforts. The new &lt;tt&gt;DataStreamer&lt;/tt&gt; will stop after writing a block, and won&apos;t attempt to recover from DN failures. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; LMK if your patch could use such a streamer, and focus only on the &lt;tt&gt;OutputStream&lt;/tt&gt; logic. Actually the &lt;tt&gt;StripedDataStreamer&lt;/tt&gt; in the latest &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-9079&quot; title=&quot;Erasure coding: preallocate multiple generation stamps and serialize updates from data streamers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-9079&quot;&gt;HDFS-9079&lt;/a&gt; patch is close to this requirement. But it does have the additional logic to report and handle failure events. I guess that&apos;s inevitable to correctly set block generation stamps.&lt;/li&gt;
	&lt;li&gt;If that goes well, we can explore whether / how to share the fan-out logic with &lt;tt&gt;DFSStripedOutputStream&lt;/tt&gt;. The outcome might be a &lt;tt&gt;DFSParalleOutputStream&lt;/tt&gt;, subclassed by &lt;tt&gt;DFSParallelStripedOutputStream&lt;/tt&gt; and &lt;tt&gt;DFSParallelContiguousOutputStream&lt;/tt&gt; (with better names).&lt;/li&gt;
	&lt;li&gt;We can further consider whether it&apos;s possible to pass the streamer events collected by &lt;tt&gt;BlockMetadataCoordinator&lt;/tt&gt; up to HBase.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="15033281" author="apache9" created="Tue, 1 Dec 2015 07:52:00 +0000"  >&lt;p&gt;Thanks for the information.&lt;/p&gt;

&lt;p&gt;Here I&apos;m trying to use only one thread to do all the things so the existing code in HDFS does not help... And also I need to abstract a new style of event-driven API to fit the requirements of WAL in HBase. I do not think it will be an &lt;tt&gt;OutputStream&lt;/tt&gt; any more.&lt;/p&gt;

&lt;p&gt;Of course, the final goal here is to put the new style &quot;OutputStream&quot; into HDFS project.&lt;/p&gt;</comment>
                            <comment id="15034663" author="zhz" created="Tue, 1 Dec 2015 21:57:37 +0000"  >&lt;p&gt;Thanks for the clarification Duo.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Here I&apos;m trying to use only one thread to do all the things &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I see. So you &quot;fanout&quot; for every packet with multiple threads. That does make the logic simpler. But I guess the logic of bumping gen stamp is still necessary &amp;#8211; imagine a packet is written to 1st DN but fails to reach 2nd DN. Does the higher level WAL just abandon the file in this case? Simply closing the file without bumping GS will cause data corruption.&lt;/p&gt;

&lt;p&gt;From performance perspective, &lt;tt&gt;FanOutOneBlockDFSOutputStream&lt;/tt&gt; makes sure every packet reaches 3 DNs before proceeding &amp;#8211; it&apos;s like calling &lt;tt&gt;hflush&lt;/tt&gt; for every packet. With slow DNs this could increase latency quite significantly. But if packet-level flush is indeed desired in the WAL use case, I think the flow in the patch makes sense.&lt;/p&gt;

&lt;p&gt;If coarser grained flushing is desired, then I think we should still separate &lt;tt&gt;OutputStream&lt;/tt&gt; and &lt;tt&gt;DataStreamer&lt;/tt&gt; logics, and we should develop a single-block single-replica fail-stop &lt;tt&gt;DataStreamer&lt;/tt&gt; as I commented above.&lt;/p&gt;</comment>
                            <comment id="15035230" author="apache9" created="Wed, 2 Dec 2015 04:03:34 +0000"  >&lt;p&gt;basically works. I added a test for it&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestFanOutOneBlockDFSOutputStream.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestFanOutOneBlockDFSOutputStream.java&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;So you &quot;fanout&quot; for every packet with multiple threads. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No, I use only one &lt;tt&gt;EventLoop&lt;/tt&gt; which means there is only one thread.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Simply closing the file without bumping GS will cause data corruption.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This does not make sense. What if client crashes before bumping GS?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;then I think we should still separate OutputStream and DataStreamer logics&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Maybe you are right but I&apos;, not sure what is the correct way since there is no netty based DFSClient yet? I need to find a way to make it basically work, and then try to abstract the logic.&lt;/p&gt;

&lt;p&gt;Next I will dig into the error handling part. Thanks.&lt;/p&gt;
</comment>
                            <comment id="15037338" author="apache9" created="Thu, 3 Dec 2015 06:16:29 +0000"  >&lt;p&gt;I read the code in &lt;tt&gt;NameNode&lt;/tt&gt; and &lt;tt&gt;DFSOutputStream&lt;/tt&gt; and I think I understand why &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhz&quot; class=&quot;user-hover&quot; rel=&quot;zhz&quot;&gt;Zhe Zhang&lt;/a&gt; said bumping GS is necessary.&lt;/p&gt;

&lt;p&gt;There are two scenarios:&lt;/p&gt;

&lt;p&gt;1. The endBlock operation has finished with at least one datanode being success. Under this scenario we could just call completeFile to close the file since we know the exact file length.&lt;br/&gt;
2. The endBlock operation has failed on all datanodes. Under this scenario, the &quot;acked length&quot; may not be the actual length of the block, maybe it is longer and cause the assert at namenode fail.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt; block.getNumBytes() &amp;lt;= commitBlock.getNumBytes() :
      &lt;span class=&quot;code-quote&quot;&gt;&quot;commitBlock length is less than the stored one &quot;&lt;/span&gt;
      + commitBlock.getNumBytes() + &lt;span class=&quot;code-quote&quot;&gt;&quot; vs. &quot;&lt;/span&gt; + block.getNumBytes();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And even if we pass the assert, it does not mean the block has the right length since it may have not been reported to namenode yet, and it is not safe to truncate the block since other one may have already read the data after the truncating point(think of wal replication). So under this scenario, at least we need to reach a consensus on the block length with each datanode before completing the file. Maybe bumping GS is the only way to do this in HDFS?&lt;/p&gt;</comment>
                            <comment id="15037472" author="apache9" created="Thu, 3 Dec 2015 08:26:28 +0000"  >&lt;p&gt;Oh, I think we could not fix &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; without changing the replication module of HBase. No matter how we implement DFSOutputStream, think of this scenario:&lt;/p&gt;

&lt;p&gt;1. rs flush an WAL entry to dn1, dn2 and dn3.&lt;br/&gt;
2. dn1 received the WAL entry, and it is read by ReplicationSource and replicated to slave cluster.&lt;br/&gt;
3. dn1 and rs both crash, dn2 and dn3 has not received this WAL entry yet, and rs has not bumped the GS of this block yet.&lt;br/&gt;
4. NameNode complete the file with a length that does not contains this WAL entry since the GS of blocks on dn2 and dn3 is correct and NameNode does not know there used to be a block with longer length.&lt;br/&gt;
5. whoops...&lt;/p&gt;

&lt;p&gt;So I think every rs should keep an &quot;acked length&quot; of the current writing WAL file, an when doing replication, ReplicationSource should ask this length first before reading and do not read beyond it. If we have this logic, then the implementation of the new &quot;DFSOutputStream&quot; is much simpler. We could just truncate the file if writing WAL failed on some datanode with our &quot;acked length&quot; and fail all the entries after the &quot;acked length&quot;. This can keep all things consistency.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15037630" author="carp84" created="Thu, 3 Dec 2015 10:36:55 +0000"  >&lt;p&gt;Agree that we may not fix &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; by simply implementing a new DFSOutputStream, but I think the FanoutOutputStream is still useful to reduce WAL sync latency. Pipeline is good for throughput but not for latency.&lt;/p&gt;</comment>
                            <comment id="15038167" author="stack" created="Thu, 3 Dec 2015 17:34:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;So I think every rs should keep an &quot;acked length&quot; of the current writing WAL file, an when doing replication....&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;HBase owning this fact is way to go. There is no way to get this info from current dfsclient, right? It would be a new metadata that this new work would reveal?&lt;/p&gt;</comment>
                            <comment id="15038178" author="zhz" created="Thu, 3 Dec 2015 17:39:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;tt&gt;DataStreamer#block&lt;/tt&gt; tracks the &quot;number of bytes acked&quot;. It is returned by &lt;tt&gt;DFSOutputStream#getBlock&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; I&apos;m still reading your analysis, will get back shortly&lt;/p&gt;</comment>
                            <comment id="15038259" author="stack" created="Thu, 3 Dec 2015 18:30:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhz&quot; class=&quot;user-hover&quot; rel=&quot;zhz&quot;&gt;Zhe Zhang&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;DataStreamer#block tracks the &quot;number of bytes acked&quot;. It is returned by DFSOutputStream#getBlock&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This attribute is exposed in dfsclient api (I should check myself... but...) Thanks.&lt;/p&gt;</comment>
                            <comment id="15038849" author="apache9" created="Thu, 3 Dec 2015 23:43:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhz&quot; class=&quot;user-hover&quot; rel=&quot;zhz&quot;&gt;Zhe Zhang&lt;/a&gt; I was wrong&#65292;the pipeline recovery is always needed in the current design of HDFS. It is not safe to increase acked length when some datanodes do not respond because the GSes are same on all datanode, if client and the succeeded datanodes all crash, namenode could complete block with a shorter length.&lt;/p&gt;

&lt;p&gt;So the only thing that can be eliminated is add datanode to existing pipeline. And once we reach a consensus on the block length on all datanodes, we could reset the acked length if needed and then move the remaining operations of closing file to a background thread to reduce latency. Thoughts? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15039718" author="apache9" created="Fri, 4 Dec 2015 04:06:09 +0000"  >&lt;blockquote&gt;
&lt;p&gt;2. dn1 received the WAL entry, and it is read by ReplicationSource and replicated to slave cluster.&lt;br/&gt;
3. dn1 and rs both crash, dn2 and dn3 has not received this WAL entry yet, and rs has not bumped the GS of this block yet.&lt;br/&gt;
4. NameNode complete the file with a length that does not contains this WAL entry since the GS of blocks on dn2 and dn3 is correct and NameNode does not know there used to be a block with longer length.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In a fan out implementation, this problem is obvious but in a pipelined implementation it is not that straight-forward and I used to think I was wrong and this could not happen in a pipelined implementation. The data can only be visible on datanode only after it receives the downstream ack. So if the pipeline is dn1-&amp;gt;dn2-&amp;gt;dn3, then dn3 is the first datanode that make a data visible to client and usually we think the data should also be written to dn1 and dn2. But maybe for performance reason, &lt;tt&gt;BlockReceiver&lt;/tt&gt; sends a packet to downstream mirror before writing it to local disk. So it could happen that dn3 make the data visible and read by client, but dn1 and dn2 crash before writing data to local disk. Then let us kill the client and dn3, and restart dn1 and dn2, whoops...&lt;/p&gt;

&lt;p&gt;And I had a discussion with my workmate &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yangzhe1991&quot; class=&quot;user-hover&quot; rel=&quot;yangzhe1991&quot;&gt;Phil Yang&lt;/a&gt;, we think that if we allow duplicate WAL entries in HBase, then the pipeline recovery part could also be moved to a background thread. We could just rewrite the WAL entries after acked point to the new file, this could also reduce the recovery latency.&lt;/p&gt;

&lt;p&gt;And for keeping an &quot;acked length&quot;, I think we could make use of the fsync method in HDFS. We could call fsync asynchronously to update length on namenode. The replication source should not read beyond the length gotten from namenode(do not trust the visible length read from datanode). The advantage here is when region server crashes, we could still get this value from namenode, and the file will be closed eventually by someone so the length will finally be correct.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15039770" author="apache9" created="Fri, 4 Dec 2015 05:28:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The design doc of hflush and happend already said that if all datanodes restart, then no guarantee could be provided. I think this is reasonable. Even if hflush succeeded, we could kill all the datanode in pipeline and the client and restart, the file after recovering lease could be shorter than the acked length. There will always be some situation that we could not know there is data loss unless we call fsync every time to update length on namenode when writing WAL I think. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15040781" author="chenheng" created="Fri, 4 Dec 2015 06:17:00 +0000"  >&lt;blockquote&gt;
&lt;p&gt;And for keeping an &quot;acked length&quot;, I think we could make use of the fsync method in HDFS. We could call fsync asynchronously to update length on namenode. The replication source should not read beyond the length gotten from namenode(do not trust the visible length read from datanode). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So if we can not avoid fsync every time, maybe this way &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; mentioned is the best solution?   Of course, we should keep &apos;acked length&apos; in RS.  Let&apos;s begin?&lt;/p&gt;</comment>
                            <comment id="15040809" author="apache9" created="Fri, 4 Dec 2015 06:36:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chenheng&quot; class=&quot;user-hover&quot; rel=&quot;chenheng&quot;&gt;Heng Chen&lt;/a&gt; We should make a trade off here. I do not think calling fsync every time is acceptable since it means namenode will have the same write pressure with the whole HBase cluster...&lt;/p&gt;</comment>
                            <comment id="15041145" author="chenheng" created="Fri, 4 Dec 2015 06:45:55 +0000"  >&lt;p&gt;Make sense... &lt;br/&gt;
Let&apos;s just keep here as original.  We can only realize &apos;acked length&apos; logic,  it could fix &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; already. &lt;br/&gt;
 As performance improvement work, keep going yours fanout Stream here. Thoughts? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15041147" author="apache9" created="Fri, 4 Dec 2015 06:49:08 +0000"  >&lt;p&gt;And I found that, &lt;tt&gt;hsync&lt;/tt&gt; and &lt;tt&gt;hflush&lt;/tt&gt; have different ack flows. &lt;tt&gt;hsync&lt;/tt&gt; only sends ack back when the data is successfully synced to local disk, so I think use &lt;tt&gt;hsync&lt;/tt&gt; is enough to detect if there is data loss(forget the &lt;tt&gt;fsync&lt;/tt&gt;).&lt;/p&gt;</comment>
                            <comment id="15041185" author="stack" created="Fri, 4 Dec 2015 07:17:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;ReplicationSource should ask this length first before reading and do not read beyond it. If we have this logic, &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Doing this would be an improvement over current way we do replication &amp;#8211; less NN ops &amp;#8211; where we open the file, read till EOF, close, then do same again to see if anything new has been added to the file.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...we could reset the acked length if needed and then move the remaining operations of closing file to a background thread to reduce latency. Thoughts? stack&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is clean up of a broken WAL? This is being able to ask each DN what it thinks the length is? While this is going on, we would be holding on to the hbase handlers not letting response go back to the client?  Would we have to do some weird accounting where three clients A, B, and C and each written an edit, and then the length we get back from exisiting DNs after a crash say does not include the edit written by client C... we&apos;ll have to figure out how to fail client C&apos;s write (though we&apos;d moved on from append and were trying to sync/hflush the append)?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We could just rewrite the WAL entries after acked point to the new file, this could also reduce the recovery latency.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think we can do this currently in the multi WAL case... would have to check (or at least one implementation that may not be the one that landed, used to do this). It would keep around the edits because it would have a standby WAL and if the current WAL was &apos;slow&apos;, we&apos;d throw it away and then add the outstanding edits to the new WAL and away we go again (I can dig it up... )&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The replication source should not read beyond the length gotten from namenode(do not trust the visible length read from datanode). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would be lots of NN ops? (In a subsequent comment you say this... nvm)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The advantage here is when region server crashes, we could still get this value from namenode, and the file will be closed eventually by someone so the length will finally be correct.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would be sweet though (could do away with keeping replication lengths up in zk?)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;There will always be some situation that we could not know there is data loss unless we call fsync every time to update length on namenode when writing WAL I think. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes. This is the case before your patch though. We should also get some experience of what its like trying fsync.&apos;d WAL...&lt;/p&gt;








</comment>
                            <comment id="15041196" author="chenheng" created="Fri, 4 Dec 2015 07:23:21 +0000"  >&lt;blockquote&gt;
&lt;p&gt;DataStreamer#block tracks the &quot;number of bytes acked&quot;. It is returned by DFSOutputStream#getBlock&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Bad news...  This method is not public.... &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhz&quot; class=&quot;user-hover&quot; rel=&quot;zhz&quot;&gt;Zhe Zhang&lt;/a&gt;  &lt;/p&gt;</comment>
                            <comment id="15041234" author="yangzhe1991" created="Fri, 4 Dec 2015 07:56:41 +0000"  >&lt;p&gt;Considering these features:&lt;br/&gt;
Hflush is much faster than hsync, especially in pipeline mode. So we have to use hflush for hbase writing.&lt;br/&gt;
The data in DN that is hflushed but not hsynced may only in memory not disk, but it can be read by client.&lt;/p&gt;

&lt;p&gt;So if we hflush data to DNs, and it is read by ReplicationSource and transferred to slave cluster, then three DNs and RS in master cluster crash. And after replaying WALs, slave will have data that master loses...&lt;/p&gt;

&lt;p&gt;The only way to prevent any data losses is hsync every time but it is too slow, and I think most users can bear data lose to speed up writing operation but can not bear slave has more data than master.&lt;/p&gt;

&lt;p&gt;Therefore, I think we can do these:&lt;br/&gt;
hflush every time, not hsync;&lt;br/&gt;
hsync periodically, for example, default per 1000ms? It can be configured by users, and users can also configure that we hsync every time, so there will not have any data loses unless all DNs disk fail...&lt;br/&gt;
RS tells &quot;acked length&quot; to ReplicationSource which is the data we hsynced, not hflushed. &lt;br/&gt;
ReplicationSource only transfer data which is not larger than acked length. So the slave cluster will never have inconsistency.&lt;br/&gt;
WAL reading can handle  duplicate entries.&lt;br/&gt;
On WAL logging, if we get error on hflush, we open a new file and rewrite this entry, and recover/hsync/close old file asynchronously.&lt;/p&gt;</comment>
                            <comment id="15041307" author="chenheng" created="Fri, 4 Dec 2015 09:06:03 +0000"  >&lt;blockquote&gt;
&lt;p&gt;hsync periodically, for example, default per 1000ms? It can be configured by users, and users can also configure that we hsync every time, so there will not have any data loses unless all DNs disk fail...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds reasonable.  we update &apos;acked length&apos; after hsync,  I think &apos;acked length&apos; logical is completed.  Any thoughts?&lt;/p&gt;</comment>
                            <comment id="15041321" author="apache9" created="Fri, 4 Dec 2015 09:13:10 +0000"  >&lt;blockquote&gt;
&lt;p&gt;This is clean up of a broken WAL? This is being able to ask each DN what it thinks the length is? While this is going on, we would be holding on to the hbase handlers not letting response go back to the client? Would we have to do some weird accounting where three clients A, B, and C and each written an edit, and then the length we get back from exisiting DNs after a crash say does not include the edit written by client C... we&apos;ll have to figure out how to fail client C&apos;s write (though we&apos;d moved on from append and were trying to sync/hflush the append)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think we can implement in this way. When a WAL is broken(one datanode fail means broken)&lt;/p&gt;

&lt;p&gt;1. Open a new WAL synchronously.&lt;br/&gt;
2. Write all the un-acked WAL entries to the new WAL file(which means we should keep all the un-acked WAL entries).&lt;br/&gt;
3. Schedule a background task to close the old WAL file.&lt;/p&gt;

&lt;p&gt;We should hold the sync WAL request if we consider that some of WAL entries after last sync has already been written out but not acked until we successfully write them to new WAL file and get ack back.&lt;/p&gt;

&lt;p&gt;And the task in phase 3&lt;/p&gt;

&lt;p&gt;1. Doing standard pipeline recovery. Maybe a little difference is that, we can truncate the block length to our acked length when negotiating with datanodes.&lt;br/&gt;
2. endBlock on each datanode.&lt;br/&gt;
3. complete file on namenode.&lt;/p&gt;

&lt;p&gt;It is does not matter if the rs is crashed during the recovery because we can make sure that the file length after lease recovery should be longer than acked length(unless the 3 datanodes are all crashed, we can not handle this using hflush).&lt;/p&gt;

&lt;p&gt;Thanks. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15041761" author="carp84" created="Fri, 4 Dec 2015 16:54:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;hsync periodically, for example, default per 1000ms&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;AFAIK, DN will do this if &lt;tt&gt;dfs.datanode.sync.behind.writes&lt;/tt&gt; is set to true, and the window is 8MB, just correct me if I&apos;m wrong.&lt;/p&gt;

&lt;p&gt;Sorry for the interruption but is the discussion here back to the issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; reports, say preventing ReplicationSource to replicate any non-persisted and later-lost data, due to the fact that we depends on hflush not hsync currently? And it seems we could not resolve the issue by implementing new DFSOutputStream?&lt;/p&gt;

&lt;p&gt;Would it be a better idea to continue the discussion on master-slave replication consistency issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt;, while focusing on the new DFSOutputStream here, to make &quot;an optimized DataOutputStream for small writes like WAL entry&quot;?&lt;/p&gt;</comment>
                            <comment id="15041910" author="yangzhe1991" created="Fri, 4 Dec 2015 18:25:05 +0000"  >&lt;p&gt;Currently there are two scenarios which may result in inconsistency between two clusters.&lt;/p&gt;

&lt;p&gt;The first is master cluster crashes(for example, power failure) or three DNs and RS crash at the same time and we lost all data that is not flushed to DNs&apos; disks but the data have been already synced to slave cluster.&lt;/p&gt;

&lt;p&gt;The second is we will rollback memstore and response client an error if we get a error on hflush but the log may indeed exists in WAL. This will not only results in inconsistency between two clusters but also gives client a wrong response because the data will &quot;revive&quot; after replaying WAL. This scenario has been discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; &lt;/p&gt;


&lt;p&gt;Comparing to the second, it is easier to solve the first scenario that we can tell ReplicationSource it can only read the logs that is already saved on three disks. We need to know the largest WAL entry id that has been synced. So HDFS&apos;s sync logic for itself may be not useful for us and we must use hsync to let HBase know the entry id. So we need a configurable periodically hsync here, and if we have only one cluster it is also helpful to reduce data losses because of data center power failure or unluckily crashing three DNs and RS at the same time. I think this work can be done without the new DFSOutputStream?&lt;/p&gt;

&lt;p&gt;For the second scenario, it is more complex because we can not rollback memstore and tell client this operation failed unless we are very sure the data will never exist in WAL, and mostly we are not sure... So we have to use a new WAL logic that rewriting the entry to the new file rather than rollback. To implement this we need to handle duplicate entries while replaying WAL. I think this logic is not conflicting with pipeline DFSOutputStream so actually we can fix it on currently WAL implementation?&lt;/p&gt;

&lt;p&gt;And this issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14790&quot; title=&quot;Implement a new DFSOutputStream for logging WAL only&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14790&quot;&gt;HBASE-14790&lt;/a&gt; may be only a performance improvement work that will not fix any bugs? Of course, the FanOutOneBlockDFSOutputStream should implement the new WAL logic directly.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; What do you think?&lt;/p&gt;</comment>
                            <comment id="15042228" author="zhz" created="Fri, 4 Dec 2015 21:00:27 +0000"  >&lt;p&gt;Thanks for the catch. If needed I guess we can make it public. Or at least have a public API to return the acked length.&lt;/p&gt;</comment>
                            <comment id="15042639" author="apache9" created="Sat, 5 Dec 2015 04:17:28 +0000"  >&lt;p&gt;We just dig into the implementation of &lt;tt&gt;DFSOutputStream&lt;/tt&gt; and &lt;tt&gt;BlockReceiver&lt;/tt&gt; here to find what we can do to increase WAL performance and correctness. Now it is clear that performance and correctness can be treated separately. So I agree that we could move the correctness related things back to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; and leave only the performance related things here.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yangzhe1991&quot; class=&quot;user-hover&quot; rel=&quot;yangzhe1991&quot;&gt;Phil Yang&lt;/a&gt; Mind post your solution on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt; again? Then people could start working there. In this issue I will focus on the performance only.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15074641" author="apache9" created="Wed, 30 Dec 2015 05:24:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FanOutOneBlockAsyncDFSOutput.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FanOutOneBlockAsyncDFSOutput.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Finally I found that there is no way to truncate a block from client side, only NameNode can do it. If we do not want to change the protocol, the only way without writing the pending data again is calling recoverLease. I will try to add a &apos;truncateToMinRcvdBytes&apos; flag in protocol when implementing it in HDFS, but now I think this is enough. I will implement a WAL based on this and collect some perf results.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15074678" author="stack" created="Wed, 30 Dec 2015 06:27:42 +0000"  >&lt;p&gt;Soon as you have a basic WAL &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;, I can try get some basic numbers?  I&apos;m doing a bit of perf testing at mo on write pipeline.&lt;/p&gt;</comment>
                            <comment id="15074735" author="apache9" created="Wed, 30 Dec 2015 07:37:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Soon as you have a basic WAL Duo Zhang, I can try get some basic numbers? I&apos;m doing a bit of perf testing at mo on write pipeline.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Great. But I think I need some time to finish the WAL implementation. The &lt;tt&gt;WALProvider&lt;/tt&gt; is not friendly to an async implementation, I need to do some refactoring first.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15111963" author="apache9" created="Fri, 22 Jan 2016 05:40:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/AsyncFSHLog.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/Apache9/hbase/blob/HBASE-14790/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/AsyncFSHLog.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Could pass a simple &lt;tt&gt;TestLogRolling&lt;/tt&gt; now.&lt;/p&gt;

&lt;p&gt;Next I will try to make it more robust and use it to run some large test.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15133896" author="apache9" created="Fri, 5 Feb 2016 09:31:40 +0000"  >&lt;p&gt;I have got a 5 regionservers test cluster and run pe tool with async enabled or disabled several times.&lt;br/&gt;
The total throughput is same, and the .999 is a little smaller with async enabled. I think this is what we expect &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;This is only a simple test, not the final result. Will be back after spring festival.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15135250" author="stack" created="Fri, 5 Feb 2016 23:27:52 +0000"  >&lt;p&gt;I gave it a try on a little cluster. Not all the metrics are hooked up and it looks like the patched version did 1/10th less operations. That said, the patch looks to be 2x faster on the simple WALPE test with default args.  it completes in half the time with half the CS, half the branch-misses, with a better instruction per cycle count. Patch is looking promising. Let me know when you&apos;d like a bit of review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In both cases, did this against a cluster of nine nodes:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ perf stat ./hbase/bin/hbase --config ~/conf_hbase org.apache.hadoop.hbase.wal.WALPerformanceEvaluation
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Here is the end of the log from the UNPATCHED run (master branch as of now):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
...
-- Histograms ------------------------------------------------------------------
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.latencyHistogram.nanos
             count = 1000000
               min = 513398
               max = 2166155
              mean = 721937.32
            stddev = 97572.13
            median = 717876.00
              75% &amp;lt;= 775738.00
              95% &amp;lt;= 869750.00
              98% &amp;lt;= 912876.00
              99% &amp;lt;= 950262.00
            99.9% &amp;lt;= 1314831.00
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.syncCountHistogram.countPerSync
             count = 1000008
               min = 1
               max = 1
              mean = 1.00
            stddev = 0.00
            median = 1.00
              75% &amp;lt;= 1.00
              95% &amp;lt;= 1.00
              98% &amp;lt;= 1.00
              99% &amp;lt;= 1.00
            99.9% &amp;lt;= 1.00
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.syncHistogram.nanos-between-syncs
             count = 1000008
               min = 453139
               max = 1871512
              mean = 639040.49
            stddev = 88377.41
            median = 633963.00
              75% &amp;lt;= 689163.00
              95% &amp;lt;= 764942.00
              98% &amp;lt;= 805957.00
              99% &amp;lt;= 836714.00
            99.9% &amp;lt;= 1871512.00


     -- Meters ----------------------------------------------------------------------
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.appendMeter.bytes
             count = 557000000
         mean rate = 763472.57 events/second
     1-minute rate = 763802.93 events/second
     5-minute rate = 699050.48 events/second
    15-minute rate = 424725.42 events/second
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.syncMeter.syncs
             count = 1000008
         mean rate = 1370.69 events/second
     1-minute rate = 1371.30 events/second
     5-minute rate = 1255.04 events/second
    15-minute rate = 762.53 events/second


2016-02-05 15:08:25,746 INFO  [WALPerfEval.logRoller] regionserver.LogRoller: LogRoller exiting.

 Performance counter stats &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &apos;./hbase/bin/hbase --config /home/stack/conf_hbase org.apache.hadoop.hbase.wal.WALPerformanceEvaluation&apos;:

     322385.687852 task-clock                #    0.438 CPUs utilized
         8,158,772 context-switches          #    0.025 M/sec
           575,922 cpu-migrations            #    0.002 M/sec
         3,064,079 page-faults               #    0.010 M/sec
   474,704,238,311 cycles                    #    1.472 GHz
   &amp;lt;not supported&amp;gt; stalled-cycles-frontend
   &amp;lt;not supported&amp;gt; stalled-cycles-backend
   204,341,980,679 instructions              #    0.43  insns per cycle
    36,933,173,991 branches                  #  114.562 M/sec
       787,891,661 branch-misses             #    2.13% of all branches

     735.817239034 seconds time elapsed

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the end of the log from the PATCHED run:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
...

-- Histograms ------------------------------------------------------------------
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.latencyHistogram.nanos
             count = 901306
               min = 156502
               max = 364739
              mean = 231465.79
            stddev = 25166.33
            median = 227923.00
              75% &amp;lt;= 246449.00
              95% &amp;lt;= 274560.00
              98% &amp;lt;= 288228.00
              99% &amp;lt;= 307981.00
            99.9% &amp;lt;= 364739.00
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.syncCountHistogram.countPerSync
             count = 0
               min = 0
               max = 0
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% &amp;lt;= 0.00
              95% &amp;lt;= 0.00
              98% &amp;lt;= 0.00
              99% &amp;lt;= 0.00
            99.9% &amp;lt;= 0.00
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.syncHistogram.nanos-between-syncs
             count = 0
               min = 0
               max = 0
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% &amp;lt;= 0.00
              95% &amp;lt;= 0.00
              98% &amp;lt;= 0.00
              99% &amp;lt;= 0.00
            99.9% &amp;lt;= 0.00

-- Meters ----------------------------------------------------------------------
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.appendMeter.bytes
             count = 502038025
         mean rate = 2283690.25 events/second
     1-minute rate = 2268881.93 events/second
     5-minute rate = 1180418.70 events/second
    15-minute rate = 486667.36 events/second
org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.syncMeter.syncs
             count = 0
         mean rate = 0.00 events/second
     1-minute rate = 0.00 events/second
     5-minute rate = 0.00 events/second
    15-minute rate = 0.00 events/second

 Performance counter stats &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &apos;./hbase/bin/hbase --config /home/stack/conf_hbase org.apache.hadoop.hbase.wal.WALPerformanceEvaluation&apos;:

     256123.078857 task-clock                #    1.030 CPUs utilized
         3,359,633 context-switches          #    0.013 M/sec
            65,083 cpu-migrations            #    0.254 K/sec
         3,144,010 page-faults               #    0.012 M/sec
   412,859,061,607 cycles                    #    1.612 GHz
   &amp;lt;not supported&amp;gt; stalled-cycles-frontend
   &amp;lt;not supported&amp;gt; stalled-cycles-backend
   199,715,055,614 instructions              #    0.48  insns per cycle
    36,232,946,697 branches                  #  141.467 M/sec
       461,875,115 branch-misses             #    1.27% of all branches

     248.692785230 seconds time elapsed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15135272" author="eclark" created="Fri, 5 Feb 2016 23:40:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;or three DNs and RS crash at the same time&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This isn&apos;t enough for data loss of things that have been sent to write but not flushed. The kernel will always clean up the page cache for you if it is able. You can kill -9 all the datanodes that you want at exactly the same time and not lose anything that&apos;s been acked by the datanodes.&lt;/p&gt;

&lt;p&gt;To lose data on crash it needs to be hardware issues at the same time, kernel bug such that clean up is not performed, or power failure.&lt;/p&gt;</comment>
                            <comment id="15135485" author="apache9" created="Sat, 6 Feb 2016 02:38:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; AFAIK, the ack of hflush only means that datanode has received the packet. Here is the comments of hflush method in DFSOutputStream.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   * Flushes out to all replicas of the block. The data is in the buffers
   * of the DNs but not necessarily in the DN&apos;s OS buffers.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And in BlockReceiver&apos;s receivePacket method, you can see this&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;BlockReceiver.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// put in queue &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; pending acks, unless sync was requested
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (responder != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; !syncBlock &amp;amp;&amp;amp; !shouldVerifyChecksum()) {
      ((PacketResponder) responder.getRunnable()).enqueue(seqno,
          lastPacketInBlock, offsetInBlock, Status.SUCCESS);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is happened before we write the data out, so theoretically it is possible that we get ack back from the pipeline but the actual data has not been written out yet. And in the real world, the latency of network is much greater than local disk io so when you get ack back from the pipeline then usually the data should have already been written out. That&apos;s why &apos;kill -9&apos; does not loss data most times. But theoretically, it could...&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15135501" author="apache9" created="Sat, 6 Feb 2016 02:54:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; Oh there is a WALPE tool, I didn&apos;t know it before, I have run a randomWrite test in the PerformanceEvaluation tool...&lt;/p&gt;

&lt;p&gt;The code quality is not good enough for merging it now. And there are two problems before I start working on preparing a patch&lt;/p&gt;

&lt;p&gt;1. Where should we place the FanOut stream. I use lots of reflection and some methods only visible to tests in HDFS to implement the new stream. Since we could get a better performance, is it enough to make HDFS guys accept it as part of the HDFS project?&lt;/p&gt;

&lt;p&gt;2. I do not introduce a new WALProvider. Since it still writes data on HDFS, I just introduce an AsyncFSHLog which shares a base class(AbstractFSHLog in the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14790&quot; title=&quot;Implement a new DFSOutputStream for logging WAL only&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14790&quot;&gt;HBASE-14790&lt;/a&gt; branch) of FSHLog and add a flag to tell DefaultWALProvider it should use FSHLog or AsyncFSHLog. And also, I introduce a new AsyncWriter interface. The append method of AsyncWriter only buffers data in memory. What do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;? Do you guys have other ideas of how to integrate the async logic in WAL?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15135542" author="stack" created="Sat, 6 Feb 2016 03:40:51 +0000"  >&lt;p&gt;First, what you think of the 2x number? I think it is kinda cool.&lt;/p&gt;

&lt;p&gt;On #1, would be cool if we could have something working here first, even if reflection (we have loads of that already). Then we go to the HDFS lads. Our using it and 2x perf will be a good story to tell.&lt;/p&gt;

&lt;p&gt;On #2, how hard to do as a WALProvider? You know my story on &apos;options&apos;. A flag in DefaultWALProvider is probably fine for a while but we should just cut over to async unless you can think of downsides.&lt;/p&gt;

&lt;p&gt;Want a review now or should I wait?&lt;/p&gt;</comment>
                            <comment id="15135606" author="apache9" created="Sat, 6 Feb 2016 05:19:52 +0000"  >&lt;p&gt;Fine. Let&apos;s do it in HBase.&lt;/p&gt;

&lt;p&gt;A little problem is that if we get an error then the only way to close the file is calling recoverLease. The reason is that I do not want to resend data to datanode but in the current DTP there is no way to truncate block data from client side so the only way to make a consensus on the block length is calling recoverLease... In the new design, so this is not a big problem.&lt;/p&gt;

&lt;p&gt;And also, we need to resolve &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14949&quot; title=&quot;Resolve name conflict when splitting if there are duplicated WAL entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14949&quot;&gt;&lt;del&gt;HBASE-14949&lt;/del&gt;&lt;/a&gt; first before applying this patch. In the current implementation, we do not do pipeline recovery, so it is easier for us to meet a sync failure. If we simply fail the sync request, we will also easier to meet the inconsistency... So here we need the logic described in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14004&quot; title=&quot;[Replication] Inconsistency between Memstore and WAL may result in data in remote cluster that is not in the origin&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14004&quot;&gt;HBASE-14004&lt;/a&gt;, write the unacked entries to new WAL file if sync failed. This will lead to the problem described in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14949&quot; title=&quot;Resolve name conflict when splitting if there are duplicated WAL entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14949&quot;&gt;&lt;del&gt;HBASE-14949&lt;/del&gt;&lt;/a&gt; that we may have two WAL files with different data mapping to the same name when splitting.&lt;/p&gt;

&lt;p&gt;On the implementation, the problem is I need to share lots of code of the original FSHLog and other related classes. But this should not be a blocker, let me try implementing a new WALProvider next.&lt;/p&gt;

&lt;p&gt;And for the reviewing, you just do it on Github? Or I upload it here and on reviewboard? I&apos;m always happy with a review. Thanks.&lt;/p&gt;</comment>
                            <comment id="15136961" author="eclark" created="Mon, 8 Feb 2016 13:54:32 +0000"  >&lt;p&gt;For any data that HBase will ever consider to be durable we will have called hsync (excluding edits that explicitly have it turned off). That turns DFSOutputStream isSync = true. That will be mean that syncBlock is true in the above code. That will mean that all data before the sync is in the kernel&apos;s page cache. Any data that&apos;s only appended but not synced will never send a result to the client for HBase.&lt;/p&gt;</comment>
                            <comment id="15136985" author="apache9" created="Mon, 8 Feb 2016 14:14:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; This is the implementation of &lt;tt&gt;ProtobufLogWriter.sync&lt;/tt&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;ProtobufLogWriter.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void sync() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    FSDataOutputStream fsdos = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.output;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (fsdos == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// Presume closed
&lt;/span&gt;    fsdos.flush();
    fsdos.hflush();
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We only call hflush here? And yes, hsync has its benefits, but it is really slow...&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15136991" author="eclark" created="Mon, 8 Feb 2016 14:26:25 +0000"  >&lt;p&gt;I was looking at WALProcedure rather than protobuf.&lt;br/&gt;
Yeah we really need something between hflush and hsync. The current behavior is just wrong and broken :-/&lt;/p&gt;</comment>
                            <comment id="15137286" author="carp84" created="Mon, 8 Feb 2016 17:28:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yeah we really need something between hflush and hsync. The current behavior is just wrong and broken&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I guess &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5954&quot; title=&quot;Allow proper fsync support for HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5954&quot;&gt;&lt;del&gt;HBASE-5954&lt;/del&gt;&lt;/a&gt; is following this topic? I believe the real hsync will be used when hardware improves to some extent (actually we already see promising result with PCIe SSD), but not sure how much longer we still need to wait. On the other hand, IMHO a fan-out DFSOutputStream is nice to have for write performance, no matter using hflush or hsync. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15145631" author="zhz" created="Sat, 13 Feb 2016 00:46:00 +0000"  >&lt;p&gt;Nice work here &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt;. By quickly browsing through the code, I assume the error handling logics will be added later right? E.g. gen stamp bumping, token renewal.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yeah we really need something between hflush and hsync. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;ve been thinking about adding a parameter to hflush/hsync to specify the level. E.g. flush to 3 DNs but sync on at least 1 of them. Would that help?&lt;/p&gt;</comment>
                            <comment id="15145757" author="apache9" created="Sat, 13 Feb 2016 03:35:54 +0000"  >&lt;blockquote&gt;
&lt;p&gt; E.g. gen stamp bumping, token renewal.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, this should be done but it requires changing in HDFS. Add a &lt;tt&gt;truncateToMinRcvdBytes&lt;/tt&gt; flag to &lt;tt&gt;OpWriteBlockProto&lt;/tt&gt;, and the operations when error occurred will be&lt;/p&gt;

&lt;p&gt;1. close all connections to datanode.&lt;br/&gt;
2. bump GS at namenode&lt;br/&gt;
3. connect to datanode with the new GS to tell datanode also bump GS and truncate block size to minRcvdBytes&lt;br/&gt;
4. end block&lt;br/&gt;
5. complete file at namenode wth minRcvdBytes&lt;/p&gt;

&lt;p&gt;Of course, stage 3 and 4 could be done with one ping-pong with some efforts.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12401274">HDFS-223</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12841977">HBASE-14004</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12446398">HDFS-916</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="12920002">HBASE-14949</subtask>
                            <subtask id="12938998">HBASE-15264</subtask>
                            <subtask id="12938999">HBASE-15265</subtask>
                            <subtask id="12947597">HBASE-15407</subtask>
                            <subtask id="12951981">HBASE-15495</subtask>
                            <subtask id="12953731">HBASE-15536</subtask>
                            <subtask id="12953732">HBASE-15537</subtask>
                            <subtask id="12953733">HBASE-15538</subtask>
                            <subtask id="12957657">HBASE-15628</subtask>
                            <subtask id="12962465">HBASE-15709</subtask>
                            <subtask id="12964142">HBASE-15743</subtask>
                            <subtask id="12964518">HBASE-15754</subtask>
                            <subtask id="12967270">HBASE-15813</subtask>
                            <subtask id="13013981">HBASE-16890</subtask>
                            <subtask id="13013983">HBASE-16891</subtask>
                            <subtask id="13016312">HBASE-16968</subtask>
                            <subtask id="13018053">HBASE-17021</subtask>
                            <subtask id="13018683">HBASE-17035</subtask>
                            <subtask id="13019196">HBASE-17048</subtask>
                            <subtask id="13019207">HBASE-17049</subtask>
                            <subtask id="13019443">HBASE-17053</subtask>
                            <subtask id="13020354">HBASE-17085</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Nov 2015 09:39:57 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            43 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2o6c7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>