<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:34:57 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6233/HBASE-6233.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6233] [brainstorm] snapshots: hardlink alternatives</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6233</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Discussion ticket around snapshots and hardlink alternatives.&lt;br/&gt;
(See the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3370&quot; title=&quot;HDFS hardlink&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3370&quot;&gt;HDFS-3370&lt;/a&gt; discussion about hardlink and implementation problems)&lt;/p&gt;

&lt;p&gt;(taking for a moment WAL out of the discussion and focusing on hfiles)&lt;br/&gt;
With hardlinks available taking snapshot will be fairly easy:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;(hfiles are immutable)&lt;/li&gt;
	&lt;li&gt;hardlink to .snapshot/name to take snapshot&lt;/li&gt;
	&lt;li&gt;hardlink from .snapshot/name to restore the snapshot&lt;/li&gt;
	&lt;li&gt;No code change needed (on fs.delete() only one reference is deleted)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but we don&apos;t have hardlinks, what are the alternatives?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12594981">HBASE-6233</key>
            <summary>[brainstorm] snapshots: hardlink alternatives</summary>
                <type id="13" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Brainstorming</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="mbertozzi">Matteo Bertozzi</assignee>
                                    <reporter username="mbertozzi">Matteo Bertozzi</reporter>
                        <labels>
                    </labels>
                <created>Mon, 18 Jun 2012 18:30:25 +0000</created>
                <updated>Thu, 2 May 2013 02:30:52 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="13396133" author="mbertozzi" created="Mon, 18 Jun 2012 18:49:51 +0000"  >&lt;p&gt;Taking a snapshot means keeping references to hfiles currently present in the table. &lt;br/&gt;
Unfortunately during compaction and split these file can be removed from the original location.&lt;/p&gt;

&lt;p&gt;One solution can be:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;move hfiles to .snapshot/files directory, during the &quot;take snapshot&quot; operation&lt;/li&gt;
	&lt;li&gt;create symlinks to .snapshot/files in the table folder.&lt;/li&gt;
	&lt;li&gt;create the snapshot reference in .snapshot/name/files&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This allows to restore snapshot easily by creating a symlink. &lt;br/&gt;
The hbase code will not change since compaction can still call fs.delete() and ends up deleting just the symlink&lt;/p&gt;

&lt;p&gt;One problem is that during the fs.rename() + fs.createSymlink() the filename is not available and if DFSInputStream.callGetBlockLocations() is called you end up with a FileNotFoundException.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;But this means that after a snapshot the files in the table folder are symlink, so you&apos;ll see both normal files + symlink during the table life.&lt;/em&gt;&lt;/p&gt;</comment>
                            <comment id="13401118" author="jmhsieh" created="Tue, 26 Jun 2012 02:30:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;  Are you suggesting that .snapshot/files is a separate directory from the actual snapshot dirs such that the .snapshot/files dir be all the files, and both the real table and the snapshot tables use symlinks?&lt;/p&gt;

&lt;p&gt;Would it be ok for a files reading from a snapshot mount to take the exception and then retry by reopening at the other location?  &lt;/p&gt;
</comment>
                            <comment id="13401198" author="mbertozzi" created="Tue, 26 Jun 2012 06:37:35 +0000"  >&lt;p&gt;@Jon&lt;br/&gt;
Yes on &quot;Take snapshot&quot; you rename the hfile to .snapshot/files directory and replace it with a symlink.&lt;br/&gt;
Also you need to create a symlink in .snapshot/name/ folder (the one that describe the snapshot).&lt;br/&gt;
When you want to restore you have just to create a symlink of the file.&lt;/p&gt;

&lt;p&gt;I see two advantages for using this approach:&lt;br/&gt;
One is code remain unchanged fs.delete() stay fs.delete() (all the &quot;symlink&quot; code is done in takeSnapshot() and nothing change from the hbase point of view)&lt;/p&gt;

&lt;p&gt;The other one is: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase 0.96 ship with snapshots (hardlink alternative)&lt;/li&gt;
	&lt;li&gt;hbase 0.98 ship with snapshot + hdfs hardlink&lt;br/&gt;
If you use the approach that I&apos;ve described a user that have taken snapshots using 0.96 doesn&apos;t have to do nothing special to migrate to 0.98. symlink to .snapshot/files/ keeps to work. And the future &apos;take snapshot&apos; just create hardlink in .snapshot/name/ and restore as another hardlink against .snapshot/name&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In the other case (take the exception and retry) you need to keep the logic in 0.98 or do some fancy script that search for the &quot;Reference&quot; files and replace with the hardlink.&lt;/p&gt;</comment>
                            <comment id="13401204" author="zhihyu@ebaysf.com" created="Tue, 26 Jun 2012 06:57:44 +0000"  >&lt;p&gt;From discussion of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3370&quot; title=&quot;HDFS hardlink&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3370&quot;&gt;HDFS-3370&lt;/a&gt;, it is unknown when hdfs hardlink would get accepted.&lt;/p&gt;</comment>
                            <comment id="13408703" author="mbertozzi" created="Sat, 7 Jul 2012 16:21:05 +0000"  >&lt;p&gt;I&apos;ve attached a document that tries to describe the hardlink alternatives (Reference Files, .META. Ref-count, Move &amp;amp; SymLink) in relation to the restore and mount operations.&lt;/p&gt;</comment>
                            <comment id="13408711" author="zhihyu@ebaysf.com" created="Sat, 7 Jul 2012 16:32:02 +0000"  >&lt;p&gt;Nice writeup.&lt;br/&gt;
Although we don&apos;t know when &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3370&quot; title=&quot;HDFS hardlink&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-3370&quot;&gt;HDFS-3370&lt;/a&gt; would be implemented, hdfs snapshot v1 would be delivered later this year.&lt;br/&gt;
Do we want to incur extra complexity in our codebase for the hadoop versions where there is no hdfs snapshot ?&lt;/p&gt;</comment>
                            <comment id="13408716" author="mbertozzi" created="Sat, 7 Jul 2012 16:57:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Do we want to incur extra complexity in our codebase for the hadoop versions where there is no hdfs snapshot?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Are you talking about hdfs snapshot or hdfs hardlink?&lt;/p&gt;

&lt;p&gt;I don&apos;t think that hbase can rely on hdfs snapshot (E.g. memstore, region info, need to be handled in a special way)&lt;/p&gt;

&lt;p&gt;For the missing hdfs hardlink support, I think that what I&apos;m trying to propose simplify a lot the snapshot, since we don&apos;t need to change the current code to handle hfile deletions.&lt;/p&gt;

&lt;p&gt;but I want some feedback on this, anyone has other suggestions/ideas?&lt;/p&gt;</comment>
                            <comment id="13408718" author="zhihyu@ebaysf.com" created="Sat, 7 Jul 2012 17:00:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;Are you talking about hdfs snapshot or hdfs hardlink?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;hdfs snapshot. I have a sense that hdfs hardlink wouldn&apos;t make it into open source.&lt;/p&gt;

&lt;p&gt;One other aspect is the timing of releases for hdfs snapshot and HBase snapshot (0.96 presumably). If the two are close enough (or hdfs snapshot being earlier a little), does it make sense to recommend customers upgrade both hdfs and HBase at the same time ?&lt;/p&gt;</comment>
                            <comment id="13408746" author="zhihyu@ebaysf.com" created="Sat, 7 Jul 2012 19:10:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;But we can have a cleanup &#8220;tool&#8221; as the other alternatives (Reference Files, .META refcount).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So structural changes are needed for symlink approach to work. We should carefully evaluate the pros and cons of maintaining this new logic.&lt;/p&gt;</comment>
                            <comment id="13408749" author="mbertozzi" created="Sat, 7 Jul 2012 19:22:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;So structural changes are needed for symlink approach to work. We should carefully evaluate the pros and cons of maintaining this new logic.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The cleanup is needed only to remove archived hfiles used by the snapshots,&lt;br/&gt;
and can be an external tool or an internal thread that scan the snapshot.&lt;br/&gt;
Is not only for the symlink approach but for all three, with the exception for .META. refcount that can run a fs.delete() automatically when refcount reaches zero.&lt;/p&gt;

&lt;p&gt;(In the Jesse implementation &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6055&quot; title=&quot;Offline Snapshots in HBase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6055&quot;&gt;&lt;del&gt;HBASE-6055&lt;/del&gt;&lt;/a&gt; there&apos;s already a cleanup tool implemented)&lt;/p&gt;</comment>
                            <comment id="13408762" author="stack" created="Sat, 7 Jul 2012 19:59:26 +0000"  >&lt;p&gt;@Matteo Thanks for taking the time to do the writeup.  Helpful.  I like how your symlink work would make it so no work moving up on to hdfs hard links.&lt;/p&gt;

&lt;p&gt;I was wondering if you have any concern around creation of all the symlinks on a table of some decent size taking a good bit of time Matteo?  The window during which the snapshot is being made could be pretty wide.  Would that be a problem?&lt;/p&gt;

&lt;p&gt;You ask for ideas and the only one I have is the hackneyed one copied from bdbje where on compaction, we do not delete files; rather we just rename them w/ a &apos;.del&apos; ending and leave them in place.  On snapshot, we make a manifest of all files in the table.  On restore, we&apos;d read the manifest and look for files first w/o the .del and then if not found, with the .del.  I&apos;ve not thought it all through to the extent of your attached pdf &amp;#8211; I can see how it could get tangled pretty quickly &amp;#8211; but throwing it up there since you were asking.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...and can be an external tool or an internal thread that scan the snapshot.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Could hitch a ride on the current meta scanner, the one that cleans the parent regions from .META.&lt;/p&gt;

&lt;p&gt;Adding list of files to .META. might make for our being able to do other fancyness such as the Accumulo fast table copy, etc.&lt;/p&gt;

&lt;p&gt;Let me read your doc. some more (and Jesse&apos;s work).&lt;/p&gt;
</comment>
                            <comment id="13408763" author="mbertozzi" created="Sat, 7 Jul 2012 20:04:09 +0000"  >&lt;blockquote&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13408764" author="mbertozzi" created="Sat, 7 Jul 2012 20:14:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;I was wondering if you have any concern around creation of all the symlinks on a table of some decent size taking a good bit of time Matteo? The window during which the snapshot is being made could be pretty wide. Would that be a problem?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The time is (fs.rename() * nfiles + fs.symlink() * nfiles), but is just a metadata operation on HDFS. I don&apos;t have the times for how long it takes but I can come up with some benchmark, maybe with hdfs under heavy load.&lt;/p&gt;

&lt;p&gt;Anyway, you need to keep track of the files in some way: create one reference file for each files or add a reference in .META. and both seems much more heavier since they require interaction with both namenode + datanode.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we do not delete files; rather we just rename them w/ a &apos;.del&apos; ending and leave them in place.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;But if you want to remove the table this files should be moved.&lt;br/&gt;
And by doing this you need to add some logic to the current code to don&apos;t read the .del files&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Adding list of files to .META. might make for our being able to do other fancyness such as the Accumulo fast table copy, etc.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The accumulo clone table is one of the feature that we can easily get with snapshots.&lt;br/&gt;
I&apos;ve called it &quot;mount snapshot&quot; that essentially is the accumulo clone table. (Take a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6353&quot; title=&quot;Snapshots shell&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6353&quot;&gt;&lt;del&gt;HBASE-6353&lt;/del&gt;&lt;/a&gt;, for a description of the snapshot operations).&lt;/p&gt;

&lt;p&gt;Again, if you think at restore with the hardlink support you can easily have everything. So we just need to come up with an alternative to hardlink.&lt;/p&gt;</comment>
                            <comment id="13408771" author="stack" created="Sat, 7 Jul 2012 20:58:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;The time is (fs.rename() * nfiles + fs.symlink() * nfiles), but is just a metadata operation on HDFS.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can take a while I&apos;ve found.  Something to be aware of.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;And by doing this you need to add some logic to the current code to don&apos;t read the .del files&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.  It&apos;d be ugly especially compared to symlinking w/ refcounting.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So we just need to come up with an alternative to hardlink....&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Smile.  Yes.&lt;/p&gt;</comment>
                            <comment id="13409066" author="stack" created="Sun, 8 Jul 2012 21:17:29 +0000"  >&lt;p&gt;Looking at the doc. again:&lt;/p&gt;

&lt;p&gt;Is there a table dir missing from this: &quot;&#9679; /hbase/.snapshots/&amp;lt;snapshot name&amp;gt;/&amp;lt;region&amp;gt;/&amp;lt;cf&amp;gt;/&amp;lt;hfiles&amp;gt;&quot;?&lt;/p&gt;

&lt;p&gt;We have a filter in front of Filesystem now, HFileSystem.  We could instrument &apos;delete&apos; moving file rather than deleting it a snapshot has happened and we want to keep deleted files around.  I thought we could implement link here too calling through if reflection determines it present and doing whatever the alternative is when its not there (would be some ugly casting to HFileSystem I suppose).&lt;/p&gt;

&lt;p&gt;Its 1000ft view, I know, but restoring snapshot, won&apos;t we have to create the table directory structure to move the hardlinked hfiles back into place?&lt;/p&gt;

&lt;p&gt;On keeping refcount in .META., Enis&apos;s suggestion over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6205&quot; title=&quot;Support an option to keep data of dropped table for some time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6205&quot;&gt;&lt;del&gt;HBASE-6205&lt;/del&gt;&lt;/a&gt;...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When a file is deleted due to a compaction/region deletion we need to move that file somewhere and update all the references.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Also having lots of file can slow down the .META. operations.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We have to move it?  We can&apos;t just decrement references?  We&apos;d have to undo the association of files with particular regions &amp;#8211; the layout under $&lt;/p&gt;
{HBASE.ROOTDIR}
&lt;p&gt; would not be as it is now.  We&apos;d present a logical view that was detached from how the hfiles were stored in hdfs.&lt;/p&gt;

&lt;p&gt;Other advantages of the refcount in .META. would be no need of moving files around or of keeping refs in hdfs... as many refs as snapshots.&lt;/p&gt;

&lt;p&gt;I think the below will take a good amount of time on a loaded table of significant size (say ten region cluster with a table with 100 regions per node with say two column families with say three storefiles each):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&#9675; Move the hfile to archive
&#9675; Create a symlink to point to the archived file
&#9675; Create a symlink &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the snapshot
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Even meta operations on namenode can take a good bit of time.&lt;/p&gt;

&lt;p&gt;Restores would be fast (You can symlink a directory? I&apos;ve not used them).&lt;/p&gt;

&lt;p&gt;Reference files does have the advantage you suggest that it&apos;ll be easy to move to hardlinks from symlinks (but again, I see the ops taking a long time, even if just meta ops &amp;#8211; is it ok that a snapshot takes a good amount of time... minutes?)&lt;/p&gt;

&lt;p&gt;Your doc. is good Matteo.&lt;br/&gt;
I think it&apos;ll take &lt;/p&gt;</comment>
                            <comment id="13409212" author="mbertozzi" created="Mon, 9 Jul 2012 06:21:15 +0000"  >&lt;blockquote&gt;
&lt;p&gt;We have to move it? We can&apos;t just decrement references? We&apos;d have to undo the association of files with particular regions &#8211; the layout under HBASE.ROOTDIR would not be as it is now. We&apos;d present a logical view that was detached from how the hfiles were stored in hdfs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 on this. If we&apos;re going to change the HBASE.ROOTDIR layout everything will be much easier. Since we just need a &quot;flat&quot; folder that contains all the hfiles and each table can keep track of its own file by scanning .META. in this way we can really use the ref-count and we don&apos;t have to move the files around.&lt;/p&gt;

&lt;p&gt;But again, this require code changes and changes in how the data is stored (What are the policy for compatibility?).&lt;br/&gt;
Also while fixing .META. problems with hbck is useful to look inside the the /hbase/&amp;lt;table&amp;gt; directory to see which files are present in a particoular table.&lt;/p&gt;</comment>
                            <comment id="13409257" author="stack" created="Mon, 9 Jul 2012 07:56:29 +0000"  >&lt;p&gt;It&apos;d be a radical change Matteo.  It feels like a hbase 2.0 kinda thing rather than a 0.96-type change (But this is a &apos;brainstorm&apos; issue so we have license to talk hypotheticals).&lt;/p&gt;

&lt;p&gt;I think we could auto-migrate from the one format to the new; new hfiles would be written into new location in hdfs while we&apos;d read the old unmigrated hfiles from the old layout (&quot;Policy&quot; for compatibility up to this is that versions go forward perhaps w/ a &quot;migration step&quot; but preferably not and we do not have to support reverting an upgrade... thats &quot;policy&quot; so far).&lt;/p&gt;

&lt;p&gt;Would we need x-row transactions updating files in .META.?  I don&apos;t think so.  Read/write locks might be enough.&lt;/p&gt;

&lt;p&gt;We might need to let .META. split now that it can grow largish fast.&lt;/p&gt;

&lt;p&gt;We&apos;ve had &quot;interesting&quot; issues updating .META. in the past: e.g. socket timeout on client side but the edit went through anyways.... that kinda thing.  Now the repercussions of failed or false positive fail will be larger?&lt;/p&gt;

&lt;p&gt;Yeah, instead of looking inside hdfs, hbck will have to read .META.  In hdfs, we&apos;d still have tables and regions, or not?&lt;/p&gt;


</comment>
                            <comment id="13409672" author="mbertozzi" created="Mon, 9 Jul 2012 17:42:46 +0000"  >&lt;p&gt;Updated the doc to cover the different hbase.root file-system layout idea.&lt;br/&gt;
Removed the extra symlink for snapshot in the &quot;Move &amp;amp; Symlink&quot; approach.&lt;br/&gt;
And added some notes about why we can&apos;t just rely on .META. refcount with the current layout.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12594958">HBASE-6230</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12556488">HBASE-6055</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12535702" name="Restore-Snapshot-Hardlink-alternatives-v2.pdf" size="97577" author="mbertozzi" created="Mon, 9 Jul 2012 17:42:46 +0000"/>
                            <attachment id="12535535" name="Restore-Snapshot-Hardlink-alternatives.pdf" size="92478" author="mbertozzi" created="Sat, 7 Jul 2012 16:21:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 26 Jun 2012 02:30:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>241710</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 23 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02ban:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11431</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>