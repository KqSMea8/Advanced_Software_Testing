<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:01:54 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2437/HBASE-2437.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2437] Refactor HLog splitLog</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2437</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;the HLog.splitLog got really long and complex and hard to verify for correctness. &lt;br/&gt;
I started to refactor it and also ported changes from hbase-2337 that deals with premature deletion of log files in case of errors. Further improvements will be possible, however the scope of this issue is to clean the code and make it behave correctly (i.e. not lose any edits)  &lt;/p&gt;

&lt;p&gt;Added a suite of unit tests that might be ported to 0.20 as well.&lt;/p&gt;

&lt;p&gt;Added a setting (hbase.skip.errors - feel free to suggest a better name) that, when set to false will make the process less tolerant to failures or corrupted files:  in case a log file is corrupted or an error stops the process from consistently splitting the log, will abort the entire operation to avoid losing any edits. When hbase.skip.errors is on any corrupted files will be partially parsed and then moved to the corrupted logs archive (see hbase-2337). &lt;/p&gt;

&lt;p&gt;Like hbase-2337 the splitLog method will first split all the logs and then proceed to archive them. If any splitted log file (oldlogfile.log) that is the result of an earlier splitLog attempt is found in the region directory, it will be deleted - this is safe since we won&apos;t move the original log files until the splitLog process completes.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12461944">HBASE-2437</key>
            <summary>Refactor HLog splitLog</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="clehene">Cosmin Lehene</assignee>
                                    <reporter username="clehene">Cosmin Lehene</reporter>
                        <labels>
                    </labels>
                <created>Tue, 13 Apr 2010 12:06:25 +0000</created>
                <updated>Fri, 20 Nov 2015 12:43:48 +0000</updated>
                            <resolved>Tue, 1 Jun 2010 18:02:33 +0000</resolved>
                                    <version>0.90.0</version>
                                    <fixVersion>0.90.0</fixVersion>
                                    <component>master</component>
                        <due>Tue, 20 Apr 2010 04:00:00 +0000</due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                    <timeoriginalestimate seconds="432000">120h</timeoriginalestimate>
                            <timeestimate seconds="432000">120h</timeestimate>
                                        <comments>
                            <comment id="12856395" author="clehene" created="Tue, 13 Apr 2010 12:07:38 +0000"  >&lt;p&gt;This issue will incorporate some of the changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2337&quot; title=&quot;log recovery: splitLog deletes old logs prematurely&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2337&quot;&gt;&lt;del&gt;HBASE-2337&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12856456" author="apurtell" created="Tue, 13 Apr 2010 16:02:42 +0000"  >&lt;p&gt;Cosmin, thanks for taking this on. We&apos;re aiming for 0.20.5 to be branch&apos;s answer to data durability and correctness issues. So that starts with &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-200&quot; title=&quot;In HDFS, sync() not yet guarantees data available to the new readers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-200&quot;&gt;&lt;del&gt;HDFS-200&lt;/del&gt;&lt;/a&gt; and related issues, but all issues which affect probability of data loss should be rolled in as well.  What do you think about targeting your changes for that release also? &lt;/p&gt;</comment>
                            <comment id="12856749" author="stack" created="Wed, 14 Apr 2010 04:46:17 +0000"  >&lt;p&gt;Does fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2442&quot; title=&quot;Log lease recovery catches IOException too widely&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2442&quot;&gt;&lt;del&gt;HBASE-2442&lt;/del&gt;&lt;/a&gt; belong in here Cosmin?&lt;/p&gt;</comment>
                            <comment id="12857199" author="clehene" created="Thu, 15 Apr 2010 06:34:19 +0000"  >&lt;p&gt;I haven&apos;t use recoverLog because it was failing in my unit tests. So I don&apos;t check size at all and just catch EOF when opening the reader.&lt;/p&gt;</comment>
                            <comment id="12857202" author="clehene" created="Thu, 15 Apr 2010 06:38:56 +0000"  >&lt;p&gt;Andrew, I think &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2337&quot; title=&quot;log recovery: splitLog deletes old logs prematurely&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2337&quot;&gt;&lt;del&gt;HBASE-2337&lt;/del&gt;&lt;/a&gt; addresses most problems already. I think we could reuse the unit tests I&apos;m writing for 0.20 branch and fix if necessary. &lt;/p&gt;</comment>
                            <comment id="12859570" author="tlipcon" created="Wed, 21 Apr 2010 22:55:17 +0000"  >&lt;p&gt;How&apos;s this going, Cosmin? I&apos;m itching to fix a couple bugs in error handling during log splitting and don&apos;t want to duplicate work.&lt;/p&gt;</comment>
                            <comment id="12859691" author="clehene" created="Thu, 22 Apr 2010 07:17:15 +0000"  >&lt;p&gt;Todd, I&apos;m sending the pach today. It still needs a little work, but the refactoring is done and could use a review, so we could coordinate. &lt;/p&gt;</comment>
                            <comment id="12859933" author="clehene" created="Thu, 22 Apr 2010 18:12:39 +0000"  >&lt;p&gt;The patch is not final, so intended for trunk, but I&apos;d appreciate a code review.&lt;/p&gt;

&lt;p&gt;some of the changes:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;splitLog was refactored - the logic can be followed easier now&lt;/li&gt;
	&lt;li&gt;logs are left in place is something goes wrong&lt;/li&gt;
	&lt;li&gt;if split is interrupted, or crashes, the second split will start from zero (having all original log files), hence will delete any oldlogfile.log found  under the regionserver if any.&lt;/li&gt;
	&lt;li&gt;protect from zombie HRS that writes some more to hlog after split started (using recoverLog)&lt;/li&gt;
	&lt;li&gt;protect from deleting a log file that was created by a zombie HRS after split has started.&lt;/li&gt;
	&lt;li&gt;skip.errors=true means whenever something goes wrong and might lose edits we abort leaving logs in place&lt;/li&gt;
	&lt;li&gt;skip.errors=false tolerate some errors: if a corrupted hlog file is encountered, read what you can and continue, then archive the corrupted log file.&lt;/li&gt;
	&lt;li&gt;deal with empty log files&lt;/li&gt;
	&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;added unit test for the above mentioned&lt;/li&gt;
	&lt;li&gt;unit test class has tools to generate log files, leave them open, corrupt them, etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The unit (or rather integration) tests are designed for hdfs-0.21, but could be adapted with small changes.&lt;/p&gt;

&lt;p&gt;I initially did the refactoring trying to avoid the recoverLog method (that opens the file for append, then closes it to make sure a file is closed) because it took to long to wait for the lease. However if a regionserver that was considered dead (zombie) keeps writing to those files, the only way to work around that so we won&apos;t lose edits is to make sure it&apos;s closed (Trying to rename the file before splitting it will allow a writer thread to keep writing even after the rename for a few seconds.) I created testLogCannotBeWrittenOnceParsed for this.&lt;/p&gt;


&lt;p&gt;In unit tests I set the lease period for a file to 100ms in the setUp method to avoid waiting 60 seconds in the unit tests. &lt;br/&gt;
getDFSCluster().getNamesystem().leaseManager.setLeasePeriod(100, 50000);&lt;/p&gt;

&lt;p&gt;Apparently on hdfs-0.20 getNameSystem is not available.&lt;/p&gt;

&lt;p&gt;Also I use hflush() in unit test to write data to a log file and then leave it open. If not flushed and left open the changes might not be seen by the reader.  hflush() could be avoided if the open file scenarios could be ignored. &lt;/p&gt;</comment>
                            <comment id="12863674" author="stack" created="Tue, 4 May 2010 05:37:25 +0000"  >&lt;p&gt;Patch looks great.&lt;/p&gt;

&lt;p&gt;+ Please change the name of this file as part of your refactoring &quot;oldlogfile.log&quot;&lt;br/&gt;
+ &quot;logs are left in place is something goes wrong&quot; .. should they be moved aside?&lt;br/&gt;
+ HBaseTestingUtility has been splintered into smaller pieces since you made this patch so these additions of yours fit well with that general direction.&lt;br/&gt;
+ I love all the tests.  I like name of this thread: ZombieLastLogWriterRegionServer&lt;br/&gt;
+ How does this test, testLogCannotBeWrittenOnceParsed, work?  The ZombieLastLogWriterRegionServer can only write one more edit at most &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; but seems like splitlogs proceeds from the first through to the last as it currently does.  Why couldn&apos;t the old Zombie writer add a bunch of edits to the last file while all other files are being split?&lt;/p&gt;
</comment>
                            <comment id="12863686" author="stack" created="Tue, 4 May 2010 06:10:05 +0000"  >&lt;p&gt;@Cosmin You seen &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2471&quot; title=&quot;Splitting logs, we&amp;#39;ll make an output file though the region no longer exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2471&quot;&gt;&lt;del&gt;HBASE-2471&lt;/del&gt;&lt;/a&gt;?  Related?&lt;/p&gt;</comment>
                            <comment id="12863700" author="clehene" created="Tue, 4 May 2010 07:18:18 +0000"  >&lt;p&gt;@Stack, thanks for the review! &lt;/p&gt;

&lt;p&gt;I&apos;ll incorporate the changes and answer the questions &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Regarding &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2471&quot; title=&quot;Splitting logs, we&amp;#39;ll make an output file though the region no longer exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2471&quot;&gt;&lt;del&gt;HBASE-2471&lt;/del&gt;&lt;/a&gt;. It doesn&apos;t check for the destination directory. I can incorporate it. The unit tests need to be changed to pre-create the region directories. &lt;/p&gt;</comment>
                            <comment id="12863826" author="stack" created="Tue, 4 May 2010 14:38:57 +0000"  >&lt;p&gt;@Cosmin Patch is big.  I need to take another look.  I&apos;d love to get this patch into 0.20.5.  Its great.&lt;/p&gt;</comment>
                            <comment id="12866399" author="posix4e" created="Wed, 12 May 2010 00:13:11 +0000"  >&lt;p&gt;I can&apos;t see to get this to apply to trunk. Is their an update, or should I do it?&lt;/p&gt;</comment>
                            <comment id="12867416" author="stack" created="Fri, 14 May 2010 06:10:47 +0000"  >&lt;p&gt;@Cosmin Any chance of an update.  Now is the time to get this in w/ its fancy tests.  Thanks.&lt;/p&gt;</comment>
                            <comment id="12867455" author="clehene" created="Fri, 14 May 2010 09:39:48 +0000"  >&lt;p&gt;I&apos;m out of office. I&apos;ll get back on the 18th. &lt;/p&gt;



</comment>
                            <comment id="12868345" author="clint.morgan" created="Mon, 17 May 2010 18:54:41 +0000"  >&lt;p&gt;I&apos;ve just been looking at HLog splitting for transactional hbase. I&apos;d like to be able to reuse the same mechanism except the HLog keys change a bit (subclass them), and the log directories are different.&lt;/p&gt;

&lt;p&gt;To allow these extensions, I was factoring the log splitting into its own class (HLogSplitter). And making the methods instance rather than static. This has the additional benefit of isolating this rather tricky splitting concern from HLog, which I think makes it read better IMO.&lt;/p&gt;

&lt;p&gt;Does this sound reasonable? Would you like to do it as part of this patch? Otherwise, I&apos;ll wait until this is applied and propose this approach in another issue.&lt;/p&gt;</comment>
                            <comment id="12868350" author="stack" created="Mon, 17 May 2010 19:04:33 +0000"  >&lt;p&gt;Sounds good to me Clint.  Maybe as separate issue?  I think Cosmin is off around the wilds of the mid-west at moment on holidays.  Hopefully hes not lost forever and we get him back soon.&lt;/p&gt;</comment>
                            <comment id="12868357" author="tlipcon" created="Mon, 17 May 2010 19:22:41 +0000"  >&lt;p&gt;+1 on splitting into a new class. I&apos;m adding some stuff into log splitting logic for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2231&quot; title=&quot;Compaction events should be written to HLog&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2231&quot;&gt;&lt;del&gt;HBASE-2231&lt;/del&gt;&lt;/a&gt; as well, and it&apos;s just messy.&lt;/p&gt;

&lt;p&gt;Does anyone know when Cosmin&apos;s coming back? If he&apos;s not coming back soon, can we have someone finish off this patch for him this week?&lt;/p&gt;</comment>
                            <comment id="12868364" author="stack" created="Mon, 17 May 2010 19:29:01 +0000"  >&lt;p&gt;If he&apos;s not back by morrow, I&apos;ll have a go at it.  I&apos;ve spent some time both in Cosmin&apos;s patch and in hlog as part of this forward port.&lt;/p&gt;</comment>
                            <comment id="12868450" author="clehene" created="Mon, 17 May 2010 23:49:18 +0000"  >&lt;p&gt;Hey &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, my flight has just been canceled. I&apos;ll get back on the 19th - I&apos;m in Chicago. &lt;br/&gt;
This patch is functionally complete. It&apos;s been running on our cluster for a while, but could use some more testing. I was just hoping to get the review and make the final changes. Moving it in it&apos;s own class sounds right. I also thought about that. So I&apos;d appreciate someone apply the patch (hope it still applies) and try it. &lt;/p&gt;</comment>
                            <comment id="12869606" author="clehene" created="Thu, 20 May 2010 13:46:57 +0000"  >&lt;p&gt;Ouch, it seems a lot of stuff has moved in trunk. Can&apos;t apply patch either.&lt;/p&gt;</comment>
                            <comment id="12869699" author="stack" created="Thu, 20 May 2010 18:07:15 +0000"  >&lt;p&gt;Version of Cosmin&apos;s patch that will apply to TRUNK.  Compiles but thats all I&apos;ve done just yet.  Need to do a bit more review, make sure tests pass, then will put it up on review.hbase.org.&lt;/p&gt;</comment>
                            <comment id="12869815" author="stack" created="Fri, 21 May 2010 00:01:28 +0000"  >&lt;p&gt;Working on the split log tests.  They depend on a feature that is in 0.21 that is not in 0.20 hdfs... being able to set namenode soft lease in unit tests.  Still working on this.&lt;/p&gt;</comment>
                            <comment id="12869896" author="stack" created="Fri, 21 May 2010 06:31:41 +0000"  >&lt;p&gt;This patch doesn&apos;t have the changes that were made by earlier patches adding startminidfscluster to HBaseTestingUtility.  That was added as part of cleanup of HBaseTestingUtility over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2587&quot; title=&quot;Corral where tests write data when running and make sure clean target removes all written&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2587&quot;&gt;&lt;del&gt;HBASE-2587&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This v3 is now failing just three of the ten or so new tests that Cosmin added.  I&apos;m going through them.  In part, tests fail because hdfs-0.20 is different to hdfs-0.21 it seems; e.g. fs.listStatus return null if file does not exist in 0.20 hdfs but throws FNFE in hadoop 0.21 (Need to verify this is indeed the case).  This is going to cause fun when we go about the work making it so same hbase runs on both hadoop 0.20 and 0.21.&lt;/p&gt;

&lt;p&gt;This patch adds some dirty reflection to allow setting a lower soft limit on file leases in namenode, a public method in hadoop 0.21 but not accessible in hdfs 0.20 thats necessary to a bunch of the new Cosmin tests.&lt;/p&gt;</comment>
                            <comment id="12870047" author="tlipcon" created="Fri, 21 May 2010 16:46:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;. fs.listStatus return null if file does not exist in 0.20 hdfs but throws FNFE in hadoop 0.21 (Need to verify this is indeed the case). This is going to cause fun when we go about the work making it so same hbase runs on both hadoop 0.20 and 0.21.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If this is true it should be considered a bug in the 0.21 release, as the FileSystem API is supposed to be compatible between releases. Let me ping Tom.&lt;/p&gt;</comment>
                            <comment id="12870066" author="stack" created="Fri, 21 May 2010 17:42:10 +0000"  >&lt;p&gt;This changed it:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
r806746 | cdouglas | 2009-08-21 15:50:10 -0700 (Fri, 21 Aug 2009) | 4 lines

HDFS-538. Per the contract elucidated in HADOOP-6201, &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt;
FileNotFoundException from FileSystem::listStatus rather than returning
&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;. Contributed by Jakob Homan.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12870115" author="stack" created="Fri, 21 May 2010 19:09:49 +0000"  >&lt;p&gt;All tests pass now.  Also moved the split log to regionserver.wal package from master package where it seems to better belong.  Posted this patch to review.hbase.org.&lt;/p&gt;</comment>
                            <comment id="12870118" author="stack" created="Fri, 21 May 2010 19:14:16 +0000"  >&lt;p&gt;OK.  Posted to review.hbase.org.&lt;/p&gt;</comment>
                            <comment id="12870459" author="tlipcon" created="Sun, 23 May 2010 20:43:54 +0000"  >&lt;p&gt;Review comments at &lt;a href=&quot;http://review.hbase.org/r/74/#review40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/74/#review40&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12871091" author="clehene" created="Tue, 25 May 2010 10:56:06 +0000"  >&lt;p&gt;Thanks for review Todd!&lt;br/&gt;
I started working on it. I&apos;ll post the changes/suggestions in the review&lt;/p&gt;


</comment>
                            <comment id="12871371" author="hbasereviewboard" created="Tue, 25 May 2010 21:33:23 +0000"  >&lt;p&gt;Message from: &quot;Cosmin Lehene&quot; &amp;lt;clehene@adobe.com&amp;gt;&lt;/p&gt;



&lt;p&gt;Working on it. Some of the stuff might need more input&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Cosmin&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/74/#review33&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/74/#review33&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2010-05-21 12:11:59, stack wrote:&lt;/p&gt;

</comment>
                            <comment id="12871376" author="hbasereviewboard" created="Tue, 25 May 2010 21:41:33 +0000"  >&lt;p&gt;Message from: &quot;Cosmin Lehene&quot; &amp;lt;clehene@adobe.com&amp;gt;&lt;/p&gt;



&lt;p&gt;Let&apos;s have a separate issue for that&lt;/p&gt;



&lt;p&gt;done - for both reader and writer&lt;/p&gt;



&lt;p&gt;done - both reader and writer impl&lt;/p&gt;



&lt;p&gt;the original version of this function determined me to start refactoring in the first place. I&apos;ll add the description but if it&apos;s still confusing it might need more work.&lt;/p&gt;



&lt;p&gt;I know and tried to get a better name when created it. Can you suggest something better? I can&apos;t figure a short descriptive enough name&lt;/p&gt;



&lt;p&gt;perhaps hbase.regionserver.hlog.splitlog.batch.size?&lt;/p&gt;



&lt;p&gt;done&lt;/p&gt;



&lt;p&gt;done&lt;/p&gt;



&lt;p&gt;fixed&lt;/p&gt;



&lt;p&gt;done&lt;/p&gt;



&lt;p&gt;Fixed&lt;/p&gt;



&lt;p&gt;done&lt;/p&gt;



&lt;p&gt;done&lt;/p&gt;



&lt;p&gt;sync() used to call syncFs(). It looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2544&quot; title=&quot;Forward port branch 0.20 WAL to TRUNK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2544&quot;&gt;&lt;del&gt;HBASE-2544&lt;/del&gt;&lt;/a&gt; changed things a bit, but it doesn&apos;t only add the SequenceFile sync marker.&lt;/p&gt;

&lt;p&gt;I added this after I&apos;ve seen inconsistent results when running splitLog on bigger hlogs. Try copying a log from the cluster locally and run splitLog from the command line a few times without flushing it after each append. I used to get inconsistent results between runs and calling sync fixed it.&lt;/p&gt;

&lt;p&gt;There&apos;s this &quot;//TODO: test the split of a large (lots of regions &amp;gt; 500 file). In my tests it seems without hflush&quot;  in the TestHLogSplit. &lt;/p&gt;

&lt;p&gt;We could do some testing to figure out why would log entries be lost when running locally.&lt;/p&gt;

&lt;p&gt;What would be a better way to flush the writer?&lt;/p&gt;



&lt;p&gt;done&lt;/p&gt;



&lt;p&gt;fixed&lt;/p&gt;



&lt;p&gt;I don&apos;t know what it&apos;s supposed to mean either &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;



&lt;p&gt;fixed&lt;/p&gt;



&lt;p&gt;I&apos;d like to be able to investigate the trailing garbage. I don&apos;t think this should ever happen (do you see any scenarios?). If it did we might lose data. We used to fix NameNode edits for fsImage by adding a missing byte to a corrupted entry.&lt;/p&gt;

&lt;p&gt;I&apos;d like to reflect more on this, maybe see other opinions. &lt;/p&gt;



&lt;p&gt;I&apos;d rather have these differences dealt at the lowest level (writers) and abstracted than spread across code.&lt;br/&gt;
What do you think? &lt;/p&gt;



&lt;p&gt;done &lt;br/&gt;
I&apos;ll need help setting guava as a maven dependency.&lt;/p&gt;



&lt;p&gt;createNewSplitter is fine.&lt;br/&gt;
It&apos;s a Callable, changed to submit in order to check for the result in case one of the writers failed (see comment below)&lt;/p&gt;



&lt;p&gt;more aspects here:&lt;br/&gt;
I think the reported size will be &amp;gt;0 after recover, even if file has no records. I was asking if we should add logic to check if it&apos;s the last log. &lt;br/&gt;
EOF for non zero length, non zero records file means file is corrupted. &lt;/p&gt;



&lt;p&gt;see above comment&lt;/p&gt;



&lt;p&gt;what&apos;s the other JIRA? see my above comments.&lt;/p&gt;



&lt;p&gt;my previous comment got lost somehow.&lt;br/&gt;
Todd suggested submitting a Callable&amp;lt;Void&amp;gt; to executor thread.&lt;br/&gt;
I wonder if we could use getCompletedTaskCount. Documentation sais it&apos;s an estimation, however it&apos;s an estimation only during runtime and seems to be correct after shutdown finishes (I looked in the source as well)&lt;/p&gt;

&lt;p&gt;Another option would be ExecutorCompletionService which seems to be suited for this kind of job.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Cosmin&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/74/#review40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/74/#review40&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2010-05-21 12:11:59, stack wrote:&lt;/p&gt;

</comment>
                            <comment id="12871577" author="hbasereviewboard" created="Wed, 26 May 2010 09:02:34 +0000"  >&lt;p&gt;Message from: &quot;Cosmin Lehene&quot; &amp;lt;clehene@adobe.com&amp;gt;&lt;/p&gt;



&lt;p&gt;correction: Todd suggested submitting a Callable&amp;lt;Void&amp;gt; to executor thread and then do a Future.get() and catch. &lt;/p&gt;



&lt;p&gt;changed it&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Cosmin&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/74/#review40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/74/#review40&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2010-05-21 12:11:59, stack wrote:&lt;/p&gt;

</comment>
                            <comment id="12871931" author="hbasereviewboard" created="Wed, 26 May 2010 20:35:41 +0000"  >&lt;p&gt;Message from: &quot;Todd Lipcon&quot; &amp;lt;todd@cloudera.com&amp;gt;&lt;/p&gt;



&lt;p&gt;Oh, it&apos;s much much improved! Thanks! I still think a &quot;high level overview&quot; would be good to see.&lt;/p&gt;



&lt;p&gt;why .regionserver.? I&apos;d say just hbase.hlog.split.batch.size or something&lt;/p&gt;



&lt;p&gt;if this applies only to hlog splitting, maybe hbase.hlog.split.skip.errors&lt;/p&gt;



&lt;p&gt;Which do you mean by &quot;writers&quot; here? I&apos;d support factoring this function out into an HdfsUtil class somewhere.&lt;/p&gt;



&lt;p&gt;I agree if it has no records (I think - do we syncfs after writing the sequencefile header?). But there&apos;s the case where inside SequenceFile we call create, but never actually write any bytes. This is still worth recovering.&lt;/p&gt;

&lt;p&gt;In general I think a corrupt tail means we should drop that record (incomplete written record) but not shut down. This is only true if it&apos;s the tail record, though.&lt;/p&gt;



&lt;p&gt;Can&apos;t find it now... does my above comment make sense?&lt;/p&gt;



&lt;p&gt;This seems really voodoo.. if anything we&apos;re probably masking a real bug by doing this. Can you write a unit test which shows this problem (even if it takes 30 minutes to run, would be good to have in our arsenal)&lt;/p&gt;



&lt;p&gt;The case where this happens is if you crash in the middle of appending a long edit. Consider the case where a single edit might have 1MB of data (large rows). We can easily crash in the middle of transferring it, before we call sync on the edit. In this case, the client never received an &quot;ack&quot; for the write, so we can feel free to throw it away (this isn&apos;t data loss, it&apos;s correct operation).&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Todd&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.hbase.org/r/74/#review40&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/74/#review40&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2010-05-21 12:11:59, stack wrote:&lt;/p&gt;

</comment>
                            <comment id="12873331" author="hbasereviewboard" created="Sat, 29 May 2010 21:17:31 +0000"  >&lt;p&gt;Message from: &quot;Cosmin Lehene&quot; &amp;lt;clehene@adobe.com&amp;gt;&lt;/p&gt;


</comment>
                            <comment id="12873333" author="clehene" created="Sat, 29 May 2010 21:56:03 +0000"  >&lt;p&gt;Changed to reflect &lt;a href=&quot;http://review.hbase.org/r/74/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.hbase.org/r/74/&lt;/a&gt;&lt;br/&gt;
I left some TODOs see review comments.&lt;/p&gt;</comment>
                            <comment id="12873349" author="clehene" created="Sun, 30 May 2010 00:45:21 +0000"  >&lt;p&gt;I&apos;ve noticed testLogCannotBeWrittenOnceParsed sometimes fails. I reduced the &quot;zombie&quot; sleep time to 1 and it fails most of the times. &lt;br/&gt;
It seems the &quot;zombie&quot; thread can write and sync (+syncFs) after the log recovery. &lt;/p&gt;</comment>
                            <comment id="12874105" author="stack" created="Tue, 1 Jun 2010 16:54:47 +0000"  >&lt;p&gt;@Cosmin I was trying to commit but testLogCannotBeWrittenOnceParsed fails for me every time too.  Can you fix?  This is only thing in way of a commit.  I&apos;ve made issues for whats still outstanding in the review over at review.hbase.org&lt;/p&gt;</comment>
                            <comment id="12874106" author="stack" created="Tue, 1 Jun 2010 17:02:26 +0000"  >&lt;p&gt;@Cosmin:  Here is how to add your guava dependency:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
pynchon-8:trunk stack$ svn diff pom.xml
Index: pom.xml
===================================================================
--- pom.xml     (revision 950141)
+++ pom.xml     (working copy)
@@ -448,6 +448,7 @@
     &amp;lt;slf4j.version&amp;gt;1.5.8&amp;lt;/slf4j.version&amp;gt;
     &amp;lt;stax-api&amp;gt;1.0.1&amp;lt;/stax-api&amp;gt;
     &amp;lt;thrift.version&amp;gt;0.2.0&amp;lt;/thrift.version&amp;gt;
+    &amp;lt;guava.version&amp;gt;r03&amp;lt;/guava.version&amp;gt;
   &amp;lt;/properties&amp;gt;
 
   &amp;lt;dependencyManagement&amp;gt;
@@ -697,10 +698,15 @@
       &amp;lt;version&amp;gt;${commons-math.version}&amp;lt;/version&amp;gt;
       &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
     &amp;lt;/dependency&amp;gt;
-        &amp;lt;dependency&amp;gt;
+     &amp;lt;dependency&amp;gt;
       &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;
       &amp;lt;artifactId&amp;gt;hadoop-test&amp;lt;/artifactId&amp;gt;
     &amp;lt;/dependency&amp;gt;
+     &amp;lt;dependency&amp;gt;
+       &amp;lt;groupId&amp;gt;com.google.guava&amp;lt;/groupId&amp;gt;
+       &amp;lt;artifactId&amp;gt;guava&amp;lt;/artifactId&amp;gt;
+       &amp;lt;version&amp;gt;${guava.version}&amp;lt;/version&amp;gt;
+    &amp;lt;/dependency&amp;gt;
   &amp;lt;/dependencies&amp;gt;
 
   &amp;lt;!--
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12874125" author="stack" created="Tue, 1 Jun 2010 17:59:46 +0000"  >&lt;p&gt;OK, after talking to Cosmin, going to make an issue to deal with the zombie testLogCannotBeWrittenOnceParsed issue.  Cosmin thinks it may be an hdfs issue (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2645&quot; title=&quot;HLog writer can do 1-2 sync operations after lease has been recovered for split process.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2645&quot;&gt;&lt;del&gt;HBASE-2645&lt;/del&gt;&lt;/a&gt;).  Lets not let it get in the way of this commit and carry on investigation elsewhere.  For now I&apos;ll comment out the test.&lt;/p&gt;</comment>
                            <comment id="12874127" author="stack" created="Tue, 1 Jun 2010 18:02:32 +0000"  >&lt;p&gt;Committed.  Thanks for the nice patch Cosmin.&lt;/p&gt;</comment>
                            <comment id="12881937" author="nspiegelberg" created="Wed, 23 Jun 2010 22:48:55 +0000"  >&lt;p&gt;Hey, late peer review, I know.  I had a couple things I saw during the peer review that I would like to get resolution on...&lt;/p&gt;

&lt;p&gt;1. FSUtils.recoverFileLease() - does the InterruptedException handler need to set Thread.currentThread().interrupt()?  What about users actually trying to kill the master?&lt;br/&gt;
2. parseHLog() - the comment says that len==0 can still happen with append support? At least for 0.20, that&apos;s only if the file wasn&apos;t closed.  However, we just did that immediately before in recoverFileLease. don&apos;t mind the code, but comment should change or be clarified&lt;br/&gt;
3. writeEditsBatchToRegions() - same thing with InterruptedException.  maybe want to have something higher up the call stack notice isInterrupted() and display a Log.info() message.  At the very least, we definitely don&apos;t want to delete the log directory in splitLog() if the user interrupts these threads and skipErrors==true&lt;br/&gt;
4. archiveLogs() - by default, we are archiving successfully split logs ala &apos;processedLogs&apos;?  I&apos;m not sure we want to do that by default.  I think people are mainly interested in problematic logs that couldn&apos;t survive the transition.  Having this as an optional toggle is okay, but a naive user wouldn&apos;t know he has these trash items.&lt;/p&gt;</comment>
                            <comment id="15017624" author="lars_francke" created="Fri, 20 Nov 2015 12:43:48 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12458882">HBASE-2312</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12459405">HBASE-2337</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12472511">HBASE-2935</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12445119" name="2437-v2.txt" size="62929" author="stack" created="Fri, 21 May 2010 00:01:28 +0000"/>
                            <attachment id="12445138" name="2437-v3.txt" size="50090" author="stack" created="Fri, 21 May 2010 06:31:41 +0000"/>
                            <attachment id="12445187" name="2437-v4.patch" size="50553" author="stack" created="Fri, 21 May 2010 19:09:49 +0000"/>
                            <attachment id="12445089" name="2437.txt" size="50603" author="stack" created="Thu, 20 May 2010 18:07:15 +0000"/>
                            <attachment id="12445864" name="HBASE-2437-v5.patch" size="66148" author="clehene" created="Sun, 30 May 2010 00:44:59 +0000"/>
                            <attachment id="12442605" name="HBASE-2437_for_HBase-0.21_with_unit_tests_for_HDFS-0.21.patch" size="43403" author="clehene" created="Thu, 22 Apr 2010 18:12:39 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 13 Apr 2010 16:02:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i00xan:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3326</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>