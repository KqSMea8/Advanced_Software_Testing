<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:21:51 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-11295/HBASE-11295.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-11295] Long running scan produces OutOfOrderScannerNextException</title>
                <link>https://issues.apache.org/jira/browse/HBASE-11295</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Attached Files:&lt;/p&gt;

&lt;p&gt;HRegionServer.java - instramented from 0.96.1.1-cdh5.0.0&lt;br/&gt;
HBaseLeaseTimeoutIT.java - reproducing JUnit 4 test&lt;br/&gt;
WaitFilter.java - Scan filter (extends FilterBase) that overrides filterRowKey() to sleep during invocation&lt;br/&gt;
SpliceFilter.proto - Protobuf defintiion for WaitFilter.java&lt;br/&gt;
OutOfOrderScann_InstramentedServer.log - instramented server log&lt;br/&gt;
Steps.txt - this note&lt;/p&gt;

&lt;p&gt;Set up:&lt;/p&gt;

&lt;p&gt;In HBaseLeaseTimeoutIT, create a scan, set the given filter (which sleeps in overridden filterRowKey() method) and set it on the scan, and scan the table.&lt;br/&gt;
This is done in test client_0x0_server_150000x10().&lt;/p&gt;

&lt;p&gt;Here&apos;s what I&apos;m seeing (see also attached log):&lt;/p&gt;

&lt;p&gt;A new request comes into server (ID 1940798815214593802 - RpcServer.handler=96) and a RegionScanner is created for it, cached by ID, immediately looked up again and cached RegionScannerHolder&apos;s nextCallSeq incremeted (now at 1).&lt;br/&gt;
The RegionScan thread goes to sleep in WaitFilter#filterRowKey().&lt;/p&gt;

&lt;p&gt;A short (variable) period later, another request comes into the server (ID 8946109289649235722 - RpcServer.handler=98) and the same series of events happen to this request.&lt;/p&gt;

&lt;p&gt;At this point both RegionScanner threads are sleeping in WaitFilter.filterRowKey(). After another period, the client retries another scan request which thinks its next_call_seq is 0.  However, HRegionServer&apos;s cached RegionScannerHolder thinks the matching RegionScanner&apos;s nextCallSeq should be 1.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12718263">HBASE-11295</key>
            <summary>Long running scan produces OutOfOrderScannerNextException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="graziergeek">Jeff Cunningham</reporter>
                        <labels>
                    </labels>
                <created>Tue, 3 Jun 2014 22:19:34 +0000</created>
                <updated>Wed, 30 Dec 2015 09:45:10 +0000</updated>
                            <resolved>Thu, 15 Jan 2015 17:36:37 +0000</resolved>
                                    <version>0.96.0</version>
                                                    <component>regionserver</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>19</watches>
                                                                <comments>
                            <comment id="14017216" author="graziergeek" created="Tue, 3 Jun 2014 22:20:48 +0000"  >&lt;p&gt;tar ball with reproducing test&lt;/p&gt;</comment>
                            <comment id="14017749" author="graziergeek" created="Wed, 4 Jun 2014 15:09:11 +0000"  >&lt;p&gt;This may be related to implementation of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5974&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-5974&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14017816" author="stack" created="Wed, 4 Jun 2014 16:15:24 +0000"  >&lt;p&gt;Any chance of your taking a look &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; ? (it is a bad time for you just now...)&lt;/p&gt;</comment>
                            <comment id="14017817" author="anoop.hbase" created="Wed, 4 Jun 2014 16:19:41 +0000"  >&lt;p&gt;As in Filte waiting happens, client times out and do retry. If this retry is allowed, we will fail returning some rows. That is why we added the next seq no#. In this case throwing exception is desired behaviour. On seeing this exception the client will restart with the initial request . U can see thos logs? If ur filter logic is going to be time taking, increase the client timeout.&lt;/p&gt;</comment>
                            <comment id="14018135" author="graziergeek" created="Wed, 4 Jun 2014 20:38:44 +0000"  >&lt;p&gt;Anoop, thanks for response.&lt;/p&gt;

&lt;p&gt;Unfortunately, OutOfOrderScannerNextException that we get when nextCallSeq is different is a DoNotRetryIOException, so no retry occurs.  The region server log has no record of this event.  We only see this on the (user) client side.&lt;/p&gt;

&lt;p&gt;Interestingly, the server&apos;s cached nextCallSeq is incremented before the server scan is executed.  When client retries, their nextCallSeq values are already out of sync &amp;#8211; the server scan is still executing and the client had no notification of timeout or error.  Should the server&apos;s cached nextCallSeq value only be incremented after the scan comes back (or fails)?&lt;/p&gt;

&lt;p&gt;If you look at the server log in the attached tarball, you will see the sequence for the one client scan (notice the handler threadIDs):&lt;br/&gt;
15:15:54,824 (RpcServer.handler=94) - &amp;gt;&amp;gt;&amp;gt; Getting scanner for new request: 1940798815214593802&lt;br/&gt;
15:15:54,824 (RpcServer.handler=94) - &amp;gt;&amp;gt;&amp;gt;   1940798815214593802 nextCallSeq: 0&lt;br/&gt;
15:15:54,825 (RpcServer.handler=96) - &amp;gt;&amp;gt;&amp;gt; Getting scanner for ID: 1940798815214593802&lt;br/&gt;
15:15:54,825 (RpcServer.handler=96) - &amp;gt;&amp;gt;&amp;gt;   1940798815214593802 nextCallSeq: 0&lt;br/&gt;
15:15:54,825 (RpcServer.handler=96) - &amp;gt;&amp;gt;&amp;gt;     incrementing nexCallSeq for : 1940798815214593802&lt;br/&gt;
15:15:54,825 (RpcServer.handler=96) - WaitFilter snoozin for (150000) ms.&lt;br/&gt;
15:16:55,135 (RpcServer.handler=97) - &amp;gt;&amp;gt;&amp;gt; Getting scanner for ID: 1940798815214593802&lt;br/&gt;
15:16:55,135 (RpcServer.handler=97) - &amp;gt;&amp;gt;&amp;gt;   1940798815214593802 nextCallSeq: 1&lt;br/&gt;
15:16:55,142 (RpcServer.handler=92) - &amp;gt;&amp;gt;&amp;gt; Getting scanner for new request: 8946109289649235722&lt;br/&gt;
15:16:55,143 (RpcServer.handler=92) - &amp;gt;&amp;gt;&amp;gt;   8946109289649235722 nextCallSeq: 0&lt;br/&gt;
15:16:55,143 (RpcServer.handler=98) - &amp;gt;&amp;gt;&amp;gt; Getting scanner for ID: 8946109289649235722&lt;br/&gt;
15:16:55,143 (RpcServer.handler=98) - &amp;gt;&amp;gt;&amp;gt;   8946109289649235722 nextCallSeq: 0&lt;br/&gt;
15:16:55,143 (RpcServer.handler=98) - &amp;gt;&amp;gt;&amp;gt;     incrementing nexCallSeq for : 8946109289649235722&lt;br/&gt;
15:16:55,143 (RpcServer.handler=98) - WaitFilter snoozin for (150000) ms.&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; Client sees OutOfOrderScannerException at this point after ~ 1 min. Nothing in region server logs. &amp;lt;&amp;lt;&amp;lt;&lt;/p&gt;
</comment>
                            <comment id="14018302" author="anoop.hbase" created="Wed, 4 Jun 2014 22:55:53 +0000"  >&lt;p&gt;When the first request for a scan is executed in HRS the next seq id expected (from client) is the incremented one ie. 1 &lt;br/&gt;
Yes the out of order exp is a DNRIOE.   The normal retry is from client on client timeout. &lt;br/&gt;
In this case of timeout we should not allow that retry to happen. The first try is already in progress and the scan advanced some rk levels. The retry will skip those snd we will fail getting those rows.&lt;br/&gt;
On the out of order exception no retry ( like u see before) has to happen. It will be cloding that scanner and creating a new scanner.   U mean this new is not happening? This way it was when we wrote code need to see any change made later fir not happen.&lt;/p&gt;</comment>
                            <comment id="14021126" author="anoop.hbase" created="Sun, 8 Jun 2014 06:51:39 +0000"  >&lt;p&gt;U can see in ClientScanner that we will treat outof order exception. We are not throwing back to app layer immediately.  We will recreate a scanner with start row as the last previous fetched row. But again this also throws same exception with out fetching any thing we will stop and throw back to app. Else we will end in this way of infinite retries. ( pls note that the retries with same scannerid is finite no# )&lt;br/&gt;
In ur case this might be happening.  U sleep in filter. If u are having such a long running scenario ( one next call will take more time may be becuase of complex filtering or so ) try reducing scanner caching ( default is 100) and/or increasing client time out.  &lt;br/&gt;
I dont think there is any problem in code.&lt;br/&gt;
The log says the retry from client on out of order exception.&lt;/p&gt;</comment>
                            <comment id="14025420" author="yifu" created="Mon, 9 Jun 2014 17:39:47 +0000"  >&lt;p&gt;Thanks for the reply Anoop!&lt;/p&gt;

&lt;p&gt;So I think I figured out the problem. It is that when a scan request takes too long to process the RPC connection times out. It is not a client timeout issue as there are retries form the client, and it seems like when another RPC connection is reestablished the nextCallSeq information on the client side is lost. Increasing RPC timeout and decreasing scanner caching both work but they also impose performance penalty so I am working to find a way around that.&lt;/p&gt;</comment>
                            <comment id="14064785" author="mark_baumgarten" created="Thu, 17 Jul 2014 10:33:33 +0000"  >&lt;p&gt;Using cdh-5.0.3 - I have the same issue when using impala and trying to export one HBase table into a parquet table....aka &quot;insert overwrite parquet_foo select x, y from hbase_table&quot;.&lt;/p&gt;</comment>
                            <comment id="14065085" author="yifu" created="Thu, 17 Jul 2014 16:34:53 +0000"  >&lt;p&gt;Hi Mark, I think this is a config problem as Anoop said. The scan takes too long to process and before it returns the result and nextCallSeq has a chance to ++, RPC and server time out while in the client side nextCallSeq is already ++ed. You can try setting the RPC timeout and server timeout to a higher value and rerun the query. This might probably solve it as it did for me.&lt;/p&gt;</comment>
                            <comment id="14065158" author="anoop.hbase" created="Thu, 17 Jul 2014 17:19:08 +0000"  >&lt;p&gt;Yes throwing OutfOrderException is correct.  So I can close this issue as no change needed in HBase?&lt;/p&gt;</comment>
                            <comment id="14065358" author="yifu" created="Thu, 17 Jul 2014 18:53:10 +0000"  >&lt;p&gt;Yes Anoop that sounds good.&lt;/p&gt;</comment>
                            <comment id="14074999" author="mark_baumgarten" created="Fri, 25 Jul 2014 21:53:42 +0000"  >&lt;p&gt;Thanks for your reply Yifu. I tried increasing (multiplying default values by four) different timeout settings (not really sure which - but altogether I fiddled with four different timeout values in my CDH cluster). My issue persists.&lt;/p&gt;

&lt;p&gt;I am very new to hadoop and I don&#180;t know what an acceptable max timeout setting might be(I guess I could try setting it to several hours instead of minutes and just see what happens). I also feel a bit uncertain where the specific RPC timeout setting is found in my CDH manager interface - maybe the error message could point to this specific setting?&lt;/p&gt;

&lt;p&gt;I managed to get my table created by using hive instead of impala - so I stopped worrying about it too much. I guess I just have to fiddle some more - but thanks for replying.&lt;/p&gt;

&lt;p&gt;/Mark  &lt;/p&gt;</comment>
                            <comment id="14250717" author="apurtell" created="Wed, 17 Dec 2014 22:38:15 +0000"  >&lt;p&gt;We can get an OutOfOrderScannerNextException if the server thinks it has processed a scanner &#8216;next&#8217; call but the client does not, and retries that &#8216;next&#8217; RPC, which happens to fail again even though technically it&apos;s using a new (relocated) scanner.&lt;/p&gt;

&lt;p&gt;When the client gets a OutOfOrderScannerNextException, the ClientScanner will retry - once. We use the boolean control variable &lt;tt&gt;retryAfterOutOfOrderException&lt;/tt&gt;, set to &apos;true&apos; initially, then set to &apos;false&apos; when looping back to relocate and retry. &lt;/p&gt;

&lt;p&gt;A comment in ScannerCallable#next says: &quot;&lt;em&gt;If at the server side fetching of next batch of data was over, there will be mismatch in the nextCallSeq number. Server will throw OutOfOrderScannerNextException and then client will reopen the scanner with start row as the last successfully retrieved row.&lt;/em&gt;&#8221; This is what happens. We set &#8216;callable&apos; to null before looping back around, so nextScanner() will create a new ScannerCallable. The new ScannerCallable does not have an initialized &#8216;scannerId&#8217; so it builds a scan open request and sends it to the server. On the server side, this creates a new RegionScanner with a new identifier. This is like starting the scan over, except the start row has been updated to the last position of the previous so from the application perspective the result stream is seamless. Both the new RegionScanner and the ScannerCallable on the client restart with nextCallSeq values of 0. &lt;/p&gt;

&lt;p&gt;Now with the new scanner we run into bad luck. With the new scanner on this &quot;retry&quot; this request times out like the first one, again with the server thinking the client should have advanced. However inside the ClientScanner state the value of retryAfterOutOfOrderException is &#8216;false&apos;, so this time we let out the OutOfOrderScannerNextException exception to bubble up to the application, &quot;expecting nextCallSeq 1, got 0&quot;&lt;/p&gt;

&lt;p&gt;I could be missing something. If not, this doesn&#8217;t seem quite right. We are using a new scanner after relocation, like we do for NSREs, that just happens to fail the same way as the last one due, perhaps due to socket timeout sending the response under similar prevailing conditions. Why have the special case handling controlled by retryAfterOutOfOrderException? We retry NSREs up to a configured threshold, then give up. Use the same threshold for OutOfOrderScannerNextExceptions?&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="14252734" author="anoop.hbase" created="Fri, 19 Dec 2014 01:29:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why have the special case handling controlled by retryAfterOutOfOrderException? We retry NSREs up to a configured threshold, then give up. Use the same threshold for OutOfOrderScannerNextExceptions?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjushch&quot; class=&quot;user-hover&quot; rel=&quot;zjushch&quot;&gt;chunhui shen&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14268683" author="apurtell" created="Thu, 8 Jan 2015 01:48:30 +0000"  >&lt;p&gt;Lars and I were tracing through the HBase client code today and spotted where in ScannerCallable#call we curiously do not increment the next sequence ID to use (for a retry) until &lt;b&gt;after&lt;/b&gt; we issue a RPC and wait for a successful response. If for some reason the RPC times out on the client - network issue perhaps - we leave call() without incrementing the sequence ID. The server will not see the client side timeout before it has incremented the expected next sequence ID. When the caller submits the retry we have a sequence mismatch.&lt;/p&gt;

&lt;p&gt;Is the below correct (diff against 0.98)? I would be surprised because retries would never have worked in the face of a client side network timeout. Maybe that is just not that common? Although I suppose we could have this JIRA because it is common enough.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java b/hbase-clie
index e329c3b..a9d3be0 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java
@@ -170,8 +170,6 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class ScannerCallable &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; RegionServerCallable&amp;lt;Result[]&amp;gt; {
           request = RequestConverter.buildScanRequest(scannerId, caching, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, nextCallSeq);
           ScanResponse response = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
           &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
-            controller.setPriority(getTableName());
-            response = getStub().scan(controller, request);
             &lt;span class=&quot;code-comment&quot;&gt;// Client and RS maintain a nextCallSeq number during the scan. Every next() call
&lt;/span&gt;             &lt;span class=&quot;code-comment&quot;&gt;// from client to server will increment &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; number in both sides. Client passes &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
&lt;/span&gt;             &lt;span class=&quot;code-comment&quot;&gt;// number along with the request and at RS side both the incoming nextCallSeq and its
&lt;/span&gt;@@ -179,9 +177,16 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class ScannerCallable &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; RegionServerCallable&amp;lt;Result[]&amp;gt; {
             &lt;span class=&quot;code-comment&quot;&gt;// should not happen. If at the server side fetching of next batch of data was over,
&lt;/span&gt;             &lt;span class=&quot;code-comment&quot;&gt;// there will be mismatch in the nextCallSeq number. Server will &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt;
&lt;/span&gt;             &lt;span class=&quot;code-comment&quot;&gt;// OutOfOrderScannerNextException and then client will reopen the scanner with startrow
&lt;/span&gt;-            &lt;span class=&quot;code-comment&quot;&gt;// as the last successfully retrieved row.
&lt;/span&gt;-            &lt;span class=&quot;code-comment&quot;&gt;// See HBASE-5974
&lt;/span&gt;+            &lt;span class=&quot;code-comment&quot;&gt;// as the last successfully retrieved row. See HBASE-5974.
&lt;/span&gt;+
+            &lt;span class=&quot;code-comment&quot;&gt;// Increment the call seq BEFORE network IO.
&lt;/span&gt;             nextCallSeq++;
+
+            &lt;span class=&quot;code-comment&quot;&gt;// Now issue the RPC
&lt;/span&gt;+            controller.setPriority(getTableName());
+            response = getStub().scan(controller, request);
+
+            &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-object&quot;&gt;Process&lt;/span&gt; results
&lt;/span&gt;             &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timestamp = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
             &lt;span class=&quot;code-comment&quot;&gt;// Results are returned via controller
&lt;/span&gt;             CellScanner cellScanner = controller.cellScanner();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14268908" author="lhofhansl" created="Thu, 8 Jan 2015 06:49:53 +0000"  >&lt;p&gt;We actually ran into the same issue. Our &quot;filter&quot; was a timerange specified on the scan object, that filtered a large percentage of the data. The client would time out because it did not hear back from the server, retries, and boom we get this exception.&lt;/p&gt;

&lt;p&gt;With the patch that we came up with above this no longer happens.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, could you have a quick look and confirm that this will not break anything new?&lt;/p&gt;</comment>
                            <comment id="14268914" author="apurtell" created="Thu, 8 Jan 2015 06:57:10 +0000"  >&lt;p&gt;Set fix versions. l will put up patches for target branches tomorrow &lt;/p&gt;</comment>
                            <comment id="14269207" author="anoop.hbase" created="Thu, 8 Jan 2015 11:20:47 +0000"  >&lt;p&gt;Client side when retry happen (Due to timeout) it should try with the same seqId.  If u see the server side, when the request comes, immediately we increment the nextSeqId expected.  If the client is not giving this number in the next call, then it is a problem..  &lt;br/&gt;
On OOScannerNextException, we retry with a new Scan. But this retry will happen only one more time. If this new Scan also giving Exception in turn (Same filtered scan and again taking time) we may get the exception again and throw back to client.  Is this happening?&lt;br/&gt;
By design, at client side, the nexSeq increment should not happen for a timeout recall.&lt;/p&gt;

&lt;p&gt;Am I missing something still?&lt;/p&gt;</comment>
                            <comment id="14269466" author="apurtell" created="Thu, 8 Jan 2015 15:54:17 +0000"  >&lt;p&gt;Yes Anoop that is what is happening. The problem is the client and server disagree about the request timing out, twice. So then our TableInputFormat based job fails consistently. &lt;/p&gt;</comment>
                            <comment id="14270294" author="anoop.hbase" created="Fri, 9 Jan 2015 00:36:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;The problem is the client and server disagree about the request timing out, twice.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If we try a 3rd time, then also the client side will time out? The same data set at server and same filter...&lt;br/&gt;
With the above change in code, I fear we will get the issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5974&quot; title=&quot;Scanner retry behavior with RPC timeout on next() seems incorrect&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5974&quot;&gt;&lt;del&gt;HBASE-5974&lt;/del&gt;&lt;/a&gt; ie. some data will not get scanned. (Data miss)&lt;br/&gt;
For such a filter which will filter out most of the data, can we increase the client timeout?&lt;br/&gt;
After &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5974&quot; title=&quot;Scanner retry behavior with RPC timeout on next() seems incorrect&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5974&quot;&gt;&lt;del&gt;HBASE-5974&lt;/del&gt;&lt;/a&gt;  another jira added the restriction part that only one more time we retry after getting a OOScannerNextExp.  Do you feel we need try for some more times  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14270508" author="apurtell" created="Fri, 9 Jan 2015 03:40:43 +0000"  >&lt;p&gt;Yes we did see issues with missing data when testing the patch. Let&apos;s drop it. &lt;/p&gt;

&lt;p&gt;It does seem reasonable to have OOSNE retry the same number of configured times as other retryable IOExceptions. &lt;/p&gt;</comment>
                            <comment id="14270670" author="anoop.hbase" created="Fri, 9 Jan 2015 07:01:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;It does seem reasonable to have OOSNE retry the same number of configured times as other retryable IOExceptions.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am +1 for this.  Ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjushch&quot; class=&quot;user-hover&quot; rel=&quot;zjushch&quot;&gt;chunhui shen&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14270811" author="zjushch" created="Fri, 9 Jan 2015 09:42:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;It does seem reasonable to have OOSNE retry the same number of configured times as other retryable IOExceptions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In my person opinion, OOSNE is caused by RPC timeout of long run scan,  if scan run time &amp;gt; RPC timeout,  increment retry number won&apos;t get anything. &lt;/p&gt;

&lt;p&gt;But, using the same retry mechanism seems reasonable, so, I am +1 for this.&lt;/p&gt;</comment>
                            <comment id="14275634" author="housejester" created="Tue, 13 Jan 2015 18:13:39 +0000"  >&lt;p&gt;I agree with chunhui. Retrying will likely just wind up resulting in the same exception which doesn&apos;t say much to the caller about what actually happened, nor what they may be able to do to fix it (eg &quot;try increasing the rpc timeout&quot;). It seems to me that the underlying issue is a scan rpc times out b/c it&apos;s doing a lot of filtering, then retries and immediately gets an OOSNE (which seems to have reasons here for being the right thing to do), and throws that, but without the original timeout exception to give more context to the caller that the issue may have started with that timeout exception. &lt;/p&gt;

&lt;p&gt;I have a similar issue, but much more troublesome in that it winds up in an endless cycle: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12266&quot; title=&quot;Slow Scan can cause dead loop in ClientScanner &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12266&quot;&gt;&lt;del&gt;HBASE-12266&lt;/del&gt;&lt;/a&gt;. In that case as well, increasing the rpc timeout was the only fix for the issue, but it took quite a bit of digging to figure that out. I haven&apos;t been able to test the v2 patch there (the timeout change was sufficient for me), but I like what it does: it makes the timeout check on an DoNotRetryIOException unconditional (ie not just for UnknownScannerExceptions). Even in my use case, the exception would have still occurred, but it would have given me more meaningful information about what I could to. At the very least, having this timeout check could be useful to provide more information in the exception, so users have an idea of what to do to proceed (without digging through the code &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ). &lt;/p&gt;</comment>
                            <comment id="14275853" author="lhofhansl" created="Tue, 13 Jan 2015 20:14:21 +0000"  >&lt;p&gt;I agree now. We should close this one.&lt;/p&gt;</comment>
                            <comment id="14275889" author="apurtell" created="Tue, 13 Jan 2015 20:34:06 +0000"  >&lt;p&gt;I don&apos;t have a strong opinion either way. We have two votes to change, one to close. &lt;/p&gt;</comment>
                            <comment id="14275904" author="lhofhansl" created="Tue, 13 Jan 2015 20:43:25 +0000"  >&lt;p&gt;Neither do I &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14278995" author="apurtell" created="Thu, 15 Jan 2015 17:36:37 +0000"  >&lt;p&gt;Where we are now with this issue is a suggestion to have OOSNE retry the same number of configured times as other retryable IOExceptions, but without strong opinion. Therefore I&apos;m going to resolve this as Not A Problem as the original report is of a correct and intended response. Reopen if something changes.&lt;/p&gt;</comment>
                            <comment id="15074865" author="veve" created="Wed, 30 Dec 2015 09:45:10 +0000"  >&lt;p&gt;I tried the &quot; increasing the rpc timeout&quot;  solution but now the job is just stopping (no error)&lt;/p&gt;

&lt;p&gt;The only logs: Query 1e4f1be62f3e7791:70e065374c943880: 0% Complete (0 out of 205)&lt;/p&gt;

&lt;p&gt;Note: I increased the RPC timeout to hbase.rpc.timeout=30 seconds&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12748238">HBASE-12266</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12648241" name="OutOfOrderScannerNextException.tar.gz" size="47753" author="graziergeek" created="Tue, 3 Jun 2014 22:20:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 4 Jun 2014 16:15:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>396465</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            50 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1w99z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>396586</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>