<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:35:29 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6295/HBASE-6295.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6295] Possible performance improvement in client batch operations: presplit and send in background</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6295</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;today batch algo is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;for Operation o: List&amp;lt;Op&amp;gt;{
  add o to todolist
  if todolist &amp;gt; maxsize or o last in list
    split todolist per location
    send split lists to region servers
    clear todolist
    wait
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We could:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;create immediately the final object instead of an intermediate array&lt;/li&gt;
	&lt;li&gt;split per location immediately&lt;/li&gt;
	&lt;li&gt;instead of sending when the list as a whole is full, send it when there is enough data for a single location&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It would be:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;for Operation o: List&amp;lt;Op&amp;gt;{
  get location
  add o to todo location.todolist
  if (location.todolist &amp;gt; maxLocationSize)
    send location.todolist to region server 
    clear location.todolist
    // don&apos;t wait, continue the loop
}
send remaining
wait
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It&apos;s not trivial to write if you add error management: retried list must be shared with the operations added in the todolist. But it&apos;s doable.&lt;br/&gt;
It&apos;s interesting mainly for &apos;big&apos; writes&lt;/p&gt;</description>
                <environment></environment>
        <key id="12596502">HBASE-6295</key>
            <summary>Possible performance improvement in client batch operations: presplit and send in background</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nkeywal">Nicolas Liochon</assignee>
                                    <reporter username="nkeywal">Nicolas Liochon</reporter>
                        <labels>
                    </labels>
                <created>Sat, 30 Jun 2012 11:45:04 +0000</created>
                <updated>Tue, 5 Aug 2014 20:11:38 +0000</updated>
                            <resolved>Mon, 24 Jun 2013 19:04:35 +0000</resolved>
                                    <version>0.95.2</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.95.2</fixVersion>
                                    <component>Client</component>
                    <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>22</watches>
                                                                <comments>
                            <comment id="13405046" author="stack" created="Mon, 2 Jul 2012 12:57:16 +0000"  >&lt;p&gt;Making it noob.  Could be fun project for someone who wants to do something a little involved.&lt;/p&gt;</comment>
                            <comment id="13417995" author="paulcavallaro" created="Thu, 19 Jul 2012 02:26:23 +0000"  >&lt;p&gt;I probably won&apos;t have time until this weekend or next week, but I wouldn&apos;t mind taking a stab at this. I&apos;ll write more once I bite into it later.&lt;/p&gt;</comment>
                            <comment id="13436937" author="paulcavallaro" created="Fri, 17 Aug 2012 18:25:52 +0000"  >&lt;p&gt;Seems to duplicate work done in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5776&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-5776&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13436963" author="stack" created="Fri, 17 Aug 2012 18:51:04 +0000"  >&lt;p&gt;@Paul Would forward porting the 89fb patch get this functionality?  If so, use this issue to do it?&lt;/p&gt;</comment>
                            <comment id="13436966" author="stack" created="Fri, 17 Aug 2012 18:53:43 +0000"  >&lt;p&gt;Or, reviewing hbase-5776, could the forward port be done in a way that addresses the issues raised over in hbase-5776?  Or what you think?  Maybe it&apos;d be best to just do what N outlines above?&lt;/p&gt;</comment>
                            <comment id="13617639" author="nkeywal" created="Fri, 29 Mar 2013 19:33:20 +0000"  >&lt;p&gt;The table multiplexers has two drawbacks imho:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;it&apos;s a new interface&lt;/li&gt;
	&lt;li&gt;it manages errors by dropping the puts that failed.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is suitable for some applications, but not all of them.&lt;/p&gt;


&lt;p&gt;I think it&apos;s possible to do something in the middle, and stick to the existing interface. This would be:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;we set two value for the write buffer: backgroundThreshold and blockingThreshold.&lt;/li&gt;
	&lt;li&gt;blockingThreshold works as today: we flush and block the callers until it&apos;s sent successfully&lt;/li&gt;
	&lt;li&gt;when backgroundThreshold is reached, we send data in the background, without blocking the user&lt;/li&gt;
	&lt;li&gt;if we have too many errors we do as today: empty the buffer and raise the error to the user at the next put.&lt;/li&gt;
	&lt;li&gt;flushCommit and puts works as today.&lt;/li&gt;
	&lt;li&gt;We keep the existing table behavior, and try, as today, to have not synchronization in the HTable code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Other comments:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if we want to be very efficient when merging calls to a given region server for different tables, we should add this in the protobuf protocol.&lt;/li&gt;
	&lt;li&gt;if we change the messages sent to the region server, we could also let the region server return a workload info. This workload would be used by the client to slow down their messages. Some clients could have a &apos;nice&apos; parameter to slow down more than others (typically map reduce jobs).&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;I will give a try to the send in background to see if it&apos;s possible to have something reasonable.&lt;/p&gt;</comment>
                            <comment id="13628203" author="nkeywal" created="Wed, 10 Apr 2013 20:25:24 +0000"  >&lt;p&gt;It&apos;s still in a hacky way. Needs some work be be clean. I need to write some unit tests, I&apos;m sure this implementation is still buggy.&lt;/p&gt;

&lt;p&gt;What I would like to keep is the logic I&apos;ve finally implemented:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;when we send the buffered writes to the regionservers, we don&apos;t stop except if we have to, i.e: we have too much tasks in progress or we ran out of retries.&lt;/li&gt;
	&lt;li&gt;we don&apos;t have this terrible Object[] to send back the results. Actually, in most methods, they are never used anyway.&lt;/li&gt;
	&lt;li&gt;we don&apos;t keep the buffer for failed operation. In other words, clearBufferOnFail would always be true (it&apos;s already the default).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If it works, it means we won&apos;t be slow down by the slowest region server anymore.&lt;/p&gt;
</comment>
                            <comment id="13628293" author="hadoopqa" created="Wed, 10 Apr 2013 21:40:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12578071/6295.v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12578071/6295.v1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestMultiParallel&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5249//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13629131" author="nkeywal" created="Thu, 11 Apr 2013 17:17:58 +0000"  >&lt;p&gt;Still hacky. I workarounded some issues coming from calculateBackoffTime, I will do to add them back. Issues were:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;when the server is not in the list, the pause time is zero&lt;/li&gt;
	&lt;li&gt;when a server crash, the number of error is equals to the number of actions we wanted to send to this server&lt;/li&gt;
	&lt;li&gt;the end time is the timeout + the date of the first error, which is not suitable if we have an infinite flow of actions.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;next version will solve this.&lt;/p&gt;</comment>
                            <comment id="13629203" author="hadoopqa" created="Thu, 11 Apr 2013 18:27:30 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12578240/6295.v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12578240/6295.v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestMultiTableInputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5268//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13630568" author="hadoopqa" created="Fri, 12 Apr 2013 20:15:57 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12578486/6295.v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12578486/6295.v3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5297//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13630828" author="stack" created="Sat, 13 Apr 2013 00:40:38 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~liochon&amp;#93;&lt;/span&gt; Does it address the following issue Nicolas?  I am not clear it does:&lt;/p&gt;

&lt;p&gt;Cluster has N regionservers.  It has M regions well distributed across the cluster.  There are X clients.&lt;/p&gt;

&lt;p&gt;All clients access region Y once every other second or so for some small bit of data.&lt;/p&gt;

&lt;p&gt;Something happens such that Y region responses get REALLY SLOW.&lt;/p&gt;

&lt;p&gt;Eventually all clients get hung up waiting on their return from region Y (it is taking a REALLY LONG time).  Because it is taking so long for the clients to get the response back, all clients get totally occupied waiting on their outstanding requests against region Y.  Because client is stuck on region Y, the application can get no data out of the cluster; i.e. 99.99% of the regions are online but one REALLY SLOW region can make it so you can&apos;t get at the rest of the data.&lt;/p&gt;

&lt;p&gt;An actual scenario is an apache frontend with a fixed number of workers, say 100.  This apache webserver goes to a thrift server.  The thrift server is hosting the hbase client.  If a region is having a problem, it could be the case that we could back up such that all the apache fixed number workers are blocked waiting on a reply out of this one slow region.&lt;/p&gt;

&lt;p&gt;Will this patch help w/ the above scenario?&lt;/p&gt;</comment>
                            <comment id="13631022" author="nkeywal" created="Sat, 13 Apr 2013 12:34:04 +0000"  >&lt;p&gt;It does help. Cases are:&lt;/p&gt;

&lt;p&gt;1) The client wants a synchronous (multi)put or (multi)get. We have to wait. &lt;br/&gt;
2) The client uses today the htable interface with autoflush set to false. In this case, with this patch we will be way faster, as we will continue to accept put from the client and send them to the servers.&lt;/p&gt;

&lt;p&gt;So today, we do in the client:&lt;/p&gt;

&lt;p&gt;  void put(Put put){&lt;br/&gt;
    toSend.add(put)&lt;br/&gt;
    if (toSend.isBigEnough()&lt;/p&gt;
{
         nbRetry = 0;
         while (nbRetry++ &amp;lt; maxRetry &amp;amp;&amp;amp; toSend.stillSomethingToSend())
             send(toSend)
         if (toSend.hasError()
            throw Exception();
     }

&lt;p&gt;In the patch we do&lt;br/&gt;
    private BackgroundSendThread backgroundSendThread;&lt;br/&gt;
    void put(Put put){&lt;br/&gt;
        if (backgroundSendThread.hasError())&lt;br/&gt;
           throw Exception();     &lt;br/&gt;
        toSend.add(put)&lt;br/&gt;
        if (toSend.isBigEnough()&lt;/p&gt;
{
            backgroundSendThread.send(toSend); // Non blocking, do retries. Set hasError if there are 
   }

&lt;p&gt;This is 100% compatible with the previous contract. I would like the new behavior to be the default.&lt;/p&gt;

&lt;p&gt;But obviously, there is a limit to what the client can keep in its background list.&lt;br/&gt;
There are 3 possible ways to manage this limit:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the total buffer size&lt;/li&gt;
	&lt;li&gt;the number of task&lt;/li&gt;
	&lt;li&gt;the throughput&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Here I implemented the simplest: control the number of task. We can implement the others as well.&lt;br/&gt;
What we gain here as well is that it will be a way to control the client. I expect it will be simple to set a different number of task per client, hence the map reduce clients will send less writes than the other.&lt;/p&gt;

&lt;p&gt;The direct case is a region under recovery: the client will be able to go to all other regions. We may have some herd effects, but I expect the difference to be just great for many use cases.&lt;/p&gt;

&lt;p&gt;What we could as well is adding a configurable error management: we could just dismiss the puts that failed too much instead of setting a blocking error. It&apos;s quite easy to add.&lt;/p&gt;


&lt;p&gt;This said, the code in HConnection* is quite strange sometimes, I&apos;m may have to propose some incompatible interface change (for example, when a list of put failed, there is an option to keep them in the write buffer: it&apos;s more difficult / expensive when there are two threads and not one).&lt;/p&gt;

&lt;p&gt;The error aboves seems unrelated to my changes, except that may be I triggered another set of flakyness by changing the internal behavior.&lt;/p&gt;</comment>
                            <comment id="13631093" author="stack" created="Sat, 13 Apr 2013 16:54:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;The direct case is a region under recovery: the client will be able to go to all other regions. We may have some herd effects, but I expect the difference to be just great for many use cases.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In my comment above, performance is not my concern.  My concern is an outstanding request against a single region or single regionserver blocking access to other regions/regionservers.  Going by your comment above, it seems that you think it will help with this case.&lt;/p&gt;

&lt;p&gt;If I were to write a unit test to prove it, do you have any suggestions for how I might go about it? (In my experience, fixing the issue I describe is critical).&lt;/p&gt;

&lt;p&gt;Thanks N.&lt;/p&gt;</comment>
                            <comment id="13631581" author="nkeywal" created="Mon, 15 Apr 2013 08:26:18 +0000"  >&lt;p&gt;I think we could simulate transient slowdown with a coprocessor. On a given RS, every 5 minutes, the coprocessor does a sleep in the preput =&amp;gt; during one minute; all puts takes 20ms than they used to. In the client code, we just try to write randomly on all regions, with autoflush off. The test should finish in both cases, but the number of puts written should be quite different.&lt;/p&gt;</comment>
                            <comment id="13635225" author="nkeywal" created="Thu, 18 Apr 2013 14:54:08 +0000"  >&lt;p&gt;Load test with YCSB on EC2. Lot of problems. The server seems sensible to the workload, and beeing asynchronous adds some workload.&lt;br/&gt;
Here is a stack with a moderate setting. I don&apos;t get the &quot;UnknownHostException: ip-10-4-226-168&quot;, may be there are much calls for AWS...&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-04-18 10:41:33,377 INFO  [regionserver60020-smallCompactions-1366296026287] org.apache.hadoop.hbase.regionserver.StoreFile: Delete Family Bloom f
2013-04-18 10:41:37,849 FATAL [regionserver60020.logRoller] org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server ip-10-4-229-217
java.io.IOException: cannot get log writer
        at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createWriter(HLogFactory.java:162)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:591)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:533)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:96)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.init(SequenceFileLogWriter.java:169)
        at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createWriter(HLogFactory.java:159)
        ... 4 more
Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:123)
        at org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:149)
        at org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:234)
        at org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342)
        at org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1441)
        at org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339)
        at org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:453)
        at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:469)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.init(SequenceFileLogWriter.java:150)
        ... 5 more
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:121)
        ... 20 more
Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: ip-10-4-226-168
        at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:417)
        at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:164)
        at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:129)
        at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:415)
        at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:382)
        at org.apache.hadoop.fs.Hdfs.&amp;lt;init&amp;gt;(Hdfs.java:85)
        ... 25 more
Caused by: java.net.UnknownHostException: ip-10-4-226-168
        ... 31 more
2013-04-18 10:41:37,851 FATAL [regionserver60020.logRoller] org.apache.hadoop.hbase.regionserver.HRegionServer: RegionServer abort: loaded coprocessor
2013-04-18 10:41:37,863 INFO  [regionserver60020.logRoller] org.apache.hadoop.hbase.regionserver.HRegionServer: STOPPED: IOE in log roller
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13635227" author="nkeywal" created="Thu, 18 Apr 2013 15:03:48 +0000"  >&lt;p&gt;On the good news part, it seems it does what we expect: performances are 25% better, even with a dead regionserver.&lt;/p&gt;</comment>
                            <comment id="13635908" author="stack" created="Fri, 19 Apr 2013 01:05:40 +0000"  >&lt;p&gt;This looks like AWS @nkeywal: Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: ip-10-4-226-168  Always happens?  (nice on the 25% improvement)&lt;/p&gt;</comment>
                            <comment id="13636168" author="nkeywal" created="Fri, 19 Apr 2013 07:56:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: ip-10-4-226-168 Always happens&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Each run brings a different issue (including with the plain trunk, but the plain trunk takes longer (2 hours) to fail). It&apos;s also because I change the settings between the runs &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;
</comment>
                            <comment id="13636236" author="nkeywal" created="Fri, 19 Apr 2013 10:08:47 +0000"  >&lt;p&gt;I&apos;ve reproduced the same stack with the trunk =&amp;gt; not caused by this patch. But it complicates testing.&lt;/p&gt;</comment>
                            <comment id="13636364" author="nkeywal" created="Fri, 19 Apr 2013 13:32:49 +0000"  >&lt;p&gt;It seems that in this test, on AWS, we&apos;re limited by the bandwidth between the client and the region server. The 25% is the time spent by the client waiting for an answer from the servers.&lt;/p&gt;

&lt;p&gt;This stack occurs sometimes with plain trunk and very often with 6295:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-04-19 09:22:45,991 WARN  [IPC Client (682317035) connection to ip-10-6-131-32.ec2.internal/10.6.131.32:60020 from root] ipc.HBaseClient (HBaseClient.java:run(664)) - IPC Client (682317035) connection to ip-10-6-131-32.ec2.internal/10.6.131.32:60020 from root: unexpected exception receiving call responses
java.lang.RuntimeException: java.lang.NullPointerException
	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.readResponse(HBaseClient.java:1017)
	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:661)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.readResponse(HBaseClient.java:1013)
	... 1 more
 1197 sec: 3411081 operations; 324,27 current ops/sec; [INSERT AverageLatency(us)=29332,6] 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, is this code changed / removed by the refactoring in progress in the client?&lt;/p&gt;</comment>
                            <comment id="13636464" author="nkeywal" created="Fri, 19 Apr 2013 15:08:55 +0000"  >&lt;p&gt;With the fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8380&quot; title=&quot;NPE in HBaseClient$Connection.readResponse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8380&quot;&gt;&lt;del&gt;HBASE-8380&lt;/del&gt;&lt;/a&gt;, it seems the stack is now in ycsb itself.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;Thread-1&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded
	at com.yahoo.ycsb.workloads.CoreWorkload.buildValues(CoreWorkload.java:436)
	at com.yahoo.ycsb.workloads.CoreWorkload.doInsert(CoreWorkload.java:460)
	at com.yahoo.ycsb.ClientThread.run(Client.java:269)
Exception in thread &quot;Thread-4&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.AbstractStringBuilder.&amp;lt;init&amp;gt;(AbstractStringBuilder.java:45)
	at java.lang.StringBuilder.&amp;lt;init&amp;gt;(StringBuilder.java:68)
	at com.yahoo.ycsb.workloads.CoreWorkload.buildValues(CoreWorkload.java:435)
	at com.yahoo.ycsb.workloads.CoreWorkload.doInsert(CoreWorkload.java:460)
	at com.yahoo.ycsb.ClientThread.run(Client.java:269)
 379 sec: 881056 operations; 49,97 current ops/sec; [INSERT AverageLatency(us)=66390,09] 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13636569" author="stack" created="Fri, 19 Apr 2013 16:33:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Stack, is this code changed / removed by the refactoring in progress in the client?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think so. It moves to a class named RpcClient instead.&lt;/p&gt;

&lt;p&gt;On the OOME, is that building a value to write?  It is not receiving a response?  And we are setting a bad size of response?&lt;/p&gt;
</comment>
                            <comment id="13636635" author="yuzhihong@gmail.com" created="Fri, 19 Apr 2013 17:27:19 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; creationTime = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
...
+              &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; waitingTime = delay + creationTime - &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please use EnvironmentEdgeManager.currentTimeMillis().&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-        &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.client.write.buffer&quot;&lt;/span&gt;, 2097152);
+        &lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.client.write.buffer&quot;&lt;/span&gt;, 2097152 * 2);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why increasing default write buffer size ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void flushCommits() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (backgroundSendSize &amp;gt; 0){
+      backgroundFlushCommits();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should we check currentWriteBufferSize &amp;gt; 0 in the if statement as well ?&lt;/p&gt;</comment>
                            <comment id="13637931" author="nkeywal" created="Mon, 22 Apr 2013 11:19:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;On the OOME, is that building a value to write? It is not receiving a response? And we are setting a bad size of response?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t know, I haven&apos;t reproduced it. I&apos;ve done a test with 5 datanodes on plain trunk, it seems much stable than with 3, so I will redo my tests with this config.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Please use EnvironmentEdgeManager.currentTimeMillis().&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It&apos;s still early stage. I prefer to do some workload test before going for the final design. For the performances, it seems great, but as well it&apos;s seems the increased workload on the server triggers some bad stuff. I wonder I I should not add a way to limit the load sent by the client to the rs, for example a given number of task per regionserver.&lt;/p&gt;

&lt;p&gt;I will do a new test tomorrow and publish a version then...&lt;/p&gt;</comment>
                            <comment id="13643087" author="nkeywal" created="Fri, 26 Apr 2013 18:12:42 +0000"  >&lt;p&gt;v4. I added a control per server: the client cannot have more than X request on a same server. If this number is reached, we continue for the other servers, but the ones on the overloaded servers are kept in the buffer. This will limit the rpc.timeout effect.&lt;/p&gt;

&lt;p&gt;It&apos;s still a hack in terms on implementation, but hopefully it&apos;s acceptable in terms of feature. I&apos;ve got some tests running locally, I will do one on a real cluster if they are ok.&lt;/p&gt;</comment>
                            <comment id="13644489" author="nkeywal" created="Mon, 29 Apr 2013 13:48:30 +0000"  >&lt;p&gt;I&apos;ve changed the per server task limit to a per region task limit.&lt;/p&gt;

&lt;p&gt;Here is the result of a test on 5 datanodes, ec2 xlarge instances, table not split. I&apos;ve executed the test multiple times on each config.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/ycsb load hbase -P workloads/workloada -s  -p columnfamily=family -p recordcount=100000000 | grep -v CLEAN | grep -v INSERT | grep -v UPDATE
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;without 6295&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 10 sec: 50159 operations; 5011,39 current ops/sec; [INSERT AverageLatency(us)=184,77] 
 20 sec: 127679 operations; 7748,9 current ops/sec; [INSERT AverageLatency(us)=121,76] 
 30 sec: 132239 operations; 455,77 current ops/sec; [INSERT AverageLatency(us)=242,47] 
 40 sec: 132239 operations; 0 current ops/sec;  
 50 sec: 132239 operations; 0 current ops/sec;  
 60 sec: 132239 operations; 0 current ops/sec;  
 70 sec: 132239 operations; 0 current ops/sec;  
 80 sec: 132239 operations; 0 current ops/sec;  
 90 sec: 167676 operations; 3532,04 current ops/sec; [INSERT AverageLatency(us)=1955,36] 
 100 sec: 250799 operations; 8308,98 current ops/sec; [INSERT AverageLatency(us)=114,35] 
 110 sec: 341999 operations; 9115,44 current ops/sec; [INSERT AverageLatency(us)=107,25] 
 120 sec: 428639 operations; 8660,54 current ops/sec; [INSERT AverageLatency(us)=109,67] 
 130 sec: 507844 operations; 7916,54 current ops/sec; [INSERT AverageLatency(us)=125,44] 
 140 sec: 588239 operations; 8035,48 current ops/sec; [INSERT AverageLatency(us)=120,31] 
 150 sec: 674879 operations; 8660,54 current ops/sec; [INSERT AverageLatency(us)=109,59] 
 160 sec: 729599 operations; 5469,27 current ops/sec; [INSERT AverageLatency(us)=111,25] 
 170 sec: 729599 operations; 0 current ops/sec;  
 180 sec: 729599 operations; 0 current ops/sec;  
 190 sec: 729599 operations; 0 current ops/sec;  
 200 sec: 729599 operations; 0 current ops/sec;  
 210 sec: 729599 operations; 0 current ops/sec;  
 220 sec: 729599 operations; 0 current ops/sec;  
 230 sec: 819076 operations; 8926,28 current ops/sec; [INSERT AverageLatency(us)=824,06] 
 240 sec: 911999 operations; 9287,66 current ops/sec; [INSERT AverageLatency(us)=102,68] 
 250 sec: 998639 operations; 8659,67 current ops/sec; [INSERT AverageLatency(us)=109,97] 
 260 sec: 1089839 operations; 9116,35 current ops/sec; [INSERT AverageLatency(us)=105,23] 
 270 sec: 1094399 operations; 455,77 current ops/sec; [INSERT AverageLatency(us)=219,31] 
 280 sec: 1094399 operations; 0 current ops/sec;  
 290 sec: 1094399 operations; 0 current ops/sec;  
 300 sec: 1098959 operations; 455,77 current ops/sec; [INSERT AverageLatency(us)=7326,11] 
 310 sec: 1098959 operations; 0 current ops/sec;  
 320 sec: 1098959 operations; 0 current ops/sec;  
 330 sec: 1131203 operations; 3222,79 current ops/sec; [INSERT AverageLatency(us)=1109,09] 
2013-04-29 09:06:04,357 INFO  [Thread-1] zookeeper.RecoverableZooKeeper (RecoverableZooKeeper.java:&amp;lt;init&amp;gt;(119)) - The identifier of this process is hconnection-0x8888e6c
2013-04-29 09:06:04,373 INFO  [Thread-1-SendThread(ip-10-68-135-50.ec2.internal:2181)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(966)) - Opening socket connection to server ip-10-68-135-50.ec2.internal/10.68.135.50:2181. Will not attempt to authenticate using SASL (Impossible de trouver une configuration de connexion)
2013-04-29 09:06:04,380 INFO  [Thread-1-SendThread(ip-10-68-135-50.ec2.internal:2181)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(849)) - Socket connection established to ip-10-68-135-50.ec2.internal/10.68.135.50:2181, initiating session
2013-04-29 09:06:04,391 INFO  [Thread-1-SendThread(ip-10-68-135-50.ec2.internal:2181)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1207)) - Session establishment complete on server ip-10-68-135-50.ec2.internal/10.68.135.50:2181, sessionid = 0x13e55e55e6e000e, negotiated timeout = 180000
 340 sec: 1158239 operations; 2702,52 current ops/sec; [INSERT AverageLatency(us)=39,33] 
 350 sec: 1158239 operations; 0 current ops/sec;  
 360 sec: 1158239 operations; 0 current ops/sec;  
 370 sec: 1158239 operations; 0 current ops/sec;  
 380 sec: 1158239 operations; 0 current ops/sec;  
 390 sec: 1158239 operations; 0 current ops/sec;  
 400 sec: 1244879 operations; 8659,67 current ops/sec; [INSERT AverageLatency(us)=790,06] 
 410 sec: 1326959 operations; 8203,9 current ops/sec; [INSERT AverageLatency(us)=52,75] 
 420 sec: 1326959 operations; 0 current ops/sec;  
 430 sec: 1326959 operations; 0 current ops/sec;  
 440 sec: 1326959 operations; 0 current ops/sec;  
 450 sec: 1326959 operations; 0 current ops/sec;  
 460 sec: 1326959 operations; 0 current ops/sec;  
 470 sec: 1349759 operations; 2279,09 current ops/sec; [INSERT AverageLatency(us)=2868,24] 
 480 sec: 1527599 operations; 17775,11 current ops/sec; [INSERT AverageLatency(us)=51,74] 
 490 sec: 1723679 operations; 19535,72 current ops/sec; [INSERT AverageLatency(us)=47,81] 
 500 sec: 1924319 operations; 20015,96 current ops/sec; [INSERT AverageLatency(us)=45,59] 
 510 sec: 2129519 operations; 20509,75 current ops/sec; [INSERT AverageLatency(us)=44,74] 
 520 sec: 2307359 operations; 17776,89 current ops/sec; [INSERT AverageLatency(us)=52,51] 
 530 sec: 2476079 operations; 16813,15 current ops/sec; [INSERT AverageLatency(us)=55,7] 
 540 sec: 2647330 operations; 17099,45 current ops/sec; [INSERT AverageLatency(us)=54,69] 
 550 sec: 2831759 operations; 18435,53 current ops/sec; [INSERT AverageLatency(us)=45,4] 
 560 sec: 2831759 operations; 0 current ops/sec;  
 570 sec: 2831759 operations; 0 current ops/sec;  
 580 sec: 2831759 operations; 0 current ops/sec;  
 590 sec: 2831759 operations; 0 current ops/sec;  
 600 sec: 2831759 operations; 0 current ops/sec;  
 610 sec: 2831759 operations; 0 current ops/sec;  
 620 sec: 2963999 operations; 13217,39 current ops/sec; [INSERT AverageLatency(us)=532,02] 
 630 sec: 2973119 operations; 911,64 current ops/sec; [INSERT AverageLatency(us)=47,38] 
 640 sec: 2973119 operations; 0 current ops/sec;  
 650 sec: 2973119 operations; 0 current ops/sec;  
 660 sec: 2973119 operations; 0 current ops/sec;  
 670 sec: 2973119 operations; 0 current ops/sec;  
 680 sec: 2973119 operations; 0 current ops/sec;  
^[( 690 sec: 2977679 operations; 455,77 current ops/sec; [INSERT AverageLatency(us)=14205,62] 
 700 sec: 2977679 operations; 0 current ops/sec;  
 710 sec: 2977679 operations; 0 current ops/sec;  
 720 sec: 3005039 operations; 2734,63 current ops/sec; [INSERT AverageLatency(us)=1225,72] 
 730 sec: 3032399 operations; 2734,63 current ops/sec; [INSERT AverageLatency(us)=185,11] 
 740 sec: 3032399 operations; 0 current ops/sec;  
 750 sec: 3032399 operations; 0 current ops/sec;  
 760 sec: 3032399 operations; 0 current ops/sec;  
 770 sec: 3032399 operations; 0 current ops/sec;  
 780 sec: 3032399 operations; 0 current ops/sec;  
 790 sec: 3064319 operations; 3190,72 current ops/sec; [INSERT AverageLatency(us)=2069,81] 
 800 sec: 3260399 operations; 19598,2 current ops/sec; [INSERT AverageLatency(us)=47,44] 
 810 sec: 3442799 operations; 18230,88 current ops/sec; [INSERT AverageLatency(us)=50,83] 
 820 sec: 3620639 operations; 17776,89 current ops/sec; [INSERT AverageLatency(us)=52,08] 
 830 sec: 3757439 operations; 13673,16 current ops/sec; [INSERT AverageLatency(us)=58,18] 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;With 6295&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 10 sec: 71333 operations; 7126,17 current ops/sec; [INSERT AverageLatency(us)=133,8] 
 20 sec: 159599 operations; 8823,07 current ops/sec; [INSERT AverageLatency(us)=95,37] 
 30 sec: 212639 operations; 5301,35 current ops/sec; [INSERT AverageLatency(us)=191,39] 
 40 sec: 284383 operations; 7171,53 current ops/sec; [INSERT AverageLatency(us)=145,36] 
 50 sec: 348278 operations; 6386,31 current ops/sec; [INSERT AverageLatency(us)=141,91] 
 60 sec: 453065 operations; 10473,46 current ops/sec; [INSERT AverageLatency(us)=92,35] 
 70 sec: 552922 operations; 9981,71 current ops/sec; [INSERT AverageLatency(us)=85,67] 
 80 sec: 654924 operations; 10195,1 current ops/sec; [INSERT AverageLatency(us)=104,82] 
 90 sec: 779759 operations; 12478,51 current ops/sec; [INSERT AverageLatency(us)=78,21] 
 100 sec: 779762 operations; 0,3 current ops/sec; [INSERT AverageLatency(us)=343108,67] 
 110 sec: 913636 operations; 13380,71 current ops/sec; [INSERT AverageLatency(us)=137,26] 
 120 sec: 1028664 operations; 11498,2 current ops/sec; [INSERT AverageLatency(us)=85,91] 
 130 sec: 1141992 operations; 11310,18 current ops/sec; [INSERT AverageLatency(us)=86,67] 
 140 sec: 1274264 operations; 13213,99 current ops/sec; [INSERT AverageLatency(us)=70,65] 
 150 sec: 1412375 operations; 13783,53 current ops/sec; [INSERT AverageLatency(us)=66,98] 
 160 sec: 1505215 operations; 9279,36 current ops/sec; [INSERT AverageLatency(us)=103,44] 
 170 sec: 1630561 operations; 12529,59 current ops/sec; [INSERT AverageLatency(us)=79,55] 
 180 sec: 1709829 operations; 7922,84 current ops/sec; [INSERT AverageLatency(us)=122,32] 
 190 sec: 1739109 operations; 2926,54 current ops/sec; [INSERT AverageLatency(us)=327,26] 
 200 sec: 1856100 operations; 11694,42 current ops/sec; [INSERT AverageLatency(us)=76,57] 
 210 sec: 1965944 operations; 10978,91 current ops/sec; [INSERT AverageLatency(us)=90,48] 
 220 sec: 2089603 operations; 12352,31 current ops/sec; [INSERT AverageLatency(us)=82,49] 
 230 sec: 2160518 operations; 7090,08 current ops/sec; [INSERT AverageLatency(us)=88,86] 
 240 sec: 2272941 operations; 11236,68 current ops/sec; [INSERT AverageLatency(us)=115,35] 
 250 sec: 2367483 operations; 9450,42 current ops/sec; [INSERT AverageLatency(us)=69,52] 
 260 sec: 2451594 operations; 8406,9 current ops/sec; [INSERT AverageLatency(us)=148,02] 
 270 sec: 2554506 operations; 10286,06 current ops/sec; [INSERT AverageLatency(us)=95,37] 
 280 sec: 2658804 operations; 10425,63 current ops/sec; [INSERT AverageLatency(us)=93,62] 
 290 sec: 2711871 operations; 5304,05 current ops/sec; [INSERT AverageLatency(us)=73,6] 
 300 sec: 2764352 operations; 5242,33 current ops/sec; [INSERT AverageLatency(us)=271,32] 
 310 sec: 2776791 operations; 1243,15 current ops/sec; [INSERT AverageLatency(us)=839,36] 
 320 sec: 2782455 operations; 566,12 current ops/sec; [INSERT AverageLatency(us)=1764,07] 
 330 sec: 2907870 operations; 12530,22 current ops/sec; [INSERT AverageLatency(us)=83,97] 
 340 sec: 3050598 operations; 14267,09 current ops/sec; [INSERT AverageLatency(us)=60,58] 
 350 sec: 3153205 operations; 10255,57 current ops/sec; [INSERT AverageLatency(us)=92,51] 
 360 sec: 3158971 operations; 576,37 current ops/sec; [INSERT AverageLatency(us)=1880,05] 
 370 sec: 3186783 operations; 2779,81 current ops/sec; [INSERT AverageLatency(us)=350,07] 
 380 sec: 3190037 operations; 325,14 current ops/sec; [INSERT AverageLatency(us)=3147,28] 
 390 sec: 3282451 operations; 9240,48 current ops/sec; [INSERT AverageLatency(us)=104,57] 
 400 sec: 3456366 operations; 17381,07 current ops/sec; [INSERT AverageLatency(us)=53,3] 
 410 sec: 3576864 operations; 12046,19 current ops/sec; [INSERT AverageLatency(us)=72,7] 
 420 sec: 3743489 operations; 16654,17 current ops/sec; [INSERT AverageLatency(us)=60,94] 
 430 sec: 3929387 operations; 18580,51 current ops/sec; [INSERT AverageLatency(us)=50,29] 
 440 sec: 4030892 operations; 10146,44 current ops/sec; [INSERT AverageLatency(us)=85,66] 
 450 sec: 4167314 operations; 13635,38 current ops/sec; [INSERT AverageLatency(us)=73,91] 
 460 sec: 4296216 operations; 12883,76 current ops/sec; [INSERT AverageLatency(us)=75,24] 
 470 sec: 4431010 operations; 13474,01 current ops/sec; [INSERT AverageLatency(us)=58,89] 
 480 sec: 4581058 operations; 14997,3 current ops/sec; [INSERT AverageLatency(us)=75,31] 
 490 sec: 4657821 operations; 7672,46 current ops/sec; [INSERT AverageLatency(us)=113,6] 
 500 sec: 4751360 operations; 9350,16 current ops/sec; [INSERT AverageLatency(us)=109] 
 510 sec: 4760708 operations; 934,33 current ops/sec; [INSERT AverageLatency(us)=1038,45] 
 520 sec: 4828627 operations; 6789,18 current ops/sec; [INSERT AverageLatency(us)=139,98] 
 530 sec: 4948462 operations; 11977,51 current ops/sec; [INSERT AverageLatency(us)=87,31] 
 540 sec: 5050637 operations; 10212,39 current ops/sec; [INSERT AverageLatency(us)=91,17] 
 550 sec: 5121323 operations; 7060,13 current ops/sec; [INSERT AverageLatency(us)=142,1] 
 560 sec: 5168196 operations; 4684,96 current ops/sec; [INSERT AverageLatency(us)=207,26] 
 570 sec: 5253669 operations; 8227,26 current ops/sec; [INSERT AverageLatency(us)=107,41] 
 580 sec: 5254516 operations; 84,67 current ops/sec; [INSERT AverageLatency(us)=3862,3] 
 590 sec: 5408430 operations; 15374,49 current ops/sec; [INSERT AverageLatency(us)=111,53] 
 600 sec: 5468717 operations; 6027,49 current ops/sec; [INSERT AverageLatency(us)=121,72] 
 610 sec: 5488564 operations; 1983,71 current ops/sec; [INSERT AverageLatency(us)=540] 
 620 sec: 5503674 operations; 1510,24 current ops/sec; [INSERT AverageLatency(us)=586,2] 
 630 sec: 5580591 operations; 7688,62 current ops/sec; [INSERT AverageLatency(us)=156,3] 
 640 sec: 5667381 operations; 8674,66 current ops/sec; [INSERT AverageLatency(us)=114,85] 
 650 sec: 5824473 operations; 15701,35 current ops/sec; [INSERT AverageLatency(us)=58,37] 
 660 sec: 5863498 operations; 3900,94 current ops/sec; [INSERT AverageLatency(us)=186,93] 
 670 sec: 5867286 operations; 378,61 current ops/sec; [INSERT AverageLatency(us)=1906,5] 
 680 sec: 5881480 operations; 1418,83 current ops/sec; [INSERT AverageLatency(us)=969,62] 
 690 sec: 5918807 operations; 3730,83 current ops/sec; [INSERT AverageLatency(us)=300,35] 
 700 sec: 5926122 operations; 731,13 current ops/sec; [INSERT AverageLatency(us)=1207,91] 
 710 sec: 6115204 operations; 18900,64 current ops/sec; [INSERT AverageLatency(us)=50,77] 
 720 sec: 6116016 operations; 80,26 current ops/sec; [INSERT AverageLatency(us)=12618,78] 
 731 sec: 6168475 operations; 5043,65 current ops/sec; [INSERT AverageLatency(us)=194,3] 
 741 sec: 6169493 operations; 99,1 current ops/sec; [INSERT AverageLatency(us)=5123,27] 
 751 sec: 6206016 operations; 3518,25 current ops/sec; [INSERT AverageLatency(us)=391,2] 
 761 sec: 6231541 operations; 2550,46 current ops/sec; [INSERT AverageLatency(us)=467,12] 
 771 sec: 6252864 operations; 2131,23 current ops/sec; [INSERT AverageLatency(us)=430,23] 
 781 sec: 6304020 operations; 5104,88 current ops/sec; [INSERT AverageLatency(us)=202,38] 
 791 sec: 6328025 operations; 2399,54 current ops/sec; [INSERT AverageLatency(us)=368,89] 
 801 sec: 6337032 operations; 900,25 current ops/sec; [INSERT AverageLatency(us)=1175,08] 
 812 sec: 6345672 operations; 863,57 current ops/sec; [INSERT AverageLatency(us)=1005,39] 
 822 sec: 6369258 operations; 2339,88 current ops/sec; [INSERT AverageLatency(us)=409,83] 
 832 sec: 6380343 operations; 1107,95 current ops/sec; [INSERT AverageLatency(us)=763,3] 
 842 sec: 6391880 operations; 1153,24 current ops/sec; [INSERT AverageLatency(us)=1177,43] 
 852 sec: 6460288 operations; 6837,38 current ops/sec; [INSERT AverageLatency(us)=143,37] 
 862 sec: 6465474 operations; 504,82 current ops/sec; [INSERT AverageLatency(us)=1027,68] 
 872 sec: 6496268 operations; 3078,17 current ops/sec; [INSERT AverageLatency(us)=296,25] 
 882 sec: 6531310 operations; 3502,45 current ops/sec; [INSERT AverageLatency(us)=439,09] 
 892 sec: 6541217 operations; 990,2 current ops/sec; [INSERT AverageLatency(us)=873,16] 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, in this test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;We nearly twice faster (for some tests the gap was not that huge, but still over 80%).&lt;/li&gt;
	&lt;li&gt;We don&apos;t have period of 20s or more where we do nothing (hence that&apos;s likely why we&apos;re twice faster at the end).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Bad news beeing:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;it crashes a lot, whatever the version (plain trunk or trunk with 6295).&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="13644676" author="nkeywal" created="Mon, 29 Apr 2013 17:41:27 +0000"  >&lt;p&gt;Example of exception (with 6295 on):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-04-29 12:05:51,515 DEBUG [IPC Client (1280551684) connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020 from root] ipc.HBaseClient: IPC Client (1280551684) connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020 from root: got response header exception { exceptionClassName: &quot;org.apache.hadoop.hbase.exceptions.RegionTooBusyException&quot; stackTrace: &quot;org.apache.hadoop.hbase.exceptions.RegionTooBusyException: region is flushing\n\tat org.apache.hadoop.hbase.regionserver.HRegion.checkResources(HRegion.java:2477)\n\tat org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:1869)\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:3822)\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3237)\n\tat sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine$Server.call(ProtobufRpcServerEngine.java:174)\n\tat org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1874)\n&quot; }
2013-04-29 12:05:51,519 DEBUG [IPC Client (1280551684) connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020 from root] ipc.HBaseClient: IPC Client (1280551684) connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020 from root: closing ipc connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020: Protocol message tag had invalid wire type.
com.google.protobuf.InvalidProtocolBufferException: Protocol message tag had invalid wire type.
        at com.google.protobuf.InvalidProtocolBufferException.invalidWireType(InvalidProtocolBufferException.java:78)
        at com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:498)
        at com.google.protobuf.GeneratedMessage$Builder.parseUnknownField(GeneratedMessage.java:438)
        at org.apache.hadoop.hbase.protobuf.generated.RPCProtos$ExceptionResponse$Builder.mergeFrom(RPCProtos.java:2225)
        at org.apache.hadoop.hbase.protobuf.generated.RPCProtos$ExceptionResponse$Builder.mergeFrom(RPCProtos.java:2071)
        at com.google.protobuf.CodedInputStream.readMessage(CodedInputStream.java:275)
        at org.apache.hadoop.hbase.protobuf.generated.RPCProtos$ResponseHeader$Builder.mergeFrom(RPCProtos.java:3713)
        at org.apache.hadoop.hbase.protobuf.generated.RPCProtos$ResponseHeader$Builder.mergeFrom(RPCProtos.java:3541)
        at com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:212)
        at com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:746)
        at com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:238)
        at com.google.protobuf.AbstractMessageLite$Builder.mergeDelimitedFrom(AbstractMessageLite.java:282)
        at com.google.protobuf.AbstractMessage$Builder.mergeDelimitedFrom(AbstractMessage.java:760)
        at com.google.protobuf.AbstractMessageLite$Builder.mergeDelimitedFrom(AbstractMessageLite.java:288)
        at com.google.protobuf.AbstractMessage$Builder.mergeDelimitedFrom(AbstractMessage.java:752)
        at org.apache.hadoop.hbase.protobuf.generated.RPCProtos$ResponseHeader.parseDelimitedFrom(RPCProtos.java:3498)
        at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.readResponse(HBaseClient.java:994)
        at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:661)
2013-04-29 12:05:51,521 DEBUG [IPC Client (1280551684) connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020 from root] ipc.HBaseClient: IPC Client (1280551684) connection to ip-10-68-155-141.ec2.internal/10.68.155.141:60020 from root: closed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m unclear on the impact, but at a point it stops working, so it could have one.&lt;/p&gt;</comment>
                            <comment id="13644701" author="stack" created="Mon, 29 Apr 2013 18:10:19 +0000"  >&lt;p&gt;RegionTooBusyException is a new one on me (I&apos;ll work on the ugly pb message in another issue)&lt;/p&gt;</comment>
                            <comment id="13645801" author="nkeywal" created="Tue, 30 Apr 2013 18:12:08 +0000"  >&lt;p&gt;v5 starts to be feature complete. I think I implemented the same interface as of today.&lt;br/&gt;
It may be too early for a complete review, but feedback on the approach is welcome. Do I break something critical in the interface? I don&apos;t know if I will be able to remove the code duplication.&lt;/p&gt;</comment>
                            <comment id="13645874" author="hadoopqa" created="Tue, 30 Apr 2013 19:32:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12581202/6295.v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12581202/6295.v5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.util.TestHBaseFsck&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationSmallTests&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationQueueFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5503//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13646260" author="sershe" created="Wed, 1 May 2013 01:06:09 +0000"  >&lt;p&gt;There are some nits in the patch that I won&apos;t go thru for now since it&apos;s not complete.&lt;br/&gt;
Lots of the code seems to be copied from other parts of HCM, and the original is not removed, will it be removed? Otherwise there&apos;s duplication.&lt;/p&gt;

&lt;p&gt;Also, what happens to rows that are not added in AsyncProcess::submit? Not clear on that&lt;/p&gt;</comment>
                            <comment id="13646465" author="nkeywal" created="Wed, 1 May 2013 08:52:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;Also, what happens to rows that are not added in AsyncProcess::submit? Not clear on that&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; Thanks for having a look. I wrote a short summary that I will put in the javadoc or in the hbase ref guide to explain what the code is supposed to do.&lt;/p&gt;
&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;The puts are sent asynchronously. The interface is 100% compatible with the HTable interface that we had in 0.94 and before.&lt;br/&gt;
If autoflush is set to false, writes are buffered in HTable. When the buffer size goes beyond the value defined in &quot;hbase.client.write.buffer&quot;, the buffer is sent asynchronously to the server. Retries will be also be managed independently. We block only:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if the users code calls HTable#flushCommit&lt;/li&gt;
	&lt;li&gt;if the user code calls HTable#close, because it implies a flushCommit&lt;/li&gt;
	&lt;li&gt;if we run out of retries for an operation: in this case we finish all the writes in progress, an raise a single aggregated error.&lt;/li&gt;
	&lt;li&gt;if we met one of the flow control condition detailed below.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It&apos;s possible to control the client stream with two parameters:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;hbase.client.max.total.tasks&quot;: number of task that we can run simultaneously. If the buffer goes beyond &quot;hbase.client.write.buffer&quot; and the number of tasks currently in progress is greater then &quot;hbase.client.max.total.tasks&quot;, we block until some of the tasks finishes. This parameter must be set accordingly with the cluster size: if there are 1000 machines in the cluster, it may make sense to have a few thousand conccurrent tasks for some tables.&lt;/li&gt;
	&lt;li&gt;&quot;hbase.client.max.perregion.tasks&quot;: number of tasks in progress for the same region. When doing a background flush, puts for a region that has already &quot;hbase.client.max.perregion.tasks&quot; or more tasks in progress are skipped, and remain in the HTable write buffer. They will be sent into a later background flush. If, when doing a background flush, all entries are skipped, we block until a slot becomes available.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Now that I wrote this, I think I have a bug in the way I manage errors and clearBufferOnFail: may be the write buffer should contain only failes puts. I will check this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Lots of the code seems to be copied from other parts of HCM, and the original is not removed, will it be removed? Otherwise there&apos;s duplication.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I really don&apos;t know. The problem I have is that this API is public. So while it&apos;s transparent in HTable (I don&apos;t change the interface nor its contract), it&apos;s not the case for the methods in HConnectionManager. That&apos;s why I added some methods: it allows to keep the existing interface of HConnectionManager while adding the background flush. I thought about implementing the previous synchronous interface with the new asynchronous methods, but I feel it can make them more fragile. I don&apos;t have any real opinion here, the whole existing code could be refactored quite a lot. That&apos;s why the patch is not final, but I can&apos;t say if the final patch will/should remove the duplication.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;RegionTooBusyException is a new one on me (I&apos;ll work on the ugly pb message in another issue)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;. In my tests, it seems the servers hangs at a point. I can stop the client and restart it, the server does not accept any new operation (for something like 5 minutes). I don&apos;t know if it&apos;s related to my changes, but it&apos;s fishy. I will do a test with a server without 6295.&lt;/p&gt;</comment>
                            <comment id="13647695" author="nkeywal" created="Thu, 2 May 2013 16:57:41 +0000"  >&lt;p&gt;I&apos;ve looked at the existing code, trying to remove the duplication:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the parametization of Process is likely wrong. It seems it was coded for the return type used in the callback, but then was misunderstood.&lt;/li&gt;
	&lt;li&gt;If we want to remove the existing Process&amp;lt;R&amp;gt; class, we should remove as well the functions that uses them. They should be replaced with the new one, and we should have callbacks for errors (today, the functions are not really asynchronous, as the there is callback only for success).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think it can be done in another patch (and removing the existing interface is another subject).&lt;/p&gt;

&lt;p&gt;So we&apos;re close to a reviewable patch imho. &lt;/p&gt;</comment>
                            <comment id="13658786" author="yuzhihong@gmail.com" created="Wed, 15 May 2013 20:43:18 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; List&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Row&amp;gt; getFailedOperation(){
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;getFailedOperation -&amp;gt; getFailedOperations&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; AsyncProcess(HConnection hci, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] tableName, ExecutorService pool,
+                          Batch.Callback&amp;lt;Res&amp;gt; callback){
+        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.hci = (HConnectionImplementation)hci;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If methods of HConnectionImplementation which are not in HConnection are used, parameter hci should be declared as HConnectionImplementation.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void submit(List&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Row&amp;gt; rowList) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+        waitForMaximumTaskNumber(maxTotalConcurrentTasks);
+
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!hasError()){
+          submit(rowList, 1, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
+        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For else case, should error condition be conveyed through boolean return value or some exception ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+       * @param rowList
+       * @param numAttempt
+       * @&lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException - &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we can&apos;t locate a region after multiple retries.
+       */
+      &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void submit(List&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Row&amp;gt; rowList, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numAttempt, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; force)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please add force parameter to javadoc. Brief explanation for the parameters should help.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (loc == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+              &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;No location found, aborting submit.&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think including tableName and row.getRow() in exception message would help debug.&lt;/p&gt;</comment>
                            <comment id="13658857" author="sershe" created="Wed, 15 May 2013 21:38:22 +0000"  >&lt;p&gt;Can you post it on rb?&lt;/p&gt;

&lt;p&gt;Also, there&apos;s still large scale (hundreds of lines) copy-pasted code shared between AsyncProcess and Process. If we don&apos;t get rid of Process fast (and I suspect realistically we won&apos;t) it can become a problem. Can at least some shared code be made shared?&lt;/p&gt;

&lt;p&gt;Also, patch needs a little bit of rebasing.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; R result;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can you please update the main comment in this file on why this is necessary.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          Row row = it.next();
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (row != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Is it a legal condition?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; &lt;span class=&quot;code-comment&quot;&gt;// to move to trace, &lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Move to trace? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (LOG.isTraceEnabled() &amp;amp;&amp;amp; numAttempt &amp;gt; 0) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is numAttempt the number of tries, or retries? The above &quot;&amp;gt; 1&quot; would seem to indicate the former, but this checks &amp;gt;0.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nextLog == 0){
            nextLog = EnvironmentEdgeManager.currentTimeMillis() + 3000;
          }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This can just be set before the start of the loop.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (EnvironmentEdgeManager.currentTimeMillis() &amp;gt; nextLog) {
...
            }
            nextLog = EnvironmentEdgeManager.currentTimeMillis() + 5000;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This will update nextLog in every iteration of the loop (after the first), so &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (EnvironmentEdgeManager.currentTimeMillis() &amp;gt; nextLog)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;will never (well, almost never, technically) become true.&lt;br/&gt;
Only needs to be updated when logging.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          retriedErrors = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BatchErrors&amp;lt;Row&amp;gt;();
          RetriesExhaustedWithDetailsException exception = errors.makeException();
          errors  = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BatchErrors&amp;lt;Row&amp;gt;();
          retriedErrors = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BatchErrors&amp;lt;Row&amp;gt;();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why does this do resetting of retriedErrors? And twice, too.&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

    /**
     * Methods and attributes to manage a batch process are grouped into &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; single class.
     * This allows, by creating a &lt;span class=&quot;code-object&quot;&gt;Process&lt;/span&gt;&amp;lt;R&amp;gt; per batch process to ensure multithread safety.
     *
     * This code should be move to HTable once processBatchCallback is not supported anymore in
     * the HConnection &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt;.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Javadoc for new class is also copy-pasted. Can you please write javadoc that explains what it does?&lt;/p&gt;

&lt;p&gt;Code in HTable looks very non-thread-safe, I am assuming that is ok.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; HConnectionManager.HConnectionImplementation.AsyncProcess&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt; ap;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why is there just one AsyncProcess per table? I thought it was supposed to be per batch request?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      ap.submit(writeAsyncBuffer);
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (previousSize == writeAsyncBuffer.size()) {
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(1000);
        } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException e) {
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; InterruptedIOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Still not sent: &quot;&lt;/span&gt; + writeAsyncBuffer.size() + &lt;span class=&quot;code-quote&quot;&gt;&quot; rows.&quot;&lt;/span&gt;);
        }
        ap.submit(writeAsyncBuffer);
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why does it keep submitting the same buffer again and again?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!clearBufferOnFail){
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (ap.hasError()){
          ap.waitUntilDone();
          writeAsyncBuffer.addAll(ap.getFailedOperation());
        }
      }
      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;What is this for? If put calls doPut, doPut calls backgroundFlushCommits, and this happens and puts some stuff into writeAsyncBuffer, &lt;br/&gt;
exception will be thrown outside of put. What will the data be used for inside the buffer?&lt;br/&gt;
Since getWriteBuffer is removed and there&apos;s no way to get at this buffer.&lt;/p&gt;

&lt;p&gt;Nit: Batch.java has some whitespace added at the end.&lt;/p&gt;

&lt;p&gt;ZKUtil has some change in deleteNodeFailSilent that look unrelated.&lt;/p&gt;</comment>
                            <comment id="13661080" author="nkeywal" created="Fri, 17 May 2013 21:58:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;HConnectionImplementation which are not in HConnection&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The problem i have here is the link between HTable and HConnectionImplementation. I don&apos;t have a nice solution.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think including tableName and row.getRow() in exception message would help debug.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;ve done it for tableName but not for getRow as it would be quite big sometimes.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, there&apos;s still large scale (hundreds of lines) copy-pasted code shared between AsyncProcess and Process. If we don&apos;t get rid of Process fast (and I suspect realistically we won&apos;t) it can become a problem. Can at least some shared code be made shared?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s the big one. &apos;Process&apos; is not a public class. I tried to reimplement the functions that use it with the Async process. The tests are not yet fine locally. I will push to RB once it&apos;s ok.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is it a legal condition?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It&apos;s historical. It means that someone could send a list with some nulls in the middle. I preferred to keep it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Since getWriteBuffer is removed and there&apos;s no way to get at this buffer.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I removed it because it was not in HTableInterface and it was an implementation leak. This said, everybody uses HTable directly. I put it back.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Code in HTable looks very non-thread-safe, I am assuming that is ok.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, HTable is non threadsafe by design. The idea is to have no lock at all in this class (but I had to put some in AsyncProcess as there is some mt stuff because of the callbacks).&lt;/p&gt;
</comment>
                            <comment id="13663266" author="nkeywal" created="Tue, 21 May 2013 19:04:53 +0000"  >&lt;p&gt;rb: &lt;a href=&quot;https://reviews.apache.org/r/11318/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11318/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13668268" author="nkeywal" created="Tue, 28 May 2013 12:12:38 +0000"  >&lt;p&gt;local tests ok. put on rb as well.&lt;/p&gt;</comment>
                            <comment id="13668309" author="hadoopqa" created="Tue, 28 May 2013 13:52:34 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12585022/6295.v8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12585022/6295.v8.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 5 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the trunk&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplicationQueueFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHCM&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5848//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13668430" author="stack" created="Tue, 28 May 2013 16:40:41 +0000"  >&lt;p&gt;Are the above failures because of the patch?&lt;/p&gt;

&lt;p&gt;The new class needs a license.&lt;/p&gt;

&lt;p&gt;Great class doc on the the new AsyncProcess class&lt;/p&gt;

&lt;p&gt;Does AsyncProcessCallback have to be public?  Is it only used inside the client package?   If so, shut down access.&lt;/p&gt;

&lt;p&gt;We need these atomics +    AtomicInteger ct = taskCounterPerRegion.get(encodedRegionName);?  It is single threaded access right?  Or you need it for internals?&lt;/p&gt;

&lt;p&gt;Why we need to add this, updateCachedLocations, if its internally used?  It means you can use HConnection in more places instead of HCI?&lt;/p&gt;

&lt;p&gt;Is this a Result or not?&lt;/p&gt;

&lt;p&gt;+  static class MyAsyncProcess&amp;lt;Res&amp;gt; extends AsyncProcess&amp;lt;Res&amp;gt; {&lt;/p&gt;

&lt;p&gt;If so, why not Result?  If not and it is just generic, just R?  Res confuses.&lt;/p&gt;

&lt;p&gt;I love the test for the new class.&lt;/p&gt;

&lt;p&gt;Excellent.&lt;/p&gt;

&lt;p&gt;+1 after fixing unit tests.&lt;/p&gt;</comment>
                            <comment id="13668441" author="nkeywal" created="Tue, 28 May 2013 16:53:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;Are the above failures because of the patch?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;TestHCM it&apos;s a bad fix of an old hidden bug. I&apos;ve got what I expect to be the right fix. I&apos;m testing it locally right now.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The new class needs a license.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;done.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Does AsyncProcessCallback have to be public? Is it only used inside the client package? If so, shut down access.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We need these atomics + AtomicInteger ct = taskCounterPerRegion.get(encodedRegionName);? It is single threaded access right? Or you need it for internals?&lt;/p&gt;&lt;/blockquote&gt;


&lt;blockquote&gt;&lt;p&gt;+ static class MyAsyncProcess&amp;lt;Res&amp;gt; extends AsyncProcess&amp;lt;Res&amp;gt; {&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It should. I will double check.&lt;br/&gt;
We need them because the client is monotheaded, but we receive the results, and resubmit in parallel.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why we need to add this, updateCachedLocations, if its internally used? It means you can use HConnection in more places instead of HCI?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I removed the cast to HCI (but I now have to push updateCachedLocations in the interface).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If so, why not Result? If not and it is just generic, just R? Res confuses.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Will do.&lt;/p&gt;

&lt;p&gt;I&apos;m going to test it on a real cluster. I&apos;ve actually tested a lot trunk with a 1.7, it was working great globally. But right now, still with trunk, I got stuck. I&apos;m also going to test the 0.95.1.&lt;/p&gt;</comment>
                            <comment id="13668451" author="stack" created="Tue, 28 May 2013 17:04:16 +0000"  >&lt;p&gt;Would suggest re-adding the cast rather than add new method to HConnection (even though I suggested using HConnection instead of HCI)?  I say this because the method added seems like it should not be public. &lt;/p&gt;

&lt;p&gt;Up to you N.  What ever makes most sense.&lt;/p&gt;</comment>
                            <comment id="13668496" author="nkeywal" created="Tue, 28 May 2013 18:01:49 +0000"  >&lt;p&gt;v9 contains the &quot;done&quot; mentioned above. The &quot;will do&quot; will come in a later version.&lt;br/&gt;
For cast vs. interface I don&apos;t have a strong opinion... I will see in the next version.&lt;/p&gt;</comment>
                            <comment id="13668571" author="hadoopqa" created="Tue, 28 May 2013 19:10:28 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12585051/6295.v9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12585051/6295.v9.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 5 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed&lt;br/&gt;
                  org.apache.hadoop.hbase.replication.TestReplicationQueueFailover&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestHCM&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5851//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13668693" author="sershe" created="Tue, 28 May 2013 21:20:38 +0000"  >&lt;p&gt;patch looks reasonable so far... can you please file a jira for Process code de-duping/removal&lt;/p&gt;</comment>
                            <comment id="13668712" author="nkeywal" created="Tue, 28 May 2013 21:44:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;can you please file a jira for Process code de-duping/removal&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;ve removed the Process class already &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
I need to look at these test errors. I haven&apos;t got them locally.&lt;/p&gt;</comment>
                            <comment id="13680076" author="yuzhihong@gmail.com" created="Tue, 11 Jun 2013 00:14:57 +0000"  >&lt;p&gt;For AsyncProcess:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * This &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; allows to keep the &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; of the previous synchronous &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt;, that uses
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;keep the interface of the previous synchronous interface&apos; -&amp;gt; &apos;keep the previous synchronous interface&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; AsyncProcessCallback&amp;lt;Result&amp;gt; {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above interface can be package-private.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; failure(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; originalIndex, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] region, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] row, Throwable t);
+    &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; retriableFailure(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; originalIndex, Row row, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] region, Throwable exception);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why the row is passed as different types in the above two methods ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void addAction(HRegionLocation loc, Action&amp;lt;Row&amp;gt; action, Map&amp;lt;HRegionLocation,
+      MultiAction&amp;lt;Row&amp;gt;&amp;gt; actionsByServer) {
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (loc != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: you can use &apos;if (loc == null) {&apos; to return early.&lt;/p&gt;

&lt;p&gt;For shouldSubmit():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        locationException = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;No location found, aborting submit &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;&quot;&lt;/span&gt; +
+            &lt;span class=&quot;code-quote&quot;&gt;&quot; tableName=&quot;&lt;/span&gt; + Bytes.toString(tableName));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should row key be included in the above message ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    Map&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;&amp;gt; regionStatus = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashMap&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;&amp;gt;();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Add comment for the meaning of the Boolean value ?&lt;/p&gt;</comment>
                            <comment id="13680501" author="yuzhihong@gmail.com" created="Tue, 11 Jun 2013 17:05:11 +0000"  >&lt;p&gt;Putting patch on cluster, I saw a lot of the following in the log:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-06-11 16:51:19,806 INFO  [HBaseWriterThread_11] client.AsyncProcess: won: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; number of tasks to be equals or less than 0, currently it&apos;s 1
2013-06-11 16:51:19,807 INFO  [HBaseWriterThread_18] client.AsyncProcess: won: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; number of tasks to be equals or less than 0, currently it&apos;s 1
2013-06-11 16:51:19,807 INFO  [HBaseWriterThread_15] client.AsyncProcess: won: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; number of tasks to be equals or less than 0, currently it&apos;s 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the above log should be at TRACE level.&lt;/p&gt;</comment>
                            <comment id="13683434" author="jmspaggi" created="Fri, 14 Jun 2013 15:18:06 +0000"  >&lt;p&gt;Hi Nicolas,&lt;/p&gt;

&lt;p&gt;Has requested, here are some performances tests for your patch.&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest 765360.3&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomScanWithRange100Test 21109.7&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomSeekScanTest 126617.6&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest 1046473.4&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest 762233.175&lt;/p&gt;


&lt;p&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest 773127.4&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomScanWithRange100Test 22348.3&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomSeekScanTest 134876.5&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest 115992.9&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest 78791.275&lt;/p&gt;


&lt;p&gt;First set is with your patch applied on yesterday&apos;s trunk.&lt;br/&gt;
Second set is yesterday&apos;s trunk without your patch.&lt;/p&gt;

&lt;p&gt;the reads and scans are not impacted, but the writes are negatively impacted with the version I tried.&lt;/p&gt;

&lt;p&gt;Just let me know when you will be ready with your next version and I will be very happy test it again.&lt;/p&gt;</comment>
                            <comment id="13683493" author="nkeywal" created="Fri, 14 Jun 2013 16:26:01 +0000"  >&lt;p&gt;Thanks again, Jean-Marc. I&apos;m going to work on a new version.&lt;/p&gt;</comment>
                            <comment id="13684524" author="jmspaggi" created="Sat, 15 Jun 2013 23:57:24 +0000"  >&lt;p&gt;Do you want me to give a try to the version 11?&lt;/p&gt;</comment>
                            <comment id="13684569" author="nkeywal" created="Sun, 16 Jun 2013 04:33:20 +0000"  >&lt;p&gt;I was expecting a qa run that&apos;s never came, but if you have time please do.&lt;br/&gt;
The issue was in flush commit, it&apos;s fixed.&lt;br/&gt;
Le 15 juin 2013 17:59, &quot;Jean-Marc Spaggiari (JIRA)&quot; &amp;lt;jira@apache.org&amp;gt; a&lt;/p&gt;
</comment>
                            <comment id="13684805" author="stack" created="Sun, 16 Jun 2013 21:25:33 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~liochon&amp;#93;&lt;/span&gt; I am not sure why precommit stops working.  I triggereed one manually for you: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6046/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6046/console&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13684919" author="nkeywal" created="Mon, 17 Jun 2013 02:31:34 +0000"  >&lt;p&gt;Thanks Stack. This build failed without a clear reason. I&apos;ve built a new patch and triggered a build myself....&lt;/p&gt;</comment>
                            <comment id="13685466" author="jmspaggi" created="Mon, 17 Jun 2013 11:32:25 +0000"  >&lt;p&gt;Results...&lt;/p&gt;

&lt;p&gt;First, I&apos;m getting a lot of this in the new version:&lt;/p&gt;

&lt;p&gt;2013-06-17 02:02:01,660 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;hbase-table-pool-6-thread-1&amp;#93;&lt;/span&gt; client.AsyncProcess: Attempt #1 failed for 1395 operations on server hbasetest,56046,1371448843669, resubmitting 1395, tableName=TestTable, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: TestTable,00000000000000000000057204,1371448911838.a2579d421e3a844ef5cc87d84219defe. is closing&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.startRegionOperation(HRegion.java:5347)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.startRegionOperation(HRegion.java:5315)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:1921)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:3954)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:3915)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3271)&lt;br/&gt;
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)&lt;/p&gt;


&lt;p&gt;And not any on the trunk version.&lt;/p&gt;

&lt;p&gt;RandomWriteTests on your version took an average of 69712 seconds&lt;br/&gt;
RandomWriteTests on trunk took an average of 112591.3 seconds&lt;/p&gt;

&lt;p&gt;So I can see an improvement, but now need to figure if the data is correct or not...&lt;/p&gt;

&lt;p&gt;I have the results for the reads too. I will extract them and post them here. I will also run some other tests to see if the data is correct or not...&lt;/p&gt;</comment>
                            <comment id="13685492" author="jmspaggi" created="Mon, 17 Jun 2013 12:21:29 +0000"  >&lt;p&gt;Here are the results for your version:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest 728486.5&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomScanWithRange100Test 22197.4&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomSeekScanTest 137125.4&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest 69712&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest 24342.1&lt;/p&gt;

&lt;p&gt;Trunk:&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest 757343.8&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomScanWithRange100Test 21856.6&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomSeekScanTest 134333&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest 112591.3&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest 77897.975&lt;/p&gt;

&lt;p&gt;Comparaison (The smaller the better):&lt;br/&gt;
org,apache,hadoop,hbase,PerformanceEvaluation$RandomReadTest 	-4%&lt;br/&gt;
org,apache,hadoop,hbase,PerformanceEvaluation$RandomScanWithRange100Test	2%&lt;br/&gt;
org,apache,hadoop,hbase,PerformanceEvaluation$RandomSeekScanTest 	2%&lt;br/&gt;
org,apache,hadoop,hbase,PerformanceEvaluation$RandomWriteTest	-62%&lt;br/&gt;
org,apache,hadoop,hbase,PerformanceEvaluation$SequentialWriteTest 	-220%&lt;/p&gt;

&lt;p&gt;I now have IntegrationTestBigLinkedList running and will run more. I keep you posted.&lt;/p&gt;</comment>
                            <comment id="13685560" author="jmspaggi" created="Mon, 17 Jun 2013 13:48:13 +0000"  >&lt;p&gt;Other tests seems to be consistent even if I don&apos;t get the exact same results... Will do some more.&lt;/p&gt;

&lt;p&gt;bin/hbase org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList Loop 2 1 3000000 /tmp/biglinkedlist 1&lt;/p&gt;

&lt;p&gt;Trunk:&lt;br/&gt;
2013-06-17 08:37:08,264 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Job complete: job_local_0006&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Counters: 31&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Verify$Counts&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REFERENCED=6000000&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   HBase Counters&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_CALLS=0&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_CALLS=609&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_RETRIES=0&lt;br/&gt;
2013-06-17 08:37:08,265 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NOT_SERVING_REGION_EXCEPTION=0&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NUM_SCANNER_RESTARTS=0&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     MILLIS_BETWEEN_NEXTS=41071&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_RESULTS=360000000&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_REMOTE_RESULTS=0&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REGIONS_SCANNED=4&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_RETRIES=0&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Output Format Counters&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Written=8&lt;br/&gt;
2013-06-17 08:37:08,266 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   FileSystemCounters&lt;br/&gt;
2013-06-17 08:37:08,267 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_READ=5696162333&lt;br/&gt;
2013-06-17 08:37:08,267 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_WRITTEN=6730223455&lt;br/&gt;
2013-06-17 08:37:08,267 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Input Format Counters&lt;br/&gt;
2013-06-17 08:37:08,267 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Read=0&lt;br/&gt;
2013-06-17 08:37:08,267 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   Map-Reduce Framework&lt;br/&gt;
2013-06-17 08:37:08,267 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output materialized bytes=414000024&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map input records=6000000&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce shuffle bytes=0&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Spilled Records=39145720&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output bytes=390000000&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Total committed heap usage (bytes)=1303552000&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     CPU time spent (ms)=0&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     SPLIT_RAW_BYTES=422&lt;br/&gt;
2013-06-17 08:37:08,268 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine input records=0&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input records=12000000&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input groups=6000000&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine output records=0&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Physical memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce output records=0&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Virtual memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 08:37:08,269 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output records=12000000&lt;br/&gt;
2013-06-17 08:37:08,271 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; test.IntegrationTestBigLinkedList$Loop: Verify finished with succees. Total nodes=6000000&lt;/p&gt;


&lt;p&gt;Nic:&lt;br/&gt;
2013-06-17 08:44:47,530 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Job complete: job_local_0006&lt;br/&gt;
2013-06-17 08:44:47,531 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Counters: 31&lt;br/&gt;
2013-06-17 08:44:47,531 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Verify$Counts&lt;br/&gt;
2013-06-17 08:44:47,531 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REFERENCED=6000000&lt;br/&gt;
2013-06-17 08:44:47,531 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   HBase Counters&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_CALLS=0&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_CALLS=607&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_RETRIES=0&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NOT_SERVING_REGION_EXCEPTION=0&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NUM_SCANNER_RESTARTS=0&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     MILLIS_BETWEEN_NEXTS=39871&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_RESULTS=360000000&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_REMOTE_RESULTS=0&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REGIONS_SCANNED=3&lt;br/&gt;
2013-06-17 08:44:47,532 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_RETRIES=0&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Output Format Counters&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Written=8&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   FileSystemCounters&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_READ=5185648641&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_WRITTEN=6110147770&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Input Format Counters&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Read=0&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   Map-Reduce Framework&lt;br/&gt;
2013-06-17 08:44:47,533 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output materialized bytes=414000018&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map input records=6000000&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce shuffle bytes=0&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Spilled Records=41455689&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output bytes=390000000&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Total committed heap usage (bytes)=1262878720&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     CPU time spent (ms)=0&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     SPLIT_RAW_BYTES=302&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine input records=0&lt;br/&gt;
2013-06-17 08:44:47,534 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input records=12000000&lt;br/&gt;
2013-06-17 08:44:47,535 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input groups=6000000&lt;br/&gt;
2013-06-17 08:44:47,535 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine output records=0&lt;br/&gt;
2013-06-17 08:44:47,535 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Physical memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 08:44:47,535 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce output records=0&lt;br/&gt;
2013-06-17 08:44:47,535 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Virtual memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 08:44:47,535 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output records=12000000&lt;br/&gt;
2013-06-17 08:44:47,536 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; test.IntegrationTestBigLinkedList$Loop: Verify finished with succees. Total nodes=6000000&lt;/p&gt;







&lt;p&gt;bin/hbase org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify -Dloadmapper.backrefs=10 -Dloadmapper.map.tasks=10 -Dloadmapper.num_to_write=100000 -Dverify.reduce.tasks=1 -Dverify.scannercaching=10000 loadAndVerify&lt;/p&gt;



&lt;p&gt;Trunk:&lt;br/&gt;
2013-06-17 09:01:45,884 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Job complete: job_local_0002&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Counters: 32&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   HBase Counters&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_CALLS=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_CALLS=196&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_RETRIES=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NOT_SERVING_REGION_EXCEPTION=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NUM_SCANNER_RESTARTS=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     MILLIS_BETWEEN_NEXTS=19795&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_RESULTS=592892544&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_REMOTE_RESULTS=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REGIONS_SCANNED=40&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_RETRIES=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify$Counters&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     ROWS_WRITTEN=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REFERENCES_CHECKED=9855224&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Output Format Counters&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Written=8&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   FileSystemCounters&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_READ=12005531128&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_WRITTEN=21471152830&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Input Format Counters&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Read=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   Map-Reduce Framework&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output materialized bytes=460630096&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map input records=1000000&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce shuffle bytes=0&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Spilled Records=42262109&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output bytes=438919408&lt;br/&gt;
2013-06-17 09:01:45,885 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Total committed heap usage (bytes)=15392387072&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     CPU time spent (ms)=0&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     SPLIT_RAW_BYTES=4144&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine input records=0&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input records=10855224&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input groups=1000000&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine output records=0&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Physical memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce output records=0&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Virtual memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 09:01:45,886 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output records=10855224&lt;/p&gt;




&lt;p&gt;Nic:&lt;br/&gt;
2013-06-17 08:56:38,894 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Job complete: job_local_0002&lt;br/&gt;
2013-06-17 08:56:38,895 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient: Counters: 32&lt;br/&gt;
2013-06-17 08:56:38,895 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   HBase Counters&lt;br/&gt;
2013-06-17 08:56:38,895 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_CALLS=0&lt;br/&gt;
2013-06-17 08:56:38,895 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_CALLS=196&lt;br/&gt;
2013-06-17 08:56:38,895 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     RPC_RETRIES=0&lt;br/&gt;
2013-06-17 08:56:38,895 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NOT_SERVING_REGION_EXCEPTION=0&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     NUM_SCANNER_RESTARTS=0&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     MILLIS_BETWEEN_NEXTS=19384&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_RESULTS=592944120&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     BYTES_IN_REMOTE_RESULTS=0&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REGIONS_SCANNED=40&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REMOTE_RPC_RETRIES=0&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify$Counters&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     ROWS_WRITTEN=0&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     REFERENCES_CHECKED=9856145&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Output Format Counters&lt;br/&gt;
2013-06-17 08:56:38,896 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Written=8&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   FileSystemCounters&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_READ=12006648901&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     FILE_BYTES_WRITTEN=21472928417&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   File Input Format Counters&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Bytes Read=0&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:   Map-Reduce Framework&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output materialized bytes=460670620&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map input records=1000000&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce shuffle bytes=0&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Spilled Records=42265579&lt;br/&gt;
2013-06-17 08:56:38,897 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output bytes=438958090&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Total committed heap usage (bytes)=15534960640&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     CPU time spent (ms)=0&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     SPLIT_RAW_BYTES=4144&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine input records=0&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input records=10856145&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce input groups=1000000&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Combine output records=0&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Physical memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Reduce output records=0&lt;br/&gt;
2013-06-17 08:56:38,898 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Virtual memory (bytes) snapshot=0&lt;br/&gt;
2013-06-17 08:56:38,899 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; mapred.JobClient:     Map output records=10856145&lt;/p&gt;

</comment>
                            <comment id="13685960" author="nkeywal" created="Mon, 17 Jun 2013 20:46:25 +0000"  >&lt;p&gt;Thanks a lot JM.&lt;br/&gt;
The log line is something I added in the patch. On trunk, we log nothing when we retry. I can change this to debug may be.&lt;br/&gt;
For the read results, it seems in line with today (as expected)&lt;br/&gt;
For the writes, it seems better or similar to my results, and this is great.&lt;/p&gt;

&lt;p&gt;I&apos;m going to do some final polishing, run all the tests locally, and I will commit to trunk &amp;amp; 0.95, hopefully before the end of the week.&lt;/p&gt;</comment>
                            <comment id="13686033" author="ecn" created="Mon, 17 Jun 2013 21:30:10 +0000"  >&lt;p&gt;I just stumbled into this ticket today.  This approach to client writes is the same as Accumulo&apos;s BatchWriter.  It&apos;s very helpful for write-heavy loads.&lt;/p&gt;</comment>
                            <comment id="13686080" author="jmspaggi" created="Mon, 17 Jun 2013 22:07:11 +0000"  >&lt;p&gt;Regarding the stack, I agree, INFO is to much. DEBUG or even TRACE might be better...&lt;/p&gt;

&lt;p&gt;I will re-run all my tests with your next version.&lt;/p&gt;</comment>
                            <comment id="13686733" author="nkeywal" created="Tue, 18 Jun 2013 13:58:41 +0000"  >&lt;p&gt;v14 is what I&apos;m likely to commit on .95 and .97. Feedback welcome. The whole tests suite ran twice without issue on my machine. JM, don&apos;t hesitate to run it again. It should have the same performance results, I haven&apos;t changed the algorithm itself.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecn&quot; class=&quot;user-hover&quot; rel=&quot;ecn&quot;&gt;Eric Newton&lt;/a&gt; Thanks a lot for the info. I looked at the code, it actually seems very similar. I&apos;ve got one question: currently, we support to have multiple queries sent in parallel on the same region. By default we don&apos;t do that: we have only one query at a time per region. Do you do something similar? &lt;/p&gt;</comment>
                            <comment id="13686790" author="ecn" created="Tue, 18 Jun 2013 14:39:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; Using the accumulo batch scanner, a single client will group requests by server: queries to multiple ranges on the same node will be sent in a single request to the node. If the number of client query threads is greater than the number of nodes, multiple threads may be used. The BatchWriter, however, will only use one thread to write to any one server.&lt;/p&gt;</comment>
                            <comment id="13687332" author="jmspaggi" created="Tue, 18 Jun 2013 22:54:48 +0000"  >&lt;p&gt;Tests are running. I might be able to post them tomorrow evening.&lt;/p&gt;</comment>
                            <comment id="13689055" author="nkeywal" created="Thu, 20 Jun 2013 09:34:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt; I&apos;m waiting for your feedback then. BTW, if you have time ( &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ), publishing a comparison between the 0.95 without this patch &amp;amp; 0.94 might be useful. I&apos;m saying this because if we have a performance degradation with the 0.94 this patch will hide it...&lt;/p&gt;</comment>
                            <comment id="13689196" author="jmspaggi" created="Thu, 20 Jun 2013 12:44:25 +0000"  >&lt;p&gt;Tests crashed yesterday because of some ZK obscure reasons... So I had to restart it. It should be done now. I will add 0.95 on the list, and run it. Which mean I should have all the results this evening (EST). I will take the required time to provide the feedback today.&lt;/p&gt;</comment>
                            <comment id="13689480" author="jmspaggi" created="Thu, 20 Jun 2013 18:23:56 +0000"  >&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Test&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Trunk&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Nic&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;0.95&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;761449.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;738362.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;754100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomScanWithRange100Test&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21858.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22356.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22400.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomSeekScanTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;134444.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;138179.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;134186.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;114272.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;76990.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;114798.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;77144.275&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24582.425&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;79107.25&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;so Trunk and 0.95 are consistent, while Nic&apos;s version show a nice improvement on the write operations (both Random and Sequentials), and a very small degradation on SeekScan. Also a small improvement on RandomRead.&lt;/p&gt;

&lt;p&gt;Do you need the IntegrationTestBigLinkedList for the 3 releases too?&lt;/p&gt;</comment>
                            <comment id="13689519" author="nkeywal" created="Thu, 20 Jun 2013 18:56:02 +0000"  >&lt;p&gt;Can I do 2097152 / 79 = 26500 to compare with the performances tests previously described in &lt;a href=&quot;http://www.spaggiari.org/media/blogs/hbase/pictures/performances_20130321.pdf?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.spaggiari.org/media/blogs/hbase/pictures/performances_20130321.pdf?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Because the performances were better previously (~35k / rows second).&lt;/p&gt;

&lt;p&gt;Same for 2097152 / 114  = 18396 vs. ~30k&lt;/p&gt;

&lt;p&gt;Or is it calculated differently?&lt;/p&gt;


&lt;p&gt;Anyway, thanks a lot for all these great tests. I will commit tomorrow morning my time if there is no objection.&lt;/p&gt;</comment>
                            <comment id="13689578" author="jmspaggi" created="Thu, 20 Jun 2013 20:01:12 +0000"  >&lt;p&gt;It&apos;s time for x lines, depending of the tests it&apos;s not the same number of lines.&lt;br/&gt;
For RandomReadTest you need to divide by 1048576&lt;br/&gt;
For RandomScanWithRange100Test you need to divide by 4096&lt;br/&gt;
For RandomSeekScanTest you need to divide by 40960.&lt;br/&gt;
For RandomWriteTest you need to divide by 1048576&lt;br/&gt;
For SequentialWriteTest you need to divide by 1048576&lt;/p&gt;

&lt;p&gt;This is the number of lines per ms. So multiply by 1000 to have the same result. Some are rows/minutes, so just adjust that.&lt;/p&gt;

&lt;p&gt;So if you want to compare, here are the numbers in the same format as te PDF that I usually produce:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Test&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Trunk&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Nic&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;0.95&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org,apache,hadoop,hbase,PerformanceEvaluation$RandomReadTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1377.08&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1420.14&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1390.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org,apache,hadoop,hbase,PerformanceEvaluation$RandomScanWithRange100Test&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;11243.12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10992.68&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10971.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org,apache,hadoop,hbase,PerformanceEvaluation$RandomSeekScanTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;304.66&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;296.43&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;305.25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org,apache,hadoop,hbase,PerformanceEvaluation$RandomWriteTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9176.07&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;13619.59&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9134.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org,apache,hadoop,hbase,PerformanceEvaluation$SequentialWriteTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;13592.40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;42655.52&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;13255.12&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I already noticed the RandomWriteTest impact compared to 0.94 branch and 0.95...&lt;/p&gt;

&lt;p&gt;I will re-run the 0.94 tests to make sure, but overall, I really think 0.95 is not doing as good as 0.95 for the RandomWriteTest.&lt;/p&gt;</comment>
                            <comment id="13689867" author="sershe" created="Thu, 20 Jun 2013 23:50:10 +0000"  >&lt;p&gt;Hmm, I just noticed this test removed usage of errorsByServer.calculateBackoffTime.&lt;br/&gt;
Can it please be put back? I have to withdraw my +1... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13689876" author="nkeywal" created="Fri, 21 Jun 2013 00:04:20 +0000"  >&lt;p&gt;I don&apos;t fully remember what it is and I didn&apos;t remove it on purpose but hopefully I can put it back. Will do this tomorrow.&lt;/p&gt;</comment>
                            <comment id="13689877" author="jmspaggi" created="Fri, 21 Jun 2013 00:07:53 +0000"  >&lt;p&gt;Will I need to re-run the tests?&lt;/p&gt;</comment>
                            <comment id="13689880" author="sershe" created="Fri, 21 Jun 2013 00:12:53 +0000"  >&lt;p&gt;Probably not, it is MTTR feature rather than perf&lt;/p&gt;</comment>
                            <comment id="13689881" author="sershe" created="Fri, 21 Jun 2013 00:14:23 +0000"  >&lt;p&gt;it&apos;s the feature that keeps tabs on wait time based on server to which we are sending the request, so for ex. in simple case, if we just did 16-second retry and now learn that region is on different server we don&apos;t wait for 32sec. to go there, but do so immediately.&lt;/p&gt;</comment>
                            <comment id="13689886" author="nkeywal" created="Fri, 21 Jun 2013 00:19:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; Thanks for the update. Ok, will do.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt; As Sergey &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Your tests results have been pretty stable, and I will try not to break everything. I&apos;ve also seen that some other jira need you as well &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. And I&apos;m quite interested by the results on 0.94 too.&lt;/p&gt;</comment>
                            <comment id="13690253" author="nkeywal" created="Fri, 21 Jun 2013 13:04:13 +0000"  >&lt;p&gt;This was a little bit more painful that I was expecting.&lt;br/&gt;
I&apos;ve done 3 modifications compared to trunk.&lt;br/&gt;
1) It&apos;s now initialized in AsyncProcess. This avoids a cast from HConnection to HConnectionImpl.&lt;br/&gt;
2) I&apos;m reporting an error once per location and try instead of all rows within a try.&lt;br/&gt;
3) I&apos;ve changed the internal structure to a concurrentMap.&lt;/p&gt;

&lt;p&gt;The test are in progress locally. I will push the patch after the first successful run.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;, could you please git it a quick review? Ideally I would like to commit it today, this will save me some merges and will give it more trial before the next .95 release candidate...&lt;/p&gt;</comment>
                            <comment id="13690262" author="jmspaggi" created="Fri, 21 Jun 2013 13:16:59 +0000"  >&lt;p&gt;0.94 tests are in progress... the should be done by 12h30 EST. I might be able to provide the results at that time. If there is any need to re-run the trunk tests with this patch, just let me know. I will most probably by a 2nd tests dedicated server soon to be able to run more tests for all those JIRAs &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13690540" author="sershe" created="Fri, 21 Jun 2013 18:10:37 +0000"  >&lt;p&gt;can you please update RB? thanks&lt;/p&gt;</comment>
                            <comment id="13690658" author="jmspaggi" created="Fri, 21 Jun 2013 19:58:05 +0000"  >&lt;p&gt;Numbers for 0.94...&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Test&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;0.94&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$FilteredScanTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;543237.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1110772.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomScanWithRange100Test&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20998.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomSeekScanTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;159891.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100201.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;38577.08&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;Again, it&apos;s time. So you need to compare with the first tab I sent. If you need I can convert that to rows/time.&lt;/p&gt;</comment>
                            <comment id="13690693" author="lhofhansl" created="Fri, 21 Jun 2013 20:36:08 +0000"  >&lt;p&gt;So the RandomReadTest takes ~760000 (ms?) in 0.95/trunk but takes ~1100000 ms in 0.94? I wonder why this is.&lt;/p&gt;</comment>
                            <comment id="13690705" author="jmspaggi" created="Fri, 21 Jun 2013 20:53:44 +0000"  >&lt;p&gt;114272ms in trunk&lt;br/&gt;
100201ms in 0.94&lt;br/&gt;
076990ms in trunk+5295&lt;br/&gt;
114798ms im 0.95&lt;/p&gt;

&lt;p&gt;So Trunk and 0.95 are about 10% slower than 0.94 (Which I have already figured with previous tests), however, with Nic&apos;s patch trunk is faster than all the other versions.&lt;/p&gt;

&lt;p&gt;On my own cluster I&apos;m doing almost only random writes... So I&apos;m really looking forward to see this in 0.9x &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13690828" author="lhofhansl" created="Fri, 21 Jun 2013 22:28:28 +0000"  >&lt;p&gt;OK... I got confused by this line in your first table:&lt;br/&gt;
org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest 	761449.8 	738362.4 	754100&lt;/p&gt;</comment>
                            <comment id="13690839" author="jmspaggi" created="Fri, 21 Jun 2013 22:39:51 +0000"  >&lt;p&gt;My bad. I gave the random write number just above...&lt;/p&gt;

&lt;p&gt;For randomRead:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Test&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Trunk&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Nic&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;0.95&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;0.94&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;org.apache.hadoop.hbase.PerformanceEvaluation$RandomReadTest&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;761449.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;738362.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;754100&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1110772&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Which mean there is a 30% (roughly) improvement between 0.94 and 0.95/trunk...&lt;/p&gt;

&lt;p&gt;Have you expected 0.94 to be faster than 0.95 for the randomReads?&lt;/p&gt;</comment>
                            <comment id="13690845" author="lhofhansl" created="Fri, 21 Jun 2013 22:44:13 +0000"  >&lt;p&gt;I had expected them to be roughly equal. I wonder what caused the improvement in 0.95+.&lt;br/&gt;
Should do that in 0.94 as well.&lt;/p&gt;</comment>
                            <comment id="13691457" author="lhofhansl" created="Sun, 23 Jun 2013 13:43:05 +0000"  >&lt;p&gt;Which version of 0.94/0.95/trunk did you use for this test, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13691463" author="jmspaggi" created="Sun, 23 Jun 2013 14:05:23 +0000"  >&lt;p&gt;Used the last versions from the branchs. So I have checked out from &lt;a href=&quot;http://svn.apache.org/repos/asf/hbase/branches/0.95/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hbase/branches/0.95/&lt;/a&gt; for 0.95, etc. So 0.94 is almost the next RC &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13691465" author="lhofhansl" created="Sun, 23 Jun 2013 14:08:44 +0000"  >&lt;p&gt;And the default setup? No parallel seeking enabled in storescanner?&lt;/p&gt;</comment>
                            <comment id="13691466" author="lhofhansl" created="Sun, 23 Jun 2013 14:12:46 +0000"  >&lt;p&gt;Oh... And that might come from different default. 0.95/trunk disable Nagle&apos;s by default. 0.94 does not.&lt;/p&gt;</comment>
                            <comment id="13691469" author="jmspaggi" created="Sun, 23 Jun 2013 14:14:59 +0000"  >&lt;p&gt;I don&apos;t touch the settings. I build the distribution and start it so I can compare what we are distributing (default version). Do you want me to try the 0.94 with a specific setting?&lt;/p&gt;</comment>
                            <comment id="13691471" author="jmspaggi" created="Sun, 23 Jun 2013 14:15:25 +0000"  >&lt;p&gt;I&apos;m running in standalone, so I don&apos;t thing Nagle has a big impact. But need to be verified.&lt;/p&gt;</comment>
                            <comment id="13691474" author="lhofhansl" created="Sun, 23 Jun 2013 14:29:11 +0000"  >&lt;p&gt;I have these set to true in hbase-site.xml:&lt;br/&gt;
hbase.ipc.client.tcpnodelay&lt;br/&gt;
ipc.server.tcpnodelay&lt;/p&gt;

&lt;p&gt;And these in hdfs-site.xml (so would won&apos;t need these, I think):&lt;br/&gt;
ipc.server.tcpnodelay&lt;br/&gt;
ipc.client.tcpnodelay&lt;/p&gt;</comment>
                            <comment id="13692183" author="sershe" created="Mon, 24 Jun 2013 17:50:05 +0000"  >&lt;p&gt;the patch looks reasonable, thanks &lt;/p&gt;</comment>
                            <comment id="13692258" author="nkeywal" created="Mon, 24 Jun 2013 19:00:18 +0000"  >&lt;p&gt;Committed to trunk &amp;amp; 0.95. I&apos;ve done a lot of tests, but it&apos;s quite easy to break something in this area. So ping me if there is anything suspicious in the next days.&lt;/p&gt;

&lt;p&gt;Thanks a lot for the reviews, and especially to Jean-Marc for all these tests.&lt;/p&gt;</comment>
                            <comment id="13692462" author="hudson" created="Mon, 24 Jun 2013 22:25:42 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #265 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/265/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/265/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background (Revision 1496159)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Action.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnection.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13692579" author="hudson" created="Mon, 24 Jun 2013 23:50:49 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #147 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/147/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/147/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background (Revision 1496159)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Action.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnection.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13692658" author="hudson" created="Tue, 25 Jun 2013 01:17:44 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #582 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/582/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/582/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background - round 2 (Revision 1496157)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background (Revision 1496156)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Action.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnection.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ServerCallable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13693206" author="eclark" created="Tue, 25 Jun 2013 17:55:44 +0000"  >&lt;p&gt;Looks like this broke integration tests.  We&apos;ve failed 5 different jobs in a row.  Seems like the async threads don&apos;t recover if there&apos;s a chaos monkey.&lt;/p&gt;

&lt;p&gt;Additionally there&apos;s a lot of spamming on the info level:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-06-25 06:54:03,749 INFO  [HBaseWriterThread_4] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6877
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_5] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6848
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_7] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6815
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_0] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6844
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_8] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6850
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_3] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6892
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_6] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6858
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_2] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6849
2013-06-25 06:54:03,750 INFO  [HBaseWriterThread_9] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6873
2013-06-25 06:54:03,751 INFO  [HBaseWriterThread_4] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6878
2013-06-25 06:54:03,751 INFO  [HBaseWriterThread_1] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6819
2013-06-25 06:54:03,751 INFO  [HBaseWriterThread_7] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6816
2013-06-25 06:54:03,751 INFO  [HBaseWriterThread_5] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6849
2013-06-25 06:54:03,751 INFO  [HBaseWriterThread_0] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6845
2013-06-25 06:54:03,751 INFO  [HBaseWriterThread_8] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6851
2013-06-25 06:54:03,752 INFO  [HBaseWriterThread_3] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6893
2013-06-25 06:54:03,752 INFO  [HBaseWriterThread_2] client.AsyncProcess: IntegrationTestDataIngestSlowDeterministic: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of tasks to be equals or less than 0, currently it&apos;s 6850
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13693274" author="nkeywal" created="Tue, 25 Jun 2013 18:57:17 +0000"  >&lt;p&gt;Thanks for the alert Elliott. I will have a look tomorrow my time.&lt;/p&gt;</comment>
                            <comment id="13694151" author="nkeywal" created="Wed, 26 Jun 2013 18:47:21 +0000"  >&lt;p&gt;For the logs, it&apos;s a bug, easy to fix. I will do it.&lt;br/&gt;
For the failure itself, the integration test uses a retry count of 10. This is not enough. If I increase to 30 it succeeds 5 times out of 5, while I&apos;ve got a 60% failure rate with a value of 10. The integration tests runs with the value found in hbase-server/.../test/resources, and this value was not changed by the various jira we had about this default value.&lt;/p&gt;

&lt;p&gt;I will run more tests during the night, but this seems to be it.&lt;/p&gt;</comment>
                            <comment id="13694163" author="stack" created="Wed, 26 Jun 2013 19:00:19 +0000"  >&lt;p&gt;+1 on committing bug fix and upping retry count as addendum on this issue.&lt;/p&gt;</comment>
                            <comment id="13694178" author="eclark" created="Wed, 26 Jun 2013 19:18:39 +0000"  >&lt;p&gt;So I see this issue on a real cluster where the local conf is added to the classpath ahead of any jars.  How would the test settings be causing this ?&lt;/p&gt;</comment>
                            <comment id="13694186" author="sershe" created="Wed, 26 Jun 2013 19:28:33 +0000"  >&lt;p&gt;I think it might have been caused by retry tweaking (the thing we discussed tomorrow about the pause length). The pause is reduced to 100ms on trunk, while being 1000ms on 94, so current trunk retries are too short.&lt;/p&gt;</comment>
                            <comment id="13694194" author="eclark" created="Wed, 26 Jun 2013 19:39:37 +0000"  >&lt;p&gt;This started failing before the retry tweaks went in.&lt;br/&gt;
And you were correct yesterday trunk is still at 1000ms as the default pause time.  ( &lt;a href=&quot;https://github.com/apache/hbase/blob/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java#L554&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hbase/blob/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java#L554&lt;/a&gt; )&lt;/p&gt;</comment>
                            <comment id="13694205" author="eclark" created="Wed, 26 Jun 2013 20:01:19 +0000"  >&lt;p&gt;oh blah never mind it&apos;s just that the fall back default wasn&apos;t changed but the xml was.  It really is 100ms base pause time.  I&apos;ll file a jira to make them all the same to stop confusion in the future.&lt;/p&gt;</comment>
                            <comment id="13694560" author="nkeywal" created="Thu, 27 Jun 2013 08:18:59 +0000"  >&lt;p&gt;The tests worked all the time with a setting of 30. I had issues with 14, that&apos;s the value in the common xml. The default in HConstant is 20. As the right values are worked out in another jira, I&apos;ve just went for 20 in this patch, it seems to be ok on a small sample. I think we should get rid of the one in hbase-server as well...&lt;/p&gt;

&lt;p&gt;I will commit today if there is no objections.&lt;/p&gt;</comment>
                            <comment id="13695498" author="nkeywal" created="Fri, 28 Jun 2013 15:05:36 +0000"  >&lt;p&gt;addendum committed.&lt;/p&gt;</comment>
                            <comment id="13695580" author="hudson" created="Fri, 28 Jun 2013 17:24:49 +0000"  >&lt;p&gt;Integrated in hbase-0.95 #274 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95/274/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95/274/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background - addendum (Revision 1497801)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTableMultiplexer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/resources/hbase-site.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13695594" author="hudson" created="Fri, 28 Jun 2013 17:40:49 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #4201 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4201/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4201/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background - addendum (Revision 1497800)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTableMultiplexer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/resources/hbase-site.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13695774" author="eclark" created="Fri, 28 Jun 2013 20:49:54 +0000"  >&lt;p&gt;So the good news is this patch really helped our perf on YCSB.&lt;br/&gt;
Build #91 is where this patch went in.&lt;/p&gt;

&lt;p&gt;The bad news is that the addendum didn&apos;t fix integration tests on a real cluster.  They still fail.&lt;/p&gt;

&lt;p&gt;Here&apos;s some logs for integration-test-data-ingest-slow-deterministic&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-06-28 13:08:32,882 DEBUG [hbase-table-pool-175-thread-2] client.AsyncProcess: Attempt #10/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,1372449851893.b7040e878147caf1f6de338faad504be., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: b7040e878147caf1f6de338faad504be
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 3205 ms.
2013-06-28 13:08:32,939 DEBUG [hbase-table-pool-173-thread-1] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,22222220,00000000000000
2013-06-28 13:08:32,945 DEBUG [hbase-table-pool-173-thread-2] client.AsyncProcess: Attempt #10/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,22222220,1372449851892.c8a2a77e0690901df245ac9fff088a0e., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c8a2a77e0690901df245ac9fff088a0e
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 3201 ms.
2013-06-28 13:08:32,996 DEBUG [hbase-table-pool-174-thread-1] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,00000000000000
2013-06-28 13:08:33,030 DEBUG [hbase-table-pool-174-thread-1] client.ClientScanner: Finished region={ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;}
2013-06-28 13:08:33,032 DEBUG [hbase-table-pool-174-thread-2] client.AsyncProcess: Attempt #10/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,1372449851893.b7040e878147caf1f6de338faad504be., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: b7040e878147caf1f6de338faad504be
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 3201 ms.
2013-06-28 13:08:33,371 DEBUG [hbase-table-pool-177-thread-2] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,b3333328,00000000000000
2013-06-28 13:08:33,408 DEBUG [hbase-table-pool-177-thread-2] client.ClientScanner: Finished region={ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;}
2013-06-28 13:08:33,411 DEBUG [hbase-table-pool-171-thread-1] client.AsyncProcess: Attempt #10/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,b3333328,1372449851893.c6df99964212adf9c8d9807926371a57., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c6df99964212adf9c8d9807926371a57
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 3215 ms.
2013-06-28 13:08:33,411 DEBUG [hbase-table-pool-177-thread-1] client.AsyncProcess: Attempt #10/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,b3333328,1372449851893.c6df99964212adf9c8d9807926371a57., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c6df99964212adf9c8d9807926371a57
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 3212 ms.
2013-06-28 13:08:35,941 DEBUG [hbase-table-pool-180-thread-2] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,1372449851893.b7040e878147caf1f6de338faad504be., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: b7040e878147caf1f6de338faad504be
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6460 ms.
2013-06-28 13:08:35,956 DEBUG [hbase-table-pool-178-thread-2] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,3bbbbbb8,1372449851893.ebd0ab2aba6df7f8ed2ee5e47872dd36., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=53019, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: ebd0ab2aba6df7f8ed2ee5e47872dd36
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6410 ms.
2013-06-28 13:08:35,968 DEBUG [hbase-table-pool-172-thread-2] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,66666660,1372449851893.6910db29befeea246245b02808ac45ec., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: 6910db29befeea246245b02808ac45ec
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6421 ms.
2013-06-28 13:08:36,000 DEBUG [hbase-table-pool-176-thread-2] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,b3333328,00000000000000
2013-06-28 13:08:36,051 DEBUG [hbase-table-pool-176-thread-2] client.ClientScanner: Finished region={ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;}
2013-06-28 13:08:36,053 DEBUG [hbase-table-pool-176-thread-1] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,b3333328,1372449851893.c6df99964212adf9c8d9807926371a57., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c6df99964212adf9c8d9807926371a57
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6456 ms.
2013-06-28 13:08:36,054 DEBUG [hbase-table-pool-179-thread-1] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,22222220,00000000000000
2013-06-28 13:08:36,061 DEBUG [hbase-table-pool-179-thread-2] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,22222220,1372449851892.c8a2a77e0690901df245ac9fff088a0e., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c8a2a77e0690901df245ac9fff088a0e
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6422 ms.
2013-06-28 13:08:36,088 DEBUG [hbase-table-pool-175-thread-1] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,1372449851893.b7040e878147caf1f6de338faad504be., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: b7040e878147caf1f6de338faad504be
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6445 ms.
2013-06-28 13:08:36,150 DEBUG [hbase-table-pool-173-thread-2] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,22222220,00000000000000
2013-06-28 13:08:36,156 DEBUG [hbase-table-pool-173-thread-1] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,22222220,1372449851892.c8a2a77e0690901df245ac9fff088a0e., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c8a2a77e0690901df245ac9fff088a0e
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6459 ms.
2013-06-28 13:08:36,237 DEBUG [hbase-table-pool-174-thread-2] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,00000000000000
2013-06-28 13:08:36,273 DEBUG [hbase-table-pool-174-thread-2] client.ClientScanner: Finished region={ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;}
2013-06-28 13:08:36,276 DEBUG [hbase-table-pool-174-thread-1] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,bbbbbbb0,1372449851893.b7040e878147caf1f6de338faad504be., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: b7040e878147caf1f6de338faad504be
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6441 ms.
2013-06-28 13:08:36,627 DEBUG [hbase-table-pool-177-thread-1] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,b3333328,00000000000000
2013-06-28 13:08:36,663 DEBUG [hbase-table-pool-177-thread-1] client.ClientScanner: Finished region={ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;}
2013-06-28 13:08:36,666 DEBUG [hbase-table-pool-171-thread-2] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,b3333328,1372449851893.c6df99964212adf9c8d9807926371a57., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c6df99964212adf9c8d9807926371a57
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6415 ms.
2013-06-28 13:08:36,667 DEBUG [hbase-table-pool-177-thread-2] client.AsyncProcess: Attempt #11/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,b3333328,1372449851893.c6df99964212adf9c8d9807926371a57., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: c6df99964212adf9c8d9807926371a57
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6453 ms.
2013-06-28 13:08:37,368 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-399] util.MultiThreadedAction: [W:10] Keys=6575, cols=68.0 K, time=00:00:50 Overall: [keys/s= 131, latency=46 ms], insertedUpTo=74999
2013-06-28 13:08:42,367 INFO  [HBaseWriterThread_7] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=6934, tasksDone=6933, currentTasksDone=6933, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,368 DEBUG [hbase-table-pool-178-thread-1] client.AsyncProcess: Attempt #12/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,3bbbbbb8,1372449851893.ebd0ab2aba6df7f8ed2ee5e47872dd36., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=53019, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: ebd0ab2aba6df7f8ed2ee5e47872dd36
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6401 ms.
2013-06-28 13:08:42,369 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-399] util.MultiThreadedAction: [W:10] Keys=6575, cols=68.0 K, time=00:00:55 Overall: [keys/s= 119, latency=46 ms], insertedUpTo=74999
2013-06-28 13:08:42,389 INFO  [HBaseWriterThread_1] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=6883, tasksDone=6882, currentTasksDone=6882, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,390 DEBUG [hbase-table-pool-172-thread-1] client.AsyncProcess: Attempt #12/14 failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 operations on server a1806.halxg.cloudera.com,60020,1372449350703, resubmitting 1, tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,66666660,1372449851893.6910db29befeea246245b02808ac45ec., hostname=a1806.halxg.cloudera.com,60020,1372449350703, seqNum=1, last exception was: org.apache.hadoop.hbase.exceptions.NotServingRegionException: org.apache.hadoop.hbase.exceptions.NotServingRegionException: Region is not online: 6910db29befeea246245b02808ac45ec
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2565)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3852)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3188)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:20938)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)
 - sleeping 6432 ms.
2013-06-28 13:08:42,401 INFO  [HBaseWriterThread_9] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=6886, tasksDone=6885, currentTasksDone=6885, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,486 DEBUG [hbase-table-pool-179-thread-2] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,22222220,00000000000000
2013-06-28 13:08:42,491 INFO  [HBaseWriterThread_8] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=7006, tasksDone=7005, currentTasksDone=7005, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,497 DEBUG [HBaseWriterThread_9] client.ClientScanner: Scan table=.META., startRow=IntegrationTestDataIngestSlowDeterministic,b3333328,00000000000000
2013-06-28 13:08:42,533 DEBUG [HBaseWriterThread_9] client.ClientScanner: Finished region={ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &apos;.META.,,1&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;&apos;}
2013-06-28 13:08:42,534 INFO  [HBaseWriterThread_4] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=7105, tasksDone=7104, currentTasksDone=7104, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,534 INFO  [HBaseWriterThread_5] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=6812, tasksDone=6811, currentTasksDone=6811, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,615 INFO  [HBaseWriterThread_2] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=7169, tasksDone=7168, currentTasksDone=7168, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:42,739 INFO  [HBaseWriterThread_3] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=7091, tasksDone=7090, currentTasksDone=7090, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:43,081 INFO  [HBaseWriterThread_0] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=6907, tasksDone=6906, currentTasksDone=6906, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:43,120 INFO  [HBaseWriterThread_6] client.AsyncProcess: : Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the global number of running tasks to be equals or less than 0, tasksSent=7102, tasksDone=7101, currentTasksDone=7101, tableName=IntegrationTestDataIngestSlowDeterministic
2013-06-28 13:08:47,370 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-399] util.MultiThreadedAction: [W:10] Keys=8191, cols=84.6 K, time=00:01:00 Overall: [keys/s= 136, latency=55 ms] Current: [keys/s=323, latency=91 ms], insertedUpTo=74999
2013-06-28 13:08:52,370 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-399] util.MultiThreadedAction: [W:10] Keys=10203, cols=105.5 K, time=00:01:05 Overall: [keys/s= 156, latency=53 ms] Current: [keys/s=402, latency=43 ms], insertedUpTo=74999
2013-06-28 13:08:57,371 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-399] util.MultiThreadedAction: [W:10] Keys=12404, cols=127.8 K, time=00:01:10 Overall: [keys/s= 177, latency=47 ms] Current: [keys/s=440, latency=22 ms], insertedUpTo=74999
2013-06-28 13:09:02,373 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-399] util.MultiThreadedAction: [W:10] Keys=14290, cols=146.8 K, time=00:01:15 Overall: [keys/s= 190, latency=44 ms] Current: [keys/s=377, latency=26 ms], insertedUpTo=74999
Failed to write keys: 4
Failed to write key: 81469
Failed to write key: 81503
Failed to write key: 81518
Failed to write key: 81524
2013-06-28 13:09:04,376 ERROR [main] hbase.IngestIntegrationTestBase: Load failed with error code 1
2013-06-28 13:10:31,691 INFO  [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-4] util.ChaosMonkey: Sleeping &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 84975 to add jitter
2013-06-28 13:11:56,667 DEBUG [main] hbase.IngestIntegrationTestBase: Restoring the cluster
2013-06-28 13:11:56,679 DEBUG [main] hbase.IngestIntegrationTestBase: Done restoring the cluster
E
Time: 466.629
There was 1 failure:
1) testDataIngest(org.apache.hadoop.hbase.IntegrationTestDataIngestSlowDeterministic)
junit.framework.AssertionFailedError: Load failed with error code 1
	at junit.framework.Assert.fail(Assert.java:57)
	at org.apache.hadoop.hbase.IngestIntegrationTestBase.runIngestTest(IngestIntegrationTestBase.java:114)
	at org.apache.hadoop.hbase.IntegrationTestDataIngestSlowDeterministic.testDataIngest(IntegrationTestDataIngestSlowDeterministic.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:117)
	at org.apache.hadoop.hbase.IntegrationTestsDriver.doWork(IntegrationTestsDriver.java:111)
	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:108)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13695950" author="hudson" created="Sat, 29 Jun 2013 00:04:50 +0000"  >&lt;p&gt;Integrated in hbase-0.95-on-hadoop2 #153 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.95-on-hadoop2/153/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.95-on-hadoop2/153/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background - addendum (Revision 1497801)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTableMultiplexer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.95/hbase-server/src/test/resources/hbase-site.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13695983" author="hudson" created="Sat, 29 Jun 2013 00:49:47 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #588 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/588/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/588/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6295&quot; title=&quot;Possible performance improvement in client batch operations: presplit and send in background&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6295&quot;&gt;&lt;del&gt;HBASE-6295&lt;/del&gt;&lt;/a&gt;  Possible performance improvement in client batch operations: presplit and send in background - addendum (Revision 1497800)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
nkeywal : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTableMultiplexer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/resources/hbase-site.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13696040" author="jmspaggi" created="Sat, 29 Jun 2013 03:56:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;I have these set to true in hbase-site.xml:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;hbase.ipc.client.tcpnodelay&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ipc.server.tcpnodelay&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;And these in hdfs-site.xml (so would won&apos;t need these, I think):&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ipc.server.tcpnodelay&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ipc.client.tcpnodelay&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;In standalone I don&apos;t have the hdfs-site.xml file... So I have put all of them in hbase-site.xml and restarted the tests for 0.94.9. I will publish the results on the mailing list.&lt;/p&gt;</comment>
                            <comment id="13696650" author="nkeywal" created="Mon, 1 Jul 2013 08:24:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;The bad news is that the addendum didn&apos;t fix integration tests on a real cluster. They still fail.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;From the logs, the number of retries is 14. In my tests, I had to go for 20 to have something reliable enough (I&apos;ve done most of them with 30, though). In the addendum I didn&apos;t change the value hbase-common, and it seems it&apos;s the one you&apos;re using... I can fix it here, but anyway it should be fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8776&quot; title=&quot;tweak retry settings some more (on trunk and 0.94)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8776&quot;&gt;&lt;del&gt;HBASE-8776&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
</comment>
                            <comment id="13696843" author="nkeywal" created="Mon, 1 Jul 2013 14:29:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; I&apos;m currently running the tests on a real cluster with 15 nodes. I&apos;m using this command&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/hbase org.apache.hadoop.hbase.IntegrationTestsDriver -r  IntegrationTestDataIngestSlowDeterministic
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With an empty config file on the client (hence using the code defaults, as YCSB).&lt;/p&gt;


&lt;p&gt;I reproduced an error, but I had this in the logs (it wasn&apos;t the last line in the logs):&lt;br/&gt;
2013-07-01 14:26:05,020 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;hbase-table-pool-13-thread-1&amp;#93;&lt;/span&gt; client.AsyncProcess: Attempt #20/20 failed for 1 operations on server ip-10-191-62-44.ec2.internal,60020,1372259546637 NOT resubmitting., tableName=IntegrationTestDataIngestSlowDeterministic, location=region=IntegrationTestDataIngestSlowDeterministic,6eeeeee8,1372688561696.f12d243ed7420921efe5fa30471c102b., hostname=ip-10-191-62-44.ec2.internal,60020,1372259546637, seqNum=1&lt;/p&gt;

&lt;p&gt;We&apos;re very aggressive with the retries at the beginning: the first retries are after a 100ms sleeping time, and even after the 16th retry we still wait for 6.4s. May be it&apos;s too aggressive. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;, are these back off times to be expected, or should I get more when I call errorsByServer.calculateBackoffTime ?&lt;/p&gt;</comment>
                            <comment id="13698155" author="jmspaggi" created="Tue, 2 Jul 2013 20:04:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Here are the results with those settings.&lt;br/&gt;
FilteredScanTest 11.02 with settings against 11.07 without the settings.&lt;br/&gt;
RandomReadTest 939 vs 940&lt;br/&gt;
RandomSeekScanTest 225.9 vs 255.8&lt;br/&gt;
RandomWriteTest 200015 vs 21362&lt;br/&gt;
RandomScanWithRange10Test 27807 vs 27720&lt;br/&gt;
SequentialRead 2924 vs 2922&lt;/p&gt;

&lt;p&gt;etc.&lt;/p&gt;

&lt;p&gt;So results are barely different. I think we should/can move this discussion out of this JIRA &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~liochon&amp;#93;&lt;/span&gt; I don&apos;t have anything running on my server now, so if you want me to test your patch again with specific settings, just let me know.&lt;/p&gt;</comment>
                            <comment id="13698174" author="lhofhansl" created="Tue, 2 Jul 2013 20:18:25 +0000"  >&lt;p&gt;Agreed. The main difference was the block cache size anyway. With the same setting there 0.94 is faster than 0.95, which at this point makes sense.&lt;/p&gt;</comment>
                            <comment id="13698599" author="stack" created="Wed, 3 Jul 2013 04:50:15 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~liochon&amp;#93;&lt;/span&gt; Go ahead and change the expotential list if you think it too aggressive.&lt;/p&gt;</comment>
                            <comment id="13698616" author="eclark" created="Wed, 3 Jul 2013 05:19:02 +0000"  >&lt;p&gt;The only reservation I have with that is we still don&apos;t know why this causes IT tests to fail.  They were passing &amp;gt; 90% of the time before this jira was committed.  Then they started failing.&lt;/p&gt;

&lt;p&gt;Why would the old client threading model recover better than this background async model ?&lt;/p&gt;</comment>
                            <comment id="13698621" author="stack" created="Wed, 3 Jul 2013 05:23:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; IT tests were passing before even after defaults had been rejiggered and before this background thread addition?&lt;/p&gt;</comment>
                            <comment id="13698633" author="eclark" created="Wed, 3 Jul 2013 05:43:21 +0000"  >&lt;p&gt;Correct. &lt;/p&gt;

&lt;p&gt;Here&apos;s the timing as I know it:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The Tests were passing 90% of the time.&lt;/li&gt;
	&lt;li&gt;Then the defaults got re-done&lt;/li&gt;
	&lt;li&gt;The tests started failing a lot (they failed 80% of the time).&lt;/li&gt;
	&lt;li&gt;Then I put in something to extend the timeouts ( &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8723&quot; title=&quot;HBase Intgration tests are failing because of new defaults.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8723&quot;&gt;&lt;del&gt;HBASE-8723&lt;/del&gt;&lt;/a&gt; ).&lt;/li&gt;
	&lt;li&gt;Then the were passing &amp;gt;90% of the time.&lt;/li&gt;
	&lt;li&gt;Then this went in.&lt;/li&gt;
	&lt;li&gt;Tests have failed consistently since this patch went in (100% of the time on any tests that have chaos monkey).&lt;/li&gt;
	&lt;li&gt;Then &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; moved the defaults for timeouts back down.&lt;/li&gt;
	&lt;li&gt;The tests continued failing.&lt;/li&gt;
&lt;/ol&gt;

</comment>
                            <comment id="13698756" author="nkeywal" created="Wed, 3 Jul 2013 08:59:22 +0000"  >&lt;p&gt;1) Settings&lt;br/&gt;
I don&apos;t think that the settings are good today in the trunk.&lt;br/&gt;
In hbase-common/resources; we still have:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;hbase.client.pause = 100 (It&apos;s 1000 in the code)&lt;/li&gt;
	&lt;li&gt;hbase.client.retries.number = 14 (it&apos;s 20 in the code)&lt;br/&gt;
As a consequence, we retry for ~30s before failing.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;We see this in Elliott&apos;s log above.&lt;br/&gt;
client.AsyncProcess: Attempt 10/14 failed for 1 operations &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;- sleeping 3201 ms.&lt;br/&gt;
=&amp;gt; the max retry is 14, not 20. &lt;br/&gt;
=&amp;gt; after 10 failure, we still sleep for only 3.2 seconds. &lt;/p&gt;

&lt;p&gt;I personally think that we should get rid of the hbase-*.xml in our package to be sure we&apos;re using the code defaults. Today, we have:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the defaults in the code&lt;/li&gt;
	&lt;li&gt;hbase-defaults.xml in hbase-common (seems to be used when do the integration test with a cluster)&lt;/li&gt;
	&lt;li&gt;hbase-site.xml in hbase-server/test (seems to be used when you run the integration test with a minicluster)&lt;/li&gt;
	&lt;li&gt;hbase-site.xml in hbase-client&lt;/li&gt;
	&lt;li&gt;hbase-site.xml in conf&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2) Previously, when we were sending a single multi call with 100 puts in it to the server and it was failing we were counting 100 errors. We now count 1 error. The previous behavior was a bug, but its consequence is that the backoff time was always the max, hiding the impact of the first point (basically we were sleeping 14 times 6 seconds, while now, during the first attempts we sleep 100 ms)&lt;/p&gt;

&lt;p&gt;3) For completeness, this patch degrades the MTTR, especially in tests. Two reasons for this. First, the clients send more writes to the server: that&apos;s why we have better performances with YCSB. Second, during a failure, the clients can still send writes to the other regions instead of waiting for the result of a write on the recovering regions. This means that there are less resources available to do the recovery, as the clients are not stuck anymore and are sending more writes. This is especially visible in tests, because we try to write as much as possible (while in real life the writes are more immutable as they are coming from an external source).&lt;/p&gt;



&lt;p&gt;I&apos;m not saying that there is not bug in the code I committed. It&apos;s complex and it&apos;s not production proven, so I&apos;m actually quite sure there are bugs &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. What I&apos;m saying is&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;on my tests, when the integration test was failing is was because we reached the maximum number of retries.&lt;/li&gt;
	&lt;li&gt;finding out what are the actual settings used is pure hell&lt;/li&gt;
	&lt;li&gt;and I was expecting that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8776&quot; title=&quot;tweak retry settings some more (on trunk and 0.94)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8776&quot;&gt;&lt;del&gt;HBASE-8776&lt;/del&gt;&lt;/a&gt; would do this.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m gonna hijack &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8776&quot; title=&quot;tweak retry settings some more (on trunk and 0.94)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8776&quot;&gt;&lt;del&gt;HBASE-8776&lt;/del&gt;&lt;/a&gt; to propose some settings.&lt;/p&gt;
</comment>
                            <comment id="13698771" author="eclark" created="Wed, 3 Jul 2013 09:17:11 +0000"  >&lt;p&gt;Ahhhh, I get it now.  I think #2 probably had the most impact here.&lt;/p&gt;

&lt;p&gt;On the subject of settings: I opened up &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8810&quot; title=&quot;Bring in code constants in line with default xml&amp;#39;s&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8810&quot;&gt;&lt;del&gt;HBASE-8810&lt;/del&gt;&lt;/a&gt; to bring the constants in line with what&apos;s in our hbase-defaults.xml.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I personally think that we should get rid of the hbase-*.xml in our package to be sure we&apos;re using the code defaults. Today, we have:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I would disagree.  The xml is really useful for users to find important settings and their defaults without having to look through the entire code base.  I do agree that we should combine all of the test hbase-site.xml&apos;s into one so that there&apos;s less confusion on which is being used.&lt;/p&gt;</comment>
                            <comment id="13699375" author="stack" created="Wed, 3 Jul 2013 19:58:42 +0000"  >&lt;p&gt;On:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
the defaults in the code
hbase-defaults.xml in hbase-common (seems to be used when &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; the integration test with a cluster)
hbase-site.xml in hbase-server/test (seems to be used when you run the integration test with a minicluster)
hbase-site.xml in hbase-client
hbase-site.xml in conf
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Removing hadoop-default.xml is a radical notion.  hbase-default.xml used to be in conf for all to view and adapt into an hbase-site.xml.  hbase-3090 moved it out of conf and into jar so that new installs picked up new defaults.  This made hbase-default.xml content effectively opaque unless you undid the jar or went to the refguide to read the doc. we generate from it (See &lt;a href=&quot;http://hbase.apache.org/book.html#hbase.site&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/book.html#hbase.site&lt;/a&gt;)  My guess is no one looks at the refguide.  This would seem to rendor hbase-default.xml near useless?   Yet we have to maintain it.  In the configuration code, we&apos;ll favor the hbase-default* setting over what we have in code.&lt;/p&gt;

&lt;p&gt;If we remove it, then we&apos;ll only use what is in code.  Means we won&apos;t have list of configs. in doc. w/ their descriptions.&lt;/p&gt;

&lt;p&gt;We could generate a class from the hbase-default.xml src that wrote out a Constants java file which had in it defines that we&apos;d use as default whenever we did Configuration#getInt.  If you added something to hbase-default.xml, you&apos;d have to use a constant.  Would mean a script run against the src that would fail if it found something in hbase-default.xml that had a default in code that was not an upper-case constant?&lt;/p&gt;

&lt;p&gt;The hbase-site.xml in conf is empty always.  Probably better named hbase-site.xml.template.&lt;/p&gt;

&lt;p&gt;The other hbase-site.xmls are configs for the local tests.  Notion is that tests have shorter timeouts and retries than what we ship as our defaults.  Do we want to reexamine this and have the hbase defaults true for tests too?&lt;/p&gt;

&lt;p&gt;Thanks Elliott and Nicolas for figuring this one out.&lt;/p&gt;
</comment>
                            <comment id="13699393" author="nkeywal" created="Wed, 3 Jul 2013 20:16:38 +0000"  >&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8810&quot; title=&quot;Bring in code constants in line with default xml&amp;#39;s&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8810&quot;&gt;&lt;del&gt;HBASE-8810&lt;/del&gt;&lt;/a&gt;, I proposed to have:&lt;br/&gt;
    a file called hbase-settings-sample.xml that would not be included when we read the conf (while we read hbase-default and hbase-site today). It would be for documentation only.&lt;br/&gt;
    a unit test to load this file and compare with the code default, to ensure our doc is in line with the code.&lt;/p&gt;

&lt;p&gt;The script would work as well. I think the test should use the defaults. Then, inside the tests, we can change them, for example when we know it&apos;s gonna fail and we don&apos;t want to try 20 times.&lt;/p&gt;</comment>
                            <comment id="13702625" author="stack" created="Mon, 8 Jul 2013 23:34:14 +0000"  >&lt;p&gt;So, lets move the above discussion over to hbase-8810.  hbase-8888 hopefully restores timings so hbase-it can pass again.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12643595">HBASE-8380</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12551766">HBASE-5843</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12642305">HBASE-8338</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12589853" name="6295.addendum.patch" size="10687" author="nkeywal" created="Thu, 27 Jun 2013 08:19:21 +0000"/>
                            <attachment id="12578071" name="6295.v1.patch" size="17096" author="nkeywal" created="Wed, 10 Apr 2013 20:18:18 +0000"/>
                            <attachment id="12587953" name="6295.v11.patch" size="88981" author="nkeywal" created="Sat, 15 Jun 2013 04:39:57 +0000"/>
                            <attachment id="12588072" name="6295.v12.patch" size="88913" author="nkeywal" created="Mon, 17 Jun 2013 02:30:01 +0000"/>
                            <attachment id="12588361" name="6295.v14.patch" size="89449" author="nkeywal" created="Tue, 18 Jun 2013 13:53:06 +0000"/>
                            <attachment id="12589080" name="6295.v15.patch" size="103785" author="nkeywal" created="Fri, 21 Jun 2013 15:03:02 +0000"/>
                            <attachment id="12578240" name="6295.v2.patch" size="18343" author="nkeywal" created="Thu, 11 Apr 2013 17:11:59 +0000"/>
                            <attachment id="12578486" name="6295.v3.patch" size="19902" author="nkeywal" created="Fri, 12 Apr 2013 19:08:11 +0000"/>
                            <attachment id="12580730" name="6295.v4.patch" size="21651" author="nkeywal" created="Fri, 26 Apr 2013 18:09:30 +0000"/>
                            <attachment id="12581202" name="6295.v5.patch" size="21269" author="nkeywal" created="Tue, 30 Apr 2013 18:07:14 +0000"/>
                            <attachment id="12581547" name="6295.v6.patch" size="28262" author="nkeywal" created="Thu, 2 May 2013 16:53:14 +0000"/>
                            <attachment id="12585022" name="6295.v8.patch" size="81992" author="nkeywal" created="Tue, 28 May 2013 12:11:58 +0000"/>
                            <attachment id="12585051" name="6295.v9.patch" size="86716" author="nkeywal" created="Tue, 28 May 2013 17:59:15 +0000"/>
                            <attachment id="12590085" name="hbase-ycsb-workloads Build time trend.png" size="23152" author="eclark" created="Fri, 28 Jun 2013 20:49:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 2 Jul 2012 12:57:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>241849</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 23 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02elz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11968</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>The puts are now streamed, i.e. sent asynchronously to the region servers if autoflush it set to false. If a region server is slow or does not respond, its puts are kept into the write buffer while the others are sent to these respective region server, until the write buffer is full. This feature is keeps the semantic of the interface already existing in 0.94 when using autoflush.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>