<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:35:45 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12721/HBASE-12721.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12721] Create Docker container cluster infrastructure to enable better testing</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12721</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Some simple work on using HBase with Docker was committed into /dev-support as &quot;hbase_docker;&quot; all this did was stand up a standalone cluster from source and start a shell. Now seems like a good time to extend this to be useful for applications that could actual benefit the community, especially around testing. Some ideas:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integration testing would be much more accessible if people could stand up distributed HBase clusters on a single host machine in a couple minutes and run our awesome hbase-it suite against it.&lt;/li&gt;
	&lt;li&gt;Binary compatibility testing of an HBase client is easiest when standing up an HBase cluster can be done once and then different client source/binary permutations run against it.&lt;/li&gt;
	&lt;li&gt;Upgrade testing, and especially rolling upgrade testing, doesn&apos;t have any upstream automation on build.apache.org, in part because it&apos;s a pain to set up x-node clusters on Apache infrastructure.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This proposal, whether it stays under /dev-support or moves out into it&apos;s own top-level module (&quot;hbase-docker&quot; would conveniently fit the existing schema &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;), strives to create a simple framework for deploying &quot;distributed,&quot; multi-container Apache HBase clusters.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12762646">HBASE-12721</key>
            <summary>Create Docker container cluster infrastructure to enable better testing</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dimaspivak">Dima Spivak</assignee>
                                    <reporter username="dimaspivak">Dima Spivak</reporter>
                        <labels>
                    </labels>
                <created>Thu, 18 Dec 2014 18:10:12 +0000</created>
                <updated>Fri, 9 Sep 2016 16:14:15 +0000</updated>
                            <resolved>Wed, 17 Aug 2016 20:27:24 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>build</component>
                    <component>community</component>
                    <component>documentation</component>
                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                                                            <comments>
                            <comment id="14251987" author="stack" created="Thu, 18 Dec 2014 18:25:02 +0000"  >&lt;p&gt;amen&lt;/p&gt;</comment>
                            <comment id="15311246" author="dimaspivak" created="Wed, 1 Jun 2016 22:20:56 +0000"  >&lt;p&gt;This is ready to go. I&apos;ve put together a lightweight Python framework that uses &lt;tt&gt;docker-py&lt;/tt&gt; to orchestrate starting multi-container HBase clusters, handle configurations, and successfully run the tests in hbase-it. Let me get a Review Board up.&lt;/p&gt;</comment>
                            <comment id="15311299" author="apurtell" created="Wed, 1 Jun 2016 22:52:38 +0000"  >&lt;p&gt;Nice! I&apos;d like to try it out. Tomorrow &lt;/p&gt;</comment>
                            <comment id="15311607" author="dimaspivak" created="Thu, 2 Jun 2016 02:29:44 +0000"  >&lt;p&gt;Please do! Here are some instructions to get started while I continue to hammer out a proper patch:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Install Docker 1.11 on a machine. I did the development and testing of this under an Ubuntu 14.04 AWS instance with a 3.13.0-85 kernel (earlier Ubuntu kernels might have problems), so something similar would be the surest way not to run into issues. If you have a cloud instance at your disposal, you can simplify setup by taking advantage of a framework script that I&apos;ve temporarily uploaded to Gist (I ran it through bit.ly because of the long raw URL, but I won&apos;t be offended if you read through the script before running it). If using the script, spin up your single cloud instance and then run &lt;tt&gt;curl -sL &lt;a href=&quot;http://bit.ly/20UntA8&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bit.ly/20UntA8&lt;/a&gt;&lt;/tt&gt;, which will install Docker, update the host&apos;s root user&apos;s SSH keys to let you log into the containers we&apos;re going to start up, and generally make your life easier. &lt;b&gt;Note that this script copies the SSH keys from the Docker images we&apos;re creating into the &lt;tt&gt;~root/.ssh folder&lt;/tt&gt; on your host, so don&apos;t use this script on a machine with an existing SSH keypair in &lt;tt&gt;~root/.ssh&lt;/tt&gt;.&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;If you ran my setup script, run &lt;tt&gt;source /usr/local/bin/clusterdock.sh&lt;/tt&gt; on the host machine to enable use of &lt;tt&gt;clusterdock_run&lt;/tt&gt;, a small helper function that makes the framework super easy to use. &lt;em&gt;Instead of dealing with virtualenvs for this Python project, we run it out of a Docker container&lt;/em&gt;. If you already had Docker installed and just want to source the script from Gist, run
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;curl -sL http://bit.ly/1ROTmE3 | source /dev/stdin
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Stand up an HBase cluster. For the purpose of a quick demo, I uploaded images I built with this framework to my personal Docker Hub acount. To get a running 4-node HBase cluster with Oracle Java 8u91, Hadoop 2.7.2, and the most recent build of HBase &lt;tt&gt;master&lt;/tt&gt; as of when I built it an hour ago, just type:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/start_cluster apache_hbase --primary-node=node-1 --secondary-nodes=&apos;node-{2..4}&apos; --hbase-version=master --start-services
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;That&apos;s it. Running that will pull down the necessary HBase image (also built with this framework), setup some configs (i.e. you could have created a 5-node cluster by changing the Bash-expandable argument to &lt;tt&gt;&amp;#45;&amp;#45;secondary-nodes&lt;/tt&gt;), and then start up services. Standard out will give information on what&apos;s happening and how to access various web UIs, but you should also be able to SSH to nodes by name (assuming you have the key-pairs setup) by using the hostnames shown during startup. Other things to try:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Stop and remove all running containers:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/housekeeping nuke
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Build your own HBase cluster images:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/build_cluster apache_hbase --hbase-version=master --hbase-git-commit=master
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Learn more about options a particular script provides:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/start_cluster -h
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Let me know if you run into any issues!&lt;/p&gt;</comment>
                            <comment id="15311632" author="vrodionov" created="Thu, 2 Jun 2016 02:50:52 +0000"  >&lt;p&gt;Great, definitely. One request: can you enhance your  scripts and containerize HBase in a cluster (not single), &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dimaspivak&quot; class=&quot;user-hover&quot; rel=&quot;dimaspivak&quot;&gt;Dima Spivak&lt;/a&gt;? Run X HBase nodes per server in M node cluster? &lt;/p&gt;</comment>
                            <comment id="15313200" author="dimaspivak" created="Thu, 2 Jun 2016 22:26:16 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;. So what you&apos;re describing is definitely possible from a technical standpoint (I actually got it working semi-decently in a recent hackathon here at Cloudera), but I think for the time being, I&apos;ll focus on the single-host use case to avoid some of the complications around keeping cluster configuration files in sync.&lt;/p&gt;</comment>
                            <comment id="15313292" author="apurtell" created="Thu, 2 Jun 2016 23:30:33 +0000"  >&lt;p&gt;Awesome. I launched an Ubuntu 14.04 EC2 instance and followed your instructions to get 1 primary + 5 secondary up and running in just a few minutes:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;HBase Shell; enter &apos;help&amp;lt;RETURN&amp;gt;&apos; for list of supported commands.
Type &quot;exit&amp;lt;RETURN&amp;gt;&quot; to leave the HBase Shell
Version 2.0.0-SNAPSHOT, rcbb95cd3a9bf9a9f8558560ae58f4061a73f15a8, Wed Jun  1 18:29:24 PDT 2016

hbase(main):001:0&amp;gt; status
1 active master, 1 backup masters, 5 servers, 0 dead, 0.4000 average load
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before I ran your setup script I did use LVM to make all locally attached SSD storage into a single volume, formatted as XFS, and made /var/lib/docker a symlink pointing to a directory on this device. &lt;/p&gt;

&lt;p&gt;Questions and/or suggestions for enhancements follow. Perhaps subtasks? I&apos;m happy to help out as I&apos;m able. The main point of interest for me is how to build 0.98 SNAPSHOT images and run the IT test suite as part of release manager duties. &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;How does one build and register different versions of HBase for launching by build_cluster? Possible to add to a local library?&lt;/li&gt;
	&lt;li&gt;Can we set up a library of HBase versions to test? 0.98, 1.1, 1.2, 1.3, and master.&lt;/li&gt;
	&lt;li&gt;Build_cluster should allow me to set Xms and Xmx, at least for regionservers. If I start up a high memory instance I might want 8 GB heaps, etc.&lt;/li&gt;
	&lt;li&gt;How would we use G1 instead of CMS? Bonus points for extra GC flag support for Shenandoah.&lt;/li&gt;
	&lt;li&gt;How would we use a different version of the JVM? (including a custom compiled version)&lt;/li&gt;
	&lt;li&gt;Let&apos;s add a script/wrapper that runs all of the IT tests. Extra credit if one can optionally specify monkey type and policy on the command line.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="15313319" author="dimaspivak" created="Thu, 2 Jun 2016 23:45:33 +0000"  >&lt;p&gt;Yay! Glad to hear it works outside of my network &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. As for the great points raised:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;How does one build and register different versions of HBase for launching by build_cluster? Possible to add to a local library?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You can do this for the 0.98 branch, for example, by running:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/build_cluster apache_hbase --hbase-version=0.98 --hbase-git-commit=0.98
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In this case, the build process will check out source code, build a binary tarball using Maven, and extract it into a proper Docker image that can then be picked up by &lt;tt&gt;start_cluster&lt;/tt&gt;. FYI, the &lt;tt&gt;hbase-version&lt;/tt&gt; argument is just a label for our internal use whereas &lt;tt&gt;hbase-git-commit&lt;/tt&gt; is what&apos;s used when checking out code; this lets you potentially do one-off builds of a particular commit and name it whatever you want.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can we set up a library of HBase versions to test? 0.98, 1.1, 1.2, 1.3, and master.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I hope so! We&apos;ve had this running internally at Cloudera for a while where once a night, we build these images, push them to our local repository, and then assuming that that succeeds, trigger a Jenkins job that runs some tests from &lt;tt&gt;hbase-it&lt;/tt&gt;. Once we have the Docker registry part ironed out, I can coordinate with a committer on setting up the necessary Jenkins infra needed to do the same.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Build_cluster should allow me to set Xms and Xmx, at least for regionservers. If I start up a high memory instance I might want 8 GB heaps, etc.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So the difference between &lt;tt&gt;build_cluster&lt;/tt&gt; and &lt;tt&gt;start_cluster&lt;/tt&gt; is that &lt;tt&gt;build_cluster&lt;/tt&gt; creates the necessary Docker image(s) needed for a &lt;tt&gt;start_cluster&lt;/tt&gt; to work properly. Once those images exist, you can pass the location of an .ini-like file as an argument to &lt;tt&gt;start_cluster&lt;/tt&gt; and it will set configurations for you before starting services (and also keep them synchronized among every node of your Docker-based cluster). Here&apos;s what the default configuration looks like:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[hadoop/slaves]
+++ &apos;\n&apos;.join([&quot;{{0}}.{network}&quot;.format(node) for node in {secondary_nodes}])

[hadoop/core-site.xml]
fs.default.name = hdfs://{primary_node[0]}.{network}:8020

[hadoop/mapred-site.xml]
mapreduce.framework.name = yarn

[hadoop/yarn-site.xml]
yarn.resourcemanager.hostname = {primary_node[0]}.{network}
yarn.nodemanager.aux-services = mapreduce_shuffle
yarn.nodemanager.aux-services.mapreduce_shuffle.class = org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.vmem-check-enabled = false

[hbase/regionservers]
+++ &apos;\n&apos;.join([&quot;{{0}}.{network}&quot;.format(node) for node in {secondary_nodes}])

[hbase/backup-masters]
{secondary_nodes[0]}.{network}

[hbase/hbase-site.xml]
hbase.cluster.distributed = true
hbase.rootdir = hdfs://{primary_node[0]}.{network}/hbase
hbase.zookeeper.quorum = {primary_node[0]}.{network}
hbase.zookeeper.property.dataDir = /usr/local/zookeeper

hbase.it.clustermanager.hadoop.hdfs.user = root
hbase.it.clustermanager.zookeeper.user = root
hbase.it.clustermanager.hbase.user = root
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note that this file uses the group (thing inside [ ]) to decide which file to modify, and it knows to format xml files as property files differently than non-xml files. As such, we could just pass in JVM arguments in here.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;How would we use G1 instead of CMS? Bonus points for extra GC flag support for Shenandoah.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Same as above, I think? If it can be controlled through an option in an &lt;tt&gt;/hbase/conf&lt;/tt&gt;-based file, this framework already supports it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;How would we use a different version of the JVM? (including a custom compiled version)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;tt&gt;./bin/build_cluster apache_hbase&lt;/tt&gt; supports a flag that specifies a Java tarball to use. I imagine I&apos;d need to modify the code a little bit to handle non-Oracle releases, though.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Let&apos;s add a script/wrapper that runs all of the IT tests. Extra credit if one can optionally specify monkey type and policy on the command line.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1!&lt;/p&gt;</comment>
                            <comment id="15313360" author="apurtell" created="Fri, 3 Jun 2016 00:08:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;clusterdock_run ./bin/build_cluster apache_hbase --hbase-version=0.98 --hbase-git-commit=0.98&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Let me try this now. Really liking the ability to specify any git ref. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Once those images exist, you can pass the location of an .ini-like file as an argument to start_cluster and it will set configurations for you before starting services &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok, what I would like to do is control how hadoop-env.sh and hbase-env.sh are generated. Consider something like:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;hadoop-env.sh&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+UseG1GC&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:MaxGCPauseMillis=100&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+PrintGCDetails&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+PrintGCDateStamps&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+PrintGCTimeStamps&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+PrintAdaptiveSizePolicy&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+PrintReferenceGC&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+ParallelRefProcEnabled&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:+TieredCompilation&quot;
COMMON_HDFS_OPTS=&quot;\$COMMON_HDFS_OPTS -XX:-ResizePLAB&quot;

export HADOOP_NAMENODE_OPTS=&quot;\$HADOOP_NAMENODE_OPTS -Xms1g -Xmx1g&quot;
export HADOOP_NAMENODE_OPTS=&quot;\$HADOOP_NAMENODE_OPTS \$COMMON_HDFS_OPTS&quot;
export HADOOP_NAMENODE_OPTS=&quot;\$HADOOP_NAMENODE_OPTS -XX:+AlwaysPreTouch&quot;
export HADOOP_NAMENODE_OPTS=&quot;\$HADOOP_NAMENODE_OPTS -verbose:gc -Xloggc:/var/log/hadoop/hdfs-namenode-gc.log&quot;

export HADOOP_SECONDARYNAMENODE_OPTS=&quot;\$HADOOP_SECONDARYNAMENODE_OPTS -Xms1g -Xmx1g&quot;
export HADOOP_SECONDARYNAMENODE_OPTS=&quot;\$HADOOP_SECONDARYNAMENODE_OPTS \$COMMON_HDFS_OPTS&quot;
export HADOOP_SECONDARYNAMENODE_OPTS=&quot;\$HADOOP_SECONDARYNAMENODE_OPTS -verbose:gc -Xloggc:/var/log/hadoop/hdfs-secondarynamenode-gc.log&quot;

export HADOOP_DATANODE_OPTS=&quot;\$HADOOP_DATANODE_OPTS -Xms1g -Xmx1g&quot;
export HADOOP_DATANODE_OPTS=&quot;\$HADOOP_DATANODE_OPTS \$COMMON_HDFS_OPTS&quot;
export HADOOP_DATANODE_OPTS=&quot;\$HADOOP_DATANODE_OPTS -XX:+AlwaysPreTouch&quot;
export HADOOP_DATANODE_OPTS=&quot;\$HADOOP_DATANODE_OPTS -verbose:gc -Xloggc:/var/log/hadoop/hdfs-datanode-gc.log&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;hbase-env.sh&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+UseG1GC&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+PrintGCDetails&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+PrintGCDateStamps&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+PrintGCTimeStamps&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+PrintAdaptiveSizePolicy&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+PrintReferenceGC&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+ParallelRefProcEnabled&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:+TieredCompilation&quot;
COMMON_HBASE_OPTS=&quot;\$COMMON_HBASE_OPTS -XX:-ResizePLAB&quot;

export HBASE_MASTER_OPTS=&quot;\$HBASE_MASTER_OPTS -Xms1g -Xmx1g&quot;
export HBASE_MASTER_OPTS=&quot;\$HBASE_MASTER_OPTS \$COMMON_HBASE_OPTS&quot;
export HBASE_MASTER_OPTS=&quot;\$HBASE_MASTER_OPTS -verbose:gc -Xloggc:/var/log/hbase/hbase-master-gc.log&quot;

export HBASE_REGIONSERVER_OPTS=&quot;\$HBASE_REGIONSERVER_OPTS -Xms32g -Xmx32g&quot;
export HBASE_REGIONSERVER_OPTS=&quot;\$HBASE_REGIONSERVER_OPTS \$COMMON_HBASE_OPTS&quot;
export HBASE_REGIONSERVER_OPTS=&quot;\$HBASE_REGIONSERVER_OPTS -XX:MaxGCPauseMillis=50&quot;
export HBASE_REGIONSERVER_OPTS=&quot;\$HBASE_REGIONSERVER_OPTS -XX:+UseCondCardMark&quot;
export HBASE_REGIONSERVER_OPTS=&quot;\$HBASE_REGIONSERVER_OPTS -XX:+AlwaysPreTouch&quot;
export HBASE_REGIONSERVER_OPTS=&quot;\$HBASE_REGIONSERVER_OPTS -verbose:gc -Xloggc:/var/log/hbase/hbase-regionserver-gc.log&quot;

export HBASE_ZOOKEEPER_OPTS=&quot;\$HBASE_ZOOKEEPER_OPTS -Xms1g -Xmx1g&quot;
export HBASE_ZOOKEEPER_OPTS=&quot;\$HBASE_ZOOKEEPER_OPTS \$COMMON_HBASE_OPTS&quot;
export HBASE_ZOOKEEPER_OPTS=&quot;\$HBASE_ZOOKEEPER_OPTS -XX:+AlwaysPreTouch&quot;
export HBASE_ZOOKEEPER_OPTS=&quot;\$HBASE_ZOOKEEPER_OPTS -verbose:gc -Xloggc:/var/log/hbase/hbase-zookeeper-gc.log&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That would handle all of the JVM flag wishlist I think.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;./bin/build_cluster apache_hbase supports a flag that specifies a Java tarball to use&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Cool, I will try it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I imagine I&apos;d need to modify the code a little bit to handle non-Oracle releases, though.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Maybe not? The OpenJDK based JVM tarballs I build unpack like Oracle releases and run fine on CentOS 6. They just lack JFR. I don&apos;t think you&apos;re using that.&lt;/p&gt;</comment>
                            <comment id="15314637" author="dimaspivak" created="Fri, 3 Jun 2016 19:21:38 +0000"  >&lt;p&gt;Looks like the framework can handle what you want it to do, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;. Here&apos;s how:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Log into your AWS host and create a file that looks like this:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;root@trying-apache-docker:~# cat andy-setup.cfg 
[hadoop/slaves]
+++ &apos;\n&apos;.join([&quot;{{0}}.{network}&quot;.format(node) for node in {secondary_nodes}])

[hadoop/core-site.xml]
fs.default.name = hdfs://{primary_node[0]}.{network}:8020

[hadoop/mapred-site.xml]
mapreduce.framework.name = yarn

[hadoop/yarn-site.xml]
yarn.resourcemanager.hostname = {primary_node[0]}.{network}
yarn.nodemanager.aux-services = mapreduce_shuffle
yarn.nodemanager.aux-services.mapreduce_shuffle.class = org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.vmem-check-enabled = false

[hbase/regionservers]
+++ &apos;\n&apos;.join([&quot;{{0}}.{network}&quot;.format(node) for node in {secondary_nodes}])

[hbase/backup-masters]
{secondary_nodes[0]}.{network}

[hbase/hbase-site.xml]
hbase.cluster.distributed = true
hbase.rootdir = hdfs://{primary_node[0]}.{network}/hbase
hbase.zookeeper.quorum = {primary_node[0]}.{network}
hbase.zookeeper.property.dataDir = /usr/local/zookeeper

hbase.it.clustermanager.hadoop.hdfs.user = root
hbase.it.clustermanager.zookeeper.user = root
hbase.it.clustermanager.hbase.user = root

[hadoop/hadoop-env.sh]
body:
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+UseG1GC&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:MaxGCPauseMillis=100&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+PrintGCDetails&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+PrintGCDateStamps&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+PrintGCTimeStamps&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+PrintAdaptiveSizePolicy&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+PrintReferenceGC&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+ParallelRefProcEnabled&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:+TieredCompilation&quot;
    COMMON_HDFS_OPTS=&quot;$COMMON_HDFS_OPTS -XX:-ResizePLAB&quot;
    
    export HADOOP_NAMENODE_OPTS=&quot;$HADOOP_NAMENODE_OPTS -Xms1g -Xmx1g&quot;
    export HADOOP_NAMENODE_OPTS=&quot;$HADOOP_NAMENODE_OPTS $COMMON_HDFS_OPTS&quot;
    export HADOOP_NAMENODE_OPTS=&quot;$HADOOP_NAMENODE_OPTS -XX:+AlwaysPreTouch&quot;
    export HADOOP_NAMENODE_OPTS=&quot;$HADOOP_NAMENODE_OPTS -verbose:gc -Xloggc:/var/log/hadoop/hdfs-namenode-gc.log&quot;
    
    export HADOOP_SECONDARYNAMENODE_OPTS=&quot;$HADOOP_SECONDARYNAMENODE_OPTS -Xms1g -Xmx1g&quot;
    export HADOOP_SECONDARYNAMENODE_OPTS=&quot;$HADOOP_SECONDARYNAMENODE_OPTS $COMMON_HDFS_OPTS&quot;
    export HADOOP_SECONDARYNAMENODE_OPTS=&quot;$HADOOP_SECONDARYNAMENODE_OPTS -verbose:gc -Xloggc:/var/log/hadoop/hdfs-secondarynamenode-gc.log&quot;
    
    export HADOOP_DATANODE_OPTS=&quot;$HADOOP_DATANODE_OPTS -Xms1g -Xmx1g&quot;
    export HADOOP_DATANODE_OPTS=&quot;$HADOOP_DATANODE_OPTS $COMMON_HDFS_OPTS&quot;
    export HADOOP_DATANODE_OPTS=&quot;$HADOOP_DATANODE_OPTS -XX:+AlwaysPreTouch&quot;
    export HADOOP_DATANODE_OPTS=&quot;$HADOOP_DATANODE_OPTS -verbose:gc -Xloggc:/var/log/hadoop/hdfs-datanode-gc.log&quot;

[hbase/hbase-env.sh]
body:
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+UseG1GC&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+PrintGCDetails&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+PrintGCDateStamps&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+PrintGCTimeStamps&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+PrintAdaptiveSizePolicy&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+PrintReferenceGC&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+ParallelRefProcEnabled&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:+TieredCompilation&quot;
    COMMON_HBASE_OPTS=&quot;$COMMON_HBASE_OPTS -XX:-ResizePLAB&quot;
    
    export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS -Xms1g -Xmx1g&quot;
    export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS $COMMON_HBASE_OPTS&quot;
    export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS -verbose:gc -Xloggc:/var/log/hbase/hbase-master-gc.log&quot;
    
    export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -Xms32g -Xmx32g&quot;
    export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS $COMMON_HBASE_OPTS&quot;
    export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -XX:MaxGCPauseMillis=50&quot;
    export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -XX:+UseCondCardMark&quot;
    export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -XX:+AlwaysPreTouch&quot;
    export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS -verbose:gc -Xloggc:/var/log/hbase/hbase-regionserver-gc.log&quot;
    
    export HBASE_ZOOKEEPER_OPTS=&quot;$HBASE_ZOOKEEPER_OPTS -Xms1g -Xmx1g&quot;
    export HBASE_ZOOKEEPER_OPTS=&quot;$HBASE_ZOOKEEPER_OPTS $COMMON_HBASE_OPTS&quot;
    export HBASE_ZOOKEEPER_OPTS=&quot;$HBASE_ZOOKEEPER_OPTS -XX:+AlwaysPreTouch&quot;
    export HBASE_ZOOKEEPER_OPTS=&quot;$HBASE_ZOOKEEPER_OPTS -verbose:gc -Xloggc:/var/log/hbase/hbase-zookeeper-gc.log&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Assuming the file is in your current working directory, run the following to use it when starting up a &lt;tt&gt;master&lt;/tt&gt; cluster:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CLUSTERDOCK_TARGET_DIR=$(pwd) clusterdock_run ./bin/start_cluster apache_hbase --hbase-version=master --configurations=/root/target/andy-setup.cfg --start-services
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;What&apos;s going on under the hood is that, since we run clusterdock out of a Docker container, we need to have a way of volume mounting a directory into that container. One easy way to do this is for the framework to always volume mount the path pointed to by &lt;tt&gt;CLUSTERDOCK_TARGET_DIR&lt;/tt&gt; into the clusterdock container&apos;s &lt;tt&gt;/root/target&lt;/tt&gt; folder. Once you have that, the &lt;tt&gt;&amp;#45;-configurations&lt;/tt&gt; argument selects which script to use. Give it a shot and let me know if it works as expected.&lt;/p&gt;</comment>
                            <comment id="15317439" author="dimaspivak" created="Mon, 6 Jun 2016 22:54:57 +0000"  >&lt;p&gt;Added a link to the first part of a review for the Docker-based cluster deployment framework designed to help run and test Apache HBase. This review includes the most user-facing parts of the code: the binary scripts, clusterdock.sh helper functions Bash script, framework packaging code (requirements.txt and Dockerfile), and README.md.&lt;/p&gt;</comment>
                            <comment id="15317452" author="dimaspivak" created="Mon, 6 Jun 2016 23:02:00 +0000"  >&lt;p&gt;Added a link to the second part of a review for the Docker-based cluster deployment framework designed to help run and test Apache HBase. This review includes code from the &quot;topology&quot; abstraction of clusterdock. That is, a set of a files in a folder used to define how to build and start a cluster (in this case, an Apache HBase one).&lt;/p&gt;</comment>
                            <comment id="15317524" author="dimaspivak" created="Tue, 7 Jun 2016 00:02:39 +0000"  >&lt;p&gt;Added a link to the third (and final) part of a review for the Docker-based cluster deployment framework designed to help run and test Apache HBase. This review includes the core clusterdock code that handles starting clusters and orchestration with Docker.&lt;/p&gt;</comment>
                            <comment id="15346937" author="dimaspivak" created="Thu, 23 Jun 2016 18:36:13 +0000"  >&lt;p&gt;Just to provide an update for anyone interested, I&apos;m putting the finishing touches on a a new mega-patch version of this to go up on ReviewBoard that would encompass the single commit that would go in (I originally split the RB into 3 for easier digestion where I got some useful comments from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=asamir&quot; class=&quot;user-hover&quot; rel=&quot;asamir&quot;&gt;Samir Ahmic&lt;/a&gt; that I iterated on, thanks for that). Following &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;&apos;s advice, I&apos;ve run the Python package through Pylint and so have a monster list of &lt;span class=&quot;error&quot;&gt;&amp;#91;mostly minor&amp;#93;&lt;/span&gt; stuff to improve/knowingly ignore. &lt;/p&gt;</comment>
                            <comment id="15352069" author="apurtell" created="Mon, 27 Jun 2016 23:47:58 +0000"  >&lt;p&gt;I tried&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/build_cluster apache_hbase --hbase-version=0.98.21-SNAPSHOT --hbase-git-commit=5133a8b3cd6dc2e6956a092e6dcaca8753c6ba27
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and got&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO:clusterdock.topologies.apache_hbase.actions:Building image dimaspivak/hbase:centos6.6_java-8u91_hadoop-2.7.2_hbase-0.98.21-SNAPSHOT...
Sending build context to Docker daemon 965.8 MB
Step 1 : FROM dimaspivak/hbase:centos6.6_nodebase
Pulling repository docker.io/dimaspivak/hbase
Tag centos6.6_nodebase not found in repository docker.io/dimaspivak/hbase

Fatal error: local() encountered an error (return code 1) while executing &apos;docker build -t dimaspivak/hbase:centos6.6_java-8u91_hadoop-2.7.2_hbase-0.98.21-SNAPSHOT --no-cache /tmp/clusterdock/da0b255c-720b-431e-a3db-7085d9766c02&apos;

Aborting.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15352082" author="dimaspivak" created="Mon, 27 Jun 2016 23:55:30 +0000"  >&lt;p&gt;Oops, forgot to push the image. Wanna try again?&lt;/p&gt;</comment>
                            <comment id="15352119" author="apurtell" created="Tue, 28 Jun 2016 00:25:46 +0000"  >&lt;p&gt;success!&lt;/p&gt;</comment>
                            <comment id="15352122" author="apurtell" created="Tue, 28 Jun 2016 00:30:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dimaspivak&quot; class=&quot;user-hover&quot; rel=&quot;dimaspivak&quot;&gt;Dima Spivak&lt;/a&gt;, what are your thoughts on bundling local SSD storage aka &apos;ephemeral store&apos; volumes into a single logical volume and mounting it on /var/lib/docker/volumes ? This would happen underneath your clusterdock stuff whenever the instance is booted.&lt;/p&gt;

&lt;p&gt;This would mean that any docker volumes created while launching clusters would not be persisted across instance stop and restart, but on the other hand volumes can be used to back cluster data like namenode and datanode storage. This is important for getting reasonable I/O latency and variance.&lt;/p&gt;

&lt;p&gt;I know Docker data volumes are meant to persist independent of the container&#8217;s life cycle. We&apos;d still have that as long as the EC2 instance is up, but not if it is put into &apos;stopped&apos; state and later started again. &lt;/p&gt;</comment>
                            <comment id="15352127" author="apurtell" created="Tue, 28 Jun 2016 00:40:13 +0000"  >&lt;p&gt;Never mind, docker doesn&apos;t like that very much&lt;/p&gt;</comment>
                            <comment id="15352135" author="dimaspivak" created="Tue, 28 Jun 2016 00:48:45 +0000"  >&lt;p&gt;So &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, I think this already works. There&apos;s an argument to the &lt;tt&gt;apache_hbase&lt;/tt&gt; topology called &lt;tt&gt;&amp;#45;&amp;#45;data-directories&lt;/tt&gt; that lets you specify locations on which to put YARN and HDFS stuff. I actually use this when running with storage-dense AWS instances (e.g. &lt;tt&gt;d2._xlarge&lt;/tt&gt;) myself to let me do ITBLL runs with tons of data (say 10 TB+) without needing to deal with logical volumes and whatnot. At the end, the utility functions that remove containers (under &lt;tt&gt;./bin/housekeeping&lt;/tt&gt;) also figure out which data directories are mounted and clean them up, too. Would that work?&lt;/p&gt;</comment>
                            <comment id="15352150" author="apurtell" created="Tue, 28 Jun 2016 01:04:10 +0000"  >&lt;p&gt;Yeah that works. &lt;/p&gt;

&lt;p&gt;&amp;gt;  I actually use this when running with storage-dense AWS instances (e.g. d2._xlarge) myself to let me do ITBLL runs with tons of data (say 10 TB+) without needing to deal with logical volumes and whatnot.&lt;/p&gt;

&lt;p&gt;This is pretty much what I want to do as often as possible when making releases or evaluating a release candidate.&lt;/p&gt;</comment>
                            <comment id="15352152" author="dimaspivak" created="Tue, 28 Jun 2016 01:06:26 +0000"  >&lt;p&gt;Woot. Alright, let me spend another day cleaning up the code based on what I got from running it through Pylint and then I&apos;ll post instructions for how you/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt; can try pushing some images to the Apache HBase Bintray and put it out for some wider testing. Thanks again for trying it out.&lt;/p&gt;</comment>
                            <comment id="15352160" author="apurtell" created="Tue, 28 Jun 2016 01:17:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dimaspivak&quot; class=&quot;user-hover&quot; rel=&quot;dimaspivak&quot;&gt;Dima Spivak&lt;/a&gt; I&apos;d be curious how to use --data-directories with 24 volumes on a d2.8xlarge to run a substantial ITBLL workload on a virtual 5 slave cluster (so, 6 nodes with master). I upped the root volume to 100GB and went through the basics from further up on this issue. I can see how to set up cluster configuration for larger heaps, thanks for that. Plenty of memory on a d2.8xlarge to run 5 RSes with 32GB heaps. &lt;/p&gt;

&lt;p&gt;That instance is stopped now but I can come back to it at any time. &lt;/p&gt;</comment>
                            <comment id="15352173" author="dimaspivak" created="Tue, 28 Jun 2016 01:28:07 +0000"  >&lt;p&gt;Yeah, give it a shot. You can pass a comma-separated list of directories into &lt;tt&gt;&amp;#45;&amp;#45;data-directories&lt;/tt&gt; and it&apos;ll set up YARN and HDFS accordingly. As an example, my instances have SSDs mounted into &lt;tt&gt;/data&lt;/tt&gt;, &lt;tt&gt;/data1&lt;/tt&gt;, &lt;tt&gt;/data2&lt;/tt&gt;, etc. My invocation to start up nodes which we use to run &lt;tt&gt;hbase-it&lt;/tt&gt; nightly is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_run ./bin/start_cluster --always-pull -n network${RANDOM} apache_hbase \
    --hbase-version=${HBASE_BRANCH} --secondary-nodes=&apos;node-{2..5}&apos; \
    --data-directories=&apos;/data,/data1,/data2,/data3,/data4,/data5&apos; --start-services
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15367303" author="dimaspivak" created="Fri, 8 Jul 2016 06:46:26 +0000"  >&lt;p&gt;Alright, I think we&apos;ve got something ready for some real use! Single patch up on ReviewBoard can be applied to tip of master branch and now includes everything needed for standalone building of all necessary images to start a multi-node HBase cluster on a single host. See RB description/testing for more details.&lt;/p&gt;</comment>
                            <comment id="15373157" author="busbey" created="Tue, 12 Jul 2016 16:15:53 +0000"  >&lt;p&gt;(note to myself that I&apos;m reviewing this on reviewboard)&lt;/p&gt;</comment>
                            <comment id="15378640" author="dimaspivak" created="Fri, 15 Jul 2016 00:05:18 +0000"  >&lt;p&gt;Posted a new patch up on RB to address &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;&apos;s comments and also retested it using the new 1.2.2 release. Anyone else wanna give it a spin?&lt;/p&gt;</comment>
                            <comment id="15407233" author="dimaspivak" created="Thu, 4 Aug 2016 06:04:11 +0000"  >&lt;p&gt;Since I last posted here, I&apos;ve done a lot of thinking about the best way to contribute this to HBase. I&apos;ve always felt a bit funny about having the whole &lt;tt&gt;clusterdock&lt;/tt&gt; framework live in HBase proper, since only the &lt;tt&gt;apache_hbase&lt;/tt&gt; topology part has anything to do with HBase, so I think I&apos;ve come up with a better way to let us use this while not bloating &lt;tt&gt;dev-support&lt;/tt&gt;. Long story short, we&apos;ve put up the &lt;tt&gt;clusterdock&lt;/tt&gt; framework in &lt;a href=&quot;https://github.com/cloudera/clusterdock&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Cloudera&apos;s GitHub&lt;/a&gt; and pushed images of the framework into &lt;a href=&quot;https://hub.docker.com/r/cloudera/clusterdock/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Docker Hub&lt;/a&gt;. The framework now supports use of topologies that are not part of the actual framework through Docker&apos;s data volume functionality. That is, instead of needing to keep one copy of the framework for our Cloudera CDH stuff, and then a duplicate copy in Apache HBase, I propose we let the framework live in our Cloudera Docker registry, and then only commit the &lt;tt&gt;apache_hbase&lt;/tt&gt; topology, which can then be used with the framework.&lt;/p&gt;

&lt;p&gt;Does that make sense? Would an example help anyone still following this?&lt;/p&gt;</comment>
                            <comment id="15407250" author="stack" created="Thu, 4 Aug 2016 06:13:45 +0000"  >&lt;p&gt;Sounds good to me as a stopgap to get this project moving along to the next stage. +1.&lt;/p&gt;</comment>
                            <comment id="15407318" author="busbey" created="Thu, 4 Aug 2016 07:00:55 +0000"  >&lt;p&gt;makes sense. sorry to see the project not under asf governance, but I agree that a central place would be better than our dev-support.&lt;/p&gt;</comment>
                            <comment id="15408105" author="apurtell" created="Thu, 4 Aug 2016 16:51:39 +0000"  >&lt;p&gt;Makes sense.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Would an example help anyone still following this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes. An example of setting up with a compilation from git sha and running ITBLL with this framework would be awesome &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15412752" author="dimaspivak" created="Tue, 9 Aug 2016 00:56:07 +0000"  >&lt;p&gt;New review up on RB. Update removes the bulk of the framework from Apache HBase but leaves behind what&apos;s needed to create an &lt;tt&gt;apache_hbase&lt;/tt&gt; topology that can be plugged into the framework. Since the original patches went up, &lt;tt&gt;clusterdock.sh&lt;/tt&gt; from the framework has also been updated to make it easier to SSH into nodes. In short, now instead of needing to worry about private keys, assuming you&apos;ve started up a cluster with nodes &lt;tt&gt;node-{1..5}.cluster&lt;/tt&gt;, you can simply run&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_ssh node-1.cluster
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;to get an interactive terminal or&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_ssh node-1.cluster &apos;echo &quot;list&quot; | hbase shell -n&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;to run a command against a running Docker-based cluster.&lt;/p&gt;</comment>
                            <comment id="15412788" author="dimaspivak" created="Tue, 9 Aug 2016 01:16:26 +0000"  >&lt;p&gt;Assuming you&apos;re running Docker 1.11+, to build HBase images from Git SHA (defaults to using Hadoop 2.7.2):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;source /dev/stdin &amp;lt;&amp;lt;&amp;lt; &quot;$(curl -sL http://tiny.cloudera.com/clusterdock.sh)&quot;
CLUSTERDOCK_TOPOLOGY_IMAGE=dimaspivak/clusterdock:apache_hbase_topology clusterdock_run ./bin/build_cluster --namespace=dimaspivak apache_hbase --hadoop-version=2.7.1 --hadoop-tarball=https://archive.apache.org/dist/hadoop/core/hadoop-2.7.1/hadoop-2.7.1.tar.gz --hbase-version=andysCommit --hbase-git-commit 1ecb0fce342ee878cf96f7a3165007192bedb2ef
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To start the cluster:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CLUSTERDOCK_TOPOLOGY_IMAGE=dimaspivak/clusterdock:apache_hbase_topology clusterdock_run ./bin/start_cluster --namespace=dimaspivak apache_hbase --hadoop-version=2.7.1 --hbase-version=andysCommit --secondary-nodes=&apos;node-{2..5}&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To run ITBLL against the cluster:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;clusterdock_ssh node-1.cluster org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15421896" author="dimaspivak" created="Mon, 15 Aug 2016 23:43:13 +0000"  >&lt;p&gt;Hey Docker-ers, any chance I can get one last review on this?&lt;/p&gt;</comment>
                            <comment id="15422083" author="busbey" created="Tue, 16 Aug 2016 02:41:56 +0000"  >&lt;p&gt;I think it got missed because it isn&apos;t in &quot;Patch Available&quot; status.&lt;/p&gt;

&lt;p&gt;I&apos;m +1 and planning to push as soon as I have my local repo ready for patches.&lt;/p&gt;</comment>
                            <comment id="15423149" author="dimaspivak" created="Tue, 16 Aug 2016 17:47:12 +0000"  >&lt;p&gt;Ooh, sorry about that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;. Lemme post it up here to get a Yetus run.&lt;/p&gt;</comment>
                            <comment id="15423184" author="hadoopqa" created="Tue, 16 Aug 2016 18:17:01 +0000"  >&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; reexec &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; 0m 10s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Docker mode activated. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; shelldocs &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; 0m 3s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Shelldocs was not available. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hbaseanti &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; Patch does not have any anti-patterns. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; @author &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch does not contain any @author tags. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; pylint &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 3s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; The patch generated 15 new + 0 unchanged - 0 fixed = 15 total (was 0) &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; shellcheck &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 4s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; There were no new shellcheck issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; whitespace &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch has no whitespace issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hadoopcheck &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 27m 34s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; Patch does not cause any errors with Hadoop 2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.1 2.6.2 2.6.3 2.7.1. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; hbaseprotoc &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 10s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; root in the patch failed. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; asflicense &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 12s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; The patch generated 2 ASF License warnings. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt;&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; 28m 23s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Docker &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client=1.11.2 Server=1.11.2 Image:yetus/hbase:date2016-08-16 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12823959/HBASE-12721_v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12823959/HBASE-12721_v5.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Issue &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12721&quot; title=&quot;Create Docker container cluster infrastructure to enable better testing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12721&quot;&gt;&lt;del&gt;HBASE-12721&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  asflicense  pylint  shellcheck  shelldocs  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; uname &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Linux a4e33b7794fd 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Build tool &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; maven &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Personality &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; master / d5080e8 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; shellcheck &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v0.4.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pylint &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v1.6.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pylint &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/artifact/patchprocess/diff-patch-pylint.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/artifact/patchprocess/diff-patch-pylint.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hbaseprotoc &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/artifact/patchprocess/patch-hbaseprotoc-root.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/artifact/patchprocess/patch-hbaseprotoc-root.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; asflicense &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/artifact/patchprocess/patch-asflicense-problems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/artifact/patchprocess/patch-asflicense-problems.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; modules &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; C: . U: . &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3108/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Powered by &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Apache Yetus 0.3.0   &lt;a href=&quot;http://yetus.apache.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://yetus.apache.org&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;
</comment>
                            <comment id="15423222" author="dimaspivak" created="Tue, 16 Aug 2016 18:54:17 +0000"  >&lt;p&gt;Let&apos;s try to clean up those pesky pylint warnings...&lt;/p&gt;</comment>
                            <comment id="15423263" author="hadoopqa" created="Tue, 16 Aug 2016 19:26:45 +0000"  >&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; reexec &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; 0m 10s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Docker mode activated. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; shelldocs &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; 0m 3s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Shelldocs was not available. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hbaseanti &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; Patch does not have any anti-patterns. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; @author &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch does not contain any @author tags. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; pylint &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 3s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; The patch generated 10 new + 0 unchanged - 0 fixed = 10 total (was 0) &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; shellcheck &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 4s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; There were no new shellcheck issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; whitespace &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch has no whitespace issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hadoopcheck &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 27m 22s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; Patch does not cause any errors with Hadoop 2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.1 2.6.2 2.6.3 2.7.1. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; hbaseprotoc &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 10s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; root in the patch failed. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; asflicense &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 13s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; The patch generated 2 ASF License warnings. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt;&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; 28m 11s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Docker &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client=1.11.2 Server=1.11.2 Image:yetus/hbase:date2016-08-16 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12823969/HBASE-12721_v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12823969/HBASE-12721_v6.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Issue &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12721&quot; title=&quot;Create Docker container cluster infrastructure to enable better testing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12721&quot;&gt;&lt;del&gt;HBASE-12721&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  asflicense  pylint  shellcheck  shelldocs  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; uname &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Linux 0fd99684a984 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Build tool &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; maven &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Personality &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; master / d5080e8 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; shellcheck &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v0.4.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pylint &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v1.6.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pylint &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/artifact/patchprocess/diff-patch-pylint.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/artifact/patchprocess/diff-patch-pylint.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hbaseprotoc &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/artifact/patchprocess/patch-hbaseprotoc-root.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/artifact/patchprocess/patch-hbaseprotoc-root.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; asflicense &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/artifact/patchprocess/patch-asflicense-problems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/artifact/patchprocess/patch-asflicense-problems.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; modules &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; C: . U: . &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3110/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Powered by &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Apache Yetus 0.3.0   &lt;a href=&quot;http://yetus.apache.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://yetus.apache.org&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;
</comment>
                            <comment id="15423269" author="dimaspivak" created="Tue, 16 Aug 2016 19:30:34 +0000"  >&lt;p&gt;One last patch... 1 warning was real, but the others are locally disabled. I think I&apos;ll need to open a separate JIRA for our Yetus personality, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;, to not consider those intentionally-ignored warnings to be problems.&lt;/p&gt;</comment>
                            <comment id="15423303" author="hadoopqa" created="Tue, 16 Aug 2016 20:08:00 +0000"  >&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; reexec &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; 0m 10s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Docker mode activated. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; shelldocs &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; 0m 3s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Shelldocs was not available. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hbaseanti &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; Patch does not have any anti-patterns. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; @author &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch does not contain any @author tags. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; pylint &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 3s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; The patch generated 9 new + 0 unchanged - 0 fixed = 9 total (was 0) &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; shellcheck &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 4s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; There were no new shellcheck issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; whitespace &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 0m 0s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch has no whitespace issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hadoopcheck &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 27m 9s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; Patch does not cause any errors with Hadoop 2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.1 2.6.2 2.6.3 2.7.1. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; hbaseprotoc &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 0m 13s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; root in the patch failed. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; asflicense &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; 1m 34s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; The patch generated 2 ASF License warnings. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt;&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; 29m 24s &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Docker &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Client=1.11.2 Server=1.11.2 Image:yetus/hbase:date2016-08-16 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12823973/HBASE-12721_v7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12823973/HBASE-12721_v7.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Issue &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12721&quot; title=&quot;Create Docker container cluster infrastructure to enable better testing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12721&quot;&gt;&lt;del&gt;HBASE-12721&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  asflicense  pylint  shellcheck  shelldocs  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; uname &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Linux a6437a449803 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Build tool &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; maven &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Personality &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; master / d5080e8 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; shellcheck &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v0.4.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pylint &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v1.6.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pylint &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/artifact/patchprocess/diff-patch-pylint.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/artifact/patchprocess/diff-patch-pylint.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hbaseprotoc &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/artifact/patchprocess/patch-hbaseprotoc-root.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/artifact/patchprocess/patch-hbaseprotoc-root.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; asflicense &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/artifact/patchprocess/patch-asflicense-problems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/artifact/patchprocess/patch-asflicense-problems.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; modules &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; C: . U: . &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/3111/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Powered by &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Apache Yetus 0.3.0   &lt;a href=&quot;http://yetus.apache.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://yetus.apache.org&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;
</comment>
                            <comment id="15425147" author="dimaspivak" created="Wed, 17 Aug 2016 18:42:55 +0000"  >&lt;p&gt;For anyone keeping score at home, the remaining Pylint warnings are caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/YETUS-309&quot; title=&quot;pylint plugin false positives&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YETUS-309&quot;&gt;&lt;del&gt;YETUS-309&lt;/del&gt;&lt;/a&gt; (which I just submitted a patch for over there). How&apos;s it look, guys? Can we commit this?&lt;/p&gt;</comment>
                            <comment id="15425177" author="busbey" created="Wed, 17 Aug 2016 18:58:02 +0000"  >&lt;p&gt;+1 from me.&lt;/p&gt;

&lt;p&gt;we&apos;ll need to either fix or exclude the RAT pings, but I&apos;ll do that as I commit it now.&lt;/p&gt;</comment>
                            <comment id="15425304" author="busbey" created="Wed, 17 Aug 2016 20:27:24 +0000"  >&lt;p&gt;pushed to master! That sufficient for now? Maybe branch-specific backports in follow-on?&lt;/p&gt;

&lt;p&gt;Took a go at a release note, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dimaspivak&quot; class=&quot;user-hover&quot; rel=&quot;dimaspivak&quot;&gt;Dima Spivak&lt;/a&gt; or whomever else feel free to update.&lt;/p&gt;

&lt;p&gt;thanks a ton for this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dimaspivak&quot; class=&quot;user-hover&quot; rel=&quot;dimaspivak&quot;&gt;Dima Spivak&lt;/a&gt;. is this baked enough for us to expand our &quot;getting started&quot; section for pseudo distributed?&lt;/p&gt;</comment>
                            <comment id="15425307" author="busbey" created="Wed, 17 Aug 2016 20:27:54 +0000"  >&lt;p&gt;Do the subtasks need to get promoted to full tasks, or closed out?&lt;/p&gt;</comment>
                            <comment id="15425317" author="dimaspivak" created="Wed, 17 Aug 2016 20:32:18 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;. I&apos;ll move those tasks to live under a new umbrella JIRA having to do with integrating the topology into testing. Documentation is blocked at the moment by the uncertainty of where we should be pushing Docker images. Once that&apos;s resolved, I&apos;ll hammer out updates to the ref guide and the RC scripts before taking a stab at Jenkins jobs to run &lt;tt&gt;hbase-it&lt;/tt&gt; upstream somewhere.&lt;/p&gt;</comment>
                            <comment id="15425514" author="hudson" created="Wed, 17 Aug 2016 22:33:08 +0000"  >&lt;p&gt;FAILURE: Integrated in Jenkins build HBase-Trunk_matrix #1433 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-Trunk_matrix/1433/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-Trunk_matrix/1433/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12721&quot; title=&quot;Create Docker container cluster infrastructure to enable better testing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12721&quot;&gt;&lt;del&gt;HBASE-12721&lt;/del&gt;&lt;/a&gt; Create Docker container cluster infrastructure to enable (busbey: rev ccf5d27d7aa238c8398d2818928a71f39bd749a0)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/profile.cfg&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/Dockerfile&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/configurations.cfg&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/ssh/id_rsa.pub&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/_&lt;em&gt;init&lt;/em&gt;_.py&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/actions.py&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/ssh/id_rsa&lt;/li&gt;
	&lt;li&gt;(add) dev-support/apache_hbase_topology/README.md&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15477447" author="apurtell" created="Fri, 9 Sep 2016 16:14:15 +0000"  >&lt;p&gt;We are missing docs on how to build a topology image, or drop in topology from this issue into a checkout of clusterdock. I don&apos;t want to use a canned topology I can&apos;t change. Going back to the old version where things &quot;just work&quot;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12991394">HADOOP-13397</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12823959" name="HBASE-12721_v5.patch" size="37514" author="dimaspivak" created="Tue, 16 Aug 2016 17:47:12 +0000"/>
                            <attachment id="12823969" name="HBASE-12721_v6.patch" size="37645" author="dimaspivak" created="Tue, 16 Aug 2016 18:54:17 +0000"/>
                            <attachment id="12823973" name="HBASE-12721_v7.patch" size="37645" author="dimaspivak" created="Tue, 16 Aug 2016 19:30:34 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12974964">HBASE-15936</subtask>
                            <subtask id="12975680">HBASE-15962</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 18 Dec 2014 18:25:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23l5r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Downstream users wishing to test HBase in a &amp;quot;distributed&amp;quot; fashion (multiple &amp;quot;nodes&amp;quot; running as separate containers on the same host) can now do so in an automated fashion while leveraging Docker for process isolation via the clusterdock project.&lt;br/&gt;
&lt;br/&gt;
For details see the README.md in the dev-support/apache_hbase_topology folder.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>