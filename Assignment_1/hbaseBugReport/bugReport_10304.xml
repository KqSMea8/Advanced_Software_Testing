<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:12:29 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-10304/HBASE-10304.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-10304] Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString</title>
                <link>https://issues.apache.org/jira/browse/HBASE-10304</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;(Jimmy has been working on this one internally.  I&apos;m just the messenger raising this critical issue upstream).&lt;/p&gt;

&lt;p&gt;So, if you make job jar and bundle up hbase inside in it because you want to access hbase from your mapreduce task, the deploy of the job jar to the cluster fails with:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
14/01/05 08:59:19 INFO Configuration.deprecation: topology.node.&lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt;.mapping.impl is deprecated. Instead, use net.topology.node.&lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt;.mapping.impl
14/01/05 08:59:19 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.defineClass1(Native Method)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.defineClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:792)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:424)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:357)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.toScan(ProtobufUtil.java:818)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(TableMapReduceUtil.java:433)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:186)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:147)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:270)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:100)
	at com.ngdata.hbaseindexer.mr.HBaseMapReduceIndexerTool.run(HBaseMapReduceIndexerTool.java:124)
	at com.ngdata.hbaseindexer.mr.HBaseMapReduceIndexerTool.run(HBaseMapReduceIndexerTool.java:64)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.ngdata.hbaseindexer.mr.HBaseMapReduceIndexerTool.main(HBaseMapReduceIndexerTool.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, ZCLBS is a hack.  This class is in the hbase-protocol module.  It is &quot;in&quot; the com.google.protobuf package.  All is well and good usually.&lt;/p&gt;

&lt;p&gt;But when we make a job jar and bundle up hbase inside it, our &apos;trick&apos; breaks.  RunJar makes a new class loader to run the job jar.  This URLCLassLoader &apos;attaches&apos; all the jars and classes that are in jobjar so they can be found when it does to do a lookup only Classloaders work by always delegating to their parent first (unless you are a WAR file in a container where delegation is &apos;off&apos; for the most part) and in this case, the parent classloader will have access to a pb jar since pb is in the hadoop CLASSPATH.  So, the parent loads the pb classes.&lt;/p&gt;

&lt;p&gt;We then load ZCLBS only this is done in the claslsloader made by RunJar; ZKCLBS has a different classloader from its superclass and we get the above IllegalAccessError.&lt;/p&gt;

&lt;p&gt;Now (Jimmy&apos;s work comes in here), this can&apos;t be fixed by reflection &amp;#8211; you can&apos;t setAccess on a &apos;Class&apos; &amp;#8211; and though it probably could be fixed by hacking RunJar so it was somehow made configurable so we could put in place our own ClassLoader to do something like containers do for WAR files (probably not a bad idea), there would be some fierce hackery involved and besides, this won&apos;t show up in hadoop anytime too soon leaving hadoop 2.2ers out in the cold.&lt;/p&gt;

&lt;p&gt;So, the alternatives are:&lt;/p&gt;

&lt;p&gt;1. Undo the ZCLSB hack.  We&apos;d lose a lot of nice perf improvement but I&apos;d say this is preferable to crazy CLASSPATH hacks.&lt;br/&gt;
2. Require folks put hbase-protocol &amp;#8211; thats all you&apos;d need &amp;#8211; on the hadoop CLASSPATH.  This is kinda crazy.&lt;br/&gt;
3. We could try shading the pb jar content or probably better, just pull pb into hbase altogether only under a different package.  If it was in our code base, we could do more ZCLSB-like speedups.&lt;/p&gt;

&lt;p&gt;I was going to experiment with #3 above unless anyone else has a better idea.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12687997">HBASE-10304</key>
            <summary>Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ndimiduk">Nick Dimiduk</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Jan 2014 04:06:47 +0000</created>
                <updated>Sat, 21 Feb 2015 23:31:18 +0000</updated>
                            <resolved>Wed, 15 Jan 2014 18:25:08 +0000</resolved>
                                    <version>0.98.0</version>
                    <version>0.96.1.1</version>
                                    <fixVersion>0.98.0</fixVersion>
                    <fixVersion>0.99.0</fixVersion>
                                    <component>documentation</component>
                    <component>mapreduce</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                <comments>
                            <comment id="13866322" author="apurtell" created="Thu, 9 Jan 2014 05:07:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;pull pb into hbase altogether only under a different package. If it was in our code base, we could do more ZCLSB-like speedups&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Of the alternatives above, this is the least bad option I think.&lt;/p&gt;</comment>
                            <comment id="13866328" author="ndimiduk" created="Thu, 9 Jan 2014 05:20:20 +0000"  >&lt;p&gt;For an immediate solution, my preference is the order in which you present the options. (1) solves the blocking problem immediately and gives us time to make an informed decision about (3). I find (2) an acceptable alternative because it can be managed via BigTop packaging and is effectively transparent to users of any distribution. Tarball users will need a big fat readme warning (though, as Mr. Purtell pointed out to me earlier today on an unrelated ticket, users sophisticated enough to rock the tarballs in prod are also very likely making use of infra automation &#224; la Puppet or Chef, so this isn&apos;t a big deal for them either). (3) amounts to forking PB, something I don&apos;t think we should do lightly. Even if we tackle is as a packaging step via maven:assembly, it&apos;ll lead to version conflict problems down the road for users who want to use PB in their own application code (unless you also want to get into jarjar territory...).&lt;/p&gt;

&lt;p&gt;Hence, let&apos;s fix things for users today via (1) or (2) so we can continue conversation on responsible execution of (3).&lt;/p&gt;</comment>
                            <comment id="13866332" author="apurtell" created="Thu, 9 Jan 2014 05:25:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;Even if we tackle is as a packaging step via maven:assembly, it&apos;ll lead to version conflict problems down the road&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was wondering if this might unblock the issue without handing back performance gains while we work on something better.&lt;/p&gt;</comment>
                            <comment id="13866840" author="phunt" created="Thu, 9 Jan 2014 17:44:19 +0000"  >&lt;p&gt;I realize that this is longer term (and perhaps you&apos;re already doing/did and I just missed it?) but what about doing 1, but get the fix you&apos;re trying to hack into hbase codebase into upstream, protobuf itself, instead. Isn&apos;t this a change that would benefit the entire protobuf community?&lt;/p&gt;</comment>
                            <comment id="13866890" author="stack" created="Thu, 9 Jan 2014 18:38:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;Isn&apos;t this a change that would benefit the entire protobuf community?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;it is a change that goes against the pb lib philosophy of making a copy before going to work on it.  The pb team also talks of &apos;copy is cheap&apos; and &apos;object creation is cheap&apos; in java up on discussion lists (which is &apos;true&apos; but no copy and no creation will always be better) so it might take a while and some work getting it contributed.&lt;/p&gt;

&lt;p&gt;If we were to go this route, we&apos;d want to push more than just this one ZCLBS change or just go the route of this gentleman &lt;a href=&quot;https://code.google.com/p/protobuf-gcless/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://code.google.com/p/protobuf-gcless/&lt;/a&gt; altogether.&lt;/p&gt;

&lt;p&gt;Let me measure what we lose reverting (option 1.).  ZCLBS came in as part of the effort at getting us back to 0.94 numbers.&lt;/p&gt;

&lt;p&gt;Interesting that folks here think 2. is viable; I&apos;d think we&apos;d just be pissing folks off... but it&apos;d be easy to require.&lt;/p&gt;

&lt;p&gt;Will get some more on 3. too. &lt;/p&gt;

&lt;p&gt;Will be back.&lt;/p&gt;</comment>
                            <comment id="13866928" author="stack" created="Thu, 9 Jan 2014 19:19:10 +0000"  >&lt;p&gt;I used this testing.  It is an assembly that creates an hbase jobjar to run on cluster.  Good for repo&apos;ing this issue.  Also, our little MR Driver program is broke since we modularized hbase.  I can fix or just purge it since it does not look like anyone uses it.&lt;/p&gt;</comment>
                            <comment id="13867029" author="phunt" created="Thu, 9 Jan 2014 20:46:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;it is a change that goes against the pb lib philosophy of making a copy before going to work on it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;perhaps then the upstream change should be to make that class (LiteralByteString) protected rather than default access? iiuc that would allow you to provide your own impl properly.&lt;/p&gt;</comment>
                            <comment id="13867059" author="stack" created="Thu, 9 Jan 2014 21:09:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;perhaps then the upstream change should be to make that class (LiteralByteString) protected rather than default access? iiuc that would allow you to provide your own impl properly.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would imply violation of the deduced &apos;copy first&apos; axiom?&lt;/p&gt;

&lt;p&gt;Reading in pb, public classes are final.&lt;/p&gt;</comment>
                            <comment id="13867308" author="devaraj" created="Fri, 10 Jan 2014 00:03:59 +0000"  >&lt;p&gt;I&apos;d say we do (1) immediately and then do the hackery in Runjar (similar to what WAR does). I am not in favor of (3) - seems to be a big undertaking.&lt;/p&gt;</comment>
                            <comment id="13867309" author="enis" created="Fri, 10 Jan 2014 00:04:02 +0000"  >&lt;p&gt;Looking at ZCLBS class, all three methods we need are indeed static. Can we get away with subclassing LiteralByteString with a simple patch or am I reading this wrong? &lt;/p&gt;
</comment>
                            <comment id="13867317" author="enis" created="Fri, 10 Jan 2014 00:09:17 +0000"  >&lt;p&gt;Attaching a patch per above. Not tested, but seems to compile. &lt;/p&gt;

&lt;p&gt;Stack, can you easily repro the problem? &lt;/p&gt;</comment>
                            <comment id="13867496" author="enis" created="Fri, 10 Jan 2014 04:43:50 +0000"  >&lt;p&gt;let&apos;s try qa. &lt;/p&gt;</comment>
                            <comment id="13867503" author="stack" created="Fri, 10 Jan 2014 05:01:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; no luck.  Slightly different version of same issue &amp;#8211; but points for good attempt for sure:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.IllegalAccessError: tried to access class com.google.protobuf.LiteralByteString from class com.google.protobuf.ZeroCopyLiteralByteString
	at com.google.protobuf.ZeroCopyLiteralByteString.wrap(ZeroCopyLiteralByteString.java:41)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.toFilter(ProtobufUtil.java:1363)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.toScan(ProtobufUtil.java:830)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(TableMapReduceUtil.java:433)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:186)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:147)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:270)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:100)
	at org.apache.hadoop.hbase.mapreduce.RowCounter.createSubmittableJob(RowCounter.java:146)
	at org.apache.hadoop.hbase.mapreduce.RowCounter.main(RowCounter.java:184)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13867541" author="stack" created="Fri, 10 Jan 2014 06:04:04 +0000"  >&lt;p&gt;My 2. above is &apos;crazy&apos; but actually way more than is actually needed.  2. only needs to have hbase-protocol on the MR client CLASSPATH, where the job is being launched from, and not under hadoop/lib on all hosts on the cluster (thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tucu00&quot; class=&quot;user-hover&quot; rel=&quot;tucu00&quot;&gt;Alejandro Abdelnur&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; for correcting my misunderstanding).   One of the lads here has confirmed that something like the below &apos;works&apos; for MRv1 and MRv2:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ export HADOOP_CLASSPATH=/usr/lib/hbase/lib/hbase-protocol-0.96.1.1-*-*-*.jar
$ ./bin/hadoop jar FATJOBJARWITHHBASE.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ export HADOOP_CLASSPATH=&lt;span class=&quot;code-quote&quot;&gt;&quot;./hbase/hbase-protocol/target/hbase-protocol-0.99.0-SNAPSHOT.jar&quot;&lt;/span&gt;
$ ./hadoop-2.2.0/bin/hadoop --config /home/stack/conf_hadoop/ jar ./hbase/hbase-assembly/target/hbase-0.99.0-SNAPSHOT-job.jar  org.apache.hadoop.hbase.mapreduce.RowCounter usertable
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I tried it locally.  It for sure gets over the MR client IllegalAccessError hurdle but I can&apos;t confirm the rowcounter mapreduce job actually runs to completion because I can&apos;t get a hadoop-2.2.0 yarn to work for me after spending a few hours on it.  I&apos;m giving up on it for the night.&lt;/p&gt;

&lt;p&gt;I could doc how to fix the exception with the above.  This would remove this issue as blocker.&lt;/p&gt;

&lt;p&gt;This &apos;fix&apos; is actually a &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; suggestion from sometime yesterday morning.&lt;/p&gt;

</comment>
                            <comment id="13867547" author="hadoopqa" created="Fri, 10 Jan 2014 06:22:31 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622298/hbase-10304_not_tested.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622298/hbase-10304_not_tested.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12622298&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8383//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13867551" author="ndimiduk" created="Fri, 10 Jan 2014 06:25:52 +0000"  >&lt;p&gt;Sounds like the recommended approach can be &lt;tt&gt;HADOOP_CLASSPATH=$(hbase mapredcp)&lt;/tt&gt;. That ensures everything we deem necessary is made available to the appropriate classloader.&lt;/p&gt;

&lt;p&gt;In the future, maybe we deprecate the fat jar? It should not be necessary given the add*DependencyJars magic in TableMapReduceUtil. Making those methods generally useful was the goal of the &lt;tt&gt;`hbase mapredcp`&lt;/tt&gt; command.&lt;/p&gt;

&lt;p&gt;The esteemed Mr. Holmes &lt;a href=&quot;http://grepalex.com/2013/02/25/hadoop-libjars/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;recommends&lt;/a&gt; people use &lt;tt&gt;-libjars&lt;/tt&gt; anyway.&lt;/p&gt;

&lt;p&gt;I think something like below should be the &quot;standard&quot; way to launch an HBase job. Java developers are used to thinking about the classpath, so I don&apos;t think it&apos;s a burden on anyone.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=$(hbase mapredcp) hadoop jar foo.jar MainClass
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or perhaps, if you&apos;re fancy&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=/path/to/hbase_config:$(hbase mapredcp) hadoop jar foo.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above command make it explicitly clear what extra classpath entries are provided to Hadoop.&lt;/p&gt;</comment>
                            <comment id="13867594" author="enis" created="Fri, 10 Jan 2014 07:40:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;no luck. Slightly different version of same issue &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeah, it seems that Packages (as in package access) are scoped per ClassLoader per &lt;a href=&quot;http://osdir.com/ml/windows.devel.java.advanced/2004-05/msg00039.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://osdir.com/ml/windows.devel.java.advanced/2004-05/msg00039.html&lt;/a&gt;. TIL. &lt;/p&gt;</comment>
                            <comment id="13867968" author="stack" created="Fri, 10 Jan 2014 16:38:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; That pointer helps.&lt;/p&gt;</comment>
                            <comment id="13868061" author="apurtell" created="Fri, 10 Jan 2014 18:10:44 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think something like below should be the &quot;standard&quot; way to launch an HBase job. Java developers are used to thinking about the classpath, so I don&apos;t think it&apos;s a burden on anyone.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=$(hbase mapredcp) hadoop jar foo.jar MainClass
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or perhaps, if you&apos;re fancy&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=/path/to/hbase_config:$(hbase mapredcp) hadoop jar foo.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;

&lt;p&gt;So can we get away with a doc change / manual update as the fix for this issue?&lt;/p&gt;</comment>
                            <comment id="13868095" author="jxiang" created="Fri, 10 Jan 2014 18:33:42 +0000"  >&lt;p&gt;I have verified the two workarounds to work fine.  With the fat hbase jobjar, I can run row counter and get correct results.&lt;/p&gt;

&lt;p&gt;1. run the job like&lt;/p&gt;

&lt;p&gt;HADOOP_CLASSPATH=/path/to/hbase_config:/path/to/hbase-protocol.jar hadoop jar fat-hbase-job.jar&lt;/p&gt;

&lt;p&gt;2. put the hbase-protocol jar under hadoop/lib so that MR can pick it up, and run the job as before&lt;/p&gt;

&lt;p&gt;+1 on doc change as the fix for this issue.&lt;/p&gt;


</comment>
                            <comment id="13868114" author="stack" created="Fri, 10 Jan 2014 18:48:50 +0000"  >&lt;p&gt;Agree with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I could have a go at it, np, but &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;, you have an opinion on where we should be going that I like (&quot;Deprecate fat job jar....&quot;) and you are a better writer... do you want to do up a doc patch?&lt;/p&gt;</comment>
                            <comment id="13868348" author="ndimiduk" created="Fri, 10 Jan 2014 21:46:54 +0000"  >&lt;p&gt;Sure, I can write something up. I suppose there&apos;s no need to deprecate the &quot;fat jar&quot; approach so long as the docs are clear.&lt;/p&gt;</comment>
                            <comment id="13868362" author="ndimiduk" created="Fri, 10 Jan 2014 21:55:41 +0000"  >&lt;p&gt;Here&apos;s some copy we can use. Where in the book would you want something like this to live? I also suggest the package-info be updated as well.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Problem&quot;&gt;&lt;/a&gt;Problem&lt;/h3&gt;
&lt;p&gt;Mapreduce jobs submitted to the cluster via a &quot;fat jar,&quot; that is, a jar containing a &apos;lib&apos; directory with their runtime dependencies, fail to launch. The symptom is an exception similar to the following:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; java.lang.IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:792)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.toScan(ProtobufUtil.java:818)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(TableMapReduceUtil.java:433)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:186)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:147)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:270)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:100)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is because of an optimization introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9867&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-9867&lt;/a&gt; that inadvertently introduced a classloader dependency.&lt;/p&gt;

&lt;p&gt;Jobs submitted using a regular jar and specifying their runtime dependencies using the -libjars parameter are not affected by this regression. More details about using the -libjars parameter are available in this &lt;a href=&quot;http://grepalex.com/2013/02/25/hadoop-libjars/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;blog post&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Solution&quot;&gt;&lt;/a&gt;Solution&lt;/h3&gt;
&lt;p&gt;In order to satisfy the new classloader requirements, hbase-protocol.jar must be included in Hadoop&apos;s classpath. This can be resolved system-wide by including a reference to the hbase-protocol.jar in hadoop&apos;s lib directory, via a symlink or by copying the jar into the new location.&lt;/p&gt;

&lt;p&gt;This can also be achieved on a per-job launch basis by specifying a value for &lt;tt&gt;HADOOP_CLASSPATH&lt;/tt&gt; at job submission time. All three of the following job launching commands satisfy this requirement:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=/path/to/hbase-protocol.jar hadoop jar MyJob.jar MyJobMainClass
$ HADOOP_CLASSPATH=$(hbase mapredcp) hadoop jar MyJob.jar MyJobMainClass
$ HADOOP_CLASSPATH=$(hbase classpath) hadoop jar MyJob.jar MyJobMainClass
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h3&gt;&lt;a name=&quot;ApacheReferenceJIRA&quot;&gt;&lt;/a&gt;Apache Reference JIRA&lt;/h3&gt;
&lt;p&gt;See also &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10304&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-10304&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13868472" author="jxiang" created="Fri, 10 Jan 2014 23:41:16 +0000"  >&lt;p&gt;I tried with -libjars, and it gave me the same problem. So it is not working for me.&lt;/p&gt;

&lt;p&gt;I also tried the three suggestions. The first two of them need some tweaking, while the third one work as-is.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;$ HADOOP_CLASSPATH=/path/to/hbase-protocol.jar hadoop jar MyJob.jar MyJobMainClass&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I got this:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14/01/10 15:31:05 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:708)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Basically, I can&apos;t connect to the ZK.  I have to add the hbase conf dir as below:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=/path/to/hbase-protocol.jar:/path/to/hbase-conf hadoop jar MyJob.jar MyJobMainClass
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;&lt;p&gt;$ HADOOP_CLASSPATH=$(hbase mapredcp) hadoop jar MyJob.jar MyJobMainClass&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Same as above. I need to add hbase conf dir to the path:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=$(hbase mapredcp):/path/to/hbase-conf hadoop jar MyJob.jar MyJobMainClass
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;blockquote&gt;&lt;p&gt;$ HADOOP_CLASSPATH=$(hbase classpath) hadoop jar MyJob.jar MyJobMainClass&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Works for me.&lt;/p&gt;</comment>
                            <comment id="13869753" author="ndimiduk" created="Mon, 13 Jan 2014 17:55:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; the only thing you needed to tweak for the first two variations was explicit inclusion of the hbase-config in $HADOOP_CLASSPATH ? Where else would the hadoop invocation pick up hbase-site.xml? Adding hbase-config in this invocation method has always been required, right?&lt;/p&gt;

&lt;p&gt;What about launching the job using our bin/hbase script? Do you see the same IllegalAccessError when launching the fat jar that way?&lt;/p&gt;</comment>
                            <comment id="13869835" author="jxiang" created="Mon, 13 Jan 2014 19:02:01 +0000"  >&lt;p&gt;Makes sense. bin/hbase script doesn&apos;t accept command jar. It may need some tweak to work.&lt;/p&gt;</comment>
                            <comment id="13869964" author="ndimiduk" created="Mon, 13 Jan 2014 20:50:13 +0000"  >&lt;p&gt;No jar command required. I&apos;m thinking:&lt;/p&gt;

&lt;p&gt;HBASE_CLASSPATH=/path/to/my/myjob-fat.jar bin/hbase MyJobMainClass&lt;/p&gt;

&lt;p&gt;I&apos;m getting my rig setup over here so I can repro and experiment a little more constructively. More to follow.&lt;/p&gt;</comment>
                            <comment id="13870164" author="ndimiduk" created="Tue, 14 Jan 2014 00:16:55 +0000"  >&lt;p&gt;Hmm. Even this version isn&apos;t working for me, same attempting to hit zookeeper on localhost.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=$(hbase classpath) hadoop jar MyJob.jar MyJobMainClass
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So basically, none of my proposed solutions work with my sample application &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; There&apos;s two different issues though: one being the topic of this ticket, the other being locating hbase-site.xml.&lt;/p&gt;</comment>
                            <comment id="13870209" author="ndimiduk" created="Tue, 14 Jan 2014 00:55:42 +0000"  >&lt;p&gt;hbase-site.xml issue was in my application.&lt;/p&gt;

&lt;p&gt;I have confirmed reproduced this bug on a 5-node Hadoop 2 cluster.&lt;/p&gt;

&lt;p&gt;The following invocations trigger the bug, as reported:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ hadoop jar MyApp-job.jar ...
$ HADOOP_CLASSPATH=/etc/hbase/conf hadoop jar MyApp-job.jar ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following invocations all result in running applications, both local applications and MRv2 jobs:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ HADOOP_CLASSPATH=/path/to/hbase-protocol.jar:/etc/hbase/conf hadoop jar MyApp-job.jar ...
$ HADOOP_CLASSPATH=$(hbase mapredcp):/etc/hbase/conf hadoop jar MyApp-job.jar ...
$ HADOOP_CLASSPATH=$(hbase classpath) hadoop jar MyApp-job.jar ...
$ HADOOP_CLASSPATH=$(hbase mapredcp):/etc/hbase/conf hadoop jar MyApp.jar MyJobMainClass -libjars $(hbase mapredcp | tr &apos;:&apos; &apos;,&apos;) ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Notice the last version that makes uses of the -libjars feature with a jar containing only application code.&lt;/p&gt;</comment>
                            <comment id="13870234" author="ndimiduk" created="Tue, 14 Jan 2014 01:12:52 +0000"  >&lt;p&gt;Here&apos;s my reference application.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ndimiduk/hbase-fatjar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/ndimiduk/hbase-fatjar&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13870243" author="ndimiduk" created="Tue, 14 Jan 2014 01:14:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; mind comparing notes, see if the above works for you and see if you hit any edge cases I didn&apos;t? Then I&apos;ll update the statement above and provide a doc patch.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13870260" author="jxiang" created="Tue, 14 Jan 2014 01:27:38 +0000"  >&lt;p&gt;Yes, the four invocations all work for me. Thanks.&lt;/p&gt;</comment>
                            <comment id="13870269" author="jxiang" created="Tue, 14 Jan 2014 01:31:42 +0000"  >&lt;p&gt;I tried to put hbase-site.xml in the fat jar top level, it also works if I don&apos;t specify the conf dir in HADOOP_CLASSPATH.&lt;/p&gt;</comment>
                            <comment id="13871260" author="ndimiduk" created="Tue, 14 Jan 2014 22:03:50 +0000"  >&lt;p&gt;Here&apos;s an update for the book. Let me know what you think.&lt;/p&gt;</comment>
                            <comment id="13871303" author="jxiang" created="Tue, 14 Jan 2014 22:37:44 +0000"  >&lt;p&gt;The content looks good to me.&lt;/p&gt;</comment>
                            <comment id="13871307" author="stack" created="Tue, 14 Jan 2014 22:40:44 +0000"  >&lt;p&gt;Nice work in here lads (Jimmy and Nick).   +1 on the quality doc.&lt;/p&gt;</comment>
                            <comment id="13871391" author="ndimiduk" created="Tue, 14 Jan 2014 23:49:16 +0000"  >&lt;p&gt;Good deal. I&apos;ll commit after the site build on QABot passes.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; should I also try my hand at updating the site? I see you&apos;ve documented it very nicely...&lt;/p&gt;</comment>
                            <comment id="13871393" author="apurtell" created="Tue, 14 Jan 2014 23:50:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;Good deal. I&apos;ll commit after the site build on QABot passes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Isn&apos;t HadoopQA always failing the site builds? &lt;/p&gt;</comment>
                            <comment id="13871396" author="stack" created="Tue, 14 Jan 2014 23:54:41 +0000"  >&lt;p&gt;Yeah.  I think Enis filed an issue on why.  Would just do an xmllint on the file after your patch goes in Nick.  If it works, apply.  If you were up for deploying the site, that&apos;d be sweet.  Ping if you need any pointers or you run into blocks.&lt;/p&gt;</comment>
                            <comment id="13871464" author="hadoopqa" created="Wed, 15 Jan 2014 01:03:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622998/HBASE-10304.docbook.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622998/HBASE-10304.docbook.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12622998&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(TableMapReduceUtil.java:433)&lt;br/&gt;
+    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:186)&lt;br/&gt;
+    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:147)&lt;br/&gt;
+    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:270)&lt;br/&gt;
+    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:100)&lt;br/&gt;
+$ HADOOP_CLASSPATH=/path/to/hbase-protocol.jar:/path/to/hbase/conf hadoop jar MyJob.jar MyJobMainClass&lt;br/&gt;
+$ HADOOP_CLASSPATH=$(hbase mapredcp):/etc/hbase/conf hadoop jar MyApp.jar MyJobMainClass -libjars $(hbase mapredcp | tr &apos;:&apos; &apos;,&apos;) ...&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8427//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13872532" author="hudson" created="Wed, 15 Jan 2014 20:08:49 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.98 #84 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.98/84/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.98/84/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10304&quot; title=&quot;Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10304&quot;&gt;&lt;del&gt;HBASE-10304&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;docbook update&amp;#93;&lt;/span&gt; Running an hbase job jar: IllegalAccessError (ndimiduk: rev 1558497)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.98/src/main/docbkx/book.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872543" author="hudson" created="Wed, 15 Jan 2014 20:16:52 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4822 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4822/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4822/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10304&quot; title=&quot;Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10304&quot;&gt;&lt;del&gt;HBASE-10304&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;docbook update&amp;#93;&lt;/span&gt; Running an hbase job jar: IllegalAccessError (ndimiduk: rev 1558490)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/docbkx/book.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872748" author="hudson" created="Wed, 15 Jan 2014 22:59:19 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.98-on-Hadoop-1.1 #77 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/77/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/77/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10304&quot; title=&quot;Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10304&quot;&gt;&lt;del&gt;HBASE-10304&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;docbook update&amp;#93;&lt;/span&gt; Running an hbase job jar: IllegalAccessError (ndimiduk: rev 1558497)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.98/src/main/docbkx/book.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872929" author="hudson" created="Thu, 16 Jan 2014 01:35:19 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-1.1 #54 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-1.1/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-1.1/54/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10304&quot; title=&quot;Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10304&quot;&gt;&lt;del&gt;HBASE-10304&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;docbook update&amp;#93;&lt;/span&gt; Running an hbase job jar: IllegalAccessError (ndimiduk: rev 1558490)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/main/docbkx/book.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14184254" author="ariforu" created="Sat, 25 Oct 2014 20:22:44 +0000"  >&lt;p&gt;What is the workaround for running such application through Oozie? Setting HADOOP_CLASSPATH in Java and MapReduce actions are not possible. There seems to be no provision to do that. &lt;/p&gt;</comment>
                            <comment id="14184290" author="ndimiduk" created="Sat, 25 Oct 2014 21:45:46 +0000"  >&lt;p&gt;This was resolved via &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11118&quot; title=&quot;non environment variable solution for &amp;quot;IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11118&quot;&gt;&lt;del&gt;HBASE-11118&lt;/del&gt;&lt;/a&gt;. Please see my comment at the end of that ticket.&lt;/p&gt;</comment>
                            <comment id="14330806" author="enis" created="Sat, 21 Feb 2015 23:31:18 +0000"  >&lt;p&gt;Closing this issue after 0.99.0 release. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12728752">HIVE-7467</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12712613">HBASE-11118</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12622998" name="HBASE-10304.docbook.patch" size="4195" author="ndimiduk" created="Tue, 14 Jan 2014 22:03:50 +0000"/>
                            <attachment id="12622298" name="hbase-10304_not_tested.patch" size="787" author="enis" created="Fri, 10 Jan 2014 00:09:17 +0000"/>
                            <attachment id="12622236" name="jobjar.xml" size="2742" author="stack" created="Thu, 9 Jan 2014 19:19:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 9 Jan 2014 05:07:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367004</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 42 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1r9ev:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367314</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>My local site run generates the docbook correctly, looks good to me on both branches. I&amp;#39;ve committed this to 0.98 and trunk.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>