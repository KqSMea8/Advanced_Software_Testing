<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:06:12 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9635/HBASE-9635.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9635] HBase Table regions are not getting re-assigned to the new region server when it comes up (when the existing region server not able to handle the load) </title>
                <link>https://issues.apache.org/jira/browse/HBASE-9635</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;HBase Table regions are not getting assigned to the new region server for a period of 30 minutes (when the existing region server not able to handle the load)


Procedure:
1. Setup Non HA Hadoop Cluster with two nodes (Node1-XX.XX.XX.XX,  Node2-YY.YY.YY.YY)
2. Install Zookeeper &amp;amp; HRegionServer in Node-1
3. Install HMaster &amp;amp; HRegionServer in Node-2
4. From Node2 create HBase Table ( table name &apos;t1&apos; with one column family &apos;cf1&apos; )
5. Perform addrecord 99649 rows 
6. kill both the node Region Server and limit the Node1 Region Server FD to 600
7. Start only the Node1 Region server ==&amp;gt; so that FD exhaust can happen in Node1 Region Server
8. After some 5-10 minuites start the Node2 Region Server

===&amp;gt; Huge number of regions of table &apos;t1&apos; are in OPENING state, which are not getting re assigned to the Node2 region server which is free. 

===&amp;gt; When the new region server comes up then the master should detect and allocate the open failed regions to the region server (here it is staying the OPENINING state for 30 minutes which will have huge impcat user app which makes use of this table)



2013-09-23 18:46:12,160 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated t1,row507465,1379937224590.2d9fad2aee78103f928d8c7fe16ba6cd.
2013-09-23 18:46:12,160 ERROR org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Failed open of region=t1,row507465,1379937224590.2d9fad2aee78103f928d8c7fe16ba6cd., starting to roll back the global memstore size.

2013-09-23 18:50:55,284 WARN org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_hb_rs_HOST-XX.XX.XX.XX,61020,1379940823286_-641204614_48] for 309 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Too many open files; Host Details : local host is: &quot;HOST-XX.XX.XX.XX/XX.XX.XX.XX&quot;; destination host is: &quot;HOST-XX.XX.XX.XX&quot;:8020;
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
        at org.apache.hadoop.ipc.Client.call(Client.java:1351)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.renewLease(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.renewLease(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:522)
        at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:679)
        at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
        at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
        at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
        at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.SocketException: Too many open files
        at sun.nio.ch.Net.socket0(Native Method)
        at sun.nio.ch.Net.socket(Net.java:97)
        at sun.nio.ch.SocketChannelImpl.&amp;lt;init&amp;gt;(SocketChannelImpl.java:84)
        at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:37)
        at java.nio.channels.SocketChannel.open(SocketChannel.java:105)
        at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62)
        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:523)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:642)
        at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)
        at org.apache.hadoop.ipc.Client.call(Client.java:1318)
        ... 16 more
2013-09-23 18:50:56,285 WARN org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_hb_rs_HOST-XX.XX.XX.XX,61020,1379940823286_-641204614_48] for 310 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Too many open files; Host Details : local host is: &quot;HOST-XX.XX.XX.XX/XX.XX.XX.XX&quot;; destination host is: &quot;HOST-XX.XX.XX.XX&quot;:8020;
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
        at org.apache.hadoop.ipc.Client.call(Client.java:1351)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
       at $Proxy13.renewLease(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.renewLease(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:522)
        at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:679)
        at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
        at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
        at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
        at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.SocketException: Too many open files
        at sun.nio.ch.Net.socket0(Native Method)
        at sun.nio.ch.Net.socket(Net.java:97)
        at sun.nio.ch.SocketChannelImpl.&amp;lt;init&amp;gt;(SocketChannelImpl.java:84)
        at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:37)
        at java.nio.channels.SocketChannel.open(SocketChannel.java:105)
        at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62)
        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:523)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:642)
        at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)
        at org.apache.hadoop.ipc.Client.call(Client.java:1318)
        ... 16 more
2013-09-23 18:50:57,287 WARN org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_hb_rs_HOST-XX.XX.XX.XX,61020,1379940823286_-641204614_48] for 311 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Too many open files; Host Details : local host is: &quot;HOST-XX.XX.XX.XX/XX.XX.XX.XX&quot;; destination host is: &quot;HOST-XX.XX.XX.XX&quot;:8020;







&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;SuSE11&lt;/p&gt;</environment>
        <key id="12670059">HBASE-9635</key>
            <summary>HBase Table regions are not getting re-assigned to the new region server when it comes up (when the existing region server not able to handle the load) </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="shankarlingayya">shankarlingayya</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Sep 2013 13:51:28 +0000</created>
                <updated>Tue, 8 Oct 2013 07:19:52 +0000</updated>
                                            <version>0.94.11</version>
                                                    <component>master</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13774774" author="sershe" created="Mon, 23 Sep 2013 17:48:02 +0000"  >&lt;p&gt;LoadBalancer should eventually handle that. See &lt;a href=&quot;http://hbase.apache.org/book.html#master.processes.loadbalancer&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/book.html#master.processes.loadbalancer&lt;/a&gt;&lt;br/&gt;
How do you have the balancer period configured?&lt;/p&gt;</comment>
                            <comment id="13774803" author="jdcryans" created="Mon, 23 Sep 2013 18:08:55 +0000"  >&lt;p&gt;The problem is pretty clear from the log: &quot;Too many open files&quot;, your host is hosed.&lt;/p&gt;</comment>
                            <comment id="13775959" author="shankarlingayya" created="Tue, 24 Sep 2013 03:31:53 +0000"  >&lt;p&gt;RegionServer1 side file descriptors got exhausted, but the RegionServer2 has enough file descriptors, now the RegionServer1 needs to communicate with HMaster to re-assign the open failed regions to the New RegionServer2, which is not happening in the above problem.&lt;/p&gt;

&lt;p&gt;After some 30 minutes duration then it is getting re-assigned to the RegionServer2.&lt;/p&gt;</comment>
                            <comment id="13777229" author="apurtell" created="Wed, 25 Sep 2013 07:34:09 +0000"  >&lt;p&gt;Did you increase the number of file handles as discussed in the manual?&lt;/p&gt;

&lt;p&gt;On another issue you indicate your cluster has two nodes yet you have HDFS replication set to 3?&lt;/p&gt;

&lt;p&gt;You can&apos;t draw reasonable conclusions from degenerate configurations. Suggest you use at least 3 slaves and one additional node as master. And follow the configuration advice in the online HBase manual. &lt;/p&gt;</comment>
                            <comment id="13777233" author="apurtell" created="Wed, 25 Sep 2013 07:41:45 +0000"  >&lt;p&gt;And if you want to simulate failures, with replication 3 you&apos;ll want an additional slave beyond 3.&lt;/p&gt;</comment>
                            <comment id="13777278" author="shankarlingayya" created="Wed, 25 Sep 2013 08:40:57 +0000"  >&lt;p&gt;when the number of slaves are 2 or 3 then the open failed regions in RegionServer1 are getting re-assigned to other existing region servers(RegionServer2 or 3)&lt;/p&gt;

&lt;p&gt;In my case when open failed in RegionServer1 at that the RegionServer2 was not up, and after that  RegionServer2 came up successfully (means there is some time gap around 1-3 min between the open failure and the new RegionServer2 coming up)&lt;/p&gt;</comment>
                            <comment id="13789004" author="rajesh23" created="Tue, 8 Oct 2013 07:19:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shankarlingayya&quot; class=&quot;user-hover&quot; rel=&quot;shankarlingayya&quot;&gt;shankarlingayya&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In my case when open failed in RegionServer1 at that the RegionServer2 was not up, and after that RegionServer2 came up successfully (means there is some time gap around 1-3 min between the open failure and the new RegionServer2 coming up)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Before starting second region server, retries could have exhausted for all the region assignments. So waiting for timeout monitor to pick them to re-assign(after 30 mins). After starting new RS, you can run hbck tool to fix the assignments.&lt;br/&gt;
command : $HBASE_HOME/bin/hbase hbck -fixAssignments&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 23 Sep 2013 17:48:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>349889</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 10 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1obwf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>350187</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>