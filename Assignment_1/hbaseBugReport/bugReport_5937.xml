<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:32:19 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5937/HBASE-5937.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5937] Refactor HLog into an interface.</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5937</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;What the summary says. Create HLog interface. Make current implementation use it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12553865">HBASE-5937</key>
            <summary>Refactor HLog into an interface.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12549194">HBASE-5699</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fpj">Flavio Junqueira</assignee>
                                    <reporter username="li">Li Pi</reporter>
                        <labels>
                    </labels>
                <created>Fri, 4 May 2012 02:42:16 +0000</created>
                <updated>Tue, 15 Oct 2013 04:46:31 +0000</updated>
                            <resolved>Tue, 2 Oct 2012 19:31:10 +0000</resolved>
                                                    <fixVersion>0.95.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                <comments>
                            <comment id="13268056" author="zhihyu@ebaysf.com" created="Fri, 4 May 2012 02:51:51 +0000"  >&lt;p&gt;We should define clearer goals for the interface.&lt;br/&gt;
Is this mostly for multi-WAL support ?&lt;/p&gt;</comment>
                            <comment id="13268074" author="li" created="Fri, 4 May 2012 03:18:24 +0000"  >&lt;p&gt;Mostly. But you could use it for other things too.&lt;/p&gt;</comment>
                            <comment id="13400187" author="jmhsieh" created="Sun, 24 Jun 2012 17:49:12 +0000"  >&lt;p&gt;Ideally we&apos;d have this interface in place for some of these different hlog wal implementations.&lt;/p&gt;</comment>
                            <comment id="13428181" author="fpj" created="Fri, 3 Aug 2012 15:24:38 +0000"  >&lt;p&gt;Just to make sure, there is nothing done related this jira yet, yes?&lt;/p&gt;</comment>
                            <comment id="13428184" author="zhihyu@ebaysf.com" created="Fri, 3 Aug 2012 15:27:49 +0000"  >&lt;p&gt;Right.&lt;/p&gt;</comment>
                            <comment id="13434195" author="fpj" created="Tue, 14 Aug 2012 15:29:17 +0000"  >&lt;p&gt;I wanted to report the progress Ivan and I have made on this issue so far. We have a repository that we have been working on, just in case anyone is interested in giving comments on our changes so far:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/fpj/hbase&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/fpj/hbase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here are some issues we have come across and we have in our todo list:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Failing tests: There are a number of tests failing and we are still investigating the causes;&lt;/li&gt;
	&lt;li&gt;getReader/createWriter: We moved these methods to HLogUtil, but we can&apos;t agree on whether they should be part of the new HLog interface or not. The main issue is that getReader is called from a number of places where we have no HLog object available. In the case we make them part of the interface, we will need to find a way of making an HLog object available in those places.&lt;/li&gt;
	&lt;li&gt;HLogSplitter: It should be part of HLogFactory.&lt;/li&gt;
	&lt;li&gt;Protected methods of FSHLog: There are a number of calls in the tests to protected methods of FSHLog. We solved it so far by type-casting, but it doesn&apos;t look very clean and I&apos;m not very happy about that.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13434231" author="zhihyu@ebaysf.com" created="Tue, 14 Aug 2012 16:23:39 +0000"  >&lt;p&gt;@Li:&lt;br/&gt;
Can I assign this issue to Flavio ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13434247" author="zhihyu@ebaysf.com" created="Tue, 14 Aug 2012 16:39:21 +0000"  >&lt;p&gt;Thanks Flavio and Ivan for tackling this issue.&lt;/p&gt;

&lt;p&gt;w.r.t. reader / writer creation, we can leave them in HLogUtil for now. They don&apos;t belong to FSHLog or HLogFactory.&lt;/p&gt;

&lt;p&gt;For HLog interface, please add javadoc for each of its methods.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; Reader {
        void init(FileSystem fs, Path path, Configuration c) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If HLog.Reader is FileSystem backed, I would assume that HLog is backed by FileSystem as well.&lt;br/&gt;
Can we declare the first parameter as Object ?&lt;br/&gt;
FSHLog can declare FSReader which extends HLog.Reader that casts first parameter from init() as FileSystem.&lt;/p&gt;

&lt;p&gt;Please tell us which tests fail so that other people can help.&lt;/p&gt;</comment>
                            <comment id="13434504" author="zhihyu@ebaysf.com" created="Tue, 14 Aug 2012 21:02:15 +0000"  >&lt;p&gt;Here is partial list of failed tests:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  test2727(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed)
  testReplayEditsWrittenViaHRegion(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed)
  testReplayEditsAfterPartialFlush(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed): expected:&amp;lt;30&amp;gt; but was:&amp;lt;20&amp;gt;
  testReplayEditsWrittenIntoWAL(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed): Flushcount=0
  test2727(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay)
  testReplayEditsWrittenViaHRegion(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay)
  testReplayEditsAfterPartialFlush(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay): expected:&amp;lt;30&amp;gt; but was:&amp;lt;20&amp;gt;
  testReplayEditsWrittenIntoWAL(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay): Flushcount=0
  testCorrectnessWhenMasterFailOver(org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing)
...
Tests in error:
  queueFailover(org.apache.hadoop.hbase.replication.TestReplication): No server address listed in .META. &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region test,mmm,1344966925833.ca73ab045b69ab49cec353012f01fd35. containing row mmm
  testDrainingServerWithAbort(org.apache.hadoop.hbase.TestDrainingServer): test timed out after 30000 milliseconds
  testFlushCommitsWithAbort(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testFlushCommitsNoAbort(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testBatchWithPut(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testBatchWithDelete(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testHTableDeleteWithList(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testBatchWithManyColsInOneRowGetAndPut(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testBatchWithIncrementAndAppend(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  testBatchWithMixedActions(org.apache.hadoop.hbase.client.TestMultiParallel): multi_test_table
  test2772(org.apache.hadoop.hbase.client.TestScannerTimeout): Failed after attempts=10, exceptions:(..)
  test3686a(org.apache.hadoop.hbase.client.TestScannerTimeout): t
  test3686b(org.apache.hadoop.hbase.client.TestScannerTimeout): t
  testZKClosingNodeVersionMismatch(org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler): KeeperErrorCode = NodeExists &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase/unassigned/7f81d00867e4832617a414d6d970c8ab
  testCloseRegion(org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler): KeeperErrorCode = NodeExists &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase/unassigned/296e7298f90ab0bec536aba4b039fa84
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13437158" author="stack" created="Sat, 18 Aug 2012 00:00:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;In the case we make them part of the interface, we will need to find a way of making an HLog object available in those places.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If these are HLog reader and writers, yeah, should be in the HLog interface I&apos;d say rather than in an HLogUtil.  Can you factory it in places like HLogInputFormat?&lt;/p&gt;

&lt;p&gt;Why move HLog defines into HLogUtil?  They seem like core defines rather than util defines: e.g. HLog.SPLITTING_EXT.&lt;/p&gt;

&lt;p&gt;Yeah, this seems like a basic one that needs solving:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      reader = HLog.getReader(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.fs, edits, conf);
+      reader = HLogUtil.getReader(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.fs, edits, conf);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You&apos;ll need a &apos;wal&apos; object, one that has been appropriately created dependent on what WAL engine has been put in place.&lt;/p&gt;

&lt;p&gt;Can you not get HLogFactory.createHLog into the places where we have getReader now &amp;#8211; e.g. in HRegion (Should HRegion even be concerned w/ HLog/WAL?  Only RegionServer should be?)?&lt;/p&gt;

&lt;p&gt;Whats FSLog?  An HDFSLog?&lt;/p&gt;

&lt;p&gt;Should HLog Interface be instead named WAL?&lt;/p&gt;

&lt;p&gt;Is it right that the HLog Interface takes an fs?  That OK for you lads?  You&apos;ll be doing a bookkeeper FS?&lt;/p&gt;

&lt;p&gt;HLog Interface seems fat.  We need all those methods?&lt;/p&gt;

&lt;p&gt;Seems good so far?&lt;/p&gt;


</comment>
                            <comment id="13438734" author="ikelly" created="Tue, 21 Aug 2012 13:47:58 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Can you factory it in places like HLogInputFormat?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;HLogInputFormat among a few funny ones which I wasn&apos;t sure how to deal with (one of the others is the PrettyPrinter). The problem with these is that they take a individual log file, rather than a whole log instance. This makes it more complicated to use it with HLogFactory, as createHLog asks for the whole log directory. We could get the log directory by using Path.getParent(), but that seemed messy to me at the time. Otherwise, yes, the solution to HLogUtil.createReader -&amp;gt; HLog#createReader is to instantiate a HLog where needed. We just haven&apos;t gotten that far yet.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Whats FSLog? An HDFSLog?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Exactly. FileSystem doesn&apos;t necessarily have to be HDFS so FSLog is a better name.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Can you not get HLogFactory.createHLog into the places where we have getReader now &#8211; e.g. in HRegion (Should HRegion even be concerned w/ HLog/WAL? Only RegionServer should be?)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As I understand it now, HRegion only creates the HLog for the META and ROOT tables, which are managed from the Master and as such, do not have access to a RegionServer. Perhaps this could be refactored a little to make HRegion always receive a preconstructed HLog.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Should HLog Interface be instead named WAL?&lt;br/&gt;
Is it right that the HLog Interface takes an fs? That OK for you lads? You&apos;ll be doing a bookkeeper FS?&lt;br/&gt;
HLog Interface seems fat. We need all those methods?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current patch is a first cut to give you guys an idea of where we are, but it&apos;s quite far from what we imagine the final interface from looking like. At the moment, what we want to do is refactor all the HLog code so that everything that access HLog is going through well defined interfaces. Once that is done, we can look at the interfaces to see where the implementation specific stuff (like Path, Filesystem etc) is leaking out, and work to resolve them.&lt;/p&gt;

&lt;p&gt;I&apos;ll try and find time to get back to do some coding on this (i.e. fix tests, refactor createReader) this week.&lt;/p&gt;</comment>
                            <comment id="13438842" author="stack" created="Tue, 21 Aug 2012 16:44:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;The problem with these is that they take a individual log file, rather than a whole log instance.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can we change this boss and pass in an HLog or whatever instance?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We just haven&apos;t gotten that far yet.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;np&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;Perhaps this could be refactored a little to make HRegion always receive a preconstructed HLog.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.  The fact that HRegion is making HLog instances smells.&lt;/p&gt;

&lt;p&gt;And +1 on your approach.&lt;/p&gt;
</comment>
                            <comment id="13449640" author="fpj" created="Thu, 6 Sep 2012 13:28:54 +0000"  >&lt;p&gt;I have moved static finals to HLog as suggested. &lt;/p&gt;

&lt;p&gt;I have also looked at making getReader/getWriter part of HLog. I picked getReader and extracted the classes using calling it. For each class, I tried to determine if we can instantiate HLog or have already an instance of it. Here is a summary:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;HLogInputFormat: Not clear how to instantiate HLog&lt;/li&gt;
	&lt;li&gt;HLogPrettyPrinter: Executed through main calls in FSHLog and HLogPrettyPrinter, so maybe we could pass necessary parameters&lt;/li&gt;
	&lt;li&gt;HLogSplitter: Have all parameters&lt;/li&gt;
	&lt;li&gt;HRegion: Have HLog object&lt;/li&gt;
	&lt;li&gt;ReplicationSource: Not clear how to instantiate HLog&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I was also wondering if there are important side-effects in the case we use the factory to get an HLog object just to get a reader or a writer. I have looked into the main constructor of FSHLog and I haven&apos;t been able to convince myself that there is a way of executing it without throwing an exception unnecessarily or having side-effects. &lt;/p&gt;

&lt;p&gt;The errors and failures I&apos;m getting for tests now are:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Failed tests:   testRetrying(org.apache.hadoop.hbase.catalog.TestMetaReaderEditor): reader: count=2, t=null
  testExceptionFromCoprocessorDuringPut(org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort): The put should have failed, as the coprocessor is buggy
  testWALCoprocessorReplay(org.apache.hadoop.hbase.coprocessor.TestWALObserver)
  test2727(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay)
  testReplayEditsWrittenViaHRegion(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay)
  testReplayEditsAfterPartialFlush(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay): expected:&amp;lt;30&amp;gt; but was:&amp;lt;20&amp;gt;
  testReplayEditsWrittenIntoWAL(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay): Flushcount=0
  test2727(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed)
  testReplayEditsWrittenViaHRegion(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed)
  testReplayEditsAfterPartialFlush(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed): expected:&amp;lt;30&amp;gt; but was:&amp;lt;20&amp;gt;
  testReplayEditsWrittenIntoWAL(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed): Flushcount=0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;testZKClosingNodeVersionMismatch(org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler): KeeperErrorCode = NodeExists for /hbase/unassigned/67f6e4f3629fa0bb34fbd5cb604ff44e
  testCloseRegion(org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler): KeeperErrorCode = NodeExists for /hbase/unassigned/e2b47297b32db6a95e2a310be053172f
  testDataCorrectnessReplayingRecoveredEdits(org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster): Failed 1 action: ExecutionException: 1 time, 
  testReplayEditsAfterRegionMovedWithMultiCF(org.apache.hadoop.hbase.regionserver.wal.TestWALReplay): Failed after attempts=10, exceptions:(..)
  testReplayEditsAfterRegionMovedWithMultiCF(org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed): Failed after attempts=10, exceptions:(..)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; </comment>
                            <comment id="13451098" author="fpj" created="Fri, 7 Sep 2012 22:46:39 +0000"  >&lt;p&gt;I&apos;ve been looking at TestMultiParallel because and I&apos;m getting this exception:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2012-09-07 19:38:31,560 WARN  [Thread-371] client.HConnectionManager$HConnectionImplementation(1020): Encountered problems when prefetch META table:
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in .META. for table: multi_test_table, row=multi_test_table,\x00,99999999999999
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:166)
        at org.apache.hadoop.hbase.client.MetaScanner.access$000(MetaScanner.java:56)
        at org.apache.hadoop.hbase.client.MetaScanner$1.connect(MetaScanner.java:135)
        at org.apache.hadoop.hbase.client.MetaScanner$1.connect(MetaScanner.java:132)
        at org.apache.hadoop.hbase.client.HConnectionManager.execute(HConnectionManager.java:394)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:132)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:107)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1017)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1071)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:959)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:916)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$Process.submit(HConnectionManager.java:1917)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$Process.doRetry(HConnectionManager.java:1957)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$Process.processBatchCallback(HConnectionManager.java:2064)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$Process.access$900(HConnectionManager.java:1859)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1848)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1827)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1003)
        at org.apache.hadoop.hbase.client.TestMultiParallel.doTestFlushCommits(TestMultiParallel.java:246)
        at org.apache.hadoop.hbase.client.TestMultiParallel.testFlushCommitsWithAbort(TestMultiParallel.java:213)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m not sure why the table is not present, and by skimming through the logs I couldn&apos;t find any hint. If anyone has a hint, I&apos;d be happy to hear, otherwise I&apos;ll keep looking. I can also post the log if anyone is interested.&lt;/p&gt;</comment>
                            <comment id="13451103" author="stack" created="Fri, 7 Sep 2012 22:50:50 +0000"  >&lt;p&gt;Post log Flavio.&lt;/p&gt;</comment>
                            <comment id="13451138" author="fpj" created="Fri, 7 Sep 2012 23:40:43 +0000"  >&lt;p&gt;Attached...&lt;/p&gt;</comment>
                            <comment id="13459755" author="fpj" created="Thu, 20 Sep 2012 17:17:24 +0000"  >&lt;p&gt;I&apos;ve been able to fix a few bugs, and I&apos;m getting fewer failures/errors now:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Failed tests:   testExceptionFromCoprocessorDuringPut(org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort): The put should have failed, as the coprocessor is buggy

Tests in error: 
  testZKClosingNodeVersionMismatch(org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler): KeeperErrorCode = NodeExists for /hbase/unassigned/740ffc6356202cd16e98dbe3ddf302cd
  testCloseRegion(org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler): KeeperErrorCode = NodeExists for /hbase/unassigned/98327c03377cb4f0bf4a366bff09e68c
  testLocalHBaseCluster(org.apache.hadoop.hbase.TestLocalHBaseCluster): Master not initialized after 200 seconds
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ll check those more closely. I was wondering of anyone has more thoughts on the getReader/getWriter point I asked above. Thanks!&lt;/p&gt;</comment>
                            <comment id="13460232" author="stack" created="Fri, 21 Sep 2012 05:38:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;Flavio Junqueira&lt;/a&gt; Sorry for not getting to your log.  What have you been having to do to get tests to pass?  How did you fix TestMultiParallel? It is stuff to do w/ this refactoring?&lt;/p&gt;

&lt;p&gt;On your question....&lt;blockquote&gt;&lt;p&gt;I have also looked at making getReader/getWriter part of HLog&lt;/p&gt;&lt;/blockquote&gt;&lt;/p&gt;

&lt;p&gt;What are you thinking?  Currently Reader and Writer are Interfaces defined inside HLog.  You get one by calling a static method on HLog.  You&apos;d like to getReader non-static, an invocation on a particular instance of HLog.&lt;/p&gt;

&lt;p&gt;That seems fine by me. It makes sense given what you are trying to do. It is less flexible than what we currently have but its flexible because it presumes a particular implementation of HLog.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;HLogInputFormat: Not clear how to instantiate HLog&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is a facility little used if ever.  I&apos;m surprised it not used more often.  Its a repair facility.  You&apos;d use it when you started a cluster somehow w/o replaying WALs.  You could use this class in a mapreduce job to quickly add the edits from WAL back up into the cluster.&lt;/p&gt;

&lt;p&gt;I took a look.  What are you thinking constructors will look like for HLogs?  There&apos;ll be a factory?  What will the factory take for arguments?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;HLogPrettyPrinter: Executed through main calls in FSHLog and HLogPrettyPrinter, so maybe we could pass necessary parameters&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is a tool for humans to look at contents of HLogs.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;HLogSplitter: Have all parameters&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is the important one (smile)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;HRegion: Have HLog object&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good... Its passed the HLog, right?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;ReplicationSource: Not clear how to instantiate HLog&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You know what this is about, right?  This is how we do replication.  We tail the WALs and as the edits come in, we send them off to other clusters.  We&apos;ll need to be able to tail logs.  Could we pass Replication an HLog instance?&lt;/p&gt;

&lt;p&gt;I hope you call your HLog Inteface WAL!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I was also wondering if there are important side-effects in the case we use the factory to get an HLog object just to get a reader or a writer&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&apos;d have to change the current HLog constructor.  It does a bunch of work when created &amp;#8211; sets a sync&apos;ing thread running (this syncing thread though is in need of some cleanup), creates dirs and sets up first WAL.  We wouldn&apos;t want it doing this stuff if we wanted the instance just to do getReader/getWriter on it.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;I have looked into the main constructor of FSHLog and I haven&apos;t been able to convince myself that there is a way of executing it without throwing an exception unnecessarily or having side-effects.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As it is currently written, yes.&lt;/p&gt;

&lt;p&gt;I think this work trying to make an Interface for WAL is kinda important.  There is this bookeeping project but the multi-WAL dev &amp;#8211; i.e. making the regionserver write more than one WAL at a time (into HDFS) &amp;#8211; could use the result of this effort too.&lt;/p&gt;

&lt;p&gt;Thanks Flavio.&lt;/p&gt;
</comment>
                            <comment id="13460592" author="fpj" created="Fri, 21 Sep 2012 16:19:10 +0000"  >&lt;p&gt;Thanks for responding, Stack.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Sorry for not getting to your log. What have you been having to do to get tests to pass? How did you fix TestMultiParallel? It is stuff to do w/ this refactoring?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It was our bug.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Currently Reader and Writer are Interfaces defined inside HLog. You get one by calling a static method on HLog. You&apos;d like to getReader non-static, an invocation on a particular instance of HLog.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;That seems fine by me. It makes sense given what you are trying to do. It is less flexible than what we currently have but its flexible because it presumes a particular implementation of HLog.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is simpler to leave getReader and getWriter as static methods. Given that a reader/writer is for a concrete WAL, Ivan and I thought that it would be best to have these methods available as instance methods. However, it is not looking simple to implement because we don&apos;t have HLog objects available in all places we need a reader or a writer, and the initialization of HLog objects makes it tricky to instantiate it only to get a reader or a writer. At this point, I&apos;m tempted to leave them as static methods for now, unless anyone has a strong preference otherwise.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I hope you call your HLog Inteface WAL!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is fine with me to make the change.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think this work trying to make an Interface for WAL is kinda important. There is this bookeeping project but the multi-WAL dev &#8211; i.e. making the regionserver write more than one WAL at a time (into HDFS) &#8211; could use the result of this effort too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;BookKeeper provides the ability to write multiple concurrent logs, but if the regionserver code is not prepared, then we won&apos;t be able to benefit from this feature. Consequently, it does sound very important to have the regionserver writing to more than one WAL at a time.&lt;/p&gt;

&lt;p&gt;Currently there is one test failing consistently for me:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hbase.TestLocalHBaseCluster
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and I believe the culprit is this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;WARNING! File system needs to be upgraded.  You have version null and I want version 7.  Run the &apos;${HBASE_HOME}/bin/hbase migrate&apos; script.
2012-09-21 17:27:06,075 FATAL [Master:0;perfectsalt-lm.barcelona.corp.yahoo.com,52906,1348241225714] master.HMaster(1838): Unhandled exception. Starting shutdown.
org.apache.hadoop.hbase.util.FileSystemVersionException: File system needs to be upgraded.  You have version null and I want version 7.  Run the &apos;${HBASE_HOME}/bin/hbase migrate&apos; script.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Any clue of why this could be happening?&lt;/p&gt;</comment>
                            <comment id="13460631" author="stack" created="Fri, 21 Sep 2012 17:20:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;Any clue of why this could be happening?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Somehow the test is pointed at wrong fs?  Did you mess w/ that?  HBase, when it starts, it looks for a file named hbase.version.  If present, it reads it to see that the version therein matches that of version the hbase software expects.  We used this facility whenever on-fs formats changed in a way that required you to run a migration step before starting cluster.&lt;/p&gt;

&lt;p&gt;So, version == null makes me think hbase is looking in wrong place for the hbase.version file... looking in localfs rather than in hdf where it perhaps wrote it on startup?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...and the initialization of HLog objects makes it tricky to instantiate it only to get a reader or a writer&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;HLog construction is the way it is again because we presume one implementation only.  I&apos;d suggest you look at what it would take moving the heavyweight stuff done in HLog to an init or start method.  NP having us change how we do the HLog setup in HBase.  Perhaps it won&apos;t help much though as the Reader and Writer might want some of the heavy setup done?&lt;/p&gt;

&lt;p&gt;I&apos;d also say that HLog is the way it is, not because it was designed, but because it evolved this way over the years.  If you fellas want to startover, I&apos;d say go for it: make a clean Interface that will work for our current hdfs use case and for the bkfs.  We&apos;ll shoehorn it into a 0.98 or whatever suits your schedule.&lt;/p&gt;</comment>
                            <comment id="13465522" author="fpj" created="Fri, 28 Sep 2012 11:16:00 +0000"  >&lt;p&gt;Attaching a preliminary patch for this issue. The patch is a bit long, but mostly trivial changes.&lt;/p&gt;

&lt;p&gt;I haven&apos;t renamed HLog to WAL as I had agreed to do because there are a number of classes that use HLog as a prefix (e.g., HLogKey) or sufix (e.g., FSHLog). I was not able to convince myself that it would be a good idea to replace all occurrences of HLog with WAL, but perhaps that&apos;s the right thing to do. &lt;/p&gt;</comment>
                            <comment id="13465599" author="hadoopqa" created="Fri, 28 Sep 2012 13:43:20 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12546979/HBASE-5937.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12546979/HBASE-5937.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 69 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2958//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2958//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13465654" author="fpj" created="Fri, 28 Sep 2012 15:06:53 +0000"  >&lt;p&gt;Patch doesn&apos;t apply cleanly, let me generate a new one.&lt;/p&gt;</comment>
                            <comment id="13465995" author="fpj" created="Fri, 28 Sep 2012 23:10:47 +0000"  >&lt;p&gt;Second attempt.&lt;/p&gt;</comment>
                            <comment id="13466032" author="hadoopqa" created="Sat, 29 Sep 2012 00:03:29 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12547074/HBASE-5937.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12547074/HBASE-5937.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 72 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 157 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2962//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13466067" author="yuzhihong@gmail.com" created="Sat, 29 Sep 2012 01:09:14 +0000"  >&lt;p&gt;Thanks Flavio for the effort.&lt;/p&gt;

&lt;p&gt;For HLogUtil.java and HLogFactory.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+ * Copyright 2010 The Apache Software Foundation
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Year is not needed.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class HLogUtil {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please add class javadoc and annotation for audience.&lt;br/&gt;
In HLog interface, I see methods without javadoc:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void registerWALActionsListener(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; WALActionsListener listener);
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; unregisterWALActionsListener(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; WALActionsListener listener);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please add javadoc for each of the interface methods: they&apos;re the first place where developer / user looks at when they want to understand HLog.&lt;br/&gt;
For a 260KB patch, review board would help reviewers a lot.&lt;/p&gt;</comment>
                            <comment id="13466165" author="fpj" created="Sat, 29 Sep 2012 09:21:14 +0000"  >&lt;p&gt;Thanks for checking it out, Ted.&lt;/p&gt;

&lt;p&gt;I checked the findbugs warnings, and I couldn&apos;t find anything related to this patch, so the new patch I uploaded does not fix any findbugs warning.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Year is not needed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sure, I have removed the three instances I found.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Please add class javadoc and annotation for audience.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For this patch, I have simply copied the signatures of public methods to the HLog interface. If there is no javadoc, it means that there was no javadoc for the method implementation there before the patch. But, if you&apos;d like us to create them for this patch, I don&apos;t have a problem working on it. To be clear, I&apos;m just pointing out that it was not there before, and in general I agree they should have javadocs.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;review board would help reviewers a lot.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed, I tried to create a review request, but I&apos;m getting an internal server error right now, so I&apos;ll try later again. Hopefully it is a transient problem.&lt;/p&gt;</comment>
                            <comment id="13466166" author="hadoopqa" created="Sat, 29 Sep 2012 09:23:24 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12547110/HBASE-5937.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12547110/HBASE-5937.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 72 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2968//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2968//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13466280" author="fpj" created="Sat, 29 Sep 2012 18:16:22 +0000"  >&lt;p&gt;This patch touches a lot of files, so it will be difficult to keep up with concurrent commits.&lt;/p&gt;</comment>
                            <comment id="13466282" author="hadoopqa" created="Sat, 29 Sep 2012 18:25:09 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12547122/HBASE-5937.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12547122/HBASE-5937.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 72 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2969//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2969//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13466288" author="yuzhihong@gmail.com" created="Sat, 29 Sep 2012 18:43:31 +0000"  >&lt;p&gt;@Flavio:&lt;br/&gt;
Your recent rebase didn&apos;t work because &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6476&quot; title=&quot;Replace all occurrances of System.currentTimeMillis() with EnvironmentEdge equivalent&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6476&quot;&gt;&lt;del&gt;HBASE-6476&lt;/del&gt;&lt;/a&gt; was backed out.&lt;br/&gt;
I think you don&apos;t need to frequently rebase. High-level comments would re-shape the patch dramatically.&lt;/p&gt;

&lt;p&gt;Thanks for your patience.&lt;/p&gt;</comment>
                            <comment id="13466307" author="yuzhihong@gmail.com" created="Sat, 29 Sep 2012 20:44:53 +0000"  >&lt;p&gt;It turns out the patch posted @ 29/Sep/12 10:14 applies cleanly to the current trunk.&lt;/p&gt;</comment>
                            <comment id="13466332" author="hadoopqa" created="Sat, 29 Sep 2012 21:46:32 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12547128/HBASE-5937.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12547128/HBASE-5937.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 72 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 157 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2971//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13466341" author="yuzhihong@gmail.com" created="Sat, 29 Sep 2012 22:16:54 +0000"  >&lt;p&gt;I got Flavio&apos;s permission to work with him on refining his patch.&lt;/p&gt;

&lt;p&gt;This patch transfers javadoc from FSHLog to HLog methods.&lt;br/&gt;
There&apos;re several methods lacking javadoc.&lt;/p&gt;

&lt;p&gt;We also need to go over the javadoc to see if certain implementation details should be transferred back to FSHLog.&lt;/p&gt;</comment>
                            <comment id="13466394" author="stack" created="Sun, 30 Sep 2012 03:30:40 +0000"  >&lt;p&gt;Do javadoc in another patch, especially if not there originally.  Its going to be hard enough landing this patch.&lt;/p&gt;</comment>
                            <comment id="13466401" author="yuzhihong@gmail.com" created="Sun, 30 Sep 2012 04:11:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;especially if not there originally&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The javadoc came from current HLog.java&lt;/p&gt;

&lt;p&gt;Looking at HLog interface, I wonder if interface Reader and interface Writer should be moved to their own files. That way we don&apos;t need to reference org.apache.hadoop.fs.FileSystem in HLog.&lt;/p&gt;</comment>
                            <comment id="13466402" author="stack" created="Sun, 30 Sep 2012 04:14:08 +0000"  >&lt;p&gt;Looking at the patch, its looking great.&lt;/p&gt;

&lt;p&gt;You fellas like how the new Interface looks or would you change it?  Stuff like isLowReplicationRollEnabled, getCoprocessorHost... these seems implementation specific.  And this mess:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void hsync() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void hflush() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void sync() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void sync(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; txid) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... You are exposing scars HBase got following the ups and downs of HDFS sync....and the battle rages still.&lt;/p&gt;

&lt;p&gt;I&apos;d be fine w/ cleanup happening in another issue after this JIRA goes in.&lt;/p&gt;

&lt;p&gt;appendNoSync should probably be append w/ a flag passed to append instead?&lt;/p&gt;

&lt;p&gt;No problem doing mass rename of HLog to WAL after patch goes in in another issue.  Here is some review:&lt;/p&gt;

&lt;p&gt;You have to do this cast?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    HBaseTestingUtility.setMaxRecoveryErrorCount(((FSHLog) wal2).getOutputStream(), 1);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... more review to follow.&lt;/p&gt;</comment>
                            <comment id="13466499" author="fpj" created="Sun, 30 Sep 2012 15:14:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;Ted Yu&lt;/a&gt; bq. Looking at HLog interface, I wonder if interface Reader and interface Writer should be moved to their own files. That way we don&apos;t need to reference org.apache.hadoop.fs.FileSystem in HLog.&lt;/p&gt;

&lt;p&gt;I was wondering the same thing. One reason for not doing it was having all interfaces to implement for HLog in the same place. But, I don&apos;t feel very strongly about leaving them in HLog.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; bq. You fellas like how the new Interface looks or would you change it? Stuff like isLowReplicationRollEnabled, getCoprocessorHost... these seems implementation specific.&lt;/p&gt;

&lt;p&gt;I think I said this in another jira, but the plan we proposed was to make of HLog an interface and expose all public methods first. This way it will be simpler to revisit the current public methods and redesign the interface. Making of HLog an interface and redesigning it all at once might be too messy.&lt;/p&gt;

&lt;p&gt;The bottom line is that we strongly agree that we need to revisit the methods currently in the interface and we need to do it eventually. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You have to do this cast? HBaseTestingUtility.setMaxRecoveryErrorCount(((FSHLog) wal2).getOutputStream(), 1);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well spotted. getOutputStream is currently not part of the interface because it is not a public method of FSHLog. According to the javadoc, it is used internally in FSHLog and in tests. Given that this is used in tests, we possibly don&apos;t want to make it specific to a particular implementation, although the test currently can&apos;t have anything else other than FSHLog for an instance of HLog. At the same time, getOutputStream returns a java.io.OutputStream, which is not specific to HDFS. I could really go both ways at this point.&lt;/p&gt;

</comment>
                            <comment id="13466590" author="stack" created="Sun, 30 Sep 2012 23:00:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;...Making of HLog an interface and redesigning it all at once might be too messy.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds fair enough.&lt;/p&gt;

&lt;p&gt;On the FSHLog cast, lets deal w/ these methods made public for testing later, after patch goes in.&lt;/p&gt;

&lt;p&gt;Methods like canGetCurReplicas are in a bit of a gray area at mo; they are package private but I see you do the cast because they are not in the Interface.  Again, we can deal w/ these later (canGetCurReplicas is an interesting one.... you know why we have it in hdfs?  Let us know if you don&apos;t know.  Might help you figuring whether it belongs in public Interface or not.  hasDeferredEntries is another.&lt;/p&gt;

&lt;p&gt;More review...&lt;/p&gt;

&lt;p&gt;Why we skip factory here?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      HLog hlog = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HLog(fs, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(rootRegionDir, &lt;span class=&quot;code-quote&quot;&gt;&quot;wals&quot;&lt;/span&gt;),
-          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(rootRegionDir, &lt;span class=&quot;code-quote&quot;&gt;&quot;old.wals&quot;&lt;/span&gt;), getConf()) {
+      HLog hlog = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FSHLog(fs, rootRegionDir, &lt;span class=&quot;code-quote&quot;&gt;&quot;wals&quot;&lt;/span&gt;, getConf()) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You think getDir doesn&apos;t belong in Interface?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-          Path dir = hlog.getDir();
+          Path dir = ((FSHLog) hlog).getDir();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You would like to hide notion of dir?  Let it be implementation detail?  Not let it out in Interface?&lt;/p&gt;

&lt;p&gt;So, getReader will take a FS implementation?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    HLog.Reader reader = HLogFactory.createReader(wal.getFileSystem(getConf()), 
+        wal, getConf());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is above right?  Taking fs and an HLog implementation?  Should we be able to get the fs from the HLog Interface?  Almost ditto for conf?  Could ask the HLog implementation for the configuration its using?  Or you just want to do that fix up later after commit?  Ditto for createWriter.  Just pass HLog Instance.&lt;/p&gt;

&lt;p&gt;This is odd method call... not your doing I&apos;d say:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    HLog.resetLogReaderClass();
+    HLogFactory.resetLogReaderClass();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;d think we&apos;d take the class we want to set reader too as an argument?&lt;/p&gt;

&lt;p&gt;On the Interface, I did not realize you could define a class on its inside.  I&apos;d say whatever about Reader and Writer &amp;#8211; they are small and it might be good keeping all together (or not &amp;#8211; whatever you think), I &apos;d think we could move this Entry class out of HLog to its own class.&lt;/p&gt;

&lt;p&gt;Just remove this stuff rather than comment out:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-comment&quot;&gt;//@org.junit.Rule
&lt;/span&gt;+  &lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; org.apache.hadoop.hbase.ResourceCheckerJUnitRule cu =
&lt;/span&gt;+  &lt;span class=&quot;code-comment&quot;&gt;//  &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.hadoop.hbase.ResourceCheckerJUnitRule();&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;HLogUtil.COMPLETE_CACHE_FLUSH should be in HLog not in HLogUtil I&apos;d say.&lt;/p&gt;

&lt;p&gt;This stuff you will probably want to hide someday: getServerNameFromHLogDirectoryName ... its implementation detail... but later.&lt;/p&gt;

&lt;p&gt;Should this be in HLogUtil &amp;#8211; getHLogDirectoryName?  Seems HLog attribute?&lt;/p&gt;

&lt;p&gt;Import in TestRowProcessorEndpoint but unused&lt;/p&gt;

&lt;p&gt;Yeah, this is dirty... getServerNameFromHLogDirectoryName... that&apos;d be in an HLog that you cast to a FSHLog rather than in HLogUtil (I&apos;d think the latter general util, not particular to an implementation?)&lt;/p&gt;

&lt;p&gt;You&apos;ll fix WALCoprocessorHost later?  So it can load whatever the WAL implementation, not just FSHLog?&lt;/p&gt;

&lt;p&gt;Is this wrong?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      HLog.Entry entry;
+      FSHLog.Entry entry;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is Entry still in the HLog Interface?&lt;/p&gt;

&lt;p&gt;This seems like a facility that belongs in HLog rather than out in HLogUtil:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      keyClass = HLog.getKeyClass(conf);
+      keyClass = HLogUtil.getKeyClass(conf);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You make a change in WALActionsListener javadoc but no other?  Maybe you were able to get away w/ using HLog only?  And not need to specify FSHLog?&lt;/p&gt;

&lt;p&gt;... let me submit this in case JIRA loses it on me.&lt;/p&gt;

</comment>
                            <comment id="13466591" author="stack" created="Sun, 30 Sep 2012 23:14:43 +0000"  >&lt;p&gt;How is HLogSplitter going to work w/ different implementations?  Currently you punt and refer to FSHLog?&lt;/p&gt;

&lt;p&gt;This too seems like an HLog thing rather than something that belongs out in util:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 HLogUtil.getRegionDirRecoveredEditsDir
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When region server opens, it&apos;ll want to ask the HLog implementation how to read back its edits?  Not go to util?&lt;/p&gt;

&lt;p&gt;FYI in hbase, like hadoop, we&apos;re about two spaces for indent (See HLogMetrics)&lt;/p&gt;

&lt;p&gt;Yeah, whats this crazy thing supposed to do?  &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; resetLogReaderClass&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Factory looks like it needs a get reader for my edits and you pass in the region whose edits you want?&lt;/p&gt;

&lt;p&gt;FYI, next time, you could use Bytes.toBytes in HBase  under util to do this: &quot;HBASE::CACHEFLUSH&quot;.getBytes(HConstants.UTF8_ENCODING);&lt;/p&gt;

&lt;p&gt;The following from HLogUtil I&apos;d think belong in an implementation:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
validateHLogFilename
getReader &lt;span class=&quot;code-comment&quot;&gt;// Why &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; in util and in factory too? .... or, its commented out along w/ createWriter?
&lt;/span&gt;getHLogDirectoryName
getRegionDirRecoveredEditsDir &lt;span class=&quot;code-comment&quot;&gt;// Can &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; later... seems like I ask the implementation &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; reader on the edits... 
&lt;/span&gt;moveAsideBadEditsFile
getSplitEditFilesSorted &lt;span class=&quot;code-comment&quot;&gt;// Yeah, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; would be in the HLog splitting implementation... or not exposed at all&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;No problem if you want to address the above later&lt;/p&gt;

&lt;p&gt;Something is up w/ your pom-it in the patch.  You are removing its contents.&lt;/p&gt;

&lt;p&gt;So, what you want to do?  If tests pass and you are fairly sure you have not done anything to change our wal write speed &amp;#8211; it doesn&apos;t look like you have changed any of that, then if you want to do a part 1 commit and then open new issue to address outstanding, improving WAL Interface, etc., I&apos;d be +1 on that.&lt;/p&gt;</comment>
                            <comment id="13466593" author="yuzhihong@gmail.com" created="Sun, 30 Sep 2012 23:45:58 +0000"  >&lt;p&gt;@Stack:&lt;br/&gt;
Thanks for the comments.&lt;/p&gt;

&lt;p&gt;About the changes to pom.xml, they were introduced on my machine yesterday.&lt;br/&gt;
I removed them in this patch.&lt;/p&gt;</comment>
                            <comment id="13466886" author="fpj" created="Mon, 1 Oct 2012 15:49:37 +0000"  >&lt;p&gt;Thanks a lot for the review, Stack, and Ted for the additions. Here are some more comments:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;How is HLogSplitter going to work w/ different implementations? Currently you punt and refer to FSHLog?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The splitter might not be necessary for every implementation, so I don&apos;t think it is a good idea to make it part of HLog. Since BookKeeper is optimized for writing multiple parallel streams efficiently, my perspective is that we want to benefit from this feature to avoid having to split upon recovery. This is my understanding at least, and it would be great to have a clarification if it is incorrect.&lt;/p&gt;

&lt;p&gt;If we assume that a splitter is necessary for every filesystem-based wal, then we could have another interface extending HLog and defining methods related to splitting. If not, then the splitter could specific to FSHLog. How does it sound? &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yeah, whats this crazy thing supposed to do? resetLogReaderClass&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I can&apos;t remember now where I got it from, but it is used in TestHLogSplit only to reset the class we use for the HLog reader. We have the ability to configure the class we use for the reader and the writer.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;FYI, next time, you could use Bytes.toBytes in HBase under util to do this: &quot;HBASE::CACHEFLUSH&quot;.getBytes(HConstants.UTF8_ENCODING);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok, thanks for the hint. I don&apos;t think I have added that statement, but I&apos;m happy to change it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The following from HLogUtil I&apos;d think belong in an implementation:&lt;br/&gt;
validateHLogFilename&lt;br/&gt;
getReader // Why this in util and in factory too? .... or, its commented out along w/ createWriter?&lt;br/&gt;
getHLogDirectoryName&lt;br/&gt;
getRegionDirRecoveredEditsDir // Can do this later... seems like I ask the implementation for reader on the edits... &lt;br/&gt;
moveAsideBadEditsFile&lt;br/&gt;
getSplitEditFilesSorted // Yeah, this would be in the HLog splitting implementation... or not exposed&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are you suggesting that we make them static methods of say FSHLog instead of having them in HLogUtil? They seem to be specific to the current trunk implementation of HLog, so it seems right to do it. The idea behind HLogUtil was to have all static methods in HLog originally. I can either move them now or create a jira to revisit HLogUtil. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;So, what you want to do? If tests pass and you are fairly sure you have not done anything to change our wal write speed &#8211; it doesn&apos;t look like you have changed any of that, then if you want to do a part 1 commit and then open new issue to address outstanding, improving WAL Interface, etc., I&apos;d be +1 on that.&lt;/p&gt;&lt;/blockquote&gt; 

&lt;p&gt;I don&apos;t think we have changed anything that would affect your wal speed, at least not consciously. The follow-up task I believe we need to work on, and they could be jiras directly, are:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Rename HLog interface to WAL as you suggested;&lt;/li&gt;
	&lt;li&gt;Revisit methods of the HLog interface;&lt;/li&gt;
	&lt;li&gt;Revisit methods of HLogUtil and HLogMetrics;&lt;/li&gt;
	&lt;li&gt;Revisit HLogSplitter.&lt;/li&gt;
	&lt;li&gt;Implement BKHLog.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13466953" author="stack" created="Mon, 1 Oct 2012 17:11:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;The splitter might not be necessary for every implementation, so I don&apos;t think it is a good idea to make it part of HLog.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its fine it doesn&apos;t need to split but Master needs some way of figuring that w/ a particular implemenation, there is no need to split.  How will you do this?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I can&apos;t remember now where I got it from, but it is used in TestHLogSplit only to reset the class we use for the HLog reader. We have the ability to configure the class we use for the reader and the writer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If only for that test, I&apos;d say we file an issue to fix this ugly addition to HLog only used in a single test....&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ok, thanks for the hint. I don&apos;t think I have added that statement, but I&apos;m happy to change it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not important.  Just an FYI.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Are you suggesting that we make them static methods of say FSHLog instead of having them in HLogUtil?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;They seem to be me like they belong in the Interface... getReader... or, if FSHLog particular, in FSHLog.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The idea behind HLogUtil was to have all static methods in HLog originally.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;To my mind, class named HLogUtil is utility that could be used by any HLog implementation.  If that is not the case, call it FSHLogUtil?&lt;/p&gt;

&lt;p&gt;You want to do your list in other JIRAs and get this patch committed now (do you want to do one last update)?&lt;/p&gt;</comment>
                            <comment id="13466998" author="enis" created="Mon, 1 Oct 2012 17:43:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think I said this in another jira, but the plan we proposed was to make of HLog an interface and expose all public methods first. This way it will be simpler to revisit the current public methods and redesign the interface. Making of HLog an interface and redesigning it all at once might be too messy.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was also gonna suggest to abstract away implementation specific method calls (splits, etc), but agreed that this patch may become unmanageable. Let&apos;s do it your way of just extracting the interface,  then we can work on the public api of the hlog. &lt;/p&gt;</comment>
                            <comment id="13467232" author="fpj" created="Mon, 1 Oct 2012 21:58:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;Its fine it doesn&apos;t need to split but Master needs some way of figuring that w/ a particular implemenation, there is no need to split. How will you do this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was wondering if the master really needs to be aware of splitting. To me it sounds like a feature that is implementation-specific. The master should be able to request the log stream for a region independent of how it gets it, no? Am I missing anything?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If only for that test, I&apos;d say we file an issue to fix this ugly addition to HLog only used in a single test....&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed, it is not pretty. I can create a jira to get rid of it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;To my mind, class named HLogUtil is utility that could be used by any HLog implementation. If that is not the case, call it FSHLogUtil?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right now it makes no difference calling it HLogUtil or FSHLogUtil because even the interface HLog is heavily file-oriented. I wouldn&apos;t discard calling it FSHLogUtil and creating an HLogUtil in the case there are methods that are implementation-independent. Right now they all seem to be tied to FSHLog somehow.&lt;/p&gt;

&lt;p&gt;I also see no issue currently with moving those methods to FSHLog directly. Originally, having HLog, HLogUtil, FSHLog was just to have an interface, an implementation of the interface, and the static methods related for implementations of the interface. Separating them seems to make clear that the static methods are FSHLog specific. I&apos;d like to have another careful look just to make sure I&apos;m not missing anything. &lt;/p&gt;

&lt;p&gt;It could be another jira too to decide if we call it FSHLogUtil or merge those methods with FSHLog. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You want to do your list in other JIRAs and get this patch committed now (do you want to do one last update)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds like a good idea because we can then focus on more concrete issue to refine it. It will make it more manageable. I&apos;ll do one more update shortly.&lt;/p&gt;



</comment>
                            <comment id="13467249" author="stack" created="Mon, 1 Oct 2012 22:16:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;To me it sounds like a feature that is implementation-specific. The master should be able to request the log stream for a region independent of how it gets it, no?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ideally it would work this way but the fs log splitting is a heavy-duty process that farms logs out to the cluster for it to split.  Might be hard &apos;hiding&apos; this big old process behind a request for edits.&lt;/p&gt;

&lt;p&gt;Ok.  Waiting on next update.  Will commit only if you promise to do the cleanup (smile) else we&apos;ll be in this half-way state that will be hard to explain to the poor folks who come after us.&lt;/p&gt;

&lt;p&gt;Good on you Flavio.&lt;/p&gt;</comment>
                            <comment id="13467250" author="fpj" created="Mon, 1 Oct 2012 22:17:49 +0000"  >&lt;p&gt;Here is an updated version as promised.&lt;/p&gt;</comment>
                            <comment id="13467253" author="fpj" created="Mon, 1 Oct 2012 22:20:55 +0000"  >&lt;p&gt;Sure, I can work on the cleanup. Hopefully it won&apos;t take long to converge to a state that is good for everyone. Let me know if you want me to create a new umbrella jira for all pending issues or if you have some other preference.&lt;/p&gt;</comment>
                            <comment id="13467295" author="apurtell" created="Mon, 1 Oct 2012 23:18:53 +0000"  >&lt;p&gt;+1 on approach and using an umbrella to group followups.&lt;/p&gt;</comment>
                            <comment id="13467575" author="hadoopqa" created="Tue, 2 Oct 2012 08:07:30 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12547291/HBASE-5937.v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12547291/HBASE-5937.v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 72 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 157 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestHCM&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2984//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13467589" author="fpj" created="Tue, 2 Oct 2012 09:21:28 +0000"  >&lt;p&gt;I&apos;ll add an issue to the umbrella jira to revisit javadocs.&lt;/p&gt;

&lt;p&gt;I don&apos;t see how TestHCM could possibly have failed because of this patch.&lt;/p&gt;

&lt;p&gt;I&apos;ll fix the findbugs warnings.&lt;/p&gt;</comment>
                            <comment id="13467769" author="fpj" created="Tue, 2 Oct 2012 14:56:32 +0000"  >&lt;p&gt;I have checked the new findbugs warning and they haven&apos;t been introduced by any of the changes I made. They appear as new because I moved code around. &lt;/p&gt;

&lt;p&gt;I have looked into finxing them, though. I fixed one about a volatile variable by making it an AtomicInteger. The warning was about incrementing a volatile variable. &lt;/p&gt;

&lt;p&gt;There are two warnings about static variables being set to a mutable array in HLog. This is due to the use of Bytes.toBytes(). I didn&apos;t want to change that, so I left as is. &lt;/p&gt;

&lt;p&gt;There two other warnings related to this code excerpt:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;      synchronized (closeLogSyncer) {
        closeLogSyncer.set(true);
        closeLogSyncer.notifyAll();
      }

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where closeLogSyncer is an AtomicBoolean, so the warning is saying that we shouldn&apos;t synchronize. It sounds right to me, but I wanted to make sure that it is correct. I can create a jira to fix it if I get a confirmation. It is a pretty simple fix.&lt;/p&gt;</comment>
                            <comment id="13467813" author="hadoopqa" created="Tue, 2 Oct 2012 15:56:05 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12547389/HBASE-5937.v3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12547389/HBASE-5937.v3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 72 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 157 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2985//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13467829" author="yuzhihong@gmail.com" created="Tue, 2 Oct 2012 16:22:18 +0000"  >&lt;p&gt;Nice to see a green QA run.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-@InterfaceAudience.Private
-&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class HLog &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; Syncable {
-  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Log LOG = LogFactory.getLog(HLog.class);
-  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] METAFAMILY = Bytes.toBytes(&lt;span class=&quot;code-quote&quot;&gt;&quot;METAFAMILY&quot;&lt;/span&gt;);
-  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] METAROW = Bytes.toBytes(&lt;span class=&quot;code-quote&quot;&gt;&quot;METAROW&quot;&lt;/span&gt;);
+&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; HLog {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please restore annotation for HLog. I suggest using Public + Evolving.&lt;/p&gt;</comment>
                            <comment id="13467855" author="stack" created="Tue, 2 Oct 2012 16:52:19 +0000"  >&lt;p&gt;I can restore the annotation on commit.  Will leave it private for now.&lt;/p&gt;</comment>
                            <comment id="13468003" author="stack" created="Tue, 2 Oct 2012 19:31:10 +0000"  >&lt;p&gt;Committed to trunk after running full suite and having it pass.  Good on you Flavio.&lt;/p&gt;

&lt;p&gt;Please create new issues for problems found reviewing this patch.&lt;/p&gt;</comment>
                            <comment id="13468066" author="yuzhihong@gmail.com" created="Tue, 2 Oct 2012 20:56:06 +0000"  >&lt;p&gt;I am confused as to the scope of the commit:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ svn log hbase-server/src/main/java/org/apache/hadoop/hbase/backup/example/LongTermArchivingHFileCleaner.java | head
------------------------------------------------------------------------
r1393126 | stack | 2012-10-02 12:29:19 -0700 (Tue, 02 Oct 2012) | 1 line

HBASE-5699 Refactor HLog into an &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;First, JIRA number was wrong.&lt;br/&gt;
Second, LongTermArchivingHFileCleaner.java wasn&apos;t even in Flavio&apos;s patch.&lt;/p&gt;

&lt;p&gt;Maybe one version of patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6707&quot; title=&quot;TEST org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient.testMultipleTables flaps&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6707&quot;&gt;&lt;del&gt;HBASE-6707&lt;/del&gt;&lt;/a&gt; was integrated by chance ?&lt;/p&gt;</comment>
                            <comment id="13468134" author="stack" created="Tue, 2 Oct 2012 22:39:19 +0000"  >&lt;p&gt;Updated the svn commit log to point to this issue instead of parent issue.  Also undid the hbase-6707 pollution accidentally committed.  Thanks for fingering this Ted.&lt;/p&gt;</comment>
                            <comment id="13468178" author="hudson" created="Tue, 2 Oct 2012 23:29:57 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3409 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3409/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3409/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5937&quot; title=&quot;Refactor HLog into an interface.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5937&quot;&gt;&lt;del&gt;HBASE-5937&lt;/del&gt;&lt;/a&gt; Refactor HLog into an interface; REMOVE &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6707&quot; title=&quot;TEST org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient.testMultipleTables flaps&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6707&quot;&gt;&lt;del&gt;HBASE-6707&lt;/del&gt;&lt;/a&gt; POLLUTION/OVERCOMMIT (Revision 1393221)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/backup/example/LongTermArchivingHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileArchiveUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13468184" author="hudson" created="Tue, 2 Oct 2012 23:33:42 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #204 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/204/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/204/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5937&quot; title=&quot;Refactor HLog into an interface.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5937&quot;&gt;&lt;del&gt;HBASE-5937&lt;/del&gt;&lt;/a&gt; Refactor HLog into an interface; REMOVE &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6707&quot; title=&quot;TEST org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient.testMultipleTables flaps&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6707&quot;&gt;&lt;del&gt;HBASE-6707&lt;/del&gt;&lt;/a&gt; POLLUTION/OVERCOMMIT (Revision 1393221)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5937&quot; title=&quot;Refactor HLog into an interface.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5937&quot;&gt;&lt;del&gt;HBASE-5937&lt;/del&gt;&lt;/a&gt; Refactor HLog into an interface (Revision 1393126)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/backup/example/LongTermArchivingHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileArchiveUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/backup/example/LongTermArchivingHFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HLogInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/WALPlayer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/LogCleaner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/metrics/RegionServerMetrics.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/Compressor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogMetrics.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogPrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALActionsListener.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileArchiveUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/MetaUtils.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/fs/TestBlockReorder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHLogRecordReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCacheOnWriteInSchema.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactSelection.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/FaultySequenceFileLogReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/HLogPerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtilsForTests.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogMethods.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRollAbort.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRollingNoCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALActionsListener.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSource.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSourceManager.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTool.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13495318" author="nkeywal" created="Mon, 12 Nov 2012 15:06:39 +0000"  >&lt;p&gt;In FSHLog, a wrong reference to getReader survived in the javadoc:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; * To read an HLog, call {@link #getReader(org.apache.hadoop.fs.FileSystem,
 * org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)}.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13495323" author="fpj" created="Mon, 12 Nov 2012 15:16:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkeywal&quot; class=&quot;user-hover&quot; rel=&quot;nkeywal&quot;&gt;Nicolas Liochon&lt;/a&gt; Please create a subtask under &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6931&quot; title=&quot;Refine WAL interface&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6931&quot;&gt;HBASE-6931&lt;/a&gt;. Thanks for reporting!&lt;/p&gt;</comment>
                            <comment id="13495334" author="nkeywal" created="Mon, 12 Nov 2012 15:24:54 +0000"  >&lt;p&gt;Hi Flavio,&lt;/p&gt;

&lt;p&gt;Done, it&apos;s in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6931&quot; title=&quot;Refine WAL interface&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6931&quot;&gt;HBASE-6931&lt;/a&gt; / &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7146&quot; title=&quot;Fix the wrong reference to getReader survived in theFSHLog javadoc&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7146&quot;&gt;&lt;del&gt;HBASE-7146&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12558321">HBASE-6116</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12458957">HBASE-2315</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12549194">HBASE-5699</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12458957">HBASE-2315</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12547185" name="5937-hlog-with-javadoc.txt" size="254228" author="yuzhihong@gmail.com" created="Sun, 30 Sep 2012 23:45:58 +0000"/>
                            <attachment id="12547128" name="HBASE-5937.patch" size="262103" author="fpj" created="Sat, 29 Sep 2012 20:44:48 +0000"/>
                            <attachment id="12547122" name="HBASE-5937.patch" size="262356" author="fpj" created="Sat, 29 Sep 2012 18:16:22 +0000"/>
                            <attachment id="12547110" name="HBASE-5937.patch" size="261792" author="fpj" created="Sat, 29 Sep 2012 09:14:00 +0000"/>
                            <attachment id="12547074" name="HBASE-5937.patch" size="261942" author="fpj" created="Fri, 28 Sep 2012 23:10:47 +0000"/>
                            <attachment id="12546979" name="HBASE-5937.patch" size="249670" author="fpj" created="Fri, 28 Sep 2012 11:16:00 +0000"/>
                            <attachment id="12547291" name="HBASE-5937.v2.patch" size="255750" author="fpj" created="Mon, 1 Oct 2012 22:17:49 +0000"/>
                            <attachment id="12547389" name="HBASE-5937.v3.patch" size="255795" author="fpj" created="Tue, 2 Oct 2012 14:49:45 +0000"/>
                            <attachment id="12544324" name="org.apache.hadoop.hbase.client.TestMultiParallel-output.txt" size="918396" author="fpj" created="Fri, 7 Sep 2012 23:40:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 4 May 2012 02:51:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>238078</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 5 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hub3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>102172</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.96notable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>