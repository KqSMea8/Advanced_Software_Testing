<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:18:48 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-10958/HBASE-10958.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-10958] [dataloss] Bulk loading with seqids can prevent some log entries from being replayed</title>
                <link>https://issues.apache.org/jira/browse/HBASE-10958</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We found an issue with bulk loads causing data loss when assigning sequence ids (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6630&quot; title=&quot;Port HBASE-6590 to trunk : Assign sequence number to bulk loaded files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6630&quot;&gt;&lt;del&gt;HBASE-6630&lt;/del&gt;&lt;/a&gt;) that is triggered when replaying recovered edits. We&apos;re nicknaming this issue &lt;b&gt;Blindspot&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;The problem is that the sequence id given to a bulk loaded file is higher than those of the edits in the region&apos;s memstore. When replaying recovered edits, the rule to skip some of them is that they have to be &lt;em&gt;lower than the highest sequence id&lt;/em&gt;. In other words, the edits that have a sequence id lower than the highest one in the store files &lt;b&gt;should&lt;/b&gt; have also been flushed. This is not the case with bulk loaded files since we now have an HFile with a sequence id higher than unflushed edits.&lt;/p&gt;

&lt;p&gt;The log recovery code takes this into account by simply skipping the bulk loaded files, but this &quot;bulk loaded status&quot; is &lt;b&gt;lost&lt;/b&gt; on compaction. The edits in the logs that have a sequence id lower than the bulk loaded file that got compacted are put in a blind spot and are skipped during replay.&lt;/p&gt;

&lt;p&gt;Here&apos;s the easiest way to recreate this issue:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Create an empty table&lt;/li&gt;
	&lt;li&gt;Put one row in it (let&apos;s say it gets seqid 1)&lt;/li&gt;
	&lt;li&gt;Bulk load one file (it gets seqid 2). I used ImporTsv and set hbase.mapreduce.bulkload.assign.sequenceNumbers.&lt;/li&gt;
	&lt;li&gt;Bulk load a second file the same way (it gets seqid 3).&lt;/li&gt;
	&lt;li&gt;Major compact the table (the new file has seqid 3 and isn&apos;t considered bulk loaded).&lt;/li&gt;
	&lt;li&gt;Kill the region server that holds the table&apos;s region.&lt;/li&gt;
	&lt;li&gt;Scan the table once the region is made available again. The first row, at seqid 1, will be missing since the HFile with seqid 3 makes us believe that everything that came before it was flushed.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12707760">HBASE-10958</key>
            <summary>[dataloss] Bulk loading with seqids can prevent some log entries from being replayed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jdcryans">Jean-Daniel Cryans</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Thu, 10 Apr 2014 18:08:02 +0000</created>
                <updated>Wed, 11 Jun 2014 02:53:04 +0000</updated>
                            <resolved>Wed, 30 Apr 2014 22:09:09 +0000</resolved>
                                    <version>0.96.2</version>
                    <version>0.98.1</version>
                    <version>0.94.18</version>
                                    <fixVersion>0.99.0</fixVersion>
                    <fixVersion>0.98.2</fixVersion>
                    <fixVersion>0.96.3</fixVersion>
                    <fixVersion>0.94.20</fixVersion>
                                        <due></due>
                            <votes>2</votes>
                                    <watches>21</watches>
                                                                <comments>
                            <comment id="13965642" author="jdcryans" created="Thu, 10 Apr 2014 18:17:19 +0000"  >&lt;p&gt;One workaround we found is to completely disable compactions, then when you need to run them you have to force flush the regions that have bulk loaded file first and ensure that bulk loads aren&apos;t coming in at the same time.&lt;/p&gt;

&lt;p&gt;Workloads that are strictly doing incremental bulk loads aren&apos;t affected, you need a mix of bulk loaded files and normal Puts.&lt;/p&gt;

&lt;p&gt;A hacky solution could be to force flush when bulk loading with seqids and grab the next sequence id that comes after the memstore flush to go to the bulk loaded file. This means that bulk loading needs to initiate a flush, get the sequence id under the region write lock, then do the bulk load. We don&apos;t need to wait for the flush to happen... unless the possibility for the bulk loaded file to be compacted before the flush is done is high enough.&lt;/p&gt;</comment>
                            <comment id="13965678" author="lhofhansl" created="Thu, 10 Apr 2014 18:43:51 +0000"  >&lt;p&gt;Seems fine to force a flush before bulk loading.&lt;/p&gt;</comment>
                            <comment id="13966016" author="jdcryans" created="Thu, 10 Apr 2014 23:45:32 +0000"  >&lt;p&gt;Here&apos;s a quick hack I put together to show one solution. In this case I inline a flush with the &lt;tt&gt;bulkLoadHFiles&lt;/tt&gt; call and I modified the &lt;tt&gt;internalFlushcache&lt;/tt&gt; code to be able to get more state back and also return a sequential ID that ends up being in between two memstores.&lt;/p&gt;

&lt;p&gt;I tested that it works following the steps listed in this jira&apos;s description.&lt;/p&gt;

&lt;p&gt;I don&apos;t really like having to wait for the flush to happen since it could take a lot of time to finish making bulk loading way slower. On the other hand, it&apos;s safer than just requesting a flush asynchronously and then grabbing a new sequence ID from HLog. Maybe it would still be fine since you need to also have a compaction to trigger the bug...&lt;/p&gt;</comment>
                            <comment id="13966037" author="jdcryans" created="Fri, 11 Apr 2014 00:02:09 +0000"  >&lt;p&gt;Here&apos;s a less intrusive hack that shows what it looks like to request an asynchronous flush from &lt;tt&gt;bulkLoadHFiles&lt;/tt&gt;. I also tested that it works like the previous patch.&lt;/p&gt;

&lt;p&gt;The benefits are that the bulk loader doesn&apos;t have to wait and it&apos;s a lot less code, but the blindspot is still there and it widens as the region server gets more load; for example, if a lot of flushing is happening, which is likely with this patch, then the flush requests are queued and a compacting can kick in and at that moment if the region server dies then data is lost.&lt;/p&gt;</comment>
                            <comment id="13966219" author="alexandre.normand" created="Fri, 11 Apr 2014 04:30:08 +0000"  >&lt;p&gt;I&apos;ll throw my 2 canadien cents and say that I prefer the &quot;removing-the-second-lane&quot; solution (the one where we do a synchronous flush prior to bulk load). My rationale is that the other approach still leaves us with a blindspot, even if greatly reduced and we would effectively still have the bug (potentially). &lt;/p&gt;</comment>
                            <comment id="13966236" author="stack" created="Fri, 11 Apr 2014 05:02:15 +0000"  >&lt;p&gt;I&apos;m w/ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alexandre.normand&quot; class=&quot;user-hover&quot; rel=&quot;alexandre.normand&quot;&gt;Alexandre Normand&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;FlushState should be FlushResult?  Does it have to be public?&lt;/p&gt;

&lt;p&gt;Should below be HBaseIOE (you know who is watching) or some specialization on HBaseIOE, FlushFailedIOE(FlushState)?&lt;/p&gt;

&lt;p&gt;throw new IOException(&lt;/p&gt;

&lt;p&gt;What is happening here:&lt;/p&gt;

&lt;p&gt;+          seqId = fs.flushSequenceId;&lt;/p&gt;

&lt;p&gt;This is the &apos;next&apos; seqid after the flush or the seqid that was written into the hfile that was flushed?&lt;/p&gt;

&lt;p&gt;Do we need to up the seqid if the flush one is being used for a bulk load so the next edit in memstore has a different number?  Or that is done already elsewhere?&lt;/p&gt;

&lt;p&gt;Good stuff JD.  A unit test would be too hard to conjure?  Maybe describe then instead how you replicate.&lt;/p&gt;</comment>
                            <comment id="13966722" author="jdcryans" created="Fri, 11 Apr 2014 16:27:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;FlushState should be FlushResult? Does it have to be public?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Some external classes to that package call &lt;tt&gt;flushcache()&lt;/tt&gt; directly. Also, that method is public so whatever it returns needs to be as visible.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should below be HBaseIOE (you know who is watching) or some specialization on HBaseIOE, FlushFailedIOE(FlushState)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s inline with the rest of that method, which the bulk loading client seems to process correctly. Not that it shouldn&apos;t be considered, but maybe in a different jira?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This is the &apos;next&apos; seqid after the flush or the seqid that was written into the hfile that was flushed?&lt;br/&gt;
Do we need to up the seqid if the flush one is being used for a bulk load so the next edit in memstore has a different number? Or that is done already elsewhere?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah that part is hard to follow, needs at least some documentation (hey it is a hack!). So it&apos;s set here:&lt;/p&gt;

&lt;p&gt;+    return new FlushState(flushSeqId, compactionRequested);&lt;/p&gt;

&lt;p&gt;That &lt;tt&gt;flushSeqId&lt;/tt&gt; comes from here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; startSeqId = wal.startCacheFlush(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.getRegionInfo().getEncodedNameAsBytes());
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (startSeqId == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          status.setStatus(&lt;span class=&quot;code-quote&quot;&gt;&quot;Flush will not be started &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; [&quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.getRegionInfo().getEncodedName()
              + &lt;span class=&quot;code-quote&quot;&gt;&quot;] - WAL is going away&quot;&lt;/span&gt;);
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
        }
        flushSeqId = startSeqId.longValue();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So it&apos;s a sequence id that&apos;s the same one as the one used to signal the flush. I thought about creating a new one just after, but I&apos;m not sure if it&apos;s necessary since that &lt;tt&gt;startSeqId&lt;/tt&gt; will be after all the MemStore edits.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A unit test would be too hard to conjure? Maybe describe then instead how you replicate.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Doesn&apos;t seem too hard to write... at least the recreating what I&apos;m doing manually shouldn&apos;t take too long to write, but testing the corner cases seems much harder.&lt;/p&gt;

&lt;p&gt;I&apos;m still wondering if there&apos;s a more elegant solution.&lt;/p&gt;</comment>
                            <comment id="13967272" author="jdcryans" created="Sat, 12 Apr 2014 00:12:25 +0000"  >&lt;p&gt;Patch that addresses most of Stack&apos;s comments and based on trunk. Still no unit test, spent too much time today trying to understand why &lt;tt&gt;TestHRegion&lt;/tt&gt; fails so much (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10312&quot; title=&quot;Flooding the cluster with administrative actions leads to collapse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10312&quot;&gt;&lt;del&gt;HBASE-10312&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="13967366" author="hadoopqa" created="Sat, 12 Apr 2014 02:55:30 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12639893/HBASE-10958.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12639893/HBASE-10958.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12639893&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.security.access.TestAccessController&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9267//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13970014" author="jdcryans" created="Tue, 15 Apr 2014 20:20:44 +0000"  >&lt;p&gt;New patch with a unit test inside &lt;tt&gt;TestWALReplay&lt;/tt&gt;. I&apos;ve done a bit of refactoring and I&apos;m tempted to go a step further and somehow extract the common bits from testRegionMadeOfBulkLoadedFilesOnly and testCompactedBulkLoadedFiles but it seems a bit messy.&lt;/p&gt;</comment>
                            <comment id="13970015" author="jdcryans" created="Tue, 15 Apr 2014 20:21:55 +0000"  >&lt;p&gt;Oh and I found that testRegionMadeOfBulkLoadedFilesOnly wasn&apos;t really testing WAL replay with a bulk loaded file, the KV was being added at LATEST_TIMESTAMP so it wasn&apos;t visible being so far in the future. I made it so we check that we got all the rows back.&lt;/p&gt;</comment>
                            <comment id="13970031" author="stack" created="Tue, 15 Apr 2014 20:35:04 +0000"  >&lt;p&gt;Patch looks great &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt;.  Minor nit is that you do&lt;/p&gt;

&lt;p&gt;+        if (fs.flushSucceeded()) &lt;/p&gt;
{
+          seqId = fs.flushSequenceId;
+        }
&lt;p&gt; else if (fs.result == FlushResult.Result.CANNOT_FLUSH_MEMSTORE_EMPTY) {&lt;/p&gt;

&lt;p&gt;flushSucceeded method (should it be isFlushSucceeded) and then you go get the result by accessing the data member directly.  Minor inconsistency.&lt;/p&gt;

&lt;p&gt;+1 on commit if hadoopqa ok.  Can address above if you want on commit.&lt;/p&gt;</comment>
                            <comment id="13970109" author="hadoopqa" created="Tue, 15 Apr 2014 22:00:29 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12640324/HBASE-10958-v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12640324/HBASE-10958-v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12640324&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.security.access.TestAccessController&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9296//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13970118" author="jdcryans" created="Tue, 15 Apr 2014 22:14:08 +0000"  >&lt;p&gt;That&apos;s a real test failure, the user that bulk loads doesn&apos;t have the permission to flush. Looking.&lt;/p&gt;</comment>
                            <comment id="13970155" author="lhofhansl" created="Tue, 15 Apr 2014 22:50:23 +0000"  >&lt;p&gt;Oh; that&apos;s an unforeseen problem. Does it make sense for a user to be able to bulkload but not to flush? (I suppose it does as bulk loading is not in principle different from inserting data via Put/Delete).&lt;/p&gt;</comment>
                            <comment id="13970158" author="jdcryans" created="Tue, 15 Apr 2014 22:53:42 +0000"  >&lt;p&gt;Yeah, and bulk loading itself is kind of like a flush since you end up with an HFile.&lt;/p&gt;</comment>
                            <comment id="13970166" author="jdcryans" created="Tue, 15 Apr 2014 22:58:00 +0000"  >&lt;p&gt;Right now bulk loading is WRITE and flush is ADMIN. Problematic!&lt;/p&gt;</comment>
                            <comment id="13970173" author="jdcryans" created="Tue, 15 Apr 2014 23:06:10 +0000"  >&lt;p&gt;Solutions on top of my head:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Do doAs inside the method. The rationale being that it&apos;s the region server that&apos;s trying to do that here, not the user. I&apos;m not sure if this is doable, and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; is laughing at me.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Matteo thinks that we should just make bulk load an ADMIN method. I agree but I&apos;m not fond of breaking secure setups that use bulk loads. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13970216" author="lhofhansl" created="Tue, 15 Apr 2014 23:51:55 +0000"  >&lt;p&gt;Wait. Are you saying the region server itself cannot issue a flush as part of the bulkLoadHFiles RPC?&lt;br/&gt;
The region server is flushing all the time on its own behalf (when the memstore is full, etc).&lt;/p&gt;</comment>
                            <comment id="13970228" author="jdcryans" created="Tue, 15 Apr 2014 23:58:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Wait. Are you saying the region server itself cannot issue a flush as part of the bulkLoadHFiles RPC?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Exact. That&apos;s why the User.runAs (and then run as the region server itself) solution seems to make sense to me.&lt;/p&gt;

&lt;p&gt;I read some more code, and it seems bulk load actually requires CREATE even though the call itself requires WRITE. From TestAccessController:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// User performing bulk loads must have privilege to read table metadata
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// (ADMIN or CREATE)
&lt;/span&gt;    verifyAllowed(bulkLoadAction, SUPERUSER, USER_ADMIN, USER_OWNER, USER_CREATE);
    verifyDenied(bulkLoadAction, USER_RW, USER_NONE, USER_RO);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So another options is to set flush and compact as CREATE actions (in line with create table, alter, disable, enable, delete).&lt;/p&gt;</comment>
                            <comment id="13970237" author="lhofhansl" created="Wed, 16 Apr 2014 00:10:51 +0000"  >&lt;p&gt;I guess I did not realize that the authorization extends to any action issued from an RPC, rather than just authorizing the RPC call itself.&lt;/p&gt;</comment>
                            <comment id="13970404" author="apurtell" created="Wed, 16 Apr 2014 04:17:26 +0000"  >&lt;p&gt;We expect READ and WRITE perms granted in a fine grained way to constraint who can do individual ops that only collectively add up to cluster impacting events like compactions, splits, and flushes. For actions that can have a global cluster impact, we&apos;d like ADMIN to be granted sparingly to admins or delegates. IIRC enable and disable are ADMIN actions also, since disabling or enabling a 10000 region table has consequences. CREATE is kind of a middle ground for schema reads and updates, but in terms of schema update that&apos;s splitting hairs I suppose since a schema update of said large table would also have consequences of the same scale.&lt;/p&gt;

&lt;p&gt;Bulk load is a special snowflake because it&apos;s a series of puts (so, WRITE) yet obviously more than that as mentioned, we need to flush, and moving files in place will probably kick off compaction. Making bulk load an ADMIN action, or CREATE, makes sense to me also.&lt;/p&gt;</comment>
                            <comment id="13970407" author="apurtell" created="Wed, 16 Apr 2014 04:22:00 +0000"  >&lt;p&gt;And the bit about needing CREATE or ADMIN to read schema metadata, this is to protect potentially sensitive information in the metadata that an ordinary user granted only READ or READ+WRITE access to the table has no need to see, that was &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8692&quot; title=&quot;[AccessController] Restrict HTableDescriptor enumeration&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8692&quot;&gt;&lt;del&gt;HBASE-8692&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13970478" author="jinghe" created="Wed, 16 Apr 2014 06:11:33 +0000"  >&lt;p&gt;Very nice explanation and insights on these permissions!&lt;br/&gt;
Looking previously at this page: &lt;a href=&quot;https://hbase.apache.org/book/hbase.accesscontrol.configuration.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hbase.apache.org/book/hbase.accesscontrol.configuration.html&lt;/a&gt;&lt;br/&gt;
we only have pretty vague info over there.&lt;br/&gt;
Also, the &apos;write&apos; permission for &apos;flush&apos; and &apos;compact&apos; in &apos;Table 8.1&apos;. Are they even correct?&lt;/p&gt;</comment>
                            <comment id="13971584" author="jdcryans" created="Wed, 16 Apr 2014 15:59:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;we&apos;d like ADMIN to be granted sparingly to admins or delegates&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;IIRC enable and disable are ADMIN actions also, since disabling or enabling a 10000 region table has consequences.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is what I see in the code in trunk:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
requirePermission(&lt;span class=&quot;code-quote&quot;&gt;&quot;preBulkLoadHFile&quot;&lt;/span&gt;, ....getTableDesc().getTableName(), el.getFirst(), &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, Permission.Action.WRITE);
requirePermission(&lt;span class=&quot;code-quote&quot;&gt;&quot;enableTable&quot;&lt;/span&gt;, tableName, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, Action.ADMIN, Action.CREATE);
requirePermission(&lt;span class=&quot;code-quote&quot;&gt;&quot;disableTable&quot;&lt;/span&gt;, tableName, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, Action.ADMIN, Action.CREATE);
requirePermission(&lt;span class=&quot;code-quote&quot;&gt;&quot;compact&quot;&lt;/span&gt;, getTableName(e.getEnvironment()), &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, Action.ADMIN);
requirePermission(&lt;span class=&quot;code-quote&quot;&gt;&quot;flush&quot;&lt;/span&gt;, getTableName(e.getEnvironment()), &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, Action.ADMIN);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;IMO flush should have lower or same perms as disableTable.&lt;/p&gt;

&lt;p&gt;So here&apos;s a list of changes I believe are needed:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;preBulkLoadHFile goes from WRITE to CREATE (seems more in line with what&apos;s really needed to bulk load given the code I posted yesterday)&lt;/li&gt;
	&lt;li&gt;compact/flush go from ADMIN to ADMIN or CREATE&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This should not have an impact on the current users. If we can agree on the changes, I&apos;ll open a new jira that&apos;s going to be blocking this one.&lt;/p&gt;</comment>
                            <comment id="13971738" author="lhofhansl" created="Wed, 16 Apr 2014 17:58:53 +0000"  >&lt;p&gt;Maybe &quot;CREATE&quot; no longer expresses what it now implies...?&lt;/p&gt;

&lt;p&gt;I can see that folks would not want to grant users CREATE (or ADMIN) so that they cannot create/drop/enable/disable tables, but still do allow them to load data via bulk load. That would now no longer possible.&lt;/p&gt;

&lt;p&gt;Also it would seem more sensible to me that if a user bulk loads some data and then for &lt;b&gt;technical&lt;/b&gt; reasons the region server decides to flush there should be no additional right needed; just a user does not need permission to flush only because a Put happens to cause a flush.&lt;br/&gt;
Have we dismissed this option?&lt;/p&gt;</comment>
                            <comment id="13971753" author="jdcryans" created="Wed, 16 Apr 2014 18:07:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;I can see that folks would not want to grant users CREATE (or ADMIN) so that they cannot create/drop/enable/disable tables, but still do allow them to load data via bulk load. That would now no longer possible.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Bulk load already needs CREATE as shown above in TestAccessController.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Have we dismissed this option?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think so, but no one has been pushing for it. It creates a precedent, nowhere else in the code do we use User.runAs to override the current user that came in via a RPC (I&apos;m not even sure if it works, but that&apos;s because I don&apos;t know that code very well).&lt;/p&gt;</comment>
                            <comment id="13971766" author="lhofhansl" created="Wed, 16 Apr 2014 18:18:29 +0000"  >&lt;p&gt;Missed the test comment. In that case let&apos;s do what you suggest.&lt;br/&gt;
(Since this in an existing issue I might sill want release 0.94.19 before we fix it depending on whether this needs more discussion)&lt;/p&gt;</comment>
                            <comment id="13971778" author="jinghe" created="Wed, 16 Apr 2014 18:29:20 +0000"  >&lt;p&gt;Just did a quick test. The requirement on &apos;CREATE&apos; for bulk load seems to come from here.  Is this even intended?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; org.apache.hadoop.hbase.security.AccessDeniedException: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions (user=user1@IBM.COM, scope=TestTable, family=, action=CREATE)
        at org.apache.hadoop.hbase.security.access.AccessController.requirePermission(AccessController.java:356)
        at org.apache.hadoop.hbase.security.access.AccessController.preGetTableDescriptors(AccessController.java:1513)
        at org.apache.hadoop.hbase.master.MasterCoprocessorHost.preGetTableDescriptors(MasterCoprocessorHost.java:1260)
        at org.apache.hadoop.hbase.master.HMaster.getTableDescriptors(HMaster.java:2569)
        at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:40438)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2150)
 ...
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:235)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHTableDescriptor(HConnectionManager.java:2632)
        at org.apache.hadoop.hbase.client.HTable.getTableDescriptor(HTable.java:548)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:233)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.run(LoadIncrementalHFiles.java:820)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13971998" author="jdcryans" created="Wed, 16 Apr 2014 21:56:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;The requirement on &apos;CREATE&apos; for bulk load seems to come from here. Is this even intended?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for doing this. There&apos;s also another place where this is called, splitStoreFile(), in order to get an HCD. I don&apos;t think it&apos;s necessary to call it twice, but it seems necessary to call it at least once else you can&apos;t:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify that the families exist&lt;/li&gt;
	&lt;li&gt;get the schema for each family so that we create the HFiles with the correct configurations when splitting&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13972111" author="jdcryans" created="Wed, 16 Apr 2014 23:51:44 +0000"  >&lt;p&gt;Forgot to reply to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;&apos;s comment:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;flushSucceeded method (should it be isFlushSucceeded) and then you go get the result by accessing the data member directly. Minor inconsistency.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;flushSucceeded() isn&apos;t just looking up a field though, it&apos;s checking two things. &lt;/p&gt;</comment>
                            <comment id="13972261" author="apurtell" created="Thu, 17 Apr 2014 03:20:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;IMO flush should have lower or same perms as disableTable.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That seems fine. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe &quot;CREATE&quot; no longer expresses what it now implies...?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;At the least we have an imperfect idea of when a user should be able to create tables and administer them, just &quot;not administer them too much&quot;&lt;/p&gt;</comment>
                            <comment id="13972269" author="apurtell" created="Thu, 17 Apr 2014 03:37:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;The requirement on &apos;CREATE&apos; for bulk load seems to come from [ getTableDescriptors ]. Is this even intended?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;CREATE is overloaded to mean &quot;RESTRICTED ADMIN&quot;, with ADMIN-ish privilege required because table schema is considered potentially sensitive. &lt;/p&gt;

&lt;p&gt;On another issue Francis Liu and I discussed the notion of creating a new permission &apos;SCHEMA&apos; which would grant permission to read schema metadata. Now as then it seems maybe not quite needed (yet). CREATE and ADMIN would have such SCHEMA permission implicitly, so how useful would SCHEMA be, and there would still need a grant beyond WRITE for bulk loading.&lt;/p&gt;</comment>
                            <comment id="13973638" author="jdcryans" created="Fri, 18 Apr 2014 00:40:17 +0000"  >&lt;p&gt;Attaching 2 patches.&lt;/p&gt;

&lt;p&gt;One is a backport for 0.94. While doing the backport I saw that a TestSnapshotFromMaster was failing and Matteo was able to see that it was an error in my patch, flushing always returned that it needed compaction. I need to rerun all the tests now but it was the only one that failed (haven&apos;t tried with security either). I also added a test in TestHRegion for that.&lt;/p&gt;

&lt;p&gt;The second patch is for trunk, in which I ported the same test to TestHRegion. Interestingly, it didn&apos;t work. I found that in 0.94 we compact if num_files &amp;gt; compactionThreshold, but in trunk it&apos;s &amp;gt;=, so it seems that we compact more often now. This patch also has the fixes from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13973739" author="hadoopqa" created="Fri, 18 Apr 2014 03:02:07 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12640751/HBASE-10958-0.94.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12640751/HBASE-10958-0.94.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12640751&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 15 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/9328//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/9328//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13973781" author="stack" created="Fri, 18 Apr 2014 04:32:15 +0000"  >&lt;p&gt;FYI rather than do this:&lt;/p&gt;

&lt;p&gt;+    String method = &quot;testFlushResult&quot;;&lt;/p&gt;

&lt;p&gt;You can do this:&lt;/p&gt;

&lt;p&gt;    method = name.getMethodName();&lt;/p&gt;

&lt;p&gt;... because in TestHRegion it does this:&lt;/p&gt;

&lt;p&gt;  @Rule public TestName name = new TestName();&lt;/p&gt;

&lt;p&gt;See here &lt;a href=&quot;http://stackoverflow.com/questions/473401/get-name-of-currently-executing-test-in-junit-4&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/473401/get-name-of-currently-executing-test-in-junit-4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;On the sometime an accessor, sometime not... not going to argue.  nit.&lt;/p&gt;

&lt;p&gt;Patch LGTM (where G==Great)&lt;/p&gt;</comment>
                            <comment id="13973789" author="jdcryans" created="Fri, 18 Apr 2014 04:53:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;method = name.getMethodName();&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Will fix (looks like I copied that from one of the few methods in that class that doesn&apos;t do it).&lt;/p&gt;</comment>
                            <comment id="13973793" author="stack" created="Fri, 18 Apr 2014 05:03:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Will fix (looks like I copied that from one of the few methods in that class that doesn&apos;t do it).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;it is a nit.  fix on commit?&lt;/p&gt;</comment>
                            <comment id="13974511" author="lhofhansl" created="Fri, 18 Apr 2014 21:40:04 +0000"  >&lt;p&gt;Nice. +1&lt;/p&gt;</comment>
                            <comment id="13975854" author="lhofhansl" created="Mon, 21 Apr 2014 18:35:28 +0000"  >&lt;p&gt;Moving to 0.94.20.&lt;/p&gt;</comment>
                            <comment id="13981605" author="jdcryans" created="Fri, 25 Apr 2014 21:06:08 +0000"  >&lt;p&gt;Committed to 0.96 and up. Like for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11008&quot; title=&quot;Align bulk load, flush, and compact to require Action.CREATE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11008&quot;&gt;&lt;del&gt;HBASE-11008&lt;/del&gt;&lt;/a&gt;, I&apos;m waiting to commit to 0.94 or I can open a backport jira.&lt;/p&gt;</comment>
                            <comment id="13981749" author="hudson" created="Fri, 25 Apr 2014 23:09:30 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #5118 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/5118/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/5118/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1590144)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13981862" author="hudson" created="Sat, 26 Apr 2014 03:19:05 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.98 #296 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.98/296/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.98/296/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1590145)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13981891" author="hudson" created="Sat, 26 Apr 2014 05:10:56 +0000"  >&lt;p&gt;SUCCESS: Integrated in hbase-0.96-hadoop2 #274 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96-hadoop2/274/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96-hadoop2/274/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1590146)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13981896" author="hudson" created="Sat, 26 Apr 2014 05:19:04 +0000"  >&lt;p&gt;FAILURE: Integrated in hbase-0.96 #395 (See &lt;a href=&quot;https://builds.apache.org/job/hbase-0.96/395/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/hbase-0.96/395/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1590146)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.96/hbase-server/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13981900" author="hudson" created="Sat, 26 Apr 2014 05:20:35 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.98-on-Hadoop-1.1 #281 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/281/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/281/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1590145)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.98/hbase-server/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13986050" author="lhofhansl" created="Wed, 30 Apr 2014 20:39:58 +0000"  >&lt;p&gt;Are you waiting for me to commit &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdcryans&quot; class=&quot;user-hover&quot; rel=&quot;jdcryans&quot;&gt;Jean-Daniel Cryans&lt;/a&gt;? Just making sure we&apos;re not mutually waiting.&lt;/p&gt;</comment>
                            <comment id="13986053" author="jdcryans" created="Wed, 30 Apr 2014 20:42:27 +0000"  >&lt;p&gt;Sorry, went to do something else, lemme get that in (with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11008&quot; title=&quot;Align bulk load, flush, and compact to require Action.CREATE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11008&quot;&gt;&lt;del&gt;HBASE-11008&lt;/del&gt;&lt;/a&gt; first).&lt;/p&gt;</comment>
                            <comment id="13986156" author="jdcryans" created="Wed, 30 Apr 2014 22:09:09 +0000"  >&lt;p&gt;Now committed to 0.94 (took some time because I wanted to double check the tests I modified were all green). Thanks everyone.&lt;/p&gt;</comment>
                            <comment id="13986221" author="lhofhansl" created="Wed, 30 Apr 2014 23:40:04 +0000"  >&lt;p&gt;You &apos;d man.&lt;/p&gt;</comment>
                            <comment id="13988386" author="hudson" created="Fri, 2 May 2014 22:59:22 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-0.94-JDK7 #132 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-JDK7/132/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-JDK7/132/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1591495)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13988408" author="hudson" created="Fri, 2 May 2014 23:15:24 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-0.94-on-Hadoop-2 #82 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-on-Hadoop-2/82/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-on-Hadoop-2/82/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1591495)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13988485" author="hudson" created="Sat, 3 May 2014 00:32:35 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-0.94 #1365 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/1365/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/1365/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1591495)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13989158" author="hudson" created="Sun, 4 May 2014 21:21:41 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-0.94-security #480 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/480/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/480/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10958&quot; title=&quot;[dataloss] Bulk loading with seqids can prevent some log entries from being replayed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10958&quot;&gt;&lt;del&gt;HBASE-10958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;dataloss&amp;#93;&lt;/span&gt; Bulk loading with seqids can prevent some log entries from being replayed (jdcryans: rev 1591495)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/HFileTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12708943">HBASE-11008</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12640751" name="HBASE-10958-0.94.patch" size="31519" author="jdcryans" created="Fri, 18 Apr 2014 00:40:17 +0000"/>
                            <attachment id="12639692" name="HBASE-10958-less-intrusive-hack-0.96.patch" size="785" author="jdcryans" created="Fri, 11 Apr 2014 00:02:09 +0000"/>
                            <attachment id="12639688" name="HBASE-10958-quick-hack-0.96.patch" size="10341" author="jdcryans" created="Thu, 10 Apr 2014 23:45:32 +0000"/>
                            <attachment id="12640324" name="HBASE-10958-v2.patch" size="30158" author="jdcryans" created="Tue, 15 Apr 2014 20:20:44 +0000"/>
                            <attachment id="12640750" name="HBASE-10958-v3.patch" size="31558" author="jdcryans" created="Fri, 18 Apr 2014 00:40:17 +0000"/>
                            <attachment id="12639893" name="HBASE-10958.patch" size="16196" author="jdcryans" created="Sat, 12 Apr 2014 00:12:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 10 Apr 2014 18:43:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>386083</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 32 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1uie7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>386348</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Bulk loading with sequence IDs, an option in late 0.94 releases and the default since 0.96.0, will now trigger a flush per region that loads an HFile (if there&amp;#39;s data that needs to flushed).</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>