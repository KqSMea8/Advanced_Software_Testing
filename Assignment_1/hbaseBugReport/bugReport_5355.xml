<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:27:01 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-5355/HBASE-5355.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-5355] Compressed RPC&apos;s for HBase</title>
                <link>https://issues.apache.org/jira/browse/HBASE-5355</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Some application need ability to do large batched writes and reads from a remote MR cluster. These eventually get bottlenecked on the network. These results are also pretty compressible sometimes.&lt;/p&gt;

&lt;p&gt;The aim here is to add the ability to do compressed calls to the server on both the send and receive paths.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12541879">HBASE-5355</key>
            <summary>Compressed RPC&apos;s for HBase</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="10">Implemented</resolution>
                                        <assignee username="karthik.ranga">Karthik Ranganathan</assignee>
                                    <reporter username="karthik.ranga">Karthik Ranganathan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Feb 2012 21:50:19 +0000</created>
                <updated>Tue, 4 Jun 2013 23:27:24 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 23:27:24 +0000</resolved>
                                    <version>0.89.20100924</version>
                                                    <component>IPC/RPC</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>23</watches>
                                                                <comments>
                            <comment id="13204046" author="tlipcon" created="Wed, 8 Feb 2012 22:04:06 +0000"  >&lt;p&gt;I&apos;ve been mulling this over in the back of my head recently with regards to the work just getting started on adding extensible RPC. Here are a few thoughts:&lt;/p&gt;

&lt;p&gt;A lot of our current lack of efficiency can be dealt with by simply avoiding multiple copies of the same data. The most egregious example: when we serialize columns, we serialize each KeyValue indepedendently, even though they all share the same row key.&lt;br/&gt;
One potential solution I&apos;ve been thinking about:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;introduce the concept of a &quot;constant pool&quot; which is associated with an RPC request or response. This pool would be serialized on the wire before the actual request/response and might be encoded like:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;total &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; length of constant pool&amp;gt; &amp;lt;number of constants&amp;gt; &amp;lt;constant 1 len&amp;gt; &amp;lt;constant 1 val&amp;gt; &amp;lt;constant 2 len&amp;gt; &amp;lt;constant 2 val&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then in the actual serialization of KeyValues, etc, we would not write out the data, but rather indexes into the constant pool.&lt;br/&gt;
The advantages to this kind of technique would be:&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;pushing all of the data near each other in the packet would make any compression more beneficial (rather than interleaving compressible user data with less compressible encoded information)&lt;/li&gt;
	&lt;li&gt;allows multiple parts of a request/response to reference the same byte arrays (eg multiple columns referring to the same row key)&lt;/li&gt;
	&lt;li&gt;allows zero-copy implementations even if we use protobufs to encode the actual call/response&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This idea might be orthogonal to the compression discussed above, but may be a cheaper (CPU-wise) way of getting a similar effect.&lt;/p&gt;</comment>
                            <comment id="13204266" author="karthik.ranga" created="Thu, 9 Feb 2012 05:14:55 +0000"  >&lt;p&gt;Yes, that would improve the compression, totally. Similar to data block encoding but for the wire transfer.&lt;/p&gt;</comment>
                            <comment id="13204280" author="stack" created="Thu, 9 Feb 2012 05:41:46 +0000"  >&lt;p&gt;Could we do same prefix compression on the wire?&lt;/p&gt;

&lt;p&gt;Todd in your proposal above we&apos;d convert KVs to your new form before putting payload on wire and then undo it on other side?&lt;/p&gt;

&lt;p&gt;Do we care about latency here?&lt;/p&gt;

&lt;p&gt;Long time back Ryan tried to a custom compression before putting stuff on the wire and then undoing it on other end hoping it would help some w/ latency but he found it upped latency.  I should dig up a pointer (could be how he went about it).&lt;/p&gt;</comment>
                            <comment id="13204296" author="tlipcon" created="Thu, 9 Feb 2012 06:07:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;Todd in your proposal above we&apos;d convert KVs to your new form before putting payload on wire and then undo it on other side?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, something like that. But hopefully it&apos;s just reference twiddling and not any actual data copying.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Long time back Ryan tried to a custom compression before putting stuff on the wire and then undoing it on other end hoping it would help some w/ latency but he found it upped latency&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I remember that too, but if I remember correctly it was going through the whole codec stream interface, which necessitates extra copies, etc. There&apos;s a lot of room for optimization there by adding new APIs to the hadoop codec stuff that operate on direct byte buffers in-place. And doing the &quot;application level compression&quot; as described above should be faster as well.&lt;/p&gt;</comment>
                            <comment id="13204317" author="ryanobjc" created="Thu, 9 Feb 2012 07:12:59 +0000"  >&lt;p&gt;I had used a number of mechanisms to attempt to reduce the size of the reply.  In no particular order:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;compression (not using the codec stream interface, using a java impl of lzo or some other fast compression)&lt;/li&gt;
	&lt;li&gt;custom-compression, reducing field dup&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The bottom line was that the late-compression was pretty expensive to reduce the size of a reply. Taking 50-100ms to compress more or less negated the entire benefit at a 5mb response. I ended up dropping this since it wasn&apos;t going to work.&lt;/p&gt;

&lt;p&gt;A while back I saw someone who had proposed a compressed representation of KV that had &apos;natural prefix&apos; compression.  It took advantage of the fact that KVs are typically stored sorted, so one could have a &apos;this KV has the same row as the previous&apos; flag, and ditto for columns, etc.&lt;/p&gt;

&lt;p&gt;Aside from that, it might make sense to use the prefix compressed data raw in the RPC response (as from the blocks), that way there is no re-compression penalty.&lt;/p&gt;</comment>
                            <comment id="13204318" author="ryanobjc" created="Thu, 9 Feb 2012 07:15:05 +0000"  >&lt;p&gt;oh btw, on the custom-compression, it wasnt so much as compression but a new form of serialization that did not duplicate fields. It was similar to your constant pool, the cost of figuring out what those constants are, then re-serializing it ended up being net-neutral at the best, and took slightly more time at worst.&lt;/p&gt;

&lt;p&gt;The act of determining what the constant pool could have been the expensive bit.  0-copy with protobuf would be great, but if the cost is in the constant pool assembly, then it might not be as beneficial as one would like.&lt;/p&gt;</comment>
                            <comment id="13205284" author="apurtell" created="Fri, 10 Feb 2012 08:06:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;A while back I saw someone who had proposed a compressed representation of KV that had &apos;natural prefix&apos; compression. It took advantage of the fact that KVs are typically stored sorted, so one could have a &apos;this KV has the same row as the previous&apos; flag, and ditto for columns, etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this was something I mentioned in some random JIRA.&lt;/p&gt;</comment>
                            <comment id="13226323" author="dhruba" created="Fri, 9 Mar 2012 18:59:58 +0000"  >&lt;p&gt;From what I understand, the aim of this jira is not to reduce latency of an RPC, but rather to reduce the network bandwidth usage. Ryan&apos;s comments makes sense: it is possible that in your setup the additional time taken to compress/decompress adds additional latency for the rpc completion times; but if you enable this on a cluster where the network bandwidth is the bottleneck, then there could be a net-gain in the rpc latency.&lt;/p&gt;

&lt;p&gt;Todd/Karthik: do you think that the prefix encoding would be a good candidate for this one? &lt;/p&gt;</comment>
                            <comment id="13248892" author="mikhail" created="Fri, 6 Apr 2012 21:35:44 +0000"  >&lt;p&gt;We have committed this feature (internally) to 89-fb. The implementation is available at &lt;a href=&quot;https://reviews.facebook.net/D1671&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1671&lt;/a&gt;. I tried to apply a patch to trunk, but it turned out to be very complex due to protocol refactoring done in trunk. Since trunk is moving to protocol buffers, this feature might be implemented very differently there compared to our RPC compression implementation 89-fb. Given these complications, we currently do not have enough resources to do the proper port to trunk, so I will commit the 89-fb patch into the 0.89-fb branch and leave the JIRA open for the trunk fix.&lt;/p&gt;</comment>
                            <comment id="13249410" author="stack" created="Sat, 7 Apr 2012 23:22:45 +0000"  >&lt;p&gt;@Mikhail Agreed.  Having looked at the 0.89 patch, by the time it was made ready for trunk, maybe 10% of the original patch would remain.  I should get Karthik talking up why he did the patch in the first place because its a good story, one that would inspire someone to make a version of the 0.89 patch for trunk.&lt;/p&gt;</comment>
                            <comment id="13264389" author="jdcryans" created="Sat, 28 Apr 2012 19:37:53 +0000"  >&lt;p&gt;I ported the patch against 0.94 and I&apos;ve tested it on a cluster, works pretty well. I&apos;m sure it breaks security somehow so it&apos;s definitely not finished.&lt;/p&gt;</comment>
                            <comment id="13465632" author="devaraj" created="Fri, 28 Sep 2012 14:22:28 +0000"  >&lt;p&gt;I&apos;ll take a pass at porting the patch to trunk (to work with the PB RPC) if there is no objection.&lt;/p&gt;</comment>
                            <comment id="13466095" author="apurtell" created="Sat, 29 Sep 2012 03:34:28 +0000"  >&lt;p&gt;+1 &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=devaraj&quot; class=&quot;user-hover&quot; rel=&quot;devaraj&quot;&gt;Devaraj Das&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We can experiment with it.&lt;/p&gt;</comment>
                            <comment id="13472776" author="devaraj" created="Tue, 9 Oct 2012 21:41:33 +0000"  >&lt;p&gt;Raised &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6966&quot; title=&quot;&amp;quot;Compressed RPCs for HBase&amp;quot; (HBASE-5355) port to trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6966&quot;&gt;&lt;del&gt;HBASE-6966&lt;/del&gt;&lt;/a&gt; for the forward port to trunk.&lt;/p&gt;</comment>
                            <comment id="13474786" author="lhofhansl" created="Fri, 12 Oct 2012 04:41:52 +0000"  >&lt;p&gt;Before we commit this or the trunk patch I&apos;d love to see some numbers comparing this full compression stream approach with just avoiding duplicate data while serializing from/to the RegionServer. On both sides we&apos;d have to reassemble the full KVs (unless we finally make a KV interface), but we can do that efficiently if we keep track of the size of the omitted parts of the KVs and preallocate the space and copy the data into that. That way we&apos;d have the same amount memory copying (ignoring DMA from the network card for the moment) and save bytes on the wire.&lt;/p&gt;

&lt;p&gt;I raised this on the mailing this a while ago, and Andy commented on that somewhere as well.&lt;br/&gt;
KV are sorted when traveling over the wire (as a set of Puts/Deletes or in a Result) we can simple avoid copying the prefix multiple times.&lt;/p&gt;

&lt;p&gt;Edit: Fixed my typical spelling mistakes.&lt;/p&gt;</comment>
                            <comment id="13475199" author="devaraj" created="Fri, 12 Oct 2012 18:01:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, the idea of eliminating duplicate data sounds very cool (and I&apos;ll dig deeper into it at some point), but IMO the work done here is kind of complementary. Couple of things (risking stating the obvious):&lt;br/&gt;
1. This will apply to all data on the wire&lt;br/&gt;
2. This will further compress the data beyond elimination of duplicate data&lt;br/&gt;
3. Not much additional code&lt;br/&gt;
4. This can be configured to be off&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="13475514" author="lhofhansl" created="Sat, 13 Oct 2012 03:30:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=devaraj&quot; class=&quot;user-hover&quot; rel=&quot;devaraj&quot;&gt;Devaraj Das&lt;/a&gt; Correct, this would only compress the prefixes of the key part, whereas this can compress the value as well. So this is really a different use case then.&lt;/p&gt;

&lt;p&gt;+1 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Any chance you can get some numbers (latency and throughput) with a without compression based on the size on the size of the data?&lt;/p&gt;
</comment>
                            <comment id="13476236" author="devaraj" created="Mon, 15 Oct 2012 16:09:12 +0000"  >&lt;p&gt;Thanks for the +1, Lars! &lt;/p&gt;

&lt;p&gt;With regard to getting numbers, not sure how easy or hard that is going to be. I suspect the improvement will show up mostly in those cases where the network bandwidth is an issue.&lt;br/&gt;
Wondering if there is an easy way to create bandwidth issues on something like an ec2 network (which is where I test).&lt;/p&gt;</comment>
                            <comment id="13477428" author="devaraj" created="Tue, 16 Oct 2012 22:47:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, do you think it is okay to commit the patch since this can be configured to be off anyway? From the comments on this jira and from the Facebook reviewboard, it seems like Facebook folks have stood to gain from this feature - &lt;a href=&quot;https://reviews.facebook.net/D1671#summary&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1671#summary&lt;/a&gt; (and hence this could help other similar deployments too). What do you think?&lt;/p&gt;</comment>
                            <comment id="13477456" author="lhofhansl" created="Tue, 16 Oct 2012 23:18:32 +0000"  >&lt;p&gt;Would need to digest the patch some more, but I do not see any principle reason against it. Would need support the SecureRpcEngine too.&lt;br/&gt;
Also it would be nice to get some numbers about much latency is increased.&lt;/p&gt;</comment>
                            <comment id="13477465" author="devaraj" created="Tue, 16 Oct 2012 23:26:35 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, I have done the required work for making it work in trunk (via &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6966&quot; title=&quot;&amp;quot;Compressed RPCs for HBase&amp;quot; (HBASE-5355) port to trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6966&quot;&gt;&lt;del&gt;HBASE-6966&lt;/del&gt;&lt;/a&gt;). As far as I am concerned, I&apos;d like to get the patch in 0.96. I&apos;ll try to get some latency numbers soon using that patch.&lt;/p&gt;</comment>
                            <comment id="13477667" author="devaraj" created="Wed, 17 Oct 2012 06:43:49 +0000"  >&lt;p&gt;Just to clarify - trunk doesn&apos;t have the SecureRpcEngine stuff (removed it via &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5732&quot; title=&quot;Remove the SecureRPCEngine and merge the security-related logic in the core engine&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5732&quot;&gt;&lt;del&gt;HBASE-5732&lt;/del&gt;&lt;/a&gt;). The patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6966&quot; title=&quot;&amp;quot;Compressed RPCs for HBase&amp;quot; (HBASE-5355) port to trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6966&quot;&gt;&lt;del&gt;HBASE-6966&lt;/del&gt;&lt;/a&gt; is meant to work with both security switched ON/OFF. Could we please have a review on the patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6966&quot; title=&quot;&amp;quot;Compressed RPCs for HBase&amp;quot; (HBASE-5355) port to trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6966&quot;&gt;&lt;del&gt;HBASE-6966&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;since 0.96 is going to be a major jump, I guess it makes sense to have this feature for 0.96.x only; made the trunk patch comparatively simpler since I didn&amp;#39;t have to worry about backward compatibility..&amp;#93;&lt;/span&gt;.&lt;/p&gt;</comment>
                            <comment id="13574642" author="lhofhansl" created="Fri, 8 Feb 2013 17:24:54 +0000"  >&lt;p&gt;I think we should close this issue and only work on the trunk patch (as per DD). I agree the extra complexity in 0.94 due to SecureRpcEngine is not worth it.&lt;/p&gt;</comment>
                            <comment id="13675421" author="stack" created="Tue, 4 Jun 2013 23:27:24 +0000"  >&lt;p&gt;Finished over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6966&quot; title=&quot;&amp;quot;Compressed RPCs for HBase&amp;quot; (HBASE-5355) port to trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6966&quot;&gt;&lt;del&gt;HBASE-6966&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12611074">HBASE-6966</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12524991" name="HBASE-5355-0.94.patch" size="31813" author="jdcryans" created="Sat, 28 Apr 2012 19:37:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Feb 2012 22:04:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>227166</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 28 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0169j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4784</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>