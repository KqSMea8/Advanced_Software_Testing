<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:56:06 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1755/HBASE-1755.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1755] Putting &apos;Meta&apos; table into ZooKeeper</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1755</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Moving to 0.22.0&lt;/p&gt;</description>
                <environment></environment>
        <key id="12432615">HBASE-1755</key>
            <summary>Putting &apos;Meta&apos; table into ZooKeeper</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="erikholstad@gmail.com">Erik Holstad</reporter>
                        <labels>
                    </labels>
                <created>Sun, 9 Aug 2009 04:43:04 +0000</created>
                <updated>Mon, 27 Jan 2014 05:28:53 +0000</updated>
                            <resolved>Sun, 26 Jan 2014 19:53:18 +0000</resolved>
                                    <version>0.90.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="12741022" author="erikholstad@gmail.com" created="Sun, 9 Aug 2009 04:52:54 +0000"  >&lt;p&gt;Did some small testing to see how a node with a lot of children would be have and what the memory usage would be.&lt;br/&gt;
These numbers were produced by running a single ZooKeeper node on my laptop and will be further tested on a bigger cluster&lt;br/&gt;
in the beginning  of next week, but just wanted to get some rough numbers.&lt;/p&gt;

&lt;p&gt;Inserted 10000 children and it didn&apos;t seem to cause any issues. Approximate  memory usage for this insert seemed to be around 6MB, so about 600B/node which seems kinda reasonable when looking at the DataNode.java code in ZooKeeper.&lt;/p&gt;</comment>
                            <comment id="12755055" author="stack" created="Mon, 14 Sep 2009 16:17:22 +0000"  >&lt;p&gt;&quot;ZooKeeper was not designed to be a general database or large object store. Instead, it manages coordination data. This data can come in the form of configuration, status information, rendezvous, etc. A common property of the various forms of coordination data is that they are relatively small: measured in kilobytes. The ZooKeeper client and the server implementations have sanity checks to ensure that znodes have less than 1M of data, but the data should be much less than that on average. Operating on relatively large data sizes will cause some operations to take much more time than others and will affect the latencies of some operations because of the extra time needed to move more data over the network and onto storage media. If large data storage is needed, the usually pattern of dealing with such data is to store it on a bulk storage system, such as NFS or HDFS, and store pointers to the storage locations in ZooKeeper.&quot;  &lt;a href=&quot;http://hadoop.apache.org/zookeeper/docs/r3.2.1/zookeeperProgrammers.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/zookeeper/docs/r3.2.1/zookeeperProgrammers.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12755615" author="streamy" created="Tue, 15 Sep 2009 18:07:55 +0000"  >&lt;p&gt;Each HRI, unoptimized, is probably about 400 bytes.  If we minimally binary encode it, we&apos;re probably talking closer to 100-150 bytes for all the information of a region.  Add another 32 bytes of overhead from the object itself, and call it 200 bytes per region at the high end.  I don&apos;t think historian belongs in ZK at all.&lt;/p&gt;

&lt;p&gt;This is small, meta data.  Several orders of magnitude smaller than 1M, and well below even 1K.  These are not large objects.&lt;/p&gt;

&lt;p&gt;I do believe this could be a big win for two reasons.  One, HBase has no db-level replication so requests for a segment of META will always go to a single node (this is the reason we still use &lt;em&gt;some&lt;/em&gt; key/val caching at streamy on top of HBase for the most commonly read rows).  Zookeeper replicates the data across all nodes so reads are fully-distributed.  Two, the code dealing with .META. is nasty and has always caused problems.  Doing something like alternate row order (ascending, for example) would be rather easy if done in ZK vs how we do it now.  &lt;/p&gt;

&lt;p&gt;However, META as a special table in HBase does work now (and is not really a bottleneck yet)...&lt;/p&gt;

&lt;p&gt;So I vote to bump further discussion of this to 0.22.  I&apos;d like to get to the next release ASAP and there is a beast of a problem to solve (with ZK help) in our current assignment/cluster task/load balancing systems before moving META to ZK, if ever.  If there was actual load balancing in HBase that balanced read load, it would help with both META as well as normal tables and potentially remove almost all need for caching outside of HBase.&lt;/p&gt;</comment>
                            <comment id="12755676" author="stack" created="Tue, 15 Sep 2009 20:27:19 +0000"  >&lt;p&gt;HRI should shrink considerably when we have it reference table descriptor and column descriptors kept elsewhere in zk.  -1 on binary encoding.  Needs to be human readable, json?, if up in zk.  But yeah, data should be getting smaller.&lt;/p&gt;

&lt;p&gt;(Chatting w/ J-D, we&apos;re thinking of dropping historian as a feature before its time and heavy-duty keeping it up in the meantime).&lt;/p&gt;

&lt;p&gt;Point taken on distribution.&lt;/p&gt;

&lt;p&gt;Agree to moving out of 0.21.&lt;/p&gt;

</comment>
                            <comment id="12755681" author="streamy" created="Tue, 15 Sep 2009 20:41:50 +0000"  >&lt;p&gt;Not sure why it needs to be human-readable but don&apos;t have a strong opinion about it.  You should be modifying with API or shell, not by editing json by hand?  KV is not &quot;human-readable&quot; but doesn&apos;t mean we don&apos;t have a toString() human-readable form, etc.&lt;/p&gt;</comment>
                            <comment id="12755697" author="stack" created="Tue, 15 Sep 2009 21:10:42 +0000"  >&lt;p&gt;human readable for debugging&apos;s sake&lt;/p&gt;</comment>
                            <comment id="13008750" author="wjiangwen" created="Sat, 19 Mar 2011 09:52:07 +0000"  >&lt;p&gt;i think zookeeper should be enhanced. let the children under a ZNode in order, and the comparator can be specified for each parent ZNode. so the client can find which region the key is in from zookeeper.&lt;/p&gt;

&lt;p&gt;and zookeeper should accept binary path, not only a string path.&lt;/p&gt;</comment>
                            <comment id="13009143" author="wjiangwen" created="Mon, 21 Mar 2011 14:37:45 +0000"  >&lt;p&gt;although ZooKeeper was not designed to be a general database or large object store. but there is no such limitation in the consistent algorithm behind ZK. ZK need to enhanced to be a meta data database, and the effort is very very small. &lt;br/&gt;
only store a large number of nodes into ZK, the data associated with each node is very little.&lt;/p&gt;</comment>
                            <comment id="13009144" author="wjiangwen" created="Mon, 21 Mar 2011 14:37:46 +0000"  >&lt;p&gt;although ZooKeeper was not designed to be a general database or large object store. but there is no such limitation in the consistent algorithm behind ZK. ZK need to enhanced to be a meta data database, and the effort is very very small. &lt;br/&gt;
only store a large number of nodes into ZK, the data associated with each node is very little.&lt;/p&gt;</comment>
                            <comment id="13009217" author="yuzhihong@gmail.com" created="Mon, 21 Mar 2011 17:18:50 +0000"  >&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3676&quot; title=&quot;Update region server load for AssignmentManager through regionServerReport()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3676&quot;&gt;&lt;del&gt;HBASE-3676&lt;/del&gt;&lt;/a&gt;, region load is reported to master through heartbeat. HBase-1502 removes heartbeat.&lt;br/&gt;
So potentially ZK may host more information about the regions.&lt;/p&gt;</comment>
                            <comment id="13009246" author="ryanobjc" created="Mon, 21 Mar 2011 18:03:35 +0000"  >&lt;p&gt;I was originally excited about this but I have recently become not a fan.  I think we should not store anything but temporary data in ZK.  The reason is there are several really good properties that we have now that we&apos;d lose:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Easy backup, just stop hbase, copy /hbase and you have a &lt;em&gt;complete&lt;/em&gt; backup.&lt;/li&gt;
	&lt;li&gt;Snapshot abilities, right now if you were to take a FS level snapshot you&apos;d have a perfect point in time backup.&lt;/li&gt;
	&lt;li&gt;There are solid tools for managing our hbase files, but none for ZK, this is a &quot;minor&quot; issue, but still the code would need to be written anyways.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13009290" author="streamy" created="Mon, 21 Mar 2011 18:54:57 +0000"  >&lt;p&gt;I generally agree that we should store temporary data in ZK, but I see META as largely temporary.&lt;/p&gt;

&lt;p&gt;Table/region meta data is already persisted on HDFS (we don&apos;t properly update, but that can be fixed without much trouble).  And we have plans to move schema and configuration information into ZK for online changes, so at least on a running cluster, we&apos;ll be depending on ZK for region configuration.&lt;/p&gt;

&lt;p&gt;Otherwise, META is largely for locations.&lt;/p&gt;

&lt;p&gt;I also think the possibility exists to keep a META region but maintain region locations in ZK.&lt;/p&gt;

&lt;p&gt;In general, the special casing and exception handling around the reading and updating of META is extraordinarily painful both in the master and in the regionservers.&lt;/p&gt;</comment>
                            <comment id="13047612" author="stack" created="Fri, 10 Jun 2011 22:46:04 +0000"  >&lt;p&gt;Moving out of 0.92.0. Pull it back in if you think different.&lt;/p&gt;</comment>
                            <comment id="13882412" author="stack" created="Sun, 26 Jan 2014 19:53:18 +0000"  >&lt;p&gt;We ain&apos;t going to do this.  Tendency now is away from zk rather than deeper investment.&lt;/p&gt;</comment>
                            <comment id="13882476" author="lhofhansl" created="Sun, 26 Jan 2014 23:23:50 +0000"  >&lt;p&gt;Not sure I agree with that tendency, though.&lt;br/&gt;
The problem is not ZK as such (IMHO), but more that we keep related state in many places. Moving all of meta to ZK - for example - would reduce that state duplication and be helpful.&lt;/p&gt;</comment>
                            <comment id="13882497" author="fenghh" created="Mon, 27 Jan 2014 01:28:08 +0000"  >&lt;p&gt;I agree with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; in some sense. ZK is not the root of all evil, it has its own recommended use pattern&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, it&apos;s (very) suitable for scenarios that:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;needs persistent (hierarchical) storage, and this storage is the only holder for some truth&lt;/li&gt;
	&lt;li&gt;the storage size is small&lt;/li&gt;
	&lt;li&gt;the access to the storage is sparse&lt;/li&gt;
	&lt;li&gt;a plus if have watch/notify mechanism for coding convenience, but the code using ZK should have inherent idempotence which cares only about the final state when it&apos;s notified (state machine code/logic cares about the total state transition, so ZK is not good for it)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;According to above:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;region location info in META table is not suitable to be in ZK: its size can be very large&lt;/li&gt;
	&lt;li&gt;region assignment status info is not suitable to be in ZK: 1). restart of a big cluster with big number of regions(say 10K-100K regions) can lead to very heavy/frequent read/write to ZK during the restart phase; 2). assignment code/logic is more like a state machine, it expects to have the full knowledge of the state transition without missed state change(event); 3). assignment status info duplicate in both master memory and ZK, ZK is not the only truth holder all the time(actually it&apos;s prohibitive to reference ZK as the only truth for each such info query, currently it serves more for assignment status info recovering when master fails, seems it&apos;s introduced to survive assignment process in case of master failure, right?)&lt;/li&gt;
	&lt;li&gt;replication info is quite suitable to be in ZK, since it matches all of the above characteristic &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Surely, if we embed a consensus lib in master, we actually have an inherent ZK within master ensemble, that way we can storage all different kinds of status/info with different access pattern in this &apos;inherent&apos; ZK within master(except region location info which is too big to be in memory)&lt;/p&gt;

&lt;p&gt;In an ideal world where master never dies, we won&apos;t use ZK to store the status/info currently stored in ZK, right? the master memory is the only truth holder. But master can die, so we need to duplicate the status/info in both master and ZK(this can potentially introduce the info-duplication problem, but the duplicate info problem can be avoided, but at the cost of efficiency: now we need to always access ZK rather than memory, it&apos;s prohibitive for data with heavy access), no duplication problem if we always use ZK as the truth(actually we treat ZK as the only truth this way for replication info, the reasons include replication info data size is small, access is sparse, so we can afford to always access ZK for replication info, that&apos;s why I think ZK is good enough for replication info&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;). &lt;br/&gt;
By embedding zk(consensus lib) within master, the zk and master memory now combine as one place, no info duplicate, no access efficiency problem, still have persistence in case of master failure...&lt;/p&gt;</comment>
                            <comment id="13882583" author="stack" created="Mon, 27 Jan 2014 05:28:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;The problem is not ZK as such (IMHO), but more that we keep related state in many places. Moving all of meta to ZK - for example - would reduce that state duplication and be helpful.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;IMO, the above is going in the wrong direction if only because zk is on other end of a network connection so it will never be good as the source of authoritative state when compared to having in-memory state inside in the process that is actually calling the shots.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fenghh&quot; class=&quot;user-hover&quot; rel=&quot;fenghh&quot;&gt;Honghua Feng&lt;/a&gt; You nailed it.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 14 Sep 2009 16:17:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32249</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 46 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hf33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99706</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>