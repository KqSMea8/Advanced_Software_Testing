<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:39:28 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-13082/HBASE-13082.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-13082] Coarsen StoreScanner locks to RegionScanner</title>
                <link>https://issues.apache.org/jira/browse/HBASE-13082</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Continuing where &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10015&quot; title=&quot;Replace intrinsic locking with explicit locks in StoreScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10015&quot;&gt;&lt;del&gt;HBASE-10015&lt;/del&gt;&lt;/a&gt; left of.&lt;br/&gt;
We can avoid locking (and memory fencing) inside StoreScanner by deferring to the lock already held by the RegionScanner.&lt;br/&gt;
In tests this shows quite a scan improvement and reduced CPU (the fences make the cores wait for memory fetches).&lt;/p&gt;

&lt;p&gt;There are some drawbacks too:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;All calls to RegionScanner need to be remain synchronized&lt;/li&gt;
	&lt;li&gt;Implementors of coprocessors need to be diligent in following the locking contract. For example Phoenix does not lock RegionScanner.nextRaw() and required in the documentation (not picking on Phoenix, this one is my fault as I told them it&apos;s OK)&lt;/li&gt;
	&lt;li&gt;possible starving of flushes and compaction with heavy read load. RegionScanner operations would keep getting the locks and the flushes/compactions would not be able finalize the set of files.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll have a patch soon.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12776620">HBASE-13082</key>
            <summary>Coarsen StoreScanner locks to RegionScanner</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ram_krish">ramkrishna.s.vasudevan</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Sat, 21 Feb 2015 06:36:14 +0000</created>
                <updated>Mon, 20 Jun 2016 19:24:27 +0000</updated>
                            <resolved>Fri, 22 Jan 2016 18:44:45 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>Performance</component>
                    <component>Scanners</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>17</watches>
                                                                                                            <comments>
                            <comment id="14330048" author="stack" created="Sat, 21 Feb 2015 07:05:14 +0000"  >&lt;p&gt;Looking forward to the ride &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=larsh&quot; class=&quot;user-hover&quot; rel=&quot;larsh&quot;&gt;larsh&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14331976" author="lhofhansl" created="Sun, 22 Feb 2015 00:50:06 +0000"  >&lt;p&gt;Simple patch. (much like the patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10015&quot; title=&quot;Replace intrinsic locking with explicit locks in StoreScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10015&quot;&gt;&lt;del&gt;HBASE-10015&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;A bit ugly, because I did not want to change the coprocessor APIs.&lt;/p&gt;

&lt;p&gt;Also thought of another drawback:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Nobody (coprocessor) can use StoreScanner alone anymore (there&apos;d be nothing to lock), i.e. all access &lt;b&gt;must&lt;/b&gt; be via Rigi.onScannerImpl or flushes or compactions). I think that&apos;s OK.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Maybe we can make the lock the compactions/flushes and StoreScanner have to agree upon explicit.&lt;/p&gt;</comment>
                            <comment id="14331989" author="stack" created="Sun, 22 Feb 2015 02:12:32 +0000"  >&lt;p&gt;How does it work?&lt;/p&gt;

&lt;p&gt;We create a RegionScanner per Scan. If we want to change the files that make up a scan, we need to synchronize on &apos;this&apos;. Calls to next, close, etc., have synchronized on &apos;this&apos; so the change of files can only be done when not nexting or closing?&lt;/p&gt;

&lt;p&gt;There may be many outstanding region scans going on.  For the completion of file updates to complete, all outstanding scanners will need to reach a &apos;safe point&apos;, i.e. post a next or close call (I suppose close don&apos;t count ... so just next).... A big row could take a while to return...&lt;/p&gt;

&lt;p&gt;Sounds good to me.&lt;/p&gt;

&lt;p&gt;Its kinda dirty passing lock from RegionScanner down from high level for use at StoreScanner scope but hey, whatever works. Why were we not able to do this at the StoreScanner scope again?&lt;/p&gt;

&lt;p&gt;On compaction and flush being delayed, for flush, we will be in the commit phase when we are trying to swap in the new file &amp;#8211; post flush from memory but the snapshot of the memstore is still around and being read from &amp;#8211; so we could hold on to memory pressure a little longer.  For compaction, yeah, could be reading from many files for a while longer though the compaction finished.&lt;/p&gt;

&lt;p&gt;You done any testing. I like the bit where we remove the locks at Store level.&lt;/p&gt;</comment>
                            <comment id="14332025" author="lhofhansl" created="Sun, 22 Feb 2015 05:09:46 +0000"  >&lt;p&gt;Quick note why this works:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;StoreScanner is passed an explicit object to sync on in updateReaders (it does not care what this object is, just that it needs to sync on it).&lt;/li&gt;
	&lt;li&gt;We pass the RegionScannerImpl object down as the &quot;sync&quot; object&lt;/li&gt;
	&lt;li&gt;All operations that call any StoreScanner method are synchronized already on RegionScannerImpl (except for nextRaw, but that requires the caller to do the locking himself)&lt;/li&gt;
	&lt;li&gt;Now any region scanner operation will prevent the readers from being updated&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;#4 is much coarser than locking at the StoreScanner object - StoreScanner.peek is by far the worst, as it is called all over the place. There is no way in StoreScanner (that I see) that avoids locking every single operation (causing a memory fence, read and write barrier in this case). As said above, the lock is almost never contended, the problem are the memory fences, which &lt;b&gt;kill&lt;/b&gt; multi core performance.&lt;/p&gt;

&lt;p&gt;It leads to the caveat listed above. Very heavy read load can essentially prevent flushes or compaction from finishing.&lt;br/&gt;
But note that this is &lt;b&gt;already&lt;/b&gt; the case, it is just currently more likely that the flush/compaction will get through, because the locks are more fine grained. Checkout StoreScanner.next(List&amp;lt;Cell&amp;gt;), it already holds a lock for the entire duration of the row fetch. This patch coarsens that to the Scan&apos;s batch and up the region. So reads on other stores can lock out flushes/compactions of a store.&lt;br/&gt;
Also note that compactions usually run a long time, and only need the lock once to switch the readers around, same for flushes. Need to do testing but I doubt it&apos;s an issue.&lt;/p&gt;

&lt;p&gt;Fair locking can help here, but comes with other issues.&lt;/p&gt;

&lt;p&gt;I&apos;ve done local node testing. (local single node HDFS cluster, running single node HBase on top)&lt;/p&gt;

&lt;p&gt;Let me know if the patch is clear. If not, what do I need to change? Worth doing?&lt;/p&gt;</comment>
                            <comment id="14332156" author="apache9" created="Sun, 22 Feb 2015 12:59:49 +0000"  >&lt;p&gt;I think the patch should work. But I wonder the actual performance improvement.&lt;br/&gt;
Since the lock is rarely contended, then it will not effect concurrency, the only problem is fencing caused large memory latency. But scanner usually does I/O(network or local disk), so is this latency really worth caring?  This patch is a little hacking I think...&lt;br/&gt;
Let&apos;s see the test result.&lt;/p&gt;</comment>
                            <comment id="14332385" author="lhofhansl" created="Sun, 22 Feb 2015 21:44:05 +0000"  >&lt;p&gt;It&apos;s not about contention. We take the lock multiple times a row, every time CPU takes out a memory barrier. When the data is in the block cache the saving can be as much as 2x.&lt;/p&gt;</comment>
                            <comment id="14332416" author="lhofhansl" created="Sun, 22 Feb 2015 23:05:00 +0000"  >&lt;p&gt;OK... Actually current number: 50m row table, 1 col, 1 version, 2gb on disk. Local HDFS with local HBase. All fits into the block cache. All filtered at the server.&lt;br/&gt;
With patch: 9.45s&lt;br/&gt;
Without patch: 12.9s&lt;/p&gt;

&lt;p&gt;(so measures HBase&apos;s internal friction, and would be a scenario where we scan to calculate an aggregate via Phoenix, etc)&lt;/p&gt;

&lt;p&gt;So not quite 2x, but not bad either.&lt;/p&gt;</comment>
                            <comment id="14332447" author="lhofhansl" created="Mon, 23 Feb 2015 00:24:58 +0000"  >&lt;p&gt;Same with FAST_DIFF encoding (768mb on disk). All data in cache:&lt;/p&gt;

&lt;p&gt;With patch: 13.2s&lt;br/&gt;
Without patch: 16.4s&lt;/p&gt;

&lt;p&gt;Data not in cache (read from SSD, OS buffer cache also cleaned, short circuit reads SCR enabled):&lt;br/&gt;
With patch: 14.2s (reading about 51mb/s from disk)&lt;br/&gt;
Without patch: 17.5s (reading about 42mb/s from disk)&lt;/p&gt;

&lt;p&gt;So assuming data locality so that we can do SCR this definitely improves things.&lt;/p&gt;

&lt;p&gt;In all cases we save about 3.3s. So we save about 66ns per row.&lt;/p&gt;

&lt;p&gt;Is it worth the hack? Not sure.&lt;/p&gt;</comment>
                            <comment id="14332462" author="lhofhansl" created="Mon, 23 Feb 2015 01:03:10 +0000"  >&lt;p&gt;Tests with multiple client threads (50m rows, FAST_DIFF, all in cache):&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;threads&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;w/ patch&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;w/o patch&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;15&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;34&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;38&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;56&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;44&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;*&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;ul&gt;
	&lt;li&gt;some scanners timed out (over 60s)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14332469" author="stack" created="Mon, 23 Feb 2015 01:30:46 +0000"  >&lt;p&gt;Benefit looks great to me. Let me try and add some numbers; perf numbers.&lt;/p&gt;</comment>
                            <comment id="14332472" author="lhofhansl" created="Mon, 23 Feb 2015 01:36:37 +0000"  >&lt;p&gt;Same without FAST_DIFF:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;threads&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;w/ patch&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;w/o patch&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;11&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;14&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;31&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;*&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;ul&gt;
	&lt;li&gt;some scanners timed out&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The numbers were quite variable in both cases.&lt;/p&gt;

&lt;p&gt;(The machine has 4 cores with hyper threads, hence tests up to 8 active handlers)&lt;/p&gt;</comment>
                            <comment id="14332476" author="lhofhansl" created="Mon, 23 Feb 2015 01:47:13 +0000"  >&lt;p&gt;So at least we have established that locking in the StoreScanner is bad &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I now remember issues we have seen with timerange range scans, where in unlucky circumstances it takes almost 20 minutes to finish scanning a single region (and that time all spent inside a &lt;b&gt;single&lt;/b&gt; RegionScanner.next() call, as in this case no Cells matched the timerange)&lt;br/&gt;
So that would be 20 minutes&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/warning.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; during which we would not be able to commit a flush or finish a compaction.&lt;/p&gt;

&lt;p&gt;So now, I do not think that is acceptable. The RegionScanner lock is too coarse. We need something in between. Hmmm....&lt;/p&gt;</comment>
                            <comment id="14334481" author="lhofhansl" created="Tue, 24 Feb 2015 06:23:36 +0000"  >&lt;p&gt;How often do I have to try fix this?! This is the third time &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14334488" author="stack" created="Tue, 24 Feb 2015 06:35:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;So that would be 20 minutes during which we would not be able to commit a flush or finish a compaction.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;1. In above case, how many column families, and if &amp;gt; 1, how much of the 20minutes was spent in each CF. If CF == 1, then there were probably no flushes nor compactions going on anyways.  If CF &amp;gt; 1, were there even any flushes/compactions going on (were they needed)? I&apos;d argue the patch proposed here probably makes the situation no worse when we have a scanner stuck down deep inside an HRegion for 20 minutes at a time.&lt;br/&gt;
2. Ain&apos;t a scanner stuck for 20minutes a different issue altogether than the one being solved here?  If a scan disappears for 20 minutes trying to pull out a row, can&apos;t we do something like the &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; chunking patch only we have it time based?  We return a partial &amp;#8211; even if empty &amp;#8211; if scanning for a full minute say?&lt;/p&gt;

&lt;p&gt;The region was probably really big. In hbase 2.0 we want to move to realm where regions are small.  This patch is therefore good for 2.0 anyways?&lt;/p&gt;

&lt;p&gt;It would be cool if we could do the lock on a Store-basis, especially given we not can flush at the Store level.&lt;/p&gt;
</comment>
                            <comment id="14334491" author="lhofhansl" created="Tue, 24 Feb 2015 06:38:49 +0000"  >&lt;p&gt;Wait. A. Minute... The scenario that I describe above already happens with the current code. StoreScanner.next(List&amp;lt;Cells&amp;gt;) would loop - with the look held - until either we found a row worth of data or exhausted the entire store. If the region has only one CF that could mean the entire region is scanned.&lt;/p&gt;

&lt;p&gt;So my change would not make it much worse, but cause any other stores of the region not be able to flush/compact during that time.&lt;/p&gt;

&lt;p&gt;(I also see what the issue with the comparison is, if the ts of the cell falls before the minStamp of the we seek to the next column... We&apos;ll do this over and over again. But that&apos;s for a different jira).&lt;/p&gt;

&lt;p&gt;So back to this.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Advantage: Much better scan performance, that can be even measure in 25% higher disk read rate. (will try with rotating disks tomorrow)&lt;/li&gt;
	&lt;li&gt;Disadvantage: a slow scan that does not match any cell in &lt;b&gt;any&lt;/b&gt; store (CF) can prevent &lt;b&gt;other&lt;/b&gt; stores in the region from flushing/compacting until the slow scan finished.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Worth doing?&lt;/p&gt;</comment>
                            <comment id="14334495" author="stack" created="Tue, 24 Feb 2015 06:43:46 +0000"  >&lt;p&gt;See my post just before yours &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=larsh&quot; class=&quot;user-hover&quot; rel=&quot;larsh&quot;&gt;larsh&lt;/a&gt;.  Yes, it is worth doing.  As you have argued elsewhere, lets not check millions of times a second for an event that only happens once an hour if that.  It would be better if the lock were Store-scoped but can do that after this.&lt;/p&gt;</comment>
                            <comment id="14334496" author="stack" created="Tue, 24 Feb 2015 06:44:13 +0000"  >&lt;p&gt;Oh, you have a test? I can try it over here. Would like to see diff in perf counters.&lt;/p&gt;</comment>
                            <comment id="14334504" author="lhofhansl" created="Tue, 24 Feb 2015 06:56:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;how many column families&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Just one.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;when we have a scanner stuck down deep inside an HRegion for 20 minutes at a time.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I agree. The scanner must have been stuck at the StoreScanner level anyway (per my analysis above)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ain&apos;t a scanner stuck for 20minutes a different issue altogether than the one being solved here? If a scan disappears for 20 minutes trying to pull out a row, can&apos;t we do something like the Jonathan Lawlor chunking patch only we have it time based? We return a partial &#8211; even if empty &#8211; if scanning for a full minute say?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Problem is that in this case the scanner produced no result at all. I suppose we can time in the StoreScanner and return an empty result (just as we would when we exhausted the region). RegionScanner will do the right thing. But then when I do the patch, the RegionScannerImpl also needs to periodically release the lock to give other threads a chance to continue with a flush.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It would be cool if we could do the lock on a Store-basis, especially given we not can flush at the Store level.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Where we place lock is not the so much the issue. It&apos;s how often we lock and unlock the lock.&lt;/p&gt;</comment>
                            <comment id="14334518" author="lhofhansl" created="Tue, 24 Feb 2015 07:14:09 +0000"  >&lt;p&gt;I have a pretty hand-rigged tests.&lt;br/&gt;
Here&apos;s a simple test in form of a unit test that you can run. (same as the one in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10015&quot; title=&quot;Replace intrinsic locking with explicit locks in StoreScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10015&quot;&gt;&lt;del&gt;HBASE-10015&lt;/del&gt;&lt;/a&gt;). Fails in the end and reports runtime and std deviation as the error message.&lt;/p&gt;</comment>
                            <comment id="14335502" author="apurtell" created="Tue, 24 Feb 2015 21:38:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;For example Phoenix does not lock RegionScanner.nextRaw() and required in the documentation&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Note, we just fixed that in &lt;a href=&quot;https://issues.apache.org/jira/browse/PHOENIX-1672&quot; title=&quot;RegionScanner.nextRaw contract not implemented correctly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PHOENIX-1672&quot;&gt;&lt;del&gt;PHOENIX-1672&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14335515" author="apurtell" created="Tue, 24 Feb 2015 21:46:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;Problem is that in this case the scanner produced no result at all. I suppose we can time in the StoreScanner and return an empty result (just as we would when we exhausted the region). RegionScanner will do the right thing.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I proposed something like this on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13090&quot; title=&quot;Progress heartbeats for long running scanners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13090&quot;&gt;&lt;del&gt;HBASE-13090&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14335636" author="stack" created="Tue, 24 Feb 2015 23:12:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jonathan.lawlor&quot; class=&quot;user-hover&quot; rel=&quot;jonathan.lawlor&quot;&gt;Jonathan Lawlor&lt;/a&gt; What you think on above? What you think of keeping a timer. What happens if we return a Result w/ nothing in it?  Will scan still proceed?&lt;/p&gt;</comment>
                            <comment id="14335701" author="jonathan.lawlor" created="Wed, 25 Feb 2015 00:10:31 +0000"  >&lt;p&gt;As it stands, whenever a client scanner receives results back from an RPC it will check its size and caching limits. If neither of those limits have been reached, the scanner assumes that the current region has been exhausted and it will try to change regions. Thus, if we return an empty Result (i.e. a Result with no cells in it) back to the scanner, it will see that neither limit has been reached and will try to change the region. Also, the client side Scanner will blindly add that result to the client side cache. The problem there is that at some point, the user would call ClientScanner#next() and receive a blank Result.&lt;/p&gt;

&lt;p&gt;In the case of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; (rpc chunking), I prevent the region change in the event that partial results are returned because it means that there are still Results left in the region. As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; has pointed out in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13090&quot; title=&quot;Progress heartbeats for long running scanners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13090&quot;&gt;&lt;del&gt;HBASE-13090&lt;/del&gt;&lt;/a&gt;, a similar concept could be borrowed here &amp;#8211; if the Result that is returned is flagged as a timer_heartbeat Result  (or something along those lines), skip the region change and continue to make RPC&apos;s until we have exhausted the region (when regions are completely exhausted, the RPC will return 0 Results to the client). This would likely require some sort of flag in the Result data structure so that the ClientScanner understands that it should continue to scan against the current region.&lt;/p&gt;
</comment>
                            <comment id="14338000" author="lhofhansl" created="Thu, 26 Feb 2015 06:46:48 +0000"  >&lt;p&gt;The StoreScanner.next() loop we can simply exit after some time limit with a empty result but returning true (i.e. more rows expected). That would be the same that happens when we exhaust the region, the region scanner will continue.&lt;/p&gt;

&lt;p&gt;In RegionScanner we could do the same and return a special indicator that the client just ignores (as described above). I guess what&apos;s tricky coprocessors that wrap a region scanner (such as Phoenix does). They&apos;d have to honor the protocol and pass the marker results to the client (or at the very least ignore them).&lt;/p&gt;

&lt;p&gt;Let&apos;s do that in another jira, though.&lt;/p&gt;

&lt;p&gt;This patch will not make things worse in principle. A store scanner can be stuck exhausting the entire store in a single next(...) call while holding the lock, prevent flushes from finishing. See extremely long scan times we&apos;ve seen have other reasons too - see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13109&quot; title=&quot;Make better SEEK vs SKIP decisions during scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13109&quot;&gt;&lt;del&gt;HBASE-13109&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
The only detriment this patch can cause is that one store scanner is stuck this way, and now prevent other stores in the region from flushing/compacting. (and note that that is only the case when no Cells in the store are returned by the store scanner).&lt;/p&gt;</comment>
                            <comment id="14339788" author="lhofhansl" created="Fri, 27 Feb 2015 06:24:41 +0000"  >&lt;p&gt;We have three problems:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;StoreScanner is locked too often&lt;/li&gt;
	&lt;li&gt;If StoreScanner.next(List&amp;lt;Cell&amp;gt;) does not find any Cells (for example if they do not match timerange or filter) it will exhaust the entire store while holding the lock, preventing flushes/compactions from finishing&lt;/li&gt;
	&lt;li&gt;Client can timeout even though the server is still working, because the server does not currently indicate that it is working but just not returning anything.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This patch is for #1. We can fix #2 in many cases by just returning an empty result after some number of iterations - but we &lt;b&gt;only&lt;/b&gt; do that if we not found any Cells for the current row, otherwise we need to finish the row, i.e.  find the next row (which of course could then exhaust the region if we&apos;re unlucky).&lt;br/&gt;
But note that the solution for #2 would &lt;b&gt;clash&lt;/b&gt; with this patch. With this patch it is no longer the lock on StoreScanner that protects it from concurrent flushes, but the synchronized on RegionScannerImpl, and that we cannot easily let without actually returning something back to the client.&lt;br/&gt;
#3 would only work with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; since we still need to be able to guarantee entire rows to the client, but if we break out of the loops because we did not find any Cell after some time we do not know whether we do a whole row or not.&lt;/p&gt;

&lt;p&gt;So in reality all these things look like need to be fixed together. Given that neither #2 nor #3 can be satisfactorily fixed without &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt;, I propose doing a bit more testing on patch, and then committing this here. Then we fix #3 (which would incidentally also fix #2 after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11544&quot; title=&quot;[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11544&quot;&gt;&lt;del&gt;HBASE-11544&lt;/del&gt;&lt;/a&gt; is in).&lt;/p&gt;</comment>
                            <comment id="14339789" author="lhofhansl" created="Fri, 27 Feb 2015 06:25:09 +0000"  >&lt;p&gt;Reattaching patch for testing.&lt;/p&gt;</comment>
                            <comment id="14339802" author="lhofhansl" created="Fri, 27 Feb 2015 06:47:40 +0000"  >&lt;p&gt;In other tests I find the gain about 41ns per row and per core (you can see how the results drift more with more cores in use above).&lt;br/&gt;
Above I measured 66ns. So scanning 10m rows, we&apos;d save 0.4-0.6s, 100m rows that&apos;d be 4-6s, and with 1bn rows it&apos;d add up to 40-60s.&lt;br/&gt;
(Note that in tests above I scanned about 11m rows/s when using all 8 cores/HTs on my box)&lt;/p&gt;</comment>
                            <comment id="14339878" author="hadoopqa" created="Fri, 27 Feb 2015 08:29:57 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12701281/13082.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12701281/13082.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 458846ef7b0528cb7952c413694eaf55c5d94342.&lt;br/&gt;
  ATTACHMENT ID: 12701281&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestStoreScanner&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestProcessBasedCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportExport&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestAtomicOperation&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.testRegionMerge(TestNamespaceAuditor.java:308)&lt;br/&gt;
	at org.apache.hadoop.hbase.TestAcidGuarantees.testMixedAtomicity(TestAcidGuarantees.java:364)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/12994//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14341946" author="stack" created="Sun, 1 Mar 2015 05:26:02 +0000"  >&lt;p&gt;I ran small test w/ this patch applied on 1.0 branch.&lt;/p&gt;

&lt;p&gt;Had ten processes each with ten clients each running on one machine doing random scans against another machine hosting a regionserver. Each scan was of 1000 rows. The dataset was 100M rows made of ten columns of data where the data was zipfian between 0 and 8k; so ten random colums w/ max of 8k. Its PE scan1000.&lt;/p&gt;

&lt;p&gt;First, no surprise, we are pegged at about 650% of CPU when about 1600 available (TODO). Otherwise, the graphs show a hike in scan next ops of a nice 10-15% with patch applied. More interesting is the GC profile.  With the patch applied, we do way less GC (looking at patch, locks are creating lots of objects &amp;#8211; haven&apos;t looked..)&lt;/p&gt;</comment>
                            <comment id="14341954" author="lhofhansl" created="Sun, 1 Mar 2015 05:54:01 +0000"  >&lt;p&gt;Thanks Mr. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. The GC part is interesting, not something I had expected, a nice bonus &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Maybe because we don&apos;t force the CPU to place memory fences and sync cache lines a million times a second that has some effect on GC - I would not understand immediately why, though.&lt;/p&gt;</comment>
                            <comment id="14342578" author="stack" created="Mon, 2 Mar 2015 01:10:50 +0000"  >&lt;p&gt;Other notes. I tried the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt; patch. It had a profile like this one, almost as good (scan next count and lowered GC profile) so a postive there. I then tried compounding this patch and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt; but its like we are up against a wall.  I doubled the scanner count and next counts actually went down (GC went up). Thread dumping gives little clue. Let me add profiler to figure more on why.&lt;/p&gt;</comment>
                            <comment id="14342581" author="lhofhansl" created="Mon, 2 Mar 2015 01:13:53 +0000"  >&lt;p&gt;Sorry, you saying after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt; this patch makes things slower? How&apos;d you test? Same way you tested yesterday?&lt;/p&gt;</comment>
                            <comment id="14342587" author="stack" created="Mon, 2 Mar 2015 01:19:16 +0000"  >&lt;p&gt;A combined patch, this and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt;, is slower instead of being a compound of the benefits this patch adds and the benefits &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt; adds. It is like we go over a perf hill and on the otherside of the hill, we slow. Let me poke some more. Will post more pictures.&lt;/p&gt;</comment>
                            <comment id="14342699" author="stack" created="Mon, 2 Mar 2015 04:11:12 +0000"  >&lt;p&gt;The fourth spike is the combined patch; more gc and less nexts&apos;. Will look more tomorrow.&lt;/p&gt;

&lt;p&gt;I think we should commit this patch to 2.0 and 1.1.&lt;/p&gt;</comment>
                            <comment id="14342740" author="lhofhansl" created="Mon, 2 Mar 2015 04:52:51 +0000"  >&lt;p&gt;Not if it makes things slower &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Not sure how not taking a bunch of locks and deferring to an already existing lock could ever make things slower - &lt;b&gt;unless&lt;/b&gt; the lock is contended and we increased the contention this way (which we&apos;re not).&lt;/p&gt;</comment>
                            <comment id="14342755" author="stack" created="Mon, 2 Mar 2015 05:10:47 +0000"  >&lt;p&gt;Argh. It makes things faster.  So does &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt;. Its when I put the two together that I see slowdown.  I&apos;ll look more into it.&lt;/p&gt;</comment>
                            <comment id="14342765" author="lhofhansl" created="Mon, 2 Mar 2015 05:20:26 +0000"  >&lt;p&gt;Oh I get that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
What I meant to say is that under no circumstances should fewer locks be slower than more unless there is contention. Lemme lock at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13071&quot; title=&quot;Hbase Streaming Scan Feature&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13071&quot;&gt;&lt;del&gt;HBASE-13071&lt;/del&gt;&lt;/a&gt; to see if something sticks out.&lt;/p&gt;

&lt;p&gt;Also check out &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13109&quot; title=&quot;Make better SEEK vs SKIP decisions during scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13109&quot;&gt;&lt;del&gt;HBASE-13109&lt;/del&gt;&lt;/a&gt;. Not entirely related, but it finally solves the SKIP vs. SEEK performance issues that have been plaguing us (SEEK is inefficient unless it can at least seek into the next block).&lt;/p&gt;

&lt;p&gt;With these three we should see some nice perf gains for scanning.&lt;/p&gt;</comment>
                            <comment id="14345596" author="stack" created="Tue, 3 Mar 2015 19:38:25 +0000"  >&lt;p&gt;Ok, redid the testing. The way to read the graphs is that the first two humps are us up against a scan &quot;ceiling&quot; where I had many clients trying to max out the regionserver (pushing out about 1Gbs and using about 5/6 of 16 cores). The second two are simple client with just two scan threads running.&lt;/p&gt;

&lt;p&gt;The humps are nopatch/patched/patched/nopathed (it was easier to do it this way).&lt;/p&gt;

&lt;p&gt;With the patch there is perhaps slightly less GC and perhaps slightly more throughput &amp;#8211; not as dramatic as first compares.&lt;/p&gt;

&lt;p&gt;+1 on commit to master. I think you should put it in 1.1. too.&lt;/p&gt;</comment>
                            <comment id="14345633" author="lhofhansl" created="Tue, 3 Mar 2015 19:58:33 +0000"  >&lt;p&gt;So this will mostly help with &quot;analytics&quot; type scans (where most data is filtered/aggregate - f.e. with Phoenix) at the server. Once we return data back to client for each row and measure the whole roundtrip it&apos;ll be vastly dominated by other inefficiencies there.&lt;/p&gt;

&lt;p&gt;Is that how you tested (filtering at server)? (This should also lower CPU cost for compactions.)&lt;/p&gt;</comment>
                            <comment id="14345801" author="stack" created="Tue, 3 Mar 2015 21:49:56 +0000"  >&lt;p&gt;Test described above, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082?focusedCommentId=14341946&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14341946&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-13082?focusedCommentId=14341946&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14341946&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Graphs are macro view. Patch doesn&apos;t seem to slow stuff down (smile).&lt;/p&gt;</comment>
                            <comment id="14346005" author="lhofhansl" created="Tue, 3 Mar 2015 23:30:36 +0000"  >&lt;p&gt;That&apos;s a plus &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14349791" author="lhofhansl" created="Fri, 6 Mar 2015 02:04:09 +0000"  >&lt;p&gt;Did some more tests with Phoenix.&lt;br/&gt;
In a case with 5 columns the gain is moderate but measurable (5-10%). For a table with only 1 column this shaves of 30-35%.&lt;br/&gt;
4m rows in both cases, all aggregates, i.e. all the work is at the server. This shows that this translates to wins even when the &quot;filtering&quot; is done up at the coprocessor level.&lt;/p&gt;

&lt;p&gt;The only reason why I am still hesitant on this one is that we&apos;ll now be forced to keep the RegionScanner lock in the future. I do not actually see a reason to get rid of it, but still...&lt;/p&gt;</comment>
                            <comment id="14350787" author="stack" created="Fri, 6 Mar 2015 19:45:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;The only reason why I am still hesitant on this one is that we&apos;ll now be forced to keep the RegionScanner lock in the future. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1. Commit. Go for it. Undoing the locks is a good thing (tm). It cleans up old lazy thinking and shows the way forward.&lt;/p&gt;

&lt;p&gt;That the lock is too coarse, we can work on later especially after flush-by-store gets done; then flush and compaction can be made purely Store-scoped.&lt;/p&gt;</comment>
                            <comment id="14350808" author="lhofhansl" created="Fri, 6 Mar 2015 20:00:02 +0000"  >&lt;p&gt;Alright... Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. I&apos;ll target 1.1+.&lt;/p&gt;</comment>
                            <comment id="14350867" author="lhofhansl" created="Fri, 6 Mar 2015 20:46:34 +0000"  >&lt;p&gt;Pushed to 1.1 and 2.0.&lt;/p&gt;</comment>
                            <comment id="14351034" author="hudson" created="Fri, 6 Mar 2015 22:25:32 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6217 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6217/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6217/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; Coarsen StoreScanner locks to RegionScanner. (larsh: rev ec1eff9b69d37d2340f057361d2b269cc5fffd56)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NonLazyKeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14351079" author="hudson" created="Fri, 6 Mar 2015 22:50:22 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.1 #254 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.1/254/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.1/254/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; Coarsen StoreScanner locks to RegionScanner. (larsh: rev 02522615d186e900de39c22d61d6592113f3d134)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NonLazyKeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14351100" author="lhofhansl" created="Fri, 6 Mar 2015 23:14:37 +0000"  >&lt;p&gt;Huh? Lemme double check the test failures. The preCommit did not indicate those.&lt;/p&gt;</comment>
                            <comment id="14351102" author="lhofhansl" created="Fri, 6 Mar 2015 23:16:34 +0000"  >&lt;p&gt;Well, actually it did... Missed it. Looking...&lt;/p&gt;</comment>
                            <comment id="14351103" author="lhofhansl" created="Fri, 6 Mar 2015 23:17:28 +0000"  >&lt;p&gt;I&apos;ll revert until I can work out what the issue is. Sorry about this.&lt;/p&gt;</comment>
                            <comment id="14351117" author="lhofhansl" created="Fri, 6 Mar 2015 23:27:22 +0000"  >&lt;p&gt;Reverted... Meh &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14351119" author="lhofhansl" created="Fri, 6 Mar 2015 23:29:28 +0000"  >&lt;p&gt;For reference, here&apos;s the rebased patch that I had committed (and subsequently reverted)&lt;/p&gt;</comment>
                            <comment id="14351125" author="hudson" created="Fri, 6 Mar 2015 23:32:21 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.1 #255 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.1/255/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.1/255/&lt;/a&gt;)&lt;br/&gt;
Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; Coarsen StoreScanner locks to RegionScanner.&quot; (larsh: rev c8610ce36f398f74aefbe46c3f65fcc9a6b4e394)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NonLazyKeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14351310" author="hudson" created="Sat, 7 Mar 2015 01:52:18 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #6219 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6219/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6219/&lt;/a&gt;)&lt;br/&gt;
Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; Coarsen StoreScanner locks to RegionScanner.&quot; (larsh: rev 5845f72ad60a7a7f5a04c01b68d841c78c38f79a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NonLazyKeyValueScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueScanner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14351919" author="lhofhansl" created="Sun, 8 Mar 2015 05:53:23 +0000"  >&lt;p&gt;Found the issue. It&apos;s a race where a compaction or a flush finishes after a StoreScanner is created, but before the readerLock could be set.&lt;/p&gt;

&lt;p&gt;Dah... Obvious in hindsight. The readerLock has to be set before the StoreScanner registers itself with addChangedReaderObserver.&lt;br/&gt;
It&apos;s not immediately obvious how to do that without changing the StoreScanner construction, which will break some coprocessors that use preScannerOpen hooks.&lt;br/&gt;
The again StoreScanner is private. So it&apos;s OK. Lemme post a new patch with a changed StoreScanner constructor.&lt;/p&gt;</comment>
                            <comment id="14351933" author="lhofhansl" created="Sun, 8 Mar 2015 06:16:18 +0000"  >&lt;p&gt;This one does pass TestAtomicOperation. But see how nasty it is.&lt;br/&gt;
Coprocessors now have to take care of setting the lock, if they don&apos;t everything is going to work until a scanner interleaves with a flush/compaction. That one could get an NPE, or if the wrong lock was set, wrong data could silently be returned.&lt;br/&gt;
(Although it &lt;b&gt;is&lt;/b&gt; clear from the StoreScanner&apos;s constructor that the lock needs to be passed).&lt;/p&gt;</comment>
                            <comment id="14351936" author="lhofhansl" created="Sun, 8 Mar 2015 06:22:37 +0000"  >&lt;p&gt;The other option is pull the readerChangeNotification subscription out and have the region scanner do that. That way - as long as a RegionScannerImpl is ultimately used - the lock would be set automatically.&lt;/p&gt;</comment>
                            <comment id="14352399" author="hadoopqa" created="Mon, 9 Mar 2015 01:24:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12703275/13082-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12703275/13082-v3.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 76cbf7da650d5858cc4a29a9efc5c64610c09f8b.&lt;br/&gt;
  ATTACHMENT ID: 12703275&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 12 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1931 checkstyle errors (more than the master&apos;s current 1930 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestStoreScanner&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.testBaseCases(TestCoprocessorScanPolicy.java:113)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13140//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14352510" author="lhofhansl" created="Mon, 9 Mar 2015 04:02:15 +0000"  >&lt;p&gt;TestStoreScanner fails, because we have special constructors &lt;b&gt;only&lt;/b&gt; used in testing. Meh.&lt;/p&gt;</comment>
                            <comment id="14352526" author="lhofhansl" created="Mon, 9 Mar 2015 04:15:53 +0000"  >&lt;p&gt;Fixes TestStoreScanner, but TestFromClientsideWithCoprocessor still hangs.&lt;/p&gt;</comment>
                            <comment id="14352600" author="hadoopqa" created="Mon, 9 Mar 2015 06:20:20 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12703356/13082-v4.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12703356/13082-v4.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 0fba20471e66b8cc1b1152a6ae5965e09ebbe6ce.&lt;br/&gt;
  ATTACHMENT ID: 12703356&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 15 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1931 checkstyle errors (more than the master&apos;s current 1930 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.testBaseCases(TestCoprocessorScanPolicy.java:113)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-rest.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/newPatchFindbugsWarningshbase-annotations.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/13141//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14353288" author="lhofhansl" created="Mon, 9 Mar 2015 18:00:19 +0000"  >&lt;p&gt;To fix TestFromClientSideWithCoprocessor I need to change the coprocessor API for preStoreScannerOpen in order to pass the correct lock object in.&lt;/p&gt;</comment>
                            <comment id="14355381" author="apurtell" created="Tue, 10 Mar 2015 18:18:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;To fix TestFromClientSideWithCoprocessor I need to change the coprocessor API for preStoreScannerOpen in order to pass the correct lock object in.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s unfortunate. &lt;/p&gt;

&lt;p&gt;We could introduce a new API and use the compatibility trick &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt; did in RegionCoprocessorHost for dispatching to old APIs if the CP has methods with the old signature. Can we have the RegionCoprocessorHost set the lock member on the returned StoreScanner if the old API was used? Should be safe, the consumer of the new API shouldn&apos;t be &lt;b&gt;changing&lt;/b&gt; the lock object, just using it. Coprocessors using the old API might not lock where they should, but this may or may not be a problem depending on what they want to do, and we could print a big fat warning if we need to dispatch to the old API. Coprocessors updated to use the new API will be fine.&lt;/p&gt;</comment>
                            <comment id="14377404" author="lhofhansl" created="Tue, 24 Mar 2015 06:55:27 +0000"  >&lt;p&gt;Here&apos;s another idea. I think it has been suggested before, but anyway... What if we had a versioned data structure that kept of the &lt;em&gt;currently&lt;/em&gt; visible files? Each time we compact/flush/bulkload, we create a new version of this. In the background we retire older versions that are no longer in use by any scanner. If that leads to any HFile no longer being used by any scanner we archive them.&lt;/p&gt;

&lt;p&gt;Scanners only need to reference the current version upon creation and and release the reference upon closing (or leas expiry). Since everything is versioned flushes/compaction can proceed immediately. New scanner will see the new data, old scanner will work on the old files. The only downside is that we&apos;ll hold on to older files until all scanners using them have finished.&lt;/p&gt;</comment>
                            <comment id="14377564" author="anoop.hbase" created="Tue, 24 Mar 2015 09:28:05 +0000"  >&lt;p&gt;If scanners can continue read from the old files, it can continue to use the data from cache (if that file blocks were in cache). Otherwise a compaction will result in need for scan from a new file whose data is not in cache. (Assume no cache on write)   I was also thinking on this especially wrt Cache usage..&lt;/p&gt;</comment>
                            <comment id="14378169" author="lhofhansl" created="Tue, 24 Mar 2015 17:10:32 +0000"  >&lt;p&gt;Exactly.&lt;br/&gt;
Logically it&apos;s relatively simple. Folding this into the current HBase will be more tricky. Some kind of abstraction around StoreFileManager providing a versioned view of all currently visible HFiles for the store.&lt;/p&gt;</comment>
                            <comment id="14378784" author="stack" created="Tue, 24 Mar 2015 22:21:54 +0000"  >&lt;p&gt;I ran this patch on my rig and see ~6-7% more throughput (high concurrency, scan1000, medium-sized rows), 7750k/s vs 8250k/s. No big CPU difference that I can discern... perhaps smoother with this patch in place.&lt;/p&gt;</comment>
                            <comment id="14378969" author="lhofhansl" created="Wed, 25 Mar 2015 00:05:19 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. That&apos;s with 1000 bytes values, right? The cost saving is per row, so the smaller the rows the higher the gain (percentage-wise)&lt;/p&gt;</comment>
                            <comment id="14379235" author="stack" created="Wed, 25 Mar 2015 03:38:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; 10 columns zipfian sized from 0 to 8k.&lt;/p&gt;</comment>
                            <comment id="14379236" author="stack" created="Wed, 25 Mar 2015 03:39:20 +0000"  >&lt;p&gt;Sorry.. average size about 180k rows. So, yeah, probably better benefits when smaller cells.&lt;/p&gt;</comment>
                            <comment id="14503889" author="jonathan.lawlor" created="Mon, 20 Apr 2015 23:00:58 +0000"  >&lt;p&gt;I&apos;m a little late to the party but this versioned data structure sounds neat. If I&apos;m understanding correctly, it sounds like this versioned data structure would also allow us to remove the lingering lock in updateReaders (and potentially remove updateReaders completely?). Instead of having to update the readers, the compaction/flush would occur in the background and be made visible to new readers via a new &quot;latest&quot; version in the data structure, is that correct? In other words, would the introduction of this new versioned data structure make StoreScanner single threaded (and thus remove any need for synchronization)?&lt;/p&gt;</comment>
                            <comment id="14504350" author="lhofhansl" created="Tue, 21 Apr 2015 05:19:42 +0000"  >&lt;p&gt;Correct. No more locking other than to fix the current version of access data structure at the beginning of the scan, and StoreScanner would indeed be single threaded (which is it 99.9999% of the already &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ). That would be bigger change.&lt;/p&gt;</comment>
                            <comment id="14564821" author="anoop.hbase" created="Fri, 29 May 2015 13:41:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=larsh&quot; class=&quot;user-hover&quot; rel=&quot;larsh&quot;&gt;larsh&lt;/a&gt; are you working on the idea of scanners continue to read from old files when a compaction happened?  Otherwise I can look at it.&lt;/p&gt;</comment>
                            <comment id="14565613" author="lhofhansl" created="Fri, 29 May 2015 22:58:01 +0000"  >&lt;p&gt;I am backed up at the moment, would love if you had a look at it.&lt;/p&gt;</comment>
                            <comment id="14934572" author="ram_krish" created="Tue, 29 Sep 2015 03:39:04 +0000"  >&lt;p&gt;Any one planning to work on this.  I am planning to take this up if there is no one working on it currently. Thoughts?&lt;/p&gt;</comment>
                            <comment id="14934574" author="stack" created="Tue, 29 Sep 2015 03:42:56 +0000"  >&lt;p&gt;Please bring it home &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; Its an important one.&lt;/p&gt;</comment>
                            <comment id="14934576" author="ram_krish" created="Tue, 29 Sep 2015 03:44:19 +0000"  >&lt;p&gt;Thanks Stack.  Better to go ahead with the versioned way of reading.  Will look into it and get back here.&lt;/p&gt;</comment>
                            <comment id="14934759" author="lhofhansl" created="Tue, 29 Sep 2015 07:07:17 +0000"  >&lt;p&gt;Feel free &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;. I just happened to look at the code again a few days ago, we need to fix this.&lt;/p&gt;</comment>
                            <comment id="14940078" author="ram_krish" created="Thu, 1 Oct 2015 17:09:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m a little late to the party but this versioned data structure sounds neat. If I&apos;m understanding correctly, it sounds like this versioned data structure would also allow us to remove the lingering lock in updateReaders (and potentially remove updateReaders completely?). &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I totally agree and can see this is going to happen after this change is done.   &lt;br/&gt;
Just wanted to confirm one thing ,&lt;br/&gt;
In case of compaction it is old data but in new file. So there is no problem.  But in case of bulk loaded files, currently in between a scan if a new file is bulk loaded it gets included, so after this it will not be. is that behavioral change fine? &lt;/p&gt;</comment>
                            <comment id="14945926" author="stack" created="Tue, 6 Oct 2015 22:11:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;But in case of bulk loaded files, currently in between a scan if a new file is bulk loaded it gets included, so after this it will not be. is that behavioral change fine?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, say more &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;. So, bulk load won&apos;t show mid-scan... you have to get to the end? That would be fine.&lt;/p&gt;

&lt;p&gt;On the patch, can we get more of Lars comments in on what is going on .... Could we get rid of some of these getReaderLocks too... in hstorefile, in hstore, etc.... would be good to not let this stuff out if we can.&lt;/p&gt;
</comment>
                            <comment id="14946193" author="ram_krish" created="Wed, 7 Oct 2015 04:02:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;So, bulk load won&apos;t show mid-scan... you have to get to the end? That would be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;New files added by bulk load during an on going scan won&apos;t be included in the current scan.  The new files will be included only when a new scan is started.  Currently during a course of a scan the bulk loaded files can be included too. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On the patch, can we get more of Lars comments in on what is going on .... Could we get rid of some of these getReaderLocks too... in hstorefile, in hstore, etc.... would be good to not let this stuff out if we can.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes we can.  I have a working version of a patch.  Some issues with Merge regions and splits.  Working on them. All the locks will be removed that are currently in StoreScanner and also the notifyReaders() will also go away totally. Just because we are updating the readers during a course of a scan we needed all those locks. &lt;/p&gt;</comment>
                            <comment id="14946198" author="stack" created="Wed, 7 Oct 2015 04:07:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;New files added by bulk load during an on going scan won&apos;t be included in the current scan. The new files will be included only when a new scan is started. Currently during a course of a scan the bulk loaded files can be included too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That makes more sense than our current implementation IMO.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yes we can. I have a working version of a patch. Some issues with Merge regions and splits. Working on them. All the locks will be removed that are currently in StoreScanner and also the notifyReaders() will also go away totally. Just because we are updating the readers during a course of a scan we needed all those locks.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sweet.&lt;/p&gt;</comment>
                            <comment id="14954527" author="ram_krish" created="Tue, 13 Oct 2015 07:10:09 +0000"  >&lt;p&gt;	Parking a work in progress patch.  With my previous patches corrected most of the test cases. Still few are failing. Looking into them.  &lt;br/&gt;
The patch introduces a state inside the StoreFile and marks the reader if it is COMPACTED or NOT_COMPACTED. Every time a scanner uses the storefile we also increment a ref count. Any scanner getting created will try to check the state and if the state is COMPACTED then those files will not be used by the scanner instead only the new file created after compaction will be added. All the COMPACTED files will be cleared by a background chore service that is instantiated per store and that will clean up the store files that are in COMPACTEd state and also that those that has ref count as 0.&lt;/p&gt;</comment>
                            <comment id="14956291" author="ram_krish" created="Wed, 14 Oct 2015 05:20:15 +0000"  >&lt;p&gt;For HadoopQA.&lt;/p&gt;</comment>
                            <comment id="14956369" author="hadoopqa" created="Wed, 14 Oct 2015 06:44:52 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12766471/HBASE-13082_2_WIP.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12766471/HBASE-13082_2_WIP.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit e5580c247c06d8c708b92e96a5622853ec06a77d.&lt;br/&gt;
  ATTACHMENT ID: 12766471&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 71 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1756 checkstyle errors (more than the master&apos;s current 1748 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +    Collection&amp;lt;StoreFileInfo&amp;gt; storeFileInfosForRegion = fs.getStoreFiles(store.getColumnFamilyName());&lt;br/&gt;
+        int cleanerInterval = conf.getInt(&quot;hbase.hfile.compactions.cleaner.interval&quot;, 5 * 60 * 1000);&lt;br/&gt;
+    return StoreUtils.hasCompactedReferences(this.storeEngine.getStoreFileManager().getStorefiles());&lt;br/&gt;
+    boolean mayBeStuck = (nonCompactedCandidateSelection.size() - filesCompacting.size() + futureFiles)&lt;br/&gt;
+    LOG.debug(&quot;Selecting compaction from &quot; + nonCompactedCandidateSelection.size() + &quot; store files, &quot; +&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): &lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15997//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14958671" author="ram_krish" created="Thu, 15 Oct 2015 10:16:47 +0000"  >&lt;p&gt;Patch for QA. Tried out an approach where thought of maintaining two lists - one the current storefiles and the other the compacted files. But maintaining two lists felt error prone and hence going with single list of storefiles but each store file exposes an API isCompacted that helps to identify if the storefile and the reader associated with it can be used by the readers and if they are compacted or not. &lt;/p&gt;</comment>
                            <comment id="14958882" author="hadoopqa" created="Thu, 15 Oct 2015 13:22:35 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12766763/HBASE-13082_3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12766763/HBASE-13082_3.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit e7defd7d9a76f44e3089db3fe522fe400fe6dcd7.&lt;br/&gt;
  ATTACHMENT ID: 12766763&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 78 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.compactions.TestCompactionWithThroughputController&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestCompactionWithCoprocessor&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTool&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestMobStoreCompaction&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide3&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestStore&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRolling&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestCompactionState&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestMergeTable&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestCompaction&lt;br/&gt;
                  org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 5 zombie test(s): 	at org.apache.hadoop.hbase.backup.TestHFileArchiving.testArchiveOnTableFamilyDelete(TestHFileArchiving.java:322)&lt;br/&gt;
	at org.apache.hadoop.hbase.replication.TestReplicationSmallTests.testDisableEnable(TestReplicationSmallTests.java:308)&lt;br/&gt;
	at org.apache.hadoop.hbase.replication.regionserver.TestReplicationWALReaderManager.test(TestReplicationWALReaderManager.java:190)&lt;br/&gt;
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation.testExcessReservationWillBeUnreserved(TestContainerAllocation.java:359)&lt;br/&gt;
	at org.apache.hadoop.hbase.replication.TestReplicationSyncUpTool.testSyncUpTool(TestReplicationSyncUpTool.java:178)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16025//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14960541" author="ram_krish" created="Fri, 16 Oct 2015 11:34:39 +0000"  >&lt;p&gt;Updated patch. All test cases corrected except for TestStore.  Am not getting the error that comes here in the report. Will try once more. &lt;/p&gt;</comment>
                            <comment id="14960548" author="ram_krish" created="Fri, 16 Oct 2015 11:44:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/39393/-&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/39393/-&lt;/a&gt; RB link.&lt;/p&gt;</comment>
                            <comment id="14960851" author="hadoopqa" created="Fri, 16 Oct 2015 15:07:14 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12767056/HBASE-13082_4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12767056/HBASE-13082_4.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 30cf4e3761e95f3cceaf8c1aa154695e18198cd6.&lt;br/&gt;
  ATTACHMENT ID: 12767056&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 102 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1750 checkstyle errors (more than the master&apos;s current 1747 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +  private Map&amp;lt;byte[], List&amp;lt;Pair&amp;lt;Boolean, StoreFile&amp;gt;&amp;gt;&amp;gt; doClose(final boolean abort, MonitoredTask status)&lt;br/&gt;
+                public Pair&amp;lt;byte[], Collection&amp;lt;Pair&amp;lt;Boolean, StoreFile&amp;gt;&amp;gt;&amp;gt; call() throws IOException {&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.compactions.TestCompactionWithThroughputController&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestStore&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRolling&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16065//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14960961" author="stack" created="Fri, 16 Oct 2015 16:23:37 +0000"  >&lt;p&gt;This is an important fix. I started to look at the rb and then got lost on why we were doing certain things. I started to read over the issue but the issue has been going on for a long time with us flip/flopping over whether this a good idea or not, lists of why this issue is good and then downsides, and then stuff like the scan implementation changed while this issue was going on. I think a one-pager is in order so can see in one place current approach, upsides and downsides.... and that we have this before we do the code (or at least, it looks like with this last patch, that we are trying an experiment &amp;#8211; which is sweet... lets factor the findings back into the one-pager). With a one-pager, we&apos;ll be able to do a better review. Thanks.&lt;/p&gt;</comment>
                            <comment id="14961093" author="ram_krish" created="Fri, 16 Oct 2015 17:59:16 +0000"  >&lt;p&gt;Next week beginning I will upload a one pager. Thanks Stack.&lt;/p&gt;</comment>
                            <comment id="14963126" author="ram_krish" created="Mon, 19 Oct 2015 10:36:30 +0000"  >&lt;p&gt;A simple one pager indicating what is the high level approach to the versioned store file approach. &lt;/p&gt;</comment>
                            <comment id="14963297" author="anoop.hbase" created="Mon, 19 Oct 2015 13:30:07 +0000"  >&lt;p&gt;So we wont reset the heap of the files during the scan.  Compaction case is fine.. the versioned approach and we wont move the old compacted files until the scanners finished will do the solution.  What about flush?   Once the flush is finished, we will have to clear the snapshot of cells in Memstore no?  Then we will have to open this newly added file for reading.. If we dont open it, we can not release the memstore snapshot.  Means we will have to keep the cells as long as the scanner completes!  That will not be acceptable IMO.&lt;/p&gt;</comment>
                            <comment id="14963400" author="anoop.hbase" created="Mon, 19 Oct 2015 14:39:19 +0000"  >&lt;p&gt;Good doc explaining the change.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Along with the ref count, we also have CompactionStatus (COMPACTED and NON_COMPACTED) added to these store file readers&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This status is in reader? It suits better in StoreFile no? Even the ref count is in reader? I would say it is better suited in StoreFile.  That call the state as Compacted we better call it as a file to be discarded?  When we mark a file as compacted the confusion can be like whether this file is a file created out of compaction. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ensure that a background thread runs periodically runs that scans the list of store files and checks for the state as COMPACTED...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is a new Chore thread adding to the system..  Mention about it clearly. It will be one thread per RS. Also what is its interval? Is it configurable? How?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hence it requires us to add new APIs which ensures that a split can go ahead even if reference files are present but they are in the COMPACTED state&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;hmm.. making this more complex &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14963502" author="ram_krish" created="Mon, 19 Oct 2015 15:56:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;What about flush? Once the flush is finished, we will have to clear the snapshot of cells in Memstore no? Then we will have to open this newly added file for reading.. If we dont open it, we can not release the memstore snapshot. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We do open the reader for sure. But one thing may be to check is that if we open but still the current scanner heap is not reset will it have any impact on the current scan is what needs to be checked?  Because during flush the reads can still be served from the snapshot. Only after flush is a point to be noted. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This status is in reader? It suits better in StoreFile no?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The reader is the common object here.  Hence was referencing it from there. Initially had it in storefile only but felt that StoreFile is more volatile. Let me check. Can be done.  Infact I was also not very sure of having the state in the reader. &lt;br/&gt;
We can change the states no problem.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This is a new Chore thread adding to the system.. Mention about it clearly. It will be one thread per RS. Also what is its interval? Is it configurable? How?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Forgot to add that config details. It is per store and the chore is started by the HStore and not the RS.  It can be configured may be once in 2 mins or so?  currently in patch it is once in 5 min.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Hence it requires us to add new APIs which ensures that a split can go ahead even if reference files are present but they are in the COMPACTED state&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is bit of sticky area.  In case of merge I have tried to forcefully clear the compacted files. May be we need to do the same with split also. But in split do we explicitly call compact?  I was not pretty sure on that. But in merge we do. &lt;/p&gt;
</comment>
                            <comment id="14963558" author="anoop.hbase" created="Mon, 19 Oct 2015 16:22:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;But one thing may be to check is that if we open but still the current scanner heap is not reset will it have any impact on the current scan is what needs to be checked?  Because during flush the reads can still be served from the snapshot&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes during the process of flush (before the new file got committed) we will serve the scan from the snapshot. Then we will call clearSnapshot which will remove the cells from memory.  So we must include the new file into the heap. Else we can not release the snapshot until the scanner is done. That will be too costly for us as we will tend to keep the cells in memory for much longer time and also which is not in our control.&lt;br/&gt;
So we wont change the store file&apos;s heap during the scan is not really possible?&lt;/p&gt;</comment>
                            <comment id="14963561" author="ram_krish" created="Mon, 19 Oct 2015 16:23:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;Because during flush the reads can still be served from the snapshot. Only after flush is a point to be noted.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is a concern. Though we are able to complete the flush from the snapshot since the files cannot be added to the storescanner&apos;s heap that could be a problem. &lt;/p&gt;</comment>
                            <comment id="14963858" author="ram_krish" created="Mon, 19 Oct 2015 19:00:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;So we wont change the store file&apos;s heap during the scan is not really possible?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think our comments were published at the same time and in between JIRA was down. Still I think we can do this for a pure bulk loaded case. &lt;/p&gt;</comment>
                            <comment id="14963860" author="ram_krish" created="Mon, 19 Oct 2015 19:02:45 +0000"  >&lt;p&gt;But again if handling flushes is a problem then resetting the heap should be done at any case. &lt;/p&gt;</comment>
                            <comment id="14964005" author="stack" created="Mon, 19 Oct 2015 20:34:47 +0000"  >&lt;p&gt;The one pager is great (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;!). Nice summary of the issue up top. Explanation of the approach your fix takes helps. &lt;/p&gt;

&lt;p&gt;I am trying to understand the COMPACTED vs NON_COMPACTED state. Is NON_COMPACTED a freshly-flushed file? Is a COMPACTED file a file that is made up of N other storefiles and you want to make sure the scan doesn&apos;t include duplicated info &amp;#8211; the compacted file and the compactions inputs?&lt;/p&gt;

&lt;p&gt;Or I think you are saying that when a file is COMPACTED, then its content can be found in another file and so it should not be included in a scan? Should the state be COMPACTED_AWAY or REPLACED (by file...). Do we need the NON_COMPACTED state? It is the default. No need to call this state anything (Active?)&lt;/p&gt;

&lt;p&gt;How can the following happen? &quot;Now in case of the versioned storefile approach change, there is a chance that there are reference files which are not yet archived after compaction because of the change in the store file management.&quot;&lt;/p&gt;

&lt;p&gt;Where will you write the COMPACTED_AWAY state? In memory or into the file? (I suppose you can&apos;t write it to the file because it is already written)&lt;/p&gt;

&lt;p&gt;Doc is great &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;&lt;/p&gt;


</comment>
                            <comment id="14964031" author="stack" created="Mon, 19 Oct 2015 20:51:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;When we mark a file as compacted the confusion can be like whether this file is a file created out of compaction.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, that was my first thought too... same as Anoop.&lt;/p&gt;

&lt;p&gt;Is that a new Chore per Store per Region?  Every two minutes seems like a long time to hold on to files?&lt;/p&gt;

&lt;p&gt;Yeah, this is a good point by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What about flush? .....So we wont change the store file&apos;s heap during the scan is not really possible?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The other thing to consider is getting bulk loaded files in here while scans are going on. Seems like they could go in on open of a new scan. That&apos;ll work nicely. A file will be bullk loaded but won&apos;t be seen by ongoing scans.&lt;/p&gt;

&lt;p&gt;The hard thing then is what to do about flush (we&apos;ve been here before!)&lt;/p&gt;

&lt;p&gt;On flush, what if we let all Scans complete before letting go the snapshot? More memory pressure. Simpler implementation.&lt;/p&gt;

&lt;p&gt;Otherwise, flush registers it has happened at the region level. Scanners check for flush events every-so-often (we already have checkpoints in the scan to ensure we don&apos;t go over size or time constraints... could check at these times) and when they find one, they swap in the flushed file. When all Scanners have done this, then we let go the snapshot.  This might be a different sort of event to the one described in the doc here..  where we swap in compacted files on new scan creation.. but yeah, implementation would be cleaner if swap in of flushed files and compacted files all happened in the one manner.&lt;/p&gt;


</comment>
                            <comment id="14964476" author="anoop.hbase" created="Tue, 20 Oct 2015 04:03:26 +0000"  >&lt;p&gt;Not getting cells from bulk loaded files which is loaded in btw a scan seems ok and seems that is the correct way.&lt;br/&gt;
Regarding flush&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On flush, what if we let all Scans complete before letting go the snapshot? More memory pressure. Simpler implementation&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes simple but heap pressure will be much more. And when the scan will get over is not really in our hands. I dont think we can think of doing this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
The other option you said seems fine.  We need to see how this will look.. Will be much more complex..  &lt;br/&gt;
So how much is the perf gain we get by fully avoiding this lock?  Worth of doing all these complex stuff. I think it is still worth as the gain may be high.&lt;br/&gt;
And this will allow to make full use of the cached blocks of compacted files is another adv.&lt;/p&gt;

&lt;p&gt;Again nice doc Ram..  Just in 2 mins we can understand the whole change and why to do it.. Getting the impl details reading through the patch is much harder.  Thanks man.&lt;/p&gt;</comment>
                            <comment id="14964481" author="apache9" created="Tue, 20 Oct 2015 04:09:08 +0000"  >&lt;blockquote&gt;
&lt;p&gt;On flush, what if we let all Scans complete before letting go the snapshot? More memory pressure. Simpler implementation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;How much time a &lt;tt&gt;RegionScanner&lt;/tt&gt; can continue sometimes depends on the user of HBase. Think of a &lt;tt&gt;Filter&lt;/tt&gt; that matches nothing. A &lt;tt&gt;RegionScanner&lt;/tt&gt; could scan the whole region if that &lt;tt&gt;Filter&lt;/tt&gt; is applied. So I do not think having a ref count on snapshot is a good idea.&lt;/p&gt;

&lt;p&gt;So I think resetting heap is necessary when there is a flush, and the problem is how to do it without a expensive overhead? Maybe something like a Biased Locking?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="14964536" author="ram_krish" created="Tue, 20 Oct 2015 05:14:40 +0000"  >&lt;p&gt;We can rename the states to ACTIVE and DISCARDED or may be IN_ACTIVE something of this sort. &lt;br/&gt;
The NON_COMPACTED indicates that it is an ACTIVE file which can be used in reads.  COMPACTED indicates that it is no longer an active file and its contents are already copied to a new file.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Is that a new Chore per Store per Region? Every two minutes seems like a long time to hold on to files?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya it is a per store per region.  But I think we need to pass the region details for selecting only those files pertaining to that region. Or do you think it is better to start this per region? &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Now in case of the versioned storefile approach change, there is a chance that there are reference files which are not yet archived after compaction because of the change in the store file management.&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;My thinking was that once split is done - we will have reference files still they are removed by compaction.  Now since we don&apos;t immediately remove the compacted files and depend on the cleaner to do it, there is a chance that when the next split occurs (may be due to user issuing split)  there may be reference files but they are actually in the COMPACTED state (here i mean they are IN_ACTIVE or DISCARDED state) and we can safely proceed with splits? &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Otherwise, flush registers it has happened at the region level. Scanners check for flush events every-so-often (we already have checkpoints in the scan to ensure we don&apos;t go over size or time constraints... could check at these times) and when they find one, they swap in the flushed file. When all Scanners have done this, then we let go the snapshot.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This seems fine but again swapping in the flushed file into the current scan will need to us to hold the locks?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So how much is the perf gain we get by fully avoiding this lock? Worth of doing all these complex stuff. I think it is still worth as the gain may be high.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was able to get 10-12% latency gain just by using the PE tool with default load. In that  case all the contents were flushed and only pure reads/scans were issued. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So I think resetting heap is necessary when there is a flush, and the problem is how to do it without a expensive overhead? Maybe something like a Biased Locking?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Biased locking - yes. You mean a new type of lock implementaion?  By default JVM works with biased locking enabled or did you mean something else?  In latest processors Re-entrant locking is considered to be much efficient. &lt;br/&gt;
&lt;a href=&quot;http://mechanical-sympathy.blogspot.in/2011/11/java-lock-implementations.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://mechanical-sympathy.blogspot.in/2011/11/java-lock-implementations.html&lt;/a&gt;.&lt;/p&gt;
</comment>
                            <comment id="14964555" author="apache9" created="Tue, 20 Oct 2015 05:30:27 +0000"  >&lt;p&gt;I mean maybe we could have a fast path without locking for normal reading since for most scan operation there is no flush involved. And if a flush happen, then we change back to use a lock. I think this is something like a BiasedLock?&lt;/p&gt;</comment>
                            <comment id="14964567" author="ram_krish" created="Tue, 20 Oct 2015 05:42:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;I mean maybe we could have a fast path without locking for normal reading since for most scan operation there is no flush involved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I thought on this but not sure run time if we can decide this. But may be if we can say that use my scan only on files then this feature can easily be used. Already we have something like InternalScan#checkOnlyStoreFiles(). So that can be an indicator. But need to see how the client can specify this. So we can have two types of StoreScanner one which is lock free and other one with lock. Ideally only for the flush case we need this lock behaviour whereas the compactions and bulkload can still go with the versioned approach. &lt;/p&gt;</comment>
                            <comment id="14964695" author="ram_krish" created="Tue, 20 Oct 2015 07:23:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;This status is in reader? It suits better in StoreFile no?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The reason for doing this (I just now checked the code once again) is because when we create a scanner on the Storefile we do it on the reader associated with the Storefile and not on the store file.  So hence do determine whether this store file can be used in the scanner or not the state and ref count if it is in the reader it will be easy to use that info. Already info like isBulkLoad and setSeqId everything is happening on the reader now and not on the StoreFile. So may be if we can introduce a getStoreFileScanner at the Storefile level rather than the Reader as how it is currently is, then we can make this change of adding the ref count and the state to the StoreFile. &lt;/p&gt;</comment>
                            <comment id="14979769" author="ram_krish" created="Thu, 29 Oct 2015 04:02:41 +0000"  >&lt;p&gt;Regarding the memstore files getting updated in the current scanner, I think we can solve it this way - let me try to explain here&lt;br/&gt;
In the current code &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lock.writeLock().lock();
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeEngine.getStoreFileManager().insertNewFiles(sfs);
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (snapshotId &amp;gt; 0) {
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.memstore.clearSnapshot(snapshotId);
      }
    } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
      &lt;span class=&quot;code-comment&quot;&gt;// We need the lock, as &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; as we are updating the storeFiles
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// or changing the memstore. Let us release it before calling
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// notifyChangeReadersObservers. See HBASE-4485 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a possible
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// deadlock scenario that could have happened &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; to hold
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// the lock.
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lock.writeLock().unlock();
    }
    notifyChangedReadersObservers();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As you can see that before we notify the observer we clear the snapshot. So this notification wil try to hold the storescanner&apos;s lock and do the heap nullify and the scanner will continue to reset the heap seeing it to be null every time it enters any scanner API like next(), seek() etc.  So here if there is an ongoing scanner going on assume it is in StoreScanner#next() it would have already held the lock and so the notify has to wait for nullifying the heap. So though the snapshot is cleared the storescanner operates on the older reference of the snapshot which cannot be GCed till the current scanner finishes the current API operation. &lt;br/&gt;
So we can change this logic slightly in such a way that let the flush code set a volatile boolean in all the StoreScanner ( the observers). Note that the flush also has cleared the snapshot but still the reference cannot be GCed. Now the current on going scanner every time it enters the scan APIs like next(), seek(), reseek() etc. check for the volatile boolean if it is true. If so, it means that the flush has happened so go ahead and nullfiy the heap and create a new heap. All this will be done by the Storescanner itself. Note that within a storescanner it is always single threaded. &lt;br/&gt;
Now even while entering a scan API if the scanner does not see the volatile boolean as true - it will continue to use the existing heap only and the scan will&lt;br/&gt;
still work because we have the older memstore snapshot ref that is not yet GCed - (similar to how things work now).  So this is more of a lazy  model and there may be lag in nullifying the heap and resetting it but should be okie considering the existing way things work.  Thoughts?!!&lt;/p&gt;</comment>
                            <comment id="14980263" author="ram_krish" created="Thu, 29 Oct 2015 11:06:06 +0000"  >&lt;p&gt;One interesting part while doing this is that of the Secondary replicas.  As per the idea of read replicas the same underlying store file will be having a reader from the Secondary region always opened. In the current code whenever we refreshStoreFiles we close the reader that we think is no longer needed. So the archiving of the file if done by the primary region will be successul. But now after this change we cannot do that because we need the file to be available and only the compacted file cleaner can close the reader.  Now there are two case&lt;br/&gt;
If suppose the compacted file cleaner has not closed the reader then the secondary region will have a reader opened on the file and so any external archive option will fail. &lt;br/&gt;
Similarly though the compacted file cleaner will close the reader and try to archive the compacted file still if there is a reader opened by the secondary region this archival will fail. Anyway the next cleaner thread will make it successful.  So may be need to see if there are any other implications. &lt;/p&gt;</comment>
                            <comment id="14982561" author="ram_krish" created="Fri, 30 Oct 2015 13:31:10 +0000"  >&lt;p&gt;After doing the code changes and testing it in a single node cluster found that having a single List&amp;lt;StoreFile&amp;gt; in the StorefileManager and adding all the newly compacted files and not removing the older one till the compaction chore runs - creates some problems like in flush where we try to count the storefiles count and decide if there are so many files and wait for the compaciton to compact it. Now if we have one single list we are bound to iterate thro the list and find if each of the file is already compacted by checking its state and then return the count based on that. It may be costlier operation and also considering the fact that all the test cases depend on the count - the patch becomes bigger. So instead if we maintain two lists one for the actual store files and other one for the compacted files and the compaction cleaner will remove the files from the comapcted list - things should work fine. Just attaching a patch for QA - some more things am just verifying. &lt;/p&gt;</comment>
                            <comment id="14982585" author="hadoopqa" created="Fri, 30 Oct 2015 13:52:50 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12769780/HBASE-13082_9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12769780/HBASE-13082_9.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 23fa18184cb68ca05246beb2189f8801200bdd7c.&lt;br/&gt;
  ATTACHMENT ID: 12769780&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 38 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16307//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16307//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14983897" author="ram_krish" created="Sat, 31 Oct 2015 08:11:42 +0000"  >&lt;p&gt;Updated patch for Hadoop QA. Previous patch did not apply cleanly.&lt;/p&gt;</comment>
                            <comment id="14983917" author="hadoopqa" created="Sat, 31 Oct 2015 09:38:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12769932/HBASE-13082_9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12769932/HBASE-13082_9.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 683f84e6a217dfd872e5f1be82c7aa4cdf232ec1.&lt;br/&gt;
  ATTACHMENT ID: 12769932&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 38 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1731 checkstyle errors (more than the master&apos;s current 1730 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16332//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14988948" author="ram_krish" created="Wed, 4 Nov 2015 05:58:49 +0000"  >&lt;p&gt;Updated doc - adds some info on how we try to handle the flush cases and its updation on the active readers. Also some points to be noted on how Secondary replicas and primary replicas work after this change. &lt;/p&gt;</comment>
                            <comment id="14990872" author="enis" created="Thu, 5 Nov 2015 01:11:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;HDFS does not allow to rename if there are any active readers. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think this is how hdfs works. The FileLink.FileLinkInputStream is especially for this particular reason where an open file may get moved to a different directory. The way region replicas work is that they rely on having a high TTL for the hfiles so that even if primary replica compacts the file away and moves the file to the archive directory, the secondary replica will be able to still read from the archive location. &lt;/p&gt;

</comment>
                            <comment id="14990891" author="enis" created="Thu, 5 Nov 2015 01:22:24 +0000"  >&lt;p&gt;The volatile check is still a memory fence barrier similar to the lock although much less expensive. Were you able to profile this implementation similar to Lars&apos; numbers above? &lt;/p&gt;</comment>
                            <comment id="14991079" author="ram_krish" created="Thu, 5 Nov 2015 04:00:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;The way region replicas work is that they rely on having a high TTL for the hfiles so that even if primary replica compacts the file away and moves the file to the archive directory, the secondary replica will be able to still read from the archive location.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Is it?  So is that because my tests are running in the Windows environment (I mean my Junits) this issue occurs.  But one thing is that after this patch comes in - the Secondary replica does not close the reader when an update happens on the secondary region. I have not yet run this secondary replica thing in my Linux box still but I found even in linux some junits failed due to this behaviour. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-      &lt;span class=&quot;code-comment&quot;&gt;// let the archive util decide &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we should archive or delete the files
&lt;/span&gt;-      LOG.debug(&lt;span class=&quot;code-quote&quot;&gt;&quot;Removing store files after compaction...&quot;&lt;/span&gt;);
-      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (StoreFile compactedFile : compactedFiles) {
-        compactedFile.closeReader(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
-      }
-      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (removeFiles) {
-        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.fs.removeStoreFiles(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.getColumnFamilyName(), compactedFiles);
-      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;&lt;p&gt;The volatile check is still a memory fence barrier similar to the lock although much less expensive. Were you able to profile this implementation similar to Lars&apos; numbers above?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I did some basic PE tool runs. I got 6 to 7% improvement. This is the case where it is pure read (scan workload on the server side with filterAll enabled) and there were no compactions or flushes. I can do some more tests on a bigger load and I think the main advantage of this patch is going to be with scans rather than gets if am not wrong. &lt;br/&gt;
The other advantage of this patch is that because we use the older files only after compactions we avoid the reset and reseek on those new compacted files and other files already in heap. Discussing with Anoop, even for flushes we can ensure that instead of reset we can only allow the heap to be changed and ensure only the new flushed file we do a seek to the current key the scaner was at which the memstore was flushed. But that can be done as a later improvement. &lt;br/&gt;
Thanks Enis for your reviews. &lt;/p&gt;</comment>
                            <comment id="14991115" author="ram_krish" created="Thu, 5 Nov 2015 04:35:43 +0000"  >&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; your point makes sense.  In current approach, if the primary compacts a file it closes the reader and archives it but still the secondary may be having a reader on that file but the archiving process is successful. So I think even in the current updated design things should work as now.  &lt;/p&gt;</comment>
                            <comment id="14991542" author="ram_krish" created="Thu, 5 Nov 2015 11:10:56 +0000"  >&lt;p&gt;I just saw this&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (FSUtils.WINDOWS) {
      &lt;span class=&quot;code-comment&quot;&gt;// compaction cannot move files &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; they are open in secondary on windows. Skip remaining.
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In one of the test case - so may this is what I was observing. Anyway will verify once in linux box also. &lt;/p&gt;</comment>
                            <comment id="14991667" author="lhofhansl" created="Thu, 5 Nov 2015 13:42:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;The volatile check is still a memory fence barrier similar to the lock although much less expensive. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right. The locks are not the problem, it&apos;s the memory barriers on every call to next and pretty that cause the  performance issue. The locks are (almost) never contended. The point was to lock once for the scan, and then use the versioned access proxy without locking.&lt;br/&gt;
Cool that even with the volatile it&apos;s faster, though!&lt;/p&gt;</comment>
                            <comment id="14992285" author="enis" created="Thu, 5 Nov 2015 19:16:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;In one of the test case - so may this is what I was observing. Anyway will verify once in linux box also.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeah, when FS is local filesystem on windows, the rename while having readers does not work. If fs is hdfs on top of windows, it works. This particular unit test is using the local file system, hence the workaround needed, but in production, we are not using ntfs as a local fs, we are using hdfs on top of ntfs. &lt;/p&gt;</comment>
                            <comment id="14993245" author="ram_krish" created="Fri, 6 Nov 2015 07:03:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;The locks are not the problem, it&apos;s the memory barriers on every call to next and pretty that cause the performance issue. The locks are (almost) never contended&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes Lars. I too agree with this.  I am trying to profile before I could come to any conclusion on the memory barrier that this volatile introduces. &lt;br/&gt;
 Ideally for the compaction cases we don&apos;t even need the notifying mechansim and can always be going on without any locks or resets of the heap but for flushes we may need it because if we don&apos;t reset then the flushed snapshot cannot be GCed and if this is going to be bigger scans then may lead to GC issues. Other than that as you always say Scanner is &amp;gt;99% single threaded.&lt;/p&gt;</comment>
                            <comment id="14993568" author="ram_krish" created="Fri, 6 Nov 2015 12:14:53 +0000"  >&lt;p&gt;Attaching an updated PDF that removes the point on the secondary replicas and the cleaner archiving the primary replicas compacted files.&lt;/p&gt;</comment>
                            <comment id="14993571" author="ram_krish" created="Fri, 6 Nov 2015 12:18:35 +0000"  >&lt;p&gt;Updated patch for QA.  This has all the mentioned things in the doc. One feedback not yet done here is that the fileStatus  - DISCARDED and ACTIVE is set with the REader in the StoreFile. This is because the inner class Reader in store file is designed in such a way that even if we want the scanner associated with this store file we need to operate on this Reader obejct rather than store file. So it is better the file status remains there I thought. Any way feed back welcome!!. will post the patch in RB too.&lt;br/&gt;
With PE tool and with 10G data and all in cache i could see around 70 to 90 secs difference in completion time on an average. (purely measuring the server side gain).&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./hbase org.apache.hadoop.hbase.PerformanceEvaluation --nomapred --oneCon=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;  --caching=5000 --filterAll=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; --rows=10000  scanRange10000 50
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="14993688" author="hadoopqa" created="Fri, 6 Nov 2015 13:52:18 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12771006/HBASE-13082_12.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12771006/HBASE-13082_12.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit bfa36891901b96b95d82f5307642c35fd2b9f534.&lt;br/&gt;
  ATTACHMENT ID: 12771006&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 46 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1728 checkstyle errors (more than the master&apos;s current 1726 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.TestHeapSize&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16429//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14995524" author="ram_krish" created="Sun, 8 Nov 2015 05:17:04 +0000"  >&lt;p&gt;Updated patch for QA. Just saw that the QA failed. &lt;/p&gt;</comment>
                            <comment id="14995572" author="hadoopqa" created="Sun, 8 Nov 2015 09:39:46 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12771229/HBASE-13082_13.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12771229/HBASE-13082_13.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 305ecaf224340b0f6e248d4fdabf0b53e1cd3b03.&lt;br/&gt;
  ATTACHMENT ID: 12771229&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 46 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1728 checkstyle errors (more than the master&apos;s current 1726 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16451//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14996072" author="ram_krish" created="Mon, 9 Nov 2015 06:06:21 +0000"  >&lt;p&gt;The test failure seems unrelated&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
TEST-org.apache.hadoop.hbase.coprocessor.TestMasterObserver.xml.&amp;lt;init&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Other test cases related to region replicas also seems to run fine.&lt;br/&gt;
The checkstyle comments (minor) have been fixed. Submitting once again for QA.&lt;/p&gt;</comment>
                            <comment id="14996209" author="hadoopqa" created="Mon, 9 Nov 2015 08:44:34 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12771291/HBASE-13082_14.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12771291/HBASE-13082_14.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 1cbcf1175e6ce497936f12c60fb2e897833ace39.&lt;br/&gt;
  ATTACHMENT ID: 12771291&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 46 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16455//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14999932" author="ram_krish" created="Wed, 11 Nov 2015 04:38:12 +0000"  >&lt;p&gt;Ping for reviews !! Will do some more tests with YCSB today. &lt;/p&gt;</comment>
                            <comment id="15000264" author="ram_krish" created="Wed, 11 Nov 2015 11:30:09 +0000"  >&lt;p&gt;Withpatch&lt;br/&gt;
=======&lt;br/&gt;
Avg: 324secs&lt;br/&gt;
Withoutpatch&lt;br/&gt;
===========&lt;br/&gt;
Avg : 410secs&lt;br/&gt;
Using the command&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./hbase org.apache.hadoop.hbase.PerformanceEvaluation --nomapred --oneCon=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;  --caching=5000 --filterAll=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; --rows=10000  scanRange10000 50
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;With YCSB scanRange can see that there is no significant gain because of network bottleneck but there is no degrade. &lt;br/&gt;
Withpatch&lt;br/&gt;
========&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;OVERALL&amp;#93;&lt;/span&gt;, Throughput(ops/sec), 3752.08334427691&lt;br/&gt;
Withoutpatch&lt;br/&gt;
==========&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;OVERALL&amp;#93;&lt;/span&gt;, Throughput(ops/sec), 3723.210569152307&lt;/p&gt;

</comment>
                            <comment id="15000270" author="ram_krish" created="Wed, 11 Nov 2015 11:32:35 +0000"  >&lt;p&gt;Attaching a JPEG showing the impact of the unlock in the StoreScanner.peek() with and without patch.&lt;/p&gt;</comment>
                            <comment id="15006602" author="ram_krish" created="Mon, 16 Nov 2015 12:32:02 +0000"  >&lt;p&gt;Ping for reviews. !!! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;. Once this is in we can try to do the sub task of reseeking only to the newly flushed file on scanner reset instead of all the files. &lt;/p&gt;</comment>
                            <comment id="15015253" author="ram_krish" created="Fri, 20 Nov 2015 05:36:59 +0000"  >&lt;p&gt;Did some JMH microbenchmark test by executing fixed set of code in a loop under 4 different conditions &lt;br/&gt;
1) With a reentrant lock&lt;br/&gt;
2) with a synchronized block&lt;br/&gt;
3) with a volatile boolean check&lt;br/&gt;
4) with no locks/synchronizations/volaties&lt;/p&gt;

&lt;p&gt;This is the JMH result that I got&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Benchmark                                       Mode  Cnt     Score   Error  Units
LockVsSynchronized.operationUnderLock          thrpt    9    57.696 &#177; 0.322  ops/s
LockVsSynchronized.operationUnderSynchronized  thrpt    9    44.692 &#177; 0.333  ops/s
LockVsSynchronized.operationUnderVolatile      thrpt    9  1056.632 &#177; 5.584  ops/s
LockVsSynchronized.operationWithoutLock        thrpt    9  1428.580 &#177; 5.372  ops/s
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So we can see that when our operations are mostly single threaded and only at times we need the parallelism like when we want to reset the scanner stack, going with volatile is significantly faster than going with a read lock. (though it is not as fast as without lock).&lt;/p&gt;</comment>
                            <comment id="15015255" author="ram_krish" created="Fri, 20 Nov 2015 05:39:00 +0000"  >&lt;p&gt;This is the jmh class that I tried.  We just calculate a sum in a loop that runs for 1000000 times and the summation step is the one that is guarded by locks or synchronizations.&lt;/p&gt;</comment>
                            <comment id="15015281" author="stack" created="Fri, 20 Nov 2015 06:12:58 +0000"  >&lt;p&gt;An order of magnitude improvement * 2. Not bad &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ramkrishna&quot; class=&quot;user-hover&quot; rel=&quot;ramkrishna&quot;&gt;ramkrishna&lt;/a&gt;.  Thanks for the jmh patch too. Let me look at the actual patch....&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The NON_COMPACTED indicates that it is an ACTIVE file which can be used in reads. COMPACTED indicates that it is no longer an active file and its contents are already copied to a new file.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In this patch you still talk of &apos;compacted&apos;... &lt;/p&gt;

&lt;p&gt; /**&lt;br/&gt;
58	   * List of compacted files inside this store&lt;br/&gt;
59	   */&lt;br/&gt;
60	  private volatile ImmutableList&amp;lt;StoreFile&amp;gt; compactedfiles = null;&lt;/p&gt;

&lt;p&gt;These are files that are not to be included in a Scan, right. Need to update comment and rename variable else we&apos;ll stay confused.&lt;/p&gt;

&lt;p&gt;BUT, reading the patch and code I see why you are calling them compacted and think you are right to do do. You just need to explain better what they are when there is no context around (e.g. in comment on data member... no need to explain when inside addCompactionResult because plenty context here).&lt;/p&gt;

&lt;p&gt;Only one thread involved here?&lt;/p&gt;

&lt;p&gt;	  public ImmutableCollection&amp;lt;StoreFile&amp;gt; clearCompactedFiles() {&lt;/p&gt;


&lt;p&gt;Suggest you change this method to return the Collection rather than set the data member internall: i.e remove the &apos;set&apos; part from sortAndSetCompactedFiles  Do the set on return.  Methods like this with &apos;side effects&apos; can be tough to follow.&lt;/p&gt;

&lt;p&gt;nit: You know the size of the array to allocate here: 124	      newCompactedFiles = Lists.newArrayList(); ...&lt;/p&gt;

&lt;p&gt;Is the below the new &apos;terminology&apos;? &lt;/p&gt;

&lt;p&gt;6585	    // check if the references are cleared now by seeing if the ref files are in DISCARDED state&lt;br/&gt;
6586	    // There should be only one file in the ACTIVE state and that is the new file&lt;/p&gt;

&lt;p&gt;i.e. DISCARDED and ACTIVE?&lt;/p&gt;

&lt;p&gt;I don&apos;t follow how we were checking for references when we went to merge but in this patch it changes to a check for compactions:&lt;/p&gt;

&lt;p&gt;	6593	    List&amp;lt;StoreFile&amp;gt; compactedFiles = new ArrayList&amp;lt;StoreFile&amp;gt;();&lt;br/&gt;
6594	    for (Store s : dstRegion.getStores()) {&lt;br/&gt;
6595	      compactedFiles.clear();&lt;br/&gt;
6596	      if (!dstRegion.isCompacted((HStore) s, dstRegion.getRegionFileSystem())) &lt;/p&gt;
{
6597	        throw new IOException(&quot;Merged region &quot; + dstRegion
6598	            + &quot; still has files that are not yet compacted, is compaction canceled?&quot;);
6599	      }

&lt;p&gt;nit: change this &lt;/p&gt;

&lt;p&gt;	6630	    if (nonCompactedFiles &amp;gt; 1) &lt;/p&gt;
{
6631	      return false;
6632	    }
&lt;p&gt;6633	    return true;&lt;/p&gt;

&lt;p&gt;to: return nonCompactedFiles &amp;lt;= 1;&lt;/p&gt;

&lt;p&gt;Fix formatting here abouts if you are doing a new patch: 	    if (!SystemUtils.IS_OS_WINDOWS) {&lt;/p&gt;

&lt;p&gt;Got to HStore. Will be back.&lt;/p&gt;

</comment>
                            <comment id="15015321" author="stack" created="Fri, 20 Nov 2015 06:49:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;// Start the CompactedHFileCleaner here&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is new?&lt;/p&gt;

&lt;p&gt;Where we explain what it does?&lt;/p&gt;

&lt;p&gt;This comment is no longer correct, right?&lt;/p&gt;

&lt;p&gt;	    // notify scanners, close file readers, and recompute store size&lt;/p&gt;

&lt;p&gt;Has to be public because its in the Interface? Does it have to be:&lt;/p&gt;

&lt;p&gt;	  public Collection&amp;lt;StoreFile&amp;gt; getCompactedfiles() &lt;/p&gt;
{


Might want to note that expectation is that access on methods like this one are single-threaded: clearCompactedFiles

Do you have to stop the chore in the region or store close? Before you do your close?

Not your change but remove it since it obviously wrong now:     // 4. Compute new store size

Yeah, this needs better explaining especially if in an Interface

67	  /**
68	   * Get the compacted store files
69	   * @return the list of compacted files
70	   */
71	  Collection&amp;lt;StoreFile&amp;gt; getCompactedfiles();

You need these in the Interface?

475	  boolean isPrimaryReplicaStore();
476	
477	  /**
478	   * Closes and archives the compacted files under this store
479	   */
480	  void closeAndArchiveCompactedFiles() throws IOException;
481	
482	  /**
483	   * Close and archive the compacted files under this store
484	   * @param compactedStorefiles the list of compacted files
485	   */
486	  void closeAndArchiveCompactedFiles(List&amp;lt;StoreFile&amp;gt; compactedStorefiles) throws IOException;

Do they have to be so specific? Can they be made more generic?

Yeah, this is hard... we have both nomenclatures going on ... compacted and

	    ACTIVE, DISCARDED;
157	  }


&lt;p&gt;This is in the StoreFile.&lt;/p&gt;

&lt;p&gt;It seems like the compacted or not belongs in StoreFileInfo rather than in StoreFile. Is this fact persisted across open/close?&lt;/p&gt;

&lt;p&gt;Maybe &apos;compactedAway&apos;?&lt;/p&gt;

&lt;p&gt;Got as far as StoreFileManager.&lt;/p&gt;
</comment>
                            <comment id="15015577" author="ram_krish" created="Fri, 20 Nov 2015 10:45:15 +0000"  >&lt;p&gt;Thanks for the reviews Stack.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Need to update comment and rename variable else we&apos;ll stay confused.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Will update the comment and say that &apos;these files are not included in reads&apos;? The name &apos;compactedfiles&apos; is still better?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Only one thread involved here?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;public ImmutableCollection&amp;lt;StoreFile&amp;gt; clearCompactedFiles() {&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes it will be single threaded. Used only while closing the store files.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Suggest you change this method to return the Collection rather than set the data member internall: i.e remove the &apos;set&apos; part from sortAndSetCompactedFiles Do the set on return. Methods like this with &apos;side effects&apos; can be tough to follow.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Okie.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;You know the size of the array to allocate here: 124	newCompactedFiles = Lists.newArrayList(); ...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes done some refactoring there.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;DISCARDED and ACTIVE?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We will make it ACTIVE and COMPACTEDAWAY (as you suggested in another comment).?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I don&apos;t follow how we were checking for references when we went to merge but in this patch it changes to a check for compactions:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think you were referring to some old patch. The patch that was latest was _14.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Fix formatting here abouts if you are doing a new patch: if (!SystemUtils.IS_OS_WINDOWS) {&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is not there in the latest patch.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Where we explain what it does?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There is a javadoc explaining what it does.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;as to be public because its in the Interface? Does it have to be:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We access Store not directly from HStore but from Store.java. So it is better to add there and anyway this is going to be common for that store.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Might want to note that expectation is that access on methods like this one are single-threaded: clearCompactedFiles&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Okie.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Do you have to stop the chore in the region or store close? Before you do your close?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes good catch. Done now.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;void closeAndArchiveCompactedFiles(List&amp;lt;StoreFile&amp;gt; compactedStorefiles) throws IOException;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In my next version will remove this but keep the other one void closeAndArchiveCompactedFiles() throws IOException;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Do they have to be so specific? Can they be made more generic?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Generic in the sense?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;t seems like the compacted or not belongs in StoreFileInfo rather than in StoreFile. Is this fact persisted across open/close?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We cannot have this in StorefileInfo because we only cache the Storefile (in the StorefileManager) and not the StorefileInfo. StoreFileInfos are created every time from the hfile path.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Maybe &apos;compactedAway&apos;?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya we can have ACTIVE and COMPACTED_AWAY.?&lt;/p&gt;</comment>
                            <comment id="15018970" author="stack" created="Fri, 20 Nov 2015 22:46:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;Will update the comment and say that &apos;these files are not included in reads&apos;? The name &apos;compactedfiles&apos; is still better?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah. When I see the change in context, compactedfiles is good name.  You need to do a bunch of explaining of what there are though... and here is a good place to do it (&quot;List of the files that were replaced by new ones on compaction; will be deleted once there are no longer any references by ongoing scanners to these files...&quot;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...Used only while closing the store files.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;One threaded because close is done with a lock held, right.... that&apos;s good. Might just say on the method that caller needs to ensure single-thread-at-a-time access.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think you were referring to some old patch. The patch that was latest was _14.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Argh!!!! Was looking at v9. My fault.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Generic in the sense?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its ok. You removed one of the two methods. That is good enough.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We cannot have this in StorefileInfo because we only cache the Storefile (in the StorefileManager) and not the StorefileInfo. StoreFileInfos are created every time from the hfile path.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmmm... this don&apos;t seem right.  Ok for now but we should address this. If SFI, should be not confined in its use... we keep meta data sometimes in SFI and then other times we modify SF.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ya we can have ACTIVE and COMPACTED_AWAY.?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do we even need two states? Could we not just stamp a StoreFile STALE or COMPACTED_AWAY? A SF has this attribute or it does not. Do we even have to stamp the SF with this property at all? We are keeping a running list up in SFManager. Why we need this?&lt;/p&gt;

&lt;p&gt;Let me go back to v14. Will be back w/ more comments.&lt;/p&gt;






</comment>
                            <comment id="15021585" author="stack" created="Mon, 23 Nov 2015 06:22:37 +0000"  >&lt;p&gt;Looking at v14:&lt;/p&gt;

&lt;p&gt;Yeah, talk about how stuff is different now in the javadoc on compactedfiles... of how now we keep the files that were compacted away around rather than immediately archive IFF referenced by scanners.  Do it up here where compactedfiles is introduced.&lt;/p&gt;

&lt;p&gt;ImmutableList is a guava-ism? We want to use this in our APIs? (They tend to change faster than we do and we are on an old version of Guava &amp;#8211; we should update)&lt;/p&gt;

&lt;p&gt;Yeah, are these guava Immutable* in later versions of Guava?&lt;/p&gt;

&lt;p&gt;This bit repeated? Worth making a private method?&lt;/p&gt;

&lt;p&gt;	    ArrayList&amp;lt;StoreFile&amp;gt; newCompactedfiles = null;&lt;br/&gt;
133	    if (compactedfiles != null) &lt;/p&gt;
{
134	      newCompactedfiles = Lists.newArrayList(compactedfiles);
135	    }
&lt;p&gt; else &lt;/p&gt;
{
136	      newCompactedfiles = Lists.newArrayList();
137	    }

&lt;p&gt;i.e. return compactedFiles == null? Lists.newArrayList(): Lists.newArrayList(compactedfiles);&lt;/p&gt;

&lt;p&gt;Yeah, below has a side-effect. Instead return what was sorted and have the caller assign:&lt;/p&gt;

&lt;p&gt;	204	  private void sortAndSetCompactedFiles(List&amp;lt;StoreFile&amp;gt; storeFiles) &lt;/p&gt;
{
205	    // Sorting may not be really needed here for the compacted files?
206	    Collections.sort(storeFiles, StoreFile.Comparators.SEQ_ID);
207	    compactedfiles = ImmutableList.copyOf(storeFiles);
208	  }

&lt;p&gt;Yeah man, say what this does when it is introduced in HRegion:&lt;/p&gt;

&lt;p&gt;815	    // Start the CompactedHFileCleaner here&lt;/p&gt;

&lt;p&gt;Why every &apos;2&apos; minutes? Any reason? 5 minutes?&lt;/p&gt;

&lt;p&gt;Help me understand, so a file goes into the compactedfiles list but it may still have references... its refcount needs to go to zero.  Only when its refcount is zero can it be removed... so when you do this:&lt;/p&gt;

&lt;p&gt;	    // check if the references are cleared now by seeing if the ref files are in DISCARDED state&lt;/p&gt;

&lt;p&gt;You are looking at an enum? Why not just look at the refcount? Have a method isReferenced? Or isAliveStill? Or isInScan?&lt;/p&gt;

&lt;p&gt;Hmm... So, we need Store Interface to have 	  public Collection&amp;lt;StoreFile&amp;gt; getCompactedfiles() { because.. the cleaner is on the Region level? What if the Cleaner was on the Store level? We&apos;d not need to expose &apos;compactedfiles&apos; outside of Store? That could be cleaner?&lt;/p&gt;

&lt;p&gt;Yeah, these guava&apos;isms in our API ain&apos;t the best? Just return a List&amp;lt;StoreFile&amp;gt; and the fact that it is a guava ImmutableList is not exposed until someone tries to change the list externally... then they&apos;ll have a surprise.... that&apos;d be fine.&lt;/p&gt;

&lt;p&gt;This is a mouthful:&lt;/p&gt;

&lt;p&gt;isReadyForCloseAfterCompaction();&lt;/p&gt;

&lt;p&gt;Is this added in this patch? If so, closeAfterCompaction? or isCloseAfterCompaction?&lt;/p&gt;

&lt;p&gt;And shouldEvictOnClose should be evictOnClose?&lt;/p&gt;

&lt;p&gt;What is going on here?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
886	              ArrayList&amp;lt;StoreFile&amp;gt; filesToRemove = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;StoreFile&amp;gt;();
887	              &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (compacted) {
888	                filesToRemove.add(f);
889	                fs.removeStoreFiles(getFamily().getNameAsString(), filesToRemove);
890	                &lt;span class=&quot;code-comment&quot;&gt;// we already have the lock here.
&lt;/span&gt;891	                getStoreEngine().getStoreFileManager().removeCompactedFiles(filesToRemove);
892	                filesToRemove.clear();
893	                &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
894	              }
895	              res.add(f);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We make filesToRemove even if we may not use it it? i.e. compacted is false. We create this array to hold one file only? Then clear it?&lt;/p&gt;

&lt;p&gt;Yeah, this don&apos;t make sense anymore, at least not where it is now:&lt;/p&gt;

&lt;p&gt;	    // 4. Compute new store size&lt;/p&gt;


&lt;p&gt;Who calls this closeAndArchiveCompactedFiles ? The chore thread?&lt;/p&gt;

&lt;p&gt;We do a copy here and operate on the copy?&lt;/p&gt;

&lt;p&gt;2351	      Collection&amp;lt;StoreFile&amp;gt; copyCompactedfiles = Lists.newArrayList(compactedfiles);&lt;br/&gt;
2352	      removeCompactedFiles(copyCompactedfiles);&lt;/p&gt;

&lt;p&gt;Can the original change in the meantime? &lt;/p&gt;

&lt;p&gt;What is isReadyForCloseAfterCompaction ? Is it not after all references have gone away? It reads like it is close of the region or Store but sounds like it is close of the referencing Scanner?&lt;/p&gt;

&lt;p&gt;Why a lock here?&lt;/p&gt;

&lt;p&gt;	      lock.writeLock().lock();&lt;/p&gt;

&lt;p&gt;..down in archiveAndRemoveCompactedFiles? There are no references to the file, right?&lt;/p&gt;

&lt;p&gt;You are only going to expose one of the below, right?, in new patch?&lt;/p&gt;

&lt;p&gt;476	  /**&lt;br/&gt;
477	   * Closes and archives the compacted files under this store&lt;br/&gt;
478	   */&lt;br/&gt;
479	  void closeAndArchiveCompactedFiles() throws IOException;&lt;br/&gt;
480	&lt;br/&gt;
481	  /**&lt;br/&gt;
482	   * Close and archive the compacted files under this store&lt;br/&gt;
483	   * @param compactedStorefiles the list of compacted files&lt;br/&gt;
484	   */&lt;br/&gt;
485	   void closeAndArchiveCompactedFiles(Collection&amp;lt;StoreFile&amp;gt; compactedStorefiles)&lt;br/&gt;
486	     throws IOException;&lt;/p&gt;


&lt;p&gt;Yeah, do we need these at all since the StoreFile is being managed at a higher level?&lt;/p&gt;

&lt;p&gt;153	&lt;br/&gt;
154	  // Indicates whether the current store file is compacted or not&lt;br/&gt;
155	  private enum FileStatus &lt;/p&gt;
{
156	    ACTIVE, DISCARDED;
157	  }


&lt;p&gt;So, StoreFile#isCompacted, does that belong in StoreFile? Same with the refcounting? It really belongs in StoreFileInfo but you say that is not available here. Where is accounting being done then? Where higher up? Can it do refcounting and whether a file that is done?&lt;/p&gt;

&lt;p&gt;Yeah, compacted and refcount belong in StoreFileInfo and if not there, then wherever the storefiles are being referenced from.... doing it in StoreFile is not right.. .this is meta info on the StoreFile instances. StoreFileManager?&lt;/p&gt;

&lt;p&gt;Yeah, change this:&lt;/p&gt;

&lt;p&gt;  ImmutableCollection&amp;lt;StoreFile&amp;gt; clearCompactedFiles();&lt;/p&gt;

&lt;p&gt;Shoud return Collection&amp;lt;StoreFile&amp;gt; and internally you do the Immutable stuff (good practice)&lt;/p&gt;

&lt;p&gt;In StoreFileScanner, when would scanner be null?&lt;/p&gt;

&lt;p&gt;      if (scanner != null) {&lt;/p&gt;

&lt;p&gt;You don&apos;t set it null in close?&lt;/p&gt;

&lt;p&gt;Hopefully we get rid of this someday&lt;/p&gt;

&lt;p&gt;	  protected volatile boolean flushed = false;&lt;/p&gt;

&lt;p&gt;Maybe a timer on scans? If goes on longer than a minute have it return and then clean up compacted files.... New issue.&lt;/p&gt;

&lt;p&gt;Saving what I have so far.&lt;/p&gt;
</comment>
                            <comment id="15021586" author="ram_krish" created="Mon, 23 Nov 2015 06:24:38 +0000"  >&lt;p&gt;An updated patch for ease of review. Incorporates the latest set of comments and removes the two FileStatus (ACTIVE and DISCARDED).  Just uses a boolean now &apos;compactedAway&apos;.&lt;br/&gt;
Thanks for the reviews so far Stack. &lt;/p&gt;</comment>
                            <comment id="15021589" author="ram_krish" created="Mon, 23 Nov 2015 06:26:25 +0000"  >&lt;p&gt;Oops. Latest comments. I will check them too. Thanks. &lt;/p&gt;</comment>
                            <comment id="15021607" author="stack" created="Mon, 23 Nov 2015 06:38:26 +0000"  >&lt;p&gt;You think we need to do     checkFlushed(); on each seek call? Would doing it on next be enough? Does checkReseek end up calling seek? (Which calls checkFlushed?) Yeah, how often we calling checkFlushed?  The less the better.&lt;/p&gt;

&lt;p&gt;I love the removal of all those locks. Looks beautiful.&lt;/p&gt;

&lt;p&gt;Is checkFlushed the right name for the method? I see you set flushed to true in 670	    flushed = true; in  updateReaders ... so should it be checkReadersChanged or checkResetStoreFiles or something?&lt;/p&gt;

&lt;p&gt;Yeah, why call checkFlushed in shipped? Is that a good place to do it? I&apos;m wondering why we&apos;d call checkFlushed in any place but on the way out of a next call?&lt;/p&gt;

&lt;p&gt;Why is it a CompactedHFilesCleaner cleaner and not a HFileCleaner? Is it a Cleaner? It closes storefiles. Discharger as in it is discharging the hfile from duty... not it is eligable for archiving... and later delete? Or Acquiter&lt;/p&gt;

&lt;p&gt;I think this patch is almost there and its a very nice one.&lt;/p&gt;



</comment>
                            <comment id="15021609" author="stack" created="Mon, 23 Nov 2015 06:39:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Oops. Latest comments. I will check them too. Thanks.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry. Done now reviewing. Sorry for overlap. Patch is almost there I think. Lets get it in.&lt;/p&gt;</comment>
                            <comment id="15021943" author="ram_krish" created="Mon, 23 Nov 2015 10:57:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Do it up here where compactedfiles is introduced.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya okie. I will add it in StorefileManager where we introduce this compactedfiles. Also removed getCompactedfiles from the Store.java.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;ImmutableList is a guava-ism? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Removed the usage of guava API.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Yeah, below has a side-effect. Instead return what was sorted and have the caller assign:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya done.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Why every &apos;2&apos; minutes? Any reason? 5 minutes?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The TTLCleaner works every 5 mins for the secondary region replica. So before that we need to move the compacted files to the archive. Hence it is 2 mins.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;You are looking at an enum? Why not just look at the refcount? Have a method isReferenced? Or isAliveStill? Or isInScan?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I have changed these things now..  Also the logic is pretty much simple. Every time do a refCount increment while getting the files for scans. (We are going to do that only on the active Store files). Scan completiong will decrement the count. Once compacted done mark the boolean as compactedAway. So for compaction cleaner chore we only check if the count and the boolean is true. If so move it to archive.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So, we need Store Interface to have public Collection&amp;lt;StoreFile&amp;gt; getCompactedfiles() { &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not needed any more. Will use the StorefileManager API. I think configuring the Cleaner per region makes sense because the region can collectively issue the cleaner across all its stores. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Is this added in this patch? If so, closeAfterCompaction? or isCloseAfterCompaction?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;closeAfterCompaction() will be the name.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We make filesToRemove even if we may not use it it? i.e. compacted is false. We create this array to hold one file only? Then clear it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Changed this. Will directly collect the compactedfiles and just remove them.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Who calls this closeAndArchiveCompactedFiles ? The chore thread?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We do a copy here and operate on the copy?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The original can change if just after we getThecompactedFiles another set of compaction gets completed. Like we do in other areas by obtaininig a read lock before getting the files for scanners similarly I have added the read lock here just for copying the compacted files.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;.down in archiveAndRemoveCompactedFiles? There are no references to the file, right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Currently the storefiles are updated under the write lock. Similarly the compacted files are also updated with the same write lock. So the removal of the compacted files are also under the write lock. This is basically to make the update to the compactedfiles list atomic. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;{ 156	ACTIVE, DISCARDED; 157	}&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Now no more enums.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;doing it in StoreFile is not right.. .this is meta info on the StoreFile instances. StoreFileManager?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agree that Storefile is not right and StorefileInfo is better. I think we can do this in a seperate JIRA. But if we do in StorefileManager currently it is an interface so every impl of the SFManager should take care of this state and ref counting. (like default and StripeSFM).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Shoud return Collection&amp;lt;StoreFile&amp;gt; and internally you do the Immutable stuff (good practice)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Okie. I just followed what clearStoreFiles() does.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In StoreFileScanner, when would scanner be null?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Changed this now. Considering the fact that we have two seperated lists for the current storefiles and compacted files this may no longer be needed.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Maybe a timer on scans? If goes on longer than a minute have it return and then clean up compacted files.... New issue.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ya true. New Issue.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Is checkFlushed the right name for the method?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Changed to checkResetHeap.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Why is it a CompactedHFilesCleaner cleaner and not a HFileCleaner?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Changed to CompactedHFilesDischarger.  Does that sound good?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Yeah, why call checkFlushed in shipped?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I rechecked this flow fully. Calling this in shipped or close() may not be needed because after the shipped() call any way we wil be calling one of the scan API like next(), reseek(), peek() etc.&lt;br/&gt;
But regarding not calling checkResetHeap in reseek(), peek(), seek() etc. I think its okie. The reason is because every next() may call reseek or seek() internally and that time if we can ensure that if we can reset the heap on flush it will ensure that we don&apos;t hold up the snapshot for a longer time. But one downside could be if there is no flush during a scan and there are lot of reseeks() we end up checking the volatile every time. But I think it is okie? &lt;/p&gt;
</comment>
                            <comment id="15021980" author="ram_krish" created="Mon, 23 Nov 2015 11:43:05 +0000"  >&lt;p&gt;Updated patch for QA.&lt;/p&gt;</comment>
                            <comment id="15023099" author="stack" created="Mon, 23 Nov 2015 21:23:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;The TTLCleaner works every 5 mins for the secondary region replica. So before that we need to move the compacted files to the archive. Hence it is 2 mins.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Add your reasoning as a comment.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Changed to CompactedHFilesDischarger. Does that sound good?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No. But more descriptive (smile). Do you have to have &apos;Compacted&apos; in there since files are discharged by the compactor always?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;But one downside could be if there is no flush during a scan and there are lot of reseeks() we end up checking the volatile every time. But I think it is okie?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, my suggestion was try to minimize the checks... and if possible, avoid doing multiple checks inside in the one access when one is all that is needed... one on the way out of the next call.  Otherwise, you start to lose alot of the nice gains you have here.&lt;/p&gt;

&lt;p&gt;Want me to review this version of patch or you want to do another first?&lt;/p&gt;




</comment>
                            <comment id="15023787" author="ram_krish" created="Tue, 24 Nov 2015 05:12:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;Do you have to have &apos;Compacted&apos; in there since files are discharged by the compactor always?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I first thought it is a cleaner because this chore moves the compacted files alone to the archive dir.  It does not deal with any other hfile. That is why I added &apos;Compacted&apos;.&lt;br/&gt;
You can review this patch except for the name of the Chore service .&lt;/p&gt;</comment>
                            <comment id="15023832" author="stack" created="Tue, 24 Nov 2015 06:05:40 +0000"  >&lt;p&gt;Nice explanation on compactedfiles&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;// Sorting may not be really needed here for the compacted files?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah. They are just going to be deleted, right... No harm sorting though I suppose.. you&apos;ll delete oldest to newest?&lt;/p&gt;

&lt;p&gt;Keep CompactedHFilesDischarger name. It ties his chore to this stuff going on in the StoreManager.&lt;/p&gt;


&lt;p&gt;Could also have the method internally do these checks for null and check for zero count?&lt;/p&gt;

&lt;p&gt;2351	    if (copyCompactedfiles != null &amp;amp;&amp;amp; copyCompactedfiles.size() != 0) &lt;/p&gt;
{
2352	      removeCompactedFiles(copyCompactedfiles);
2353	    }

&lt;p&gt;Then all in one place.&lt;/p&gt;

&lt;p&gt;closeAfterCompaction seems misnamed. The return is whether there are references outstanding and if the file can be safely removed/closed? &lt;/p&gt;

&lt;p&gt;470	  /**&lt;br/&gt;
471	   * Closes and archives the compacted files under this store&lt;br/&gt;
472	   */&lt;br/&gt;
473	  void closeAndArchiveCompactedFiles() throws IOException;&lt;/p&gt;

&lt;p&gt;We&apos;ll only close and archive if no references and if it is marked as compacted, right? Otherwise, we&apos;ll do it at a later place?&lt;/p&gt;

&lt;p&gt;So, we are going to change this in another issue?&lt;/p&gt;

&lt;p&gt;      compactedFile.markCompacted();&lt;/p&gt;

&lt;p&gt;i.e. marking a file as compacted rather than telling StoreFileManager it is compacted?&lt;/p&gt;

&lt;p&gt;So, the StoreFile has new attributes of current refcount and if compacted away. StoreFileManager has list of compacted files. StoreFileManager is in charge of the list of StoreFlies in a Store. It makes ruling on what to include in a Scan. It does clearFiles... and compaction. Shouldn&apos;t it be in charge of knowing when files are not to be included in a Scan/can be removed? When we mark a file compacted, we should do it on StoreFileManager?  Can it do the refcounting? When a Scan is done, tell the StoreFileManager so it can do the refcounting?&lt;/p&gt;

&lt;p&gt;From your earlier comment:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We cannot have this in StorefileInfo because we only cache the Storefile (in the StorefileManager) and not the StorefileInfo. StoreFileInfos are created every time from the hfile path.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can StoreFileManager then do refcounting and knowing what files are compacted? Would that be doable and put these attributes in one location?&lt;/p&gt;

&lt;p&gt;This should be happening internal to StoreFileManager rather than out here in HStore?&lt;/p&gt;

&lt;p&gt;	853	      Collection&amp;lt;StoreFile&amp;gt; compactedfiles =&lt;br/&gt;
854	          storeEngine.getStoreFileManager().clearCompactedFiles();&lt;br/&gt;
855	      // clear the compacted files&lt;br/&gt;
856	      if (compactedfiles != null &amp;amp;&amp;amp; !compactedfiles.isEmpty()) &lt;/p&gt;
{
857	        removeCompactedFiles(compactedfiles);
858	      }

&lt;p&gt;Gets complicated here on the end in closeAndArchiveCompactedFiles where there is a lock for the Store being used to close out storefiles....  And, you are just following on from what is in here already. Ugh.&lt;/p&gt;

&lt;p&gt;In StoreFile you have&lt;/p&gt;

&lt;p&gt;  public boolean isCompacted() {&lt;/p&gt;

&lt;p&gt;and then later you have on the Reader isCompactedAway. These methods should be named the same (And see above where hopefully, we don&apos;t have to do this on the StoreFile itself at all). Ditto for getRefCount (Does StoreFileManager know refcount?)&lt;/p&gt;

&lt;p&gt;Looking at the additions to StoreFileManager, if compaction was kept internal to StoreFileManager, would you have to add these new methods?&lt;/p&gt;

&lt;p&gt;Does StoreFileScanner have reference to StoreFileManager?&lt;/p&gt;

&lt;p&gt;On how often to call checkResetHeap, we have to be prompt because we are carrying a snapshot until we do reset?&lt;/p&gt;





</comment>
                            <comment id="15024368" author="ram_krish" created="Tue, 24 Nov 2015 12:22:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;Could also have the method internally do these checks for null and check for zero count?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Done.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;closeAfterCompaction seems misnamed. The return is whether there are references outstanding and if the file can be safely removed/closed?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;isReferencedInReads() is better?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Does StoreFileScanner have reference to StoreFileManager?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No there is no reference.&lt;br/&gt;
Coming to this StorefileManager and refcounting, as you can see that SFM has a list of storeFiles that are under the current store. But the StorefileScanner is created by the StoreFile only. In the sense the StoreScanner creates a StorefileScanner on each of this storefiles returned by the StorefileManager. The decrement in ref counting we will have to do when the scanner on the Storefile is done (ie StoreFileScanner.close()). So this how can the SFM do this ref counting? SFM is not involved in the scan process except for maintiaining the list of storefiles eligible for scanning. What do you think?  &lt;br/&gt;
If we need to support this way, then SFM needs to be modified iin such a way that the scanner creation also happen thro the SFM.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Gets complicated here on the end in closeAndArchiveCompactedFiles where there is a lock for the Store being used to close out storefiles.... And, you are just following on from what is in here already. Ugh.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I thought it is better to have the lock there (though it is a lock at the store level) where the compacted file is updated. One thing can be done is maintain a new lock only for the compacted file but doing so one problem is that addCompactionResults we need to split into two like first hold the current lock and update the storeFile list and then hold the new compaciton lock and update the compactedFiles list. And use this comapcted lock every time we remove (in write mode) and select the compacted files ( in read mode).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On how often to call checkResetHeap, we have to be prompt because we are carrying a snapshot until we do reset?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. We are carrying the snapshot hence thought it is better if we can check on every scan API so that the snapshot can be released as soon as possible. &lt;/p&gt;</comment>
                            <comment id="15024435" author="ram_krish" created="Tue, 24 Nov 2015 12:52:24 +0000"  >&lt;p&gt;Updated patch.  The refCounting is still in the Storefile because that is where we create the scanner and close the scanner. The SFM is not involved in that. But now added markCompactedAway() in SFM and once the compactedREsults are added to the SFM we call this API from the compact() F/W. So that in future any impl of the compaction logic can do this marking. &lt;/p&gt;</comment>
                            <comment id="15024811" author="hadoopqa" created="Tue, 24 Nov 2015 16:41:17 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12774054/HBASE-13082_17.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12774054/HBASE-13082_17.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 0bae444b34b6be3a28b5ccc036afb5add23818c6.&lt;br/&gt;
  ATTACHMENT ID: 12774054&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 46 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16651//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="15027356" author="stack" created="Wed, 25 Nov 2015 18:47:39 +0000"  >&lt;p&gt;+1 Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;StoreFileManager and StoreFileInfo all needs cleaning up &amp;#8211; where does StoreFile accounting get done, where is StoreFile metadata kept &amp;#8211; but not as part of this patch.&lt;/p&gt;</comment>
                            <comment id="15031384" author="ram_krish" created="Mon, 30 Nov 2015 06:27:21 +0000"  >&lt;p&gt;Will commit this patch shortly.&lt;/p&gt;</comment>
                            <comment id="15033578" author="anoop.hbase" created="Tue, 1 Dec 2015 12:07:37 +0000"  >
&lt;p&gt;sortCompactedfiles  This is already been called on new temp ArrayList. Do we still need create a new list?  May be to be best way is create ImmutableList here at end for setting to instance variable&lt;/p&gt;

&lt;p&gt;private ChoreService choreService;&lt;br/&gt;
We dont need to keep a ref to this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;LOG.trace(&quot;No compacted files to compact&quot;);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Say no compacted files to archive.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeEngine.getStoreFileManager().addCompactionResults(compactedFiles, result);
      &lt;span class=&quot;code-comment&quot;&gt;// Mark the files as compactedAway once the storefiles and compactedfiles list is finalised
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// Let a background thread close the actual reader on these compacted files and also
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// ensure to evict the blocks from block cache so that they are no longer in
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// cache
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeEngine.getStoreFileManager().markCompactedAway(compactedFiles);
	  &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Do we need 2 API calls for this?  Can the marking be done within addCompactionResults?  May be we need a better name for that API then.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
     * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the file is compacted and &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there are no references
     */
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isReferencedInReads() {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; !(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.compactedAway &amp;amp;&amp;amp; refCount.get() == 0);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;That looks bad this API checks the status of compactedAway also.  We incr refCount with out any check. Either name the API accordingly or just it return state of refCount. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isCompactedAway() {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.reader != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.reader.isCompactedAway();
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
  }
  &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;  We will have not null reader on every file every time right? As per this logic when there is no reader on a file we treat it as compacted away. Return false instead of true?  Seems we use this only in tests.  Why because the other API isReferencedInReads is  checking both ref count and compactedAway state!&lt;/p&gt;

  &lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  StoreFile.Reader r = file.getReader();
                &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (r != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; !r.isReferencedInReads()) {
	&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Better add similar API in StoreFile also and use that rather than using directly from reader.&lt;/p&gt;


&lt;p&gt;removeCompactedFiles -&amp;gt; Every time the chore runs, we seems to make a ThreadPoolExecutor and ExecutorService which seems expensive. Why we need multi threaded reader close?&lt;/p&gt;

&lt;p&gt;checkResetHeap -&amp;gt; This is working with out any lock now.  Say flushed was true and so we did nullifyCurrentHeap().   Another reader by this time created new heap. Then only the old thread got a chance.  This will try set the var to false.  In btw that another flush happened and variable was set to ON. But we may miss this reset of heap?  It will make the ref to that snapshot for longer time max till all reader on that snapshot is completed. Should be ok as it is rare case also.. Just saying. &lt;/p&gt;


&lt;p&gt;private HRegion region; -&amp;gt; Do we need this ref of HRegion type? Can be Region?&lt;/p&gt;</comment>
                            <comment id="15033596" author="ram_krish" created="Tue, 1 Dec 2015 12:21:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;sortCompactedfiles This is already been called on new temp ArrayList. Do we still need create a new list? May be to be best way is create ImmutableList here at end for setting to instance variable&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Stack suggested not to use Guava DS and APIs.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Can the marking be done within addCompactionResults?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If we do this way then we have to add the markcompactedAway in all the compaction impl. This way it will be better. Also better we do it inside the store level lock.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;That looks bad this API checks the status of compactedAway also. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The name is Ok I think.  Any other name you suggest?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;isCompactedAway() {&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is used in tests only because wanted to check some conditions for the tests. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Better add similar API in StoreFile also and use that rather than using directly from reader.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This cannot be done so easily because all our StorefileScanners are created over the Reader. So if we want to access from Storefile then it will be a bigger change. Any way there is a follow up that was discussed to make things work with StoreFileManager and StorefileInfo getting used by the manager.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;removeCompactedFiles -&amp;gt; Every time the chore runs, we seems to make a ThreadPoolExecutor and ExecutorService which seems expensive. Why we need multi threaded reader close?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The close() is a costly operation hence did not want to do these things serially when we know that we can do it parallely. The reason for creating the executor every time was that not sure what is the thread count to be allocated to the executor.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Should be ok as it is rare case also.. Just saying.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;YA if there are very frequent flushes then this will happen, till then the GC will not be cleared for that snapshot till the scan is over.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;HRegion region; -&amp;gt; Do we need this ref of HRegion type? Can be Region?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Okie that can be done I think.&lt;/p&gt;</comment>
                            <comment id="15033701" author="ram_krish" created="Tue, 1 Dec 2015 13:51:19 +0000"  >&lt;p&gt;Changed the way isReferencedInREads is called and instead replaced it with&lt;br/&gt;
r.isCompactedAway() &amp;amp;&amp;amp; !r.isReferencedInReads().&lt;br/&gt;
The isReferencedInReads is now&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isReferencedInReads() {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; refCount.get() != 0;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15033709" author="ram_krish" created="Tue, 1 Dec 2015 13:55:14 +0000"  >&lt;p&gt;Patch for QA with the updated comments. The StoreFileManager.addCompactionResults() API name is not changed. &lt;/p&gt;</comment>
                            <comment id="15033927" author="hadoopqa" created="Tue, 1 Dec 2015 15:54:35 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12775032/HBASE-13082_18.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12775032/HBASE-13082_18.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 7979ac46cce36f21033f8ed03c8d0dd5fddde005.&lt;br/&gt;
  ATTACHMENT ID: 12775032&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 46 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated new checkstyle errors. Check build console for list of new errors.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.TestHeapSize&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16717//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="15034089" author="ram_krish" created="Tue, 1 Dec 2015 17:11:49 +0000"  >&lt;p&gt;Updatd patch correcting the test case.  The checkstyle comment am not sure whether this patch has introduced it. The javadoc is not related to this patch. &lt;/p&gt;</comment>
                            <comment id="15034534" author="hadoopqa" created="Tue, 1 Dec 2015 20:42:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12775074/HBASE-13082_19.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12775074/HBASE-13082_19.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit a7673ed7552542c9848d95f9492bf3a55d2060e2.&lt;br/&gt;
  ATTACHMENT ID: 12775074&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 50 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated new checkstyle errors. Check build console for list of new errors.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16719//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="15039742" author="ram_krish" created="Fri, 4 Dec 2015 04:52:08 +0000"  >&lt;p&gt;Pushed to master. Thanks for the reviews &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; and others for providing feedback on the patch.&lt;/p&gt;</comment>
                            <comment id="15041227" author="hudson" created="Fri, 4 Dec 2015 07:52:50 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-Trunk_matrix #530 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-Trunk_matrix/530/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-Trunk_matrix/530/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; Coarsen StoreScanner locks to RegionScanner (Ram) (ramkrishna: rev 8b3d1f144408e4a7a014c5ac46418c9e91b9b0db)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15041432" author="anoop.hbase" created="Fri, 4 Dec 2015 11:16:03 +0000"  >&lt;p&gt;Can we have it in 1.3 also?&lt;/p&gt;</comment>
                            <comment id="15041873" author="stack" created="Fri, 4 Dec 2015 18:01:32 +0000"  >&lt;p&gt;Wahoo.&lt;/p&gt;

&lt;p&gt;+1 on 1.3. Probably too late for 1.2.&lt;/p&gt;</comment>
                            <comment id="15048506" author="ram_krish" created="Wed, 9 Dec 2015 11:16:53 +0000"  >&lt;p&gt;Oops. I need to prepare a patch for 1.3 which I started but left it due to some conflicts. Let me complete it by the end of this week.&lt;/p&gt;</comment>
                            <comment id="15108407" author="hudson" created="Wed, 20 Jan 2016 11:36:49 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-Trunk_matrix #645 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-Trunk_matrix/645/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-Trunk_matrix/645/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15101&quot; title=&quot;Leaked References to StoreFile.Reader after HBASE-13082&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15101&quot;&gt;&lt;del&gt;HBASE-15101&lt;/del&gt;&lt;/a&gt; Leaked References to StoreFile.Reader after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; (ramkrishna: rev 93e200d52b29d35ad5a98eed9eea05783960f6b2)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15110921" author="hudson" created="Thu, 21 Jan 2016 17:06:30 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.3 #505 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3/505/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3/505/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 (Ram) (ramkrishna: rev 58521869b06a63894e422e9c9403e48b4b12f388)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionConfiguration.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/OnlineRegions.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischargeHandler.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/EventType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/MockRegionServerServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischarger.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15111600" author="hudson" created="Thu, 21 Jan 2016 23:27:46 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3-IT #451 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3-IT/451/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3-IT/451/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 (Ram) (ramkrishna: rev 58521869b06a63894e422e9c9403e48b4b12f388)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/OnlineRegions.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischargeHandler.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/EventType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionConfiguration.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/MockRegionServerServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15112838" author="stack" created="Fri, 22 Jan 2016 18:37:47 +0000"  >&lt;p&gt;Reopening. This commit introduces a test that fails reliably. Git bisect fingers this commit:&lt;/p&gt;

&lt;p&gt;58521869b06a63894e422e9c9403e48b4b12f388 is the first bad commit&lt;br/&gt;
commit 58521869b06a63894e422e9c9403e48b4b12f388&lt;br/&gt;
Author: ramkrishna &amp;lt;ramkrishna.s.vasudevan@gmail.com&amp;gt;&lt;br/&gt;
Date:   Thu Jan 21 21:22:40 2016 +0530&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 (Ram)&lt;/p&gt;

&lt;p&gt;:040000 040000 ac9ba8c501616a32632f7b46adfe0afb7073458b 140cac3904b52a7d599e20f21c8d55961847ca77 M	hbase-client&lt;br/&gt;
:040000 040000 f3f53edf84a0f7885dcc577159ba5bbc1a8c6922 7c023622983f3bc4d9c1a43b2dd52c7d2d181b51 M	hbase-server&lt;/p&gt;


&lt;p&gt;Here is my little test:&lt;/p&gt;

&lt;p&gt;mvn clean install -DskipTests &amp;amp;&amp;amp; mvn test -Dtest=TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Let me revert for now since its your w/e &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15112847" author="stack" created="Fri, 22 Jan 2016 18:44:45 +0000"  >&lt;p&gt;Reresolving. Wrong issue. Meant to do the backport issue.&lt;/p&gt;</comment>
                            <comment id="15113280" author="hudson" created="Fri, 22 Jan 2016 22:49:29 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3 #509 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3/509/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3/509/&lt;/a&gt;)&lt;br/&gt;
Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 (stack: rev a5228a0b4d8b4c6b9bab58e1eee015393edaaade)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/MockRegionServerServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionConfiguration.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/EventType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/OnlineRegions.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischargeHandler.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15113298" author="hudson" created="Fri, 22 Jan 2016 23:06:45 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3-IT #454 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3-IT/454/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3-IT/454/&lt;/a&gt;)&lt;br/&gt;
Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 (stack: rev a5228a0b4d8b4c6b9bab58e1eee015393edaaade)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischargeHandler.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/EventType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/OnlineRegions.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/MockRegionServerServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionConfiguration.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15114679" author="hudson" created="Mon, 25 Jan 2016 02:55:57 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3-IT #460 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3-IT/460/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3-IT/460/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 - recommit (ramkrishna: rev bc0e5fc048de3f18ab07bd5cb06509eb349e951a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/EventType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/OnlineRegions.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionConfiguration.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischargeHandler.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/MockRegionServerServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15114824" author="hudson" created="Mon, 25 Jan 2016 06:32:44 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3 #513 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3/513/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3/513/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14970&quot; title=&quot;Backport HBASE-13082 and its sub-jira to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14970&quot;&gt;&lt;del&gt;HBASE-14970&lt;/del&gt;&lt;/a&gt; Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13082&quot; title=&quot;Coarsen StoreScanner locks to RegionScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13082&quot;&gt;&lt;del&gt;HBASE-13082&lt;/del&gt;&lt;/a&gt; and its sub-jira to branch-1 - recommit (ramkrishna: rev bc0e5fc048de3f18ab07bd5cb06509eb349e951a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/TestCompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionMergeTransactionOnCluster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/backup/example/TestZooKeeperTableArchiveClient.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/OnlineRegions.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/MockRegionServerServices.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java&lt;/li&gt;
	&lt;li&gt;hbase-client/src/main/java/org/apache/hadoop/hbase/executor/EventType.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestSnapshotFromMaster.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestWideScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionConfiguration.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/master/MockRegionServer.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFileManager.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedStoreScanner.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischargeHandler.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRegionReplicas.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactedHFilesDischarger.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MockStoreFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15181406" author="lhofhansl" created="Sat, 5 Mar 2016 01:34:06 +0000"  >&lt;p&gt;So I found a deceptively simple way of (1) avoiding the locks in every method, (2) avoiding resetting the scanner stack, (3) avoiding an extra cleanup chore:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;At StoreScanner creation time create a CountDownLatch initialized with 1.&lt;/li&gt;
	&lt;li&gt;When a StoreScanner is closed, call countDown() on the latch.&lt;/li&gt;
	&lt;li&gt;When the compaction calls updateReaders on the StoreScanner it calls await() on the latch and will block until the scanner is done.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;So we have an easy way to ensure that no compactions can finish while a scanner using referring to the store files is running. That also means that we no longer need to reset the scanner stack (a compaction only happens after the scanner is closed), and lastly the compactions will naturally stack up behind the scanners and eventually run.&lt;/p&gt;

&lt;p&gt;The risk is that scanner is not properly closed and we&apos;ll never count down that latch, and hence block compactions forever. I&apos;ve not seen this happening in my tests, also every scanner is guarded by a lease, so eventually we will close it. The other risk is that we simply might not be able to get any compactions through in a busy system.&lt;/p&gt;

&lt;p&gt;Comments? Happy to attach a patch (or open another jira for this)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15181417" author="lhofhansl" created="Sat, 5 Mar 2016 01:46:10 +0000"  >&lt;p&gt;Lemme attach the patch anyway - just so it&apos;s parked somewhere. Does what&apos;s described above.&lt;br/&gt;
Note that updateReaders is now only used to block compactions from finishing, not to do any work, so we could rename it.&lt;/p&gt;

&lt;p&gt;This should actually be better that this patch even for performance since we&apos;re avoiding a volatile reference and hence a memory fence.&lt;/p&gt;

&lt;p&gt;But as stated, it is riskier if Storescanner are not closed correctly.&lt;/p&gt;</comment>
                            <comment id="15181541" author="anoop.hbase" created="Sat, 5 Mar 2016 05:45:22 +0000"  >&lt;p&gt;So this means when there are parallel scanners, the thread doing compaction will get blocked.  Means it can delay other compaction requests in Q. Means if there are some parallel writes also that may delay flushes. So may block writes &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Is these possible Lars?&lt;/p&gt;</comment>
                            <comment id="15181578" author="ram_krish" created="Sat, 5 Mar 2016 06:43:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;&lt;br/&gt;
In the current trunk and 1.3 actually we are not doing any updateReaders after compactions. Only after flushes we are doing. So how does this patch work with flushes if you will wait on the latch that is created per StoreScanner. Because for flush we are forced to update the scanner because we are cleaning up the memstore snapshot. But yes we do have the reference to the older memstore snapshot but holding it up for a longer time is not good is what was discussed previously in this JIRA impl. So even if compactions get blocked if there are large scans then it will affect the compaction requests that comes newly?&lt;/p&gt;</comment>
                            <comment id="15181607" author="lhofhansl" created="Sat, 5 Mar 2016 07:22:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ramkrishna.s.vasudevan%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;ramkrishna.s.vasudevan@gmail.com&quot;&gt;ramkrishna vasudevan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, Yep, that&apos;s what I suggest as downside (&quot;risks&quot;) above.&lt;br/&gt;
Everything that is calling updateReaders will have to wait behind active StoreScanners. Instead of a lot of huh hah, compactions are delayed until they can safely finish.&lt;br/&gt;
But those would only be StoreScanner open at the time the compaction/flush tries to finish. So actually my point about delaying compactions potentially forever is not true. Instead as as soon as the old set or StoreScanners is done the compaction/flush can proceed and the new Scanner would only see the new files.&lt;/p&gt;

&lt;p&gt;The flush part is concerning, though. Thanks for pointing that out.&lt;/p&gt;

&lt;p&gt;That was already the cases before in other situations (like a Scanner that only encounters deleted Cells with has a Filter that filters most Cells, etc). But that would not be the case in trunk anymore - just that there we&apos;d disallow the file to be removed, which is better. There is currently still the checkFlushed call, which needs a volatile and hence causes a memory barrier.&lt;/p&gt;

&lt;p&gt;I&apos;ll do some tests. This wasn&apos;t meant as an actual patch to be committed, just wanted to get some feedback. I&apos;m always a fan of simplest code possible.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12681977">HBASE-10060</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12776140">HBASE-13071</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12777230">HBASE-13090</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12700364" name="13082-test.txt" size="2981" author="lhofhansl" created="Tue, 24 Feb 2015 07:14:09 +0000"/>
                            <attachment id="12703166" name="13082-v2.txt" size="9047" author="lhofhansl" created="Fri, 6 Mar 2015 23:29:28 +0000"/>
                            <attachment id="12703275" name="13082-v3.txt" size="17493" author="lhofhansl" created="Sun, 8 Mar 2015 06:16:18 +0000"/>
                            <attachment id="12703356" name="13082-v4.txt" size="20223" author="lhofhansl" created="Mon, 9 Mar 2015 04:15:53 +0000"/>
                            <attachment id="12701281" name="13082.txt" size="8682" author="lhofhansl" created="Fri, 27 Feb 2015 06:25:09 +0000"/>
                            <attachment id="12700069" name="13082.txt" size="8682" author="lhofhansl" created="Sun, 22 Feb 2015 00:50:06 +0000"/>
                            <attachment id="12791584" name="CountDownLatch-0.98.txt" size="6149" author="lhofhansl" created="Sat, 5 Mar 2016 01:46:10 +0000"/>
                            <attachment id="12767337" name="HBASE-13082.pdf" size="118718" author="ram_krish" created="Mon, 19 Oct 2015 10:36:30 +0000"/>
                            <attachment id="12770531" name="HBASE-13082_1.pdf" size="234758" author="ram_krish" created="Wed, 4 Nov 2015 05:58:49 +0000"/>
                            <attachment id="12771006" name="HBASE-13082_12.patch" size="108898" author="ram_krish" created="Fri, 6 Nov 2015 12:18:35 +0000"/>
                            <attachment id="12771229" name="HBASE-13082_13.patch" size="108845" author="ram_krish" created="Sun, 8 Nov 2015 05:17:04 +0000"/>
                            <attachment id="12771291" name="HBASE-13082_14.patch" size="109126" author="ram_krish" created="Mon, 9 Nov 2015 06:06:21 +0000"/>
                            <attachment id="12773775" name="HBASE-13082_15.patch" size="109267" author="ram_krish" created="Mon, 23 Nov 2015 06:24:38 +0000"/>
                            <attachment id="12773823" name="HBASE-13082_16.patch" size="106094" author="ram_krish" created="Mon, 23 Nov 2015 11:43:05 +0000"/>
                            <attachment id="12774054" name="HBASE-13082_17.patch" size="107316" author="ram_krish" created="Tue, 24 Nov 2015 12:52:24 +0000"/>
                            <attachment id="12775032" name="HBASE-13082_18.patch" size="109010" author="ram_krish" created="Tue, 1 Dec 2015 13:55:14 +0000"/>
                            <attachment id="12775074" name="HBASE-13082_19.patch" size="110288" author="ram_krish" created="Tue, 1 Dec 2015 17:11:49 +0000"/>
                            <attachment id="12766279" name="HBASE-13082_1_WIP.patch" size="102365" author="ram_krish" created="Tue, 13 Oct 2015 07:10:09 +0000"/>
                            <attachment id="12771005" name="HBASE-13082_2.pdf" size="233605" author="ram_krish" created="Fri, 6 Nov 2015 12:14:53 +0000"/>
                            <attachment id="12766471" name="HBASE-13082_2_WIP.patch" size="101684" author="ram_krish" created="Wed, 14 Oct 2015 05:20:15 +0000"/>
                            <attachment id="12766763" name="HBASE-13082_3.patch" size="122193" author="ram_krish" created="Thu, 15 Oct 2015 10:16:47 +0000"/>
                            <attachment id="12767056" name="HBASE-13082_4.patch" size="151358" author="ram_krish" created="Fri, 16 Oct 2015 11:34:39 +0000"/>
                            <attachment id="12769932" name="HBASE-13082_9.patch" size="102748" author="ram_krish" created="Sat, 31 Oct 2015 08:11:42 +0000"/>
                            <attachment id="12769780" name="HBASE-13082_9.patch" size="103909" author="ram_krish" created="Fri, 30 Oct 2015 13:31:43 +0000"/>
                            <attachment id="12771728" name="HBASE-13082_withoutpatch.jpg" size="29440" author="ram_krish" created="Wed, 11 Nov 2015 11:32:35 +0000"/>
                            <attachment id="12771729" name="HBASE-13082_withpatch.jpg" size="95060" author="ram_krish" created="Wed, 11 Nov 2015 11:32:35 +0000"/>
                            <attachment id="12773447" name="LockVsSynchronized.java" size="2380" author="ram_krish" created="Fri, 20 Nov 2015 05:39:00 +0000"/>
                            <attachment id="12702237" name="gc.png" size="20008" author="stack" created="Tue, 3 Mar 2015 19:38:25 +0000"/>
                            <attachment id="12701780" name="gc.png" size="22947" author="stack" created="Mon, 2 Mar 2015 04:11:12 +0000"/>
                            <attachment id="12701673" name="gc.png" size="24082" author="stack" created="Sun, 1 Mar 2015 05:26:02 +0000"/>
                            <attachment id="12702236" name="hits.png" size="13540" author="stack" created="Tue, 3 Mar 2015 19:38:25 +0000"/>
                            <attachment id="12701781" name="next.png" size="13995" author="stack" created="Mon, 2 Mar 2015 04:11:12 +0000"/>
                            <attachment id="12701672" name="next.png" size="14631" author="stack" created="Sun, 1 Mar 2015 05:26:02 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12916902">HBASE-14895</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>33.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 21 Feb 2015 07:05:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            40 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i25vxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>After this JIRA we will not be doing any scanner reset after compaction during a course of a scan. The files that were compacted will still be continued to be used in the scan process. The compacted files will be archived by a background thread that runs every 2 mins by default only when there are no active scanners on those comapcted files. The above duration can be controlled using the knob &amp;#39;hbase.hfile.compactions.cleaner.interval&amp;#39;. </customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>