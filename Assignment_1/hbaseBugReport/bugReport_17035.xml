<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:20:23 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-17035/HBASE-17035.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-17035] Check why we roll a wal writer at 10MB when the configured roll size is 120M+ with AsyncFSWAL</title>
                <link>https://issues.apache.org/jira/browse/HBASE-17035</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Found this when addressing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16890&quot; title=&quot;Analyze the performance of AsyncWAL and fix the same&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16890&quot;&gt;HBASE-16890&lt;/a&gt;. It is one of the possible reason that why AsyncFSWAL performs worse than FSHLog when running PE tool.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16890?focusedCommentId=15636688&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15636688&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-16890?focusedCommentId=15636688&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15636688&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13018683">HBASE-17035</key>
            <summary>Check why we roll a wal writer at 10MB when the configured roll size is 120M+ with AsyncFSWAL</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12911749">HBASE-14790</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Apache9">Duo Zhang</assignee>
                                    <reporter username="Apache9">Duo Zhang</reporter>
                        <labels>
                    </labels>
                <created>Sun, 6 Nov 2016 14:05:34 +0000</created>
                <updated>Wed, 9 Nov 2016 01:33:39 +0000</updated>
                            <resolved>Wed, 9 Nov 2016 01:33:39 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>wal</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="15643236" author="ram_krish" created="Mon, 7 Nov 2016 06:08:08 +0000"  >&lt;p&gt;I am just to analyze your findings. If I find any will report back. &lt;/p&gt;</comment>
                            <comment id="15643365" author="ram_krish" created="Mon, 7 Nov 2016 07:20:14 +0000"  >&lt;p&gt;While loading 50G of data with 50 threads. AsyncFSWAL is more than twice the time it takes for FShLOg.&lt;br/&gt;
There are 126 log roll requests with fSHLog but with AsyncFSWAL we have 215 log roll requests. And we have lot of log rolls with 10MB to 13MB sizes and that what I got is not due to memory flush.&lt;br/&gt;
Interesting part is this&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2016-11-07 18:09:13,688 INFO  [regionserver/stobdtserver5/10.224.54.65:16041.logRoller] wal.AbstractFSWAL: Rolled WAL /hbase1/WALs/stobdtserver5,16041,1478521203795/stobdtserver5%2C16041%2C1478521203795.1478522344435 with entries=1566632, filesize=518.92 MB; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WAL /hbase1/WALs/stobdtserver5,16041,1478521203795/stobdtserver5%2C16041%2C1478521203795.1478522353615
2016-11-07 18:09:13,853 INFO  [regionserver/stobdtserver5/10.224.54.65:16041.logRoller] wal.AbstractFSWAL: Rolled WAL /hbase1/WALs/stobdtserver5,16041,1478521203795/stobdtserver5%2C16041%2C1478521203795.1478522353615 with entries=1566992, filesize=13.88 MB; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WAL /hbase1/WALs/stobdtserver5,16041,1478521203795/stobdtserver5%2C16041%2C1478521203795.1478522353689
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The new WAL file generated is immediately rolled to another file of size 13.88MB but the total number of entries is almost the same but the size is so small. This pattern repeats quite frequently. &lt;/p&gt;</comment>
                            <comment id="15643389" author="anoop.hbase" created="Mon, 7 Nov 2016 07:34:14 +0000"  >&lt;p&gt;Oh..  That means there is some thing silly on calc the #cells added to WAL &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Based on that and sum of cell length we decide on the roll?&lt;/p&gt;</comment>
                            <comment id="15643412" author="apache9" created="Mon, 7 Nov 2016 07:45:32 +0000"  >&lt;p&gt;I guess there is a race when requesting log roll. I haven&apos;t think of it very deeply as I do not think unnecessary log roll will impact performance a lot when I wrote AsyncFSWAL.&lt;/p&gt;

&lt;p&gt;Still waiting on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;. I have changed the rolling logic in that patch...&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15643418" author="ram_krish" created="Mon, 7 Nov 2016 07:48:00 +0000"  >&lt;p&gt;I think this is the case. Pls do correct me if am wrong.&lt;br/&gt;
-&amp;gt; WE have an active Writer (say w1). We do sequence of appends/sync calls on this. Say we now do a synccompleted() and there we request a log roll. &lt;br/&gt;
-&amp;gt; Before the log roll request is completed we waitForSafePoint(). We just check if we can schedule a task or not but there is a sycn on waitingConsumePayloads.&lt;br/&gt;
-&amp;gt; Now before the log roll request is processed since the writer is still not swapped out we do accept more appends. In consume()&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AsyncWriter writer = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.writer;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We do this. The writer is still the older one.&lt;br/&gt;
-&amp;gt; Now the log roll request tries to get completed and it creates W2. And the writer instance is updated.&lt;br/&gt;
-&amp;gt; By the time the appends that were added on W1 will now again see that the size is bigger than logRollSize and trigger a logRoll. But this time the again the logRoll happens but it will now account for the size of W2 only since that is the writer instance active now and it will create a new file W3.&lt;/p&gt;</comment>
                            <comment id="15643432" author="ram_krish" created="Mon, 7 Nov 2016 07:58:04 +0000"  >&lt;p&gt;I will run with this patch HBASe-17021. If it is solved then it is fine. &lt;/p&gt;</comment>
                            <comment id="15643441" author="apache9" created="Mon, 7 Nov 2016 08:02:40 +0000"  >&lt;p&gt;No.&lt;/p&gt;

&lt;p&gt;The waitForSafePoint is used to confirm that all out-going data have been acked, which means there will be no synccompleted after we return from waitForSafePoint and before the switch of writer. And the doReplaceWriter is protected by rollWriterLock, so it is impossible that we request a log roll again when there is a doReplaceWriter actively running.&lt;/p&gt;</comment>
                            <comment id="15643452" author="apache9" created="Mon, 7 Nov 2016 08:06:00 +0000"  >&lt;p&gt;No, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt; does not solve the problem. I can observe the same result when running PE tool with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here I mean we can start working based on the new roll logic introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15643512" author="ram_krish" created="Mon, 7 Nov 2016 08:39:42 +0000"  >&lt;p&gt;I think with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt; the accounting of the entries is corrected&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2016-11-07 18:59:33,465 INFO  [regionserver/stobdtserver5/10.224.54.65:16041.logRoller] wal.AbstractFSWAL: Rolled WAL /hbase1/WALs/stobdtserver5,16041,1478525130117/stobdtserver5%2C16041%2C1478525130117.1478525364568 with entries=14376, filesize=522.53 MB; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WAL /hbase1/WALs/stobdtserver5,16041,1478525130117/stobdtserver5%2C16041%2C1478525130117.1478525373221
2016-11-07 18:59:33,822 INFO  [regionserver/stobdtserver5/10.224.54.65:16041.logRoller] wal.AbstractFSWAL: Rolled WAL /hbase1/WALs/stobdtserver5,16041,1478525130117/stobdtserver5%2C16041%2C1478525130117.1478525373221 with entries=488, filesize=17.62 MB; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WAL /hbase1/WALs/stobdtserver5,16041,1478525130117/stobdtserver5%2C16041%2C1478525130117.1478525373466

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On the part you say on waitForSafePoint. I will again check from logs.&lt;/p&gt;

&lt;p&gt;But my point is (even after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;). The waitingRoll is set inside &apos;consumeLock.lock();&apos; So by the time the waitForSafePoint tries to acquire the lock we could have added new entries and did a sync call which calls syncCompleted()??&lt;br/&gt;
Also I can see sometimes we get requestLogroll from syncCompleted for the same length&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Requesting log roll 537902596
Requesting log roll 537902596
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15643518" author="ram_krish" created="Mon, 7 Nov 2016 08:42:23 +0000"  >&lt;p&gt;But I know why you say that it won&apos;t be called again because of &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!rollWriterLock.tryLock()) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So let me see.&lt;/p&gt;</comment>
                            <comment id="15643540" author="apache9" created="Mon, 7 Nov 2016 08:52:33 +0000"  >&lt;p&gt;Where do you get the length? If it is writer.getLength then it is possible. If there are multiple out-going sync requests then it is possible that when they come back they all see the writer.getLength is larger than the logrollsize. But this will not cause multiple rolls as the requests from same WAL will be stored only once in log roller. There is a map in log roller.&lt;/p&gt;</comment>
                            <comment id="15643562" author="ram_krish" created="Mon, 7 Nov 2016 09:02:32 +0000"  >&lt;p&gt;It is not for the same log. You can see in the above atached log snippet that the log gets immediately rolled from W1 -&amp;gt; W2 -&amp;gt; W3. Will be back with some more info.&lt;/p&gt;</comment>
                            <comment id="15643571" author="apache9" created="Mon, 7 Nov 2016 09:06:58 +0000"  >&lt;p&gt;Then it is a bug for the waitForSafePoint.&lt;/p&gt;</comment>
                            <comment id="15643698" author="apache9" created="Mon, 7 Nov 2016 10:06:41 +0000"  >&lt;p&gt;I think I found a possible race.&lt;/p&gt;

&lt;p&gt;In syncCompleted method in the patch of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;, we will try finished roll before request log roll. If we successfully finishes a roll, the waitForSafePoint will return and doReplaceWriter will switch the writer. But in syncCompleted, we still use the old writer instance to get length and then compare it to the logrollsize to determine if we should request a roll. Under a heavy load, it is possible that we continue the work after tryFinishedRoll in syncCompleted method after the rollWriter is finished. This will cause a roll immediately after a roll.&lt;/p&gt;

&lt;p&gt;Let me prepare a new patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;, not very hard to fix.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15643705" author="anoop.hbase" created="Mon, 7 Nov 2016 10:10:16 +0000"  >&lt;p&gt;Great. Possibly this will fix the perf degrade also &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Will test the new patch on diff cases.&lt;/p&gt;</comment>
                            <comment id="15643782" author="ram_krish" created="Mon, 7 Nov 2016 10:33:39 +0000"  >&lt;p&gt;The writer may still be pointing to the old writer when we try to get the length in syncCompleted. That is possible. &lt;br/&gt;
Also suppose we had called sync 3 times on the older writer, the syncCompleted gets triggered 3 times. So if request log rowll was called with the first one, the 2nd and 3rd one should not be acquiring the lock. &lt;br/&gt;
But it still acquires the lock.&lt;/p&gt;</comment>
                            <comment id="15643797" author="ram_krish" created="Mon, 7 Nov 2016 10:37:14 +0000"  >&lt;p&gt;Ok. This is what you say on that writer instance.&lt;/p&gt;</comment>
                            <comment id="15643798" author="apache9" created="Mon, 7 Nov 2016 10:37:27 +0000"  >&lt;p&gt;requestLogRoll is asynchronous. It just adds an entry in a map in LogRoller. So it is possible that the requestLogRoll is triggered 3 times with the same writer instance. You can see the comment in the syncCompleted method in the v1 patch of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15643987" author="ram_krish" created="Mon, 7 Nov 2016 12:03:26 +0000"  >&lt;p&gt;Let me explain what I see. I saw your latest comment and patch. &lt;br/&gt;
But am not sure if it is going to solve this problem. &lt;/p&gt;

&lt;p&gt;Since requestLogRoll is having a map if the request log comes for the same log we roll it only once.&lt;br/&gt;
But I can see that syncCompleted is called at the same time and there I feel that there is a chance that the writer reference got updated and so we have two immediate rolls happening one for the old file and the other for the new file that just got rolled since the writer instance got updated.&lt;br/&gt;
BTW after applying your patch (the new one in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;) the time of execution of PE remains the same.&lt;br/&gt;
So log roll is not the only culprit here in my opinion. There is something more to it. Let us check with WALPE.&lt;/p&gt;</comment>
                            <comment id="15644051" author="apache9" created="Mon, 7 Nov 2016 12:30:06 +0000"  >&lt;p&gt;Yeah there are still wal rolls with small size. Let me dig more.&lt;/p&gt;</comment>
                            <comment id="15644061" author="apache9" created="Mon, 7 Nov 2016 12:35:22 +0000"  >&lt;p&gt;Oh the fix in v1 patch is not right, let me think of a better way to fix it...&lt;/p&gt;</comment>
                            <comment id="15644269" author="apache9" created="Mon, 7 Nov 2016 14:09:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt; I&apos;ve upload patch v2 in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt; where I have fixed a typo... I tried and there is no small size roll anymore. Could you please verify it again?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15644712" author="ram_krish" created="Mon, 7 Nov 2016 16:56:49 +0000"  >&lt;p&gt;I will check it. &lt;/p&gt;</comment>
                            <comment id="15646432" author="anoop.hbase" created="Tue, 8 Nov 2016 04:12:07 +0000"  >&lt;p&gt;So how is the perf now compared to old wal?  U see some improve? Or there may be some more things.&lt;br/&gt;
Elsewhere mentioned abt the #syncs more in async wal.  So seems like the latency associated with sync() op is much reduced and so we get more frequent sync calls getting passed as IO op. When the sync() is taking time, the next sync will accumulate more append and so reduced total# syncs. So this is a clear trade off?&lt;/p&gt;</comment>
                            <comment id="15646487" author="apache9" created="Tue, 8 Nov 2016 04:46:10 +0000"  >&lt;p&gt;It is still slower than the old FSHLog. Need to dig more.&lt;/p&gt;</comment>
                            <comment id="15646531" author="ram_krish" created="Tue, 8 Nov 2016 05:11:41 +0000"  >&lt;p&gt;One more query on the operation of syncFutures.&lt;br/&gt;
in finishSync() that gets called asynchronously we peek and then remove from the syncFutures. So we add to syncFutures in a synchronized block but we remove it asynchronously. So will this have an impact? How ever once we mark the syncFuture as done then the blocking thread on sync will get released. But will  this comparator logic will work fine now since syncFuture is now a PriorityQueue? In FSHLog it is LinkedBlockingqueue.&lt;/p&gt;</comment>
                            <comment id="15646548" author="apache9" created="Tue, 8 Nov 2016 05:20:53 +0000"  >&lt;p&gt;In the v2 patch syncFutures is no longer accessed in a synchronized block. The reason why I use a PriorityQueue here is because the sync with a higher txid may come first as we do this in HRegion.put&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; txid = wal.append();
  wal.sync(txid);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There is no lock so sync may come with a different order with append.&lt;/p&gt;</comment>
                            <comment id="15646549" author="ram_krish" created="Tue, 8 Nov 2016 05:21:37 +0000"  >&lt;p&gt;Similarly in FanoutFSOutput we have waitingAckQueue.&lt;br/&gt;
The AckHandler#completed() call does remove from this deque. Am not sure if this AckHandler#channelRead0 is going to be sequential. We add in flushBuffer to this queue and we remove in this AckHandler thread.&lt;br/&gt;
Is this fine? I don&apos;t know this model of netty so wanted to confirm once.&lt;/p&gt;</comment>
                            <comment id="15646554" author="apache9" created="Tue, 8 Nov 2016 05:24:10 +0000"  >&lt;p&gt;Netty event loop is single threaded and the seqNo for DFSPacket is generated inside event loop so it is fine.&lt;/p&gt;</comment>
                            <comment id="15646561" author="ram_krish" created="Tue, 8 Nov 2016 05:26:25 +0000"  >&lt;p&gt;I am just seeing v2. Now it is accessed in a different way.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The reason why I use a PriorityQueue here is because the sync with a higher txid may come first as we do this in HRegion.put&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Correct. I agree to use PriorityQueue. But just was checking cases where all it could go wrong. &lt;br/&gt;
Even now there is no synchronization. So you expect the remove/add to work correctly?&lt;/p&gt;</comment>
                            <comment id="15646573" author="apache9" created="Tue, 8 Nov 2016 05:32:51 +0000"  >&lt;p&gt;The syncFutures is only accessed inside the event loop thread. It is single threaded.&lt;/p&gt;</comment>
                            <comment id="15647596" author="apache9" created="Tue, 8 Nov 2016 13:41:10 +0000"  >&lt;p&gt;The issue is fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15649473" author="apache9" created="Wed, 9 Nov 2016 01:33:39 +0000"  >&lt;p&gt;Fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-17021&quot; title=&quot;Use RingBuffer to reduce the contention in AsyncFSWAL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-17021&quot;&gt;&lt;del&gt;HBASE-17021&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                                                <inwardlinks description="Is contained by">
                                        <issuelink>
            <issuekey id="13018053">HBASE-17021</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 7 Nov 2016 06:08:08 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i35z87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>