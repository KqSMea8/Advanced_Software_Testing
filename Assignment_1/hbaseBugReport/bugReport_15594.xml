<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 21:05:13 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-15594/HBASE-15594.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-15594] [YCSB] Improvements</title>
                <link>https://issues.apache.org/jira/browse/HBASE-15594</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Running YCSB and getting good results is an arcane art. For example, in my testing, a few handlers (100) with as many readers as I had CPUs (48), and upping connections on clients to same as #cpus made for 2-3x the throughput. The above config changes came of lore; which configurations need tweaking is not obvious going by their names, there were no indications from the app on where/why we were blocked or on which metrics are important to consider. Nor was any of this stuff written down in docs.&lt;/p&gt;

&lt;p&gt;Even still, I am stuck trying to make use of all of the machine. I am unable to overrun a server though 8 client nodes trying to beat up a single node (workloadc, all random-read, with no data returned -p  readallfields=false). There is also a strange phenomenon where if I add a few machines, rather than 3x the YCSB throughput when 3 nodes in cluster, each machine instead is doing about 1/3rd.&lt;/p&gt;

&lt;p&gt;This umbrella issue is to host items that improve our defaults and noting how to get good numbers running YCSB. In particular, I want to be able to saturate a machine.&lt;/p&gt;

&lt;p&gt;Here are the configs I&apos;m currently working with. I&apos;ve not done the work to figure client-side if they are optimal (weird is how big a difference client-side changes can make &amp;#8211; need to fix this). On my 48 cpu machine, I can do about 370k random reads a second from data totally cached in bucketcache. If I short-circuit the user gets so they don&apos;t do any work but return immediately, I can do 600k ops a second but the CPUs are at 60-70% only. I cannot get them to go above this. Working on it.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;
hbase.ipc.server.read.threadpool.size
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;48&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;
    hbase.regionserver.handler.count
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;
hbase.client.ipc.pool.size
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;
hbase.htable.threads.max
&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;48&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12956205">HBASE-15594</key>
            <summary>[YCSB] Improvements</summary>
                <type id="14" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Umbrella</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2016 16:43:16 +0000</created>
                <updated>Wed, 29 Jun 2016 19:16:22 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>18</watches>
                                                                                                            <comments>
                            <comment id="15226612" author="stack" created="Tue, 5 Apr 2016 16:44:04 +0000"  >&lt;p&gt;I think this a critical issue given we should be able to use all of a machine and that YCSB is the yardstick by which we are measured (like-it-or-not)&lt;/p&gt;</comment>
                            <comment id="15226634" author="anoop.hbase" created="Tue, 5 Apr 2016 16:51:23 +0000"  >&lt;p&gt;So u are doing this test on trunk or branch-1?&lt;/p&gt;</comment>
                            <comment id="15226655" author="stack" created="Tue, 5 Apr 2016 16:56:43 +0000"  >&lt;p&gt;branch-1. branch-1 because I want to bring fixes into branch-1. You want me to try something? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15226658" author="anoop.hbase" created="Tue, 5 Apr 2016 16:59:06 +0000"  >&lt;p&gt;Just wanted to know whether 11425 work helped wrt more CPU usage..    We can check this later also.&lt;/p&gt;</comment>
                            <comment id="15226675" author="stack" created="Tue, 5 Apr 2016 17:09:09 +0000"  >&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11425&quot; title=&quot;Cell/DBB end-to-end on the read-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11425&quot;&gt;&lt;del&gt;HBASE-11425&lt;/del&gt;&lt;/a&gt; helps us get more work done but the issue here is more about getting over the apparent wall, improving defaults, and making configs less cryptic.&lt;/p&gt;</comment>
                            <comment id="15226683" author="busbey" created="Tue, 5 Apr 2016 17:12:23 +0000"  >&lt;p&gt;Is the plan for updated docs in our &lt;a href=&quot;http://hbase.apache.org/book.html#ycsb&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;very-outdated YCSB section in the ref guide&lt;/a&gt;? Or the &lt;a href=&quot;https://github.com/brianfrankcooper/YCSB/blob/master/hbase098/README.md&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBase README section in the YCSB project&lt;/a&gt;? either works since we can update the other to point. Since YCSB has multiple clients to deal with multiple HBase API versions already, it might be easier to point all of them at our ref guide.&lt;/p&gt;</comment>
                            <comment id="15226789" author="enis" created="Tue, 5 Apr 2016 18:04:15 +0000"  >&lt;p&gt;Great. Coincidentally, I was running YCSB myself yesterday. I can try to replicate your results. &lt;/p&gt;</comment>
                            <comment id="15226919" author="carp84" created="Tue, 5 Apr 2016 18:54:01 +0000"  >&lt;p&gt;Which version of YCSB you&apos;re running sir &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;? We happen to do benchmarking these days comparing 1.1.2 (with miscellaneous fixes on increment as well as reader/writer rowlock backported) and 0.98.12 using ycsb-0.7.0, and it turns out the pure read(get) performance declined a lot in our 1.1.2. After days of debugging (actually just located the root cause few hours ago), we found that there&apos;s a &lt;b&gt;small but fatal&lt;/b&gt; bug in &lt;tt&gt;HBaseClient10&lt;/tt&gt; that it initializes one connection per thread. We could find below codes in &lt;tt&gt;HBaseClient10#init&lt;/tt&gt;, line 135:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      THREAD_COUNT.getAndIncrement();
      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt;(THREAD_COUNT) {
        connection = ConnectionFactory.createConnection(config);
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;After fixing it in below way, the performance recovered:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      THREAD_COUNT.getAndIncrement();
      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt;(THREAD_COUNT) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(connection == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) connection = ConnectionFactory.createConnection(config);
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We were using 4 physical nodes as client, each node ran 8 YCSB process, each process launched 100 threads. We loaded 100GB data into 3 RS cluster, and then ran each client to do random get for 30 min, and w/o the fix 1.1.2 performance is ~20% lower than 0.98.12, which could be reproduced steadily. Hope this information could help.&lt;/p&gt;</comment>
                            <comment id="15226971" author="carp84" created="Tue, 5 Apr 2016 19:30:36 +0000"  >&lt;p&gt;Also raised an &lt;a href=&quot;https://github.com/brianfrankcooper/YCSB/issues/681&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;issue&lt;/a&gt; in YCSB, JFYI.&lt;/p&gt;</comment>
                            <comment id="15227017" author="stack" created="Tue, 5 Apr 2016 19:54:58 +0000"  >&lt;p&gt;Thanks for pointer &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt; ... will do both (one point at other).&lt;/p&gt;</comment>
                            <comment id="15227019" author="stack" created="Tue, 5 Apr 2016 19:55:23 +0000"  >&lt;p&gt;I&apos;m trying to hit 100% but am unable.&lt;/p&gt;</comment>
                            <comment id="15227283" author="busbey" created="Tue, 5 Apr 2016 22:38:40 +0000"  >&lt;p&gt;The number of connections bug was fixed in &lt;a href=&quot;https://github.com/brianfrankcooper/YCSB/pull/651&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;YCSB-651&lt;/a&gt;, which will be included in the 0.8.0 release, which is in candidates now.&lt;/p&gt;</comment>
                            <comment id="15227680" author="carp84" created="Wed, 6 Apr 2016 04:13:55 +0000"  >&lt;p&gt;Yeah, also got a response from YCSB-681. Thanks for the note Sean.&lt;/p&gt;</comment>
                            <comment id="15227699" author="stack" created="Wed, 6 Apr 2016 04:39:56 +0000"  >&lt;p&gt;Thank you for chiming in &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carp84&quot; class=&quot;user-hover&quot; rel=&quot;carp84&quot;&gt;Yu Li&lt;/a&gt; I have a 0.8.0 SNAPSHOT of YCSB that includes the above fix (sounds like it was a pain to find!):&lt;/p&gt;

&lt;p&gt;stack@ve0524:~/YCSB$ git log --oneline|grep 651&lt;br/&gt;
b21a3bf Merge pull request #651 from manolama/hbase10_init&lt;/p&gt;

&lt;p&gt;Are you able to overrun one of serving RegionServers in your setup? Can you drive the CPUs to 100%? I am unable. They are always 30-40% idle. Thanks.&lt;/p&gt;</comment>
                            <comment id="15227711" author="apache9" created="Wed, 6 Apr 2016 04:55:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; I guess your &apos;48 cpus&apos; are 2 * 12 cores with hyper-threading on? Have you tried disable the hyper-threading and try again?&lt;br/&gt;
I&apos;m not sure whether it is the problem. But hyper-threading does bring some difficulties to calculate the correct cpu utilization since it is only a virtual core and can not always perform like a physical core.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15227753" author="stack" created="Wed, 6 Apr 2016 05:31:00 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; for chiming in. I don&apos;t have easy access to the machines so a bit of a PITA disabling hyperthreading. Does anyone actually do this on production machines? Do you fellows do it? Thanks.&lt;/p&gt;</comment>
                            <comment id="15227763" author="apache9" created="Wed, 6 Apr 2016 05:40:42 +0000"  >&lt;p&gt;I do not have the permission to change the BIOS option of a server either...&lt;br/&gt;
But I think hyper-threading is a general option that does not only effect HBase. We could try some other applications on our own machine with or without hyper-threading.&lt;/p&gt;

&lt;p&gt;What do you think? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15227798" author="stack" created="Wed, 6 Apr 2016 06:19:57 +0000"  >&lt;p&gt;Hacking out the scheduler so I run the CallRunner in the Reader thread rather than give it to RpcSimpleScheduler to sort by priority and run in an appropriate executor, throughput doubles for my hacked simple (fake) Get and I can hit a 1M ops a second with 48 readers (200 readers seems to do a bit less). Scheduler costs and is a bottleneck (as expected). I&apos;m using PE rather than YCSB at the moment. mpstat show 19% idle still. htop shows about 1/3rd of CPUs at about 97% w/ the others doing less.&lt;/p&gt;</comment>
                            <comment id="15227909" author="carp84" created="Wed, 6 Apr 2016 07:58:56 +0000"  >&lt;p&gt;Yes, YCSB-651 is indeed a pain to find since lots of changes from 0.98.12 to 1.1.2 and we have to debug from server to client side to locate the problem...&lt;/p&gt;

&lt;p&gt;Checking the code, I&apos;m afraid with &lt;tt&gt;hbase.client.ipc.pool.size&lt;/tt&gt; set to 100 there would still be separate connection created for the same ConnectionId, so the setting would cause the same problem as the YCSB-651 bug.&lt;/p&gt;

&lt;p&gt;In our testing (i.e. 4 clients, each with 8*100 YCSB threads, 3 RS), there would be 3200 (4*8*100) socket connections to each RS, and the total read ops degraded from 750K/s to 580k/s (only 1 field with 128B cell, lrucache 100% hit). And our analysis is that with such high thread number on client side, plenty of connections would cause more context switch thus affect performance.&lt;/p&gt;

&lt;p&gt;I&apos;d suggest to remove the &lt;tt&gt;hbase.client.ipc.pool.size&lt;/tt&gt; setting and give it another try.&lt;/p&gt;</comment>
                            <comment id="15228827" author="stack" created="Wed, 6 Apr 2016 18:27:10 +0000"  >&lt;p&gt;Sorry, I missed this. hyperthreading messes w/ utilization and idle numbers reported as you suggest &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; though trying I was able to get to &amp;lt;20% idle w/ an odd CPU hitting 100%. Will focus more on throughput from here on.&lt;/p&gt;

&lt;p&gt;1. &lt;a href=&quot;http://perfdynamics.blogspot.com/2014/01/monitoring-cpu-utilization-under-hyper.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://perfdynamics.blogspot.com/2014/01/monitoring-cpu-utilization-under-hyper.html&lt;/a&gt;&lt;br/&gt;
2. &lt;a href=&quot;https://blogs.oracle.com/partnertech/en/entry/cpu_utilization_of_multi_threaded&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://blogs.oracle.com/partnertech/en/entry/cpu_utilization_of_multi_threaded&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15228950" author="stack" created="Wed, 6 Apr 2016 19:37:31 +0000"  >&lt;p&gt;Talking w/ someone versed in this stuff, I should be able to get to  10% or less idle time according to mpstat. So, a TODO here. Am going to work on why 3 node cluster doesn&apos;t do 3x the throughput how.&lt;/p&gt;</comment>
                            <comment id="15229310" author="stack" created="Wed, 6 Apr 2016 23:15:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;Checking the code, I&apos;m afraid with hbase.client.ipc.pool.size set to 100 there would still be separate connection created for the same ConnectionId, so the setting would cause the same problem as the YCSB-651 bug.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How you make out that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carp84&quot; class=&quot;user-hover&quot; rel=&quot;carp84&quot;&gt;Yu Li&lt;/a&gt;? There is no ConnectionId going on (at least in tip of branch-1 that I am working on) and if I look at the stack traces with hbase.client.ipc.pool.size == #cpus, it seems well-behaved. I count #cpu connections.&lt;/p&gt;

&lt;p&gt;On other hand, there is a zk connection issue: For each connection, there is its own zk connection which makes no sense. Connections should be sharing a zk connection. Each ycsb instance has hundreds of zk threads...(for 48 connections, there are 248 zk threads). There were so many zk threads, it was the bottleneck for me putting more load on the cluster. Had to up the ensemble connections from 300 to 3000 hbase.zookeeper.property.maxClientCnxns. I was seeing complaint that we were at max connections in ensemble logs. Need to fix this.&lt;/p&gt;

&lt;p&gt;Setting hbase.client.ipc.pool.size to #cpus doubles my ycsb throughput. At the default of 1 or 2 or 12, my throughput is way less.&lt;/p&gt;</comment>
                            <comment id="15229325" author="stack" created="Wed, 6 Apr 2016 23:24:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;d suggest to remove the hbase.client.ipc.pool.size setting and give it another try.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, if I leave this at default, my numbers are way less... 125k ops second on a single regionserver vs 400k.&lt;/p&gt;

&lt;p&gt;Starting 5 instances of ycsb, each w/ a pool size of 48, shows about the same throughput as running one instance maybe a bit more. W/ 700 threads running per instance, there&apos;ll be a bunch of context switching for sure.  It feels though like there is something holding us up given it is rare I fill all server handlers in spite of all these client instances (2k connections but handlers fluctuate wildly between 24 and max of 200). Running with PerformanceEvaluation, I was able to have handler count stay constantly up at the maximum.&lt;/p&gt;</comment>
                            <comment id="15229582" author="carp84" created="Thu, 7 Apr 2016 03:01:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;There is no ConnectionId going on&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Oh I meant the below codes in &lt;tt&gt;RpcClientImpl#getConnection&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    ConnectionId remoteId =
      &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ConnectionId(ticket, call.md.getService().getName(), addr);
    &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (connections) {
      connection = connections.get(remoteId);
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (connection == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        connection = createConnection(remoteId, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.codec, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.compressor);
        connections.put(remoteId, connection);
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When pool size larger than 1, there&apos;ll be more connection created to the RS.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For each connection, there is its own zk connection which makes no sense... Need to fix this&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed, good catch sir!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Setting hbase.client.ipc.pool.size to #cpus doubles my ycsb throughput. At the default of 1 or 2 or 12, my throughput is way less.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is the case running a single YCSB instance? If so, I guess I find the key point. When we hit YCSB-651 in our test, we were running 8 YCSB instances each with 100 threads, so there would be 800 connections created, way more than #cpus. Maybe in my case setting hbase.client.ipc.pool.size to #cpus/8 is the best choice, let me check and confirm.&lt;/p&gt;</comment>
                            <comment id="15229686" author="stack" created="Thu, 7 Apr 2016 04:50:29 +0000"  >&lt;p&gt;First, thanks for chiming in here &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carp84&quot; class=&quot;user-hover&quot; rel=&quot;carp84&quot;&gt;Yu Li&lt;/a&gt; Helps to bounce experience off another.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This is the case running a single YCSB instance? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;I tried doing 1 Connection of 4 and then running many instances but my numbers would not budge. When I set it to #cpus, my throughput doubled.&lt;/p&gt;

&lt;p&gt;Running multiple instances of the connections==#cpus doesn&apos;t seem to change my throughput which is odd.&lt;/p&gt;

&lt;p&gt;I seem to have &apos;fixed&apos; my issue where running 3 RS did not triple my throughput. Rather, I was seeing that each RS was getting 1/3rd of what the lone RS was getting. My issue was that I was getting this in the zk ensemble logs:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2016-04-06 14:55:36,218 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2222] server.NIOServerCnxnFactory: Too many connections from /10.17.240.23 - max is 300
2016-04-06 14:55:36,218 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2222] server.NIOServerCnxnFactory: Too many connections from /10.17.240.27 - max is 300
2016-04-06 14:55:36,218 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2222] server.NIOServerCnxnFactory: Too many connections from /10.17.240.23 - max is 300
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As a workaround, I set:&lt;/p&gt;


&lt;p&gt;354   &amp;lt;property&amp;gt;&lt;br/&gt;
355     &amp;lt;name&amp;gt;hbase.zookeeper.property.maxClientCnxns&amp;lt;/name&amp;gt;&lt;br/&gt;
356     &amp;lt;value&amp;gt;3000&amp;lt;/value&amp;gt;&lt;br/&gt;
357     &amp;lt;description&amp;gt;Property from ZooKeeper&apos;s config zoo.cfg.&lt;br/&gt;
358     Limit on number of concurrent connections (at the socket level) that a&lt;br/&gt;
359     single client, identified by IP address, may make to a single member of&lt;br/&gt;
360     the ZooKeeper ensemble. Set high to avoid zk connection issues running&lt;br/&gt;
361     standalone and pseudo-distributed.&amp;lt;/description&amp;gt;&lt;br/&gt;
362   &amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;.... to 3000 from 300.&lt;/p&gt;

&lt;p&gt;Need to fix the zk issue.&lt;/p&gt;

&lt;p&gt;There is also something up w/ naming of the connections...  will be back.&lt;/p&gt;

</comment>
                            <comment id="15233177" author="stack" created="Fri, 8 Apr 2016 23:59:59 +0000"  >&lt;p&gt;There is more to do it seems. I put up &lt;a href=&quot;https://github.com/brianfrankcooper/YCSB/pull/692&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/brianfrankcooper/YCSB/pull/692&lt;/a&gt; We are still making too many Connection instances.&lt;/p&gt;</comment>
                            <comment id="15290493" author="stack" created="Thu, 19 May 2016 05:38:09 +0000"  >&lt;p&gt;In YCSB trunk, there is an asynchbase now. I ran some compares. Also tried more than one RS on a node. In general, it seems like the asynchbase is able to drive more loading... a little bit more (with way less threads in client). Four RS on a Node are better than one if you size the handlers and readers appropriate; i.e. give each instance 1/4 the &quot;CPU&quot;s (Lets fix this and handlers and readers by cpu-count rather than ask users guess what is good!). Single RS w/ hbase10 could do 115k random reads (workloadc) with cpus about 35% idle. Four RS on single node w/ asynchbase could do about 175K with about 25% idle (Six nodes each running a Client with 48 threads &amp;#8211; the number of cpus &amp;#8211; against a single node server). Contention I can see in JFR is setting up the Scanner (registering the scanner in the Region Map), purging the WeakHashMap of bucketcache locks (this is an L1/L2 setup), and TimeRangeTracker. There are some rough notes here: &lt;a href=&quot;https://docs.google.com/document/d/1oyzHaue__mdnKEQrgeLVrufRIGqI08AHi7RszDPqmoI/edit?usp=sharing&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://docs.google.com/document/d/1oyzHaue__mdnKEQrgeLVrufRIGqI08AHi7RszDPqmoI/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="15291495" author="stack" created="Thu, 19 May 2016 16:52:19 +0000"  >&lt;p&gt;Random read, here is where CPU is being spent (perf top). We have some work to do:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  7.25%  perf-42125.map      [.] Lorg/apache/hadoop/hbase/io/hfile/HFileReaderV3$ScannerV3;.blockSeek
  6.17%  perf-42125.map      [.] Lorg/apache/hadoop/hbase/io/hfile/bucket/BucketCache;.getBlock
  6.14%  perf-42125.map      [.] Lorg/apache/hadoop/hbase/util/Counter;.add
  4.40%  perf-42125.map      [.] jshort_disjoint_arraycopy
  4.06%  libjvm.so           [.] TypeArrayKlass::allocate_common(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, bool, &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;*)
  2.93%  libjvm.so           [.] SpinPause
  2.43%  perf-42125.map      [.] jint_disjoint_arraycopy
  2.34%  perf-42125.map      [.] jlong_disjoint_arraycopy
  1.38%  perf-42125.map      [.] jbyte_disjoint_arraycopy
  1.35%  perf-42125.map      [.] Lorg/apache/hadoop/hbase/io/hfile/HFileBlockIndex$BlockIndexReader;.binarySearchNonRootIndex
  1.25%  libjvm.so           [.] ParallelTaskTerminator::offer_termination(TerminatorTerminator*)
  1.01%  perf-42125.map      [.] Lorg/apache/hadoop/hbase/util/CompoundBloomFilter;.contains
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Little by way of compares in this list since random read. The blockSeek is interesting as is counter. Need to work on that. The getBlock looks to be the purge from the weak hash map of all locks taking a bunch of time; shows as point of contention too. TODO after figure how to hit 100% CPU.&lt;/p&gt;</comment>
                            <comment id="15291530" author="ram_krish" created="Thu, 19 May 2016 17:11:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;The blockSeek is interesting as is counter.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;BlockSeek interested to know what you think. For random reads that will be a major one as we need to seek in a block for the given cell.  &lt;/p&gt;</comment>
                            <comment id="15291547" author="stack" created="Thu, 19 May 2016 17:16:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;. BlockSeek interested to know what you think.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Seems easy enough to &apos;fix&apos; at a later point... but my focus at moment is heating cores (smile)&lt;/p&gt;</comment>
                            <comment id="15316116" author="stack" created="Mon, 6 Jun 2016 01:48:57 +0000"  >&lt;p&gt;Hackery.. how to do Call on Reader thread and short-circuit Gets&lt;/p&gt;</comment>
                            <comment id="15316142" author="stack" created="Mon, 6 Jun 2016 02:42:10 +0000"  >&lt;p&gt;So, again, the Reader doing the whole read/parse of the request and then executing it ups our ops by &amp;gt;2x (From about 125k to 425k workloadc random reads from LRUBlockCache &amp;#8211; about 7-11% CPU idle). The new occupied-readers-count metric shows Readers reading all occupied nearly all the time... as opposed to what we see when we look at handlers (I can&apos;t get a higher utilization on handlers no matter what loading I put up). Mighty &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt; pointed me at a short-circuit the kudu folks do where they do direct handoff from reader to worker thread &lt;a href=&quot;http://gerrit.cloudera.org:8080/#/c/2938/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://gerrit.cloudera.org:8080/#/c/2938/&lt;/a&gt;... let me see if I can do similar.&lt;/p&gt;

&lt;p&gt;After the above hackery, the next &apos;blocker&apos; is the registry of Scanners in the Region CSLM with synchronization to get read point. If I hack it out &amp;#8211; have some ideas for making it less of a hurdle &amp;#8211; it is interesting to see that we then get stuck behind sending the response AND our throughput goes down slightly... So some work to do here.&lt;/p&gt;</comment>
                            <comment id="15316188" author="anoop.hbase" created="Mon, 6 Jun 2016 04:30:15 +0000"  >&lt;p&gt;Interesting Stack.&lt;/p&gt;</comment>
                            <comment id="15317219" author="stack" created="Mon, 6 Jun 2016 20:52:19 +0000"  >&lt;p&gt;0.98 is faster... 2x? 300k vs 125/140k. Reading from totally cached data (workloadc).&lt;/p&gt;</comment>
                            <comment id="15317250" author="stack" created="Mon, 6 Jun 2016 21:11:27 +0000"  >&lt;p&gt;Yeah. 300k for raw 0.98. Handlers are more occupied, running at about 42 out of 48 occupied. Let me add in my reader metric and see...&lt;/p&gt;</comment>
                            <comment id="15321299" author="stack" created="Wed, 8 Jun 2016 19:29:32 +0000"  >&lt;p&gt;I tried using simple FifoRpcScheduler but it only gave me a slight bump over the default. Had to up the Readers. It likes lots of Readers.  At far left of the hits graph, you can see rate when I do the Call on the Reader thread, The next rise at 125k ops is me messing w/ factor and ratios in SimpleRpcScheduler trying to give a Q per handler thread but it made no diff. On the right you see the first rise where I had default Readers for FIfo and then 48 Readers.&lt;/p&gt;</comment>
                            <comment id="15321577" author="enis" created="Wed, 8 Jun 2016 22:32:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;So, again, the Reader doing the whole read/parse of the request and then executing it ups our ops by &amp;gt;2x (From about 125k to 425k workloadc random reads from LRUBlockCache &#8211; about 7-11% CPU idle)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Very interesting. So the BQ handoff is the bottleneck even though no contention (1 Q per handler)? Try to hack disruptor? &lt;/p&gt;</comment>
                            <comment id="15330109" author="vrodionov" created="Tue, 14 Jun 2016 18:32:03 +0000"  >&lt;p&gt;One more thing to consider:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;io.storefile.bloom.error.rate&lt;/b&gt; which is default to 0.01. Interesting to see how setting this config to a lower value will affect overall random read performance and 99% latency? I would try to set it to 0.0001. Won&apos;t give anything if you have 1 store file (after major compaction), should improve numbers for all other cases.&lt;/p&gt;</comment>
                            <comment id="15330190" author="stack" created="Tue, 14 Jun 2016 19:11:16 +0000"  >&lt;p&gt;Five humps which are:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Current state of branch-1&lt;/li&gt;
	&lt;li&gt;branch-1 plus &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15971&quot; title=&quot;Regression: Random Read/WorkloadC slower in 1.x than 0.98&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15971&quot;&gt;&lt;del&gt;HBASE-15971&lt;/del&gt;&lt;/a&gt; (fifo) and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16023&quot; title=&quot;Fastpath for the FIFO rpcscheduler&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16023&quot;&gt;&lt;del&gt;HBASE-16023&lt;/del&gt;&lt;/a&gt; (fastpath)&lt;/li&gt;
	&lt;li&gt;branch-1 with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15971&quot; title=&quot;Regression: Random Read/WorkloadC slower in 1.x than 0.98&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15971&quot;&gt;&lt;del&gt;HBASE-15971&lt;/del&gt;&lt;/a&gt; (fifo) only&lt;/li&gt;
	&lt;li&gt;Hacks trying to remove region scanner sync point and then the Store registry of listener&lt;/li&gt;
	&lt;li&gt;Finally, running with codel that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mantonov&quot; class=&quot;user-hover&quot; rel=&quot;mantonov&quot;&gt;Mikhail Antonov&lt;/a&gt; asked for (its a bit slower than current branch-1 with no fixes).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15330217" author="stack" created="Tue, 14 Jun 2016 19:18:37 +0000"  >&lt;p&gt;Yeah. The mismatch between Readers and Handlers via queues costs us big time &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;. I don&apos;t see how 1 Q per handler will help (I&apos;ve tried it roughly but seemed to make no diff... possible to do w/ configs).  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ikeda&quot; class=&quot;user-hover&quot; rel=&quot;ikeda&quot;&gt;Hiroshi Ikeda&lt;/a&gt; work over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14331&quot; title=&quot;a single callQueue related improvements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14331&quot;&gt;HBASE-14331&lt;/a&gt; has promise. After the fixes in here though, we are bottlenecked on returning the result. After removing sync points in Region Scanner setup and the registering of Store Listeners for changed Readers, returning the results is the bottleneck to attack  next.&lt;/p&gt;</comment>
                            <comment id="15330221" author="stack" created="Tue, 14 Jun 2016 19:20:33 +0000"  >&lt;p&gt;I am intentionally getting all from cache in these tests &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; I am trying to drive the CPU to 100% but am unable to, not as yet at least. I am trying to find all the obstacles to our being able to overrun a machine.&lt;/p&gt;</comment>
                            <comment id="15355686" author="stack" created="Wed, 29 Jun 2016 19:16:22 +0000"  >&lt;p&gt;Commented out counts. Reduces count#add from ~10% of all CPU to ~3%&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12859840">HBASE-14331</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12896012">HBASE-14479</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12814869" name="counts.patch" size="7203" author="stack" created="Wed, 29 Jun 2016 19:16:22 +0000"/>
                            <attachment id="12808225" name="fast.patch" size="5293" author="stack" created="Mon, 6 Jun 2016 01:48:57 +0000"/>
                            <attachment id="12809012" name="fifo.hits.png" size="15583" author="stack" created="Wed, 8 Jun 2016 19:29:32 +0000"/>
                            <attachment id="12809011" name="fifo.readers.png" size="40004" author="stack" created="Wed, 8 Jun 2016 19:29:32 +0000"/>
                            <attachment id="12810594" name="withcodel.png" size="21680" author="stack" created="Tue, 14 Jun 2016 19:11:16 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12975340">HBASE-15948</subtask>
                            <subtask id="12975829">HBASE-15967</subtask>
                            <subtask id="12976215">HBASE-15971</subtask>
                            <subtask id="12976976">HBASE-15994</subtask>
                            <subtask id="12979043">HBASE-16022</subtask>
                            <subtask id="12979054">HBASE-16023</subtask>
                            <subtask id="12980354">HBASE-16063</subtask>
                            <subtask id="12985147">HBASE-16146</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 5 Apr 2016 16:51:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            24 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vo6n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>