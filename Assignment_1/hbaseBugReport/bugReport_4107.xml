<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:15:58 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-4107/HBASE-4107.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-4107] OOME while writing WAL checksum causes corrupt WAL</title>
                <link>https://issues.apache.org/jira/browse/HBASE-4107</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;An issue was observed where upon shutdown of a regionserver the regionserver log was corrupt.  It appears from the following stacktrace that an Java heap memory exception occurred while writing the checksum to the WAL.  Corrupting the WAL can potentially cause data loss. &lt;/p&gt;

&lt;p&gt;2011-07-14 14:54:53,741 FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog&lt;br/&gt;
java.io.IOException: Reflection&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:147)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog.sync(HLog.java:987)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:964)&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor1336.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:145)&lt;br/&gt;
        ... 2 more&lt;br/&gt;
Caused by: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$Packet.&amp;lt;init&amp;gt;(DFSClient.java:2375)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:3271)&lt;br/&gt;
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:150)&lt;br/&gt;
        at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:132)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3354)&lt;br/&gt;
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Writer.syncFs(SequenceFile.java:944)&lt;br/&gt;
        ... 6 more&lt;/p&gt;</description>
                <environment>&lt;p&gt;CentOS 5.5x64&lt;/p&gt;</environment>
        <key id="12514259">HBASE-4107</key>
            <summary>OOME while writing WAL checksum causes corrupt WAL</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="asautins">Andy Sautins</reporter>
                        <labels>
                    </labels>
                <created>Fri, 15 Jul 2011 18:06:36 +0000</created>
                <updated>Thu, 28 Feb 2013 00:46:55 +0000</updated>
                            <resolved>Thu, 28 Feb 2013 00:46:55 +0000</resolved>
                                    <version>0.90.1</version>
                                                    <component>regionserver</component>
                    <component>wal</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13091863" author="davelatham" created="Fri, 26 Aug 2011 16:41:45 +0000"  >&lt;p&gt;We recently hit the same issue.  I am able to download the corrupt WAL log file through the HDFS web interface, but cannot post it publicly.&lt;/p&gt;</comment>
                            <comment id="13091878" author="stack" created="Fri, 26 Aug 2011 17:08:37 +0000"  >&lt;p&gt;@Dave you need a walplayer (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3619&quot; title=&quot;OOME in Master splitting logs when the edits are BIG; 4-15MB&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3619&quot;&gt;&lt;del&gt;HBASE-3619&lt;/del&gt;&lt;/a&gt;).  Someone of us needs to hack it up.  I don&apos;t think it&apos;d be too hard to do.&lt;/p&gt;

&lt;p&gt;@Andy Do you think it the checksum&apos;ing that caused the OOME?  That might just be where we tripped over the OOME first.  I&apos;d more suspect the HFile$Reader.decompress that is going on concurrently.  Looks like the master splitting the log passed the data missing the checksum, so yeah, we lost that bit of data on the tail of WAL around time of OOME (My analysis here is cursory just looking at logs.  I did not do confirmation by digging in code).&lt;/p&gt;</comment>
                            <comment id="13091896" author="davelatham" created="Fri, 26 Aug 2011 17:40:30 +0000"  >&lt;p&gt;It looks like HLog main has support to invoke --split.  Does it looks like if I call that on the log that it will put split it and put the data into the right place?&lt;/p&gt;

&lt;p&gt;We had a handful of regionservers go OOM yesterday while a MR job was doing heavy writes to a column family that doesn&apos;t usually get them.  In this case, the first OOM occurred here during writing the checksum.&lt;/p&gt;</comment>
                            <comment id="13091916" author="stack" created="Fri, 26 Aug 2011 18:05:07 +0000"  >&lt;p&gt;@Dave That might work.  You could see what regions had files added to their recovered.edits and then you could do a reassign of the regions and on open in their new locations, they should play the recovered.edits.  If you try it, let us know how it goes.  Good stuff.&lt;/p&gt;</comment>
                            <comment id="13091917" author="asautins" created="Fri, 26 Aug 2011 18:08:46 +0000"  >&lt;p&gt;The behavior that Dave is seeing is what we were seeing as well.  It looks like objects are created from within the call to HLog.sync, specifically in our case DFSClient was creating a new Packet object and tried to allocate a byte array it couldn&apos;t allocate.  &lt;/p&gt;

&lt;p&gt;For the time being gotten around this issue by increasing the heap from 2G to 4G on our regionservers.  That seem to resolve it for us for now.  I&apos;ll look into it again, but it seems like an unfortunate situation where the data is written, but the checksum isn&apos;t able to be written due to an OOM.  It seems like possibly changing DFSClient to use a pool of pre-allocated Packet objects for writing might address this, but I&apos;m not sure I fully grasp the full problem yet. &lt;/p&gt;

</comment>
                            <comment id="13443521" author="lhofhansl" created="Tue, 28 Aug 2012 20:53:06 +0000"  >&lt;p&gt;Is this still an issue, or can we close this?&lt;/p&gt;</comment>
                            <comment id="13443647" author="asautins" created="Tue, 28 Aug 2012 23:21:55 +0000"  >&lt;p&gt;I believe we can close it.  This issue we were experiencing was resolved for us after apply ing &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2379&quot; title=&quot;0.20: Allow block reports to proceed without holding FSDataset lock&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2379&quot;&gt;&lt;del&gt;HDFS-2379&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12491805" name="master.splitting.log" size="12043" author="davelatham" created="Fri, 26 Aug 2011 16:41:45 +0000"/>
                            <attachment id="12491804" name="regionserver.oom.log" size="4567" author="davelatham" created="Fri, 26 Aug 2011 16:41:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 26 Aug 2011 16:41:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>27173</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 16 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02ccv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11603</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>