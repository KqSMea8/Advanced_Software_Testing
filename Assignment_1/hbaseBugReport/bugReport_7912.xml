<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:50:14 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7912/HBASE-7912.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7912] HBase Backup/Restore Based on HBase Snapshot</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7912</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Finally, we completed the implementation of our backup/restore solution, and would like to share with community through this jira. &lt;/p&gt;

&lt;p&gt;We are leveraging existing hbase snapshot feature, and provide a general solution to common users. Our full backup is using snapshot to capture metadata locally and using exportsnapshot to move data to another cluster; the incremental backup is using offline-WALplayer to backup HLogs; we also leverage global distribution rolllog and flush to improve performance; other added-on values such as convert, merge, progress report, and CLI commands. So that a common user can backup hbase data without in-depth knowledge of hbase.  Our solution also contains some usability features for enterprise users. &lt;/p&gt;

&lt;p&gt;The detail design document and CLI command will be attached in this jira. We plan to use 10~12 subtasks to share each of the following features, and document the detail implement in the subtasks: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;b&gt;Full Backup&lt;/b&gt; : provide local and remote back/restore for a list of tables&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;offline-WALPlayer&lt;/b&gt; to convert HLog to HFiles offline (for incremental backup)&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;distributed&lt;/b&gt; Logroll and distributed flush&lt;/li&gt;
	&lt;li&gt;Backup &lt;b&gt;Manifest&lt;/b&gt; and history&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Incremental&lt;/b&gt; backup: to build on top of full backup as daily/weekly backup&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Convert&lt;/b&gt;  incremental backup WAL files into hfiles&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Merge&lt;/b&gt; several backup images into one(like merge weekly into monthly)&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;add and remove&lt;/b&gt; table to and from Backup image&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Cancel&lt;/b&gt; a backup process&lt;/li&gt;
	&lt;li&gt;backup progress &lt;b&gt;status&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;full backup based on &lt;b&gt;existing snapshot&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;&lt;b&gt;-------------------------------------------------------------------------------------------------------------&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;Below is the original description, to keep here as the history for the design and discussion back in 2013&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;There have been attempts in the past to come up with a viable HBase backup/restore solution (e.g., &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4618&quot; title=&quot;HBase backups&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4618&quot;&gt;HBASE-4618&lt;/a&gt;).  Recently, there are many advancements and new features in HBase, for example, FileLink, Snapshot, and Distributed Barrier Procedure. This is a proposal for a backup/restore solution that utilizes these new features to achieve better performance and consistency. &lt;/p&gt;

&lt;p&gt;A common practice of backup and restore in database is to first take full baseline backup, and then periodically take incremental backup that capture the changes since the full baseline backup. HBase cluster can store massive amount data.  Combination of full backups with incremental backups has tremendous benefit for HBase as well.  The following is a typical scenario for full and incremental backup.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The user takes a full backup of a table or a set of tables in HBase.&lt;/li&gt;
	&lt;li&gt;The user schedules periodical incremental backups to capture the changes from the full backup, or from last incremental backup.&lt;/li&gt;
	&lt;li&gt;The user needs to restore table data to a past point of time.&lt;/li&gt;
	&lt;li&gt;The full backup is restored to the table(s) or to different table name(s).  Then the incremental backups that are up to the desired point in time are applied on top of the full backup.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;We would support the following key features and capabilities.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Full backup uses HBase snapshot to capture HFiles.&lt;/li&gt;
	&lt;li&gt;Use HBase WALs to capture incremental changes, but we use bulk load of HFiles for fast incremental restore.&lt;/li&gt;
	&lt;li&gt;Support single table or a set of tables, and column family level backup and restore.&lt;/li&gt;
	&lt;li&gt;Restore to different table names.&lt;/li&gt;
	&lt;li&gt;Support adding additional tables or CF to backup set without interruption of incremental backup schedule.&lt;/li&gt;
	&lt;li&gt;Support rollup/combining of incremental backups into longer period and bigger incremental backups.&lt;/li&gt;
	&lt;li&gt;Unified command line interface for all the above.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The solution will support HBase backup to FileSystem, either on the same cluster or across clusters.  It has the flexibility to support backup to other devices and servers in the future.  &lt;/p&gt;</description>
                <environment></environment>
        <key id="12633702">HBASE-7912</key>
            <summary>HBase Backup/Restore Based on HBase Snapshot</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12750434">HBASE-12342</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="vrodionov">Vladimir Rodionov</assignee>
                                    <reporter username="rding">Richard Ding</reporter>
                        <labels>
                            <label>backup</label>
                    </labels>
                <created>Fri, 22 Feb 2013 23:01:09 +0000</created>
                <updated>Thu, 17 Nov 2016 22:26:30 +0000</updated>
                                                            <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>5</votes>
                                    <watches>57</watches>
                                                                <comments>
                            <comment id="13584801" author="yuzhihong@gmail.com" created="Fri, 22 Feb 2013 23:13:38 +0000"  >&lt;p&gt;What release are you targeting this feature ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13584807" author="mbertozzi" created="Fri, 22 Feb 2013 23:20:48 +0000"  >&lt;p&gt;Can you explain the main differences between this and snapshots?&lt;/p&gt;

&lt;p&gt;also not sure if taking the first backup as snapshot and then keeping the WALs is a good idea. The WALs are not per table/region but you get lots of data that is not related to your backup.&lt;/p&gt;</comment>
                            <comment id="13585033" author="jinghe" created="Sat, 23 Feb 2013 06:05:24 +0000"  >&lt;p&gt;Hi, Matteo&lt;br/&gt;
HBase snapshot enables the efficient capture of a consistent and point-in-time (both to some degree) HBase table image.  But snapshot alone is not enough for a complete backup and restore/recovery solution.  The snapshot information and data is tightly coupled and stored with the existing HBase cluster &amp;#8211; in-place backup if I understand it correctly. Restore/recovery is only possible for certain types of data loss on the live HBase, for example, application errors.  We want to backup HBase data to FileSystem cross clusters. This proposal is a logical extension to the snapshot feature. &lt;/p&gt;</comment>
                            <comment id="13585046" author="jinghe" created="Sat, 23 Feb 2013 06:14:58 +0000"  >&lt;p&gt;Hi,Matteo&lt;/p&gt;

&lt;p&gt;Regarding the second part of your comment, it is good one. One idea is to replay the backed-up WALs into HFiles offline behind the scene and you only replay and keep in storage what you need. Also restore the resulting HFiles via bulk load utility is faster during incremental restore. That is important thing as well. &lt;/p&gt;</comment>
                            <comment id="13585051" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 06:21:49 +0000"  >&lt;p&gt;w.r.t. second part of Matteo&apos;s comment, once &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5699&quot; title=&quot;Run with &amp;gt; 1 WAL in HRegionServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5699&quot;&gt;&lt;del&gt;HBASE-5699&lt;/del&gt;&lt;/a&gt; is implemented, we can group WALEdits by table. Meaning, one HLog file only contains edits from a single table.&lt;br/&gt;
Then WAL replay can pick up relevant HLog files by table name.&lt;/p&gt;</comment>
                            <comment id="13585053" author="jinghe" created="Sat, 23 Feb 2013 06:24:52 +0000"  >&lt;p&gt;Hi, Ted&lt;/p&gt;

&lt;p&gt;Since this depends on snapshot (offline and online), 0.96 is the hope-for target release.&lt;/p&gt;</comment>
                            <comment id="13585129" author="mbertozzi" created="Sat, 23 Feb 2013 14:39:39 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;But snapshot alone is not enough &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a complete backup and restore/recovery solution. The snapshot information and data is tightly coupled and stored with the existing HBase cluster &#8211; in-place backup &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; I understand it correctly. Restore/recovery is only possible &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; certain types of data loss on the live HBase, &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; example, application errors. We want to backup HBase data to FileSystem cross clusters.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Not sure to follow...&lt;br/&gt;
A snapshot basically references all the data at the specified moment in the table.&lt;br/&gt;
You can restore a table from a snapshot that means remove the new content and replace with the old content/schema. Or you can create a new table (clone) from the snapshot content.&lt;br/&gt;
This means that you can drop your table and &quot;recreate&quot; it from the snapshot and you get back all your data.&lt;/p&gt;

&lt;p&gt;Also you can Export the snapshot to another cluster. And this means copying the snapshot metadata + the hfiles. And this allows you to restore/clone the snapshot on the other cluster. So is basically having the Cluster A table at time X on Cluster B.&lt;/p&gt;

&lt;p&gt;and I guess is what you want to do...&lt;br/&gt;
but maybe I&apos;m missing something&lt;/p&gt;</comment>
                            <comment id="13585132" author="yuzhihong@gmail.com" created="Sat, 23 Feb 2013 14:50:49 +0000"  >&lt;p&gt;@Matteo:&lt;br/&gt;
I think the difference in Richard&apos;s proposal is this:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;and then periodically take incremental backup that capture the changes since the full baseline backup.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13585160" author="mbertozzi" created="Sat, 23 Feb 2013 16:38:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ted_yu&quot; class=&quot;user-hover&quot; rel=&quot;ted_yu&quot;&gt;Ted Yu&lt;/a&gt; unless you need all the history put by put, you can take a snapshot every hour and the files not compacted are shared between the old one and the new one and maybe the table (but this could be improved once we have the compaction at block level instead of file level)&lt;/p&gt;</comment>
                            <comment id="13585290" author="rding" created="Sun, 24 Feb 2013 04:32:01 +0000"  >&lt;p&gt;@Matteo:&lt;br/&gt;
Snapshot alone is not enough for a disaster recovery solution. Although HBase replication is a viable disaster recovery solution, backup and recovery can also be very useful for users who don&apos;t need a live standby cluster and for situations where programmer or operator errors occur. &lt;/p&gt;

&lt;p&gt;Due to the high volume of data getting into a HBase cluster, it may not be feasible to only take frequent full backups. Here we propose to implement the standard RDBM backup technology that supports periodic full snapshot backups as well as incremental backup of transaction logs.&lt;/p&gt;

&lt;p&gt;We&apos;ve found that snapshot backups take a lot less time than backups based on Export utility. And with bulk loading, restore is also faster.  &lt;/p&gt;</comment>
                            <comment id="13585317" author="jinghe" created="Sun, 24 Feb 2013 07:05:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;unless you need all the history put by put, you can take a snapshot every hour and the files not compacted are shared between the old one and the new one &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;you take a snapshot every hour, and we copy out the snapshot every hour, &lt;/p&gt;</comment>
                            <comment id="13585322" author="jinghe" created="Sun, 24 Feb 2013 07:44:33 +0000"  >&lt;p&gt;(The last comment was accidentaly sent out before I finished. Contitue here.)&lt;br/&gt;
this is still a full backup every hour. If you export the snapshots to the same target, in ExportSnapshot, there is optimization to avoid duplicate copying of the same files (not yet compacted files) by checking if the files are already in the target. &lt;br/&gt;
Still because of compaction, hour by hour, eventually the same target will be full of duplicate data (different files but contain the same data).  Or did I misundertand anything here?&lt;br/&gt;
Snapshot and exporting snaphot is ideal for full baseline backup. There is a need to incrementally backup the delta from t1 to t2. WALs are good for that. &lt;/p&gt;</comment>
                            <comment id="13585340" author="mbertozzi" created="Sun, 24 Feb 2013 10:19:21 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Still because of compaction, hour by hour, eventually the same target will be full of duplicate data (different files but contain the same data). Or did I misundertand anything here?
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;True, this is a problem of the current way to use the fs + compaction, but that can be solved in the future. I think that somewhere referring to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7806&quot; title=&quot;Isolate the FileSystem calls&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7806&quot;&gt;HBASE-7806&lt;/a&gt; I&apos;ve mentioned data deduplication to fix this case.&lt;/p&gt;

&lt;p&gt;If we have the log per table/region as Ted mentioned I think that the snapshot + wals is a good short term approach. But looking at the long term the snapshot should be enough since the only problem now is the duplicated data due to compaction (also other consistency models can be plugged into snapshot, instead of the current Flush and snapshot, multi table and specified familes are other things that can be added to the snapshot, and as far as I remember were mentioned in the beginning of the development but skipped from the first step to get out with the basic functionality)&lt;/p&gt;</comment>
                            <comment id="13629701" author="carp84" created="Fri, 12 Apr 2013 02:15:34 +0000"  >&lt;p&gt;@Matteo&lt;br/&gt;
One kind of late question for the comment &quot;unless you need all the history put by put, you can take a snapshot every hour and the files not compacted are shared between the old one and the new one and maybe the table&quot;:&lt;/p&gt;

&lt;p&gt;For disaster recovery, we need to export snapshot to another cluster if following the snapshot way, right? In this case, can files shared between local snapshots still be shared between the target-exported image? Or do we support &quot;incrementally&quot; export snapshot? IMHO, we need this &quot;incremental&quot; feature to reduce cross-cluster copy cost, for both export/backup and restore, what&apos;s your opinion?&lt;/p&gt;</comment>
                            <comment id="13957991" author="yuzhihong@gmail.com" created="Wed, 2 Apr 2014 18:23:18 +0000"  >&lt;p&gt;A few questions on the design doc:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;to make sure only one backup is on-going&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can this constraint be relaxed ?&lt;br/&gt;
There can be more than one namespace in the source cluster. Is it reasonable to allow concurrent backups, one for each namespace ?&lt;/p&gt;

&lt;p&gt;In the document, WAL number is log sequence Id, right ?&lt;/p&gt;</comment>
                            <comment id="13958402" author="mbertozzi" created="Thu, 3 Apr 2014 00:55:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;The snapshot information and data is tightly coupled and stored with the existing HBase cluster &amp;#8211; in-place backup. We want to backup HBase data to FileSystem cross clusters and possible other storage media or servers.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;How ExportSnapshot is not enabling this?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Full backup and restore. Backup will first invoke HBase snapshot and export snapshot internally. &lt;br/&gt;
The full backup can be restored with HBase bulk import utility.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;What does &quot;internally&quot; means? &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Incremental backup uses WALs to capture the data changes since last full backup or incremental &lt;br/&gt;
backup. We execute roll log across region servers to track the WALs that need to be in the backup. &lt;br/&gt;
Then a distributed copy is used to move the physical files to target FileSystem.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;When the logs are copied are also splitted to avoid to send tables that are not part of the backup or is just a file copy?&lt;/p&gt;

&lt;p&gt;Is a &quot;Full backup&quot; just a snapshot?&lt;/p&gt;

&lt;p&gt;Where the backup manifests will be stored? I guess they must stay on the source cluster to allow you to implement the &quot;wal cleaner&quot; to keep around logs for Incremental backup.&lt;/p&gt;

&lt;p&gt;how do you decide for how log keep logs for a possible incoming Incremental Backup? &lt;/p&gt;

&lt;p&gt;how do you decide when is better doing an Incremental Backup as a full backup (e.g. Major compaction happened) vs just keeping the WAL?&lt;/p&gt;

&lt;p&gt;from the document looks like that you are triying to build a separate system that can produce the same result of the current snapshot (aside of the &quot;extensions&quot;). I think you should aim to &quot;merge&quot; the snapshot code inside of the Backup Manager &amp;amp; co, since as far as I understand by doing a full backup you basically get the snapshot, and also you half rely on ExportSnapshot.&lt;/p&gt;</comment>
                            <comment id="13958443" author="carp84" created="Thu, 3 Apr 2014 02:14:52 +0000"  >&lt;p&gt;Glad to see the work and discussion here is put back on schedule &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nidmhbase&quot; class=&quot;user-hover&quot; rel=&quot;nidmhbase&quot;&gt;Demai Ni&lt;/a&gt;, I could see you&apos;ve got a bunch of questions to answer here. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13958944" author="nidmhbase" created="Thu, 3 Apr 2014 16:36:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carp84&quot; class=&quot;user-hover&quot; rel=&quot;carp84&quot;&gt;Yu Li&lt;/a&gt;, yes. Glad that we finally reached to the point that the solution is ready. And thanks for your contribution.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A few questions on the design doc:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;to make sure only one backup is on-going&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can this constraint be relaxed ?&lt;br/&gt;
There can be more than one namespace in the source cluster. Is it reasonable to allow concurrent backups, one for each namespace ?&lt;/p&gt;

&lt;p&gt;In the document, WAL number is log sequence Id, right ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;At this moment, the solution only support one backup at a time. But you are totally right that there is no technical blocker to relax it.  That will definitely be the very next step. &lt;/p&gt;

&lt;p&gt;and yes, WAL number is log sequence Id.&lt;/p&gt;</comment>
                            <comment id="13960473" author="nidmhbase" created="Fri, 4 Apr 2014 21:57:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;, &lt;/p&gt;

&lt;p&gt;many thanks for the comments. Very good point about &apos;full backup&apos;, which pretty much a wrap on snapshot and exportsnapshot. As Snapshot is a very good feature, so &apos;full backup&apos; alone doesn&apos;t provide much more benefit. &lt;/p&gt;

&lt;p&gt;The valuable part is the incremental-backup, which is on top of the full backup.  so that a user only need to take the &apos;full backup&apos; once at the initial phase. A concept of &apos;backup image&apos; is introduced, which is identified by backupID. The manifest file is stored inside &apos;backup image&apos; together with the data HFiles. so that &apos;backup image&apos; is self-explained, and can be moved around and restored independently.  &lt;/p&gt;

&lt;p&gt;Demai&lt;/p&gt;
</comment>
                            <comment id="13964537" author="nidmhbase" created="Wed, 9 Apr 2014 18:49:15 +0000"  >&lt;p&gt;hi, folks,&lt;/p&gt;

&lt;p&gt;The full backup patch is attached in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10900&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBase-10900&lt;/a&gt;, and detail frame work is documented there for your inputs. thanks&lt;/p&gt;

&lt;p&gt;Demai &lt;/p&gt;</comment>
                            <comment id="13994060" author="nidmhbase" created="Fri, 9 May 2014 23:39:19 +0000"  >&lt;p&gt;hi, folks,&lt;/p&gt;

&lt;p&gt;We have patches for both full backup (v4) and incremental backup (v1) uploaded today. With that, it is easy to apply this &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12644215/HBASE-11085-trunk-v1-contains-HBASE-10900-trunk-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-11085-trunk-v1-contains-HBASE-10900-trunk-v4.patch&lt;/a&gt; directly on trunk, and give it a try. &lt;/p&gt;

&lt;p&gt;Please see the example in both incremental backup jira : &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11085&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-11085&lt;/a&gt; and fullbackup jira : &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10900&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-10900&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will open more jiras and patches for other features (just as, merge, convert, delete, history, progress) in the coming weeks.&lt;/p&gt;

&lt;p&gt;Also, thanks for the review comments from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, and others. We will have a few follow-up improvements about zookeeper, protobuff, and leveraging the new snapshot manifest&lt;/p&gt;

&lt;p&gt;Demai&lt;/p&gt;</comment>
                            <comment id="13995387" author="nidmhbase" created="Mon, 12 May 2014 18:23:34 +0000"  >&lt;p&gt;Need HBase-11148 to roll the logs for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;full backup&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11085&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;incremental backup&lt;/a&gt;, and also mark a timestamp for the next incremental&lt;/p&gt;</comment>
                            <comment id="13995431" author="nidmhbase" created="Mon, 12 May 2014 18:37:35 +0000"  >&lt;p&gt;the ping on May 9 was lost during apache email outage. so reposted here&lt;br/&gt;
----------------------&lt;br/&gt;
hi, folks,&lt;/p&gt;

&lt;p&gt;We have patches for both full backup (v4) and incremental backup (v1) uploaded today. With that, it is easy to apply this &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12644215/HBASE-11085-trunk-v1-contains-HBASE-10900-trunk-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-11085-trunk-v1-contains-HBASE-10900-trunk-v4.patch&lt;/a&gt; directly on trunk, and give it a try.&lt;/p&gt;

&lt;p&gt;Please see the example in both incremental backup jira : &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11085&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-11085&lt;/a&gt; and fullbackup jira : &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10900&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-10900&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will open more jiras and patches for other features (just as, merge, convert, delete, history, progress) in the coming weeks.&lt;/p&gt;

&lt;p&gt;Also, thanks for the review comments from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; and others. We will have a few follow-up improvements about zookeeper, protobuff, and leveraging the new snapshot manifest&lt;/p&gt;

&lt;p&gt;Demai&lt;/p&gt;</comment>
                            <comment id="13996086" author="stack" created="Tue, 13 May 2014 05:44:45 +0000"  >&lt;p&gt;Very nice.&lt;/p&gt;

&lt;p&gt;This doc. with perhaps a little more commentary like it could go into the hbase refguide when this feature is committed?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12638283/HBase_BackupRestore-Jira-7912-CLI-v1.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12638283/HBase_BackupRestore-Jira-7912-CLI-v1.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We should add a &apos;backups&apos; chapter to hbase refguide when this comes in?&lt;/p&gt;

&lt;p&gt;From design doc:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We execute roll log across region servers to track the WALs that need to be in the backup. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Late question.  How we ensure the WAL is not moved aside or even deleted between time of snapshot and copy aside?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We&#8217;ll convert/replay the backed-up Hlogs into HFiles for fast incremental restore.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is interesting.  It is done against a cluster or it is just a MR job/tool?&lt;/p&gt;

&lt;p&gt;Looks very nice.&lt;/p&gt;

&lt;p&gt;Have you lads had much chance testing it out?&lt;/p&gt;

&lt;p&gt;What needs to go in first?  What should we review first?&lt;/p&gt;

&lt;p&gt;Thanks lads.&lt;/p&gt;

</comment>
                            <comment id="13996158" author="jinghe" created="Tue, 13 May 2014 07:10:42 +0000"  >&lt;p&gt;HI, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;thanks for the comment.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Have you lads had much chance testing it out?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, our QA and us all have tested this.  This feature has been in our product for 2 releases now&lt;/p&gt;</comment>
                            <comment id="13996599" author="nidmhbase" created="Tue, 13 May 2014 16:44:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;/p&gt;

&lt;p&gt;thanks for the comments. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This doc. with perhaps a little more commentary like it could go into the hbase refguide when this feature is committed?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In additional to the cli pdf I attached in this jira. more completed documents can be found here:  &lt;a href=&quot;http://www-01.ibm.com/support/knowledgecenter/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.admin.doc/doc/admin_hbase_bkuprestore_overview.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;IBM BigInsights 2.1.2&lt;/a&gt;, which was officially released in March 2014. We will open source all the features related with Backup/Restore from IBM BigInsights. We can move the documents to &apos;backup&apos; session of HBase ref book as you suggested, and certainly after incorporated the comments/suggestions from the community.&lt;/p&gt;

&lt;p&gt;About testing, thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jinghe&quot; class=&quot;user-hover&quot; rel=&quot;jinghe&quot;&gt;Jerry He&lt;/a&gt;&apos;s comment. We already did functional, stress testing internally before release. For the current patches, since we did some changes per suggestions from the community, additional dev testing is being carried on. &lt;/p&gt;

&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;We&#8217;ll convert/replay the backed-up Hlogs into HFiles for fast incremental restore. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is interesting. It is done against a cluster or it is just a MR job/tool?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;~70% of the code logic is from WalPlayer, a MR job against target cluster. The difference is, we don&apos;t rely on a live hbase cluster when convert the HLog to Hfiles as the code can access the tableinfo offline. Currently the code is only useful for the backup/restore solution. We&apos;d like to open another jira for the logic as a general tool/improvement of WalPlayer, and the new jira will have a dependency on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8073&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-8083 &lt;/a&gt;. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What needs to go in first? What should we review first?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Actually, need you and other folks&apos; suggestion here. &lt;/p&gt;

&lt;p&gt;From the dependency perspective, I&apos;d like to have &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10900&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Full backup HBase-10900&lt;/a&gt; in first, and then &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11085&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;incremental backup HBase-11085&lt;/a&gt;, and once Jerry&apos;s &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11148&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;global log roll HBase-11148&lt;/a&gt; get accepted. I will put a patch to update full and incremental to use it immediately.  Then, I would like to improve it with protobuff and abstract out zookeeper. &lt;/p&gt;

&lt;p&gt;If community accepts the solution of the general framework provided by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10900&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Full backup HBase-10900&lt;/a&gt; and  &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11085&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;incremental backup HBase-11085&lt;/a&gt;. We will build the patches of other features on top of the framework. &lt;/p&gt;

&lt;p&gt;At this moment, I am thinking about open another review board for the combined patches of &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12644215/HBASE-11085-trunk-v1-contains-HBASE-10900-trunk-v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;both incremental and full backup &lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;I understand a lot of codes involved here, and open to any suggestion to make the review easier to everyone. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;

&lt;p&gt;Demai&lt;/p&gt;</comment>
                            <comment id="14011276" author="nidmhbase" created="Wed, 28 May 2014 16:33:06 +0000"  >&lt;p&gt;hi, guys,&lt;/p&gt;

&lt;p&gt;I opened a review for the framework (patches of both full and incremental backup) here: &lt;a href=&quot;https://reviews.apache.org/r/21981/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/21981/&lt;/a&gt;. &lt;br/&gt;
Thanks for your suggestion/comments.&lt;/p&gt;

&lt;p&gt;Demai&lt;/p&gt;</comment>
                            <comment id="14017538" author="fenghh" created="Wed, 4 Jun 2014 10:04:46 +0000"  >&lt;p&gt;Just finished reading the design doc &quot;HBaseBackupRestore-Jira-7912-DesignDoc-v1.pdf&quot;. It&apos;s a good enhancement and extension to current data backup/restore option/solution, and the design doc reads quite concise and clear &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Some comments:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;&quot;Use case example 1&quot; in page 3: The full backup doesn&apos;t contain data of table3 and table4, so when restoring table3 and table4, their data are all restored from the incremental backups, right? Sounds it&apos;s not a typical scenario(full-backup + incremental backups) for backup/restore.&lt;/li&gt;
	&lt;li&gt;&quot;4. Full Backup&quot;: Does log roll take place after taking (full) snapshot? What if new writes arrive after taking snapshot but before log roll?&lt;/li&gt;
	&lt;li&gt;&quot;5. Incremental Backup&quot;: What if some RS fails during the log roll procedure so that not all current log number are recorded onto ZooKeeper?&lt;/li&gt;
	&lt;li&gt;What if some log files are archived/deleted between two incremental backups and are not included in any incremental backup? Is it possible?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Some (possible) typos in the design doc:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;&quot;2. Key features and Use Cases&quot;: &quot;Full back uses HBase...&quot; =&amp;gt; &quot;Full backup uses HBase...&quot;&lt;/li&gt;
	&lt;li&gt;&quot;5. Incremental Backup&quot;: &quot;kicks of a global...&quot; =&amp;gt; &quot;kicks off a global...&quot;&lt;/li&gt;
	&lt;li&gt;&quot;5. Incremental Backup&quot;: &quot;Incremental backups and also be...&quot; =&amp;gt; &quot;Incremental backups can also be...&quot;&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14017973" author="nidmhbase" created="Wed, 4 Jun 2014 18:30:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fenghh&quot; class=&quot;user-hover&quot; rel=&quot;fenghh&quot;&gt;Honghua Feng&lt;/a&gt;, many thanks for the comments &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&quot;Use case example 1&quot; in page 3: The full backup doesn&apos;t contain data of table3 and table4, so when restoring table3 and table4, their data are all restored from the incremental backups, right? Sounds it&apos;s not a typical scenario(full-backup + incremental backups) for backup/restore.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;during step c. &quot;.. user adds other table..&quot; this actually triggers an implicite full backup for table 3 and table 4. So when restore them in the future, the data will come both full and incremental backup. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&quot;4. Full Backup&quot;: Does log roll take place after taking (full) snapshot? What if new writes arrive after taking snapshot but before log roll?&lt;/p&gt;&lt;/blockquote&gt; 
&lt;p&gt;the logic is to take log roll first and then snapshot. if new writes arrive in between, it will be saved in the full backup image. And the same writes will be saved again in the next incremental backup. The approach is to ensure no data loss by allowing duplicate puts during restore. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&quot;5. Incremental Backup&quot;: What if some RS fails during the log roll procedure so that not all current log number are recorded onto ZooKeeper?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;in such case, the backup process will abort, and the clean up logic is the same as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11172&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HBASE-11172 cancel a backup process &lt;/a&gt;. The code will remove the incomplete backup image and roll back zookeeper state to the previous backup. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What if some log files are archived/deleted between two incremental backups and are not included in any incremental backup? Is it possible?&lt;/p&gt;&lt;/blockquote&gt; 
&lt;p&gt;Good point. (also thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;, who pointed out the same problem earlier). There is a log cleaner that hasn&apos;t been included in the patch yet. It is called BackupLogCleaner extended from BaseLogCleanerDelegate, as part of hbase.master.logcleaner.plugins. It would keep the logs. The side-effect would be (if user don&apos;t do incremental too often) too much log files left. We have a stop -all feature to remove all backup tables, also will free up the logs. &lt;/p&gt;

&lt;p&gt;Thanks for pointing out the typo. I will fix them up in the doc. &lt;/p&gt;</comment>
                            <comment id="14018210" author="nidmhbase" created="Wed, 4 Jun 2014 21:25:45 +0000"  >&lt;p&gt;uploaded designDoc V2 with a few minor changes, and listed limitations&lt;/p&gt;</comment>
                            <comment id="14183314" author="stack" created="Fri, 24 Oct 2014 19:09:22 +0000"  >&lt;p&gt;Moved out of hbase 1.0.  No progress.&lt;/p&gt;</comment>
                            <comment id="14611269" author="vrodionov" created="Thu, 2 Jul 2015 00:59:19 +0000"  >&lt;p&gt;Updated version of a design document. Contains some new features and roadmap. Any feedback is welcomed.&lt;/p&gt;

&lt;p&gt;One question on design decision: should we add incremental support to snapshots and use it in this feature or this approach (incremental support in backup) is OK.&lt;/p&gt;

&lt;p&gt;I am asking about this because folks @HW have different opinions.  &lt;/p&gt;

&lt;p&gt;I am, personally -1 on adding new features to snapshots because I see them obsolete once a backup/restore feature is fully complete. &lt;/p&gt;</comment>
                            <comment id="14611468" author="mbertozzi" created="Thu, 2 Jul 2015 04:55:49 +0000"  >&lt;p&gt;you should probably wait or coordinate with the guys over &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13991&quot; title=&quot;Hierarchical Layout for Humongous Tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13991&quot;&gt;HBASE-13991&lt;/a&gt;&lt;br/&gt;
if we change the fs-layout, you can fully replace snapshots with the backup feature, get rid of the filelinks and so on (see the jira)&lt;/p&gt;

&lt;p&gt;couple of question on the incremental backup&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;assuming that on the WAL there are multiple regions, is there any logic to decide that using hfiles instead of wal is better? or do you want always the full ability to restore up to &quot;a specific seqid&quot;?&lt;/li&gt;
	&lt;li&gt;when do you decide to &quot;compact the wals&quot; on the backup? who is doing that the backup manger?&lt;/li&gt;
	&lt;li&gt;when you export to another media, who is responsible to compact the wals?&lt;/li&gt;
	&lt;li&gt;in the document there is mention of &quot;convert the wals to hfiles&quot;, in this way we loose the ability to restore up to &quot;a specific seqid&quot;, which goes back to the question, if we don&apos;t need that, is there any logic to decide that using hfiles instead of wal is better for incremental?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14612142" author="vrodionov" created="Thu, 2 Jul 2015 16:15:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;you should probably wait or coordinate with the guys over &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13991&quot; title=&quot;Hierarchical Layout for Humongous Tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13991&quot;&gt;HBASE-13991&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I joined the watch list, thanks&lt;/p&gt;

&lt;p&gt;Now your questions:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;assuming that on the WAL there are multiple regions, is there any logic to decide that using hfiles instead of wal is better? or do you want always the full ability to restore up to &quot;a specific seqid&quot;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;First of all, we do not restore to a specific seqId, we restore a specific backup image, which in turn, for each table is a combination of a last snapshot and sequence of WAL files. WAL conversion to HFiles is a way to improve restore performance, because HFiles we just copy over to restore location and WAL files we have to replay.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;when do you decide to &quot;compact the wals&quot; on the backup? who is doing that the backup manger?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Its a manual procedure which can be executed by system (global) admin. When to run it is up to this person to decide.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;when you export to another media, who is responsible to compact the wals?&lt;/p&gt;&lt;/blockquote&gt; 
&lt;p&gt;Exporting to another media is the artifact from the original design, feature which won&apos;t be supported. I will update the doc. If by compacting wals you mean - converting them to HFiles or merging backup images, then this is manual procedures (you will have to run hbase backup convert/merge tool).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;in the document there is mention of &quot;convert the wals to hfiles&quot;, in this way we loose the ability to restore up to &quot;a specific seqid&quot;, which goes back to the question, if we don&apos;t need that, is there any logic to decide that using hfiles instead of wal is better for incremental?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for this question, it turned out that original design has a flaw we have not noticed before. As since we do not record last backed up seqId and do not restore up to that seqId - that is kind of tricky imo, there will be some duplicates of KVs in store files after incremental restore. These duplicates are result of how we do full backup and first incremental backup after full. &lt;/p&gt;

&lt;p&gt;During full backup we perform distributed log roll and record, for every RS, last WAL timestamp, then we do snapshot. The next WAL after recorded will make it into next incremental backup set, but it will contains some edits (puts, deletes) which have been recorded by a previous snapshot. During restore, we first restore snapshot, then we will replay WALs and create some duplicates of KVs in different store files. &lt;/p&gt;






</comment>
                            <comment id="14612147" author="vrodionov" created="Thu, 2 Jul 2015 16:18:06 +0000"  >&lt;p&gt;I want to clarify this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I am, personally -1 on adding new features to snapshots because I see them obsolete once a backup/restore feature is fully complete.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I just wanted to point out that I do not see any reason in adding incremental support to snapshots. Snapshots are lightweight by design and implementation. They can be created pretty fast. They are stored in place (in the same cluster) and do not consume much space. You need incremental support only if you do export of snapshot, but this is what backup is designed for. Correct? Use incremental backup instead.&lt;/p&gt;</comment>
                            <comment id="14612372" author="vrodionov" created="Thu, 2 Jul 2015 18:54:48 +0000"  >&lt;p&gt;Added incremental restore sub-section, described potential data duplication after first incremental  backup after full backup.&lt;/p&gt;</comment>
                            <comment id="14612377" author="vrodionov" created="Thu, 2 Jul 2015 18:55:41 +0000"  >&lt;p&gt;Kindly soliciting feedback from community.&lt;/p&gt;</comment>
                            <comment id="14612384" author="ndimiduk" created="Thu, 2 Jul 2015 19:01:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;Kindly soliciting feedback from community.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You may have more luck with a mail to the dev/user lists.&lt;/p&gt;</comment>
                            <comment id="14612401" author="mbertozzi" created="Thu, 2 Jul 2015 19:19:08 +0000"  >&lt;p&gt;more questions&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is the backup manager handling stuff like &quot;take a backup every N hours&quot;? Do we really want &quot;scheduled jobs&quot; handled by hbase? shouldn&apos;t we provide just the backup api and have the cron logic delegated to some external tool?&lt;/li&gt;
	&lt;li&gt;let say I want to take monthly backup of a specified table, are the WALs with that table in it always kept around for a possible future incremental backup?
	&lt;ul&gt;
		&lt;li&gt;what if I took a backup once on a test table and then I don&apos;t care about it anymore and I don&apos;t delete the backup? are all the wals kept around forever?&lt;/li&gt;
		&lt;li&gt;if the table I want to backup is &quot;small&quot; compared to the others are there cleaners to avoid having lots of space wasted by other tables in the wal or the incremental requires multi-wal (one wal per table)?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14612459" author="vrodionov" created="Thu, 2 Jul 2015 20:17:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;:&lt;br/&gt;
Backup scheduling is a feature which can be excluded from a feature list, because, as you pointed out everything can be done with a regular cron job (we will provide API through hbase command line tool).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;let say I want to take monthly backup of a specified table, are the WALs with that table in it always kept around for a possible future incremental backup?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, if you take backup only once a month, WAL files MUST be kept in archive location for at least a month. Just do not do that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, make backups at least daily. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;what if I took a backup once on a test table and then I don&apos;t care about it anymore and I don&apos;t delete the backup? are all the wals kept around forever?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;WAL files will be kept at backup destination until the particular backup image exists. The CML tool will allow to delete/merge/convert incremental backup images. Full set of useful commands. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;if the table I want to backup is &quot;small&quot; compared to the others are there cleaners to avoid having lots of space wasted by other tables in the wal or the incremental requires multi-wal (one wal per table)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good question. In the current patch (See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11085&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-11085&lt;/a&gt;) the whole WAL gets copied even if we backup only one &apos;small&apos; table. This will be improved - read design document, it describes two approaches.&lt;/p&gt;

</comment>
                            <comment id="14612544" author="jinghe" created="Thu, 2 Jul 2015 21:20:23 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you for picking up the work! &lt;br/&gt;
Hopefully we&apos;ll have a good backup support in HBase from this work.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; had many good questions previously &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14613440" author="jinghe" created="Fri, 3 Jul 2015 20:22:47 +0000"  >&lt;p&gt;I went thru the v5 doc.  Looks good.&lt;/p&gt;

&lt;p&gt;There are some changes in there I see are good.&lt;br/&gt;
One of them is to use a new system table hbase:backup instead of zookeeper.  I definitely see benefit of using a system table.&lt;br/&gt;
There is also a section talking about with security support consistent with the existing HBase security.&lt;br/&gt;
Regarding the section &quot;First incremental after full backup restore&quot;, yes, there could data duplicated in two backups (the full and the incr).&lt;br/&gt;
It is better to fix it during the backup.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;&apos;s filesystem layout question is mainly a concern for upgrade and migration, I think. &lt;br/&gt;
We&apos;ve faced such problems. &lt;br/&gt;
We will need to make sure the current backup images (data and metadata) can be used to restore to future hbase releases.&lt;/p&gt;

&lt;p&gt;Will continue to read, and may comment later.&lt;/p&gt;</comment>
                            <comment id="14613517" author="lhofhansl" created="Fri, 3 Jul 2015 23:46:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; had mentioned something he did with incremental backups using snapshots once.&lt;/p&gt;</comment>
                            <comment id="14613541" author="mbertozzi" created="Sat, 4 Jul 2015 01:13:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; snapshots are already &quot;incremental&quot; in case you don&apos;t compact. you just export the new files. I don&apos;t think Elliott did more than that. &lt;br/&gt;
but this is different, here we are incremental because we copy the WAL. In case of no compaction the snapshot-incremental is probably better but as soon you start having compactions you have to copy the compacted files with the data you already have exported, since snapshot are only file based (so we may copy more data compared to the set of wals we are copying).&lt;/p&gt;</comment>
                            <comment id="14615326" author="vrodionov" created="Mon, 6 Jul 2015 17:13:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryhe&quot; class=&quot;user-hover&quot; rel=&quot;jerryhe&quot;&gt;Jerry He&lt;/a&gt; wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Regarding the section &quot;First incremental after full backup restore&quot;, yes, there could data duplicated in two backups (the full and the incr).&lt;br/&gt;
It is better to fix it during the backup.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Doing this during backup requires support of backup/restore up to a sequence Id (mvcc number). Doing this in a read path is trivial (several lines of code in a StoreScanner).  &lt;/p&gt;</comment>
                            <comment id="14615352" author="vrodionov" created="Mon, 6 Jul 2015 17:33:02 +0000"  >&lt;p&gt;Sequence ID is per Region and WAL is per RegionServer. We will need to store maximum sequence id per region after full backup. When we finish snapshot, we can collect all maximum sequence ids from store files and store them as a Map&amp;lt;Region, long&amp;gt;. During first incremental restore, we will need to check sequence id of every WAL Entry. If its below or equals to maximum seq id for this region - skip this entry. The logic will remains unchanged for all other incremental restores after the first one.  &lt;/p&gt;</comment>
                            <comment id="14615385" author="vrodionov" created="Mon, 6 Jul 2015 17:48:44 +0000"  >&lt;p&gt;So, the deduplication can be implemented either during read (original approach mentioned in the doc) or during restore (see above) or even during backup. Deduplication during backup will require WAL filtering during copy support, but this  is a feature which is on the roadmap. There are some pro- and contra- for all of them.&lt;/p&gt;

&lt;p&gt;READ: very simple to implement, but we will have duplication of some data in a file system of HBase after restore.&lt;br/&gt;
RESTORE:  not that simple, but no data duplication in HBase cluster after restore, but there will be some data duplication in backup location.&lt;br/&gt;
BACKUP: not that simple as well, but no duplication at all ... but relies on WAL filtering during copy support. &lt;/p&gt;
</comment>
                            <comment id="14617018" author="vrodionov" created="Tue, 7 Jul 2015 17:20:00 +0000"  >&lt;p&gt;Updated version of design document. Added section for KVs deduplication and some other stuff. &lt;/p&gt;</comment>
                            <comment id="14617316" author="vrodionov" created="Tue, 7 Jul 2015 20:24:45 +0000"  >&lt;p&gt;For the most recent updates please go to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14030&quot; title=&quot;HBase Backup/Restore Phase 1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14030&quot;&gt;&lt;del&gt;HBASE-14030&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15219148" author="vrodionov" created="Thu, 31 Mar 2016 01:01:28 +0000"  >&lt;p&gt;Updated design doc:&lt;/p&gt;

&lt;p&gt;Added description of backup directory layout, backup manifest and backup image.&lt;/p&gt;</comment>
                            <comment id="15219257" author="enis" created="Thu, 31 Mar 2016 03:17:18 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vrodionov&quot; class=&quot;user-hover&quot; rel=&quot;vrodionov&quot;&gt;Vladimir Rodionov&lt;/a&gt; for updating the design doc for layout and backup image formats. It helps understanding the patches better. &lt;/p&gt;

&lt;p&gt;We had discussed offline about this, and I thought the plan was to use the &lt;tt&gt;backupId&lt;/tt&gt; as the leading dir name. Instead of &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ROOT/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/test&#173;1459375580152/backup_1459375618126/archive/data/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/test&#173;1459375
580152/543f8c02c388dd931fb9bcd1c38e7372/f/a6ce4789f9b444d89bbc755254afd27d&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;, I think we should use the same directory layout of the &lt;tt&gt;hbase.rootdir&lt;/tt&gt; under the backup root dir: &lt;/p&gt;

&lt;p&gt;So for full backups it should look like this: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ROOT/backup_1459375618126/archive/data/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/test&#173;1459375
580152/543f8c02c388dd931fb9bcd1c38e7372/f/a6ce4789f9b444d89bbc755254afd27d&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. And for incremental backups the layout should still follow the same &lt;tt&gt;hbase.rootdir&lt;/tt&gt; layout. So instead of: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ROOT/WALs/backup_1459378688723/10.22.11.177%2C58809%2C1459378626079.14593786
59124&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;it should be: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ROOT/backup_1459378688723/WALs/10.22.11.177,58809,1459378626079/10.22.11.177%2C58809%2C1459378626079.14593786
59124&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Notice that there is an extra &amp;lt;ServerName&amp;gt; in the layout as well. &lt;/p&gt;

&lt;p&gt;This structure will allow the rest of the code base (like hfile links, etc) to work seamlessly and also will help with a large number of files under WALs. Also, all the table in the table set for a backup will be hosted together etc. &lt;/p&gt;

&lt;p&gt;You have &lt;tt&gt;not used&lt;/tt&gt; and &lt;tt&gt;obsolite&lt;/tt&gt; fields in the PB structures. Since this is new work, whatever is not used and not needed should be removed from the patches. &lt;/p&gt;

&lt;p&gt;The backup images contain this: &lt;tt&gt;required string root_dir = 3&#894;&lt;/tt&gt;, which I think we should remove. The problem with having the absolute path in the manifests is that, it will make the directory un-relocatable. The issue is that if the operator does rename, or otherwise changes NN info etc, then it will be silent data loss. I think we should make it so that every path in image / manifest is relative, and all ancestors are implicitly under the same remote backup location. &lt;/p&gt;

&lt;p&gt;This is from the doc: &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;There was concern that we can lose data in between incremental backup sessions and this why the tracking of already copied WAL files has been added, but it turned out that is not necessary to do this because we ALWAYS include ALL tables which have at least one backup session into final backup table list for incremental backup.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Without this, the issue with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15442&quot; title=&quot;HBase Backup Phase 2: Potential data loss and or data duplication in incremental backup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15442&quot;&gt;&lt;del&gt;HBASE-15442&lt;/del&gt;&lt;/a&gt; will still happen, no? With the dependency generation algorithm as in the doc, if I have: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;full backup t1 with backup_id = bid1&lt;/li&gt;
	&lt;li&gt;incremental backup t2 with backup_id = bid2&lt;/li&gt;
	&lt;li&gt;incremental backup t1 with backup_id = bid3&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;then bid3 will NOT depend on bid2, so it is data loss still, no? &lt;/p&gt;

&lt;p&gt;&lt;tt&gt;BackupImage&lt;/tt&gt; itself just duplicates the information that we already have in the manifest files. Do we really need that structure at all. Can we instead keep a list of backup_ids and read the manifests at the time of restore? &lt;/p&gt;</comment>
                            <comment id="15219325" author="vrodionov" created="Thu, 31 Mar 2016 04:35:06 +0000"  >&lt;blockquote&gt;
&lt;p&gt;We had discussed offline about this, and I thought the plan was to use the backupId as the leading dir name.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;-1. It is as it is. There is a reason for this layout: each table has a list (set) of backup sessions. All  depends on this layout.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You have not used and obsolite fields in the PB structures. Since this is new work, whatever is not used and not needed should be removed from the patches.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, this can be done, but some &quot;unused&quot; fields contains backup session stats. We do not use it now, but in a future?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;BackupImage itself just duplicates the information that we already have in the manifest files. Do we really need that structure at all. Can we instead keep a list of backup_ids and read the manifests at the time of restore?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Need to estimate the work.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;full backup t1 with backup_id = bid1&lt;br/&gt;
incremental backup t2 with backup_id = bid2&lt;br/&gt;
incremental backup t1 with backup_id = bid3&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;When you do incremental backup on t2, system automatically enhance backup set and adds ALL tables to it, which have at least one full backup image. So it will add t1 to t2. This is for free, because we copy only WAL files. No data loss.&lt;/p&gt;





</comment>
                            <comment id="15220352" author="yuzhihong@gmail.com" created="Thu, 31 Mar 2016 18:09:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;string rel_wal_ref&#8203; &#173; list of WAL files (relative) to this backup, which have been copied by other backup sessions but.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The above sentence seems incomplete. Is rel_wal_ref field still needed ?&lt;/p&gt;</comment>
                            <comment id="15220933" author="enis" created="Fri, 1 Apr 2016 00:44:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;-1. It is as it is. There is a reason for this layout: each table has a list (set) of backup sessions. All depends on this layout.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not sure I understand the objection. The dependency is from the backup history information, not from the layout from what I can see. You already have the backupId as the leading in the incremental case. Doing the same for full backup case makes perfect sense. If you have only one layout type, then doing an &lt;tt&gt;ls&lt;/tt&gt; in the backup directory will give you all the backupId&apos;s etc. And again, there are other advantages for using the exact same layout that we have inside a backup directory. For example, again, file links and other stuff will work transparently, and when we are finished with the new layout that is proposed for 2.0, we can automatically migrate to that layout with very little changes. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;OK, this can be done, but some &quot;unused&quot; fields contains backup session stats. We do not use it now, but in a future?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If we need them in the future, we can add them back. It is what PB is good for. Can you please remove the stuff that is not needed to keep the patches simple. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;When you do incremental backup on t2, system automatically enhance backup set and adds ALL tables to it, which have at least one full backup image. So it will add t1 to t2. This is for free, because we copy only WAL files. No data loss.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Alright. As long as these kind of cases are covered with a test, it should be good. &lt;/p&gt;</comment>
                            <comment id="15221184" author="vrodionov" created="Fri, 1 Apr 2016 05:27:56 +0000"  >&lt;blockquote&gt;
&lt;p&gt;This structure will allow the rest of the code base (like hfile links, etc) to work seamlessly and also will help with a large number of files under WALs. Also, all the table in the table set for a backup will be hosted together etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How is that? For myself, personally, existing backup root layout is not a US Constitution - can be changed. Two requirements:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Must be justified and rational&lt;/li&gt;
	&lt;li&gt;We have spare time to work on it.&lt;/li&gt;
&lt;/ol&gt;

</comment>
                            <comment id="15222131" author="enis" created="Fri, 1 Apr 2016 18:34:42 +0000"  >&lt;p&gt;Backup layout is a new feature that is not in the code base. That is why this patch has to justify why it has to have a different layout than the actual layout we follow under hbase.rootdir, not the other way around. All of the utility methods under &lt;tt&gt;HRegionFileSystem&lt;/tt&gt;, &lt;tt&gt;MasterFileSystem&lt;/tt&gt;, Hfile links, wal links, etc as well as the layout abstraction in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14439&quot; title=&quot;New/Improved Filesystem Abstractions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14439&quot;&gt;HBASE-14439&lt;/a&gt; works with the relative layouts under the root directory. That is why it is very important to follow the same pattern unless there is a very valid reason not to. It is only rational, simple to understand and maintainable, to have a single unified layout across the root directory, snapshot exports, and different kinds of backup directories. What we have with the current patches is a mixture of two. Even between full and incremental backup there is no consistency in the directory structure. &lt;/p&gt;</comment>
                            <comment id="15223137" author="lhofhansl" created="Sun, 3 Apr 2016 06:35:20 +0000"  >&lt;p&gt;Pardon my ignorance here, but can somebody briefly explain the pros and cons of the two layout options?&lt;br/&gt;
&quot;It is as it is&quot; but also &quot;that&apos;s how the rest of the HBase does it&quot; both do not really sound like compelling arguments to me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Offhand it feels useful to group everything that belongs to a specific backup in a single directory tree and from that angle would favour leading with the backup ID... There might be various other reasons.&lt;/p&gt;</comment>
                            <comment id="15223458" author="vrodionov" created="Sun, 3 Apr 2016 18:53:01 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Pardon my ignorance here, but can somebody briefly explain the pros and cons of the two layout options?&lt;br/&gt;
&quot;It is as it is&quot; but also &quot;that&apos;s how the rest of the HBase does it&quot; both do not really sound like compelling arguments to me &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Lars, &quot;it is as it is&quot; means that it was initial design decision of IBM team and they have implemented this layout. It is done. To change this layout we need really strong arguments against it. &lt;/p&gt;

&lt;p&gt;Putting all under the same backupid root may seem better, than having all data under table root if you do restore for the whole session, if you restore the single table (due to some issues in this table), which is in my opinion is more common use case, having everything under table root looks more preferable.   &lt;/p&gt;</comment>
                            <comment id="15225385" author="enis" created="Tue, 5 Apr 2016 00:34:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;Lars, &quot;it is as it is&quot; means that it was initial design decision of IBM team and they have implemented this layout. It is done. To change this layout we need really strong arguments against it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Isn&apos;t the justification above enough? We should have consistency in the file layout, no matter it is root directory, exported snapshots or backups. Even between backup types, full and increment have different layout making it a maintenance burden for no reason. Plus there are even more things to consider: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;For incremental backups, lacking the extra directory level for ServerName means that every WAL in the backup will end up in the same directory. For 1000 servers, where every servers rolls the WAL every half an hour, that is 48K WAL files per day. If you have incremental backup every week, it is 336K files under one directory. We already know that the NN will fail with this.&lt;/li&gt;
	&lt;li&gt;In the full backup layout, we are repeating the ns + table for no good reason at all.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15235744" author="vrodionov" created="Mon, 11 Apr 2016 19:05:55 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Isn&apos;t the justification above enough? We should have consistency in the file layout, no matter it is root directory, exported snapshots or backups. Even between backup types, full and increment have different layout making it a maintenance burden for no reason.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;, what maintenance burden are referring to?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Plus there are even more things to consider:&lt;br/&gt;
For incremental backups, lacking the extra directory level for ServerName means that every WAL in the backup will end up in the same directory. For 1000 servers, where every servers rolls the WAL every half an hour, that is 48K WAL files per day. If you have incremental backup every week, it is 336K files under one directory. We already know that the NN will fail with this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This looks like artificial number manipulation. Nobody runs incremental backups once a week and increasing WAL size from default 128MB can help as well. Although I agree: having additional subdirectory is better.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the full backup layout, we are repeating the ns + table for no good reason at all.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We are not repeating, ns is upper directory level, similar to hbase layout. I am not sure I am following you here, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15238048" author="devaraj" created="Tue, 12 Apr 2016 21:43:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;We are not repeating, ns is upper directory level, similar to hbase layout. I am not sure I am following you here&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; is referring to the fact that you have the namespace repeated in the path twice. For example, in this the &apos;default&apos; namespace appears twice:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ROOT/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/test&#173;1459375580152/backup_1459375618126/archive/data/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/test&#173;1459375
580152/543f8c02c388dd931fb9bcd1c38e7372/f/a6ce4789f9b444d89bbc755254afd27d&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15238140" author="vrodionov" created="Tue, 12 Apr 2016 22:38:37 +0000"  >&lt;p&gt;That we can&apos;t change. We can&apos;t remove first NS - it refers to full table name in a hierarchy, the second occurrence is created by snapshot export routine. &lt;/p&gt;</comment>
                            <comment id="15238460" author="vrodionov" created="Wed, 13 Apr 2016 02:09:33 +0000"  >&lt;p&gt;Updated backup directory layout section.&lt;/p&gt;</comment>
                            <comment id="15243833" author="vrodionov" created="Fri, 15 Apr 2016 23:20:29 +0000"  >&lt;p&gt;Added command line tool section.&lt;/p&gt;</comment>
                            <comment id="15321772" author="vrodionov" created="Thu, 9 Jun 2016 01:55:16 +0000"  >&lt;p&gt;Design doc was updated to reflect the current implementation.&lt;/p&gt;</comment>
                            <comment id="15363450" author="vrodionov" created="Tue, 5 Jul 2016 23:17:56 +0000"  >&lt;p&gt;Updated design doc.&lt;/p&gt;</comment>
                            <comment id="15478012" author="vrodionov" created="Fri, 9 Sep 2016 19:21:46 +0000"  >&lt;p&gt;Backup User Guide is attached. Prepared by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fwelsch&quot; class=&quot;user-hover&quot; rel=&quot;fwelsch&quot;&gt;Frank Welsch&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15484865" author="stack" created="Mon, 12 Sep 2016 18:18:19 +0000"  >&lt;p&gt;I reviewed the doc. It is nice and high-level pitched properly at a &apos;user&apos;. It is in msword format. Can we do it up in refguide format and as a patch on rb? There are some minor issues that could be better addressed via comments up on rb. Looks like backup is well-worthy of its own, dedicated chapter.&lt;/p&gt;

&lt;p&gt;Nit: On usage, the backupid exists nowhere in the system except as output from the backup command? Later it is explained what it is which is helpful. Also, later again it is explained that it does live as part of the backup history. Could be good to call out these facts earlier.&lt;/p&gt;

&lt;p&gt;Could also say how long a backup is going to take roughly. Me as an operator would be afraid to run a backup because I&apos;d think the command could run for ever on my 100 node cluster. Reading later in the manual, it seems that it could start and return immediately and then I check in on status. Would be good to surface some of that up here at start of doc. to allay the fears of the poor operator.&lt;/p&gt;

&lt;p&gt;I tried running this feature by checkout the branch. I built and started it up. In logs I see:&lt;/p&gt;

&lt;p&gt;2016-09-12 09:31:35,927 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;ProcedureExecutor-3&amp;#93;&lt;/span&gt; master.TableStateManager: Unable to get table hbase:backup state&lt;br/&gt;
org.apache.hadoop.hbase.TableNotFoundException: hbase:backup&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.TableStateManager.getTableState(TableStateManager.java:174)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.TableStateManager.isTableState(TableStateManager.java:131)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.AssignmentManager.isDisabledorDisablingRegionInRIT(AssignmentManager.java:1221)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:739)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1567)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1546)&lt;br/&gt;
       	at org.apache.hadoop.hbase.util.ModifyRegionUtils.assignRegions(ModifyRegionUtils.java:254)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.assignRegions(CreateTableProcedure.java:430)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:127)&lt;br/&gt;
       	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:57)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:119)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:452)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1066)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:855)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:808)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)&lt;br/&gt;
       	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:494)&lt;/p&gt;

&lt;p&gt;... a few times. That bad?&lt;/p&gt;

&lt;p&gt;A restart seemed to come up w/o this issue.&lt;/p&gt;

&lt;p&gt;Poking at the command-line, the usage is nice but a bit wonky in the listing... could do w/ some cleanup:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
kalashnikov:hbase.git.commit2 stack$ ./bin/hbase backup create
ERROR: wrong number of arguments
Usage: hbase backup create &amp;lt;type&amp;gt; &amp;lt;BACKUP_ROOT&amp;gt; [tables] [-s name] [-convert] [-silent] [-w workers][-b bandwith]
 type          &lt;span class=&quot;code-quote&quot;&gt;&quot;full&quot;&lt;/span&gt; to create a full backup image;
               &lt;span class=&quot;code-quote&quot;&gt;&quot;incremental&quot;&lt;/span&gt; to create an incremental backup image
  BACKUP_ROOT   The full root path to store the backup image,
                    the prefix can be hdfs, webhdfs or gpfs
 Options:
  tables      If no tables (&quot;&quot;) are specified, all tables are backed up. Otherwise it is a
               comma separated list of tables.
 -w          number of parallel workers.
 -b          bandwith per one worker (in MB sec)
 -set        name of backup set
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Convert is unexplained as is silent (I can guess what the latter means)&lt;/p&gt;

&lt;p&gt;I would have liked file: scheme as an option for backup location if only for testing purposes (the timelinev2 folks might like this too....). I can file an issue.&lt;/p&gt;

&lt;p&gt;-w workers are threads or mapreduce tasks? Thats what I asked myself when I saw it.&lt;/p&gt;

&lt;p&gt;Would be great working the doc explaination of each of these options back into the command usage. More folks will read the cmd output than doc (unfortunately). e.g. the doc explains what the -w option is about where usage output does not.&lt;/p&gt;

&lt;p&gt;Does that &apos;-b&apos; for bandwidth actually work? If so, how.&lt;/p&gt;

&lt;p&gt;I get different usage when an error:&lt;/p&gt;

&lt;p&gt;kalashnikov:hbase.git.commit2 stack$ ./bin/hbase backup create full &lt;a href=&quot;http://tmp&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://tmp&lt;/a&gt; -s first&lt;br/&gt;
2016-09-12 09:55:01,437 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; util.AbstractHBaseTool: Error when parsing command-line arguments&lt;br/&gt;
org.apache.commons.cli.UnrecognizedOptionException: Unrecognized option: -s&lt;br/&gt;
       	at org.apache.commons.cli.Parser.processOption(Parser.java:363)&lt;br/&gt;
       	at org.apache.commons.cli.Parser.parse(Parser.java:199)&lt;br/&gt;
       	at org.apache.commons.cli.Parser.parse(Parser.java:85)&lt;br/&gt;
       	at org.apache.hadoop.hbase.util.AbstractHBaseTool.parseArgs(AbstractHBaseTool.java:135)&lt;br/&gt;
       	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:94)&lt;br/&gt;
       	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)&lt;br/&gt;
       	at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:133)&lt;br/&gt;
usage: bin/hbase org.apache.hadoop.hbase.backup.BackupDriver &amp;lt;options&amp;gt;&lt;br/&gt;
Options:&lt;br/&gt;
 -all          All tables&lt;br/&gt;
 -b &amp;lt;arg&amp;gt;      Bandwidth (MB/s)&lt;br/&gt;
 -debug        Enable debug loggings&lt;br/&gt;
 &lt;del&gt;h,&lt;/del&gt;-help     Show usage&lt;br/&gt;
 -n &amp;lt;arg&amp;gt;      History length&lt;br/&gt;
 -path &amp;lt;arg&amp;gt;   Backup destination root directory path&lt;br/&gt;
 -set &amp;lt;arg&amp;gt;    Backup set name&lt;br/&gt;
 -t &amp;lt;arg&amp;gt;      Table name&lt;br/&gt;
 -w &amp;lt;arg&amp;gt;      Number of workers&lt;/p&gt;

&lt;p&gt;Should it be the same not to confuse (I was thinking I&apos;d run the wrong tool)?&lt;/p&gt;

&lt;p&gt;So, I&apos;m passing -s but it looks like I should pass -set. Why some options single letter with the hyphen but then others are words (and they don&apos;t do the unix-y thing of requiring double hyphen?)&lt;/p&gt;

&lt;p&gt;When I ran the command, I got:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
kalashnikov:hbase.git.commit2 stack$ ./bin/hbase backup create full file:&lt;span class=&quot;code-comment&quot;&gt;///tmp -set first
&lt;/span&gt;2016-09-12 09:57:47,923 WARN  [main] util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
2016-09-12 09:57:48,829 ERROR [main] util.AbstractHBaseTool: Error running command-line tool
java.io.IOException: Backup set &apos;first&apos; is either empty or does not exist
       	at org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand.execute(BackupCommands.java:188)
       	at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:113)
       	at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:128)
       	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
       	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
       	at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:133)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;d guess it is the scheme that is disallowed but the complaint is that &apos;first&apos; does not exist.&lt;/p&gt;

&lt;p&gt;Rereading the doc., I got sense that I had to first add my &apos;set&apos; before I could refer to it so I tried following and got below output:&lt;/p&gt;

&lt;p&gt;kalashnikov:hbase.git.commit2 stack$ ./bin/hbase backup set&lt;br/&gt;
2016-09-12 10:02:27,178 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; util.AbstractHBaseTool: Error running command-line tool&lt;br/&gt;
java.io.IOException: command line format&lt;br/&gt;
       	at org.apache.hadoop.hbase.backup.impl.BackupCommands$BackupSetCommand.execute(BackupCommands.java:469)&lt;br/&gt;
       	at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:113)&lt;br/&gt;
       	at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:128)&lt;br/&gt;
       	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)&lt;br/&gt;
       	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)&lt;br/&gt;
       	at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:133)&lt;/p&gt;

&lt;p&gt;Then I thought it was just that there no help on &apos;set&apos;... so:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
kalashnikov:hbase.git.commit2 stack$ ./bin/hbase backup set add first
2016-09-12 10:04:07,068 ERROR [main] util.AbstractHBaseTool: Error running command-line tool
java.lang.RuntimeException: Wrong args
       	at org.apache.hadoop.hbase.backup.impl.BackupCommands$BackupSetCommand.processSetAdd(BackupCommands.java:559)
       	at org.apache.hadoop.hbase.backup.impl.BackupCommands$BackupSetCommand.execute(BackupCommands.java:477)
       	at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:113)
       	at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:128)
       	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
       	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
       	at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:133)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I see what I did wrong now but I&apos;d think that I&apos;d get some usage on the set command...&lt;/p&gt;

&lt;p&gt;Hm... I tried &apos;-h&apos; and that seems to work. Suggest it more user friendly if no args dumps help.... but no, the usage is for another command than set:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ ./bin/hbase backup set -h
usage: bin/hbase org.apache.hadoop.hbase.backup.BackupDriver &amp;lt;options&amp;gt;
Options:
 -all          All tables
 -b &amp;lt;arg&amp;gt;      Bandwidth (MB/s)
 -debug        Enable debug loggings
 -h,--help     Show usage
 -n &amp;lt;arg&amp;gt;      History length
 -path &amp;lt;arg&amp;gt;   Backup destination root directory path
 -set &amp;lt;arg&amp;gt;    Backup set name
 -t &amp;lt;arg&amp;gt;      Table name
 -w &amp;lt;arg&amp;gt;      &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of workers
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I tried history command. It emitted nothing. I add a -h and got the above.&lt;/p&gt;

&lt;p&gt;Is &apos;history&apos; the &apos;list&apos; of backups taken? They the same thing?&lt;/p&gt;

&lt;p&gt;I think these command-line tools need to run smoothly. If they don&apos;t, no operator is going to trust the rest of the backup/restore tooling chain.&lt;/p&gt;

&lt;p&gt;I don&apos;t have access to a little cluster just yet. Will be back when I have an hdfs to copy backups up to so I can test other commands.&lt;/p&gt;

&lt;p&gt;Also, critical to add more detail on how it works and a limitations section as suggested by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; up on the dev mailing list thread.&lt;/p&gt;

&lt;p&gt;The &apos;backup scenario&apos; on the end of the doc is great (the doc in general is really good).&lt;/p&gt;




</comment>
                            <comment id="15484973" author="stack" created="Mon, 12 Sep 2016 18:58:21 +0000"  >&lt;p&gt;Was there supposed to be a section on addressing failure modes (came up on the discussion out on dev list)? I did not see it in the doc. Thanks.&lt;/p&gt;</comment>
                            <comment id="15485053" author="vrodionov" created="Mon, 12 Sep 2016 19:30:44 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; for review &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;We will address command-line tool usability shortly. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Could also say how long a backup is going to take roughly. Me as an operator would be afraid to run a backup because I&apos;d think the command could run for ever on my 100 node cluster.&lt;/p&gt;&lt;/blockquote&gt; 

&lt;p&gt;Too many unknowns to make a good estimate here. Backup is a sequence of snapshot and distcp. Both should work reasonably fast for 100 node cluster. Incremental backup is just distcp, hence will run even faster.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Unable to get table hbase:backup state&lt;br/&gt;
org.apache.hadoop.hbase.TableNotFoundException: hbase:backup&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That is the issue not only for backup system table - for all tables in HBase. This error is annoying I agree. Needs to be addressed in a separate JIRA for CreateTableProcedure.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Convert is unexplained as is silent (I can guess what the latter means)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Artefacts from the past. Will remove them.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I would have liked file: scheme as an option for backup location if only for testing purposes (the timelinev2 folks might like this too....). I can file an issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You can file JIRA, of course. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;-w workers are threads or mapreduce tasks? Thats what I asked myself when I saw it.&lt;br/&gt;
Would be great working the doc explaination of each of these options back into the command usage. More folks will read the cmd output than doc (unfortunately). e.g. the doc explains what the -w option is about where usage output does not.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that is M/R task number for M/R - based distributed backup/restore service. In theory, one can provide totally non-M/R based implementation for all distributed services and exact meaning of &lt;b&gt;-w&lt;/b&gt; can be different in this case.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Does that &apos;-b&apos; for bandwidth actually work? If so, how.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, it works for both: export snapshot and distcp copy. You can specify bandwidth per map task in both tools.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I tried history command. It emitted nothing. I add a -h and got the above.&lt;br/&gt;
Is &apos;history&apos; the &apos;list&apos; of backups taken? They the same thing?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, history is the list of backups in system table. You saw nothing because you had nothing in a system table. &lt;/p&gt;

&lt;p&gt;Overall, thanks for quick review of command-line tools and we will address usability issues shortly. &lt;/p&gt;



</comment>
                            <comment id="15485158" author="stack" created="Mon, 12 Sep 2016 20:13:55 +0000"  >&lt;p&gt;I am game to try it out again when you have something new posted (and I should have a cluster by then to go further). When no hard info on how long stuff will take, a hint would be good. I think the command-line tools should exhibit a bit of &apos;polish&apos; so operators get good feeling of &apos;quality&apos; even when all they are doing is poking around. Thanks.&lt;/p&gt;</comment>
                            <comment id="15485203" author="apurtell" created="Mon, 12 Sep 2016 20:30:09 +0000"  >&lt;p&gt;Thanks for looking at this from that perspective &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. I haven&apos;t had time to look at this but would be coming at it from the same perspective. Sounds like there will be an update to put a bit of polish on the tools. Will be back then.&lt;/p&gt;</comment>
                            <comment id="15504659" author="fwelsch" created="Mon, 19 Sep 2016 20:53:27 +0000"  >&lt;p&gt;I am attaching revised doc of the feature. The revisions are for the following:&lt;br/&gt;
--correct the backupId argument spelling and format on the CLI&lt;br/&gt;
--to remove the hbase backup cancel functionality from the doc because it&apos;s not yet supported&lt;br/&gt;
--list limitations of the current HBase backup-and-restore functionality&lt;br/&gt;
--added required property setting in the container-executor.cfg file&lt;/p&gt;</comment>
                            <comment id="15569958" author="stack" created="Wed, 12 Oct 2016 21:50:41 +0000"  >&lt;p&gt;I wanted to try removing the hbase:backup table since my install already had it so I do a listing in the shell and don&apos;t see the backup table but it is in the list of regions. I suppose we don&apos;t show hbase:backup in our  shell listing (or any of our system tables).  Over in review on the mega patch, I ask about the hbase:backup table. I get this even though I don&apos;t do any backups it seems. We don&apos;t want that, right?&lt;/p&gt;

&lt;p&gt;I was able to disable it and drop it (that ok?) even though it not listed as a table.&lt;/p&gt;

&lt;p&gt;I restart and get the complaint about TableNotFoundException again. The table is created though I&apos;ve not asked for it and have done no backups.&lt;/p&gt;

&lt;p&gt;Up in the review of the  monster patch  note that command descriptions are capitalized for all commands but the two newly added backup and restore.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Some commands take arguments. Pass no args or -h &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; usage.
  shell           Run the HBase shell
  hbck            Run the hbase &apos;fsck&apos; tool
  snapshot        Create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; snapshot of a table
  snapshotinfo    Tool &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; dumping snapshot information
  wal             Write-ahead-log analyzer
  hfile           Store file analyzer
  zkcli           Run the ZooKeeper shell
  master          Run an HBase HMaster node
  regionserver    Run an HBase HRegionServer node
  zookeeper       Run a Zookeeper server
  &lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;            Run an HBase REST server
  thrift          Run the HBase Thrift server
  thrift2         Run the HBase Thrift2 server
  clean           Run the HBase clean up script
  classpath       Dump hbase CLASSPATH
  mapredcp        Dump CLASSPATH entries required by mapreduce
  pe              Run PerformanceEvaluation
  ltt             Run LoadTestTool
  canary          Run the Canary tool
  version         Print the version
  backup          backup tables &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; recovery
  restore         restore tables from existing backup image
  CLASSNAME       Run the class named CLASSNAME
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; I notice here that the inconsistency is carried over into the restore and backup subcommands. Would suggest that the format of the below align w/ the above. Why do something &apos;new&apos;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Usage: hbase backup COMMAND [command-specific arguments]
where COMMAND is one of:
  create     create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; backup image
  delete     delete an existing backup image
  describe   show the detailed information of a backup image
  history    show history of all successful backups
  progress   show the progress of the latest backup request
  set        backup set management
Run &apos;hbase backup COMMAND -h&apos; to see help message &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; each command
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When I ran backup command I got the above. When I ran the restore to see what it can do I got an error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
stack@ve0524:~$ ./hbase/bin/hbase --config ~/conf_hbase restore
2016-10-12 14:27:54,702 DEBUG [main] backup.RestoreDriver: Will automatically restore all the dependencies
ERROR: remain args length=0
Usage: hbase restore [-set set_name] &amp;lt;backup_root_path&amp;gt; &amp;lt;backup_id&amp;gt; &amp;lt;tables&amp;gt; [tableMapping]
       [-overwrite] [-check]
 backup_root_path  The parent location where the backup images are stored
 backup_id         The id identifying the backup image
 table(s)          Table(s) from the backup image to be restored.
                   Tables are separated by comma.
 Options:
   tableMapping    A comma separated list of target tables.
                   If specified, each table in &amp;lt;tables&amp;gt; must have a mapping.
   -overwrite      With &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; option, restore overwrites to the existing table &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there&apos;s any in
                   restore target. The existing table must be online before restore.
   -check          With &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; option, sequence and dependencies are checked
                   and verified without executing the restore command
   -set set_name   Backup set to restore, mutually exclusive with table list &amp;lt;tables&amp;gt;.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I tried &apos;backup create&apos; and I got an error for seemingly the same reason as I got an error above &amp;#8211; missing an argument (which is fine) but the error message is different this time. Above it is: &apos;ERROR: remain args length=0&apos;. Here it is &apos;ERROR: wrong number of arguments: 1&apos;.&lt;/p&gt;

&lt;p&gt;Looking in my shell at the output for backup, restore, and &apos;backup create&apos;, none of the columns align... sometimes Options: is up against the left edge, other times it is offset. Ditto for options. Needs to be consistent else gives the impression that the tool can&apos;t be trusted to do backup and restore (see monster patch review for some detail on why we might have the inconsistency here).&lt;/p&gt;

&lt;p&gt;In &apos;restore&apos;, the &apos;-overwrite&apos; is mentioned in the options list bu tnot in the usage top-line.&lt;/p&gt;

&lt;p&gt;In monster patch review it notes that sometimes options are single letter but mostly they are words.. set, table.&lt;/p&gt;

&lt;p&gt;If I do &apos;backup set&apos;, I get an error because I am missing args but as opposed to the above complaints that I&apos;m missing an arg., I get a new error type again:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ERROR: Command line format
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;d think all complaints about missing args would error the same.&lt;/p&gt;

&lt;p&gt;In this command, the options come before the commands listing (I&apos;d think options would come after as is usual and as per their listing on the usage line).&lt;/p&gt;

&lt;p&gt;Trying to make a backup, I am looking at BACKUP_ROOT which is capitalized for no good reason. I see in the description it says: &quot; BACKUP_ROOT     The full root path to store the backup image, the prefix can be hdfs, webhdfs or gpfs&quot; What is &apos;prefix&apos;. Do we mean &apos;scheme&apos;? We support gpfs now?&lt;/p&gt;

&lt;p&gt;I tried to create a backup:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ ./hbase/bin/hbase --config ~/conf_hbase backup create full hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backu&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It failed with java.lang.IllegalArgumentException Wrong FS: hdfs://ve0524.halxg.cloudera.com:8020/hbase/WALs, expected: &lt;a href=&quot;file:///&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:///&lt;/a&gt; and then later I got an NPE: &lt;/p&gt;

&lt;p&gt;2016-10-12 14:45:39,064 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; backup.BackupDriver: Error running command-line tool&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.cleanupTargetDir(FullTableBackupClient.java:178)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.failBackup(FullTableBackupClient.java:251)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.execute(FullTableBackupClient.java:533)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.impl.HBaseBackupAdmin.backupTables(HBaseBackupAdmin.java:532)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand.execute(BackupCommands.java:225)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:114)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:135)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.BackupDriver.run(BackupDriver.java:171)&lt;br/&gt;
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)&lt;br/&gt;
        at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:140)&lt;/p&gt;

&lt;p&gt;Not sure why it says &apos;Wrong FS&apos;.&lt;/p&gt;

&lt;p&gt;I&apos;ll leave it at that for now.&lt;/p&gt;








</comment>
                            <comment id="15570273" author="vrodionov" created="Wed, 12 Oct 2016 23:52:33 +0000"  >&lt;blockquote&gt;
&lt;p&gt;It failed with java.lang.IllegalArgumentException Wrong FS: hdfs://ve0524.halxg.cloudera.com:8020/hbase/WALs, expected: &lt;a href=&quot;file:///&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:///&lt;/a&gt; and then later I got an NPE:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Can you post full stack trace, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;? It seems something is wrong with your hbase conf file.&lt;/p&gt;

&lt;p&gt;Google: &quot;java.lang.IllegalArgumentException Wrong FS: hdfs:&quot; &lt;br/&gt;
&lt;a href=&quot;https://www.google.com/webhp?sourceid=chrome-instant&amp;amp;rlz=1C5CHFA_enUS548US548&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=java.lang.IllegalArgumentException+Wrong+FS%3A+hdfs%3A&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://www.google.com/webhp?sourceid=chrome-instant&amp;amp;rlz=1C5CHFA_enUS548US548&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=java.lang.IllegalArgumentException+Wrong+FS%3A+hdfs%3A&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Next time, can you try recommended:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ ./hbase/bin/hbase backup create full hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backu&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;hbase pick up config from CLASSPATH, all other options, such as --config may require you putting all hadoop xml files into command CLASSPATH manually.&lt;/p&gt;</comment>
                            <comment id="15570379" author="stack" created="Thu, 13 Oct 2016 00:37:34 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2016-10-12 17:19:49,538 DEBUG [AsyncRpcChannel-pool2-t13] ipc.AsyncRpcChannel: Use SIMPLE authentication &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; service ClientService, sasl=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
2016-10-12 17:19:49,554 ERROR [main] impl.FullTableBackupClient: Unexpected BackupException : Wrong FS: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/hbase/WALs, expected: file:///
&lt;/span&gt;java.lang.IllegalArgumentException: Wrong FS: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/hbase/WALs, expected: file:///
&lt;/span&gt;        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:647)
        at org.apache.hadoop.fs.RawLocalFileSystem.pathToFile(RawLocalFileSystem.java:82)
        at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:425)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1515)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1555)
        at org.apache.hadoop.fs.FileSystem$4.&amp;lt;init&amp;gt;(FileSystem.java:1712)
        at org.apache.hadoop.fs.FileSystem.listLocatedStatus(FileSystem.java:1711)
        at org.apache.hadoop.fs.ChecksumFileSystem.listLocatedStatus(ChecksumFileSystem.java:589)
        at org.apache.hadoop.fs.FileSystem$6.&amp;lt;init&amp;gt;(FileSystem.java:1787)
        at org.apache.hadoop.fs.FileSystem.listFiles(FileSystem.java:1783)
        at org.apache.hadoop.hbase.backup.util.BackupClientUtil.getFiles(BackupClientUtil.java:161)
        at org.apache.hadoop.hbase.backup.util.BackupServerUtil.getWALFilesOlderThan(BackupServerUtil.java:381)
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.execute(FullTableBackupClient.java:492)
        at org.apache.hadoop.hbase.backup.impl.HBaseBackupAdmin.backupTables(HBaseBackupAdmin.java:532)
        at org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand.execute(BackupCommands.java:225)
        at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:114)
        at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:135)
        at org.apache.hadoop.hbase.backup.BackupDriver.run(BackupDriver.java:171)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:140)
2016-10-12 17:19:49,557 ERROR [main] impl.FullTableBackupClient: BackupId=backup_1476317988066,startts=1476317988637,failedts=1476317989557,failedphase=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;,failedmessage=Wrong FS: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/hbase/WALs, expected: file:///
&lt;/span&gt;2016-10-12 17:19:49,559 DEBUG [AsyncRpcChannel-pool2-t14] ipc.AsyncRpcChannel: Use SIMPLE authentication &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; service ClientService, sasl=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
2016-10-12 17:19:49,656 DEBUG [main] ipc.AsyncRpcClient: Stopping async HBase RPC client
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I pass the --config pointing at my conf dir which points at my hdfs and hbase. If I don&apos;t pass a --config, it&apos;ll use all defaults and not find the clusters (My config dir includes symlink to hdfs-site.xml).&lt;/p&gt;

&lt;p&gt;Yeah, I&apos;ve seen similar mismatch issues in the past in my own code (your google pointer is for a code writer, not for a &apos;user&apos; like me).  I can bang my head and try &apos;fixing&apos; it but am trying to convey a &apos;users&apos; experience followiing instruction and tool usage. What is a little odd here is that the complaint is out of the backup tool, not about the arg I&apos;m passing (must not be reading it immediately... because doesn&apos;t matter if I pass a &lt;a href=&quot;file:///&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:///&lt;/a&gt; or hdfs:/// scheme for backup location).&lt;/p&gt;

&lt;p&gt;Let me know what you want me to try... &lt;/p&gt;

&lt;p&gt;This is straight cluster deploy. An Hadoop 2.7.3 build. All generally checks out.&lt;/p&gt;</comment>
                            <comment id="15570534" author="vrodionov" created="Thu, 13 Oct 2016 01:54:42 +0000"  >&lt;p&gt;Ooops, may be a bug.&lt;/p&gt;

&lt;p&gt;Update:&lt;/p&gt;

&lt;p&gt;No, it can not be. When tool starts we create instance of Configuration:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    Configuration conf = HBaseConfiguration.create();
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ret = ToolRunner.run(conf, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BackupDriver(), args);    
    &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit(ret);    
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That is what we get from CLASSPATH. Check your setup, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;&lt;/p&gt;

</comment>
                            <comment id="15571120" author="anoop.hbase" created="Thu, 13 Oct 2016 07:23:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I do a listing in the shell and don&apos;t see the backup table but it is in the list of regions. I suppose we don&apos;t show hbase:backup in our shell listing (or any of our system tables). Over in review on the mega patch, I ask about the hbase:backup table. I get this even though I don&apos;t do any backups it seems. We don&apos;t want that, right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;u run shell as a normal user or super user?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I was able to disable it and drop it (that ok?) even though it not listed as a table.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;When it is a non super user, I feel we should not allow to disable/delete any of the system tables.&lt;/p&gt;</comment>
                            <comment id="15572296" author="stack" created="Thu, 13 Oct 2016 15:44:14 +0000"  >&lt;p&gt;My CLASSPATH is fine enough to do cluster start/stop, loadings, shell, MR bulk jobs. It is pasted below. Tell me what is missing. I can add my config if that&apos;d help. How did you test against a cluster? What was your setup like?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
stack@ve0524:~$ ./hbase/bin/hbase --config ~/conf_hbase   classpath
/home/stack/conf_hbase:/home/stack/bin/jdk&lt;span class=&quot;code-comment&quot;&gt;//lib/tools.jar:/home/stack/hbase/bin/..:/home/stack/hbase/bin/../lib/activation-1.1.jar:/home/stack/hbase/bin/../lib/antisamy-1.4.3.jar:/home/stack/hbase/bin/../lib/aopalliance-1.0.jar:/home/stack/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/home/stack/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/stack/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/home/stack/hbase/bin/../lib/api-util-1.0.0-M20.jar:/home/stack/hbase/bin/../lib/asm-3.1.jar:/home/stack/hbase/bin/../lib/avro-1.7.4.jar:/home/stack/hbase/bin/../lib/batik-css-1.7.jar:/home/stack/hbase/bin/../lib/batik-ext-1.7.jar:/home/stack/hbase/bin/../lib/batik-util-1.7.jar:/home/stack/hbase/bin/../lib/bsh-core-2.0b4.jar:/home/stack/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/stack/hbase/bin/../lib/commons-beanutils-core-1.7.0.jar:/home/stack/hbase/bin/../lib/commons-cli-1.2.jar:/home/stack/hbase/bin/../lib/commons-codec-1.9.jar:/home/stack/hbase/bin/../lib/commons-collections-3.2.2.jar:/home/stack/hbase/bin/../lib/commons-compress-1.4.1.jar:/home/stack/hbase/bin/../lib/commons-configuration-1.6.jar:/home/stack/hbase/bin/../lib/commons-daemon-1.0.13.jar:/home/stack/hbase/bin/../lib/commons-digester-1.8.jar:/home/stack/hbase/bin/../lib/commons-el-1.0.jar:/home/stack/hbase/bin/../lib/commons-fileupload-1.2.jar:/home/stack/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/stack/hbase/bin/../lib/commons-io-2.4.jar:/home/stack/hbase/bin/../lib/commons-lang-2.6.jar:/home/stack/hbase/bin/../lib/commons-logging-1.2.jar:/home/stack/hbase/bin/../lib/commons-math-2.2.jar:/home/stack/hbase/bin/../lib/commons-math3-3.1.1.jar:/home/stack/hbase/bin/../lib/commons-net-3.1.jar:/home/stack/hbase/bin/../lib/curator-client-2.7.1.jar:/home/stack/hbase/bin/../lib/curator-framework-2.7.1.jar:/home/stack/hbase/bin/../lib/curator-recipes-2.7.1.jar:/home/stack/hbase/bin/../lib/disruptor-3.3.0.jar:/home/stack/hbase/bin/../lib/esapi-2.1.0.jar:/home/stack/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/stack/hbase/bin/../lib/gson-2.2.4.jar:/home/stack/hbase/bin/../lib/guava-12.0.1.jar:/home/stack/hbase/bin/../lib/guice-3.0.jar:/home/stack/hbase/bin/../lib/guice-servlet-3.0.jar:/home/stack/hbase/bin/../lib/hadoop-annotations-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-auth-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-client-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-common-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-distcp-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-hdfs-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-mapreduce-client-app-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-mapreduce-client-common-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-mapreduce-client-core-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-yarn-api-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-yarn-client-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-yarn-common-2.7.1.jar:/home/stack/hbase/bin/../lib/hadoop-yarn-server-common-2.7.1.jar:/home/stack/hbase/bin/../lib/hbase-annotations-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-annotations-2.0.0-SNAPSHOT-tests.jar:/home/stack/hbase/bin/../lib/hbase-client-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-common-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/stack/hbase/bin/../lib/hbase-examples-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-external-blockcache-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-it-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/stack/hbase/bin/../lib/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-procedure-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-resource-bundle-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-server-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/stack/hbase/bin/../lib/hbase-shell-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-spark-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/hbase-thrift-2.0.0-SNAPSHOT.jar:/home/stack/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/home/stack/hbase/bin/../lib/httpclient-4.2.5.jar:/home/stack/hbase/bin/../lib/httpcore-4.4.1.jar:/home/stack/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/home/stack/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/home/stack/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/home/stack/hbase/bin/../lib/jackson-xc-1.9.13.jar:/home/stack/hbase/bin/../lib/jamon-runtime-2.4.1.jar:/home/stack/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/stack/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/stack/hbase/bin/../lib/javax.inject-1.jar:/home/stack/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/home/stack/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/stack/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/stack/hbase/bin/../lib/jcodings-1.0.8.jar:/home/stack/hbase/bin/../lib/jersey-client-1.9.jar:/home/stack/hbase/bin/../lib/jersey-core-1.9.jar:/home/stack/hbase/bin/../lib/jersey-guice-1.9.jar:/home/stack/hbase/bin/../lib/jersey-json-1.9.jar:/home/stack/hbase/bin/../lib/jersey-server-1.9.jar:/home/stack/hbase/bin/../lib/jets3t-0.9.0.jar:/home/stack/hbase/bin/../lib/jettison-1.3.3.jar:/home/stack/hbase/bin/../lib/jetty-6.1.26.jar:/home/stack/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/stack/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/stack/hbase/bin/../lib/joni-2.1.2.jar:/home/stack/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/stack/hbase/bin/../lib/jsch-0.1.42.jar:/home/stack/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/stack/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/stack/hbase/bin/../lib/jsr305-1.3.9.jar:/home/stack/hbase/bin/../lib/junit-4.12.jar:/home/stack/hbase/bin/../lib/leveldbjni-all-1.8.jar:/home/stack/hbase/bin/../lib/libthrift-0.9.3.jar:/home/stack/hbase/bin/../lib/log4j-1.2.17.jar:/home/stack/hbase/bin/../lib/metrics-core-3.1.2.jar:/home/stack/hbase/bin/../lib/nekohtml-1.9.12.jar:/home/stack/hbase/bin/../lib/netty-all-4.0.30.Final.jar:/home/stack/hbase/bin/../lib/paranamer-2.3.jar:/home/stack/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/stack/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/stack/hbase/bin/../lib/servlet-api-2.5.jar:/home/stack/hbase/bin/../lib/slf4j-api-1.7.7.jar:/home/stack/hbase/bin/../lib/slf4j-log4j12-1.6.1.jar:/home/stack/hbase/bin/../lib/snappy-java-1.1.2.jar:/home/stack/hbase/bin/../lib/spymemcached-2.11.6.jar:/home/stack/hbase/bin/../lib/xalan-2.7.0.jar:/home/stack/hbase/bin/../lib/xercesImpl-2.9.1.jar:/home/stack/hbase/bin/../lib/xml-apis-1.3.03.jar:/home/stack/hbase/bin/../lib/xml-apis-ext-1.3.04.jar:/home/stack/hbase/bin/../lib/xmlenc-0.52.jar:/home/stack/hbase/bin/../lib/xom-1.2.5.jar:/home/stack/hbase/bin/../lib/xz-1.0.jar:/home/stack/hbase/bin/../lib/zookeeper-3.4.6.jar:/home/stack/hadoop-2.7.3-SNAPSHOT/etc/hadoop:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/common/lib/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/common/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/hdfs:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/hdfs/lib/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/hdfs/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/yarn/lib/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/yarn/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/mapreduce/lib/*:/home/stack/hadoop-2.7.3-SNAPSHOT/share/hadoop/mapreduce/*:/home/stack/hadoop/contrib/capacity-scheduler/*.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="15572301" author="stack" created="Thu, 13 Oct 2016 15:46:09 +0000"  >&lt;p&gt;All processes are run by me so I&apos;m superuser. Yeah, you should be superuser to drop system tables I&apos;d say. I didn&apos;t try as normal user.&lt;/p&gt;</comment>
                            <comment id="15572548" author="anoop.hbase" created="Thu, 13 Oct 2016 17:08:04 +0000"  >&lt;p&gt;So even super user can not see the system table names listed. But can disable it. That is strange. Not specific to this feature.. Am saying generically.  May be some thing we need to check.  As it came up here am adding the comment.&lt;/p&gt;</comment>
                            <comment id="15572552" author="stack" created="Thu, 13 Oct 2016 17:09:32 +0000"  >&lt;p&gt;Agree. New, unrelated issue.&lt;/p&gt;</comment>
                            <comment id="15572714" author="vrodionov" created="Thu, 13 Oct 2016 18:02:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, can you list content of your /home/stack/conf_hbase? Is core-site.xml there? If yes, what is defaultFS? &lt;/p&gt;</comment>
                            <comment id="15572743" author="stack" created="Thu, 13 Oct 2016 18:12:08 +0000"  >&lt;p&gt;Adding a defaultFS fixes it. Thanks.&lt;/p&gt;</comment>
                            <comment id="15572783" author="stack" created="Thu, 13 Oct 2016 18:29:05 +0000"  >&lt;p&gt;Seems like a good thing to add to doc.(there is nothing on this at mo) and for the tooling to test for. I&apos;d guess others will run into this issue. Googling will only make them blame the tool.&lt;/p&gt;</comment>
                            <comment id="15572912" author="stack" created="Thu, 13 Oct 2016 19:25:06 +0000"  >&lt;p&gt;Here is some more:&lt;/p&gt;

&lt;p&gt;I played with sets. When I add to a set, it lists: Added tables &lt;span class=&quot;error&quot;&gt;&amp;#91;clicks students&amp;#93;&lt;/span&gt; to &apos;s&apos; backup set ... but when I list the set, I get s=&lt;/p&gt;
{clicks,students}
&lt;p&gt;; i.e. in former it is square brackets and space delimited but in the latter it is curlies and commas.&lt;/p&gt;

&lt;p&gt;Why is this an error: stack@ve0524:~$ ./hbase/bin/hbase --config ~/conf_hbase backup set&lt;br/&gt;
ERROR: Command line format&lt;/p&gt;

&lt;p&gt;It should just dump the help/usage w/o complaint. When I do &apos;./hbase/bin/hbase --config ~/conf_hbase backup&apos;... it does the right thing (dumping out help/usage but not reporting ERROR). Then again, this does: &lt;br/&gt;
stack@ve0524:~$ ./hbase/bin/hbase --config ~/conf_hbase backup create&lt;br/&gt;
ERROR: wrong number of arguments: 1&lt;/p&gt;

&lt;p&gt;When required args are not supplied, dumping help/usage rather than ERROR is usual and user friendly.&lt;/p&gt;

&lt;p&gt;When I run a backup, it finishes the job with these:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2016-10-13 11:42:47,634 INFO  [main] mapreduce.Job:  map 100% reduce 0%
2016-10-13 11:42:47,635 INFO  [main] mapreduce.Job: Job job_local781524854_0001 completed successfully
2016-10-13 11:42:47,660 INFO  [main] mapreduce.Job: Counters: 27
        File &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt; Counters
                FILE: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of bytes read=55034661
                FILE: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of bytes written=56196072
                FILE: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of read operations=0
                FILE: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of large read operations=0
                FILE: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of write operations=0
                HDFS: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of bytes read=24283676687
                HDFS: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of bytes written=24283672819
                HDFS: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of read operations=116
                HDFS: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of large read operations=0
                HDFS: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of write operations=42
        Map-Reduce Framework
                Map input records=12
                Map output records=0
                Input split bytes=1322
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=1077
                Total committed heap usage (bytes)=3061186560
        org.apache.hadoop.hbase.snapshot.ExportSnapshot$Counter
                BYTES_COPIED=15861720126
                BYTES_EXPECTED=15861720126
                BYTES_SKIPPED=0
                COPY_FAILED=0
                FILES_COPIED=12
                FILES_SKIPPED=0
                MISSING_FILES=0
        File Input Format Counters
                Bytes Read=0
        File Output Format Counters
                Bytes Written=0
2016-10-13 11:42:47,660 INFO  [main] snapshot.ExportSnapshot: Finalize the Snapshot Export
2016-10-13 11:42:47,661 ERROR [main] snapshot.ExportSnapshot: Snapshot export failed
java.io.IOException: Filesystem closed
        at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
        at org.apache.hadoop.hdfs.DFSClient.rename(DFSClient.java:1956)
        at org.apache.hadoop.hdfs.DistributedFileSystem.rename(DistributedFileSystem.java:626)
        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.run(ExportSnapshot.java:1010)
        at org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyService.copy(MapReduceBackupCopyService.java:302)
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.snapshotCopy(FullTableBackupClient.java:288)
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.execute(FullTableBackupClient.java:510)
        at org.apache.hadoop.hbase.backup.impl.HBaseBackupAdmin.backupTables(HBaseBackupAdmin.java:532)
        at org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand.execute(BackupCommands.java:225)
        at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:114)
        at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:135)
        at org.apache.hadoop.hbase.backup.BackupDriver.run(BackupDriver.java:171)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:140)
2016-10-13 11:42:47,766 ERROR [main] impl.FullTableBackupClient: Unexpected BackupException : java.io.IOException: Filesystem closed
java.io.IOException: java.io.IOException: Filesystem closed
        at org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyService.copy(MapReduceBackupCopyService.java:325)
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.snapshotCopy(FullTableBackupClient.java:288)
        at org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.execute(FullTableBackupClient.java:510)
        at org.apache.hadoop.hbase.backup.impl.HBaseBackupAdmin.backupTables(HBaseBackupAdmin.java:532)
        at org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand.execute(BackupCommands.java:225)
        at org.apache.hadoop.hbase.backup.BackupDriver.parseAndRun(BackupDriver.java:114)
        at org.apache.hadoop.hbase.backup.BackupDriver.doWork(BackupDriver.java:135)
        at org.apache.hadoop.hbase.backup.BackupDriver.run(BackupDriver.java:171)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.backup.BackupDriver.main(BackupDriver.java:140)
Caused by: java.io.IOException: Filesystem closed
        at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The command I ran was $ ./hbase/bin/hbase --config ~/conf_hbase backup create full clicks I&apos;m missing the backup location which probably explains the above. I&apos;d think the tool would verify the command before going ahead and running a mapreduce job?&lt;/p&gt;

&lt;p&gt;This is interesting... if I pass a set and a table as command lets me do, it runs the backup twice. I was sort of expecting one backup dir with all content in it. No biggie. Here is the command I ran (the -set included the table so the tool behavior avoids backup overwrite).&lt;/p&gt;

&lt;p&gt; ./hbase/bin/hbase --config ~/conf_hbase backup create full hdfs://ve0524.halxg.cloudera.com:8020/backup clicks -set s&lt;/p&gt;

&lt;p&gt;Probably worth documenting this behavior.&lt;/p&gt;

&lt;p&gt;Oh. Just noticed that usage says tables and -set are mutually exclusive but above I was able to run a command with tables and -set. Fix the usage?&lt;/p&gt;

&lt;p&gt;Why in here:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
stack@ve0524:~$ ./hbase/bin/hbase --config ~/conf_hbase backup create
ERROR: wrong number of arguments: 1
Usage: hbase backup create &amp;lt;type&amp;gt; &amp;lt;BACKUP_ROOT&amp;gt; [tables] [-set name] [-w workers][-b bandwith]
 type           &lt;span class=&quot;code-quote&quot;&gt;&quot;full&quot;&lt;/span&gt; to create a full backup image
                &lt;span class=&quot;code-quote&quot;&gt;&quot;incremental&quot;&lt;/span&gt; to create an incremental backup image
 BACKUP_ROOT     The full root path to store the backup image,
                 the prefix can be hdfs, webhdfs or gpfs
Options:
 tables          If no tables (&quot;&quot;) are specified, all tables are backed up.
                 Otherwise it is a comma separated list of tables.
 -w              number of parallel workers (MapReduce tasks).
 -b              bandwith per one worker (MapReduce task) in MBs per sec
 -set            name of backup set to use (mutually exclusive with [tables])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... does the tables &apos;option&apos; not take a hyphen but all others do? Most of the time options are delimited by space but not always....&lt;/p&gt;

&lt;p&gt;I tried and incremental against the clicks table. I got a SUCCESS on the end but it seems to have updated the manifest on unrelated tables. Is that expected? Here is the command:&lt;/p&gt;

&lt;p&gt;stack@ve0524:~$ ./hbase/bin/hbase --config ~/conf_hbase backup create incremental hdfs://ve0524.halxg.cloudera.com:8020/backup clicks&lt;/p&gt;

&lt;p&gt;... here is the output:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
...
2016-10-13 12:00:02,154 INFO  [main] impl.BackupManifest: Manifest file stored to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backup/backup_1476385197835/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/clicks/.backup.manifest
&lt;/span&gt;2016-10-13 12:00:02,156 DEBUG [AsyncRpcChannel-pool2-t88] ipc.AsyncRpcChannel: Use SIMPLE authentication &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; service ClientService, sasl=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
2016-10-13 12:00:02,213 INFO  [main] impl.BackupManifest: Manifest file stored to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backup/backup_1476385197835/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/students/.backup.manifest
&lt;/span&gt;2016-10-13 12:00:02,271 INFO  [main] impl.BackupManifest: Manifest file stored to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backup/backup_1476385197835/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/tsdb-tree/.backup.manifest
&lt;/span&gt;2016-10-13 12:00:02,330 INFO  [main] impl.BackupManifest: Manifest file stored to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backup/backup_1476385197835/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/tsdb/.backup.manifest
&lt;/span&gt;2016-10-13 12:00:02,379 INFO  [main] impl.BackupManifest: Manifest file stored to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ve0524.halxg.cloudera.com:8020/backup/backup_1476385197835/WALs/.backup.manifest
&lt;/span&gt;2016-10-13 12:00:02,388 INFO  [main] impl.FullTableBackupClient: Backup backup_1476385197835 completed.
Backup session backup_1476385197835 finished. Status: SUCCESS
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m just surprised seeing manifests for unrelated tables being updated. Maybe you can&apos;t incremental a single table? Should it complain if so?&lt;/p&gt;

&lt;p&gt;If I describe the incremental it talks about other tables:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ID             : backup_1476385425149
Type           : INCREMENTAL
Tables         : ycsb,tsdb-uid,tsdb-meta,clicks,students,tsdb-tree,tsdb
State          : COMPLETE
Start time     : Thu Oct 13 12:03:45 PDT 2016
End time       : Thu Oct 13 12:03:49 PDT 2016
Progress       : 100
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... that formatting and &apos;:&apos; is a bit wonky...... A 100 is 100% I suppose.&lt;/p&gt;

&lt;p&gt;It is nice I can ask about the backups. Thats good. The history is good too... especially the bit where it says why FAILED:&lt;/p&gt;

&lt;p&gt;State          : FAILED&lt;br/&gt;
Start time     : Wed Oct 12 14:49:46 PDT 2016&lt;br/&gt;
Failed message : Wrong FS: hdfs://ve0524.halxg.cloudera.com:8020/hbase/WALs, expected: &lt;a href=&quot;file:///&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:///&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I was able to backup and restore a small table. Nice. Checks out.&lt;/p&gt;

&lt;p&gt;I  made an incremental and was then able to do a full restore (an incremental w/o a FULL first complains saying &apos;wrong type&apos;... messaging could be better saying need a FULL first).&lt;/p&gt;

&lt;p&gt;Thats enough for now. Would be interesting to spend more time trying the combos but basics seems to work. Thats good. Interface is messy, inconsistent, and so will leave operator with bad impression. If that were fixed, and stuff above, then I&apos;d be game for merge (No incentive to fix once it is in).&lt;/p&gt;











</comment>
                            <comment id="15572979" author="vrodionov" created="Thu, 13 Oct 2016 19:49:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; thanks for giving it a try. We will address the issues you discovered (as well as those in RB) in the separate JIRA: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-16825&quot; title=&quot;Backup mega patch: Review 52748 work&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-16825&quot;&gt;HBASE-16825&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15573011" author="vrodionov" created="Thu, 13 Oct 2016 20:03:12 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I&apos;m just surprised seeing manifests for unrelated tables being updated. Maybe you can&apos;t incremental a single table? Should it complain if so?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is by design. It seems that your first FULL backup was for all tables. You did not specify table list. Correct? In this case next incremental backup (even for a single table) will update meta for ALL tables, which backup system knows already. This is for free. We copy WAL files just once, but update meta (manifests, table description and region boundaries) for ALL tables, which have records in hbase:backup.&lt;/p&gt;</comment>
                            <comment id="15573057" author="stack" created="Thu, 13 Oct 2016 20:20:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;You did not specify table list. Correct?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;When I did my first FULL, no. But doing INCREMENTAL, I did:&lt;/p&gt;

&lt;p&gt;$ ./hbase/bin/hbase --config ~/conf_hbase backup create incremental hdfs://ve0524.halxg.cloudera.com:8020/backup clicks&lt;/p&gt;

&lt;p&gt;I did not expect it to touch other tables. If it does that is well and good but it will confuse. Can you do something better messaging why it is doing this? Thanks.&lt;/p&gt;</comment>
                            <comment id="15573215" author="vrodionov" created="Thu, 13 Oct 2016 21:19:04 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Can you do something better messaging why it is doing this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;These are details of internal implementation. &lt;/p&gt;</comment>
                            <comment id="15573349" author="stack" created="Thu, 13 Oct 2016 22:08:41 +0000"  >&lt;p&gt;It is confusing that I ask for INCREMENTAL on a table but all get updated. Passing the table arg does nothing or is useless?&lt;/p&gt;</comment>
                            <comment id="15573642" author="vrodionov" created="Fri, 14 Oct 2016 00:24:23 +0000"  >&lt;p&gt;No, it is not useless. If you try to do incremental backup for table that does not have full backup - you will get error message. This is the current design side effect: incremental backup does all tables, which have full backup regardless of table list specified (because it is free). Once we have WAL filtering on backup completed - the list of tables will get much more sense - only those tables will be backed up.&lt;/p&gt;</comment>
                            <comment id="15574221" author="stack" created="Fri, 14 Oct 2016 05:14:16 +0000"  >&lt;p&gt;I&apos;m reporting as a &apos;user&apos; that the operation is cryptic (as it seems to be going by your above description). Suggest you do something to make it less so.&lt;/p&gt;</comment>
                            <comment id="15674988" author="stack" created="Thu, 17 Nov 2016 22:26:30 +0000"  >&lt;p&gt;Any follow up here?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12710741">HBASE-11085</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714278">HBASE-11172</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714281">HBASE-11173</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714288">HBASE-11174</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714295">HBASE-11175</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714326">HBASE-11180</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714327">HBASE-11181</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12714329">HBASE-11182</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12707087">HBASE-10926</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12706227">HBASE-10900</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12843261">HBASE-14030</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12846354">HBASE-14123</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12714238">HBASE-11170</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12829269" name="Backup-and-Restore-Apache_19Sep2016.pdf" size="398350" author="fwelsch" created="Mon, 19 Sep 2016 20:53:27 +0000"/>
                            <attachment id="12827813" name="Backup-and-Restore-Apache_9Sep2016.pdf" size="353070" author="vrodionov" created="Fri, 9 Sep 2016 19:21:46 +0000"/>
                            <attachment id="12799036" name="HBaseBackupAndRestore - v0.8.pdf" size="542140" author="vrodionov" created="Fri, 15 Apr 2016 23:20:29 +0000"/>
                            <attachment id="12816339" name="HBaseBackupAndRestore -0.91.pdf" size="485130" author="vrodionov" created="Tue, 5 Jul 2016 23:17:56 +0000"/>
                            <attachment id="12809092" name="HBaseBackupAndRestore-v0.9.pdf" size="526360" author="vrodionov" created="Thu, 9 Jun 2016 01:55:16 +0000"/>
                            <attachment id="12798424" name="HBaseBackupAndRestore.pdf" size="502697" author="vrodionov" created="Wed, 13 Apr 2016 02:09:33 +0000"/>
                            <attachment id="12638284" name="HBaseBackupRestore-Jira-7912-DesignDoc-v1.pdf" size="63127" author="nidmhbase" created="Wed, 2 Apr 2014 16:25:10 +0000"/>
                            <attachment id="12648389" name="HBaseBackupRestore-Jira-7912-DesignDoc-v2.pdf" size="72793" author="nidmhbase" created="Wed, 4 Jun 2014 21:25:45 +0000"/>
                            <attachment id="12743201" name="HBaseBackupRestore-Jira-7912-v4.pdf" size="185122" author="vrodionov" created="Thu, 2 Jul 2015 00:59:19 +0000"/>
                            <attachment id="12743368" name="HBaseBackupRestore-Jira-7912-v5 .pdf" size="193659" author="vrodionov" created="Thu, 2 Jul 2015 18:54:48 +0000"/>
                            <attachment id="12743997" name="HBaseBackupRestore-Jira-7912-v6.pdf" size="202433" author="vrodionov" created="Tue, 7 Jul 2015 17:20:00 +0000"/>
                            <attachment id="12638283" name="HBase_BackupRestore-Jira-7912-CLI-v1.pdf" size="38544" author="nidmhbase" created="Wed, 2 Apr 2014 16:25:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 22 Feb 2013 23:13:38 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>314197</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1i7x3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>314542</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>