<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:10:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3524/HBASE-3524.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3524] NPE from CompactionChecker</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3524</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I recently updated production data to use HBase 0.90.0.&lt;br/&gt;
Now I&apos;m periodically seeing:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;10/02/11 17:23:27&amp;#93;&lt;/span&gt; 30076066 &lt;span class=&quot;error&quot;&gt;&amp;#91;mpactionChecker&amp;#93;&lt;/span&gt; ERROR nServer$MajorCompactionChecker  - Caught exception&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:832)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:810)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.isMajorCompaction(HRegion.java:2800)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker.chore(HRegionServer.java:1047)&lt;br/&gt;
	at org.apache.hadoop.hbase.Chore.run(Chore.java:66)&lt;/p&gt;

&lt;p&gt;The only negative effect is that this is interrupting compactions from happening. But that is pretty serious and this might be a sign of data corruption?&lt;/p&gt;

&lt;p&gt;Maybe it&apos;s just my data, but this task should at least involve improving the handling to catch the NPE and still iterate through the other onlineRegions that might compact without error.  The MajorCompactionChecker.chore() method only catches IOExceptions and so this NPE breaks out of that loop. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12498311">HBASE-3524</key>
            <summary>NPE from CompactionChecker</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ryanobjc">ryan rawson</assignee>
                                    <reporter username="jk-public@troove.net">James Kennedy</reporter>
                        <labels>
                    </labels>
                <created>Fri, 11 Feb 2011 01:56:27 +0000</created>
                <updated>Fri, 20 Nov 2015 12:43:35 +0000</updated>
                            <resolved>Sat, 12 Feb 2011 05:53:41 +0000</resolved>
                                    <version>0.90.0</version>
                                    <fixVersion>0.90.1</fixVersion>
                    <fixVersion>0.90.2</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12993318" author="jk-public@troove.net" created="Fri, 11 Feb 2011 02:56:07 +0000"  >&lt;p&gt;Did some more debugging and got a little more intel:  What&apos;s null on that line is sf.getReader().timeRangeTracker.&lt;/p&gt;

&lt;p&gt;It seems to be consistently null for many if not all tables.  Anyone know how this could happen?&lt;/p&gt;</comment>
                            <comment id="12993320" author="jk-public@troove.net" created="Fri, 11 Feb 2011 03:00:27 +0000"  >&lt;p&gt;I found this in the hbase.log:&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;10/02/11 18:37:29&amp;#93;&lt;/span&gt; 44386  &lt;span class=&quot;error&quot;&gt;&amp;#91;1297391814420-0&amp;#93;&lt;/span&gt; WARN  adoop.hbase.regionserver.Store  - Skipping hdfs://localhost:7701/hbase/.META./1028785192/info/2685681686584745388 because its empty. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-646&quot; title=&quot;EOFException opening HStoreFile info file (spin on HBASE-645 and 550)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-646&quot;&gt;&lt;del&gt;HBASE-646&lt;/del&gt;&lt;/a&gt; DATA LOSS?&lt;/p&gt;

&lt;p&gt;So perhaps this issue is a symptom of corrupt meta data. HOW can I fix this!?&lt;/p&gt;</comment>
                            <comment id="12993321" author="ryanobjc" created="Fri, 11 Feb 2011 03:01:01 +0000"  >&lt;p&gt;Old files causing new code to break it seems. Good job tracking it down!&lt;/p&gt;</comment>
                            <comment id="12993326" author="jk-public@troove.net" created="Fri, 11 Feb 2011 03:16:21 +0000"  >&lt;p&gt;Thanks. I&apos;m in a bit of a pickle. Though I tested all upgrades on QA and test data, this issue has only cropped up on a production deploy. Since our production app appeared to be running smoothly we gave it a +1 and there is already new user data in there. I&apos;m wondering if I should revert to older data anyway (some user data loss) until this corruption is handled...&lt;/p&gt;

&lt;p&gt;Shouldn&apos;t 0.90.0 automatically upgrade old data?&lt;/p&gt;</comment>
                            <comment id="12993327" author="ryanobjc" created="Fri, 11 Feb 2011 03:25:21 +0000"  >&lt;p&gt;the issue is that if the hfile does not have timerangeBytes, this code doesn&apos;t trigger:&lt;/p&gt;

&lt;p&gt;(StoreFile.java)&lt;br/&gt;
      if (timerangeBytes != null) &lt;/p&gt;
{
        this.reader.timeRangeTracker = new TimeRangeTracker();
        Writables.copyWritable(timerangeBytes, this.reader.timeRangeTracker);
      }

&lt;p&gt;And timeRangeTracker remains null.&lt;/p&gt;

&lt;p&gt;But this code doesnt check for null:&lt;/p&gt;

&lt;p&gt;(Store.java)&lt;br/&gt;
832        long oldest = now - sf.getReader().timeRangeTracker.minimumTimestamp;&lt;/p&gt;


&lt;p&gt;if timeRangeTracker is null, we should probably use Integer.MIN_VALUE for minimumTimestamp.&lt;/p&gt;

&lt;p&gt;What is the creation time of your empty file? When is it from? Maybe it&apos;s old?&lt;/p&gt;</comment>
                            <comment id="12993328" author="ryanobjc" created="Fri, 11 Feb 2011 03:31:57 +0000"  >&lt;p&gt;try this patch:&lt;/p&gt;

&lt;p&gt;diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java b/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
index d7e3ce3..519111a 100644&lt;br/&gt;
&amp;#8212; a/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;br/&gt;
@@ -829,7 +829,10 @@ public class Store implements HeapSize {&lt;br/&gt;
       if (filesToCompact.size() == 1) {&lt;br/&gt;
         // Single file&lt;br/&gt;
         StoreFile sf = filesToCompact.get(0);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;long oldest = now - sf.getReader().timeRangeTracker.minimumTimestamp;&lt;br/&gt;
+        long oldest =&lt;br/&gt;
+            (sf.getReader().timeRangeTracker == null) ?&lt;br/&gt;
+                Long.MIN_VALUE :&lt;br/&gt;
+                now - sf.getReader().timeRangeTracker.minimumTimestamp;&lt;br/&gt;
         if (sf.isMajorCompaction() &amp;amp;&amp;amp;&lt;br/&gt;
             (this.ttl == HConstants.FOREVER || oldest &amp;lt; this.ttl)) {&lt;br/&gt;
           if (LOG.isDebugEnabled()) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;no test yet! doh!&lt;/p&gt;</comment>
                            <comment id="12993341" author="jk-public@troove.net" created="Fri, 11 Feb 2011 04:45:42 +0000"  >&lt;p&gt;This patch obviously stops the npe and allows compaction checking to follow through.&lt;/p&gt;

&lt;p&gt;Furthermore I added a log output line that indicates when/what stores have .timeRangeTracker == null when encountered.  It seemed that 7 or 8 tables (out of 50) had this problem and when i forced their major compaction from the hbase shell they stopped reporting the error.&lt;/p&gt;

&lt;p&gt;So it looks like the major compactions created new stores with timeRangeTracker properly.&lt;/p&gt;

&lt;p&gt;I&apos;m still concerned though about how this happened in the first place and I need to do some thorough testing of the data to ensure nothing was lost.&lt;/p&gt;

&lt;p&gt;Ryan, in your opinion do you think this data is likely to have survived corruption?&lt;/p&gt;

&lt;p&gt;And thanks for your speedy help.&lt;/p&gt;</comment>
                            <comment id="12993343" author="ryanobjc" created="Fri, 11 Feb 2011 04:59:57 +0000"  >&lt;p&gt;compaction is &quot;optional&quot;, meaning if it fails no data is lost, so you&lt;br/&gt;
should probably be fine.&lt;/p&gt;

&lt;p&gt;Older versions of the code did not write out time tracker data and&lt;br/&gt;
that is why your older files were giving you npes.&lt;/p&gt;</comment>
                            <comment id="12993365" author="jk-public@troove.net" created="Fri, 11 Feb 2011 07:19:29 +0000"  >&lt;p&gt;&amp;gt; What is the creation time of your empty file? When is it from? Maybe it&apos;s old?&lt;/p&gt;

&lt;p&gt;Let me re-reproduce these issues from scratch tomorrow morning.&lt;/p&gt;</comment>
                            <comment id="12993653" author="jk-public@troove.net" created="Fri, 11 Feb 2011 19:34:53 +0000"  >&lt;p&gt;So that .meta file with DATA LOSS is definitely old (2010-05-20).&lt;br/&gt;
Looking back over old logs i realized that DATA LOSS WARN has been there for a while.&lt;br/&gt;
So probably that is a separate issue from this CompactionChecker problem.&lt;br/&gt;
Guess I&apos;ll just delete the file in HDFS.&lt;/p&gt;

&lt;p&gt;So, it looks like my data is stable now after the forced compactions. I didn&apos;t have to apply the patch in production code to stop the NPEs.&lt;/p&gt;

&lt;p&gt;I&apos;m still concerned about how this happened to some regions and not others since all were left up long enough to get to that NPE point which only prevented the first post-0.90.0 upgrade full compactions for 8 out of 50 tables. Maybe the other 42 were updated as part of the initial startup process...&lt;/p&gt;</comment>
                            <comment id="12993788" author="stack" created="Sat, 12 Feb 2011 01:32:28 +0000"  >&lt;p&gt;Here is a patch that does what Ryan has pasted into comment.  +1 on commit.  Hard to add a test for this.&lt;/p&gt;</comment>
                            <comment id="12993792" author="jk-public@troove.net" created="Sat, 12 Feb 2011 01:40:24 +0000"  >&lt;p&gt;Why choose Long.MIN_VALUE? Wouldn&apos;t Long.MAX_VALUE encourage a major compaction and get pre-0.90.0 StoreFile&apos;s out of the picture sooner?&lt;/p&gt;</comment>
                            <comment id="12993793" author="ryanobjc" created="Sat, 12 Feb 2011 01:45:26 +0000"  >&lt;p&gt;the logic is:&lt;/p&gt;


&lt;p&gt;             (this.ttl == HConstants.FOREVER || oldest &amp;lt; this.ttl)) {&lt;/p&gt;


&lt;p&gt;so if we set oldest to MAX_VALUE then it will &lt;em&gt;never&lt;/em&gt; be smaller than this.ttl which is set to &apos;length of time in ms an edit should live&apos;.  Therefore it would be in the range from 1 -&amp;gt; MAX_VALUE, and by setting oldest to MIN_VALUE this branch will ALWAYS be true and prefer to major compact a single file.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;</comment>
                            <comment id="12993794" author="jk-public@troove.net" created="Sat, 12 Feb 2011 01:48:07 +0000"  >&lt;p&gt;duh, yep i get it. Just crossed a wire somewhere.&lt;/p&gt;</comment>
                            <comment id="12993795" author="ryanobjc" created="Sat, 12 Feb 2011 01:50:50 +0000"  >&lt;p&gt;ttl logic is a little backwards from what one might expect. &lt;/p&gt;

&lt;p&gt;I need a unit test here and then commit. it will become part of 0.90.1. &lt;/p&gt;</comment>
                            <comment id="12993838" author="ryanobjc" created="Sat, 12 Feb 2011 05:53:41 +0000"  >&lt;p&gt;fixed in both trunk &amp;amp; branch.&lt;/p&gt;</comment>
                            <comment id="12994649" author="hudson" created="Tue, 15 Feb 2011 03:59:35 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #1745 (See &lt;a href=&quot;https://hudson.apache.org/hudson/job/HBase-TRUNK/1745/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://hudson.apache.org/hudson/job/HBase-TRUNK/1745/&lt;/a&gt;)&lt;/p&gt;
</comment>
                            <comment id="15017562" author="lars_francke" created="Fri, 20 Nov 2015 12:43:35 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12470921" name="3524.txt" size="1593" author="stack" created="Sat, 12 Feb 2011 01:32:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 11 Feb 2011 03:01:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26898</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hmmn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100928</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>