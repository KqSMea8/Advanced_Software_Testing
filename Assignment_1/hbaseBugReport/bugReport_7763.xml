<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:48:49 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7763/HBASE-7763.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7763] Compactions not sorting based on size anymore.</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7763</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently compaction selection is not sorting based on size.  This causes selection to choose larger files to re-write than are needed when bulk loads are involved.&lt;/p&gt;

</description>
                <environment></environment>
        <key id="12630781">HBASE-7763</key>
            <summary>Compactions not sorting based on size anymore.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="eclark">Elliott Clark</assignee>
                                    <reporter username="eclark">Elliott Clark</reporter>
                        <labels>
                    </labels>
                <created>Mon, 4 Feb 2013 23:19:10 +0000</created>
                <updated>Sat, 23 Mar 2013 04:53:20 +0000</updated>
                            <resolved>Mon, 11 Feb 2013 21:55:15 +0000</resolved>
                                    <version>0.94.6</version>
                    <version>0.95.0</version>
                                    <fixVersion>0.94.6</fixVersion>
                    <fixVersion>0.95.0</fixVersion>
                                    <component>Compaction</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                <comments>
                            <comment id="13570755" author="eclark" created="Mon, 4 Feb 2013 23:52:20 +0000"  >&lt;p&gt;0.94 version&lt;/p&gt;</comment>
                            <comment id="13570757" author="eclark" created="Mon, 4 Feb 2013 23:52:36 +0000"  >&lt;p&gt;Trunk version&lt;/p&gt;</comment>
                            <comment id="13570765" author="yuzhihong@gmail.com" created="Mon, 4 Feb 2013 23:59:11 +0000"  >&lt;p&gt;Good catch.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Comparator&amp;lt;StoreFile&amp;gt; SEQ_ID =
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Comparator&amp;lt;StoreFile&amp;gt; SEQ_ID =
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Is the above change necessary ?&lt;/p&gt;</comment>
                            <comment id="13570776" author="eclark" created="Tue, 5 Feb 2013 00:06:57 +0000"  >&lt;p&gt;The change isn&apos;t 100% needed.  I just did it so that comparators are symmetrical.&lt;/p&gt;</comment>
                            <comment id="13570820" author="hadoopqa" created="Tue, 5 Feb 2013 01:04:49 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12567909/HBASE-7763-trunk-0.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12567909/HBASE-7763-trunk-0.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4324//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13570821" author="yuzhihong@gmail.com" created="Tue, 5 Feb 2013 01:09:01 +0000"  >&lt;p&gt;+1 on patch.&lt;/p&gt;</comment>
                            <comment id="13570838" author="sershe" created="Tue, 5 Feb 2013 01:26:49 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13570851" author="lhofhansl" created="Tue, 5 Feb 2013 01:45:25 +0000"  >&lt;p&gt;Wow, when did this change and how did it go undetected?&lt;/p&gt;</comment>
                            <comment id="13570858" author="lhofhansl" created="Tue, 5 Feb 2013 01:51:22 +0000"  >&lt;p&gt;Looking at the patch it seems this was wrong for a while.&lt;br/&gt;
Will this throw off any other recent selection improvements? Some of the Facebook folks should look at this.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kannanm&quot; class=&quot;user-hover&quot; rel=&quot;kannanm&quot;&gt;Kannan Muthukkaruppan&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikhail&quot; class=&quot;user-hover&quot; rel=&quot;mikhail&quot;&gt;Mikhail Bautin&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nspiegelberg&quot; class=&quot;user-hover&quot; rel=&quot;nspiegelberg&quot;&gt;Nicolas Spiegelberg&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=karthik.ranga&quot; class=&quot;user-hover&quot; rel=&quot;karthik.ranga&quot;&gt;Karthik Ranganathan&lt;/a&gt;, does any of you have any comments?&lt;/p&gt;</comment>
                            <comment id="13570924" author="stack" created="Tue, 5 Feb 2013 03:43:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; Should there be a test to ensure we don&apos;t break it again?  Otherwise +1&lt;/p&gt;</comment>
                            <comment id="13570936" author="eclark" created="Tue, 5 Feb 2013 03:57:02 +0000"  >&lt;p&gt;on trunk it would be pretty easy to create a test.  I&apos;ll get that up soon.&lt;/p&gt;</comment>
                            <comment id="13572138" author="ram_krish" created="Wed, 6 Feb 2013 04:24:09 +0000"  >&lt;p&gt;Has the patch been removed?&lt;/p&gt;</comment>
                            <comment id="13572174" author="lhofhansl" created="Wed, 6 Feb 2013 04:57:09 +0000"  >&lt;p&gt;Elliot removed it for some reason.&lt;/p&gt;</comment>
                            <comment id="13572206" author="stack" created="Wed, 6 Feb 2013 05:59:50 +0000"  >&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; removed it because its too special for the likes of us&lt;/p&gt;</comment>
                            <comment id="13572212" author="eclark" created="Wed, 6 Feb 2013 06:27:53 +0000"  >&lt;p&gt;Yeah I removed it because I&apos;ve pretty much found out that it&apos;s not enough.  I thought I had a simple solution(that I was going to post instead) but this is more complex than I had previously thought.&lt;/p&gt;

&lt;p&gt;The current selection algorithm will select the largest files.  So sorting by size doesn&apos;t really cut down on the ammount of compactions.  This was done so that compactions will have a supposedly better chance of not picking up the same files over and over again.&lt;/p&gt;

&lt;p&gt;So I tried changing that.  It was better in some cases and worse in others.&lt;/p&gt;

&lt;p&gt;Also I think there are some issues with the way files are choosen with regards to the ratio.  All files smaller than or older than (depending upon sorting) the first file that does not break the ratio are chosen.  However you can think up a set of files where the first file that doesn&apos;t break the ratio is the wrong border to pick.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;p&gt;9999, 107, 50, 10, 10, 10, 10&lt;/p&gt;

&lt;p&gt;50 &amp;gt; 40 * 1.2 so I would think that shouldn&apos;t be included in any compaction.  However it will be.  Because&lt;/p&gt;

&lt;p&gt;107 &amp;lt; 90 * 1.2&lt;/p&gt;

&lt;p&gt;So I&apos;m working on getting a better understanding of what these small changes will do.&lt;/p&gt;

&lt;p&gt;Attached is the patch that I&apos;m using to test.  I still need to add more tests and more policies to test the ratio issue.&lt;/p&gt;</comment>
                            <comment id="13572226" author="hadoopqa" created="Wed, 6 Feb 2013 06:53:04 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12568172/HBASE-7763-trunk-TESTING.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12568172/HBASE-7763-trunk-TESTING.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 12 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestCheckTestClasses&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4350//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13572310" author="eclark" created="Wed, 6 Feb 2013 10:20:49 +0000"  >&lt;p&gt;More testing.&lt;/p&gt;

&lt;p&gt;These tests run compactions fewer times.  The hope is that I can find something that compacts well without having to be run a lot, so I don&apos;t want to bias towards things that compact too much.&lt;/p&gt;</comment>
                            <comment id="13572322" author="hadoopqa" created="Wed, 6 Feb 2013 10:40:39 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12568198/HBASE-7763-trunk-TESTING.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12568198/HBASE-7763-trunk-TESTING.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 12 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4352//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13572356" author="eclark" created="Wed, 6 Feb 2013 12:03:30 +0000"  >&lt;p&gt;This test patch produced the results here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.google.com/spreadsheet/ccc?key=0AqJ3FqeHriCkdGxWRE1pN2tIUTREdzhzZ0VzMGEwT2c&amp;amp;usp=sharing&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://docs.google.com/spreadsheet/ccc?key=0AqJ3FqeHriCkdGxWRE1pN2tIUTREdzhzZ0VzMGEwT2c&amp;amp;usp=sharing&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;From what I can see what we have is the worst of all worlds.&lt;/p&gt;

&lt;p&gt;Just adding sorting gets us more io but it also removes a lot more files.  Meaning there could be less re-writing&lt;/p&gt;

&lt;p&gt;Sorting, taking the smallest, and doing the ratio search from the right to the left seems to give us the best files removed per meg of io.  But since it&apos;s more conservative on number of files to compact it could lead to more re-writing in the long term.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="13572363" author="hadoopqa" created="Wed, 6 Feb 2013 12:29:51 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12568210/HBASE-7763-trunk-TESTING.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12568210/HBASE-7763-trunk-TESTING.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 12 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4353//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13572592" author="sershe" created="Wed, 6 Feb 2013 17:19:50 +0000"  >&lt;p&gt;I am reading the patch... meanwhile, one consideration that I somehow forgot when reviewing the original is that you cannot select non-contiguous sequence of files (by seqNum) for compaction currently, given that during reads the preference of which file to read from is established by file seqNums (KeyValueHeap::KVScannerComparator::compare). So if selection is re-sorted someone still needs to ensure it&apos;s contiguous.&lt;/p&gt;</comment>
                            <comment id="13572598" author="sershe" created="Wed, 6 Feb 2013 17:23:40 +0000"  >&lt;p&gt;e.g. if by seqnum you have F0..3 with sizes 18,40,10,10, and ratio 1.0, you shouldn&apos;t compact 18,10,10 into F4, as it will get max seqnum from F3, and if F1 has K1 and F0 had exact same K1, the read preference of K1s will change (correct me if I&apos;m wrong...)&lt;/p&gt;</comment>
                            <comment id="13572616" author="sershe" created="Wed, 6 Feb 2013 17:53:00 +0000"  >&lt;p&gt;Is RatioRight &quot;Ratio&quot; in perf results?&lt;br/&gt;
RatioRight doesn&apos;t make intuitive sense to me. It is picking the same as original algo, except requiring that ratio condition be satisfied for all files inside compaction. &lt;br/&gt;
Say you have 4 3 1 1, minfiles 2, ratio 1, does it make sense to compact 1 1? Is the goal to reduce compaction size?&lt;/p&gt;

&lt;p&gt;As an aside, RatioRight doesn&apos;t appear to check minfiles-sized compaction for having valid ratio. E.g. 9 3 1, minfiles 2, ratio 1, 3 1 would get compacted.&lt;/p&gt;

&lt;p&gt;With regard to sorting I&apos;ll comment later if seqNum issue is shown to be non-issue, I diffed them with the basic policy and in general the idea of sorting by size does make sense,&lt;/p&gt;</comment>
                            <comment id="13572633" author="eclark" created="Wed, 6 Feb 2013 18:17:38 +0000"  >&lt;p&gt;Seq nums are just breaking a tie on ordering for key values that have the same timestamp.  We&apos;ve always said that it&apos;s non-deterministic which kv you will get back if you have two writes at the same timestamp.&lt;/p&gt;</comment>
                            <comment id="13572650" author="eclark" created="Wed, 6 Feb 2013 18:31:01 +0000"  >&lt;ul&gt;
	&lt;li&gt;Default: What we have now.
	&lt;ul&gt;
		&lt;li&gt;Class: &lt;tt&gt;DefaultCompactionPolicy&lt;/tt&gt;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Sort: Default + Sort by size.
	&lt;ul&gt;
		&lt;li&gt;Class: &lt;tt&gt;DefaultCompactionPolicySort&lt;/tt&gt;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;SortSmall: Currently after finding some files that satisfy some definition of the ratio the compaction select then keeps only Max number of files.  To do that it drops the smallest.  The hope was to get the bigger files togther so that later they wouldn&apos;t be part of a smaller compaction.  From testing this doesn&apos;t seem to work.  So after sorting I take the smaller files to compact.   eg if I have &lt;span class=&quot;error&quot;&gt;&amp;#91;101, 100, 99&amp;#93;&lt;/span&gt; and my max is 2.  The old method would take 101 + 100.  Now I would take 99 + 100.
	&lt;ul&gt;
		&lt;li&gt;Class: DefaultCompactionPolicySortSmall&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Ratio: Default + the guarantee that all files satisfy Fi &amp;lt; sum( f0..Fi-1) * ratio.  Right now only the left most file in the compaction has to follow this.  Which means you can compact wildly different files together if large files dominate the sum. eg &lt;span class=&quot;error&quot;&gt;&amp;#91;1000000000, 999, 998, 2, 1&amp;#93;&lt;/span&gt; that will compact 999 + 998 + 2 + 1.  1 and 2 seem like very strange candidates to compact with such unlike files.
	&lt;ul&gt;
		&lt;li&gt;Class: DefaultCompactionPolicyRatioRight&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;SortSmallRatio: Everything discussed in one class.  Sort by size.  Take smallest files when truncating list for max files.  And ensure all files satisfy the raito.
	&lt;ul&gt;
		&lt;li&gt;Class: DefaultCompactionPolicySortSmallRatioRight&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13572862" author="sershe" created="Wed, 6 Feb 2013 21:41:17 +0000"  >&lt;p&gt;1) The book seems to disagree about seqNum:&lt;br/&gt;
&quot;To overwrite an existing value, do a put at exactly the same row, column, and version as that of the cell you would overshadow.&quot;&lt;br/&gt;
&quot;If multiple writes to a cell have the same version, are all versions maintained or just the last? ... Currently, only the last written is fetchable.&quot;&lt;/p&gt;

&lt;p&gt;Although maybe this is not a big deal to change, maybe someone else can comment. I was previously assuming this is important when thinking about compactions.&lt;/p&gt;

&lt;p&gt;2) Any particular reason to run two iterations of selection? Can it run until it stops compacting or gets the number of files to same baseline? Also, -6k/-4k files is hard to judge about baseline.&lt;/p&gt;

&lt;p&gt;3) +1 on taking the smallest files in case of max files limitation.&lt;/p&gt;

&lt;p&gt;4) In your 100000000-900-1 example I would argue that 900 and 1 files are similar, in light of the 100000000 file. This is really a question of whether you want more I/O, more files on average, but smaller compactions; or less I/O and less files but large compactions. I am not an expert customer scenarios, I wonder if L/R be configurable?&lt;br/&gt;
Also, Facebook was trying to solve similar problem with tier-based compaction (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6371&quot; title=&quot;[89-fb] Tier based compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6371&quot;&gt;&lt;del&gt;HBASE-6371&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7055&quot; title=&quot;port HBASE-6371 tier-based compaction from 0.89-fb to trunk (with changes)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7055&quot;&gt;&lt;del&gt;HBASE-7055&lt;/del&gt;&lt;/a&gt;) where files would be selected based on their characteristics; for example size.&lt;/p&gt;</comment>
                            <comment id="13572864" author="sershe" created="Wed, 6 Feb 2013 21:41:57 +0000"  >&lt;p&gt;s/about baseline/without baseline/&lt;/p&gt;</comment>
                            <comment id="13572946" author="eclark" created="Wed, 6 Feb 2013 22:39:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;Although maybe this is not a big deal to change, maybe someone else can comment.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Bulk loaded files break this contract pretty badly.  (So maybe size based sorting should be used only for stores containing bulk loaded files)  But it does seem like something that would need to be discussed first.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Any particular reason to run two iterations of selection?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;To have behave something more like a recursive en queued compaction.&lt;/p&gt;
</comment>
                            <comment id="13572984" author="stack" created="Wed, 6 Feb 2013 23:14:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Seq nums are just breaking a tie on ordering for key values that have the same timestamp. We&apos;ve always said that it&apos;s non-deterministic which kv you will get back if you have two writes at the same timestamp.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, it&apos;d break the tie in favor of the mostly recently written which would be less surprising than if it were the reverse.  I suppose too, we would need to always select a contiguous set of files &amp;#8211; contiguous in the order in which they were written &amp;#8211; if we wanted to be sure to return the last written (if we could select any set, we might not include the file that had the key w/ most recent update).  I believe it used to work this way (thats why the note in the refguide that Sergey quotes).&lt;/p&gt;

&lt;p&gt;This is great stuff you fellas are doing.  It can make all the difference in the world... any improvement found herein.&lt;/p&gt;

</comment>
                            <comment id="13573072" author="lhofhansl" created="Thu, 7 Feb 2013 01:17:21 +0000"  >&lt;p&gt;So just to state the obvious: The selections depends on what metric we&apos;re trying to optimize.&lt;br/&gt;
We can (1) optimize for write amplification (i.e. minimizing it) or optimize for (2) read performance (reducing the number of scanner participating in the merge scan).&lt;/p&gt;

&lt;p&gt;For case #1 we&apos;d pick larger files first, and for #2 we&apos;d pick smaller files first.&lt;br/&gt;
Making this configurable or pluggable thus makes a lot of sense.&lt;/p&gt;

&lt;p&gt;They actual behavior in a production setting is very hard to predict, and as I said above: The folks from Facebook did a lot of research and measuring to come up with the current compaction selection algorithm. I&apos;m surprised they are quiet on this.&lt;/p&gt;</comment>
                            <comment id="13573713" author="sershe" created="Thu, 7 Feb 2013 17:54:58 +0000"  >&lt;p&gt;There&apos;s also a third thing, you can pick up more files, that way you get read perf, low write amplification, but bursty compactions. Which is also the problem for many people as far as I know, since they run major compactions manually.&lt;br/&gt;
Agree with all the improvements above being configurable except sorting, for sorting I am not sure. I am usually in favor of allowing people to improve perf at the risk of shooting themselves in the foot, so as long as we make it very explicit that they will get less guarantees than the refguide says, maybe it should be configurable too. Not certain how important this guarantee is.&lt;/p&gt;</comment>
                            <comment id="13573887" author="eclark" created="Thu, 7 Feb 2013 20:28:56 +0000"  >&lt;p&gt;For the bulk load scenario, sorting by size is very important. Take this example: Bulk loads every hour of small files: (ratio 1.2, max 3 files, min 2)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;5000 20 20 20 20 20 &amp;#93;&lt;/span&gt;  The largest file is from compactions but has -1 as it&apos;s seqNum. So we&apos;ll be compacting [ 500 20 20 ] then &lt;span class=&quot;error&quot;&gt;&amp;#91;5040 20 20&amp;#93;&lt;/span&gt; then &lt;span class=&quot;error&quot;&gt;&amp;#91;5080 20 20&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;So I think we should always have a sort by size after the sort by seqid comparator, in addition to configurable additions talked about above.&lt;/p&gt;


&lt;p&gt;I&apos;ve never seen a user put the same ts and expect to obscure the older one. (Sample size of 1 and all)&lt;br/&gt;
  But it seems like if we come up with something that&apos;s much better but have to give up that one line in the ref guide.  It would be a fair trade.&lt;/p&gt;</comment>
                            <comment id="13573927" author="sershe" created="Thu, 7 Feb 2013 21:05:00 +0000"  >&lt;p&gt;How would we be compacting 5000 with 20 20 with such ratio? Unless major is forced it will compact 20s together in various combinations until they reach 5000/1.2, right?&lt;/p&gt;</comment>
                            <comment id="13573937" author="eclark" created="Thu, 7 Feb 2013 21:16:09 +0000"  >&lt;p&gt;Sorry yeah there needs to be another 5k block on the start&lt;/p&gt;</comment>
                            <comment id="13573959" author="sershe" created="Thu, 7 Feb 2013 21:36:36 +0000"  >&lt;p&gt;Then you&apos;d compact two 5ks (which might be a good idea), then have 10k 20 20 20 and it will go on compacting 20s as intended. &lt;br/&gt;
On the other hand, without size sort, if there&apos;s 4k 5k 5k, it would presumably turn into 4k 10k, and as data is added, 4k will never be compacted except in case of major, is that correct?&lt;br/&gt;
I am +0.9 on sort, someone more experienced can chime in on the balance of breaking the refguide thing versus optimizing this; in my opinion it&apos;s ok to break it if it&apos;s configurable.&lt;/p&gt;

&lt;p&gt;Also, when you make final patch is it possible to make the compare test into an utility so that other ideas can be tested for default policy. Or it can be a separate jira.&lt;/p&gt;</comment>
                            <comment id="13574897" author="eclark" created="Fri, 8 Feb 2013 22:32:30 +0000"  >&lt;p&gt;So I talked with stack and I think he&apos;s correct that even if the seq id promise is not that important, we should honor it.&lt;/p&gt;

&lt;p&gt;So here&apos;s a patch that just adds size based sorting for bulk loaded files, and files that are created by compacting bulk loaded files (these were previously not well sorted). &lt;/p&gt;

&lt;p&gt;I still want to make other changes to the file selection process but that&apos;s a bigger change.  So I kept the perf testing util; I&apos;ll address my other selection thoughts in another jira.&lt;/p&gt;</comment>
                            <comment id="13574925" author="hadoopqa" created="Fri, 8 Feb 2013 22:58:00 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12568650/HBASE-7763-trunk-1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12568650/HBASE-7763-trunk-1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestStoreFile&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4387//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13574935" author="eclark" created="Fri, 8 Feb 2013 23:12:31 +0000"  >&lt;p&gt;Fix for test failure.  Was just a test that I didn&apos;t change for the new ordering.&lt;/p&gt;</comment>
                            <comment id="13574941" author="sershe" created="Fri, 8 Feb 2013 23:25:51 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    /**
-     * FILE_SIZE = descending sort StoreFiles (largest --&amp;gt; smallest in size)
-     */
-    &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Comparator&amp;lt;StoreFile&amp;gt; FILE_SIZE = Ordering.natural().reverse()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Removed due to lack of usage?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[] seeds = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[] {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If a fixed set of random numbers is needed, maybe they can be generated by Random w/fixed seed? Then used &lt;br/&gt;
as seeds to separate randoms if needed.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    List&amp;lt;StoreFile&amp;gt; storeFiles = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;StoreFile&amp;gt;(startingStoreFiles);
+    CompactSelection sel = cp.selectCompaction(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;StoreFile&amp;gt;(storeFiles), &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Lots of lists created around this area. At least the first one looks not useful, as it&apos;s never used without wrapping again.&lt;/p&gt;

&lt;p&gt;Nit: spacing, like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i =0; i&amp;lt; 50; i++) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There are some double blank lines also.&lt;/p&gt;

&lt;p&gt;Can number of iterations be a const, or configurable?&lt;/p&gt;</comment>
                            <comment id="13574942" author="yuzhihong@gmail.com" created="Fri, 8 Feb 2013 23:29:12 +0000"  >&lt;p&gt;For PerfTestCompactionPolicy:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Collection&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]&amp;gt; data() {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Arrays.asList(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[][] {
+        {&lt;span class=&quot;code-quote&quot;&gt;&quot;Default&quot;&lt;/span&gt;,   &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DefaultCompactionPolicy(), 3, 2, 1.2f},
+        {&lt;span class=&quot;code-quote&quot;&gt;&quot;Default&quot;&lt;/span&gt;,   &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DefaultCompactionPolicy(), 4, 2, 1.2f},
+        {&lt;span class=&quot;code-quote&quot;&gt;&quot;Default&quot;&lt;/span&gt;,   &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DefaultCompactionPolicy(), 5, 2, 1.2f},
+        {&lt;span class=&quot;code-quote&quot;&gt;&quot;Default&quot;&lt;/span&gt;,   &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DefaultCompactionPolicy(), 4, 2, 1.3f},
+        {&lt;span class=&quot;code-quote&quot;&gt;&quot;Default&quot;&lt;/span&gt;,   &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DefaultCompactionPolicy(), 4, 2, 1.4f},
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think other compaction policies would be added to the above list. Should the test be named PerfTestCompactionPolicies ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; PerfTestCompactionPolicy(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; name, CompactionPolicy cp, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; max, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; min, &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt; ratio) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please add javadoc for the parameters.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Log LOG = LogFactory.getLog(PerfTestCompactionPolicy.class);
...
+    &lt;span class=&quot;code-comment&quot;&gt;//print out tab delimited so that it can be used in excel/gdocs.
&lt;/span&gt;+    &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(
+                     name
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Should LOG be used above ?&lt;/p&gt;</comment>
                            <comment id="13574981" author="eclark" created="Sat, 9 Feb 2013 00:10:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Removed due to lack of usage?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yep. That plus the fact that it&apos;s usage is not needed and would be wrong.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If a fixed set of random numbers is needed, maybe they can be generated by Random w/fixed seed? Then used &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;as seeds to separate randoms if needed.&lt;br/&gt;
Done&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Lots of lists created around this area. At least the first one looks not useful, as it&apos;s never used without wrapping again.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yep, since filesToCompact and the storeFiles are different parts of the same list we need to do some copying to keep away from concurrent modification exceptions.  I removed the one extra that was un-needed.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Nit: spacing, like&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Fixed.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should LOG be used above ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Nope.  Logger adds way too many other things into a string.  I used sysout so that it can be piped into a tab delim file.&lt;/p&gt;</comment>
                            <comment id="13574989" author="sershe" created="Sat, 9 Feb 2013 00:22:49 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13574991" author="hadoopqa" created="Sat, 9 Feb 2013 00:25:46 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12568657/HBASE-7763-trunk-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12568657/HBASE-7763-trunk-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.security.access.TestAccessController&lt;br/&gt;
                  org.apache.hadoop.hbase.util.TestHBaseFsck&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): &lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4388//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13575023" author="hadoopqa" created="Sat, 9 Feb 2013 01:24:04 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12568665/HBASE-7763-trunk-3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12568665/HBASE-7763-trunk-3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/4390//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13575100" author="kannanm" created="Sat, 9 Feb 2013 06:48:06 +0000"  >&lt;p&gt;Lars: Sorry to pitch in late, but looks like the points got discussed subsequently.&lt;/p&gt;

&lt;p&gt;SequenceID based sorting, and selection of contiguous sub-range of files is important during compactions. This is because, for duplicate entries (same Key (RowKey+ColKey+TS)) in multiple files, sequence id is used as the tie breaker. Looks like proposed fix now is limited to bulk loaded files (which have sequence id of zero). That seems to be ok.&lt;/p&gt;</comment>
                            <comment id="13576142" author="stack" created="Mon, 11 Feb 2013 21:28:53 +0000"  >&lt;p&gt;+1 on patch.  Keeps seqid sorting as first order sort.&lt;/p&gt;</comment>
                            <comment id="13576203" author="hudson" created="Mon, 11 Feb 2013 23:15:53 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3867 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3867/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3867/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7763&quot; title=&quot;Compactions not sorting based on size anymore.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7763&quot;&gt;&lt;del&gt;HBASE-7763&lt;/del&gt;&lt;/a&gt; Compactions not sorting based on size anymore. (Revision 1444977)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/PerfTestCompactionPolicies.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13576314" author="hudson" created="Tue, 12 Feb 2013 02:47:54 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #403 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/403/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/403/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7763&quot; title=&quot;Compactions not sorting based on size anymore.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7763&quot;&gt;&lt;del&gt;HBASE-7763&lt;/del&gt;&lt;/a&gt; Compactions not sorting based on size anymore. (Revision 1444977)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
eclark : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/compactions/PerfTestCompactionPolicies.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13577964" author="eclark" created="Wed, 13 Feb 2013 22:02:16 +0000"  >&lt;p&gt;0.94 version.  Thoughts on this one ?&lt;/p&gt;</comment>
                            <comment id="13578049" author="lhofhansl" created="Thu, 14 Feb 2013 00:01:11 +0000"  >&lt;p&gt;Is this limited to bulk loaded files in 0.94? Doesn&apos;t look that way.&lt;/p&gt;</comment>
                            <comment id="13578057" author="eclark" created="Thu, 14 Feb 2013 00:13:07 +0000"  >&lt;p&gt;Yeah it should be.&lt;/p&gt;

&lt;p&gt;Sort by Bulk load time first (This isn&apos;t there in trunk)&lt;br/&gt;
then sort by seqid&lt;br/&gt;
then sort by size&lt;br/&gt;
then filename&lt;/p&gt;

&lt;p&gt;so only files that dont have a bulk load time (or have exactly the same bulkload time), and have the same seq id will be affected by this.  That should only be files that contain only data from bulk load but were created by compactions.&lt;/p&gt;</comment>
                            <comment id="13578060" author="lhofhansl" created="Thu, 14 Feb 2013 00:17:18 +0000"  >&lt;p&gt;+1 for 0.94 then.&lt;/p&gt;</comment>
                            <comment id="13578071" author="sershe" created="Thu, 14 Feb 2013 00:46:20 +0000"  >&lt;p&gt;Why is the order of seqid and bulktime sorts reversed between 94 an trunk? Not related to this patch, just a general question.&lt;br/&gt;
+1&lt;/p&gt;</comment>
                            <comment id="13581622" author="eclark" created="Tue, 19 Feb 2013 20:59:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why is the order of seqid and bulktime sorts reversed between 94 an trunk? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No idea.  Let me investigate some&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12569275" name="HBASE-7763-094-0.patch" size="5067" author="eclark" created="Wed, 13 Feb 2013 22:02:16 +0000"/>
                            <attachment id="12568650" name="HBASE-7763-trunk-1.patch" size="12420" author="eclark" created="Fri, 8 Feb 2013 22:32:30 +0000"/>
                            <attachment id="12568657" name="HBASE-7763-trunk-2.patch" size="14791" author="eclark" created="Fri, 8 Feb 2013 23:12:31 +0000"/>
                            <attachment id="12568665" name="HBASE-7763-trunk-3.patch" size="14483" author="eclark" created="Sat, 9 Feb 2013 00:10:34 +0000"/>
                            <attachment id="12568210" name="HBASE-7763-trunk-TESTING.patch" size="102010" author="eclark" created="Wed, 6 Feb 2013 12:03:30 +0000"/>
                            <attachment id="12568198" name="HBASE-7763-trunk-TESTING.patch" size="102983" author="eclark" created="Wed, 6 Feb 2013 10:20:49 +0000"/>
                            <attachment id="12568172" name="HBASE-7763-trunk-TESTING.patch" size="48300" author="eclark" created="Wed, 6 Feb 2013 06:27:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 4 Feb 2013 23:59:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>311277</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 43 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1hpwf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>311623</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>