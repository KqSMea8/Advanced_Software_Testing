<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:06:12 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2959/HBASE-2959.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2959] Scanning always starts at the beginning of a row</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2959</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;, the code in &lt;tt&gt;HRegion#get&lt;/tt&gt; was changed like so:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void get(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Get get,
-    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; NavigableSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; []&amp;gt; qualifiers, List&amp;lt;KeyValue&amp;gt; result)
-  &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
-    store.get(get, qualifiers, result);
+  /*
+   * Do a get based on the get parameter.
+   */
+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; List&amp;lt;KeyValue&amp;gt; get(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Get get) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+    Scan scan = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Scan(get);
+
+    List&amp;lt;KeyValue&amp;gt; results = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;KeyValue&amp;gt;();
+
+    InternalScanner scanner = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
+    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+      scanner = getScanner(scan);
+      scanner.next(results);
+    } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (scanner != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
+        scanner.close();
+    }
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; results;
   }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So instead of doing a &lt;tt&gt;get&lt;/tt&gt; straight on the &lt;tt&gt;Store&lt;/tt&gt;, we now open a scanner.  The problem is that we eventually end up in &lt;tt&gt;ScanQueryMatcher&lt;/tt&gt; where the constructor does: &lt;tt&gt;this.startKey = KeyValue.createFirstOnRow(scan.getStartRow());&lt;/tt&gt;.  This entails that if we have a very wide row (thousands of columns), the scanner will need to go through thousands of &lt;tt&gt;KeyValue&lt;/tt&gt;&apos;s before finding the right entry, because it always starts from the beginning of the row, whereas before it was much more straightforward.&lt;/p&gt;

&lt;p&gt;This problem was under the radar for a while because the overhead isn&apos;t too unreasonable, but later on, &lt;tt&gt;incrementColumnValue&lt;/tt&gt; was changed to do a &lt;tt&gt;get&lt;/tt&gt; under the hood.  At StumbleUpon we do thousands of ICV per second, so thousand of times per second we&apos;re scanning some really wide rows.  When a row is contented, this results in all the IPC threads being stuck on acquiring a row lock, while one thread is doing the ICV (albeit slowly due to the excessive scanning).  When all IPC threads are stuck, the region server is unable to serve more requests.&lt;/p&gt;

&lt;p&gt;As a nice side effect, fixing this bug will make &lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;incrementColumnValue&lt;/tt&gt; faster, as well as the first call to &lt;tt&gt;next&lt;/tt&gt; on a scanner.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473267">HBASE-2959</key>
            <summary>Scanning always starts at the beginning of a row</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="tsuna">Benoit Sigoure</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 Sep 2010 17:59:48 +0000</created>
                <updated>Wed, 16 Jul 2014 23:14:33 +0000</updated>
                            <resolved>Wed, 16 Jul 2014 23:14:33 +0000</resolved>
                                    <version>0.20.4</version>
                    <version>0.20.5</version>
                    <version>0.20.6</version>
                    <version>0.89.20100621</version>
                                                    <component>regionserver</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12906016" author="ryanobjc" created="Fri, 3 Sep 2010 18:53:52 +0000"  >&lt;p&gt;We start at the beginning of the row because there might be delete family&lt;br/&gt;
entries there. If we didn&apos;t pick those up we&apos;d not properly mask deletes&lt;/p&gt;

&lt;p&gt;scanner. The problem is that we eventually end up in &lt;tt&gt;ScanQueryMatcher&lt;/tt&gt;&lt;br/&gt;
where the constructor does: {{ this.startKey =&lt;br/&gt;
KeyValue.createFirstOnRow(scan.getStartRow());}}. This entails that if we&lt;br/&gt;
have a very wide row (thousands of columns), the scanner will need to go&lt;br/&gt;
through thousands of {{KeyValue}}s before finding the right entry, because&lt;br/&gt;
it always starts from the beginning of the row, whereas before it was much&lt;br/&gt;
more straightforward.&lt;br/&gt;
too unreasonable, but later on, &lt;tt&gt;incrementColumnValue&lt;/tt&gt; was changed to do a&lt;br/&gt;
&lt;tt&gt;get&lt;/tt&gt; under the hood. At StumbleUpon we do thousands of ICV per second, so&lt;br/&gt;
thousand of times per second we&apos;re scanning some really wide rows. When a&lt;br/&gt;
row is contented, this results in all the IPC threads being stuck on&lt;br/&gt;
acquiring a row lock, while one thread is doing the ICV (albeit slowly due&lt;br/&gt;
to the excessive scanning). When all IPC threads are stuck, the region&lt;br/&gt;
server is unable to serve more requests.&lt;br/&gt;
&lt;tt&gt;incrementColumnValue&lt;/tt&gt; faster, as well as the first call to &lt;tt&gt;next&lt;/tt&gt; on a&lt;br/&gt;
scanner.&lt;/p&gt;</comment>
                            <comment id="12906030" author="ryanobjc" created="Fri, 3 Sep 2010 19:21:14 +0000"  >&lt;p&gt;well my mobile gmail client clearly triggers something bad with jira...&lt;/p&gt;

&lt;p&gt;So the old get code also began at the start of a row, this is to capture the delete family case.  If we got rid of delete family perhaps we could skip more...&lt;/p&gt;
</comment>
                            <comment id="12906681" author="pranavkhaitan" created="Tue, 7 Sep 2010 05:55:12 +0000"  >&lt;p&gt;The reseeking technique would help here. &lt;/p&gt;

&lt;p&gt;Another technique would be to use the bloom filter to find out if we could have any deletes in the file for that row. If bloom filter says that no deletes are present, then go directly to the required place.&lt;/p&gt;</comment>
                            <comment id="12906687" author="ryanobjc" created="Tue, 7 Sep 2010 06:21:34 +0000"  >&lt;p&gt;If we got rid of DeleteFamily would make this easy to implement.&lt;/p&gt;

</comment>
                            <comment id="12906848" author="streamy" created="Tue, 7 Sep 2010 15:56:51 +0000"  >&lt;p&gt;I&apos;m -1 on removing delete family, at least at this point.  It&apos;s pretty widely used and the alternative is &quot;not scalable&quot;.&lt;/p&gt;

&lt;p&gt;I think we should first optimize with reseeks, then look at other optimizations using meta data / blooms, and if we still have issues we might think about removing delete family.  However, I think with the use of meta data, that someone not using delete families would pay virtually no perf hit and would bypass the start-of-row seek.&lt;/p&gt;</comment>
                            <comment id="12906966" author="jdcryans" created="Tue, 7 Sep 2010 20:51:01 +0000"  >&lt;p&gt;One other way this issue is screwing us is that seeking through all those cells will also put more load on the block cache (if the row is contained in more than one block). I&apos;ve been monitoring our deployment closely and the load is definitely much higher on our machines, and the fsReadLatency_avg_time is 10x on average. Also, I grepped through our logs how many times we see evictions per day; our most loaded server had at max 70 evictions before the upgrade, yesterday our busiest server did 2246 evictions and today it&apos;s already at 1503.&lt;/p&gt;</comment>
                            <comment id="12907133" author="tsuna" created="Wed, 8 Sep 2010 08:44:29 +0000"  >&lt;p&gt;Yes this issue is a pretty major performance regression for us (although the way we use HBase to hit this regression is somewhat questionable - the schema is way suboptimal for HBase).&lt;/p&gt;

&lt;p&gt;Jonathan, I&apos;m missing some context about &quot;delete family&quot;.  Ryan and Stack mentioned some of it to me but I still don&apos;t understand why it would be so expensive to store delete markers for each and every KeyValue you delete.  Putting such markers before actual data will always make it harder for HBase to honor them since HBase has to &quot;seek back&quot; to see them (or seek early and then seek forward to find the actual data provided that there was no delete marker, which is the problem we&apos;re running into here), and HBase isn&apos;t very good at &quot;seeking back&quot;.&lt;/p&gt;</comment>
                            <comment id="12907333" author="streamy" created="Wed, 8 Sep 2010 17:44:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;Wrong or indeterminate behavior when there are duplicate versions of a column&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There hasn&apos;t been any change in HBase behavior.  This issue has always existed.  And until recent patches from Pranav, we would actually read the entire row even if we only wanted a single column out of it.  So there have been distinct perf improvements added on trunk not regressions.  I think the regressions are coming from your change in schema design.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Jonathan, I&apos;m missing some context about &quot;delete family&quot;. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Imagine I have a row with 20k columns and versions in it.  I want to delete this row.  I now have to read in all 20k KVs then do an insert 20k new delete marker KVs.  When I do a read on this row later, I will have to shuffle through all 40k of these KVs, processing the delete marker before each deleted KV.  The actual delete operation will be quite slow and then all reads against this row will be slow (well beyond the hit of a start-of-row seek).  Deleting rows is fairly common IMO, I know that we are doing it here and I&apos;ve made use of it in the past as well.&lt;/p&gt;

&lt;p&gt;The direction I&apos;d like to see is to move delete families to the side if we don&apos;t want to pay the cost of having to start every row read at the start of the row.  It&apos;d be an open question if we wanted to do that with delete columns as well, since the same issue will exist if you have a single column with many versions (a schema used here).&lt;/p&gt;

&lt;p&gt;A space efficient way would be to have a delete bloom (could be:  deletefam+row+ts as the key, can stuff in deletecol+row+col+ts to the same bloom as well).  If you hit the bloom, then you have to do the start-of-row seek.  If not, you go straight to the column/version in question and don&apos;t pay any delete tax besides the bloom lookup.  If you have no deletes then there will be virtually no increase in memory usage or latency.&lt;/p&gt;</comment>
                            <comment id="12907335" author="streamy" created="Wed, 8 Sep 2010 17:50:54 +0000"  >&lt;p&gt;Sorry, mis-pasted the first quote.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yes this issue is a pretty major performance regression for us&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m just trying to be clear.  It is not &lt;em&gt;this&lt;/em&gt; issue that is causing a performance regression (though this issue is likely involved with the slowness).  This issue has not changed since 0.20, it is the move to making Gets into Scans.  And in that, it&apos;s probably that previously a Get would early-out if the incremented column was in MemStore whereas now we seek every file before doing the get.&lt;/p&gt;</comment>
                            <comment id="12907372" author="tsuna" created="Wed, 8 Sep 2010 19:30:23 +0000"  >&lt;p&gt;Is there a way to short-circuit the code and attempt to be more direct like the old code used to when it was using &lt;tt&gt;get&lt;/tt&gt;?  The current code goes through a bazillion lines to make a &lt;tt&gt;get&lt;/tt&gt;, which creates a scanner, etc.  Isn&apos;t it possible to just quickly grab whatever locks are needed, try to hit the memstore, and do the ICV super fast this way?&lt;/p&gt;</comment>
                            <comment id="12907375" author="streamy" created="Wed, 8 Sep 2010 19:36:17 +0000"  >&lt;p&gt;I think it is possible to do something like that for ICV gets (not normal gets) and will look into implementing it this week.&lt;/p&gt;</comment>
                            <comment id="12918312" author="streamy" created="Tue, 5 Oct 2010 23:15:31 +0000"  >&lt;p&gt;Should we still punt this from 0.90?  Doubtful anything will be done in time.&lt;/p&gt;</comment>
                            <comment id="12918317" author="stack" created="Tue, 5 Oct 2010 23:24:23 +0000"  >&lt;p&gt;Moving out of 0.90.  Wide rows will kill 0.90.  We need to warn against them.&lt;/p&gt;</comment>
                            <comment id="12918320" author="stack" created="Tue, 5 Oct 2010 23:28:09 +0000"  >&lt;p&gt;Let me take back last comment.  Ryan says it should be better than it has ever been.   He&apos;s working on proving it.&lt;/p&gt;</comment>
                            <comment id="12918330" author="streamy" created="Tue, 5 Oct 2010 23:47:47 +0000"  >&lt;p&gt;It is way better.  We have rows with many many thousands of columns (well, versions).  All the new seek stuff has made significant improvement.&lt;/p&gt;

&lt;p&gt;Agree that this is still an issue, but this is not even at implementation stage, we still have to have more design discussions.  So +1 on punting.&lt;/p&gt;</comment>
                            <comment id="12918333" author="streamy" created="Tue, 5 Oct 2010 23:49:29 +0000"  >&lt;p&gt;And this is certainly not a blocker.&lt;/p&gt;</comment>
                            <comment id="14064316" author="apurtell" created="Wed, 16 Jul 2014 23:14:33 +0000"  >&lt;p&gt;Cleaning up issue by resolving as Won&apos;t Fix based on discussion&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12457095">HBASE-2248</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12462095">HBASE-2450</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12475882">HBASE-3082</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 Sep 2010 18:53:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26556</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 22 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02c9r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11589</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>performance</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>