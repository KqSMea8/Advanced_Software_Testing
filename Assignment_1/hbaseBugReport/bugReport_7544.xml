<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:46:46 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7544/HBASE-7544.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7544] Transparent table/CF encryption</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7544</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Introduce transparent encryption of HBase on disk data.&lt;/p&gt;

&lt;p&gt;Depends on a separate contribution of an encryption codec framework to Hadoop core and an AES-NI (native code) codec. This is work done in the context of &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-4491&quot; title=&quot;Encryption and Key Protection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-4491&quot;&gt;MAPREDUCE-4491&lt;/a&gt; but I&apos;d gather there will be additional JIRAs for common and HDFS parts of it.&lt;/p&gt;

&lt;p&gt;Requirements:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Transparent encryption at the CF or table level&lt;/li&gt;
	&lt;li&gt;Protect against all data leakage from files at rest&lt;/li&gt;
	&lt;li&gt;Two-tier key architecture for consistency with best practices for this feature in the RDBMS world&lt;/li&gt;
	&lt;li&gt;Built-in key management&lt;/li&gt;
	&lt;li&gt;Flexible and non-intrusive key rotation&lt;/li&gt;
	&lt;li&gt;Mechanisms not exposed to or modifiable by users&lt;/li&gt;
	&lt;li&gt;Hardware security module integration (via Java KeyStore)&lt;/li&gt;
	&lt;li&gt;HBCK support for transparently encrypted files (+ plugin architecture for HBCK)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Additional goals:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Shell support for administrative functions&lt;/li&gt;
	&lt;li&gt;Avoid performance impact for the null crypto codec case&lt;/li&gt;
	&lt;li&gt;Play nicely with other changes underway: in HFile, block coding, etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;We&apos;re aiming for rough parity with Oracle&apos;s transparent tablespace encryption feature, described in &lt;a href=&quot;http://www.oracle.com/technetwork/database/owp-security-advanced-security-11gr-133411.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.oracle.com/technetwork/database/owp-security-advanced-security-11gr-133411.pdf&lt;/a&gt; as&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&#8220;Transparent Data Encryption uses a 2-tier key architecture for flexible and non-intrusive key rotation and least operational and performance impact: Each application table with at least one encrypted column has its own table key, which is applied to all encrypted columns in that table. Equally, each encrypted tablespace has its own tablespace key. Table keys are stored in the data dictionary of the database, while tablespace keys are stored in the header of the tablespace and additionally, the header of each underlying OS file that makes up the tablespace.  Each of these keys is encrypted with the TDE master encryption key, which is stored outside of the database in an external security module: either the Oracle Wallet (a PKCS#12 formatted file that is encrypted using a passphrase supplied either by the designated security administrator or DBA during setup),  or a Hardware Security Module (HSM) device for higher assurance &lt;span class=&quot;error&quot;&gt;&amp;#91;&#8230;&amp;#93;&lt;/span&gt;&#8221;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Further design details forthcoming in a design document and patch as soon as we have all of the clearances in place.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12627246">HBASE-7544</key>
            <summary>Transparent table/CF encryption</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="apurtell">Andrew Purtell</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Fri, 11 Jan 2013 20:33:02 +0000</created>
                <updated>Mon, 22 Aug 2016 05:48:38 +0000</updated>
                            <resolved>Tue, 26 Nov 2013 04:25:13 +0000</resolved>
                                                    <fixVersion>0.98.0</fixVersion>
                                    <component>HFile</component>
                    <component>io</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>38</watches>
                                                                <comments>
                            <comment id="13551510" author="apurtell" created="Fri, 11 Jan 2013 20:56:10 +0000"  >&lt;p&gt;The design also covers encrypting WALedits for sensitive CFs but I&apos;m debating if that should be a separate JIRA. More shortly.&lt;/p&gt;</comment>
                            <comment id="13551589" author="tlipcon" created="Fri, 11 Jan 2013 22:24:40 +0000"  >&lt;p&gt;I&apos;m a little skeptical: why not do this at the HDFS layer?&lt;/p&gt;</comment>
                            <comment id="13551599" author="apurtell" created="Fri, 11 Jan 2013 22:32:00 +0000"  >&lt;p&gt;&amp;gt; I&apos;m a little skeptical: why not do this at the HDFS layer?&lt;/p&gt;

&lt;p&gt;This design simply structures encryption exactly the same as we do compression. &lt;/p&gt;

&lt;p&gt;Should we do compression at the HDFS layer?&lt;/p&gt;

&lt;p&gt;Can you be more specific with what you have in mind? Say we have per CF keys and want to set up readers and writers to use them, what kind of provision would/could HDFS have for that?&lt;/p&gt;</comment>
                            <comment id="13551604" author="apurtell" created="Fri, 11 Jan 2013 22:39:02 +0000"  >&lt;p&gt;Also, I&apos;m struggling to see how to encrypt WALEdits on a per CF basis with HDFS level tricks, but sure this could be a separate case.&lt;/p&gt;</comment>
                            <comment id="13551623" author="apurtell" created="Fri, 11 Jan 2013 23:21:46 +0000"  >&lt;p&gt;Note: I moved the below out of the description of this issue:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have an experimental patch that introduces encryption at the HFile level, with all necessary changes propagated up to the HStore level. For the most part, the changes are straightforward and mechanical. After &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7414&quot; title=&quot;Convert some HFile metadata to PB&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7414&quot;&gt;&lt;del&gt;HBASE-7414&lt;/del&gt;&lt;/a&gt;, we can introduce specification of an optional encryption codec in the file trailer. The work is not ready to go yet because key management and the HBCK pieces are TBD.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this is what Todd was commenting about and I agree so far as it&apos;s an implementation option not a description of the objective per se.&lt;/p&gt;</comment>
                            <comment id="13551645" author="tlipcon" created="Fri, 11 Jan 2013 23:39:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should we do compression at the HDFS layer?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;IMO yes, probably &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you be more specific with what you have in mind? Say we have per CF keys and want to set up readers and writers to use them, what kind of provision would/could HDFS have for that?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll admit I missed the bit above about per-CF keys. That&apos;s a little odd, though, because the &apos;hbase&apos; user would have to have to have access to all the keys, and that user is the only one who would have access to the on-disk files What&apos;s the threat model here?&lt;/p&gt;</comment>
                            <comment id="13551696" author="apurtell" created="Sat, 12 Jan 2013 00:23:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;the &apos;hbase&apos; user would have to have to have access to all the keys, and that user is the only one who would have access to the on-disk files&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The aim is to protect sensitive data against accidental leakage and to facilitate auditable compliance according to the regulations under which several industries operate. We assume under normal circumstances that the &apos;hbase&apos; user is the only one who would have access to on-disk files. However this does not guarantee leakage isn&apos;t possible if HDFS configuration is incorrect &amp;#8211; HDFS and HBase might be independently managed &amp;#8211; or if a server is decommissioned from the cluster and mishandled. The usual rationale for this type of feature. &lt;/p&gt;

&lt;p&gt;Schema design considerations are similar to those of HFile compression. Some tables might only have one sensitive column encrypted, to minimize performance impacts. We might also not want to encrypt every type of block in the HFile (nor compress them). &lt;/p&gt;

&lt;p&gt;There would be a master key supplied to HBase processes, managed by the cluster administrator, protected by the Java Keystore, perhaps residing on a hardware security module. Within HBase, per-table and per-CF keys are created on demand. There are a couple of reasons why the 2-tier key architecture is good (reduction of scope of compromise, facilitating lazy key rotation, etc.) The administrator would need to run HBCK on a system with access to the master key material in order to take recovery actions.&lt;/p&gt;

&lt;p&gt;I will attach a design doc and patch for consideration, once I have the go ahead. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13551699" author="apurtell" created="Sat, 12 Jan 2013 00:29:32 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Should we do compression at the HDFS layer?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;IMO yes, probably &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As a longer term project, I wouldn&apos;t mind looking at pushing both compression and encryption down into HDFS somehow. I haven&apos;t really thought it through. It seems higher risk because of the externialities.&lt;/p&gt;</comment>
                            <comment id="13551705" author="apurtell" created="Sat, 12 Jan 2013 00:47:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;Within HBase, per-table and per-CF keys are created on demand. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I should be a little clearer about this. The admin can turn on encryption one CF at a time, or can at any time do it for the whole table. In the latter case, every CF not configured for encryption would be set up accordingly.&lt;/p&gt;</comment>
                            <comment id="13577847" author="apurtell" created="Wed, 13 Feb 2013 19:24:08 +0000"  >&lt;p&gt;I have a WIP patch that might be in good enough shape to drop soon. However, I would like to solicit opinion on something in advance:&lt;/p&gt;

&lt;p&gt;This work builds on a crypto codec framework to be submitted to the Hadoop Common and MapReduce projects. It will be maintained out of tree as a patch or on a feature branch until those APIs show up downstream (on the assumption that will happen eventually). Even so, there will be a period of time where some versions of Hadoop will have new APIs and some won&apos;t. There will probably be a request to backport from trunk to Hadoop 2.0, but I won&apos;t speculate on outcome. I can put code which refers to the new APIs in what would become part of a new hadoop-compat module (for Hadoop 3.0), or handle all of the instantiations with reflection to account for changes which may not have such a clear version boundary. I lean toward the latter as a realist, though I think of reflection as the least bad option. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13585582" author="apurtell" created="Mon, 25 Feb 2013 03:10:19 +0000"  >&lt;p&gt;Attached 7554.patch. This depends on changes to Hadoop Common not yet in tree and is intended to be informational only at this time.&lt;/p&gt;</comment>
                            <comment id="13592085" author="apurtell" created="Mon, 4 Mar 2013 09:35:19 +0000"  >&lt;p&gt;Feedback from the Feb 28 HUG: Row key data may leak into encoded region names in META and in ZooKeeper znodes. We have not addressed this yet, mainly because of the challenge of dealing with META. It should be straightforward to encrypt znode data on write and decrypt on read. For META we cannot change the region name encoding without disrupting sort order. The solution for obscuring on disk META data is for the admin to enable encryption on the META table (and for HBase to support META schema configuration changes).&lt;/p&gt;

&lt;p&gt;We may simply want to clearly document that constructing row keys with sensitive data should be avoided, as it may leak among users of the system. &lt;/p&gt;

&lt;p&gt;Transparent encryption does not address protection of the data of one user from another. This is outside the scope of this JIRA. To address this other use case, we might propose HTable support for compression codecs for mutation data. Aside from being useful for transparent compression, encryption codecs can stand in for compression codecs, thus the user can at their option encrypt keys and data. (It&apos;s an application concern so HTable support for this would be convenient but not essential.) Encrypting keys will have obvious consequences that should still be documented.&lt;/p&gt;</comment>
                            <comment id="13602890" author="apurtell" created="Thu, 14 Mar 2013 23:38:45 +0000"  >&lt;p&gt;Updated patch and document.&lt;/p&gt;

&lt;p&gt;Instead of using reflection in the Encryption facade to avoid compilation failures if org.apache.hadoop.io.crypto is not available, now sources that reference that package are conditionally included in the generate-sources phase if a new &apos;crypto&apos; profile is selected via -Dcrypto. Reflection is no longer required so is removed. Use of the build-helper plugin in this way would be transitional. Also updated to use AES-128 for WAL encryption instead of AES-256.&lt;/p&gt;</comment>
                            <comment id="13603534" author="yuzhihong@gmail.com" created="Fri, 15 Mar 2013 17:13:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;if a new &apos;crypto&apos; profile is selected via -Dcrypto&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess you meant &apos;-Pcrypto&apos; above.&lt;/p&gt;

&lt;p&gt;The patch applies cleanly on trunk, however:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-testCompile) on project hbase-server: Compilation failure
[ERROR] /Users/tyu/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java:[602,30] cannot find symbol
[ERROR] symbol  : constructor Reader(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.hbase.io.hfile.CacheConfig,org.apache.hadoop.hbase.io.encoding.DataBlockEncoding)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If patch is ready for review, maybe put it on review board ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13603546" author="yuzhihong@gmail.com" created="Fri, 15 Mar 2013 17:23:35 +0000"  >&lt;p&gt;In the patch, I saw the following new files:&lt;/p&gt;

&lt;p&gt;hbase-common/crypto/main/with/java/org/apache/hadoop/hbase/io/crypto/Encryption.java&lt;br/&gt;
hbase-common/crypto/main/without/java/org/apache/hadoop/hbase/io/crypto/Encryption.java&lt;/p&gt;

&lt;p&gt;Looking at the javadoc for the above classes, I don&apos;t see much difference. I guess the second file is for when org.apache.hadoop.io.crypto is not available.&lt;br/&gt;
Does it make sense to extract classes under hbase-common/crypto into their own module ?&lt;/p&gt;</comment>
                            <comment id="13603555" author="apurtell" created="Fri, 15 Mar 2013 17:29:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;I guess you meant &apos;-Pcrypto&apos; above.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No I meant -Dcrypto.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The patch applies cleanly on trunk, however: &lt;span class=&quot;error&quot;&gt;&amp;#91;Compilation failure because artifacts with API changes are not in the local Maven cache&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like artifacts with the API changes in the patch are not in the local Maven cache. Can&apos;t help you there.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If patch is ready for review&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll be maintaining this out of tree until org.apache.hadoop.io.crypto is available somewhere downstream.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Does it make sense to extract classes under hbase-common/crypto into their own module ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No I don&apos;t think a separate module makes sense. There are a lot of changes in hadoop-server in order to make use of crypto in block encoding contexts. The Maven profile is a transitional approach to avoiding compilation problems if building against a Hadoop without crypto support. I think once there is a Hadoop with org.apache.hadoop.io.crypto available &amp;#8211; perhaps this will be 3.0 aka trunk &amp;#8211; then it probably makes sense to move o.a.h.h.io.crypto.Encryption into a new hadoop-compat module, as well as use a new factory in that new compat module to instantiate SequenceFile readers and writers for HLog. &lt;/p&gt;
</comment>
                            <comment id="13603570" author="yuzhihong@gmail.com" created="Fri, 15 Mar 2013 17:40:09 +0000"  >&lt;p&gt;w.r.t. the compilation error, it was due to missing the last parameter in the ctor:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Reader(FileSystem fs, Path path, CacheConfig cacheConf,
        DataBlockEncoding preferredEncodingInCache,
        Encryption.Context cryptoContext) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I am a little confused by the new crypto profile. In hbase-common/pom.xml:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+      Profile &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; building against a crypto enabled Hadoop. Activate using:
+       mvn -Pcrypto
+    --&amp;gt;
+    &amp;lt;profile&amp;gt;
+      &amp;lt;id&amp;gt;crypto&amp;lt;/id&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13603596" author="apurtell" created="Fri, 15 Mar 2013 17:55:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;w.r.t. the compilation error&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A &apos;mvn -Dcrypto -Dhadoop.profile=2.0 -DskipTests clean install&apos; to get everything in place in the local Maven cache followed by a &apos;mvn -Dcrypto -Dhadoop.profile=2.0 test -Dtest=TestHFileEncryption&apos; works for me here. &lt;/p&gt;

&lt;p&gt;(I am using a locally patched version of Hadoop branch-2 with crypto support. You can get it at &lt;a href=&quot;https://github.com/intel-hadoop/hadoop-common-rhino/tree/branch-2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/intel-hadoop/hadoop-common-rhino/tree/branch-2&lt;/a&gt;. Be sure to compile Hadoop with -Pnative and include the directory holding the newly built libhadoop.so in LD_LIBRARY_PATH or TestHFileEncryption won&apos;t pass.)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In hbase-common/pom.xml&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes that should be -Dcrypto. The &apos;crypto&apos; or &apos;nocrypto&apos; profiles are activated depending on if that is defined or not. If you have some thoughts on how this could be done better with Maven that would be great. Unfortunately a separate module isn&apos;t feasible because of the changes in hbase-server. Originally I didn&apos;t do any of this Maven hacking, I just used reflection in Encryption.java, but I don&apos;t want to do it that way because reflection is brittle and slow. I also need to use a different constructor for the WALReader in SequenceFileLogReader. (This is because HBase uses the deprecated Hadoop 1 style constructors for SequenceFile and the crypto support for SequenceFile, when using those constructors, requires a crypto context at instantiation.) So at a minimum I had to separate out a crypto enabled SequenceFileLogReader from a stock SequenceFileLogReader. This difference would be an excellent candidate for a hadoop-compat module as soon as there&apos;s a Hadoop version suitable for targeting.&lt;/p&gt;</comment>
                            <comment id="13603611" author="apurtell" created="Fri, 15 Mar 2013 18:04:56 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;w.r.t. the compilation error&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A &apos;mvn -Dcrypto -Dhadoop.profile=2.0 -DskipTests clean install&apos; to get everything in place in the local Maven cache followed by a &apos;mvn -Dcrypto -Dhadoop.profile=2.0 test -Dtest=TestHFileEncryption&apos; works for me here&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Almost forgot that I also have to modify the root pom.xml to define hadoop-two.version to 2.0.4-SNAPSHOT. For some reason defining &apos;-Dhadoop-two.version=2.0.4-SNAPSHOT&apos; on the Maven command line doesn&apos;t do what I expect, Maven will still select 2.0.2-alpha as specified in the POM when building hbase-server. I raised this issue on dev@ but IIRC Nick said it worked for him, so I don&apos;t know what to make of that. &lt;/p&gt;</comment>
                            <comment id="13603612" author="yuzhihong@gmail.com" created="Fri, 15 Mar 2013 18:05:00 +0000"  >&lt;p&gt;I still couldn&apos;t get pass the compilation error.&lt;br/&gt;
This is due to a change similar to the following is missing in TestStoreFile.java at line 602.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java
index 81a313a..4225771 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java
...
@@ -478,7 +474,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TestStoreFile &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; HBaseTestCase {
     writer.close();

     StoreFile.Reader reader = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StoreFile.Reader(fs, f, cacheConf,
-        DataBlockEncoding.NONE);
+        DataBlockEncoding.NONE, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Will try out the above Hadoop branch-2 git.&lt;/p&gt;</comment>
                            <comment id="13603619" author="yuzhihong@gmail.com" created="Fri, 15 Mar 2013 18:09:39 +0000"  >&lt;p&gt;w.r.t. defining hadoop-two.version as 2.0.4-SNAPSHOT, I proposed doing this for trunk over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904&quot; title=&quot;Make mapreduce jobs pass based on 2.0.4-alpha&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7904&quot;&gt;&lt;del&gt;HBASE-7904&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What do you think ?&lt;/p&gt;</comment>
                            <comment id="13603620" author="apurtell" created="Fri, 15 Mar 2013 18:09:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;I still couldn&apos;t get pass the compilation error. This is due to a change similar to the following is missing in TestStoreFile.java at line 602.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for trying it out. The build is passing here. Let me make a new patch, maybe the one attached to this issue is incorrect.&lt;/p&gt;</comment>
                            <comment id="13603624" author="apurtell" created="Fri, 15 Mar 2013 18:11:31 +0000"  >&lt;blockquote&gt;
&lt;p&gt;w.r.t. defining hadoop-two.version as 2.0.4-SNAPSHOT, I proposed doing this for trunk over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904&quot; title=&quot;Make mapreduce jobs pass based on 2.0.4-alpha&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7904&quot;&gt;&lt;del&gt;HBASE-7904&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
What do you think ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;IIRC I changed my vote to +0 on that.&lt;br/&gt;
I&apos;d rather see someone who knows Maven better than I fix the build so you can specify a hadoop-two version other than in the root POM on the command line.&lt;/p&gt;</comment>
                            <comment id="13603632" author="apurtell" created="Fri, 15 Mar 2013 18:19:13 +0000"  >&lt;p&gt;Updated patch rebased to current trunk (SVN r1457042)&lt;/p&gt;</comment>
                            <comment id="13603664" author="yuzhihong@gmail.com" created="Fri, 15 Mar 2013 18:43:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;Future work is planned on optimizing WAL encryption.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think another improvement, once &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5699&quot; title=&quot;Run with &amp;gt; 1 WAL in HRegionServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5699&quot;&gt;&lt;del&gt;HBASE-5699&lt;/del&gt;&lt;/a&gt; is in place, is to only encrypt WAL for table(s) where encryption is turned on.&lt;/p&gt;</comment>
                            <comment id="13603680" author="apurtell" created="Fri, 15 Mar 2013 18:50:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think another improvement, once &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5699&quot; title=&quot;Run with &amp;gt; 1 WAL in HRegionServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5699&quot;&gt;&lt;del&gt;HBASE-5699&lt;/del&gt;&lt;/a&gt; is in place, is to only encrypt WAL for table(s) where encryption is turned on.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for the feedback. I did try this already BTW, encrypting WALedits case by case instead of using SequenceFile record encryption (aka &quot;compression&quot;) currently significantly hurts performance. Agreed with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5699&quot; title=&quot;Run with &amp;gt; 1 WAL in HRegionServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5699&quot;&gt;&lt;del&gt;HBASE-5699&lt;/del&gt;&lt;/a&gt; maybe it&apos;s possible to segregate WALedits for table(s) with encryption turned on to an encrypted container while leaving the others alone.&lt;/p&gt;</comment>
                            <comment id="13710611" author="apurtell" created="Wed, 17 Jul 2013 02:05:04 +0000"  >&lt;p&gt;I recently added some simple shell support for testing this to 0.94-ish code, dropping the patch here for later. Should work modulo a minor fix up. A proper new patch requires a fair amount of rebasing.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure what is the long term disposition of the Hadoop side patches this issue depends on. It might be worth trying this with JRE ciphers.&lt;/p&gt;</comment>
                            <comment id="13769955" author="apurtell" created="Tue, 17 Sep 2013 21:00:47 +0000"  >&lt;p&gt;Reattaching previous work as files named &apos;historical-*&apos;. On account of radio silence over in Hadoop on a proposed encryption algorithm framework for Hadoop common, I have redone this work to remove any external dependencies, based on HFile v3 and targeting 0.98.&lt;/p&gt;</comment>
                            <comment id="13769966" author="apurtell" created="Tue, 17 Sep 2013 21:10:17 +0000"  >&lt;p&gt;Patch &apos;7544p1&apos; provides an encryption scaffold and AES algorithm support in hbase-common.&lt;/p&gt;

&lt;p&gt;The API design on the HBase side is similar to the historical patch but we were not bound by any legacy so where it could be improved it has been improved. I&apos;m much happier with this result, actually, there are no dependencies on anything but standard Java security APIs. This patch wraps and hides the JCE javax.crypto.Cipher type so as to allow future addition of HBase optimized/accelerated encryption algorithm implementations not based on the JCE, which in the case of at least the Oracle JRE requires encryption algorithm providers to be signed with a restricted code signing key not obtainable by an open source project. (Unsigned JCE providers are allowed by the OpenJDK JRE, but OpenJDK is not recommended for production.) The name of this type can be trivally changed if there is a concern about how it hides javax.crypto.Cipher. I did initially use the name &apos;Algorithm&apos; but this seemed too generic and might be confused with Compression.Algorithm.&lt;/p&gt;

&lt;p&gt;Implementing a native optimized/accelerated AES cipher for HBase is ongoing work that should be completed shortly.&lt;/p&gt;</comment>
                            <comment id="13769969" author="apurtell" created="Tue, 17 Sep 2013 21:12:19 +0000"  >&lt;p&gt;Patch &apos;7544p2&apos; introduces new protos for encryption and support in hbase-client (which hbase-server will also have available, pulled in as a dependency) for protecting key material in an algorithm agnostic way. This is used for protecting CF keys in table schema and HFiles.&lt;/p&gt;</comment>
                            <comment id="13769978" author="apurtell" created="Tue, 17 Sep 2013 21:16:56 +0000"  >&lt;p&gt;Provisional patch &apos;7544p3&apos;, which depends on uncommitted work on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8496&quot; title=&quot;Implement tags and the internals of how a tag should look like&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8496&quot;&gt;&lt;del&gt;HBASE-8496&lt;/del&gt;&lt;/a&gt; (HFile V3), implements HFile V3 reader and writer support for transparently encrypted HFiles using the new cipher framework in hbase-common. It needs more unit tests, shell support, and cluster testing and performance impact evaluation as was done for the historical patch. This work is ongoing. I am attaching it now so you can get a sense of the work if you are so inclined.&lt;/p&gt;</comment>
                            <comment id="13769984" author="apurtell" created="Tue, 17 Sep 2013 21:19:13 +0000"  >&lt;p&gt;Additional patches will be forthcoming shortly for WAL encryption and the remaining bits of the historical work not yet ported over.&lt;/p&gt;</comment>
                            <comment id="13794534" author="apurtell" created="Mon, 14 Oct 2013 21:58:23 +0000"  >&lt;p&gt;Rebase against latest trunk.&lt;/p&gt;

&lt;p&gt;Patch &apos;7544p4.patch&apos; adds an encrypting protobuf WAL, currently missing support for dictionary compression but will add that after more testing. Another easy planned addition here is selective encryption of only the WALEdits for encrypted families.&lt;/p&gt;

&lt;p&gt;Added some unit tests, notably one that confirms if hbck is run on the secure enclave with access to key material (implicitly using the same configuration as for regionservers) it can handle encrypted HFiles.&lt;/p&gt;

&lt;p&gt;Also note that an ASL licensed open source accelerated JCE codec for AES in CTR mode is available at &lt;a href=&quot;https://github.com/intel-hadoop/project-diceros&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/intel-hadoop/project-diceros&lt;/a&gt; . Will be used if installed and hbase.crypto.algorithm.aes.provider=&quot;DC&quot;. This is not required for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7544&quot; title=&quot;Transparent table/CF encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7544&quot;&gt;&lt;del&gt;HBASE-7544&lt;/del&gt;&lt;/a&gt; but will substantially reduce the latency and CPU cost introduced by encryption compared to the default AES codec that ships with the Oracle/OpenJDK JRE. &lt;/p&gt;</comment>
                            <comment id="13799792" author="apurtell" created="Sat, 19 Oct 2013 05:29:34 +0000"  >&lt;p&gt;Attached patch &apos;7544.patch&apos; pulls it all together with a new integration test and bug fixes. Also see review &lt;a href=&quot;https://reviews.apache.org/r/14769/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/14769/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ve left the split out patches attached as they still illustrate how the changes are grouped.&lt;/p&gt;</comment>
                            <comment id="13804478" author="apurtell" created="Thu, 24 Oct 2013 18:07:09 +0000"  >&lt;p&gt;Posted updated patch to RB.&lt;/p&gt;

&lt;p&gt;Adds a missing license header.&lt;/p&gt;

&lt;p&gt;Adds shell support for testing this feature, new CF attributes &apos;ENCRYPTION&apos; (the algorithm name, as a string) and &apos;ENCRYPTION_KEY&apos; (a string that will be hashed into a 128 bit key).&lt;/p&gt;

&lt;p&gt;Adds caching of instantiated key providers. &lt;/p&gt;

&lt;p&gt;Adds LoadTestTool support for enabling transparent encryption on a CF.&lt;/p&gt;</comment>
                            <comment id="13805853" author="apurtell" created="Fri, 25 Oct 2013 23:59:14 +0000"  >&lt;p&gt;Changes in latest patch:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Support random HFile keying.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Check the results of key unwrapping with a CRC.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Introduce a new configuration value for holding an alternate master key alias. If the current master key fails to unwrap, and an alternate is available, try it. Allows for gradual master key rotation.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Plumb configuration down to the HFileV3 reader so we can avoid parsing the site file when creating a reader.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Update KeyProviderForTesting for verifying configuration plumbing.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Additional test cases and changes to existing test cases to confirm new functionality.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;No more changes are planned.&lt;/p&gt;</comment>
                            <comment id="13814561" author="apurtell" created="Wed, 6 Nov 2013 03:11:23 +0000"  >&lt;p&gt;Fix a findbug warning and kick off HadoopQA&lt;/p&gt;</comment>
                            <comment id="13814581" author="hadoopqa" created="Wed, 6 Nov 2013 03:50:41 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12612313/7544.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12612313/7544.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 82 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestStripeCompactor&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7742//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13814610" author="apurtell" created="Wed, 6 Nov 2013 05:15:09 +0000"  >&lt;p&gt;Remove an unwanted change in TestStripeCompactor and resubmit.&lt;/p&gt;

&lt;p&gt;Checked the FindBugs report, and locally prior to patch submission, and didn&apos;t see new items on account of this patch.&lt;/p&gt;</comment>
                            <comment id="13814687" author="hadoopqa" created="Wed, 6 Nov 2013 07:58:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12612322/7544.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12612322/7544.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 82 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7745//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13822040" author="apurtell" created="Thu, 14 Nov 2013 00:50:54 +0000"  >&lt;p&gt;Updated patch rebased on latest trunk, addressing review comments, also supporting alternate SecureRandom providers for AES easily via Configuration.&lt;/p&gt;</comment>
                            <comment id="13822225" author="hadoopqa" created="Thu, 14 Nov 2013 07:13:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12613751/7544.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12613751/7544.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 82 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7855//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13824356" author="anoop.hbase" created="Sat, 16 Nov 2013 03:15:58 +0000"  >&lt;p&gt;+1 for an updated patch addressing minor comments in RB. Great work Andy!&lt;/p&gt;</comment>
                            <comment id="13824713" author="apurtell" created="Sun, 17 Nov 2013 02:32:26 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;. The latest patch is up on a test cluster for performance and stability analysis. Looking good. Will commit and post the results of same later this week.&lt;/p&gt;</comment>
                            <comment id="13829781" author="ram_krish" created="Fri, 22 Nov 2013 08:08:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;&lt;br/&gt;
Added some small review comments on the RB.  &lt;br/&gt;
The WAL encryption is per CF or per WAL file?  Am asking this because we write the encryption info on the WAL header right?  Sorry if am missing something here.&lt;/p&gt;</comment>
                            <comment id="13829852" author="apurtell" created="Fri, 22 Nov 2013 10:17:27 +0000"  >&lt;p&gt;The WAL encryption is per WAL file. Selective edit encryption on a per family basis is future work. I haven&apos;t done it initially to keep things simple for the first cut. &lt;/p&gt;</comment>
                            <comment id="13831003" author="apurtell" created="Sun, 24 Nov 2013 18:32:17 +0000"  >&lt;p&gt;I have addressed the latest round of review comments, and rebased on latest trunk. Running unit tests now. Will submit for HadoopQA if the results are good locally and then commit after. Thanks Ram, Anoop, and Stack for your reviews. &lt;/p&gt;</comment>
                            <comment id="13831038" author="apurtell" created="Sun, 24 Nov 2013 20:22:40 +0000"  >&lt;p&gt;Client observed latency analysis, parallel minicluster load test&lt;/p&gt;</comment>
                            <comment id="13832120" author="apurtell" created="Tue, 26 Nov 2013 00:28:28 +0000"  >&lt;p&gt;Final patch. Passes all unit and integration tests locally. Submitting to HadoopQA.&lt;/p&gt;</comment>
                            <comment id="13832242" author="hadoopqa" created="Tue, 26 Nov 2013 03:10:18 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12615745/7544-final.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12615745/7544-final.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 99 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7992//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13832299" author="apurtell" created="Tue, 26 Nov 2013 04:21:41 +0000"  >&lt;p&gt;Checked the QA output. There were no test failures or zombies. No test timed out either though a couple executions overlapped. No test failures locally. Committing. Let&apos;s see what happens.&lt;/p&gt;</comment>
                            <comment id="13832308" author="apurtell" created="Tue, 26 Nov 2013 04:40:47 +0000"  >&lt;p&gt;I resolved this as fixed after commit but will of course reopen for addendums if Jenkins is unhappy. Running some trunks builds on ec2 Jenkins now also. &lt;/p&gt;</comment>
                            <comment id="13832372" author="apurtell" created="Tue, 26 Nov 2013 07:10:40 +0000"  >&lt;p&gt;Got a good run on Hadoop 2 here: &lt;a href=&quot;http://jenkins-public.iridiant.net/job/HBase-TRUNK-Hadoop-2/529/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://jenkins-public.iridiant.net/job/HBase-TRUNK-Hadoop-2/529/testReport/&lt;/a&gt;&lt;br/&gt;
Seems like a unrelated failure (TestLogRolling.testLogRollOnDatanodeDeath) on Hadoop 1 here: &lt;a href=&quot;http://jenkins-public.iridiant.net/job/HBase-TRUNK/535/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://jenkins-public.iridiant.net/job/HBase-TRUNK/535/testReport/&lt;/a&gt;&lt;br/&gt;
Running again on Hadoop 1 here: &lt;a href=&quot;http://jenkins-public.iridiant.net/job/HBase-TRUNK/536/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://jenkins-public.iridiant.net/job/HBase-TRUNK/536/testReport/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13832506" author="hudson" created="Tue, 26 Nov 2013 11:29:27 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #852 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/852/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/852/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7544&quot; title=&quot;Transparent table/CF encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7544&quot;&gt;&lt;del&gt;HBASE-7544&lt;/del&gt;&lt;/a&gt;. Transparent CF encryption (apurtell: rev 1545536)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/security/EncryptionUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/test/java/org/apache/hadoop/hbase/security&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/test/java/org/apache/hadoop/hbase/security/TestEncryptionUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Cipher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/CipherProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Context.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Decryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/DefaultCipherProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Encryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Encryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/KeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/KeyStoreKeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes/AES.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes/AESDecryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes/AESEncryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultDecodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultEncodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/KeyProviderForTesting.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestCipherProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyStoreKeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes/TestAES.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/EncryptionProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HFileProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/WALProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Encryption.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/HFile.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/WAL.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WriterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/CompressionTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/HFileCorruptionChecker.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HFilePerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/RandomSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFilePerformance.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionRandomKeying.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/HLogPerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestSecureHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestSecureWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsckEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-shell/src/main/ruby/hbase/admin.rb&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13832776" author="yuzhihong@gmail.com" created="Tue, 26 Nov 2013 17:23:53 +0000"  >&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7997/artifact/trunk/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7997/artifact/trunk/patchprocess/patchJavadocWarnings.txt&lt;/a&gt; :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Cipher.java:119: warning - @param argument &lt;span class=&quot;code-quote&quot;&gt;&quot;encryptor&quot;&lt;/span&gt; is not a parameter name.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13832921" author="apurtell" created="Tue, 26 Nov 2013 19:26:01 +0000"  >&lt;p&gt;Committed trivial javadoc typo fix. Attached as &apos;7544-addendum-1.patch&apos;. Thanks for spotting it Ted.&lt;/p&gt;</comment>
                            <comment id="13833185" author="hudson" created="Tue, 26 Nov 2013 22:52:08 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK #4699 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/4699/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/4699/&lt;/a&gt;)&lt;br/&gt;
Amend &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7544&quot; title=&quot;Transparent table/CF encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7544&quot;&gt;&lt;del&gt;HBASE-7544&lt;/del&gt;&lt;/a&gt;. Fix javadoc typo for Cipher#createDecryptionStream (apurtell: rev 1545790)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Cipher.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7544&quot; title=&quot;Transparent table/CF encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7544&quot;&gt;&lt;del&gt;HBASE-7544&lt;/del&gt;&lt;/a&gt;. Transparent CF encryption (apurtell: rev 1545536)&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/security/EncryptionUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/test/java/org/apache/hadoop/hbase/security&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-client/src/test/java/org/apache/hadoop/hbase/security/TestEncryptionUtil.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Cipher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/CipherProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Context.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Decryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/DefaultCipherProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Encryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Encryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/KeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/KeyStoreKeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes/AES.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes/AESDecryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/aes/AESEncryptor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultDecodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultEncodingContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/KeyProviderForTesting.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestCipherProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyStoreKeyProvider.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes/TestAES.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/EncryptionProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/HFileProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/WALProtos.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/Encryption.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/HFile.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-protocol/src/main/protobuf/WAL.proto&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/AbstractHFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV3.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WriterBase.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/CompressionTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/HFileCorruptionChecker.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HFilePerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/RandomSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFilePerformance.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileSeek.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionKeyRotation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEncryptionRandomKeying.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/HLogPerformanceEvaluation.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestSecureHLog.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestSecureWALReplay.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsckEncryption.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-shell/src/main/ruby/hbase/admin.rb&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13833725" author="hudson" created="Wed, 27 Nov 2013 12:17:50 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #853 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/853/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/853/&lt;/a&gt;)&lt;br/&gt;
Amend &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7544&quot; title=&quot;Transparent table/CF encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7544&quot;&gt;&lt;del&gt;HBASE-7544&lt;/del&gt;&lt;/a&gt;. Fix javadoc typo for Cipher#createDecryptionStream (apurtell: rev 1545790)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Cipher.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13969917" author="apurtell" created="Tue, 15 Apr 2014 19:06:08 +0000"  >&lt;p&gt;For an upcoming talk on security features I went back and looked at the impact of WAL encryption on more recent JVMs and after the changes to the WAL threading model that went in to 0.98+. I had to resort to a dual core mobile CPU with hyperthreading from ~2010 (with cpufreq locked at max) at the moment since Amazon HVMs don&apos;t give access to perf hw registers, but I plan to retest on bare Haswell server hardware. &lt;/p&gt;

&lt;p&gt;Three runs averaged, HLogPerformanceEvaluation -keySize 50 -valueSize 100 -threads 100 -iterations 1000000 ( -encryption AES )&lt;br/&gt;
VM flags: -XX:+UseG1GC -XX:+UseAES -XX:+UseAESIntrinsics (AES flags where supported)&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Test&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Throughput ops/sec&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Total cycles&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Insns per cycle&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Oracle Java 1.7.0_45-b18 - None&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;52658.302&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8878179986750&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Oracle Java 1.7.0_45-b18 - AES WAL encryption&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;48045.834&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9911748458387&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;OpenJDK 1.8.0_20-b09 - None&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;54874.125&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8662634367005&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;OpenJDK 1.8.0_20-b09 - AES WAL encryption&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50659.507&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9668111259270&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.61&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;What is interesting are the relative differences in later test cases from the first test case. Though there is more work per edit to do with encryption enabled by definition, for this microbenchmark the throughput of 8u20 with WAL encryption and AES intrinsics enabled is only ~4% off from 7u45 with no WAL encryption because of native code generation improvements on AES-NI capable hardware. Ops/sec measurements vary ~1.5% from run to run.&lt;/p&gt;</comment>
                            <comment id="15016177" author="lars_francke" created="Fri, 20 Nov 2015 11:54:14 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12682640">HBASE-10077</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12683080">HBASE-10095</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12682074">HBASE-10063</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12682073">HBASE-10062</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12682084">HBASE-10065</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12697279">HBASE-10613</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12681205">HBASE-10031</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12689909">HBASE-10388</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12669369">HBASE-9578</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12998812">HBASE-16463</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                            <outwardlinks description="requires">
                                        <issuelink>
            <issuekey id="12646149">HBASE-8496</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12615892" name="7544-addendum-1.patch" size="619" author="apurtell" created="Tue, 26 Nov 2013 19:30:14 +0000"/>
                            <attachment id="12615745" name="7544-final.patch" size="316783" author="apurtell" created="Tue, 26 Nov 2013 00:28:28 +0000"/>
                            <attachment id="12613751" name="7544.patch" size="320011" author="apurtell" created="Thu, 14 Nov 2013 00:50:54 +0000"/>
                            <attachment id="12612322" name="7544.patch" size="319424" author="apurtell" created="Wed, 6 Nov 2013 05:13:51 +0000"/>
                            <attachment id="12612313" name="7544.patch" size="320326" author="apurtell" created="Wed, 6 Nov 2013 03:11:08 +0000"/>
                            <attachment id="12610414" name="7544.patch" size="321347" author="apurtell" created="Fri, 25 Oct 2013 23:59:14 +0000"/>
                            <attachment id="12610120" name="7544.patch" size="272935" author="apurtell" created="Thu, 24 Oct 2013 18:07:09 +0000"/>
                            <attachment id="12609257" name="7544.patch" size="265150" author="apurtell" created="Sat, 19 Oct 2013 05:29:34 +0000"/>
                            <attachment id="12608358" name="7544p1.patch" size="82899" author="apurtell" created="Mon, 14 Oct 2013 21:58:23 +0000"/>
                            <attachment id="12603743" name="7544p1.patch" size="80979" author="apurtell" created="Wed, 18 Sep 2013 01:54:20 +0000"/>
                            <attachment id="12608359" name="7544p2.patch" size="43800" author="apurtell" created="Mon, 14 Oct 2013 21:58:23 +0000"/>
                            <attachment id="12603676" name="7544p2.patch" size="39030" author="apurtell" created="Tue, 17 Sep 2013 21:12:19 +0000"/>
                            <attachment id="12608360" name="7544p3.patch" size="95019" author="apurtell" created="Mon, 14 Oct 2013 21:58:23 +0000"/>
                            <attachment id="12603678" name="7544p3.patch" size="69829" author="apurtell" created="Tue, 17 Sep 2013 21:16:56 +0000"/>
                            <attachment id="12608361" name="7544p4.patch" size="54907" author="apurtell" created="Mon, 14 Oct 2013 21:58:23 +0000"/>
                            <attachment id="12603670" name="historical-7544.patch" size="265699" author="apurtell" created="Tue, 17 Sep 2013 21:00:47 +0000"/>
                            <attachment id="12603671" name="historical-7544.pdf" size="1109829" author="apurtell" created="Tue, 17 Sep 2013 21:00:47 +0000"/>
                            <attachment id="12603672" name="historical-shell.patch" size="4589" author="apurtell" created="Tue, 17 Sep 2013 21:00:47 +0000"/>
                            <attachment id="12615514" name="latency-single.7544.xlsx" size="124234" author="apurtell" created="Sun, 24 Nov 2013 20:22:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>19.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 11 Jan 2013 22:24:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>304016</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i17hn3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>251827</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This change introduces a transparent encryption feature for protecting HFile and WAL data at rest. For detailed information including configuration examples see the Security section of the HBase manual.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>