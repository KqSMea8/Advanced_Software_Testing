<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:54:27 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1551/HBASE-1551.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1551] HBase should manage multiple node ZooKeeper quorum</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1551</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I thought there was already a JIRA for this, but I cannot seem to find it.&lt;/p&gt;

&lt;p&gt;We need to manage multiple node ZooKeeper quorums (required for fully distributed option) in HBase to make things easier for users.&lt;/p&gt;

&lt;p&gt;Here&apos;s relevant IRC conversation with Ryan and Andrew:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Jun 17 18:14:39 &amp;lt;dj_ryan&amp;gt;	right now we include our client deps in hbase/lib
Jun 17 18:14:47 &amp;lt;dj_ryan&amp;gt;	so removing zookeeper would be problematic
Jun 17 18:14:56 &amp;lt;dj_ryan&amp;gt;	but hbase does put up a &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; zk quorum
Jun 17 18:15:02 &amp;lt;dj_ryan&amp;gt;	it just doesnt bother with q&amp;gt;1
Jun 17 18:15:05 &amp;lt;apurtell&amp;gt;	dj_ryan, nitay: agreed, so that&apos;s why i wonder about a &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; zk quorum managed by hbase
Jun 17 18:15:12 &amp;lt;apurtell&amp;gt;	q ~= 5
Jun 17 18:15:22 &amp;lt;dj_ryan&amp;gt;	so maybe we should ship tools to manage it
Jun 17 18:15:23 &amp;lt;apurtell&amp;gt;	&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; possible
Jun 17 18:15:29 &amp;lt;dj_ryan&amp;gt;	i can agree with that
Jun 17 18:15:39 &amp;lt;nitay&amp;gt;	apurtell, ok, i&apos;d be happy to bump the priority of hbase managing full cluster and work on that
Jun 17 18:15:47 *	iand (n=iand@205.158.58.226.ptr.us.xo.net) has joined #hbase
Jun 17 18:15:48 &amp;lt;apurtell&amp;gt;	nitay: that would be awesome
Jun 17 18:15:57 &amp;lt;apurtell&amp;gt;	then i can skip discussions with cloudera about including zk also
Jun 17 18:16:12 &amp;lt;apurtell&amp;gt;	and we can use some &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; ports that won&apos;t conflict with a typical zk install
Jun 17 18:16:15 &amp;lt;nitay&amp;gt;	but i also think that users should be able to point at existing clusters, so as &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; as your rpms are compatible, it should be fine
Jun 17 18:16:23 &amp;lt;nitay&amp;gt;	apurtell, isn&apos;t hadoop going to start using ZK
Jun 17 18:16:31 &amp;lt;apurtell&amp;gt;	nitay: agree, but &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the cloudera-autoconfig-rpm (and deb) &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;
Jun 17 18:16:34 &amp;lt;nitay&amp;gt;	the cloudera dude was working on using it &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; namenode whatnot like we &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; master
Jun 17 18:16:35 &amp;lt;dj_ryan&amp;gt;	so there are only 2 things
Jun 17 18:16:38 &amp;lt;dj_ryan&amp;gt;	- set up myids
Jun 17 18:16:38 &amp;lt;nitay&amp;gt;	what are they doing &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; that
Jun 17 18:16:40 &amp;lt;dj_ryan&amp;gt;	- start zk
Jun 17 18:16:42 &amp;lt;dj_ryan&amp;gt;	- stop zk
Jun 17 18:16:50 &amp;lt;dj_ryan&amp;gt;	we dont want to start/stop zk just when we are doing a cluster bounce
Jun 17 18:16:51 &amp;lt;nitay&amp;gt;	ye stupid myids
Jun 17 18:16:52 &amp;lt;dj_ryan&amp;gt;	you start it once
Jun 17 18:16:54 &amp;lt;dj_ryan&amp;gt;	and be done with ti
Jun 17 18:16:58 *	iand (n=iand@205.158.58.226.ptr.us.xo.net) has left #hbase (&lt;span class=&quot;code-quote&quot;&gt;&quot;Leaving.&quot;&lt;/span&gt;)
Jun 17 18:17:13 &amp;lt;apurtell&amp;gt;	dj_ryan: yes, start it once. that&apos;s what i &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt;. works fine through many hbase restarts...
Jun 17 18:17:28 &amp;lt;nitay&amp;gt;	so then we need a separate shell cmd or something to stop zk
Jun 17 18:17:35 &amp;lt;nitay&amp;gt;	and start on start-hbase &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not already running type thing
Jun 17 18:17:43 &amp;lt;dj_ryan&amp;gt;	yes
Jun 17 18:17:58 &amp;lt;nitay&amp;gt;	ok
Jun 17 18:18:19 &amp;lt;apurtell&amp;gt;	with quorum peers started on nodes in conf/regionservers, up to ~5 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; possible
Jun 17 18:18:37 &amp;lt;apurtell&amp;gt;	but what about zoo.cfg?
Jun 17 18:18:51 &amp;lt;nitay&amp;gt;	oh i was thinking of having separate conf/zookeepers
Jun 17 18:18:58 &amp;lt;apurtell&amp;gt;	nitay: even better
Jun 17 18:18:59 &amp;lt;nitay&amp;gt;	but we can use first five RS too
Jun 17 18:19:26 &amp;lt;nitay&amp;gt;	apurtell, yeah so really there wouldnt be a conf/zookeepers, i would rip out hostnames from zoo.cfg
Jun 17 18:19:38 &amp;lt;nitay&amp;gt;	or go the other way, generate zoo.cfg from conf/zookeepers
Jun 17 18:19:42 &amp;lt;nitay&amp;gt;	gotta &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; one or the other
Jun 17 18:19:49 &amp;lt;nitay&amp;gt;	dont want to have to edit both
Jun 17 18:19:54 &amp;lt;apurtell&amp;gt;	nitay: right
Jun 17 18:20:21 &amp;lt;apurtell&amp;gt;	well...
Jun 17 18:20:29 &amp;lt;nitay&amp;gt;	zoo.cfg has the right info right now, cause u need things other than just hostnames, i.e. client and quorum ports
Jun 17 18:20:31 &amp;lt;apurtell&amp;gt;	we can leave out servers from our &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; zoo.cfg
Jun 17 18:20:39 &amp;lt;apurtell&amp;gt;	and consider a conf/zookeepers
Jun 17 18:20:47 &amp;lt;dj_ryan&amp;gt;	i call it conf/zoos
Jun 17 18:20:54 &amp;lt;dj_ryan&amp;gt;	in my zookeeper config
Jun 17 18:20:54 &amp;lt;dj_ryan&amp;gt;	dir
Jun 17 18:20:57 &amp;lt;nitay&amp;gt;	and then have our parsing of zoo.cfg insert them
Jun 17 18:21:08 &amp;lt;nitay&amp;gt;	cause right now its all off java Properties anyways
Jun 17 18:21:12 &amp;lt;apurtell&amp;gt;	and let the zk wrapper parse the files &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; they exist and otherwise build the list of quorum peers like it does already
Jun 17 18:21:34 &amp;lt;apurtell&amp;gt;	so someone could edit either and it would dtrt
Jun 17 18:21:48 &amp;lt;nitay&amp;gt;	apurtell, yeah, makes sense
Jun 17 18:21:58 &amp;lt;nitay&amp;gt;	we can discuss getting rid of zoo.cfg completely
Jun 17 18:22:12 &amp;lt;nitay&amp;gt;	put it all in XML and just create a Properties &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ZK off the right props
Jun 17 18:22:14 &amp;lt;apurtell&amp;gt;	&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; my purposes, i just need some files available &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a post install script to lay down a &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; hbase cluster config based on what it discovers about the hadoop installation
Jun 17 18:23:56 &amp;lt;apurtell&amp;gt;	then i need to hook sysvinit and use chkconfig to enable/disable services on the cluster nodes according to their roles defined by hadoop/conf/masters and hadoop/conf/regionservers
Jun 17 18:24:13 &amp;lt;apurtell&amp;gt;	so we put the hmaster on the namenode
Jun 17 18:24:17 &amp;lt;apurtell&amp;gt;	and the region servers on the datanodes
Jun 17 18:24:35 &amp;lt;apurtell&amp;gt;	hadoop/conf/slaves i mean
Jun 17 18:24:44 &amp;lt;apurtell&amp;gt;	and pick N hosts out of slaves to host the zk quorum
Jun 17 18:24:50 &amp;lt;apurtell&amp;gt;	make sense?
Jun 17 18:25:33 &amp;lt;nitay&amp;gt;	yes i think so, and u&apos;ll be auto generating the hbase configs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; what servers run what then?
Jun 17 18:25:50 &amp;lt;apurtell&amp;gt;	nitay: yes
Jun 17 18:25:51 &amp;lt;nitay&amp;gt;	which is why a simple line by line conf/zookeepers type file is clean and easy
Jun 17 18:25:57 &amp;lt;apurtell&amp;gt;	nitay: agree
Jun 17 18:25:59 &amp;lt;apurtell&amp;gt;	so i think my initial question has been answered, hbase will manage a &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; zk ensemble
Jun 17 18:26:07 &amp;lt;apurtell&amp;gt;	... somehow
Jun 17 18:26:10 &amp;lt;nitay&amp;gt;	right :)
Jun 17 18:26:15 &amp;lt;apurtell&amp;gt;	ok, thanks
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12428414">HBASE-1551</key>
            <summary>HBase should manage multiple node ZooKeeper quorum</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nitay">Nitay Joffe</assignee>
                                    <reporter username="nitay">Nitay Joffe</reporter>
                        <labels>
                    </labels>
                <created>Fri, 19 Jun 2009 20:46:37 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:45 +0000</updated>
                            <resolved>Thu, 9 Jul 2009 19:05:45 +0000</resolved>
                                                    <fixVersion>0.20.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>3</watches>
                                                                                                            <comments>
                            <comment id="12722005" author="nitay" created="Fri, 19 Jun 2009 20:59:06 +0000"  >&lt;p&gt;This is a bit trickier than a simple set of bash scripts because we need to parse zoo.cfg (and put in values from hbase-site.xml).&lt;br/&gt;
I&apos;m writing a java tool to do this that the shell scripts can call to. Let me know if you guys have other ideas. &lt;/p&gt;</comment>
                            <comment id="12722020" author="apurtell" created="Fri, 19 Jun 2009 21:21:27 +0000"  >&lt;p&gt;@Nitay: We can still do this privately for convenience of users who want HBase to manage ZK on their behalf, but for any Cloudera packaging it has been decided we will unbundle ZK and just pick up the configuration produced by their ZK package. Otherwise I think this issue could be resolved as Later. &lt;/p&gt;</comment>
                            <comment id="12722024" author="nitay" created="Fri, 19 Jun 2009 21:28:54 +0000"  >&lt;p&gt;Right, thanks for the info. I&apos;ll keep playing with this. If nothing else it will get rid of my own scripts to do such things &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                            <comment id="12726257" author="nitay" created="Wed, 1 Jul 2009 22:57:33 +0000"  >&lt;p&gt;Here is first stab at this. It could probably use some cleaning, but should show how things will end up working.&lt;/p&gt;

&lt;p&gt;The idea is to have bin/hbase-zookeepers.sh (which is like hbase-daemons.sh for zookeeper) call out to ZKServerTool which reads conf/zookeepers and conf/zoo.cfg to get the list of ZooKeeper servers in the quorum. bin/hbase-zookeepers.sh then starts an HQuorumPeer on each of those servers. The HQuorumPeer finds out which server it is in the list and writes the myid file.&lt;/p&gt;

&lt;p&gt;Note that I had to make some minor changes to ZooKeeper. I&apos;ve attached the edits to their code along with a Jar that contains the edited version.&lt;/p&gt;

&lt;p&gt;There is a case missing that I still need to work out. The HQuorumPeer finds out its myid by comparing its hostname to zoo.cfg, but it needs to read conf/zookeepers too.&lt;/p&gt;

&lt;p&gt;As you can probably tell, this is all a big huge mess. While working on it, I was thinking what if we just got rid of zoo.cfg all together. ZooKeeper out of the box can&apos;t read it anyways because we are injecting things from hbase-site.xml. I think we can put all of the ZK config options in hbase-site.xml and put the list of quorum servers in conf/zookeepers. Anyone who wants to find the quorum would assemble the host:port list from conf/zookeepers and hbase-site.xml.&lt;/p&gt;

&lt;p&gt;I chatted about this on IRC with Chris Wensel. He makes a good point that us shipping conf/zookeepers doesn&apos;t seem right and we shoud write the ZK quorum host:port property to hbase-site.xml. I agree with him, but want to prevent putting it in two places.&lt;/p&gt;

&lt;p&gt;Andrew, I&apos;m interested in your thoughts on the matter as I know you need this JIRA for your stuff.&lt;/p&gt;

&lt;p&gt;Here&apos;s the relevant conversation:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[15:28]  &amp;lt;St^Ack&amp;gt; nitay: what about max connections and stuff like that?
[15:29]  &amp;lt;nitay&amp;gt; St^Ack, i&apos;d move it all to hbase-site.xml
[15:29]  &amp;lt;nitay&amp;gt; generate a java &lt;span class=&quot;code-quote&quot;&gt;&quot;Properties&quot;&lt;/span&gt; from the right options
[15:29]  &amp;lt;nitay&amp;gt; and feed that to ZK
[15:29]  &amp;lt;nitay&amp;gt; right now its zoo.cfg =&amp;gt; Properties =&amp;gt; ZK Config =&amp;gt; ZK
[15:29]  &amp;lt;cwensel&amp;gt; nitay: i think you only need quorum servers.. the &lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt; isn&apos;t used by the client (could be wrong)
[15:29]  &amp;lt;nitay&amp;gt; instead it&apos;d be HBaseConfiguration =&amp;gt; ZK Properties =&amp;gt; ZK Config...
[15:30]  &amp;lt;nitay&amp;gt; cwensel, clientPort and some of the tick stuff i think may be used
[15:31]  &amp;lt;nitay&amp;gt; i have the tool to read conf/zookeepers or conf/zoo.cfg &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server list
[15:31]  &amp;lt;nitay&amp;gt; but its just ugly
[15:31]  &amp;lt;nitay&amp;gt; having ot &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; that
[15:31]  &amp;lt;nitay&amp;gt; and then in hbase we&apos;re gonna have to inject the server list from conf/zookeepers into conf/zoo.cfg
[15:31]  &amp;lt;nitay&amp;gt; seems ugly to me
[15:31]  &amp;lt;cwensel&amp;gt; nitay: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, but you are parsing the servers and adding the ports.. should just use a client string
[15:31]  &amp;lt;cwensel&amp;gt; you can keep zoo.cfg, just don&apos;t use it &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the client side
[15:31]  &amp;lt;cwensel&amp;gt; make it optional &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; hbase is managing the zk instance
[15:32]  &amp;lt;cwensel&amp;gt; allow it to be removed &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there is a tandem zk cluster
[15:32]  &amp;lt;nitay&amp;gt; ye that works, it&apos;d be much cleaner &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; client just write conf/zookeepers and we put it together with ports
[15:32]  &amp;lt;nitay&amp;gt; that part is trivial
[15:33]  &amp;lt;nitay&amp;gt; or directly puts in host:port string as u&apos;re saying
[15:33]  &amp;lt;cwensel&amp;gt; just force the user to put the string of servers in hbase-site.xml
[15:33]  &amp;lt;cwensel&amp;gt; but keep zoo.cfg to reduce friction &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; local test hbase servers
[15:33]  &amp;lt;nitay&amp;gt; well then its in two places, there and conf/zookeepers
[15:33]  &amp;lt;nitay&amp;gt; we want conf/zookeepers no matter what
[15:33]  &amp;lt;cwensel&amp;gt; why?
[15:33]  &amp;lt;nitay&amp;gt; b/c its consistent with conf/regionservers etc
[15:34]  &amp;lt;nitay&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; users that have hbase managing zk
[15:34]  &amp;lt;cwensel&amp;gt; but those are only used by the base scripts, right?
[15:34]  &amp;lt;nitay&amp;gt; yes
[15:34]  &amp;lt;cwensel&amp;gt; not read by the config files
[15:34]  &amp;lt;nitay&amp;gt; well yes and no
[15:34]  &amp;lt;cwensel&amp;gt; i would create a &apos;client&apos; property that points to the zk servers.. 
[15:34]  &amp;lt;nitay&amp;gt; im proposing they would be, bsaically im just saying i dont want &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; information in more than one place
[15:35]  &amp;lt;cwensel&amp;gt; i understand
[15:35]  &amp;lt;nitay&amp;gt; right now its going to be in zoo.cfg and conf/zookeepers
[15:35]  &amp;lt;nitay&amp;gt; u&apos;re saying it&apos;ll be in hbase-site.xml and conf/zookeepers
[15:35]  &amp;lt;cwensel&amp;gt; but hbase config shouldn&apos;t read zookeepers
[15:35]  &amp;lt;nitay&amp;gt; why not?
[15:35]  &amp;lt;cwensel&amp;gt; i wouldn&apos;t have zookeepers.. hbase managing a zk cluster is a convenience.. unlikely to happen in the wild in production
[15:35]  &amp;lt;nitay&amp;gt; hmm i dont necessarily agree
[15:36]  &amp;lt;nitay&amp;gt; i think there&apos;s lots of users that will have no idea what zk is and just want it to work
[15:36]  &amp;lt;cwensel&amp;gt; the only thing hadoop reads are .xml (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; and site) files
[15:36]  &amp;lt;cwensel&amp;gt; don&apos;t couple bash script convenience to the hbase config objec
[15:36]  &amp;lt;cwensel&amp;gt; agreed on it just working..
[15:37]  &amp;lt;cwensel&amp;gt; but it will be a local psuedo cluster with only on zk instance
[15:37]  &amp;lt;nitay&amp;gt; i see your point, but is there a way we can get best of both worlds, no coupling, yet information in one place
[15:37]  &amp;lt;nitay&amp;gt; sure in local pseudo mode conf/zookeepers will be just &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost&quot;&lt;/span&gt;
[15:37]  &amp;lt;cwensel&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; will be localhost:2181
[15:37]  &amp;lt;cwensel&amp;gt; in both xml and cfg
[15:37]  &amp;lt;cwensel&amp;gt; should work out of the box that way
[15:38]  &amp;lt;cwensel&amp;gt; unless you want to write scripts that launch tandem zk instances across the cluster (thinking that&apos;s out of scope) i would make all the zk stuff optional
[15:38]  &amp;lt;nitay&amp;gt; yes again the issue is when user wants to go fully dist they have to manually write conf/zookeepers (simple) and &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; no apparent reason also to hbase-site.xml
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12726267" author="apurtell" created="Wed, 1 Jul 2009 23:23:43 +0000"  >&lt;p&gt;Based on my understanding, the Cloudera ZK install will put a working zoo.cfg in /etc/zookeeper/conf/zoo.cfg. For the first pass, this will bring up a single-node ensemble only. HBase will need to append the ensemble details to zoo.cfg. Can be a post install step executed by the admin. Therefore we will also need to create the myid files. They have not settled on the precise location of where the data files will be located yet. &lt;/p&gt;

&lt;p&gt;On a Cloudera distro ZK service will be a set of external daemons from the HBase perspective, managed separately. &lt;/p&gt;</comment>
                            <comment id="12726270" author="cwensel" created="Wed, 1 Jul 2009 23:31:59 +0000"  >&lt;p&gt;there are three issues here:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;hbase as client to zk&lt;/li&gt;
	&lt;li&gt;deployment of zk cluster&lt;/li&gt;
	&lt;li&gt;zk server configuration&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;it is a hard requirement that hbase know who its zk quorum is as a consumer of zk.&lt;/p&gt;

&lt;p&gt;it is optional that hbase scripts manage a zk cluster (though a cluster is required somewhere). &lt;/p&gt;

&lt;p&gt;and if hbase is managing the zk cluster, zk finds its zoo.cfg&lt;/p&gt;

&lt;p&gt;it would be &quot;nice&quot; (if not awkward) if hbase zk client looked for zoo.cfg if there wasn&apos;t already list of quorum servers in hbase-site.xml&lt;/p&gt;

&lt;p&gt;if hbase took responsibility for deploying/managing zk servers across a cluster, then bin &apos;conf/zookeepers&apos; should be maintained. should be noted zk is very ec2 unfriendly, having to know all parties at provisioning. leads us to want a standalone zk cluster shared across tandem clusters.&lt;/p&gt;

&lt;p&gt;i opened hbase-1600 so we can have multiple hbase client instances talking to distinct hbase clusters from within a single jvm.&lt;/p&gt;

&lt;p&gt;also thinking that turning on/off zk management by hbase should be a bash/env config, not a hbase-site.xml config, hbase.cluster.distributed&lt;/p&gt;</comment>
                            <comment id="12726294" author="apurtell" created="Thu, 2 Jul 2009 01:34:11 +0000"  >&lt;p&gt;Anybody know offhand of ZK jira(s) for dynamic quorum peer discovery and addition/removal? &lt;/p&gt;</comment>
                            <comment id="12726311" author="stack" created="Thu, 2 Jul 2009 03:52:12 +0000"  >&lt;p&gt;@nitay you have jruby available so if you wanted to write parse in ruby, its available to you.&lt;/p&gt;

&lt;p&gt;@nitay, in HBaseConfiguration, there is &lt;a href=&quot;http://hadoop.apache.org/core/docs/current/api/org/apache/hadoop/conf/Configuration.html#iterator(&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/core/docs/current/api/org/apache/hadoop/conf/Configuration.html#iterator(&lt;/a&gt;).  You could iterate all properties in the Configuration and use any that have a hbase.zookeeper prefix writing configuration for zk.  This would give you a non-hardcoded system for adding zk config. to hbase-site.xml&lt;/p&gt;

&lt;p&gt;@nitay, if we did something like above, would it be possible for a client to do HBaseConfiguration.set(&quot;hbase.zookeeper.... quorum&quot;, blah, blah) and THEN connect to zk quorum or would that be too late?  When does client try to connect to quorum?  On class loading or when you create a HTable instance?&lt;/p&gt;

&lt;p&gt;.bq also thinking that turning on/off zk management by hbase should be a bash/env config, not a hbase-site.xml config, hbase.cluster.distributed&lt;/p&gt;

&lt;p&gt;This seems like a good idea&lt;/p&gt;</comment>
                            <comment id="12726349" author="nitay" created="Thu, 2 Jul 2009 06:33:39 +0000"  >&lt;p&gt;@andrew, see &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-107&quot; title=&quot;Allow dynamic changes to server cluster membership&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-107&quot;&gt;&lt;del&gt;ZOOKEEPER-107&lt;/del&gt;&lt;/a&gt; and possibly &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-29&quot; title=&quot;Flexible quorums&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-29&quot;&gt;&lt;del&gt;ZOOKEEPER-29&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;@stack/cwensel, hbase management of ZK is in a bash/env thing. There&apos;s a setting in hbase-env.sh called HBASE_MANAGES_ZK which toggles whether HBase will start/stop ZK.&lt;/p&gt;

&lt;p&gt;@stack/andrew,cwensel, Yes the iterator thing along the line of what I was thinking of.&lt;br/&gt;
Here&apos;s my current thinking:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Move all of the ZooKeeper config paraments into hbase-*.xml using zookeeper.property.KEY = VALUE.&lt;/li&gt;
	&lt;li&gt;Add a special property for the list of quorum servers, say zookeeper.quorum. This option can default to &quot;localhost&quot;.&lt;/li&gt;
	&lt;li&gt;If there is a zoo.cfg present in the classpath, use its data above the zookeeper.property.KEY options.&lt;/li&gt;
	&lt;li&gt;When we need to instantiate something to talk to ZooKeeper, we simply create a new HBaseConfiguration and call some method on it e.g. toZooKeeperProperties().&lt;br/&gt;
This method will iterate through the zookeeper.property.KEY and turn each into the appropriate ZooKeeper configurations (i.e. KEY=VALUE). It will generate&lt;br/&gt;
the server.X property from the zookeeper.quorum configuration option. As mentioned above, if there is a zoo.cfg in the classpath, overwrite the data with its configuration.&lt;br/&gt;
This will return a Properties object that can be used to construct the appropriate ZooKeeper config and start/talk to their servers.&lt;/li&gt;
	&lt;li&gt;For start/stop management of full ZK quorum cluster, use something like my ZKServerTool in the patch (modified of course) to do the parsing mentioned above and turn it&lt;br/&gt;
into a simple line-by-line list of quorum servers. As I do in this patch, the bin/zookeepers.sh can then simply call bin/hbase o.a.h.h.z.ZKServerTool to get the list of hosts.&lt;br/&gt;
If you want something like a conf/zookeepers you can simply run ZKServerTool yourself.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The benefits from all this are:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;One place for all ZK configuration. No duplicate setting of parameters.&lt;/li&gt;
	&lt;li&gt;No more nasty zoo.cfg. Give the user what they&apos;re already used to, a single XML config file.&lt;/li&gt;
	&lt;li&gt;New user only need edit zookeeper.quorum to get full cluster.&lt;/li&gt;
	&lt;li&gt;Programmable control of what ZK one is talking to.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;That&apos;s all I can think of for now.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="12726525" author="cwensel" created="Thu, 2 Jul 2009 16:06:24 +0000"  >
&lt;blockquote&gt;&lt;p&gt;@stack/cwensel, hbase management of ZK is in a bash/env thing. There&apos;s a setting in hbase-env.sh called HBASE_MANAGES_ZK which toggles whether HBase will start/stop ZK.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;does this mean we are storing the value in two places?&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;The mode the cluster will be in. Possible values are
    false: standalone and pseudo-distributed setups with managed Zookeeper
    true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
  &amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12726574" author="nitay" created="Thu, 2 Jul 2009 17:41:28 +0000"  >&lt;p&gt;No. The are separate things. hbase.cluster.distributed is for switching between local/pseudo mode and distributed.&lt;br/&gt;
It is the same as what setting hbase.master to &quot;local&quot; used to be.&lt;br/&gt;
HBASE_MANAGES_ZK is for HBase to start/stop ZK.&lt;/p&gt;</comment>
                            <comment id="12726617" author="stack" created="Thu, 2 Jul 2009 18:40:42 +0000"  >&lt;p&gt;@nitay on hbase-env.sh, yeah, I was thinking the value in cwensel&apos;s point was that we have distributed spanning two configs.  You cleared up my misconception.&lt;/p&gt;

&lt;p&gt;@nitay, I think you need to keep the hbase zookeeper config inside of an hbase namespace.  The Hadoop Configuation system is a floozy.  It will go with anyone who calls load resource on it pulling in their properties.  I could see that out on a MR task, the Configuration could have all kinds of pollution in it.  Would suggest an hbase prefix &amp;#8211; hbase.zookeeper prefix?&lt;/p&gt;

&lt;p&gt;@nitay on &quot;if zoo.cfg in the CLASSPATH&quot;, that might work.  We might want to try narrow the places we look on the CLASSPATH.  But lets start open and narrow later (we probably want this to be open as possible at mo. until we learn more about the cloudera config.)&lt;/p&gt;

&lt;p&gt;@nitay on toZooKeeperProperties, do we have to expose that?  Can&apos;t we just pass a HBaseConfiguation to the HBase ZK Wrapper (I&apos;m not up on latest dev here so this might be an off suggestion)&lt;/p&gt;
</comment>
                            <comment id="12726619" author="nitay" created="Thu, 2 Jul 2009 18:42:56 +0000"  >&lt;p&gt;@stack, Okay, all the points you make are good and easily implementable. I&apos;ll open a separate JIRA for this and link this one.&lt;/p&gt;</comment>
                            <comment id="12726654" author="cwensel" created="Thu, 2 Jul 2009 19:59:19 +0000"  >&lt;p&gt;I keep coming back to whether or not hbase should &apos;manage&apos; a zk cluster as anything more than a getting started convenience.&lt;/p&gt;

&lt;p&gt;as a &lt;em&gt;convenience&lt;/em&gt;, scripts should boot a tandem zk instance so hbase will run.&lt;/p&gt;

&lt;p&gt;and by default, the hbase client should look at localhost for the zk quorum server (singular)&lt;/p&gt;

&lt;p&gt;and the env should state whether or not a simple zk instance should be started on &apos;start&apos; and stopped on &apos;stop&apos;, true by default&lt;/p&gt;

&lt;p&gt;but i&apos;m wondering if hbase&apos;s responsibility for zk stops there since it is not embedded into hbase, but is external.&lt;/p&gt;

&lt;p&gt;by stopping there, zk server params don&apos;t leak into hbase config. we still have zoo.cfg, but only zk server side cares.&lt;/p&gt;

&lt;p&gt;that is, by changing an env prop (manage zk or not), i invalidate the need for a whole set of hbase-default.xml properties for that deployment. i&apos;m thinking hbase props should be valid regardless of the topology/env, otherwise they aren&apos;t hbase properties but env properties (for the most part).&lt;/p&gt;

&lt;p&gt;to illustrate a bit..&lt;/p&gt;

&lt;p&gt;initially in ec2, i&apos;ll probably only have one master, and so only one zk instance. under ec2 we provision/boot the master first to get its name (will be tricky still to bootstrap zk here). slaves are then booted with the master name embedded in the *-site.xml files. this pattern works great for developers that need a ephemeral cluster, and a &apos;good enough&apos; production like cluster (to support batch jobs). &lt;/p&gt;

&lt;p&gt;long term, we will need to provision N hbase masters against a bespoke standalone/independent zk cluster. the zk cluster will need to be provisioned first, then zk configured so they know the quorum.&lt;/p&gt;

&lt;p&gt;in these scenarios, we never touch start-hbase/stop-hbase or any high level bash scripts. just the core scripts to start individual services.&lt;/p&gt;
</comment>
                            <comment id="12726656" author="cwensel" created="Thu, 2 Jul 2009 20:06:44 +0000"  >&lt;p&gt;this begs the question can a zk cluster be shared across multiple hbase clusters.&lt;/p&gt;</comment>
                            <comment id="12726658" author="nitay" created="Thu, 2 Jul 2009 20:14:32 +0000"  >&lt;p&gt;As long as both can talk to it, yes it can. All you have to change is the property zookeeper.znode.parent, which is the base directory where HBase stores its data in ZooKeeper.&lt;br/&gt;
It defaults to &quot;/hbase&quot;. You can set one cluster to e.g. &quot;/hbase1&quot;, and the other to &quot;/hbase2&quot; and they will not interfere with each other.&lt;/p&gt;</comment>
                            <comment id="12727130" author="stack" created="Fri, 3 Jul 2009 20:39:54 +0000"  >&lt;p&gt;.bq ...but i&apos;m wondering if hbase&apos;s responsibility for zk stops there since it is not embedded into hbase, but is external.&lt;/p&gt;

&lt;p&gt;Yeah, we wondered same and tried to do it that way initially.  But we then fellas wanted to programmatically set zk cluster location and zoo.cfg was becoming a pain.  This patch probably err&apos;s on providing too much zk management but I think it fair to say we are here because nitay and j-d experiments up to this have not been satisfactory (is that fair Nitay/J-D?)&lt;/p&gt;</comment>
                            <comment id="12727132" author="stack" created="Fri, 3 Jul 2009 20:52:39 +0000"  >&lt;p&gt;Nitay, do we really need bin/hbase-zookeepers?  We can&apos;t make bin/hbase-daemons.sh work switching off whats been asked to start?  There is little difference in the scripts (especially when you don&apos;t change usage string &amp;#8211; smile).&lt;/p&gt;

&lt;p&gt;Fix usage in zookeepers.sh (says zookeeper instead of zookeepers).&lt;/p&gt;

&lt;p&gt;In HQP change name of method from &apos;run&apos; to something else (because &apos;run&apos; usually associated with Thread).  Same in ZKST.&lt;/p&gt;

&lt;p&gt;Patch has binary for the new zk jar.  Maybe leave out in future.&lt;/p&gt;

&lt;p&gt;Otherwise, patch looks great.  Lacks documentation but that&apos;ll be in different issue?&lt;/p&gt;

&lt;p&gt;What should I test?&lt;/p&gt;






</comment>
                            <comment id="12729002" author="nitay" created="Thu, 9 Jul 2009 01:58:20 +0000"  >&lt;p&gt;Second version of patch.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Removed hbase-zookeepers.sh as Stack suggested and replaced with switch in hbase-daemons.sh.&lt;/li&gt;
	&lt;li&gt;Fix method names.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll open a JIRA for documenting ZooKeeper management in HBase.&lt;/p&gt;

&lt;p&gt;I tested starting/stopping full ZK cluster, and using existing ZK quorum. I tested it with configuration in hbase-site.xml, and in zoo.cfg. Can&apos;t think of anything else to test currently.&lt;/p&gt;</comment>
                            <comment id="12729064" author="stack" created="Thu, 9 Jul 2009 06:06:45 +0000"  >&lt;p&gt;@nitay&lt;/p&gt;

&lt;p&gt;Talks about HADOOP env variables up in the comments but down in code in uses HBASE ones (in zookeepers.sh).&lt;/p&gt;

&lt;p&gt;So no file with list of hosts to start zookeeper on?  Just read from hbase-site.xml?&lt;/p&gt;

&lt;p&gt;Looks good Nitay.  Didn&apos;t test.  Will try it in morning.&lt;/p&gt;</comment>
                            <comment id="12729383" author="stack" created="Thu, 9 Jul 2009 18:58:34 +0000"  >&lt;p&gt;Go ahead commit Nitay.  We can file issues with it as we find them.  I don&apos;t have resources to hand to test this at mo.&lt;/p&gt;</comment>
                            <comment id="12729385" author="nitay" created="Thu, 9 Jul 2009 19:06:56 +0000"  >&lt;p&gt;Committed. Changed HADOOP stuff to HBASE.&lt;/p&gt;

&lt;p&gt;List of ZooKeeper servers comes from zoo.cfg, if there is one in the classpath, or hbase-site.xml.&lt;/p&gt;

&lt;p&gt;If you want a list of ZooKeeper hosts you can run bin/hbase org.apache.hadoop.hbase.zookeeper.ZKServerTool.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12412947" name="hbase-1551-v2.patch" size="16862" author="nitay" created="Thu, 9 Jul 2009 01:58:20 +0000"/>
                            <attachment id="12412334" name="hbase-1551.patch" size="1358143" author="nitay" created="Wed, 1 Jul 2009 22:57:33 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12429414">HBASE-1606</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 19 Jun 2009 21:21:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32188</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 24 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hdx3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99517</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>