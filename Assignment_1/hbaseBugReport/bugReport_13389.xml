<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:42:49 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-13389/HBASE-13389.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-13389] [REGRESSION] HBASE-12600 undoes skip-mvcc parse optimizations</title>
                <link>https://issues.apache.org/jira/browse/HBASE-13389</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; moved the edit sequenceid from tags to instead exploit the mvcc/sequenceid slot in a key. Now Cells near-always have an associated mvcc/sequenceid where previous it was rare or the mvcc was kept up at the file level. This is sort of how it should be many of us would argue but as a side-effect of this change, read-time optimizations that helped speed scans were undone by this change.&lt;/p&gt;

&lt;p&gt;In this issue, lets see if we can get the optimizations back &amp;#8211; or just remove the optimizations altogether.&lt;/p&gt;

&lt;p&gt;The parse of mvcc/sequenceid is expensive. It was noticed over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13291&quot; title=&quot;Lift the scan ceiling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13291&quot;&gt;HBASE-13291&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The optimizations undone by this changes are (to quote the optimizer himself, Mr &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Looks like this undoes all of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9751&quot; title=&quot;Excessive  readpoints checks in StoreFileScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9751&quot;&gt;&lt;del&gt;HBASE-9751&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8151&quot; title=&quot;Decode memstoreTS in HFileReaderV2 only when necessary&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8151&quot;&gt;&lt;del&gt;HBASE-8151&lt;/del&gt;&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8166&quot; title=&quot;Avoid writing the memstoreTS into HFiles when possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8166&quot;&gt;&lt;del&gt;HBASE-8166&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
We&apos;re always storing the mvcc readpoints, and we never compare them against the actual smallestReadpoint, and hence we&apos;re always performing all the checks, tests, and comparisons that these jiras removed in addition to actually storing the data - which with up to 8 bytes per Cell is not trivial.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is the &apos;breaking&apos; change: &lt;a href=&quot;https://github.com/apache/hbase/commit/2c280e62530777ee43e6148fd6fcf6dac62881c0#diff-07c7ac0a9179cedff02112489a20157fR96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hbase/commit/2c280e62530777ee43e6148fd6fcf6dac62881c0#diff-07c7ac0a9179cedff02112489a20157fR96&lt;/a&gt;&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12787829">HBASE-13389</key>
            <summary>[REGRESSION] HBASE-12600 undoes skip-mvcc parse optimizations</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12783345">HBASE-13291</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 Apr 2015 21:48:59 +0000</created>
                <updated>Tue, 26 Jan 2016 05:05:02 +0000</updated>
                                                                            <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                <comments>
                            <comment id="14394111" author="jeffreyz" created="Fri, 3 Apr 2015 06:05:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; The performance regression is due to we keep mvcc values longer(&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11315&quot; title=&quot;Keeping MVCC for configurable longer time &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11315&quot;&gt;&lt;del&gt;HBASE-11315&lt;/del&gt;&lt;/a&gt;) so comes the later change &lt;a href=&quot;https://github.com/apache/hbase/commit/2c280e62530777ee43e6148fd6fcf6dac62881c0#diff-07c7ac0a9179cedff02112489a20157fR96&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hbase/commit/2c280e62530777ee43e6148fd6fcf6dac62881c0#diff-07c7ac0a9179cedff02112489a20157fR96&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;I&apos;m surprised the extra mvcc value caused so much perf regression. Here is the code which calculates minSeqId to keep in file Compactor.java during compaction. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-comment&quot;&gt;// when isAllFiles is &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, all files are compacted so we can calculate the smallest 
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// MVCC value to keep
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(fd.minSeqIdToKeep &amp;lt; file.getMaxMemstoreTS()) {
          fd.minSeqIdToKeep = file.getMaxMemstoreTS();
        }
....
        &lt;span class=&quot;code-comment&quot;&gt;// output to writer:
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Cell c : cells) {
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (cleanSeqId &amp;amp;&amp;amp; c.getSequenceId() &amp;lt;= smallestReadPoint) {
            CellUtil.setSequenceId(c, 0);
          }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14394114" author="jeffreyz" created="Fri, 3 Apr 2015 06:09:24 +0000"  >&lt;p&gt;Should we keep the time period configuration shorter or revert all related changes? Thanks.&lt;/p&gt;</comment>
                            <comment id="14394693" author="stack" created="Fri, 3 Apr 2015 17:01:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m surprised the extra mvcc value caused so much perf regression. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, weirdly I see it costing us a bunch. Will report better over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13291&quot; title=&quot;Lift the scan ceiling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13291&quot;&gt;HBASE-13291&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should we keep the time period configuration shorter or revert all related changes? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&apos;ll figure it &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Thanks for the input.&lt;/p&gt;</comment>
                            <comment id="14395844" author="lhofhansl" created="Sat, 4 Apr 2015 18:00:26 +0000"  >&lt;p&gt;It turns out that the optimization in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8151&quot; title=&quot;Decode memstoreTS in HFileReaderV2 only when necessary&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8151&quot;&gt;&lt;del&gt;HBASE-8151&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9751&quot; title=&quot;Excessive  readpoints checks in StoreFileScanner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9751&quot;&gt;&lt;del&gt;HBASE-9751&lt;/del&gt;&lt;/a&gt; still works, but only after 6 days, when compactions allow setting mvcc readpoints to 0.&lt;/p&gt;

&lt;p&gt;I think we can get the optimization for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8166&quot; title=&quot;Avoid writing the memstoreTS into HFiles when possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8166&quot;&gt;&lt;del&gt;HBASE-8166&lt;/del&gt;&lt;/a&gt; and back and still have &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; correctly, if we replace this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
- &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; needMvcc = fd.maxMVCCReadpoint &amp;gt;= smallestReadPoint;
+
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Compression.Algorithm compression = store.getFamily().getCompactionCompression();
StripeMultiFileWriter.WriterFactory factory = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StripeMultiFileWriter.WriterFactory() {
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Writer createWriter() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; store.createWriterInTmp(
- fd.maxKeyCount, compression, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, needMvcc, fd.maxTagsLength &amp;gt; 0);
+ fd.maxKeyCount, compression, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, fd.maxTagsLength &amp;gt; 0);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
- &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; needMvcc = fd.maxMVCCReadpoint &amp;gt;= smallestReadPoint;
+ &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; needMvcc = fd.maxMVCCReadpoint &amp;gt;= 0;
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Compression.Algorithm compression = store.getFamily().getCompactionCompression();
StripeMultiFileWriter.WriterFactory factory = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StripeMultiFileWriter.WriterFactory() {
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Writer createWriter() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; store.createWriterInTmp(
fd.maxKeyCount, compression, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, needMvcc, fd.maxTagsLength &amp;gt; 0);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So when all mvccr readpoint are 0, the next compaction can then still do the optimization for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8166&quot; title=&quot;Avoid writing the memstoreTS into HFiles when possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8166&quot;&gt;&lt;del&gt;HBASE-8166&lt;/del&gt;&lt;/a&gt; and not write the mvcc information at all. It just will be later... Before we already do that when we do not have any scanner open with a readpoint older than any of the readpoints in the HFile, now we have to wait until comactions set them all to 0.&lt;/p&gt;

&lt;p&gt;It&apos;s not all that bad. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, if the data is older than 6 days I&apos;d expect this to no longer show in the profiler.&lt;/p&gt;

&lt;p&gt;Maybe we need to write some unittests for this, although I assume that won&apos;t be easy.&lt;/p&gt;</comment>
                            <comment id="14395851" author="lhofhansl" created="Sat, 4 Apr 2015 18:09:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, I have to admit I do not quite follow the reasoning behind &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
The main question I have:&lt;br/&gt;
Do we need valid (non 0) mvcc readpoints for committed data (i.e. data that was flushed to an HFile and hence we&apos;ll never need to replay any HLogs for those)? Do we need these anywhere but in the memstore?&lt;/p&gt;</comment>
                            <comment id="14395875" author="lhofhansl" created="Sat, 4 Apr 2015 18:36:44 +0000"  >&lt;p&gt;Lastly... 6 days from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11315&quot; title=&quot;Keeping MVCC for configurable longer time &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11315&quot;&gt;&lt;del&gt;HBASE-11315&lt;/del&gt;&lt;/a&gt; is not right. We have major compaction set to be done every 7 days, with a jitter of 1/2 week.&lt;br/&gt;
I.e. data might be major compacted as early as &lt;em&gt;3.5&lt;/em&gt; days. The retention of mvcc data should be less than that. Maybe 3 days or so.&lt;/p&gt;</comment>
                            <comment id="14395880" author="lhofhansl" created="Sat, 4 Apr 2015 18:47:43 +0000"  >&lt;p&gt;Make &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8166&quot; title=&quot;Avoid writing the memstoreTS into HFiles when possible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8166&quot;&gt;&lt;del&gt;HBASE-8166&lt;/del&gt;&lt;/a&gt; work again.&lt;/p&gt;</comment>
                            <comment id="14395994" author="jeffreyz" created="Sat, 4 Apr 2015 23:18:23 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; for looking this. I think your patch can help a bit.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Do we need valid (non 0) mvcc readpoints for committed data (i.e. data that was flushed to an HFile and hence we&apos;ll never need to replay any HLogs for those)? Do we need these anywhere but in the memstore?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There are three cases(I could think of and maybe more) that we need the logSeqId(mvcc) around to help us keep the put order.&lt;/p&gt;

&lt;p&gt;Assuming all put/deletes are of same row &amp;amp; timestamp(version) &lt;br/&gt;
case 1) region server recovery case&lt;br/&gt;
We need mvcc(logSeqId) only when region is in recovery mode but not after recovery.&lt;/p&gt;

&lt;p&gt;case 2) replication receiving side, we need logSeqId to maintain the order because region move or recovery in replication playing side cause puts out of order&lt;br/&gt;
We need mvcc for couple of days(to be safe) so that at least the data eventually in receiving side are correct.&lt;/p&gt;

&lt;p&gt;case 3) put , delete, put. Currently delete overshadows the later put but with logSeqId we can easily solve the issue because logSeqId is the real version of a put.&lt;br/&gt;
Seems to me not needed(before I thought we need to keep mvcc around till a major compaction)&lt;/p&gt;





</comment>
                            <comment id="14395995" author="jeffreyz" created="Sat, 4 Apr 2015 23:23:39 +0000"  >&lt;p&gt;There is another thought. If we can keep mvcc being part of key byte array(logically it is but not in key serialization &amp;amp; deserialization) then we could use lazy read approach because mvcc is hardly used during key comparison.&lt;/p&gt;</comment>
                            <comment id="14396059" author="stack" created="Sun, 5 Apr 2015 04:04:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Seems to me not needed(before I thought we need to keep mvcc around till a major compaction)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Please say more. To what does the above statement apply? To all three of your &apos;cases&apos; or just to the last case, case #3?&lt;/p&gt;</comment>
                            <comment id="14481348" author="jeffreyz" created="Mon, 6 Apr 2015 15:57:24 +0000"  >&lt;blockquote&gt;
&lt;p&gt;To what does the above statement apply? To all three of your &apos;cases&apos; or just to the last case, case #3?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Just for case#3. The other two cases need mvcc around for a little bit time.&lt;/p&gt;</comment>
                            <comment id="14481916" author="lhofhansl" created="Mon, 6 Apr 2015 20:54:56 +0000"  >&lt;p&gt;We do need to revisit the 6 days, right? Would 3 days be enough? &lt;/p&gt;

&lt;p&gt;Lemme try to understand the cases:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;when we replay data due to recovery we want it to fall into the right place w.r.t to existing data. Why do we need more than the maximum time to roll a log (1h)?&lt;/li&gt;
	&lt;li&gt;replication... Yeah, that&apos;s important. I&apos;d say if you have a replication lag of more than a few hours you have a larger problem anyway.&lt;/li&gt;
	&lt;li&gt;This too... Although I do not actually agree that this is an advantage. Mutations (including deletes) being idempotent in HBase is a feature and not a problem.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;So with all this I do see any reason to keep these for more than a few hours. It&apos;s very possible that I am missing something.&lt;/p&gt;</comment>
                            <comment id="14482106" author="stack" created="Mon, 6 Apr 2015 22:42:11 +0000"  >&lt;p&gt;I have been trying to write up life of a sequenceid: &lt;a href=&quot;https://docs.google.com/document/d/16beczDie-KU1uSpJvd0GoUlQbPtQBL93rOOPqnE5Ma0/edit#&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://docs.google.com/document/d/16beczDie-KU1uSpJvd0GoUlQbPtQBL93rOOPqnE5Ma0/edit#&lt;/a&gt;  Let me pick it up again. Will add in above notes. Would be sweet if could backfill tests that verify our expectations align with the story we are telling.&lt;/p&gt;</comment>
                            <comment id="14482163" author="enis" created="Mon, 6 Apr 2015 23:12:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;when we replay data due to recovery we want it to fall into the right place w.r.t to existing data. Why do we need more than the maximum time to roll a log (1h)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think the min time to keep is max time an edit can live in the memstore without being flushed. This is not related to log roll (since we still replay edits from a previous log roll) but how much further an edit can be replayed through dist log replay I think. &lt;br/&gt;
Case 3 as Jeff puts it is an issue with the comparison order. We compare entries with &lt;tt&gt;row &amp;gt; column -&amp;gt; ts -&amp;gt; type -&amp;gt; seqId&lt;/tt&gt; order, however, we should compare entries in &lt;tt&gt;row &amp;gt; column -&amp;gt; ts -&amp;gt; seqId -&amp;gt; type&lt;/tt&gt; order so that Put, Delete, Put with the same TS works. If we do better resolution for ts&apos;s, this is not needed though. &lt;/p&gt;</comment>
                            <comment id="14482262" author="lhofhansl" created="Tue, 7 Apr 2015 00:13:37 +0000"  >&lt;p&gt;Yeah, not related to log roll, sorry. I meant the max time before we force a memstore flush (1 hour by default)... &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5930&quot; title=&quot;Limits the amount of time an edit can live in the memstore.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5930&quot;&gt;&lt;del&gt;HBASE-5930&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I still have not heard a convincing reason why the time to keep the mvcc stuff around needs to be greater than an hour or two &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14482283" author="stack" created="Tue, 7 Apr 2015 00:28:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;So with all this I do see any reason to keep these for more than a few hours.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its not log rolling as per Enis. It is when memstore is flushed.  Default is memstores are flushed at least once an hour:&lt;/p&gt;

&lt;p&gt; public static final int DEFAULT_CACHE_FLUSH_INTERVAL = 3600000;&lt;/p&gt;

&lt;p&gt;So if an old edit comes in during distributed log replay, an edit that has already been flushed to an hfile, we need to be able to put it in the appropriate slot (as you say). This can happen if we are overplaying edits in case where Master does not have last flush sequenceid on a region. If HFiles have all their seqids, it is easy.  But if mvcc has been purged from hfiles (optimization) and we get an edit that falls into the hfile time range, we are going to be confused.  Somehow the optimization purging mvcc should not run until we are sure old WALs with seqids older than those in hfiles for all regions have been let go.&lt;/p&gt;

&lt;p&gt;For replication, yeah, needs a few days.  The root of the lag may take a few days to fix.&lt;/p&gt;

&lt;p&gt;On the put -&amp;gt; delete -&amp;gt; put, you are not against changing sort order so that seqid prevails over type are you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;? Would be good change for 2.0.&lt;/p&gt;</comment>
                            <comment id="14482322" author="lhofhansl" created="Tue, 7 Apr 2015 00:45:45 +0000"  >&lt;p&gt;I think we had comment overlap. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...you are not against changing sort order so that seqid prevails over type are you...?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would actually be against it, since it breaks the fact that all mutations in HBase are idempotent - when the client encounters any problem with a batch of updates, it can just do those again, and the outcome would be identical - within the limits of what HBase defines, i.e. with ms resolution, now we would complicate that, and need explaining to do.&lt;/p&gt;

&lt;p&gt;So with the discussion above in place, can be lower the default time to 3 days? So that we can be reasonably sure that major compactions would purge the mvcc cruft?&lt;/p&gt;</comment>
                            <comment id="14482334" author="enis" created="Tue, 7 Apr 2015 00:53:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;I would actually be against it, since it breaks the fact that all mutations in HBase are idempotent - when the client encounters any problem with a batch of updates, it can just do those again, and the outcome would be identical &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t understand how this is related to idempotent updates. The sort order proposed will still keep ts before the type/seqId.  &lt;br/&gt;
3 days should be good enough for replication I say. &lt;/p&gt;</comment>
                            <comment id="14482550" author="stack" created="Tue, 7 Apr 2015 04:13:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; 3 days is arbitrary. If it so happens that someone has failed to observe a backed up replication and don&apos;t notice it till a week has gone by, will they lose data? Can we not have the optimization instead cut in when it is guaranteed the mvcc is no longer needed?&lt;/p&gt;

&lt;p&gt;In-cluster, it seems a matter of hours will do it as long as we check that locally flushing is working. Below are a few &apos;statements&apos; of why I think it should be fine.  For replication, as I read it, edits get a new seqid when applied to the sink cluster so source cluster seqid doesn&apos;t factor in at all. Maybe I misread.&lt;/p&gt;

&lt;p&gt;As per Enis, I don&apos;t get how idempotency is effected.&lt;/p&gt;

&lt;p&gt;Notes on in-cluster:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;For log replay in-cluster, when Distributed Log Replay, if a Region gets an edit with a seqid that fits inside a range covered by an existing hfile, then we can just drop it because it already persisted. This would be for case were an old WAL is being replayed though the edits have been flushed out to hfiles already (and the optimization dropping mvcc has been run).&lt;/li&gt;
	&lt;li&gt;If a region can&apos;t flush, then we should not run the optimization (This is probably ok... compaction will likely just not succeed if we can&apos;t flush but optimization should check last flush time).&lt;/li&gt;
	&lt;li&gt;If no replication, optimization can run on any file as long as no outstanding scanners and read point is beyond the oldest edit in an hfile (optimization does this now I believe).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14482558" author="jeffreyz" created="Tue, 7 Apr 2015 04:22:49 +0000"  >&lt;p&gt;Changing comparing order in row &amp;gt; column -&amp;gt; ts -&amp;gt; seqId -&amp;gt; type order can make things more consistently and doesn&apos;t change HBase current idempotence. For example, for puts with the same timestamp, the last put wins while if we do put, delete, put or delete, put , put and the delete always win.&lt;/p&gt;

&lt;p&gt;I think it&apos;s better that a delete should be treated as a put so users can have same exceptions as puts. Otherwise, for low time resolution OS or when a put is missing, we often want to check if there is a delete overshadowing newer puts.&lt;/p&gt;

&lt;p&gt;Yeah, keeping mvcc 3 days is good enough. &lt;/p&gt;</comment>
                            <comment id="14486820" author="lhofhansl" created="Thu, 9 Apr 2015 06:29:24 +0000"  >&lt;p&gt;Misunderstood the comparison order. All good &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14492722" author="lhofhansl" created="Mon, 13 Apr 2015 17:45:08 +0000"  >&lt;p&gt;Should we apply my patch.&lt;/p&gt;</comment>
                            <comment id="14492743" author="stack" created="Mon, 13 Apr 2015 17:55:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Yes, in a subtask.  Lets figure this 6 days vs 3 days vs a couple of hours and other items raised here as other subtasks or issues.&lt;/p&gt;</comment>
                            <comment id="14500883" author="lhofhansl" created="Fri, 17 Apr 2015 23:17:03 +0000"  >&lt;p&gt;Sure. After discussions we had (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, and I) I think we can reinstate my original code, where we check against the oldest running scanner and if all Cell in an HFile are older than that scaner (in terms of MVCC timestamp) we can set them to 0 and not store them upon compaction.&lt;/p&gt;

&lt;p&gt;The observation being that we only need MVCC stamps in the HFile to cover flushes/compactions that happen while a current scanner is running.&lt;br/&gt;
All other cases we should be covering with metadata in the HFiles trailer, not on individual Cells.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;, do you agree? &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; changed that, and I bet you had a very good reason.&lt;/p&gt;</comment>
                            <comment id="14502173" author="jeffreyz" created="Sun, 19 Apr 2015 23:53:54 +0000"  >&lt;blockquote&gt;
&lt;p&gt;All other cases we should be covering with metadata in the HFiles trailer, not on individual Cells.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This may be hard to achieve because out of order puts can be flushed at different time. Let&apos;s say row1/logSeqId=2 is flushed earlier than row1/logSeqId=1. HFile trailer meta data&apos;s mvcc range will be overlapped among multiple HFiles.  &lt;/p&gt;

&lt;p&gt;One option is that we can reinstate your original code by checking against the oldest running scanner and only keep mvcc around during region recovery time so that we can still keep &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; goal. &lt;/p&gt;

&lt;p&gt;If not much overall read performance degrade(because this part may not be the bottleneck in the read path), I think it&apos;s better to keep current way so all cases can work correctly for out of order puts. How do you guys think? Thanks.&lt;/p&gt;
</comment>
                            <comment id="14502201" author="lhofhansl" created="Mon, 20 Apr 2015 01:02:48 +0000"  >&lt;p&gt;Correctness &amp;gt; Performance &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  We need to have this correct in all cases.&lt;/p&gt;

&lt;p&gt;OK. So lemme file a sub issue to apply the patch I attache here. Not as good as the original patch, but better.&lt;/p&gt;

&lt;p&gt;Here we need to have the discussion about how long to keep the Cells, it seems we want this less than the minimum time between major compactions (which is 3.5 days currently - 1 week +- 1/2 week) for performance (but again correctness is more important).&lt;br/&gt;
Might also want to change the detection code for whether a major compaction is needed, if we can rid of MVCC stamp, we should major compact.&lt;/p&gt;</comment>
                            <comment id="14502373" author="jeffreyz" created="Mon, 20 Apr 2015 05:22:39 +0000"  >&lt;p&gt;That sounds good. We can shorter the time period to 2 or 3 days. In one case that keeping mvcc longer can gain some performance because it makes possible that we can compact HFiles out of order in minor compactions.&lt;/p&gt;</comment>
                            <comment id="14503806" author="lhofhansl" created="Mon, 20 Apr 2015 22:16:15 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;, just discussed a bit with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;... If we kept the in-order compactions, we won&apos;t need MVCC stamps in the HFile beyond the oldest scanner, right?&lt;/p&gt;

&lt;p&gt;I feel like I am missing something. Could you show an example of when we need MVCC stamps in the HFile beyond the oldest scanner when you have some time?&lt;br/&gt;
The issue has to do with Puts/Deletes happening in the same millisecond, right?&lt;/p&gt;</comment>
                            <comment id="14503943" author="stack" created="Mon, 20 Apr 2015 23:31:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;This may be hard to achieve because out of order puts can be flushed at different time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do &apos;out of order&apos; puts happen at DLR time only &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt;? i.e. WALs can be replayed in any order since they are farmed out over the cluster. We also cannot guarantee when a region that is receiving DLR edits will flush hfiles; e.g. we could get row1/logSeqId=2 during DLR and flush because we had memory pressure, but then later row1/logSeqId=1 might arrive and be flushed into a newer hfile. The fix for this is to not let compactions happen when region is in recovery &amp;#8211; this is probably the case already (or let compactions go on but preserve mvcc while in recovery)?&lt;/p&gt;

&lt;p&gt;So, the Lars fix would be to drop mvcc if no scanner outstanding with a span that includes mvcc in current hfile AND we are not in DLR recovery mode? &lt;/p&gt;

&lt;p&gt;Are there other places where we might have out-of-order puts? (Flushes are single threaded and edits go into FSHLog and MemStore in order caveat Elliott and Nate&apos;s recent find: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12751?focusedCommentId=14377157&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14377157&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-12751?focusedCommentId=14377157&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14377157&lt;/a&gt;).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...and only keep mvcc around during region recovery time so that we can still keep &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; goal&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;On keeping seqid in the KV in hfiles so we can do &quot;...out of order in minor compactions..... &quot;&lt;/p&gt;

&lt;p&gt;...don&apos;t we mean compacting non-adjacent files rather than out-of-order here?&lt;/p&gt;

&lt;p&gt;So, yeah, if we preserved mvcc always, we could do any order and non-adjacent. Would be nice.&lt;/p&gt;

&lt;p&gt;Otherwise, as I see it, if we want to do non-adjacent compactions (which as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; says above, we do not currently have), then we could do it if all files under a Store have zero for mvcc and we just order the edits by the hfile meta data mvcc number. When there are files with an mvcc per KV, then we should probably merge those first...  Would have to think it through more.&lt;/p&gt;

&lt;p&gt;It gets a little complicated though if the Store has some files with a hfile meta data mvcc number but other files have an mvcc per KV. We could not do a file that has an mvcc per KV with a non-adjacent &lt;/p&gt;

&lt;p&gt;But we could do it also if files with zero if we have the Lars optimization, we could do non-adjacent if we respected the hfile seqid order.  It gets tricky if a file has mvcc in the KV and all the rest do not.  Files with KVs in the mvcc need to be compacted together ahead of &lt;/p&gt;</comment>
                            <comment id="14504361" author="stack" created="Tue, 21 Apr 2015 05:26:09 +0000"  >&lt;p&gt;Thinking on it, during out-of-order DLR, there are a few ways in which we could lose data if we bring back the optimization that zeros all mvccs promoting the highest mvcc seen to be the hfiles mvcc kept in the hfile metadata.&lt;/p&gt;

&lt;p&gt;During recovery of a region during DLR, we may flush hfiles in a manner such that the older edits are in the most recently flushed file or hfiles are made of edits that do not have a linearly increasing mvcc. This is a violation of tenets that  hold when flushes always drop files that have mvcc/sequenceid in excess of files currently present in the filesystem (and whose edits have increasing mvccs)&lt;/p&gt;

&lt;p&gt;We have to be careful compacting these files dropped during recovery. We need to compact them all up together first &amp;#8211; after the region comes on line &amp;#8211; before we can mix them in with zero&apos;d mvcc files (it has to be after region comes online and not before because region may crash during recovery having dropped one or more out-of-order hfiles)&lt;/p&gt;

&lt;p&gt;Here is an illustration.&lt;/p&gt;

&lt;p&gt;A region is recovering. It comes under memory pressure so flushes the edits it received so far. It so happens that it mostly received older edits but a few new ones came in too. It dumps out (Let the letters be keys and the numbers mvcc):&lt;/p&gt;

&lt;p&gt;A 2&lt;br/&gt;
B 4&lt;br/&gt;
C 10&lt;/p&gt;

&lt;p&gt;Recovery completes and it drops another hfile:&lt;/p&gt;

&lt;p&gt;A 1&lt;br/&gt;
B 5&lt;br/&gt;
C 11&lt;/p&gt;

&lt;p&gt;Now, if we compact the first file with a zero&apos;d mvcc file with a sequenceid of 8, the product will be a zero&apos;d mvcc hfile whose seqid is 10.&lt;/p&gt;

&lt;p&gt;If we then compact this &apos;10&apos; file with the second file flushed, we lose the &apos;B 5&apos; edit because it is &amp;lt; &apos;10&apos;. Even if we compacted all three files together &amp;#8211; the zero&apos;d mvcc hfile and the two files dropped during recovery &amp;#8211; we could lose &apos;B 5&apos; and &apos;A 2&apos; since both have mvccs &amp;lt; &apos;10&apos;.&lt;/p&gt;
</comment>
                            <comment id="14508495" author="jeffreyz" created="Thu, 23 Apr 2015 05:39:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; Well said and good examples! As of today. there are two cases that we could have out of order puts: DLR or replication, where the order of wal files to be replayed isn&apos;t guaranteed.  &lt;/p&gt;

&lt;p&gt;For non-adjacent hfile compactions, it seems that we have to keep mvcc in KVs level, For example, hfile1(max mvcc=1) hfile2(max mvcc=2) and hfile3(max mvcc=3). If we just compact hfile1 and hfile3, we can&apos;t set the newly compacted hfile&apos;s max mvcc=3 because hfile2 may have same rows in either hfile1 or hfile2.&lt;/p&gt;

&lt;p&gt;Keeping mvcc will make the &quot;haunting&quot; out-of-order issue go away and one less concern. Let me know which option we should go and I can also help on the fix.&lt;/p&gt;

</comment>
                            <comment id="14508507" author="lhofhansl" created="Thu, 23 Apr 2015 05:53:56 +0000"  >&lt;p&gt;Thanks for the explanation. After 6 days (currently) we &lt;em&gt;are&lt;/em&gt; zero&apos;ing mvcc during compactions. In &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13497&quot; title=&quot;Remove MVCC stamps from HFile when that is safe&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13497&quot;&gt;&lt;del&gt;HBASE-13497&lt;/del&gt;&lt;/a&gt; I allow a compaction to not store mvcc stuff, when it&apos;s all 0 anyway (not looking at the current scanner, but only going my the HFile&apos;s data). So that&apos;s safe at least. I agree we cannot put the original optimization back.&lt;/p&gt;</comment>
                            <comment id="14508508" author="lhofhansl" created="Thu, 23 Apr 2015 05:54:56 +0000"  >&lt;p&gt;Feel free to +1 the patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13497&quot; title=&quot;Remove MVCC stamps from HFile when that is safe&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13497&quot;&gt;&lt;del&gt;HBASE-13497&lt;/del&gt;&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14509175" author="stack" created="Thu, 23 Apr 2015 14:59:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;After 6 days (currently) we are zero&apos;ing mvcc during compactions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Pardon me, where is this enforced (all hfiles participating in a compaction must be 6-days old?)  6-days is arbitrary, right? It means that there cannot be a WAL outstanding that has an edit that has not yet been flushed, right?  It also means, that there cannot be an edit in a WAL that has not been replicated and flushed on the remote side? Is there a trigger we could use instead rather than an arbitrary timing?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffreyz&quot; class=&quot;user-hover&quot; rel=&quot;jeffreyz&quot;&gt;Jeffrey Zhong&lt;/a&gt; Thanks for chiming in. I don&apos;t see the WALEdit sequenceid being used when we replicate. Is this something to implement? (Sounds like a good idea... )&lt;/p&gt;</comment>
                            <comment id="14510470" author="jeffreyz" created="Fri, 24 Apr 2015 05:09:11 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I don&apos;t see the WALEdit sequenceid being used when we replicate. Is this something to implement? (Sounds like a good idea... )&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;I thought we already had used it because intra-replication did otherwise I can give a first try on this.&lt;/p&gt;</comment>
                            <comment id="14632376" author="lhofhansl" created="Sat, 18 Jul 2015 10:57:34 +0000"  >&lt;p&gt;So where are we with this?&lt;/p&gt;

&lt;p&gt;To answer your question above &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, in the subtask I just put the part of the optimization back, namely if all involved HFiles have a max timestamp of 0, then there is no need to write the timestamp into the new HFile (as all would be 0 anyway).&lt;br/&gt;
(previously it did that if all timestamp are older than the oldest running scanner, but as discussed here, we can&apos;t do that any long)&lt;/p&gt;

&lt;p&gt;So how do we proceed with this one?&lt;/p&gt;</comment>
                            <comment id="15116641" author="anoop.hbase" created="Tue, 26 Jan 2016 04:07:55 +0000"  >&lt;p&gt;There is already a jira to remove the DLR and cleanup code. So then we can undo &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; and will get back the old mvcc parse optimization&lt;/p&gt;</comment>
                            <comment id="15116678" author="lhofhansl" created="Tue, 26 Jan 2016 04:46:23 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;. Which jira are you referring to? Can we undo &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; right now, or does it depend on this other jira being implemented first?&lt;/p&gt;</comment>
                            <comment id="15116696" author="anoop.hbase" created="Tue, 26 Jan 2016 05:05:02 +0000"  >&lt;p&gt;It is &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15020&quot; title=&quot;Remove DistributedLogReplay (a.k.a DLR)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15020&quot;&gt;HBASE-15020&lt;/a&gt;.  We can remove whole code parts added for DLR. Any way that is disabled and found to have bugs still.  Ya may be we can undo &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12600&quot; title=&quot;Remove REPLAY tag dependency in Distributed Replay Mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12600&quot;&gt;&lt;del&gt;HBASE-12600&lt;/del&gt;&lt;/a&gt; now itself I feel (before whole code parts removal)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12709430" name="13389.txt" size="2003" author="lhofhansl" created="Sat, 4 Apr 2015 18:47:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 Apr 2015 06:05:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            46 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i27q7z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>