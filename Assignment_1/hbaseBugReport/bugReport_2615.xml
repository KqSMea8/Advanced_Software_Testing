<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:03:22 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2615/HBASE-2615.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2615] M/R on bulk imported tables</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2615</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;We are bulk importing using loadtable.rb and running M/R jobs using HBase as input.&lt;/p&gt;

&lt;p&gt;We&apos;re taking the following steps:&lt;br/&gt;
1a. Load HBase with a M/R job using the normal API. &lt;br/&gt;
OR&lt;br/&gt;
1b. Load HBase with bulk import.&lt;/p&gt;

&lt;p&gt;THEN&lt;/p&gt;

&lt;p&gt;2a. Using the shell, do a &quot;count&quot; over the table.&lt;br/&gt;
OR&lt;br/&gt;
2b. Run a M/R job that scans the whole HBase table (and nothing else).&lt;/p&gt;

&lt;p&gt;Of the 4 combos, 3 are fine: 1a+2a, 1a+2b, 1b+2a.  We&apos;re having trouble with 1b+2b.  When we run the M/R job, it doesn&apos;t seem to read in any records, but there are no explicit errors in either the Hadoop or HBase logs.&lt;/p&gt;

&lt;p&gt;Any ideas on what might be wrong with the bulk import to cause this problem?  We confirmed this problem exists in both hbase-0.20.3 and hbase-0.20.4.&lt;/p&gt;

&lt;p&gt;We have created dummy data (see attached). This is the test case:&lt;/p&gt;

&lt;p&gt;After loading the data into HDFS. In hbase shell:&lt;br/&gt;
create &apos;tiny&apos;, &apos;values&apos;&lt;/p&gt;

&lt;p&gt;Execute: &lt;/p&gt;
{HBASE-HOME}/bin/hbase org.jruby.Main {HBASE-HOME}
&lt;p&gt;/bin/loadtable.rb tiny tinytable&lt;/p&gt;

&lt;p&gt;Then run the simple row counter&lt;/p&gt;
{HADOOP-HOME}
&lt;p&gt;/bin/hadoop jar &lt;/p&gt;
{HBASE-HOME}
&lt;p&gt;/hbase-0.20.x.jar rowcounter tiny values&lt;/p&gt;

&lt;p&gt;Notice that map input records read is always zero. We confirmed that other mapreduce jobs do not execute the map function at all, always returning 0 records.&lt;/p&gt;

&lt;p&gt;We also ran a major_compaction of all Hbase tables (.META. and .ROOT. as well) but this did not fix the problem.&lt;/p&gt;</description>
                <environment>&lt;p&gt;os.arch=amd64; os.version=2.6.9-67.ELsmp; java.version=1.6.0_15; java.vendor=Sun Microsystems Inc.&lt;/p&gt;</environment>
        <key id="12465486">HBASE-2615</key>
            <summary>M/R on bulk imported tables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="azzadev">Azza Abouzeid</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 May 2010 16:40:10 +0000</created>
                <updated>Fri, 12 Oct 2012 06:15:38 +0000</updated>
                            <resolved>Sun, 6 Jun 2010 06:51:16 +0000</resolved>
                                    <version>0.20.3</version>
                    <version>0.20.4</version>
                                    <fixVersion>0.20.5</fixVersion>
                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12871806" author="azzadev" created="Wed, 26 May 2010 16:49:55 +0000"  >&lt;p&gt;Dummy HDFS data (properly formatted HFile) of 1000 records.&lt;/p&gt;</comment>
                            <comment id="12872691" author="stack" created="Thu, 27 May 2010 23:09:52 +0000"  >&lt;p&gt;One problem is that we are making a region too many.  The first region has the empty string as the start and end rows.  This must be a bug in add_table.rb.   I deleted the bad region (it had nothing in it) but still the mr count fails.  Looking more.&lt;/p&gt;</comment>
                            <comment id="12873143" author="stack" created="Fri, 28 May 2010 20:29:57 +0000"  >&lt;p&gt;Using hfile tool, I confirmed that the keys in the two files are ordered:&lt;/p&gt;

&lt;p&gt;./bin/hbase org.apache.hadoop.hbase.io.hfile.HFile&lt;/p&gt;</comment>
                            <comment id="12874829" author="stack" created="Wed, 2 Jun 2010 22:19:28 +0000"  >&lt;p&gt;So, add table tool makes regions:&lt;/p&gt;

&lt;p&gt;tiny,,1275509545408&lt;br/&gt;
tiny,user2028689897,1275509581851&lt;/p&gt;

&lt;p&gt;This seems right.  Last key in one of the two files is user2026413677/values:field1/9223372036854775807/Put/vlen=1023.  First key in the second file is: user2028689897/values:field1/9223372036854775807/Put/vlen=1019 &lt;/p&gt;

&lt;p&gt;Now I&apos;m trying to dig in whats different between scan in shell and scan in MR.&lt;/p&gt;</comment>
                            <comment id="12874873" author="stack" created="Thu, 3 Jun 2010 00:10:11 +0000"  >&lt;p&gt;The scanner is skipping all entries because timestamps on values do not fit within the Scanner&apos;s timerange specification.&lt;/p&gt;

&lt;p&gt;Looking at the data files, indeed the timestamp is user1000319044/values:field1/9223372036854775807/Put/vlen=1023 is large, maximum?&lt;/p&gt;

&lt;p&gt;How were these files written?  Maybe a bug in our hfile writer?&lt;/p&gt;</comment>
                            <comment id="12874877" author="stack" created="Thu, 3 Jun 2010 00:14:54 +0000"  >&lt;p&gt;Was one of the KeyValue constructors that doesn&apos;t specify timestamps used emitting from map or reduce task?  If so, sounds like a documentation bug at the least.&lt;/p&gt;</comment>
                            <comment id="12874882" author="stack" created="Thu, 3 Jun 2010 00:22:31 +0000"  >&lt;p&gt;So, let me fix the Record Writer so it catches this case.  Comes of a chat up on IRC w/ Todd:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
17:15 &amp;lt; tlipcon&amp;gt; why does the MR job filter on timestamp?
17:16 &amp;lt; St^Ack&amp;gt; scanner does
17:16 &amp;lt; St^Ack&amp;gt; rowcounter will count whatever fits inside the Scan spec
17:16 &amp;lt; tlipcon&amp;gt; but counter doesn&apos;t specify a time range, does it?
17:16 &amp;lt; St^Ack&amp;gt; no
17:16 &amp;lt; St^Ack&amp;gt; but whats in data files is maximum timestamp
17:16 &amp;lt; tlipcon&amp;gt; is that Special?
17:16 &amp;lt; St^Ack&amp;gt; yeah, usually
17:16 &amp;lt; St^Ack&amp;gt; it gets replaced by current
17:17 &amp;lt; St^Ack&amp;gt; but writing hfiles, you are kinda bypassing the stuff that does the convertion &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; you
17:17 &amp;lt; tlipcon&amp;gt; ah I see
17:18 &amp;lt; tlipcon&amp;gt; good &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt;
17:18 &amp;lt; St^Ack&amp;gt; at least a doc fix...
17:18 &amp;lt; St^Ack&amp;gt; not sure what &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; we could &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; to stop folks hanging themselves
17:18 &amp;lt; tlipcon&amp;gt; HFileOutputFormat&apos;s recordwriter could be smarter
17:19 &amp;lt; tlipcon&amp;gt; check the KVs going out before writing
17:19 &amp;lt; St^Ack&amp;gt; add LATEST_TIMESTAMP check in there and substitute currentTimeMillis I suppose
17:20 &amp;lt; St^Ack&amp;gt; i think that&apos;d work
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12874891" author="azzadev" created="Thu, 3 Jun 2010 00:49:06 +0000"  >&lt;p&gt;We modified the KeyValue constructor in our data generation script to include current timestamp and MR jobs work. Thanks, nice catch!&lt;/p&gt;

&lt;p&gt;Perhaps, the API could only expose the constructor interfaces that require a timestamp or add a MIN/current timestamp by default to tuples instead of MAX to guarantee it being read.&lt;/p&gt;</comment>
                            <comment id="12874969" author="stack" created="Thu, 3 Jun 2010 06:01:10 +0000"  >&lt;p&gt;Small patch and test.  Review please.&lt;/p&gt;

&lt;p&gt;(I tried posting to review.hbase.org but it complains &apos;The file &apos;src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.java&apos; (r2a272af) could not be found in the repository&apos; which seems to be way wrong)&lt;/p&gt;</comment>
                            <comment id="12874970" author="stack" created="Thu, 3 Jun 2010 06:02:44 +0000"  >&lt;p&gt;.bq Perhaps, the API could only expose the constructor interfaces that require a timestamp or add a MIN/current timestamp by default to tuples instead of MAX to guarantee it being read.&lt;/p&gt;

&lt;p&gt;I made it so if a kv with maximum timestamp is emitted, we&apos;ll set it instead to now before writing.&lt;/p&gt;</comment>
                            <comment id="12874980" author="tlipcon" created="Thu, 3 Jun 2010 06:42:49 +0000"  >&lt;p&gt;+1, lgtm&lt;/p&gt;

&lt;p&gt;Sorry about reviewboard error, crontab was screwed up after switching to the new ec2 instance, should be fixed now.&lt;/p&gt;</comment>
                            <comment id="12875918" author="stack" created="Sat, 5 Jun 2010 16:45:12 +0000"  >&lt;p&gt;Thanks for review Todd.  Committed to branch and trunk (on branch, no test because it junit4 added)&lt;/p&gt;</comment>
                            <comment id="12875939" author="ryanobjc" created="Sat, 5 Jun 2010 21:07:15 +0000"  >&lt;p&gt;so after this patch, we no longer allow user set timestamps?  Are you sure that&apos;s a good idea?&lt;/p&gt;</comment>
                            <comment id="12875946" author="stack" created="Sat, 5 Jun 2010 21:40:17 +0000"  >&lt;p&gt;They can... We only change the timstamp to now if the timestamp in the kv is LATEST_TIMESTAMP (we chatted in gtalk and I showed Ryan  how the code does this &amp;#8211; he agreed it ok)&lt;/p&gt;</comment>
                            <comment id="12875951" author="tlipcon" created="Sat, 5 Jun 2010 21:56:26 +0000"  >&lt;p&gt;Looks like this actually broke the build. The problem seems to be that changing the timestamp at write time changes the sort order. See: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/HBase-TRUNK/1300/testReport/org.apache.hadoop.hbase.mapreduce/TestHFileOutputFormat/test_LATEST_TIMESTAMP_isReplaced/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/HBase-TRUNK/1300/testReport/org.apache.hadoop.hbase.mapreduce/TestHFileOutputFormat/test_LATEST_TIMESTAMP_isReplaced/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12875956" author="stack" created="Sat, 5 Jun 2010 22:18:58 +0000"  >&lt;p&gt;Yeah, if timestamp changed, then we&apos;d be out of order (ts should go from bigger to smaller).  Iwasn&apos;t using comparator... I committed fix that uses ts less than previosu&lt;/p&gt;</comment>
                            <comment id="12876005" author="stack" created="Sun, 6 Jun 2010 06:51:16 +0000"  >&lt;p&gt;Closing.  It builds fine now on hudson after my fixup.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12446230" name="2615.txt" size="6301" author="stack" created="Thu, 3 Jun 2010 06:01:10 +0000"/>
                            <attachment id="12445563" name="dummydata.tar.gz" size="770911" author="azzadev" created="Wed, 26 May 2010 16:49:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 May 2010 23:09:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26386</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 28 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08sdr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>49198</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>