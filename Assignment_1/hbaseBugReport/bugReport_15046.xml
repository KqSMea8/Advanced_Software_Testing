<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:59:02 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-15046/HBASE-15046.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-15046] Perf test doing all mutation steps under row lock</title>
                <link>https://issues.apache.org/jira/browse/HBASE-15046</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;This issue is about perf testing a redo of the write pipeline so that rather than:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;take rowlock&lt;/li&gt;
	&lt;li&gt;start mvcc&lt;/li&gt;
	&lt;li&gt;append to WAL&lt;/li&gt;
	&lt;li&gt;add to memstore&lt;/li&gt;
	&lt;li&gt;sync WAL&lt;/li&gt;
	&lt;li&gt;let go of rowlock&lt;/li&gt;
	&lt;li&gt;finish up mvcc&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;instead.... try...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;take rowlock&lt;/li&gt;
	&lt;li&gt;start mvcc&lt;/li&gt;
	&lt;li&gt;append to WAL&lt;/li&gt;
	&lt;li&gt;sync WAL&lt;/li&gt;
	&lt;li&gt;add to memstore&lt;/li&gt;
	&lt;li&gt;finish up mvcc&lt;/li&gt;
	&lt;li&gt;let go of rowlock&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The latter is more straight-forward undoing need of rolling back memstore if all does not succeed.&lt;/p&gt;

&lt;p&gt;It might be slower though. This issue is a look-see/try it.&lt;/p&gt;

&lt;p&gt;The redo will also help address the parent issue in a more general way so we can do without the special-casing done for branch-1.0 and branch-1.1 done in a sibling subtask.&lt;/p&gt;

&lt;p&gt;Other benefits are that the current write pipeline is copy/pasted in a few places  &amp;#8211; in append, increment and checkand* &amp;#8211; and a refactor will allow us to fix this duplication.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12924586">HBASE-15046</key>
            <summary>Perf test doing all mutation steps under row lock</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12895334">HBASE-14460</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Dec 2015 00:42:16 +0000</created>
                <updated>Mon, 8 Feb 2016 22:54:39 +0000</updated>
                            <resolved>Mon, 8 Feb 2016 17:58:49 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="15073328" author="lhofhansl" created="Tue, 29 Dec 2015 00:59:17 +0000"  >&lt;p&gt;It&apos;s this right now, though:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;take rowlock&lt;/li&gt;
	&lt;li&gt;start mvcc&lt;/li&gt;
	&lt;li&gt;append to WAL&lt;/li&gt;
	&lt;li&gt;add to memstore&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;let go of rowlock&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;sync WAL&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;in case of error: rollback memstore&lt;/li&gt;
	&lt;li&gt;finish up mvcc&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Right? That was the whole point of rolling back the memstore, so that we can sync the wal to the DNs without holding the row lock, I doubt we want to undo that part.&lt;/p&gt;</comment>
                            <comment id="15073403" author="chenheng" created="Tue, 29 Dec 2015 03:08:23 +0000"  >&lt;p&gt;Currently, sync WAL is not really &apos;sync&apos; (it use hflush not hsync). So with &apos;rollback memstore&apos;, it may cause inconsistency between WAL and memstore.  I am not sure the tradeoff between performance and correctness?&lt;/p&gt;</comment>
                            <comment id="15073419" author="eclark" created="Tue, 29 Dec 2015 03:26:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;That was the whole point of rolling back the memstore, so that we can sync the wal to the DNs without holding the row lock, I doubt we want to undo that part.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There can be any number of updates in flight for a single row. So holding the row lock longer doesn&apos;t have the down side that it used to. Since every row lock is reader/writer the only time that holding the lock longer has any performance issue is when there are puts and check/mutates in flight to the same row. And @stack has already shown that increments are much faster by not having to wait for mvcc ( made possible by holding the row lock longer).&lt;/p&gt;</comment>
                            <comment id="15073451" author="chenheng" created="Tue, 29 Dec 2015 03:51:55 +0000"  >&lt;blockquote&gt;
&lt;p&gt;So holding the row lock longer doesn&apos;t have the down side that it used to. Since every row lock is reader/writer the only time that holding the lock longer has any performance issue is when there are puts and check/mutates in flight to the same row.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Oh,  the row lock in doMiniBatchMutation is shared lock.  So there is no performance regression if we move sync WAL into row lock scope.  Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; for your explanation.  &lt;/p&gt;</comment>
                            <comment id="15073563" author="lhofhansl" created="Tue, 29 Dec 2015 07:01:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;Currently, sync WAL is not really &apos;sync&apos; (it use hflush not hsync). So with &apos;rollback memstore&apos;, it may cause inconsistency between WAL and memstore. I am not sure the tradeoff between performance and correctness?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not so. hflush might not persist to disk (just forces changes to the typically 3 involved data nodes), but it is the point at the we report back to the client that the write was successful, no amount of reordering mvcc and hflush can guard against (say) a power outage taking the wrong three machines down.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, so this is possible after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12751&quot; title=&quot;Allow RowLock to be reader writer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12751&quot;&gt;&lt;del&gt;HBASE-12751&lt;/del&gt;&lt;/a&gt; (which is in master, only)? That would be cool simplification indeed.&lt;/p&gt;</comment>
                            <comment id="15073616" author="eclark" created="Tue, 29 Dec 2015 08:04:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12751&quot; title=&quot;Allow RowLock to be reader writer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12751&quot;&gt;&lt;del&gt;HBASE-12751&lt;/del&gt;&lt;/a&gt; went into branch-1 as well via &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14465&quot; title=&quot;Backport &amp;#39;Allow rowlock to be reader/write&amp;#39; to branch-1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14465&quot;&gt;&lt;del&gt;HBASE-14465&lt;/del&gt;&lt;/a&gt;. But yeah the optimization is possible because of that jira.&lt;/p&gt;</comment>
                            <comment id="15074694" author="stack" created="Wed, 30 Dec 2015 06:48:49 +0000"  >&lt;p&gt;Here is what a RS looks like when YCSB write only is being run against it. Two samples.&lt;/p&gt;

&lt;p&gt;Trying to change ordering but this doMiniBatchMutation has a lot going on. First few attempts have me locked up. Will keep at it.&lt;/p&gt;</comment>
                            <comment id="15074710" author="lhofhansl" created="Wed, 30 Dec 2015 07:15:29 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. I&apos;m very interested in this. Wanna huddle first thing next year?&lt;/p&gt;

&lt;p&gt;I&apos;ve also written a simple load tester for a kind of workload we have, which essentially overrides (i.e. writes new versions of) the same keys (row key + CF + CQ) over and over again in batches; it&apos;s likely multiple threads/clients will touch the same key in a batch.&lt;/p&gt;</comment>
                            <comment id="15075274" author="stack" created="Wed, 30 Dec 2015 18:16:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; I&apos;m game to huddle, for sure.  This doMiniBatch thingy needs refactor at a minimum. Let me post a few graphs for simple loading that shows a benefit doing all under row lock; I think there is more to be had here. I&apos;d be interested in your load tester to see if benefit is still there when doing your loading type.&lt;/p&gt;</comment>
                            <comment id="15075283" author="stack" created="Wed, 30 Dec 2015 18:26:44 +0000"  >&lt;p&gt;Simple patch that has all operations happen under the row lock (i.e. moves the sync and catchup on mvcc all under the row lock where before these were done after releasing locks).&lt;/p&gt;

&lt;p&gt;TODO: this doMiniBatch method is pages long and hard to follow. It has DLR handling and rollback of memstore (which will not be needed if we go forward on this path where we sync the WAL first before updating memstore) as well as code copy/pasted in increment, append, etc. methods. Could do with some cleanup.&lt;/p&gt;

&lt;p&gt;Flamegraph shows that after moving the sync, the profile looks the same with a few percent saved here and there.&lt;/p&gt;

&lt;p&gt;The other two graphs show that the rate of operations is up slightly... on average above 12k/second where without patch, its below 12k per second. The second graph is showing the new metrics that have how many ops happen inside a latency window. It shows that with the patch, more ops are completing inside the 0-1ms window than w/o the patch.&lt;/p&gt;

&lt;p&gt;Next up is more extensive compare. This is short runs of the YCSB write-only workload.&lt;/p&gt;

&lt;p&gt;If all could be done under row lock, I could then put in place the Increment fast path as default done in sibling issue and rather than it having narrow consistency, if I change all ops to this all_under_lock pattern, then we&apos;ll have back our row-based consistency.&lt;/p&gt;
</comment>
                            <comment id="15075308" author="eclark" created="Wed, 30 Dec 2015 18:49:47 +0000"  >&lt;p&gt;Thanks for this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; everything is looking great.&lt;/p&gt;</comment>
                            <comment id="15080456" author="stack" created="Sun, 3 Jan 2016 15:38:35 +0000"  >&lt;p&gt;Here is run of a suite of ycsb tests (30 threads to a single regionserver): load workload a, run workload a (50/50), then workload b (95 read/5 write), c (100 read), f (50 read/50 read modify write). Graphs are about same for both patched and unpatched dominibatch.... The pure writes and reads seem to be slightly faster ... not sure why reads would be faster but 95/5 seems a tad slower (in middle is an aborted run &amp;#8211; the patch seems to bring on mvcc lockup... need to look into that). Let me keep going down this path.... will try some more intense runs meantime.&lt;/p&gt;</comment>
                            <comment id="15082066" author="stack" created="Tue, 5 Jan 2016 00:20:08 +0000"  >&lt;p&gt;I tried with 50 ycsb threads running through same suite. The graphs look samish (again, the patched version got stuck in mvcc... will have to fix that). Let me work up a more substantial patch that does all under row locks.&lt;/p&gt;</comment>
                            <comment id="15082710" author="chenheng" created="Tue, 5 Jan 2016 09:30:15 +0000"  >&lt;p&gt;Looks great.  All operations happens on one single row or random rows? &lt;/p&gt;</comment>
                            <comment id="15082733" author="chenheng" created="Tue, 5 Jan 2016 09:45:18 +0000"  >&lt;blockquote&gt;
&lt;p&gt;not sure why reads would be faster but 95/5 seems a tad slower (in middle is an aborted run &#8211; the patch seems to bring on mvcc lockup... need to look into that).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Did all read requests happen on the latest inserted rows? what&apos;s the requestdistribution param, uniform, zipfian or latest ?&lt;/p&gt;</comment>
                            <comment id="15083472" author="stack" created="Tue, 5 Jan 2016 17:59:02 +0000"  >&lt;p&gt;Its ycsb &amp;#8211; we run each workload for an hour &amp;#8211; so random rows &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chenheng&quot; class=&quot;user-hover&quot; rel=&quot;chenheng&quot;&gt;Heng Chen&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15084961" author="chenheng" created="Wed, 6 Jan 2016 04:09:00 +0000"  >&lt;p&gt;yeah,  so i want to know what is the request distribution param in your workload (It seems that default value is uniform).&lt;/p&gt;</comment>
                            <comment id="15096952" author="stack" created="Wed, 13 Jan 2016 20:44:52 +0000"  >&lt;p&gt;Here is perf run with the latest patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15082&quot; title=&quot;Fix merge of MVCC and SequenceID performance regression&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15082&quot;&gt;&lt;del&gt;HBASE-15082&lt;/del&gt;&lt;/a&gt;: i.e. wait on read point to match write point before releasing row lock.&lt;/p&gt;

&lt;p&gt;In the graph, we have before and after and its ycsb:&lt;/p&gt;

&lt;p&gt;load&lt;br/&gt;
workloada (50read/50update)&lt;br/&gt;
workloadb (95read/5update)&lt;br/&gt;
workloadc (100read)&lt;br/&gt;
workloadf (50/read-modify-write 50)&lt;/p&gt;

&lt;p&gt;Graphs show that for the 100% read case, workloadc, we are doing worse... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &amp;#8211; 35k before and 30k ops after &amp;#8211; otherwise, the graphs are very similar.&lt;/p&gt;

&lt;p&gt;Need to do 95% write and 5% read compare too... also figure out why we are doing more GC&apos;ing when this patch is in place; that don&apos;t seem right.. .should be less..&lt;/p&gt;</comment>
                            <comment id="15096995" author="eclark" created="Wed, 13 Jan 2016 21:14:25 +0000"  >&lt;p&gt;We might be able to get that 5% back by going with the complexity of rollbacks on the default doMiniBatchMutation code path.&lt;/p&gt;</comment>
                            <comment id="15102703" author="stack" created="Fri, 15 Jan 2016 23:41:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;We might be able to get that 5% back by going with the complexity of rollbacks on the default doMiniBatchMutation code path.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Say more &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Turns out I had my graphs reversed. Perf is effectively the same with the patched version being perhaps slightly better and for sure better when just Gets. I reran it a few times. Let me try another, more direct test to be sure. This patch might be back alive.&lt;/p&gt;</comment>
                            <comment id="15109837" author="stack" created="Thu, 21 Jan 2016 00:55:40 +0000"  >&lt;p&gt;Just a bit more detail showing that new write path is a little faster than what we had previous when doing a ycsb loading, a 50/50 and an 80% writes test case. Attached are patched and unpatched graphs. Also attached are the workloadw json output which shows better latency, more ops for patched case. Not a significant difference but simpler write path should help going forward.&lt;/p&gt;
</comment>
                            <comment id="15137929" author="eclark" created="Mon, 8 Feb 2016 22:54:39 +0000"  >&lt;p&gt;If we spend the time between append and sync putting the kv&apos;s in the concurrent skip list map, that&apos;s time that would otherwise be just wasted.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12779912" name="1.2.svg" size="1457144" author="stack" created="Wed, 30 Dec 2015 06:48:49 +0000"/>
                            <attachment id="12779911" name="1.2.v2.svg" size="1378955" author="stack" created="Wed, 30 Dec 2015 06:48:49 +0000"/>
                            <attachment id="12780427" name="50threads_ycsb.png" size="33156" author="stack" created="Tue, 5 Jan 2016 00:20:08 +0000"/>
                            <attachment id="12780022" name="all_under_lock.patch" size="3572" author="stack" created="Wed, 30 Dec 2015 18:26:44 +0000"/>
                            <attachment id="12780023" name="all_under_lock.svg" size="1378138" author="stack" created="Wed, 30 Dec 2015 18:26:44 +0000"/>
                            <attachment id="12780236" name="call_times_0-1_and_1-3_ycsb.png" size="31666" author="stack" created="Sun, 3 Jan 2016 15:38:35 +0000"/>
                            <attachment id="12782639" name="compare.png" size="101839" author="stack" created="Fri, 15 Jan 2016 23:41:00 +0000"/>
                            <attachment id="12782127" name="gc.png" size="36897" author="stack" created="Wed, 13 Jan 2016 20:44:52 +0000"/>
                            <attachment id="12780024" name="latencies.png" size="23264" author="stack" created="Wed, 30 Dec 2015 18:26:44 +0000"/>
                            <attachment id="12783481" name="nopatch.png" size="49623" author="stack" created="Thu, 21 Jan 2016 00:55:40 +0000"/>
                            <attachment id="12783482" name="notpatched.workloadw.80percentwrites.json" size="2018" author="stack" created="Thu, 21 Jan 2016 00:55:40 +0000"/>
                            <attachment id="12782128" name="ops.png" size="45009" author="stack" created="Wed, 13 Jan 2016 20:44:52 +0000"/>
                            <attachment id="12783480" name="patched.png" size="46745" author="stack" created="Thu, 21 Jan 2016 00:55:40 +0000"/>
                            <attachment id="12783483" name="patched.workloadw.80percentwrites.json" size="2022" author="stack" created="Thu, 21 Jan 2016 00:55:40 +0000"/>
                            <attachment id="12780025" name="writes.png" size="14650" author="stack" created="Wed, 30 Dec 2015 18:26:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>15.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 29 Dec 2015 00:59:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            44 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2qctr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>In here we perf tested a realignment of the write pipeline and mvcc handling.  Thought was that this work was a predicate for a general fix of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14460&quot; title=&quot;[Perf Regression] Merge of MVCC and SequenceId (HBASE-8763) slowed Increments, CheckAndPuts, batch operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14460&quot;&gt;&lt;strike&gt;HBASE-14460&lt;/strike&gt;&lt;/a&gt; (turns out, realignment of write path was not needed to fix the increment perf regression). The perf testing here made it so we were able to simplify writing. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-15158&quot; title=&quot;Change order in which we do write pipeline operations; do all under row locks!&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-15158&quot;&gt;&lt;strike&gt;HBASE-15158&lt;/strike&gt;&lt;/a&gt; was just committed. This work is done.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>