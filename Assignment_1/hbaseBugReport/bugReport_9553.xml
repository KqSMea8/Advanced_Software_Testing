<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:05:31 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9553/HBASE-9553.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9553] Pad HFile blocks to a fixed size before placing them into the blockcache</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9553</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;In order to make it easy on the garbage collector and to avoid full compaction phases we should make sure that all (or at least a large percentage) of the HFile blocks as cached in the block cache are exactly the same size.&lt;/p&gt;

&lt;p&gt;Currently an HFile block is typically slightly larger than the declared block size, as the block will accommodate that last KV on the block. The padding would be a ColumnFamily option. In many cases 100 bytes would probably be a good value to make all blocks exactly the same size (but of course it depends on the max size of the KVs).&lt;/p&gt;

&lt;p&gt;This does not have to be perfect. The more blocks evicted and replaced in the block cache are of the exact same size the easier it should be on the GC.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12668916">HBASE-9553</key>
            <summary>Pad HFile blocks to a fixed size before placing them into the blockcache</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Sep 2013 00:18:30 +0000</created>
                <updated>Sun, 8 Dec 2013 01:36:42 +0000</updated>
                            <resolved>Sun, 8 Dec 2013 01:36:42 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13769048" author="ndimiduk" created="Tue, 17 Sep 2013 01:02:24 +0000"  >&lt;p&gt;I think it&apos;s worth giving a try. Why not take it one step further and self-manage a slice of the BlockCache with this pre-defined block size, a la MemStoreLAB? Reserve, say, 80% of the BlockCache for slab management and leave the rest for the awkward-sized blocks.&lt;/p&gt;

&lt;p&gt;Instead of explicitly setting the buffer size, why not sample existing HFiles and calculate a guesstimate?&lt;/p&gt;</comment>
                            <comment id="13769121" author="lhofhansl" created="Tue, 17 Sep 2013 02:49:40 +0000"  >&lt;p&gt;The memstore stores small variable sized KVs so slab is essential there.&lt;br/&gt;
Not sure a slab is needed or even desired here, as we already have fixed (well after we do some simple padding) sized chunks for memory. The padding is simple and low overhead.&lt;/p&gt;

&lt;p&gt;Could calculate standard variation of the KV sizes and add that to the HFile&apos;s metadata. Then the padding could be a multiple of the standard deviation, subject to some maximum (like 2% of the hfile&apos;s blocksize or something).&lt;/p&gt;

&lt;p&gt;For testing, I would generate data with KVs drawn from a simple size distribution and then measure the GC as we evict/replace block in the block cache.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vasu.mariyala%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;vasu.mariyala@gmail.com&quot;&gt;Vasu Mariyala&lt;/a&gt;, this is the idea I was talking about earlier today.&lt;/p&gt;</comment>
                            <comment id="13769150" author="jmspaggi" created="Tue, 17 Sep 2013 03:32:09 +0000"  >&lt;p&gt;The idea seems correct. Looking forward to seeing the results. I&apos;m not sure we will get much improvements, but as Nick sais, it&apos;s worth giving at try.&lt;/p&gt;</comment>
                            <comment id="13769161" author="xieliang007" created="Tue, 17 Sep 2013 03:38:43 +0000"  >&lt;p&gt;probably it could beat the current implement&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; but imho, the off-heap solution(e.g. bucket cache with off-heap enabled) is still better than padding. per one of our internal benchmark, the off-heap block caching model could cut off the &quot;99% pencentile latency&quot; to a half, comparing the current on-heap block caching implement.&lt;/p&gt;

&lt;p&gt;ps: i remembered(unclear) hotspot internal could dynamically resize some stuff, like PLAB, to meet the diff obj sizes. maybe some vm expects could  give more explaination&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; of cause, i agree, the change from app code would be better than depends on hotspot&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13769273" author="anoop.hbase" created="Tue, 17 Sep 2013 07:00:18 +0000"  >&lt;p&gt;What abt when the on-cache encoding is enabled. Will the HFile block sizes can change much from block to block?&lt;/p&gt;</comment>
                            <comment id="13770316" author="tlipcon" created="Wed, 18 Sep 2013 02:13:15 +0000"  >&lt;p&gt;Interested to see the results here. When I tested block cache churn before, I didn&apos;t see heap fragmentation really crop up: &lt;a href=&quot;http://blog.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-2/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://blog.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-2/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For testing this improvement, it would be good to produce similar graphs of the CMS maximum chunk size metric from -XX:+PrintFLSStatistics output under some workload, and show that the improvement results in less fragmentation over time for at least some workload(s).&lt;/p&gt;</comment>
                            <comment id="13770389" author="mcorgan" created="Wed, 18 Sep 2013 03:50:14 +0000"  >&lt;p&gt;I don&apos;t know the code-level implementation details of any of the garbage collectors, but I imagine they do this to an extent already by dividing the heap into regions of different chunk sizes and placing blocks into slightly bigger slots than they need, effectively doing the padding by leaving empty space after each block.  Maybe not for tiny objects, but possibly for bigger ones.&lt;/p&gt;

&lt;p&gt;I also worry it would be hard to pick a single size to round all the blocks to because hbase allows configurable block size and encoding per table.  And even if all tables use the default block size and encoding, the encoding will result in different block sizes depending on the nature of the data in each table.&lt;/p&gt;

&lt;p&gt;It would be a good question for the Mechanical Sympathy mailing list.&lt;/p&gt;</comment>
                            <comment id="13771564" author="lhofhansl" created="Thu, 19 Sep 2013 03:39:34 +0000"  >&lt;p&gt;So I did some simple tests with just byte[]&apos;s:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;allocated chunks of 10000 64k+-100 bytes&lt;/li&gt;
	&lt;li&gt;allocated chunks of 10000 65636 (64k+100) bytes&lt;/li&gt;
	&lt;li&gt;allocated chunks of 10000 64k+-1000 bytes&lt;/li&gt;
	&lt;li&gt;allocated chunks of 10000 66536 (64k+1000) bytes&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Runs allocate and GC 10m of those 64k byte[]&apos;s.&lt;/p&gt;

&lt;p&gt;With various GC settings... There was no discernible difference, between the fixed and variable sized blocks.&lt;br/&gt;
Maybe I should have done this testing before I filed this idea, going to close as &quot;Invalid&quot;.&lt;/p&gt;</comment>
                            <comment id="13773174" author="apurtell" created="Fri, 20 Sep 2013 16:54:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe I should have done this testing before I filed this idea, going to close as &quot;Invalid&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This was an interesting issue though.&lt;/p&gt;

&lt;p&gt;A negative result is just as interesting and informative as a positive one. In some cases, more.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Sep 2013 01:02:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>348848</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 13 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1o5hb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>349146</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>