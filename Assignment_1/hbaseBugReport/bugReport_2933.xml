<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:05:58 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2933/HBASE-2933.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2933] Skip EOF Errors during Log Recovery</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2933</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;While testing a cluster, we hit upon the following assert during region assigment.  We were killing the master during a long run of splits.  We think what happened is that the HMaster was killed while splitting, woke up &amp;amp; split again.  If this happens, we will have 2 files: 1 partially written and 1 complete one.  Since encountering partial log splits upon Master failure is considered normal behavior, we should continue at the RS level if we encounter an EOFException &amp;amp; not an filesystem-level exception, even with skip.errors == false.&lt;/p&gt;

&lt;p&gt;2010-08-20 16:59:07,718 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Error opening MailBox_dsanduleac,57db45276ece7ce03ef7e8d9969eb189:99900000000008@facebook.com,1280960828959.7c542d24d4496e273b739231b01885e6.&lt;br/&gt;
java.io.EOFException&lt;br/&gt;
        at java.io.DataInputStream.readInt(DataInputStream.java:375)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.readRecordLength(SequenceFile.java:1902)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1932)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1837)&lt;br/&gt;
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1883)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.next(SequenceFileLogReader.java:121)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.next(SequenceFileLogReader.java:113)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.replayRecoveredEdits(HRegion.java:1981)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.replayRecoveredEdits(HRegion.java:1956)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.replayRecoveredEditsIfAny(HRegion.java:1915)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:344)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1490)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:1437)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:1345)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:619)&lt;br/&gt;
2010-08-20 16:59:07,719 ERROR org.apache.hadoop.hbase.regionserver.RSZookeeperUpdater: Aborting open of region 7c542d24d4496e273b739231b01885e6&lt;/p&gt;</description>
                <environment></environment>
        <key id="12472139">HBASE-2933</key>
            <summary>Skip EOF Errors during Log Recovery</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nspiegelberg">Nicolas Spiegelberg</assignee>
                                    <reporter username="nspiegelberg">Nicolas Spiegelberg</reporter>
                        <labels>
                    </labels>
                <created>Sat, 21 Aug 2010 01:07:15 +0000</created>
                <updated>Fri, 20 Nov 2015 12:42:34 +0000</updated>
                            <resolved>Sat, 16 Oct 2010 05:29:01 +0000</resolved>
                                                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12900957" author="tlipcon" created="Sat, 21 Aug 2010 01:54:00 +0000"  >&lt;p&gt;Hrm, isn&apos;t this basically the same as that other ticket about log splitting? ie if the master gets killed during splitting, the next master should completely resplit and the half-done log splits should be removed, right?&lt;/p&gt;</comment>
                            <comment id="12900967" author="nspiegelberg" created="Sat, 21 Aug 2010 03:36:32 +0000"  >&lt;p&gt;Linking related issues that I found.  @todd: I don&apos;t recall seeing one about deleting the old logs at Master startup.  I remember addressing it in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2337&quot; title=&quot;log recovery: splitLog deletes old logs prematurely&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2337&quot;&gt;&lt;del&gt;HBASE-2337&lt;/del&gt;&lt;/a&gt;, so may it didn&apos;t get properly ported to 0.90.  I agree that we should delete old split logs on master startup + split.  Should we also be making sure that any EOF exceptions don&apos;t force the region offline, especially if they are still archived?&lt;/p&gt;</comment>
                            <comment id="12902279" author="tlipcon" created="Wed, 25 Aug 2010 02:19:28 +0000"  >&lt;p&gt;I can&apos;t remember the particular JIRA either, but it seems to me that the regionserver shouldn&apos;t even get to the point of doing recovery if the logs haven&apos;t been completely recovered. ie the phases should be:&lt;/p&gt;

&lt;p&gt;1) Original RS is writing logs and dies&lt;br/&gt;
2) Master A notices failure and starts splitting logs. It gets halfway through writing region_1/oldlog&lt;br/&gt;
3) Master A dies&lt;br/&gt;
4) Master B takes over, and knows from ZK that RS&apos;s recovery is incomplete.&lt;br/&gt;
5) Master B should remove the half-written log split done by Master A, and try again from the start.&lt;/p&gt;

&lt;p&gt;ie no region server should attempt to open region 1 until the logs have been properly split. Thus, the RS should never see an EOFException on log recovery, since it indicates that log splitting is incomplete.&lt;/p&gt;</comment>
                            <comment id="12902306" author="streamy" created="Wed, 25 Aug 2010 05:22:39 +0000"  >&lt;p&gt;I believe this happened when a cluster was being forcibly shutdown in the middle of log splitting on the master.  The new master came up acting like a cluster startup not failover.  I&apos;m not even sure if this makes a difference or not in the current master but it might on the new master.  I guess in both cases we should be doing the same log splitting checks?&lt;/p&gt;</comment>
                            <comment id="12902612" author="tlipcon" created="Wed, 25 Aug 2010 20:16:03 +0000"  >&lt;p&gt;Yep - even with good working master failover, you might lose power on the cluster, in which case all the masters would die. We&apos;d have a &quot;clean startup&quot; but to not lose data we have to split &lt;b&gt;all&lt;/b&gt; the logs (woo!)&lt;/p&gt;</comment>
                            <comment id="12907088" author="stack" created="Wed, 8 Sep 2010 04:53:45 +0000"  >&lt;p&gt;Bringing into 0.90.  Need to write a test to ensure that new master removes old partially split logs if old master died mid-split; also make it so we don&apos;t die if RS gets EOF &amp;#8211; though this should never happen as Todd says if proper split &amp;#8211; but also we should keep going if we get something like IOE &quot;&quot;File is corrupt!&quot; (See below)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; readRecordLength() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (in.getPos() &amp;gt;= end) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -1;
      }
      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; length = in.readInt();
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (version &amp;gt; 1 &amp;amp;&amp;amp; sync != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp;
          length == SYNC_ESCAPE) {              &lt;span class=&quot;code-comment&quot;&gt;// process a sync entry
&lt;/span&gt;        in.readFully(syncCheck);                &lt;span class=&quot;code-comment&quot;&gt;// read syncCheck
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!Arrays.equals(sync, syncCheck))    &lt;span class=&quot;code-comment&quot;&gt;// check it
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;File is corrupt!&quot;&lt;/span&gt;);
        syncSeen = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (in.getPos() &amp;gt;= end) {
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; -1;
        }
        length = in.readInt();                  &lt;span class=&quot;code-comment&quot;&gt;// re-read length
&lt;/span&gt;      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        syncSeen = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
      }

      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; length;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12907092" author="stack" created="Wed, 8 Sep 2010 05:12:51 +0000"  >&lt;p&gt;Looking in logs I see this kinda thing:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2010-09-07 18:10:27,965 WARN org.apache.hadoop.hbase.regionserver.wal.HLog: Found existing old edits file. It could be the result of a previous failed split attempt. Deleting hdfs:&lt;span class=&quot;code-comment&quot;&gt;//sv4borg9:9000/hbase/api_access_token_stats_day/1845102219/recovered.edits/0000000068762427569, length=264167&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;.. so we&apos;re some cleanup of old split attempts.&lt;/p&gt;</comment>
                            <comment id="12914566" author="nspiegelberg" created="Fri, 24 Sep 2010 18:04:56 +0000"  >&lt;p&gt;Handles EOFE and the IOE that was mentioned by stack.  The SequenceFile.Reader has a few more IOEs, so this isn&apos;t 100% fail-proof.  The general problem we seem to have is that we need to differentiate between a Network IOE and a File Format IOE.  A File Format IOE is idempotent, where a Network IOE may not be.&lt;/p&gt;

&lt;p&gt;Network = we need to fail and let another server try to take over&lt;br/&gt;
FileFormat = our file was written or parsed incorrectly. retrying won&apos;t fix anything. We need to just open what we have and store the original file away for later analysis.&lt;/p&gt;</comment>
                            <comment id="12917105" author="stack" created="Fri, 1 Oct 2010 23:41:23 +0000"  >&lt;p&gt;Marking as patch available&lt;/p&gt;</comment>
                            <comment id="12917797" author="nspiegelberg" created="Mon, 4 Oct 2010 22:04:58 +0000"  >&lt;p&gt;Note that I created &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6986&quot; title=&quot;SequenceFile.Reader should distinguish between Network IOE and Parsing IOE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6986&quot;&gt;HADOOP-6986&lt;/a&gt; to fix all edge-cases of ParseExceptions in the SequenceFile.Reader.  I will create a new jira to address the edge-cases once this fix is in 0.20-append.&lt;/p&gt;</comment>
                            <comment id="12918152" author="nspiegelberg" created="Tue, 5 Oct 2010 20:36:12 +0000"  >&lt;p&gt;@Stack : This jira should be good to commit, right?  We can address the edge cases with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3081&quot; title=&quot;Log Splitting &amp;amp; Replay: Distinguish between Network IOE and Parsing IOE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3081&quot;&gt;&lt;del&gt;HBASE-3081&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12921637" author="stack" created="Sat, 16 Oct 2010 05:29:01 +0000"  >&lt;p&gt;@Nicolas Thanks for clarification.  Committed.  Thanks for the patch.&lt;/p&gt;</comment>
                            <comment id="15017286" author="lars_francke" created="Fri, 20 Nov 2015 12:42:34 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12459405">HBASE-2337</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12465884">HBASE-2643</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12475878">HBASE-3081</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12475809">HADOOP-6986</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12455505" name="HBASE-2933.patch" size="6604" author="nspiegelberg" created="Fri, 24 Sep 2010 18:04:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 21 Aug 2010 01:54:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26545</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hjwn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100487</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>