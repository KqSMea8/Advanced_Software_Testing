<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:06:19 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9648/HBASE-9648.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9648] collection one expired storefile causes it to be replaced by another expired storefile</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9648</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;There&apos;s a shortcut in compaction selection that causes the selection of expired store files to quickly delete.&lt;br/&gt;
However, there&apos;s also the code that ensures we write at least one file to preserve seqnum. This new empty file is &quot;expired&quot;, because it has no data, presumably.&lt;br/&gt;
So it&apos;s collected again, etc.&lt;br/&gt;
This affects 94, probably also 96.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12670327">HBASE-9648</key>
            <summary>collection one expired storefile causes it to be replaced by another expired storefile</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="jmspaggi">Jean-Marc Spaggiari</assignee>
                                    <reporter username="sershe">Sergey Shelukhin</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Sep 2013 18:07:14 +0000</created>
                <updated>Tue, 19 Aug 2014 06:33:46 +0000</updated>
                                                                            <component>Compaction</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13776583" author="jmspaggi" created="Tue, 24 Sep 2013 18:16:54 +0000"  >&lt;p&gt;Is the region really empty? From the logs provided by the user we can see this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
size=491.0; total size &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; store is 5.7m
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;491 bytes is very small, I agree, but might not be totally empty.&lt;/p&gt;</comment>
                            <comment id="13776868" author="jmspaggi" created="Tue, 24 Sep 2013 22:51:28 +0000"  >&lt;p&gt;Here are the details for the file which was causing the issue.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
jmspaggiari@t430s:~/workspace/hbase-0.94.10$ bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -m -s -v -f fca0882dc7624342a8f4fce4b89420ff 
13/09/24 14:54:09 INFO util.ChecksumType: Checksum can use java.util.zip.CRC32
Scanning -&amp;gt; fca0882dc7624342a8f4fce4b89420ff
13/09/24 14:54:09 INFO hfile.CacheConfig: Allocating LruBlockCache with maximum size 247.9m
13/09/24 14:54:09 ERROR metrics.SchemaMetrics: Inconsistent configuration. Previous configuration &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; using table name in metrics: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; configuration: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/09/24 14:54:09 WARN metrics.SchemaConfigured: Could not determine table and column family of the HFile path fca0882dc7624342a8f4fce4b89420ff. Expecting at least 5 path components.
13/09/24 14:54:09 WARN snappy.LoadSnappy: Snappy &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; library is available
13/09/24 14:54:09 INFO util.NativeCodeLoader: Loaded the &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library
13/09/24 14:54:09 INFO snappy.LoadSnappy: Snappy &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; library loaded
13/09/24 14:54:09 INFO compress.CodecPool: Got brand-&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; decompressor
Block index size as per heapsize: 336
reader=fca0882dc7624342a8f4fce4b89420ff,
    compression=snappy,
    cacheConf=CacheConfig:enabled [cacheDataOnRead=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;] [cacheDataOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheIndexesOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheBloomsOnWrite=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheEvictOnClose=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] [cacheCompressed=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;],
    firstKey=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;,
    lastKey=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;,
    avgKeyLen=0,
    avgValueLen=0,
    entries=0,
    length=491
Trailer:
    fileinfoOffset=56,
    loadOnOpenDataOffset=0,
    dataIndexCount=0,
    metaIndexCount=0,
    totalUncomressedBytes=489,
    entryCount=0,
    compressionCodec=SNAPPY,
    uncompressedDataIndexSize=0,
    numDataIndexLevels=1,
    firstDataBlockOffset=-1,
    lastDataBlockOffset=0,
    comparatorClassName=org.apache.hadoop.hbase.KeyValue$KeyComparator,
    majorVersion=2,
    minorVersion=0
Fileinfo:
    DATA_BLOCK_ENCODING = NONE
    DELETE_FAMILY_COUNT = \x00\x00\x00\x00\x00\x00\x00\x00
    EARLIEST_PUT_TS = \x7F\xFF\xFF\xFF\xFF\xFF\xFF\xFF
    MAJOR_COMPACTION_KEY = \x00
    MAX_SEQ_ID_KEY = 19978535453
    TIMERANGE = -1....-1
    hfile.AVG_KEY_LEN = 0
    hfile.AVG_VALUE_LEN = 0
Unable to retrieve the midkey
Bloom filter:
    Not present
Delete Family Bloom filter:
    Not present
Stats:
no data available &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; statistics
Scanned kv count -&amp;gt; 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13776877" author="jmspaggi" created="Tue, 24 Sep 2013 22:58:21 +0000"  >&lt;p&gt;So here is the idea.&lt;/p&gt;

&lt;p&gt;Since the file is empty, there is no TIMERANGE stored into the file. And therefor, the selectExpiredStoreFilesToCompact method will elect it for compaction.&lt;/p&gt;

&lt;p&gt;This patch is to validate that, if there is only a single empty file, we don&apos;t elect it for compaction.&lt;/p&gt;

&lt;p&gt;If there is more than one file, even if they are all empty, they still can be selected since it&apos;s better to have just a single one at the end instead of multiple empty files.&lt;/p&gt;

&lt;p&gt;Patch for trunk coming in a second.&lt;/p&gt;</comment>
                            <comment id="13776890" author="jmspaggi" created="Tue, 24 Sep 2013 23:07:05 +0000"  >&lt;p&gt;Patch for trunk for Hadoop QA and comments.&lt;/p&gt;</comment>
                            <comment id="13776905" author="sershe" created="Tue, 24 Sep 2013 23:18:58 +0000"  >&lt;p&gt;I think in the reported case there was more than one file in store (and thus the candidate list), it&apos;s that it was selecting one expired file.&lt;br/&gt;
Judging by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6059&quot; title=&quot;Replaying recovered edits would make deleted data exist again&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6059&quot;&gt;&lt;del&gt;HBASE-6059&lt;/del&gt;&lt;/a&gt; description and comments, we actually don&apos;t have to generate a new file unless we are talking about the highest-seqid file in the region (which also implies not removing the last file).&lt;br/&gt;
So it may make sense to allow lazy-writer code to run if there&apos;re files remaining in store (which would presumably mean for ever minor compactions). In that case not running expired check on single last file would be enough.&lt;/p&gt;</comment>
                            <comment id="13776913" author="jmspaggi" created="Tue, 24 Sep 2013 23:29:25 +0000"  >&lt;p&gt;Indeed. You&apos;re right. There was way more files than just one. I don&apos;t know why I ignored that.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure to get how it&apos;s related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6059&quot; title=&quot;Replaying recovered edits would make deleted data exist again&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6059&quot;&gt;&lt;del&gt;HBASE-6059&lt;/del&gt;&lt;/a&gt;. Are you suggesting to &quot;simply&quot; remove the test and do something like that? So if any other file need to be compacted, it will be. I&apos;m not sure we need to add any check for the last store.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; ArrayList&amp;lt;StoreFile&amp;gt; selectExpiredStoreFiles(
      ArrayList&amp;lt;StoreFile&amp;gt; candidates, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; maxExpiredTimeStamp) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (candidates == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || candidates.size() == 0) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;

    ArrayList&amp;lt;StoreFile&amp;gt; expiredStoreFiles = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;

    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (StoreFile storeFile : candidates) {
      &lt;span class=&quot;code-comment&quot;&gt;// If the storeFile is empty, then there is no need to compact it.
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// Empty files don&apos;t have time range information.
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((storeFile.getReader().getEntries() &amp;gt; 0)
          &amp;amp;&amp;amp; (storeFile.getReader().getMaxTimestamp() &amp;lt; maxExpiredTimeStamp)) {
        LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Deleting the expired store file by compaction: &quot;&lt;/span&gt; + storeFile.getPath()
            + &lt;span class=&quot;code-quote&quot;&gt;&quot; whose maxTimeStamp is &quot;&lt;/span&gt; + storeFile.getReader().getMaxTimestamp()
            + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; the max expired timestamp is &quot;&lt;/span&gt; + maxExpiredTimeStamp);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (expiredStoreFiles == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          expiredStoreFiles = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;StoreFile&amp;gt;();
        }
        expiredStoreFiles.add(storeFile);
      }
    }

    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; expiredStoreFiles;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Also here is the list of files for reference.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-rw-------   1 hadoop supergroup       2194 2013-09-21 14:32 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/014ead47a9484d67b55205be16802ff1
-rw-------   1 hadoop supergroup      31321 2013-09-24 05:49 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/1305d625bd4a4be39a98ae4d91a66140
-rw-------   1 hadoop supergroup       1350 2013-09-24 10:31 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/1352e0828f974f08b1f3d7a9dff04abd
-rw-------   1 hadoop supergroup       4194 2013-09-21 10:38 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/17a546064bd840619816809ae0fc4c49
-rw-------   1 hadoop supergroup       1061 2013-09-20 22:55 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/1cb3df115da244288bd076968ab4ccf6
-rw-------   1 hadoop supergroup       1375 2013-08-24 10:17 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/1e41a96c49fc4e5ab59392d26935978d
-rw-------   1 hadoop supergroup      96296 2013-08-26 15:48 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/22d72fd897e34424b5420a96483a571e
-rw-------   1 hadoop supergroup       1356 2013-08-26 15:23 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/25fee1ffadbe42549bd0b7b13d782b72
-rw-------   1 hadoop supergroup       6229 2013-09-21 11:14 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/26289c777ec14dc5b7021b4d6b1050c5
-rw-------   1 hadoop supergroup       1223 2013-09-21 02:42 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/2757d7ba9c8448d6a3d5d46bd4d59758
-rw-------   1 hadoop supergroup    5302248 2013-08-24 02:22 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/2ec40943787246ea983608dd6591db24
-rw-------   1 hadoop supergroup       1596 2013-08-24 03:37 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/3157fd1cabe4483aaa4d9a21f75e4d88
-rw-------   1 hadoop supergroup       1338 2013-09-22 04:25 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/36b0f80a4a7b492f97358b64d879a2df
-rw-------   1 hadoop supergroup       3264 2013-09-21 12:05 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/39e249fcb532400daed73aed6689ceeb
-rw-------   1 hadoop supergroup       4549 2013-09-21 08:56 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/3bc9e2a566ad460a9b0ed336b2fb5ed9
-rw-------   1 hadoop supergroup       1630 2013-09-22 03:22 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/48026d08aae748f08aad59e4eea903be
-rw-------   1 hadoop supergroup     105395 2013-09-20 21:12 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/53198825f085401cbbd4322faa0e3aae
-rw-------   1 hadoop supergroup       3859 2013-09-21 09:09 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/71c2f9b2a8ff4c049fcc5a9a22af5cfe
-rw-------   1 hadoop supergroup     311688 2013-09-20 21:12 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/97ff16d6da974c30835c6e0acc7c737a
-rw-------   1 hadoop supergroup       1897 2013-08-24 08:43 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/a172d7577641434d82abcce88a433213
-rw-------   1 hadoop supergroup       3380 2013-09-21 13:04 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/be678e5c60534c65a012a798fbc7e284
-rw-------   1 hadoop supergroup      43710 2013-09-22 02:15 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/e2508a23acf1491f9d38b9a8594e41e8
-rw-------   1 hadoop supergroup       5409 2013-09-21 10:10 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/f432846182714b93a1c3df0f5835c09b
-rw-------   1 hadoop supergroup        491 2013-09-24 11:18 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/f7d8669cf7a047b98c1d3b13c16cfaec
-rw-------   1 hadoop supergroup        491 2013-09-24 11:18 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/fa1b8f6cc9584eb28365dcd8f10d3f0a
-rw-------   1 hadoop supergroup        491 2013-09-13 11:28 /hbase/compound3/5ab5fdfcf2aff2633e1d6d5089c96aa2/d/fca0882dc7624342a8f4fce4b89420ff
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13777081" author="sershe" created="Wed, 25 Sep 2013 02:32:45 +0000"  >&lt;p&gt;If you look at the code now (at least in 94 the archeological record survives) it has provisions for creating the writer for compaction output lazily (even a comment about it iirc), so that if there&apos;s no data, there&apos;s no file; but then below it goes and says, we need to create writer anyway because blah-blah see that jira.&lt;br/&gt;
So when the original problem on the thread picks one file to remove, this code says oh no I need to create the empty file anyway, and creates it; after which the expired-file-selection code picks the new file, as a single file, to remove, and it creates another empty file, forever. Expired file compaction is supposed to be fast so it pre-empts any real compaction.&lt;br/&gt;
What I&apos;m saying is that this empty-file-creation might not always be necessary, judging by that jira. All we want to avoid is losing the latest-used seqNum in the store, which means we can have no-output compaction as long as we are not dropping the file with the last seqNum. So the original problem from the thread will go away if that was done, deletion of some random expired file would just nuke it. It will also be generally useful to not create these blank files as often.&lt;br/&gt;
The only edge case remaining is when this file is the file with the last seqNum (I incorrectly said above that it is when it&apos;s the only file), in which case expired file thing should not pick it.&lt;/p&gt;</comment>
                            <comment id="13777092" author="hadoopqa" created="Wed, 25 Sep 2013 02:53:46 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12604906/HBASE-9648-v0-trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12604906/HBASE-9648-v0-trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7364//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13777147" author="jmspaggi" created="Wed, 25 Sep 2013 04:46:06 +0000"  >&lt;p&gt;Ok. I see your point.&lt;/p&gt;

&lt;p&gt;In trunk, the code moved to DefaultCompactor&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-comment&quot;&gt;// Create the writer even &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; no kv(Empty store file is also ok),
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// because we need record the max seq id &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the store file, see HBASE-6059
&lt;/span&gt;        writer = store.createWriterInTmp(fd.maxKeyCount, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.compactionCompression, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,
            fd.maxMVCCReadpoint &amp;gt;= smallestReadPoint, fd.maxTagsLength &amp;gt; 0);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So basically, we need to avoid creating this empty file if it doesn&apos;t have the max seq id. The thing is, we don&apos;t have this information there.&lt;/p&gt;

&lt;p&gt;However, the modification to RatioBasedcompactionPolicy.selectExpiredStoreFiles should not be difficult.&lt;/p&gt;

&lt;p&gt;... Ok. I think I found something. I will draft that and post it tomorrow morning for your review.&lt;/p&gt;</comment>
                            <comment id="13777590" author="jmspaggi" created="Wed, 25 Sep 2013 15:06:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;, something like that? I&apos;m not 100% sure it&apos;s required to loop over the storeFiles. If they are ordered, then we can just pickup the last one... Same for the requests files. But the idea is here. Wondering is this is what you had in minds. Triggering Hadoop QA in the meantime to see if it works. &lt;/p&gt;</comment>
                            <comment id="13777725" author="hadoopqa" created="Wed, 25 Sep 2013 16:44:26 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12605019/HBASE-9648-v1-trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12605019/HBASE-9648-v1-trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/7372//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13778235" author="sershe" created="Wed, 25 Sep 2013 23:40:20 +0000"  >&lt;p&gt;For the expired selection check, candidate list is not the same as list of files in store.&lt;br/&gt;
For the other check logic for last file is ok, presence of data in input doesn&apos;t mean that there&apos;d be anything in the output... I wonder if simpler check is possible when selecting. I will be in some meetings, let me thing about it.&lt;br/&gt;
From code perspective looks ok. Can you create a test?&lt;/p&gt;</comment>
                            <comment id="13778369" author="lhofhansl" created="Thu, 26 Sep 2013 02:16:02 +0000"  >&lt;p&gt;Can we just not do the immediate deletion of the HFile when getMaxTimestamp() returns -1?&lt;/p&gt;</comment>
                            <comment id="13778470" author="jmspaggi" created="Thu, 26 Sep 2013 04:38:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the expired selection check, candidate list is not the same as list of files in store.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I will change to comment to say &quot;If the last candidate&quot; instead...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;presence of data in input doesn&apos;t mean that there&apos;d be anything in the output&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I agree. Maybe everything will be deleted by the compaction, TTL, etc. But worst case, that will write an empty file wich will be avoided at the next iteration.&lt;/p&gt;

&lt;p&gt;I will take a look how we can implement a test for that.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Can we just not &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; the immediate deletion of the HFile when getMaxTimestamp() returns -1?
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can, but are they not going to stay there for ever if we do that? Or is another process going to clean them later?&lt;/p&gt;
</comment>
                            <comment id="13778480" author="lhofhansl" created="Thu, 26 Sep 2013 04:52:28 +0000"  >&lt;p&gt;I&apos;d have to study the code a bit more, but I thought it just means that they&apos;ll be removed after the compaction, rather than before (as part of the compaction selection). On the mailing list it was reported that disabling this feature fixed the problem. (See hbase.store.delete.expired.storefile in Store.java in 0.94)&lt;/p&gt;</comment>
                            <comment id="13779054" author="sershe" created="Thu, 26 Sep 2013 18:16:05 +0000"  >&lt;p&gt;Yeah, that is what we recommended &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;br/&gt;
Deleting the file definitely makes sense, we can shortcut and archive it immediately without any compaction.&lt;br/&gt;
At that point there&apos;s also no need to do convoluted checks because we also have full view of all files.&lt;/p&gt;</comment>
                            <comment id="13779314" author="lhofhansl" created="Thu, 26 Sep 2013 22:23:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;, are you agreeing? Can&apos;t quite parse that out &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Basically what I was saying was that we skip the early delete optimization for empty storefiles. It just means they&apos;ll get deleted after the compaction, but apparently without the issue we&apos;re seeing here.&lt;/p&gt;</comment>
                            <comment id="13782332" author="sershe" created="Mon, 30 Sep 2013 22:12:35 +0000"  >&lt;p&gt;Oh. I meant we can just nuke them immediately without going thru the entire compaction pipeline.&lt;br/&gt;
This would solve the problem much simpler (either your approach or mine), we don&apos;t even have to scan them.&lt;br/&gt;
The last file cannot be deleted though, even if expired, to preserve seqNum&lt;/p&gt;</comment>
                            <comment id="13782333" author="sershe" created="Mon, 30 Sep 2013 22:13:25 +0000"  >&lt;p&gt;Or do you mean the code to delete after compaction already exists? &lt;/p&gt;</comment>
                            <comment id="13782406" author="lhofhansl" created="Mon, 30 Sep 2013 23:12:53 +0000"  >&lt;p&gt;I might be misunderstanding the issue...&lt;br/&gt;
When hbase.store.delete.expired.storefile is true an old storefile is nuked immediately as part of the selection process (rather than being compacted and then deleted). The issue is when we only have a single store file left and it is expired, in that case we nuke, but write a new (empty) one to keep the sequenceId; this file is then nuked (because we return -1 from getMaxTimestamp() for empty files), and from here we repeat the same cycle. Another apparent issue is the ratio based selection with empty files.&lt;/p&gt;</comment>
                            <comment id="13782415" author="sershe" created="Mon, 30 Sep 2013 23:27:23 +0000"  >&lt;p&gt;Yeah, that is the issue. However, it&apos;s not just deleted, it goes thru compaction with a request for one file, then it&apos;s at least nominally scanned (probably it skips the entire file in scanner), committed, etc. etc.&lt;br/&gt;
We could just archive it straight away, no compaction or anything.&lt;/p&gt;

&lt;p&gt;The fixes previously discussed here were fixing the special case handling for the creation of new file, as we don&apos;t really need to do it as often as we do. &lt;/p&gt;</comment>
                            <comment id="13783155" author="sershe" created="Tue, 1 Oct 2013 17:34:08 +0000"  >&lt;p&gt;let me try to make example patch&lt;/p&gt;</comment>
                            <comment id="13783157" author="jmspaggi" created="Tue, 1 Oct 2013 17:38:55 +0000"  >&lt;p&gt;Will be nice also to be able to reproduce this issue, to test a potential fix.&lt;/p&gt;</comment>
                            <comment id="13783563" author="sershe" created="Wed, 2 Oct 2013 01:26:03 +0000"  >&lt;p&gt;Actually we kind of already do, in testDeleteExpiredStoreFiles in TestStore.&lt;br/&gt;
It expires 4 files and verifies there are still 4 file &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13783564" author="sershe" created="Wed, 2 Oct 2013 01:28:48 +0000"  >&lt;p&gt;*on first loop iteration&lt;/p&gt;</comment>
                            <comment id="13783581" author="sershe" created="Wed, 2 Oct 2013 02:12:49 +0000"  >&lt;p&gt;preliminary patch&lt;/p&gt;</comment>
                            <comment id="13784040" author="jmspaggi" created="Wed, 2 Oct 2013 14:57:15 +0000"  >&lt;p&gt;Ok. For the test, I see. We are testing it, but it&apos;s working as expected. We creates 4 files which are not empty and we try to compact them. We don&apos;t have the corner case where those files are empty, and when there is only one single file in the store, etc.&lt;/p&gt;

&lt;p&gt;So if I take the test from your patch but not the rest, it should be failing, right? Overall the patch looks good. There is some small things but we will keep that for the final version &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13784187" author="sershe" created="Wed, 2 Oct 2013 17:29:18 +0000"  >&lt;p&gt;Well, the test would fail but not just due to logical reasons, also because the flow changes, there&apos;s no longer real compaction when this happens, it just archives the files. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt; wdyt?&lt;/p&gt;</comment>
                            <comment id="13784197" author="jmspaggi" created="Wed, 2 Oct 2013 17:39:41 +0000"  >&lt;p&gt;But a good test should not really worry about the flow, right? That&apos;s the goal of it. I will try to reproduce that without the patch, and try it with and see...&lt;/p&gt;</comment>
                            <comment id="13784202" author="sershe" created="Wed, 2 Oct 2013 17:45:32 +0000"  >&lt;p&gt;Well, I mean the logic changed. The test was checking that compactions happen, and they no longer do&lt;/p&gt;</comment>
                            <comment id="13788393" author="sershe" created="Mon, 7 Oct 2013 18:23:57 +0000"  >&lt;p&gt;ping? any other opinion on this?&lt;br/&gt;
We can also file a bug to limit empty file creation as per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt; patch, or do it the other way around.&lt;/p&gt;</comment>
                            <comment id="13800658" author="jmspaggi" created="Mon, 21 Oct 2013 13:48:42 +0000"  >&lt;p&gt;Ping again &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Should we move forward with what I proposed initially and open another JIRA if we want to go further?&lt;/p&gt;</comment>
                            <comment id="13800859" author="sershe" created="Mon, 21 Oct 2013 17:39:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt; you were one of the people I was pinging &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Any opinion, incl. on the above patch?&lt;/p&gt;</comment>
                            <comment id="13807297" author="sershe" created="Mon, 28 Oct 2013 22:10:00 +0000"  >&lt;p&gt;la la la&lt;/p&gt;</comment>
                            <comment id="13807398" author="jmspaggi" created="Mon, 28 Oct 2013 22:15:39 +0000"  >&lt;p&gt;Sorry busy because of Strata &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I will have may more time next week (starting Thursday/Friday this week)...&lt;/p&gt;</comment>
                            <comment id="13839201" author="sershe" created="Wed, 4 Dec 2013 18:53:01 +0000"  >&lt;p&gt;stumbled upon this jira (not bug &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) again... do you want to go with either patch&lt;/p&gt;</comment>
                            <comment id="13842202" author="jmspaggi" created="Sat, 7 Dec 2013 12:39:49 +0000"  >&lt;p&gt;So. Back on this JIRA &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I think patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9648&quot; title=&quot;collection one expired storefile causes it to be replaced by another expired storefile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9648&quot;&gt;HBASE-9648&lt;/a&gt;-v1-trunk.patch can fix this issue the user faced on the mailing list.  It basically do what need to be done to avoid this from the first level.&lt;/p&gt;

&lt;p&gt;It passed Hadoop QA, but I can also port it to 0.94 and give it a bigger try on my own cluster...&lt;/p&gt;</comment>
                            <comment id="13845948" author="sershe" created="Thu, 12 Dec 2013 01:01:11 +0000"  >&lt;p&gt;Makes sense... I can move the other patch for different jira. Technically, in compaction policy, last candidate is not necessarily the latest file in store as some files might not be candidates (for example, already compacting if there are multiple compaction threads). But it should be ok. &lt;br/&gt;
Can you resubmit the patch for QA to kick in again? Thanks.&lt;/p&gt;</comment>
                            <comment id="13846494" author="jmspaggi" created="Thu, 12 Dec 2013 17:50:39 +0000"  >&lt;p&gt;Sure. I will rebase (if required) and re-submit later today (this evening probably).&lt;/p&gt;</comment>
                            <comment id="13846566" author="sershe" created="Thu, 12 Dec 2013 18:37:47 +0000"  >&lt;p&gt;Rebased the other patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10141&quot; title=&quot;instead of putting expired store files thru compaction, just archive them&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10141&quot;&gt;&lt;del&gt;HBASE-10141&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13847560" author="hadoopqa" created="Fri, 13 Dec 2013 15:02:16 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12618595/HBASE-9648-v2-trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12618595/HBASE-9648-v2-trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8157//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13847797" author="sershe" created="Fri, 13 Dec 2013 19:14:43 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((requestMaxSequenceId == storeMaxSequenceId) || (requestEntries &amp;gt; 0)) writer =
+            store.createWriterInTmp(fd.maxKeyCount, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.compactionCompression, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,
+              fd.maxMVCCReadpoint &amp;gt;= smallestReadPoint, fd.maxTagsLength &amp;gt; 0);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Nit: please add braces.&lt;/p&gt;

&lt;p&gt;Other than that, seeing if inputs have entries is not technically speaking valid because coproc can replace scanners. &lt;br/&gt;
Should it rather create writer either if last seqId is being compacted there, or on first record from the scanner, if needed?&lt;/p&gt;</comment>
                            <comment id="13847827" author="jmspaggi" created="Fri, 13 Dec 2013 19:35:55 +0000"  >&lt;p&gt;Or can we look at the entries before we trigger the coprocessors? That way we are sure they will not modify the scanner? and we keep the writer creation the way it is in the patch?&lt;/p&gt;</comment>
                            <comment id="13847934" author="sershe" created="Fri, 13 Dec 2013 21:43:34 +0000"  >&lt;p&gt;coproc takes a scanner (StoreScanner of all files) and produces a scanner. What do you mean?&lt;/p&gt;</comment>
                            <comment id="13847947" author="jmspaggi" created="Fri, 13 Dec 2013 21:55:52 +0000"  >&lt;p&gt;Hum. Looking at it again, I might be missing something.&lt;/p&gt;

&lt;p&gt;Even if coprocessors can replace the scanner, that doesn&apos;t change the list of store files, right? Or can the scanner make the compactor looking at another set of store files?&lt;/p&gt;</comment>
                            <comment id="13847970" author="sershe" created="Fri, 13 Dec 2013 22:10:26 +0000"  >&lt;p&gt;The scanner created by coproc can hypothetically do anything. Actually I am kind of ambivalent on that one. Maybe we should just document it, I suspect coprocs usually don&apos;t generate new KVs out of no input KVs.&lt;br/&gt;
But, is it difficult to create writer on first entry? If it&apos;s easy, any reason to not do it?&lt;/p&gt;</comment>
                            <comment id="13853550" author="sershe" created="Fri, 20 Dec 2013 01:03:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmspaggi&quot; class=&quot;user-hover&quot; rel=&quot;jmspaggi&quot;&gt;Jean-Marc Spaggiari&lt;/a&gt; ping?&lt;/p&gt;</comment>
                            <comment id="13853561" author="jmspaggi" created="Fri, 20 Dec 2013 01:18:56 +0000"  >&lt;p&gt;OK then what&apos;s about something like this? Just pushing it here as a suggestion. Can we just look at the stores before the coprocs get called so we are sure they don&apos;t mess anything?&lt;/p&gt;</comment>
                            <comment id="13853690" author="hadoopqa" created="Fri, 20 Dec 2013 05:34:12 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12619721/HBASE-9648-v3-trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12619721/HBASE-9648-v3-trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
  ATTACHMENT ID: 12619721&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.1&lt;/font&gt;.  The patch compiles against the hadoop 1.1 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/8238//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13854374" author="sershe" created="Fri, 20 Dec 2013 18:10:00 +0000"  >&lt;p&gt;Just clarifying, why is it hard to create writer is needed? For the case when there are seemingly no KVs when you were creating the writer. I think coprocs cannot screw up the seqIds, because set of files is already chosen, so that should be ok&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12734940">HBASE-11776</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12684309">HBASE-10141</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12604902" name="HBASE-9648-v0-0.94.patch" size="932" author="jmspaggi" created="Tue, 24 Sep 2013 22:58:21 +0000"/>
                            <attachment id="12604906" name="HBASE-9648-v0-trunk.patch" size="1016" author="jmspaggi" created="Tue, 24 Sep 2013 23:07:05 +0000"/>
                            <attachment id="12605019" name="HBASE-9648-v1-trunk.patch" size="3973" author="jmspaggi" created="Wed, 25 Sep 2013 15:04:34 +0000"/>
                            <attachment id="12618595" name="HBASE-9648-v2-trunk.patch" size="3740" author="jmspaggi" created="Fri, 13 Dec 2013 13:37:36 +0000"/>
                            <attachment id="12619721" name="HBASE-9648-v3-trunk.patch" size="4032" author="jmspaggi" created="Fri, 20 Dec 2013 01:18:56 +0000"/>
                            <attachment id="12606240" name="HBASE-9648.patch" size="16894" author="sershe" created="Wed, 2 Oct 2013 02:12:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 24 Sep 2013 18:16:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>350156</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1odiv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>350450</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Rebased patch attached to trigger Hadoop QA</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>