<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:03:06 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9291/HBASE-9291.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9291] Enable client to setAttribute that is sent once to each region server</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9291</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently a Scan and Mutation allow the client to set its own attributes that get passed through the RPC layer and are accessible from a coprocessor. This is very handy, but breaks down if the amount of information is large, since this information ends up being sent again and again to every region. Clients can work around this with an endpoint &quot;pre&quot; and &quot;post&quot; coprocessor invocation that:&lt;br/&gt;
1) sends the information and caches it on the region server in the &quot;pre&quot; invocation&lt;br/&gt;
2) invokes the Scan or sends the batch of Mutations, and then&lt;br/&gt;
3) removes it in the &quot;post&quot; invocation.&lt;br/&gt;
In this case, the client is forced to identify all region servers (ideally, all region servers that will be involved in the Scan/Mutation), make extra RPC calls, manage the caching of the information on the region server, age-out the information (in case the client dies before step (3) that clears the cached information), and must deal with the possibility of a split occurring while this operation is in-progress.&lt;/p&gt;

&lt;p&gt;Instead, it&apos;d be much better if an attribute could be identified as a &quot;region server&quot; attribute in OperationWithAttributes and the HBase RPC layer would take care of doing the above.&lt;/p&gt;

&lt;p&gt;The use case where the above are necessary in Phoenix include:&lt;br/&gt;
1) Hash joins, where the results of the smaller side of a join scan are packaged up and sent to each region server, and&lt;br/&gt;
2) Secondary indexing, where the metadata of knowing a) which column family/column qualifier pairs and b) which part of the row key contributes to which indexes are sent to each region server that will process a batched put.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12664906">HBASE-9291</key>
            <summary>Enable client to setAttribute that is sent once to each region server</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="giacomotaylor">James Taylor</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 19:24:28 +0000</created>
                <updated>Tue, 7 Jan 2014 19:53:00 +0000</updated>
                                                                            <component>IPC/RPC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13748281" author="anoop.hbase" created="Fri, 23 Aug 2013 04:44:44 +0000"  >&lt;p&gt;Now for Phoenix scan, there are many attributes being passed via the Scan#setAttribute..  So this will be going with every RPC call (openScanner, next...)&lt;/p&gt;

&lt;p&gt;Region level passing only once is fine James?  The use case is very much with Scan only.  So how about having a openAttrs in scan rather than just attrs?  The attrs as now, will be passed with every RPC.  But the open attrs will be passed only when the request from client side is for open scanner. These attrs can be cached along with the RegionScanner against the scannedId.  (In Trunk we already have a RegionScannerHolder object in which we can save other info like attrs also)&lt;/p&gt;

&lt;p&gt;So this is not like pass only once for a RS, but pass for a region. &lt;/p&gt;

&lt;p&gt;If this looks fine with you, I can take up this and give a patch. (If u started working with this already, pls go ahead)  What do u say James?&lt;/p&gt;</comment>
                            <comment id="13748382" author="giacomotaylor" created="Fri, 23 Aug 2013 08:09:54 +0000"  >&lt;p&gt;That&apos;s a good point about these attributes going over every RPC call, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, but I&apos;m not too worried about these ones because the amount of information is pretty small.&lt;/p&gt;

&lt;p&gt;For the use cases I mentioned, especially with Hash Joins, the information will potentially be huge. The other case, secondary indexes, the information is not huge, but it&apos;s big enough that I wouldn&apos;t want to include it on every single Put.&lt;/p&gt;

&lt;p&gt;For both these cases, it&apos;d be a cache at the RegionServer level.  All the regions would get this information from this cache.&lt;/p&gt;</comment>
                            <comment id="13748396" author="anoop.hbase" created="Fri, 23 Aug 2013 08:40:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;especially with Hash Joins, the information will potentially be huge&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes there some thing like call once for a RS and cache there will be very much required. The smaller table data which we need to pass and store at RS can be really big..&lt;/p&gt;</comment>
                            <comment id="13748944" author="apurtell" created="Fri, 23 Aug 2013 20:02:11 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The use case where the above are necessary in Phoenix include:&lt;br/&gt;
1) Hash joins, where the results of the smaller side of a join scan are packaged up and sent to each region server, and&lt;br/&gt;
2) Secondary indexing, where the metadata of knowing a) which column family/column qualifier pairs and b) which part of the row key contributes to which indexes are sent to each region server that will process a batched put.&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;br/&gt;
For both these cases, it&apos;d be a cache at the RegionServer level. All the regions would get this information from this cache. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m wondering if any HBase changes are needed. Can you create an Endpoint, call it first to transmit the large data along with a &quot;join ID&quot;, and then pass the join ID only on the operationAttribute, that your Observer(s) would look for, and finally manage that RegionServer level cache with a singleton for that purpose? Now as a consequence there would be the additional round trip for the Exec call, but given the data you want to send over and cache for many additional invocations is large, the overhead would be small.&lt;/p&gt;</comment>
                            <comment id="13860510" author="apurtell" created="Thu, 2 Jan 2014 18:22:12 +0000"  >&lt;p&gt;Copied from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6104?focusedCommentId=13860505&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13860505:&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-6104?focusedCommentId=13860505&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13860505:&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What prevents your observer from taking the data in an attribute of the first mutation presented and applying it on a regionserver level? Whether your observer does something locally on the region or globally on the regionserver in response to an attribute is up to you. LarsH put in state sharing for region observers in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6505&quot; title=&quot;Allow shared RegionObserver state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6505&quot;&gt;&lt;del&gt;HBASE-6505&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13860654" author="apurtell" created="Thu, 2 Jan 2014 19:41:46 +0000"  >&lt;p&gt;Coped from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6104?focusedCommentId=13860623&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13860623:&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-6104?focusedCommentId=13860623&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13860623:&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It&apos;s about conserving network bandwidth - we don&apos;t want to take the hit of transferring the same data between client and server multiple times. For example, with secondary indexing, we&apos;d be tacking on data for every Put - if you have a batch of 10,000, that&apos;s a lot of extra data. We could try to figure out which Put is the &quot;first one&quot; for each region, but what if a split occurs after we figure this out &#8211; this seems too brittle.&lt;br/&gt;
In the case of a Hash Join, we&apos;d be sending over the compressed results of a scan that ran over the smaller table (which gets joined against in a coprocessor when the scan over the other table is ran). This can become very large - imagine you&apos;re joining against a table with 10M rows. We would not want to send this data for every region of the region server (or even multiple times per region depending on how the scan gets parallelized on the client).&lt;/p&gt;</comment>
                            <comment id="13860731" author="apurtell" created="Thu, 2 Jan 2014 20:33:07 +0000"  >&lt;p&gt;First let me clarify my above second suggestion: We could hang a map accessible to all CPs in the RS off of RegionServerServices as like was done for the region level in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6505&quot; title=&quot;Allow shared RegionObserver state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6505&quot;&gt;&lt;del&gt;HBASE-6505&lt;/del&gt;&lt;/a&gt;. Then the client would provide the (large) state as an attribute on only the first mutation sent to each regionserver. (More on this below.) The CP would observe the attribute and apply it to RS-level shared state. Then the mutation and subsequent mutations could be processed referring to the updated RS-level state. &lt;/p&gt;

&lt;p&gt;The client side is tricky.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We could try to figure out which Put is the &quot;first one&quot; for each region, but what if a split occurs after we figure this out &#8211; this seems too brittle.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If we introduce a new client API to the effect of &quot;send one RPC to each RS&quot;, then this amounts to a modified coprocessor endpoint execution, but with an invocation target that is a singleton to each RS, and should be subject to the same security considerations. Passing an attribute on the first put to a RS sidesteps the need for EXEC grants (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6104&quot; title=&quot;Require EXEC permission to call coprocessor endpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6104&quot;&gt;&lt;del&gt;HBASE-6104&lt;/del&gt;&lt;/a&gt;) on any endpoint invocation target, which is what sounds like the goal you are after.&lt;/p&gt;

&lt;p&gt;Whether an endpoint invocation or a mutation, we have the same issue that the local knowledge of cluster state can at any point be stale. Live servers can come and go, and regions can move around, and there is no transactional state update protocol running between clients and servers for updating this information. Even if there were, cluster topology can change mid flight. A &quot;send one RPC to each RS&quot; API could miss a newly onlined server that came up after the call(s) started and yet opened some relevant regions asynchronously. &lt;/p&gt;

&lt;p&gt;Whether trying to figure out which put is the first for a RS, or selecting keys for a set of coprocessor endpoints such that you only invoke one per RS, or using a new &quot;send one RPC to each RS&quot;, on the server you&apos;d have to handle the same set of issues, right? There could be 0, 1, or ~2 large data transfers per RS:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;0 if a new server is onlined and regions are assigned after the put or &quot;send one RPC to each RS&quot; calls are in progress&lt;/li&gt;
	&lt;li&gt;1 if the cluster topology is unchanged over the entire client action&lt;/li&gt;
	&lt;li&gt;~2 if a region is moved or split, or even in the case of one-RPC-per-server if there is a RPC retry on account of the failed transmission back to the client of a server side success indication&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I wouldn&apos;t use the word brittle. &quot;Messy&quot; is better. It always is.&lt;/p&gt;</comment>
                            <comment id="13860763" author="jamestaylor" created="Thu, 2 Jan 2014 21:13:53 +0000"  >&lt;p&gt;For the sending of the cache for Put operations, there needs to be a guarantee that the Region Server has the data being cached prior to any calling of the coprocessor hooks on the server-side. If this data is added to the first Put for each region server, is there any guarantee that one of the other regions isn&apos;t processed first (since these are sent in parallel from the client)?&lt;/p&gt;

&lt;p&gt;I think the join/scan scenarios may be more complicated, as Phoenix does it&apos;s own parallelization of the scan by breaking it up into row key ranges. From the POV of the HBase client, these look like separate scans. I think we&apos;re stuck establishing the region server cache ourselves for this case.&lt;/p&gt;

&lt;p&gt;Given the flexibility of region observer coprocessors, I&apos;m sure we can work out a way to send the cache through these rather than an endpoint coprocessor. For example, we can just issue a Get with a single key per region server to get the data over. FWIW, in the case of the data not being on the region server as expected, we&apos;ll end up throwing and the client will retry.&lt;/p&gt;

&lt;p&gt;As far as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6505&quot; title=&quot;Allow shared RegionObserver state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6505&quot;&gt;&lt;del&gt;HBASE-6505&lt;/del&gt;&lt;/a&gt;, we couldn&apos;t take advantage of it since it only allows the shared state to be shared between the same coprocessor. In this case, we have a different one that sends the data to cache versus the ones that use the data (our Put and Scan region observer coprocessors).&lt;/p&gt;</comment>
                            <comment id="13861024" author="apurtell" created="Fri, 3 Jan 2014 00:45:15 +0000"  >&lt;p&gt;Then maybe this issue comes down to this:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;As far as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6505&quot; title=&quot;Allow shared RegionObserver state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6505&quot;&gt;&lt;del&gt;HBASE-6505&lt;/del&gt;&lt;/a&gt;, we couldn&apos;t take advantage of it since it only allows the shared state to be shared between the same coprocessor. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, so I proposed adding something similar to RegionServerServices, which is a singleton per RS, available to a coprocessor from the RegionCoprocessorEnvironment.&lt;/p&gt;</comment>
                            <comment id="13861039" author="jamestaylor" created="Fri, 3 Jan 2014 00:55:04 +0000"  >&lt;p&gt;That seems like an improvement, but I don&apos;t think it&apos;s a requirement for us. We&apos;re using a singleton right now and our coprocessors are loaded through the system class path at startup, so I don&apos;t think we&apos;ll have any issues (but please correct me if I&apos;m mistaken).&lt;/p&gt;

&lt;p&gt;Any idea on the answer to my above question about tacking on the info to cache on the first Put: If this data is added to the first Put for each region server, is there any guarantee that one of the other regions isn&apos;t processed first (since these are sent in parallel from the client)?&lt;/p&gt;</comment>
                            <comment id="13864614" author="apurtell" created="Tue, 7 Jan 2014 19:53:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;Any idea on the answer to my above question about tacking on the info to cache on the first Put: If this data is added to the first Put for each region server, is there any guarantee that one of the other regions isn&apos;t processed first (since these are sent in parallel from the client)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not to my knowledge, you can guarantee a put is the &quot;first&quot; Put by dispatching Puts to appropriate keys to get a once-per-RS op first, then proceed with the rest of the work in another RPC. There&apos;s a race there but you mentioned you already handle the case if part of the keyspace has relocated inbetween. Pushing this down into the client library won&apos;t prevent the same kind of race, might as well handle it in your application since you may have special knowledge not available to a generalized API.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 23 Aug 2013 04:44:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344849</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 49 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ngvb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345149</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Phoenix</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>