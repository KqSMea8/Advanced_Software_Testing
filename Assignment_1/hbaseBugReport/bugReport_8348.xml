<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:54:22 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8348/HBASE-8348.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8348] Polish the migration to 0.96</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8348</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Currently, migration works but there&apos;s still a couple of rough edges:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8045&quot; title=&quot;Fix .META. migration after HBASE-3171&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8045&quot;&gt;&lt;del&gt;HBASE-8045&lt;/del&gt;&lt;/a&gt; finished the .META. migration but didn&apos;t remove ROOT, so it&apos;s still on the filesystem.&lt;/li&gt;
	&lt;li&gt;Data in ZK needs to be removed manually. Either we fix up the data in ZK or we delete it ourselves.&lt;/li&gt;
	&lt;li&gt;TestMetaMigrationRemovingHTD has a testMetaUpdatedFlagInROOT method, but ROOT is gone now.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Elliott was also mentioning that we could have &quot;hbase migrate&quot; do the HFileV1 checks, clear ZK, remove ROOT, etc.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12642630">HBASE-8348</key>
            <summary>Polish the migration to 0.96</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rajesh23">rajeshbabu</assignee>
                                    <reporter username="jdcryans">Jean-Daniel Cryans</reporter>
                        <labels>
                    </labels>
                <created>Mon, 15 Apr 2013 22:55:31 +0000</created>
                <updated>Fri, 20 Nov 2015 11:53:01 +0000</updated>
                            <resolved>Fri, 20 Sep 2013 17:46:46 +0000</resolved>
                                    <version>0.95.0</version>
                                    <fixVersion>0.96.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>19</watches>
                                                                                                            <comments>
                            <comment id="13633673" author="enis" created="Wed, 17 Apr 2013 02:00:42 +0000"  >&lt;p&gt;Having a migrate script would definitely help with the migration for admins. &lt;/p&gt;</comment>
                            <comment id="13650003" author="rajesh23" created="Mon, 6 May 2013 19:14:22 +0000"  >&lt;p&gt;I will take up this issue(to write migrate script) and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7766&quot; title=&quot;master cannot go from 94 to 96 due to zookeeper data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7766&quot;&gt;&lt;del&gt;HBASE-7766&lt;/del&gt;&lt;/a&gt; if no one started working on these.&lt;/p&gt;</comment>
                            <comment id="13700183" author="stack" created="Thu, 4 Jul 2013 16:26:25 +0000"  >&lt;p&gt;Also &quot;..test that &amp;lt; 0.95 hlogs and hfiles are readable&quot; (from Matteo)&lt;/p&gt;</comment>
                            <comment id="13708359" author="rajesh23" created="Mon, 15 Jul 2013 10:09:06 +0000"  >&lt;p&gt;Here is the patch for trunk which includes migration tool to&lt;br/&gt;
1) Migrate zookeeper data if no hbase process is alive&lt;br/&gt;
&#9632; Find .META region server from &lt;del&gt;ROOT&lt;/del&gt; and create meta-region-server&lt;br/&gt;
&#9632; Migrate table states to PB(solve &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7766&quot; title=&quot;master cannot go from 94 to 96 due to zookeeper data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7766&quot;&gt;&lt;del&gt;HBASE-7766&lt;/del&gt;&lt;/a&gt; and helps to find exact state of a table otherwise even disabled tables also be will enabled during master startup.)&lt;br/&gt;
&#9632; clean the znodes which are not used in 0.95.0 or not needed during clean cluster startup(znodes like rs,root-region-server,unassigned,splitlog,hbase-id,shutdown are removed).&lt;br/&gt;
2) remove &lt;del&gt;ROOT&lt;/del&gt; table from filesystem&lt;br/&gt;
3) Identify HFiles of version 1(using HFileV1Detector tool). &lt;/p&gt;

&lt;p&gt;and also removed TestMetaMigrationRemovingHTD#testMetaUpdatedFlagInROOT&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Also &quot;..test that &amp;lt; 0.95 hlogs and hfiles are readable&quot; (from Matteo)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Able to read hfiles and user table hlogs of older hbase version properly but not able to read META table hlogs because we are writing edits of it into a separate hlog suffixed by &quot;-meta&quot;. So not able to find it from hlogs od older version.&lt;br/&gt;
I think It would be better to flush &lt;del&gt;ROOT&lt;/del&gt; and .META. tables atleast before stopping the cluster. Please suggest some solution for this scenario.&lt;/p&gt;


&lt;p&gt;Please review the patch and provide any suggestions/comments.&lt;/p&gt;




</comment>
                            <comment id="13708399" author="hadoopqa" created="Mon, 15 Jul 2013 11:40:03 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12592303/HBASE-8348_trunk.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12592303/HBASE-8348_trunk.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6338//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13708402" author="rajesh23" created="Mon, 15 Jul 2013 11:52:52 +0000"  >&lt;p&gt;setting default fs in HFileV1Detector tool.&lt;/p&gt;</comment>
                            <comment id="13708438" author="hadoopqa" created="Mon, 15 Jul 2013 13:09:53 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12592318/HBASE-8348_trunk_v2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12592318/HBASE-8348_trunk_v2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6339//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13723440" author="v.himanshu" created="Tue, 30 Jul 2013 05:55:59 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 +    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+      region = HRegion.openHRegion(HRegionInfo.ROOT_REGIONINFO,
+          HTableDescriptor.ROOT_TABLEDESC, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, getConf());
+      Scan s = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Scan();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;ROOT? Or you mean FIRST_META_REGIONINFO?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bq. +        } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (child.equals(conf.get(&lt;span class=&quot;code-quote&quot;&gt;&quot;zookeeper.znode.tableEnableDisable&quot;&lt;/span&gt;,
+            &lt;span class=&quot;code-quote&quot;&gt;&quot;table&quot;&lt;/span&gt;))
+            || child.equals(conf.get(
+                &lt;span class=&quot;code-quote&quot;&gt;&quot;zookeeper.znode.masterTableEnableDisable&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;table&quot;&lt;/span&gt;))) {
+          checkAndMigrateTableStatesToPB(zkw);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Why are we doing this?&lt;/p&gt;

&lt;p&gt;I wonder the utility of migrating the existing znodes / or creating meta server znodes while doing the migration to 0.95.&lt;br/&gt;
Why not let HBase create them out of the box? What if we fail in the middle of this znode upgrade? What&lt;/p&gt;</comment>
                            <comment id="13723834" author="rajesh23" created="Tue, 30 Jul 2013 13:11:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;ROOT? Or you mean FIRST_META_REGIONINFO?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Its ROOT only.Before migrating to 0.95.x, root table files will be left out in file system, from that scanning .META. server address to create META server znode. This will be helpful during master initialization to identify .META. server is dead or not. Ideally it should help in splitting META logs but in 0.95.x meta hlog files are suffixed with &quot;meta&quot;, so cannot find them in older versions hlogs. If we dont flush .META. and &lt;del&gt;ROOT&lt;/del&gt; tables before stopping the existing cluter, there may be chance of loosing recently created tables.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I wonder the utility of migrating the existing znodes / or creating meta server znodes while doing the migration to 0.95. Why not let HBase create them out of the box?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;zookeeper.znode.tableEnableDisable znode helps to find the exact state of the table, It will be better to migrate table states to PB instead of deleting them. Otherwise even if tables are disabled, they will be enabled during master initialization.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What if we fail in the middle of this znode upgrade? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;User can retry, otherwise master initialization may fail. Ex: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7766&quot; title=&quot;master cannot go from 94 to 96 due to zookeeper data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7766&quot;&gt;&lt;del&gt;HBASE-7766&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13730836" author="stack" created="Tue, 6 Aug 2013 14:48:22 +0000"  >&lt;p&gt;This link does migration, make sure it works in line w/ all going on in here.&lt;/p&gt;</comment>
                            <comment id="13731135" author="v.himanshu" created="Tue, 6 Aug 2013 19:18:11 +0000"  >&lt;p&gt;And, I would argue that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7766&quot; title=&quot;master cannot go from 94 to 96 due to zookeeper data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7766&quot;&gt;&lt;del&gt;HBASE-7766&lt;/del&gt;&lt;/a&gt; is one of the reason I would vote for nuking all the znodes and let HBase re-create them. We do need replication znodes to migrate through. I opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9141&quot; title=&quot;Replication Znodes Backup Tool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9141&quot;&gt;&lt;del&gt;HBASE-9141&lt;/del&gt;&lt;/a&gt; for that task.&lt;/p&gt;</comment>
                            <comment id="13731141" author="v.himanshu" created="Tue, 6 Aug 2013 19:20:58 +0000"  >&lt;p&gt;And yes, I agree with disabled table getting enabled in 0.96; I think it is okay if we doc that the table which are disabled in 0.94.x, might get enabled on migration. And, users could disable them once the migration is done. What do you think Rajeshbabu?&lt;/p&gt;</comment>
                            <comment id="13732575" author="stack" created="Wed, 7 Aug 2013 18:56:35 +0000"  >&lt;p&gt;Add the below to the migration doc as what you see if you try and connect w/ old client:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

7:22:15  Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.IllegalArgumentException: Not a host:port pair: PBUF
17:22:15  *
17:22:15   api-compat-8.ent.cloudera.com &#65533;&#65533;  &#65533;&#65533;&#65533;( 
17:22:15  	at org.apache.hadoop.hbase.util.Addressing.parseHostname(Addressing.java:60)
17:22:15  	at org.apache.hadoop.hbase.ServerName.&amp;lt;init&amp;gt;(ServerName.java:101)
17:22:15  	at org.apache.hadoop.hbase.ServerName.parseVersionedServerName(ServerName.java:283)
17:22:15  	at org.apache.hadoop.hbase.MasterAddressTracker.bytesToServerName(MasterAddressTracker.java:77)
17:22:15  	at org.apache.hadoop.hbase.MasterAddressTracker.getMasterAddress(MasterAddressTracker.java:61)
17:22:15  	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:703)
17:22:15  	at org.apache.hadoop.hbase.client.HBaseAdmin.&amp;lt;init&amp;gt;(HBaseAdmin.java:126)
17:22:15  	at Client_4_3_0.setup(Client_4_3_0.java:716)
17:22:15  	at Client_4_3_0.main(Client_4_3_0.java:63)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From Aleks.&lt;/p&gt;</comment>
                            <comment id="13735268" author="rajesh23" created="Fri, 9 Aug 2013 20:36:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=v.himanshu&quot; class=&quot;user-hover&quot; rel=&quot;v.himanshu&quot;&gt;Himanshu Vashishtha&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;think it is okay if we doc that the table which are disabled in 0.94.x, might get enabled on migration. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt; I think its better to migrate zk data(atleast table states) than clearing because if a table is in ENABLIGN state then we may skip assignments during master startup.&lt;/p&gt;



</comment>
                            <comment id="13735700" author="rajesh23" created="Sat, 10 Aug 2013 02:56:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;if a table is in ENABLIGN state then we may skip assignments during master startup.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sorry. Before migrating we will stop full cluster. During clean cluster startup this problem wont happen.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think it is okay if we doc that the table which are disabled in 0.94.x, might get enabled on migration. And, users could disable them once the migration is done.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;To do this, user need to note disabled tables before startup and then again need to disable after migration. I feel its not good. Lets see what others will tell on this.&lt;/p&gt;


</comment>
                            <comment id="13739482" author="rajesh23" created="Wed, 14 Aug 2013 10:14:34 +0000"  >&lt;p&gt;Here is the patch includes migrations script&lt;br/&gt;
Migration steps include:&lt;br/&gt;
1) running NamespaceUpgrade tool - migrates hdfs data    &lt;br/&gt;
2) running ZK data migrator tool - migrates zookeeper data. current patch migrating replication znodes as well.&lt;br/&gt;
3) removing hbase.id (to avoid &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9177&quot; title=&quot;Cluster UUID is not properly parsable after rewriting to PB.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9177&quot;&gt;&lt;del&gt;HBASE-9177&lt;/del&gt;&lt;/a&gt;)&lt;br/&gt;
4) running HFileV1Detector tool - to identify v1 hfiles.&lt;/p&gt;

&lt;p&gt;Tested the patch in the cluster&lt;br/&gt;
===============================&lt;br/&gt;
1) installed two clusters with 0.94.11 version hbase. Enabled replication.&lt;br/&gt;
i) master cluster ii) slave cluster&lt;br/&gt;
2) created table with replication scope 1 and done some puts and deletes. replication in progress&lt;br/&gt;
3) stopped two clusters.&lt;br/&gt;
4) ran migrate script&lt;br/&gt;
5) restarted two clusters with 0.96.0 version hbase.&lt;br/&gt;
6) done some puts and replication also happening as usual. Everything fine.&lt;/p&gt;

&lt;p&gt;TODO: We can use replication backup tool once its ready&lt;/p&gt;</comment>
                            <comment id="13739762" author="stack" created="Wed, 14 Aug 2013 15:19:50 +0000"  >&lt;p&gt;This is great.&lt;/p&gt;

&lt;p&gt;I wonder if we should call the step &apos;upgrade&apos; rather than &apos;migrate&apos; (We used to call it &apos;migrate&apos; but hadoop talks abot &apos;upgrading&apos;).&lt;/p&gt;

&lt;p&gt;So what is the below doing?&lt;/p&gt;

&lt;p&gt;+ elif [ &quot;$COMMAND&quot; = &quot;migrate&quot; ] ; then&lt;br/&gt;
+  &quot;$bin&quot;/hbase-cleanup.sh --config $&lt;/p&gt;
{HBASE_CONF_DIR}
&lt;p&gt; --migrate&lt;br/&gt;
+  exitCode=$?&lt;br/&gt;
+  if [ &quot;$exitCode&quot; = &quot;0&quot; ]; then&lt;br/&gt;
+    &quot;$bin&quot;/hbase org.apache.hadoop.hbase.util.HFileV1Detector $@&lt;br/&gt;
+  fi&lt;br/&gt;
+  exit $?&lt;/p&gt;

&lt;p&gt;So we clean up zk and hdfs first and then run the hfilev1 detector?  Should the detector run first?&lt;/p&gt;

&lt;p&gt;Should we rename the hbase-cleanup.sh script to be called migrate.sh or upgrade.sh now it does more than cleaning?&lt;/p&gt;

&lt;p&gt;THis script looks excellent.  Nice work &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt;  Let me delete the one I started over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9134&quot; title=&quot;Run NamespaceUpgrade from hbase migration script&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9134&quot;&gt;&lt;del&gt;HBASE-9134&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; What you think?&lt;/p&gt;
</comment>
                            <comment id="13739813" author="rajesh23" created="Wed, 14 Aug 2013 16:06:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;So we clean up zk and hdfs first and then run the hfilev1 detector? Should the detector run first?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I will change it. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Should we rename the hbase-cleanup.sh script to be called migrate.sh or upgrade.sh now it does more than cleaning?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I will change it to upgrade.sh. And also we can have options like upgradeZk,updgradHdfs,updgradeAll right? then if user sees any problems in zk, he can run upgrade with updradeZk option once again. similarly with hdfs.&lt;/p&gt;

</comment>
                            <comment id="13739849" author="stack" created="Wed, 14 Aug 2013 16:36:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt; Yes to above.  Great work.&lt;/p&gt;</comment>
                            <comment id="13739870" author="v.himanshu" created="Wed, 14 Aug 2013 16:56:51 +0000"  >&lt;p&gt;This is great. I was thinking of having a Upgrade class (as Stack suggested) and let it do all the leg work (call various migrate tools and stuff). Either works. &lt;/p&gt;

&lt;p&gt;So, we just stop the upgrade in case of error in any of the above steps? Yes, options for upgrading different components would be great. &lt;/p&gt;

&lt;p&gt;Yes, HFileV1Detector tool should be run first and then if there are any HFileV1, prompt a message for compacting those regions. &lt;/p&gt;


&lt;p&gt;I don&apos;t think we should delete the hbase.id file. It could have issues with cyclic replication, for example, where we detect the origin of an edit by its cluster id. I hit &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9177&quot; title=&quot;Cluster UUID is not properly parsable after rewriting to PB.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9177&quot;&gt;&lt;del&gt;HBASE-9177&lt;/del&gt;&lt;/a&gt; last night when doing the upgrade where we read and write cluster id differently in 94 and trunk (write utf, but do readFully). I will review the patch there. &lt;/p&gt;</comment>
                            <comment id="13739879" author="stack" created="Wed, 14 Aug 2013 17:03:14 +0000"  >&lt;p&gt;There will be a pre-upgrade step for user to run before they take the cluster offline.  In it we&apos;ll ask them to run the v1 detector and if any found, keep compacting till all hfile v1s are gone.&lt;/p&gt;

&lt;p&gt;There is also the issue of meta edits that Himanshu came across.  Not sure how we are going to ensure .META. has all edits on shutdown if it not a &apos;clean&apos; shutdown.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; What are you referring to when you say &quot;... It could have issues with cyclic replication, for example&quot;?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13739916" author="v.himanshu" created="Wed, 14 Aug 2013 17:35:15 +0000"  >&lt;p&gt;For a waledit, the clusterId of the originator cluster is the identifier. In current code, Replicationsource decides whether an edit is to be shipped to a sink by comparing the sink&apos;s clusterId with waledits&apos; clusterid (ship it if clusterid is different). &lt;br/&gt;
In case we change it, replication of older edits (tagged with older clusterId) will be shipped back to the origin cluster again, as the clusterid will not match. Without HBase-7709, it will cause infinite loop. With proposed 7709 fix, they will be shipped back to the origin cluster once.&lt;/p&gt;</comment>
                            <comment id="13739952" author="stack" created="Wed, 14 Aug 2013 17:50:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; Good one. Makes sense.  Therefore, can&apos;t purge hbase.id and get a new id.&lt;/p&gt;</comment>
                            <comment id="13740369" author="v.himanshu" created="Wed, 14 Aug 2013 22:59:00 +0000"  >&lt;p&gt;Rajesh, few more comments:&lt;br/&gt;
a) I think you should also remove the hbase.id znode as master has to rewrite it anyway. &lt;br/&gt;
Also, talking to Matteo, also delete online-snapshot znode. That way, there will be only two znodes left: table, replication.&lt;br/&gt;
b) We could use the replication znode backup tool, or just replace it in place. That tool is more generic as with that you could serialize your znodes anywhere (on another znode, or on fs), and restore it. BUT, in-place replacement also works.&lt;/p&gt;</comment>
                            <comment id="13741911" author="rajesh23" created="Fri, 16 Aug 2013 04:49:20 +0000"  >&lt;p&gt;Himanshu,&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;a) I think you should also remove the hbase.id znode as master has to rewrite it anyway. Also, talking to Matteo, also delete online-snapshot znode. That way, there will be only two znodes left: table, replication.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I will remove these. &lt;/p&gt;

&lt;p&gt;If we use replication znode backup tool, failures can happen in multiple places a) while taking backup b) deleting znodes c) while restoring right?&lt;br/&gt;
Need to handle all cases and user also need to aware of them while running again on failure?&lt;br/&gt;
But with replacement, just if we run the same command again we can continue from the place where its failed. Its simple to use also.&lt;/p&gt;

&lt;p&gt;Lets see what others will say about this. If its ok to use backup tool, for me also no problem.&lt;/p&gt;</comment>
                            <comment id="13741932" author="v.himanshu" created="Fri, 16 Aug 2013 05:22:49 +0000"  >&lt;p&gt;I agree that backup tool is more involved and is over weight for this purpose. It could be used where we want to take snapshot of znodes, etc. To upgrade to PB, let&apos;s use the in place approach. &lt;/p&gt;</comment>
                            <comment id="13742777" author="v.himanshu" created="Sat, 17 Aug 2013 01:09:57 +0000"  >&lt;p&gt;Thinking more about making migration more user friendly and testable, I re-worked the attached patch. Hope that&apos;s okay Rajesh. The key changes are:&lt;/p&gt;

&lt;p&gt;a) Use Tool to handle the upgrade (aka UpgradeTo96), instead of a script.&lt;/p&gt;

&lt;p&gt;b) Add unit tests for various steps involved in upgrade (detect HFilesV1, upgrading znodes). There is already a test class for namespace upgrade. (Figured out via unit tests that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8778&quot; title=&quot;Region assigments scan table directory making them slow for huge tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8778&quot;&gt;&lt;del&gt;HBASE-8778&lt;/del&gt;&lt;/a&gt; broke HFileV1Detector).&lt;/p&gt;

&lt;p&gt;c) Refactor HFileV1Detector (return proper value, print script friendly output, removed duplicate code, etc). It prints processed tables, regions to major compact, list HFileV1 and corrupted (Storefile with undefined major version).&lt;/p&gt;

&lt;p&gt;d) Delete hbase.id and online-snapshot znodes.&lt;/p&gt;

&lt;p&gt;I tested this on a 0.94 cluster, and it works good.&lt;/p&gt;
&lt;h4&gt;&lt;a name=&quot;Samplehelpusage%3A&quot;&gt;&lt;/a&gt;Sample help usage:&lt;/h4&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/hbase org.apache.hadoop.hbase.migration.UpgradeTo96
This tool helps in upgrading to 0.96. The upgrade involves major compacting any HFileV1, upgrading file system layout &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; namespaces, and updating znodes. Please follow the following steps:

1) Major compact HFileV1: On a running pre-0.96 (i.e., 0.94.x, 0.92.x) cluster, run &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; tool using option -checkHFileV1. Look at the console output &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there are any regions to major compact. (grep &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;Regions to Major compact&quot;&lt;/span&gt; on the console output). Major compact the listed regions. Keep on repeating &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; step till there are no regions to major compact. If none, please shutdown the hbase cluster. As we need to update znodes, ensure that zookeeper is up and running.

2) Upgrade Namespace and Znodes: After step 1) run &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; tool using option -upgrade. In &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; you want to upgrade either of them, use option -ns, or -zk to upgrade namespace and znodes, respectively.

Refer below &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more help on options.

usage: UpgradeTo96 [-chkHFileV1] [-dirTocheckHFileV1 &amp;lt;arg&amp;gt;] [-h] [-ns]
       [-upgrade] [-zk]
 -chkHFileV1,--checkForHFileV1                     Check &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; HFileV1
 -dirTocheckHFileV1,--dirToCheckForHFileV1 &amp;lt;arg&amp;gt;   Relative path of
                                                   directory to check &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;
                                                   HFileV1. Default is
                                                   hbase.rootdir
 -h,--help                                         Help
 -ns,--namespace                                   Upgrade the namespace
                                                   to 0.96
 -upgrade,--upgrade-NS-ZK                          Upgrade both namespace
                                                   and znodes
 -zk,--Znodes                                      Upgrade the znodes
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h4&gt;&lt;a name=&quot;Detectionphase%3A&quot;&gt;&lt;/a&gt;Detection phase:&lt;/h4&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/hbase org.apache.hadoop.hbase.migration.UpgradeTo96 -chkHFileV1
Result: 

Tables Processed: 
hdfs:&lt;span class=&quot;code-comment&quot;&gt;//localhost:41020/hbase-0.94/.migration
&lt;/span&gt;
&lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of HFileV1: 0
HFileV1:

&lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of corrupted files:0
Corrupted Files: 

&lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of Regions with HFileV1: 0
Regions to Major Compact: 

No HFileV1 found.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h4&gt;&lt;a name=&quot;Upgradephase%3A&quot;&gt;&lt;/a&gt;Upgrade phase:&lt;/h4&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
hbase-daemon.sh start zookeeper
himanshu@ubuntu:~/Work/Cloudera/apacheHBase/hbase$ bin/hbase org.apache.hadoop.hbase.migration.UpgradeTo96 -upgradeUpgrading Namespace
Successfully Upgraded NameSpace.
Upgrading Znodes
Succesfully upgraded znodes.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13742778" author="v.himanshu" created="Sat, 17 Aug 2013 01:12:54 +0000"  >&lt;p&gt;Minor nit on the upgrade section:&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;Upgradephase%3A&quot;&gt;&lt;/a&gt;Upgrade phase:&lt;/h4&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/hbase org.apache.hadoop.hbase.migration.UpgradeTo96 -upgrade
Upgrading Namespace
Successfully Upgraded NameSpace.
Upgrading Znodes
Succesfully upgraded znodes.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13742803" author="hadoopqa" created="Sat, 17 Aug 2013 02:36:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12598565/HBASE-8348-approach-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12598565/HBASE-8348-approach-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestFullLogReconstruction&lt;br/&gt;
                  org.apache.hadoop.hbase.migration.TestUpgradeTo96&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6796//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13742823" author="hadoopqa" created="Sat, 17 Aug 2013 03:25:48 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12598566/HBASE-8348-approach-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12598566/HBASE-8348-approach-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.migration.TestUpgradeTo96&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6797//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13742976" author="rajesh23" created="Sat, 17 Aug 2013 17:13:54 +0000"  >&lt;p&gt;This is really superb Himanshu.&lt;/p&gt;

&lt;p&gt;Only thing missing is checking for no live processes exist before upgrade.In current patch I have added that check and skipping upgrade if any live processes exists. Tested in the cluster. Its fine as well.&lt;/p&gt;

&lt;p&gt;Removed TestMetaMigrationRemovingHTD#testMetaUpdatedFlagInROOT test.&lt;/p&gt;

&lt;p&gt;The reason for TestUpgradeTo96#testHFileV1Detector failure is because RootKeyComparator class not exists so not able deserialize trailer propery. It got removed recently as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9196&quot; title=&quot;Remove dead code related to KeyValue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9196&quot;&gt;&lt;del&gt;HBASE-9196&lt;/del&gt;&lt;/a&gt;(Remove dead code related to KeyValue)&lt;br/&gt;
We need to add it back or skip root table hfile v1 check.&lt;/p&gt;</comment>
                            <comment id="13742978" author="rajesh23" created="Sat, 17 Aug 2013 17:21:33 +0000"  >&lt;p&gt;This check protects if user runs upgrade tool before stopping full cluster by mistake.&lt;/p&gt;</comment>
                            <comment id="13742983" author="hadoopqa" created="Sat, 17 Aug 2013 18:32:55 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12598610/HBASE-8348-approach-3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12598610/HBASE-8348-approach-3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6800//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13743048" author="v.himanshu" created="Sat, 17 Aug 2013 22:39:39 +0000"  >&lt;p&gt;Hurray! I especially like how the failed test report says that root table has corrupt files &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Thanks for taking care of that Rajesh.&lt;/p&gt;</comment>
                            <comment id="13743064" author="stack" created="Sun, 18 Aug 2013 00:00:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;But with replacement, just if we run the same command again we can continue from the place where its failed. Its simple to use also.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agree&lt;/p&gt;

&lt;p&gt;On the script name, would suggest calling it Upgrade rather than UpgradeTo96.&lt;/p&gt;

&lt;p&gt;Regards the text for help, &apos;This tool helps in upgrading to 0.96.&apos;  &amp;#8211; doesn&apos;t it run the whole upgrade?&lt;/p&gt;

&lt;p&gt;Would suggest that the help is outside in the documentation rather than as usage on the script.&lt;/p&gt;

&lt;p&gt;Does cluster have to be shut down for the actual upgrade to run?&lt;/p&gt;

&lt;p&gt;I&apos;d suggest dividing upgrade into two parts, a --check, and a --execute.&lt;/p&gt;

&lt;p&gt;Otherwise, this is looking great.  Between the two of you, you are doing a nice job on a critical process.  Let me take a look at the patch.&lt;/p&gt;




</comment>
                            <comment id="13743067" author="stack" created="Sun, 18 Aug 2013 00:15:13 +0000"  >&lt;p&gt;+  echo &quot;  upgradeTo96      upgrade hbase to 0.96&quot;&lt;/p&gt;

&lt;p&gt;On above, just say upgrade&apos;.  And help should be &apos;upgrade from 0.94 (or 0.92)?&apos;.&lt;/p&gt;

&lt;p&gt;The below is odd...&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static byte[] toByteArray(final String clusterKey) {&lt;br/&gt;
+  public static byte[] toByteArray(final String clusterKey) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If it is going to be made public, it should probably get a better name (but I can&apos;t come up w/ one &amp;#8211; smile) so maybe just having the parameter name be clusterKey works.... does this have to be public?&lt;/p&gt;

&lt;p&gt;Why not an accessor rather than make a private member public?&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private String masterAddressZNode;&lt;br/&gt;
+  public String masterAddressZNode;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On Upgrade script, I&apos;d suggest that user runs &apos;check&apos; then print out &quot;regions xyz need major compacting..... see refguide link for more&quot;&lt;/p&gt;

&lt;p&gt;Then for executing the upgrade, yeah, as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt; suggests, should check if stuff is running and not run if stuff is.&lt;/p&gt;

&lt;p&gt;I&apos;d say that operator probably doesn&apos;t care about znodes and ns steps upgrading, not until it goes wrong (but it won&apos;t go wrong!).  In refguide we can talk up the steps and what each does.  So would suggest making this less detailed:&lt;/p&gt;

&lt;p&gt;+        &quot;Upgrade both namespace and znodes&quot;));&lt;/p&gt;


&lt;p&gt;These usage Strings are too long:&lt;/p&gt;

&lt;p&gt;+    System.out.println(&quot;This tool helps in upgrading to 0.96. The upgrade involves major &quot; +&lt;br/&gt;
+    		&quot;compacting any HFileV1, upgrading file system layout for namespaces, and updating &quot; +&lt;br/&gt;
+    		&quot;znodes. Please follow the following steps:&quot;);&lt;/p&gt;

&lt;p&gt;Usually folks keep the usage 80 characters wide.  Would suggest you just point folks to the refguide 0.96 migration section.   There we can do the detail rather than here.&lt;/p&gt;

&lt;p&gt;Otherwise, this stuff is looking really good.  Thanks for working on it lads.&lt;/p&gt;</comment>
                            <comment id="13744602" author="jeffreyz" created="Tue, 20 Aug 2013 01:33:25 +0000"  >&lt;p&gt;This tool is great! Today I populated some data with snapshots in a 0.94 cluster and upgrade it to 0.96. After upgrade, all existing data are intact! When I looked at the code, there are some very minor things as following: &lt;/p&gt;

&lt;p&gt;1) it seems the following two lines in ZKDataMigrator.java are not needed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      FileSystem fs = FileSystem.get(getConf());
      FSUtils.setFsDefault(conf, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(fs.getUri()));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;2) If I specify both -ns -zk in command line, only name space is upgraded. &lt;br/&gt;
3) Since ./bin/hbase run with default &quot;INFO,console&quot;, in my option, we could use log4j to print message out instead of System.err.println. Because it prints out &quot;Region server(s) ### are alive or  rs znodes not expired.&quot;, not sure it&apos;s an info, warn or error message.&lt;/p&gt;</comment>
                            <comment id="13744680" author="v.himanshu" created="Tue, 20 Aug 2013 04:01:30 +0000"  >&lt;p&gt;Thanks for trying this Jeffrey, and glad to know that it worked for you.&lt;/p&gt;

&lt;p&gt;1) Looks like they are redundant yes. Will remove it.&lt;/p&gt;

&lt;p&gt;2) If I specify both -ns -zk in command line, only name space is upgraded. &lt;br/&gt;
Good point, I will take this into account. (One could use --upgrade instead of using both options separately, though).&lt;/p&gt;

&lt;p&gt;3) I tried to be consistent with other tools (SnapshotInfo, CompactionTool, HFileV1Detector and others) and used console. &lt;br/&gt;
I think it is okay to use error as this blocks the upgrade step. Please let me know in case you disagree.&lt;/p&gt;</comment>
                            <comment id="13744716" author="v.himanshu" created="Tue, 20 Aug 2013 05:18:34 +0000"  >&lt;p&gt;Attached is a patch which takes review comments from Stack and Jeffrey into account. It also has the changes mentioned by Rajesh to abort upgrade in case any HBase process is alive. Key changes:&lt;/p&gt;

&lt;p&gt;a) Made the help crispier (and linked to refguide&apos;s migrate 0.96 section).&lt;br/&gt;
b) Re-added the Test class TestUpgradeTo96. HFileV1Detector now skips ROOT table.&lt;br/&gt;
c) bq. private static byte[] toByteArray(final String clusterKey) {&lt;br/&gt;
ReplicationPeer is build in the ZKDataMigrator class, and therefore we no longer need this.&lt;br/&gt;
d) bq.  + public String masterAddressZNode;&lt;br/&gt;
This is now consistent with all other base znodes (they all are public). I think it is okay.&lt;br/&gt;
e) Script now has two parts: --check (checks for HFileV1 and any live process), and --execute (does the actual upgrade). The detailed help section attached in the previous will have explanation of other options (upgrade ns, or zk, etc) and it will be incorporated in refguide (as Stack mentioned).&lt;/p&gt;</comment>
                            <comment id="13744744" author="hadoopqa" created="Tue, 20 Aug 2013 06:25:58 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12598905/HBASE-8348-approach-2-v2.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12598905/HBASE-8348-approach-2-v2.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(TestMRJobs.java:180)&lt;br/&gt;
	at org.apache.hadoop.mapreduce.v2.TestUberAM.testSleepJob(TestUberAM.java:58)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6823//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13745160" author="jeffreyz" created="Tue, 20 Aug 2013 17:26:13 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think it is okay to use error as this blocks the upgrade step. Please let me know in case you disagree.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ok, it&apos;s fine with me, +1 for your latest patch!(Though I think it&apos;s better to use log4j onwards unless there are some issues which I&apos;m not aware of.) Thanks! &lt;/p&gt;</comment>
                            <comment id="13745489" author="v.himanshu" created="Tue, 20 Aug 2013 21:48:58 +0000"  >&lt;p&gt;Thanks for the review Jeffrey. &lt;br/&gt;
I will upload one more version to correct handling of various confs while setting default fs, etc, later today.&lt;/p&gt;</comment>
                            <comment id="13745614" author="v.himanshu" created="Tue, 20 Aug 2013 23:25:03 +0000"  >&lt;p&gt;Attaching patch which does:&lt;br/&gt;
a) correctly set fs (using hbase.rootdir uri).&lt;br/&gt;
b) minor refactoring in UpgradeTo96 (initially, we were checking for live processes even if user doesn&apos;t set execute option). &lt;/p&gt;

&lt;p&gt;Rest of the patch is similar to old one. Thanks.&lt;/p&gt;</comment>
                            <comment id="13745682" author="stack" created="Wed, 21 Aug 2013 01:05:55 +0000"  >&lt;p&gt;Why this change?&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private String masterAddressZNode;&lt;br/&gt;
+  public String masterAddressZNode;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Why make a datamember public?  Why not an accessor?&lt;/p&gt;

&lt;p&gt;This is unorthodox and is the line too long?&lt;/p&gt;

&lt;p&gt;+  private boolean upgradeNS = false, upgradeZnode = false, upgrade = false,&lt;br/&gt;
+      checkForHFileV1 = false;&lt;/p&gt;

&lt;p&gt;Call the datamembers out individually.&lt;/p&gt;

&lt;p&gt;Why different spacing here after the &apos;if&apos;?&lt;/p&gt;

&lt;p&gt;+    if (cmd.hasOption(&quot;zk&quot;)) upgradeZnode = true;&lt;br/&gt;
+    if (cmd.hasOption(&quot;execute&quot;)) upgrade = true;&lt;br/&gt;
+    if(cmd.hasOption(&quot;check&quot;)) checkForHFileV1 = true;&lt;br/&gt;
+    if(che&lt;/p&gt;

&lt;p&gt;Suggest you follow general conventions on how to do usage.  Rather than this:&lt;/p&gt;

&lt;p&gt;+    System.out.println(&quot;This tool runs in two modes: --check, and --execute.&quot;);&lt;/p&gt;

&lt;p&gt;do....&lt;/p&gt;

&lt;p&gt;+    System.out.println(&quot;Usage: Upgrade -&lt;del&gt;check|&lt;/del&gt;-execute&quot;);&lt;/p&gt;

&lt;p&gt;Do the above take args?&lt;/p&gt;

&lt;p&gt;And see how other commands do options...&lt;/p&gt;

&lt;p&gt;Can&apos;t you get options to print this out for you anyways?&lt;/p&gt;

&lt;p&gt;More to follow.&lt;/p&gt;

&lt;p&gt;We need to get something in and then can do patches on top of it....&lt;/p&gt;</comment>
                            <comment id="13746848" author="stack" created="Wed, 21 Aug 2013 21:10:57 +0000"  >&lt;p&gt;Regards this message, +        System.out.println(&quot;ERROR: Please look for corrupt files, or regions to major compact.&quot;);&lt;/p&gt;

&lt;p&gt;... what would a corrupt file be?  Are you going to freak folks out if they see this message?  Does the v1 checker print out the instnaces of v1 hfiles?&lt;/p&gt;

&lt;p&gt;I&apos;m w/ Jeffrey that these messages should be LOG.warn or LOG.error rather than System.out.println... then you don&apos; thave to invent your own style of ERROR logging w/ your ERROR prefix.  Will also have date stamp on it... and there other facilities you could use like printing stack trace&lt;/p&gt;

&lt;p&gt;Yeah, stuff like this could then be logged as LOG.warn:&lt;/p&gt;

&lt;p&gt;+          System.err.println(&quot;Backup master(s) &quot; + backupMasters&lt;br/&gt;
+              + &quot; are alive or backup-master znodes not expired.&quot;);&lt;/p&gt;

&lt;p&gt;Why bother w/ the system.err.println if we are going to throw a IOE?&lt;/p&gt;

&lt;p&gt;+      System.err.println(e);&lt;br/&gt;
+      throw new IOException(e);&lt;/p&gt;

&lt;p&gt;Good..&lt;/p&gt;

&lt;p&gt;+      if (zkw != null) &lt;/p&gt;
{
+        zkw.close();
+      }


&lt;p&gt;Won&apos;t the first res be overwritten by the second &amp;#8211; is that what you want?  Shoudl you proceed if the first has a non-zero result?  And why not just do return upgradeZNodes instead of catch result in a res and the in new statement doing the return res.&lt;/p&gt;

&lt;p&gt;+    int res = upgradeNamespace();&lt;br/&gt;
+    res = upgradeZnodes();&lt;/p&gt;


&lt;p&gt;Should be LOG.info: +    System.out.println(&quot;Upgrading Namespace&quot;);&lt;/p&gt;

&lt;p&gt;Should be LOG.error: +      System.err.println(&quot;FAILURE: while updating Namespace&quot;); (You are inventing your own language and it is inconsistent... it is ERROR earlier and then here it is FAILURE)&lt;/p&gt;

&lt;p&gt;Is this generally useful or should it instead be under the migration package:&lt;/p&gt;

&lt;p&gt;diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/ZKDataMigrator.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/ZKDataMigrator.java&lt;/p&gt;


&lt;p&gt;Why get a logger and then do this?&lt;/p&gt;

&lt;p&gt;+        System.out.println(&quot;No hbase related data available in zookeeper. returning..&quot;);&lt;br/&gt;
+        return 0;&lt;/p&gt;

&lt;p&gt;Just use loggers everywhere I&apos;d say except for the usage output.&lt;/p&gt;

&lt;p&gt;I would be interested in seeing a log of a run of this tool.&lt;/p&gt;

&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt;  Lets get this turned around quick.  Main blocker on a 0.96RC.  Thanks.&lt;br/&gt;
+    return res;&lt;/p&gt;</comment>
                            <comment id="13747179" author="v.himanshu" created="Thu, 22 Aug 2013 03:01:03 +0000"  >&lt;p&gt;Thanks for the reviews, Stack.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;... what would a corrupt file be? Are you going to freak folks out if they see this message? Does the v1 checker print out the instnaces of v1 hfiles?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;A corrupt file is a store file which has an unknown major version (neither 1 nor 2). Yes, the tool prints out all such files, and also prints V1 files. I will add in the description what does corrupt mean. I think it is important to let the user know if there is any such file.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
There are some HFileV1, or corrupt files (files with incorrect major version). 
Please look at the log &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a list of such files.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sure, I have a patch to replace all system.out.xxx (in UploadTo96 and HFileV1Detector tool) to LOG.xxx. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Shoudl you proceed if the first has a non-zero result? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Namespace upgrade tool returns 0 unless there is any error (which it throws on the caller). So, this would work too. But let me add the check.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;And why not just do return upgradeZNodes instead of catch result in a res and the in new statement doing the return res.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Will do.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can&apos;t you get options to print this out for you anyways?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It is used, after the description on the tool. Okay, will make the help consistent with other tools, by just printing the options. More description can be added in the ref guide.&lt;/p&gt;

&lt;p&gt;I think we should get this working patch in, and then do refinements based on users feedback (before 0.96 comes out). I will upload a patch tonight, with a log of its run.&lt;br/&gt;
BTW, I figured out that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9126&quot; title=&quot;Make HFile MIN VERSION as 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9126&quot;&gt;&lt;del&gt;HBASE-9126&lt;/del&gt;&lt;/a&gt; removed the V1 support altogether and now, we get an exception if the major version is 1. Could that cleanup be done in 0.98 (or another dot release, in case we tell users to go through 0.96.0 before doing any upgrade from 0.94.x). It is just a suggestion, though. I am okay otherwise, and will fix the HFileV1 tool. Please let me know. Thanks.&lt;/p&gt;</comment>
                            <comment id="13747274" author="v.himanshu" created="Thu, 22 Aug 2013 06:04:44 +0000"  >&lt;p&gt;Attached is a log file, that contains sample runs of the tool.&lt;/p&gt;</comment>
                            <comment id="13747276" author="v.himanshu" created="Thu, 22 Aug 2013 06:06:50 +0000"  >&lt;p&gt;I have attached a patch and log file. This patch takes care of the review comments by Jeffrey and Stack. The log file contains sample run of the tool (command and log statements).&lt;/p&gt;

&lt;p&gt;I will file a jira to fix the HFileV1 tool now. Thanks.&lt;/p&gt;</comment>
                            <comment id="13747572" author="v.himanshu" created="Thu, 22 Aug 2013 14:58:36 +0000"  >&lt;p&gt;Re-attaching to let qa bot run.&lt;/p&gt;</comment>
                            <comment id="13747592" author="stack" created="Thu, 22 Aug 2013 15:22:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; I set hadoopqa running H.  It seems like have to run it manually these times.  Let me look at the patch....&lt;/p&gt;</comment>
                            <comment id="13747602" author="stack" created="Thu, 22 Aug 2013 15:41:17 +0000"  >&lt;p&gt;Should this be in there still:&lt;/p&gt;

&lt;p&gt;+    options.addOption(new Option(&quot;check&quot;, &quot;checkForHFileV1&quot;, false, &quot;Checks for HFileV1 in &quot;&lt;br/&gt;
+        + &quot; the hbase.rootdir (or provided directory).&quot;));&lt;/p&gt;

&lt;p&gt;If the v1 check does not work in 0.96, is there anything done when the check runs?&lt;/p&gt;

&lt;p&gt;Thanks for making the log.  The usage though needs a bit of work.  It says:&lt;/p&gt;

&lt;p&gt;usage: $bin/hbase upgrade &lt;span class=&quot;error&quot;&gt;&amp;#91;-check&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;-dirTocheck &amp;lt;arg&amp;gt;&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;-execute&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;-h&amp;#93;&lt;/span&gt;&lt;br/&gt;
       &lt;span class=&quot;error&quot;&gt;&amp;#91;-ns&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;-zk&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The problem w/ the above is that you do not convey that check and execute are mutually exclusive.  This is normally done by doing:&lt;/p&gt;

&lt;p&gt;upgrade -&lt;del&gt;check|&lt;/del&gt;&lt;del&gt;execute|&lt;/del&gt;-help&lt;/p&gt;

&lt;p&gt;You can override the usage that is output by Option, IIRC?&lt;/p&gt;

&lt;p&gt;If --check now does nothing, it should be removed.&lt;/p&gt;

&lt;p&gt;Make this option shorter because it makes less room for the option descriptions &amp;#8211; call it &apos;dir&apos; only?:&lt;/p&gt;

&lt;p&gt; &lt;del&gt;dirTocheck,&lt;/del&gt;-dirToCheckForHFileV1 &amp;lt;arg&amp;gt;   Relative path of directory to&lt;/p&gt;

&lt;p&gt;The example usage is good but again, if v1 check does not work, it should not be included here:&lt;/p&gt;

&lt;p&gt;To check for HFileV1 in hbase.rootdir: &lt;br/&gt;
$ bin/hbase upgrade --check&lt;/p&gt;

&lt;p&gt;... it will only confuse.&lt;/p&gt;

&lt;p&gt;Anything on meta flush issue?&lt;/p&gt;

&lt;p&gt;Should upgrade check for WAL files?&lt;/p&gt;

&lt;p&gt;The log is nice.  Thanks for making it.  Helps w/ review.&lt;/p&gt;

&lt;p&gt;I&apos;d say hide the zk, ns, and help options?  Or at least try and not have them show in the main usage line.  They only confuse.  You want operators to focus on check or execute.  Besides, if ns or zk or already upgraded, don&apos;t the calls to ns or zk become noops (would be good to check) so there is no harm running both each time?  If so, remove this distinction I&apos;d say.  More options means more likely folks will be confused.&lt;/p&gt;

&lt;p&gt;I someone wants to run the v1 check against a running 0.94 instance, how do they do that now?  They do it out of a 0.96 binary?&lt;/p&gt;

&lt;p&gt;In the process check, do we check for zk?  If zk is down, how does it get &apos;udated&apos;?&lt;/p&gt;

&lt;p&gt;Good stuff.&lt;/p&gt;




</comment>
                            <comment id="13747642" author="hadoopqa" created="Thu, 22 Aug 2013 16:33:38 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12599440/HBASE-8348-approach-2-v2.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12599440/HBASE-8348-approach-2-v2.3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop1.0&lt;/font&gt;.  The patch compiles against the hadoop 1.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.migration.TestNamespaceUpgrade&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6839//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13747670" author="v.himanshu" created="Thu, 22 Aug 2013 17:17:26 +0000"  >&lt;p&gt;Thanks for reviewing Stack.&lt;/p&gt;

&lt;p&gt;Pretty sure this failure is not related. Its fails on a 2 sec timeout (passes on local).&lt;/p&gt;

&lt;p&gt;Re: Help, I thought we said to add more details in the ref guide. In case user give both option and check fails, it will not go to the execute part.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You can override the usage that is output by Option, IIRC?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Let me take a look on that. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;if v1 check does not work, it should not be included here:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We need that and I will upload a fix for 9297 soon.&lt;/p&gt;

&lt;p&gt;Re zk down:&lt;br/&gt;
If zk is down, the upgradeZnodes part throws exception to the user. I posted that as a requirement in the first Sample Help (&quot;As we need to update znodes, ensure that zookeeper is up and running.&quot;)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yes, re-running them is a noop. Okay, will remove ns and zk option. Thanks.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13747902" author="v.himanshu" created="Thu, 22 Aug 2013 21:22:21 +0000"  >&lt;p&gt;Thanks for reviewing.&lt;/p&gt;

&lt;p&gt;The last patch takes care of the comments mentioned by Stack. &lt;/p&gt;

&lt;p&gt;1) I attached a usage log (log-2), which list sample commands with their output. It covers basic use case (list help, run check, execute update with HBase process running, with HDFS down, etc). It has one use where there are two HFileV1 and one corrupt file (case #4).&lt;/p&gt;

&lt;p&gt;2) HFileV1 Tool is working again (it no longer uses FixedFileTrailer instance, so no regression from 9126).&lt;/p&gt;

&lt;p&gt;3) Removed ns/zk options. Checked that after one run, they are noop.&lt;/p&gt;</comment>
                            <comment id="13747916" author="stack" created="Thu, 22 Aug 2013 21:42:30 +0000"  >&lt;p&gt;So, execute and check are mutually exclusive?  and the dir is used when you check, right?  Not when you execute?  Let me try this last version.  It looks committable.  I can clean the usage if you tell me the above.&lt;/p&gt;
</comment>
                            <comment id="13747949" author="v.himanshu" created="Thu, 22 Aug 2013 22:00:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;and the dir is used when you check, right? Not when you execute?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;mutually exclusive&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I made it to handle both (just in case) such that if a user gives both, then check will be evaluated first, and then the execute. &lt;br/&gt;
In case there is any error in check (a HFileV1 is present, for example), then it will not go to the execute step.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If someone wants to run the v1 check against a running 0.94 instance, how do they do that now? They do it out of a 0.96 binary?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. They could point to any directory using -dir option while checking.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In the process check, do we check for zk? If zk is down, how does it get &apos;udated&apos;?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, a running zk and hdfs is required.&lt;/p&gt;

&lt;p&gt;Sorry if the usage is still not clear enough. I was thinking of writing a little help section in the ref guide to help admins.&lt;/p&gt;</comment>
                            <comment id="13747965" author="stack" created="Thu, 22 Aug 2013 22:12:34 +0000"  >&lt;p&gt;I tried it and got this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-08-22 15:11:05,880 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/Users/stack/checkouts/0.95
2013-08-22 15:11:05,881 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=Check Live Processes.
2013-08-22 15:11:05,901 INFO  [main] zookeeper.RecoverableZooKeeper: &lt;span class=&quot;code-object&quot;&gt;Process&lt;/span&gt; identifier=Check Live Processes. connecting to ZooKeeper ensemble=localhost:2181
2013-08-22 15:11:05,904 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:05,910 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:06,025 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly &lt;span class=&quot;code-keyword&quot;&gt;transient&lt;/span&gt; ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
2013-08-22 15:11:06,025 INFO  [main] util.RetryCounter: Sleeping 2000ms before retry #1...

2013-08-22 15:11:11,014 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:11,015 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:11,117 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly &lt;span class=&quot;code-keyword&quot;&gt;transient&lt;/span&gt; ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
2013-08-22 15:11:11,117 INFO  [main] util.RetryCounter: Sleeping 4000ms before retry #2...
2013-08-22 15:11:11,117 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:11,117 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:12,219 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:12,220 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:12,321 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:12,322 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:12,424 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:12,424 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:13,526 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:13,526 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:13,628 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:13,628 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:13,729 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:13,730 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:21,514 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:21,514 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:21,615 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:21,616 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:21,717 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:21,717 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:21,818 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly &lt;span class=&quot;code-keyword&quot;&gt;transient&lt;/span&gt; ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
2013-08-22 15:11:21,818 INFO  [main] util.RetryCounter: Sleeping 8000ms before retry #3...
2013-08-22 15:11:22,818 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:22,818 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:22,920 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:22,921 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:23,022 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:23,023 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:24,124 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:24,125 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:24,226 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:24,227 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:24,328 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:24,328 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:25,430 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:25,430 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:25,531 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:25,532 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:25,633 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:25,634 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:26,736 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:26,736 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:26,837 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:26,838 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:26,939 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:26,940 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:28,041 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:28,041 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:28,143 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:28,143 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:28,245 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:28,245 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:29,347 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:29,348 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:29,449 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:29,449 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:29,551 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:29,552 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:30,653 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:30,653 WARN  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:30,755 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly &lt;span class=&quot;code-keyword&quot;&gt;transient&lt;/span&gt; ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
2013-08-22 15:11:30,755 INFO  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
2013-08-22 15:11:30,755 ERROR [main] zookeeper.RecoverableZooKeeper: ZooKeeper exists failed after 3 retries
2013-08-22 15:11:30,755 WARN  [main] zookeeper.ZKUtil: Check Live Processes. Unable to set watcher on znode (/hbase)
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:202)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:482)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.isAnyHBaseProcessAlive(UpgradeTo96.java:154)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.run(UpgradeTo96.java:125)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.main(UpgradeTo96.java:232)
2013-08-22 15:11:30,755 WARN  [main-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] zookeeper.ClientCnxn: Session 0x0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; server &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)
2013-08-22 15:11:30,756 ERROR [main] zookeeper.ZooKeeperWatcher: Check Live Processes. Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:202)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:482)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.isAnyHBaseProcessAlive(UpgradeTo96.java:154)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.run(UpgradeTo96.java:125)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.main(UpgradeTo96.java:232)
2013-08-22 15:11:30,756 ERROR [main] migration.UpgradeTo96: Got exception &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; checking live hbase processes
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:202)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:482)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.isAnyHBaseProcessAlive(UpgradeTo96.java:154)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.run(UpgradeTo96.java:125)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.main(UpgradeTo96.java:232)
2013-08-22 15:11:30,857 INFO  [main] zookeeper.ZooKeeper: Session: 0x0 closed
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; 2013-08-22 15:11:30,857 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
java.io.IOException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
	at org.apache.hadoop.hbase.migration.UpgradeTo96.isAnyHBaseProcessAlive(UpgradeTo96.java:184)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.run(UpgradeTo96.java:125)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.main(UpgradeTo96.java:232)
Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:202)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:482)
	at org.apache.hadoop.hbase.migration.UpgradeTo96.isAnyHBaseProcessAlive(UpgradeTo96.java:154)
	... 3 more
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You expect zk to be up and running?&lt;/p&gt;</comment>
                            <comment id="13747970" author="stack" created="Thu, 22 Aug 2013 22:14:56 +0000"  >&lt;p&gt;Here are some mods to the last version of the patch making usage better reflect the mutual exclusivity, moving upgrade up from package to commands, made usage consistent so has &apos;&lt;del&gt;&apos; everywhere instead of &apos;&lt;/del&gt;&lt;del&gt;&apos; and then &apos;&lt;/del&gt;&apos; sometimes in the help, removed alternative version so commands &amp;#8211; alternatives too long.&lt;/p&gt;</comment>
                            <comment id="13747971" author="v.himanshu" created="Thu, 22 Aug 2013 22:15:21 +0000"  >&lt;p&gt;Yes, both zk and hdfs should be up and running.&lt;/p&gt;</comment>
                            <comment id="13747973" author="stack" created="Thu, 22 Aug 2013 22:15:57 +0000"  >&lt;p&gt;include new files.&lt;/p&gt;</comment>
                            <comment id="13748021" author="stack" created="Thu, 22 Aug 2013 22:52:58 +0000"  >&lt;p&gt;I committed the script as a subtask.  Leaving this issue open as upgrade parent issue for doc, and anything else we can think we need related to migration.&lt;/p&gt;</comment>
                            <comment id="13749710" author="hadoopqa" created="Sun, 25 Aug 2013 17:48:24 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12599519/8348v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12599519/8348v5.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 7 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6888//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6888//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13754302" author="v.himanshu" created="Fri, 30 Aug 2013 01:39:59 +0000"  >&lt;p&gt;Attached is a help section on migration. It is in doc format; let me know if it is okay, and I will do a doc patch for it. Thanks.&lt;/p&gt;</comment>
                            <comment id="13754335" author="hadoopqa" created="Fri, 30 Aug 2013 03:19:15 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12600712/Upgradeto96.docx&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12600712/Upgradeto96.docx&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/6976//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/6976//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13767925" author="stack" created="Sun, 15 Sep 2013 21:49:09 +0000"  >&lt;p&gt;Make sure we doc. the new annotation stuff after Jon&apos;s tightening it all.&lt;/p&gt;</comment>
                            <comment id="13769793" author="v.himanshu" created="Tue, 17 Sep 2013 18:40:31 +0000"  >&lt;p&gt;So, I tested migration to 0.96 on a production quality (dirty) dataset (got a dataset dump from a 15 nodes cluster). &lt;br/&gt;
Following are some numbers.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Dataset%3A&quot;&gt;&lt;/a&gt;Dataset:&lt;/h5&gt;
&lt;p&gt;1) Tables: 100&lt;br/&gt;
2) Number of regions: 743&lt;br/&gt;
3) RS on original cluster: 15&lt;br/&gt;
4) Logs to split: 425 wal files, 26G&lt;br/&gt;
5) Number of HFiles to detect for HFileV1: ~ 4k&lt;br/&gt;
6) Snapshots: 4&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Upgradenumbers%3A&quot;&gt;&lt;/a&gt;Upgrade numbers:&lt;/h5&gt;
&lt;p&gt;1) Time for hfilev1 checker: ~ 15s&lt;br/&gt;
2) Time to do log split (offline mode): 900s (15min)&lt;/p&gt;

&lt;p&gt;The destination cluster is 4 RS + 1 master. &lt;br/&gt;
Looking at the logs, cluster UI, the upgrade is successful.&lt;/p&gt;

&lt;p&gt;It is to note that for upgrade, we recommend clean shutdown of the 94.x cluster; the above test is an example of a very bad shutdown (425 WAL files across 15 regionservers to split).&lt;/p&gt;</comment>
                            <comment id="13769800" author="stack" created="Tue, 17 Sep 2013 18:46:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; Excellent&lt;/p&gt;</comment>
                            <comment id="13772644" author="stack" created="Fri, 20 Sep 2013 05:42:34 +0000"  >&lt;p&gt;Downing to critical.  I see only doc outstanding in this issue.&lt;/p&gt;</comment>
                            <comment id="13773216" author="v.himanshu" created="Fri, 20 Sep 2013 17:30:05 +0000"  >&lt;p&gt;For migration, it looks we have already doc&apos;ed the required stuff in the ref guide.&lt;br/&gt;
For API related changes, I think it should be done in a separate jira (related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9245&quot; title=&quot;Remove dead or deprecated code from hbase 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9245&quot;&gt;&lt;del&gt;HBASE-9245&lt;/del&gt;&lt;/a&gt; and its likes)? Please let me know if I miss anything. Thanks.&lt;/p&gt;</comment>
                            <comment id="13773234" author="stack" created="Fri, 20 Sep 2013 17:46:46 +0000"  >&lt;p&gt;Resolving as done.  I just added the last minor but of doc on what it looks like when old client connects to new cluster.  Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=himanshu%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;himanshu@cloudera.com&quot;&gt;Himanshu Vashishtha&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rajesh23&quot; class=&quot;user-hover&quot; rel=&quot;rajesh23&quot;&gt;rajeshbabu&lt;/a&gt; for the great work done in here.&lt;/p&gt;</comment>
                            <comment id="15015888" author="lars_francke" created="Fri, 20 Nov 2015 11:53:01 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12662007">HBASE-9134</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12630791">HBASE-7766</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12661156">HBASE-9110</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12664720">HBASE-9278</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12662936">HBASE-9177</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12654040">HBASE-8778</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599519" name="8348v5.txt" size="47535" author="stack" created="Thu, 22 Aug 2013 22:15:57 +0000"/>
                            <attachment id="12599518" name="8348v5.txt" size="15342" author="stack" created="Thu, 22 Aug 2013 22:14:56 +0000"/>
                            <attachment id="12598905" name="HBASE-8348-approach-2-v2.1.patch" size="46946" author="v.himanshu" created="Tue, 20 Aug 2013 05:09:17 +0000"/>
                            <attachment id="12599058" name="HBASE-8348-approach-2-v2.2.patch" size="47079" author="v.himanshu" created="Tue, 20 Aug 2013 23:25:03 +0000"/>
                            <attachment id="12599440" name="HBASE-8348-approach-2-v2.3.patch" size="47120" author="v.himanshu" created="Thu, 22 Aug 2013 14:58:36 +0000"/>
                            <attachment id="12599497" name="HBASE-8348-approach-2-v2.4.patch" size="48285" author="v.himanshu" created="Thu, 22 Aug 2013 21:16:26 +0000"/>
                            <attachment id="12598566" name="HBASE-8348-approach-2.patch" size="44506" author="v.himanshu" created="Sat, 17 Aug 2013 01:30:18 +0000"/>
                            <attachment id="12598610" name="HBASE-8348-approach-3.patch" size="38039" author="rajesh23" created="Sat, 17 Aug 2013 17:13:54 +0000"/>
                            <attachment id="12592303" name="HBASE-8348_trunk.patch" size="12941" author="rajesh23" created="Mon, 15 Jul 2013 10:09:06 +0000"/>
                            <attachment id="12592318" name="HBASE-8348_trunk_v2.patch" size="13529" author="rajesh23" created="Mon, 15 Jul 2013 11:52:52 +0000"/>
                            <attachment id="12597935" name="HBASE-8348_trunk_v3.patch" size="19633" author="rajesh23" created="Wed, 14 Aug 2013 10:14:34 +0000"/>
                            <attachment id="12600712" name="Upgradeto96.docx" size="7083" author="v.himanshu" created="Fri, 30 Aug 2013 01:39:59 +0000"/>
                            <attachment id="12600711" name="Upgradeto96.pdf" size="93863" author="v.himanshu" created="Fri, 30 Aug 2013 01:39:59 +0000"/>
                            <attachment id="12599364" name="log" size="10069" author="v.himanshu" created="Thu, 22 Aug 2013 06:04:44 +0000"/>
                            <attachment id="12599496" name="log-2" size="13717" author="v.himanshu" created="Thu, 22 Aug 2013 21:15:08 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12661156">HBASE-9110</subtask>
                            <subtask id="12665137">HBASE-9311</subtask>
                            <subtask id="12666445">HBASE-9406</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>15.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 17 Apr 2013 02:00:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323044</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1jqhz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323389</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Added upgrade script that must be run moving a 0.92.x or 0.94.x era hbase dataset to 0.96.x</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>