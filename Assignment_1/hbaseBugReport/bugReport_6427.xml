<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:36:40 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6427/HBASE-6427.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6427] Pluggable compaction and scan policies via coprocessors</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6427</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;When implementing higher level stores on top of HBase it is necessary to allow dynamic control over how long KVs must be kept around.&lt;br/&gt;
Semi-static config options for ColumnFamilies (# of version or TTL) is not sufficient.&lt;/p&gt;

&lt;p&gt;This can be done with a few additional coprocessor hooks, or by makeing Store.ScanInfo pluggable.&lt;/p&gt;

&lt;p&gt;Was:&lt;br/&gt;
The simplest way to achieve this is to have a pluggable class to determine the smallestReadpoint for Region. That way outside code can control what KVs to retain.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599399">HBASE-6427</key>
            <summary>Pluggable compaction and scan policies via coprocessors</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="lhofhansl">Lars Hofhansl</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 04:23:27 +0000</created>
                <updated>Thu, 2 May 2013 02:29:54 +0000</updated>
                            <resolved>Tue, 31 Jul 2012 04:00:52 +0000</resolved>
                                                    <fixVersion>0.94.2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                                                            <comments>
                            <comment id="13418922" author="lhofhansl" created="Fri, 20 Jul 2012 05:09:28 +0000"  >&lt;p&gt;Let me clarify what I mean by this:&lt;br/&gt;
If I wanted to implement an MVCC based optimistic transaction engine on top of HBase I would naturally want to use HBase&apos;s built in versioning (where possible).&lt;br/&gt;
In that case it is not clear a priori how many versions to keep or for how long (i.e. specifying VERSION/TTL is too static). The outside engine would need to determine that.&lt;br/&gt;
The simplest of all approaches would be to do that via the smallestReadpoint in each region, by making its determination pluggable.&lt;/p&gt;</comment>
                            <comment id="13422394" author="lhofhansl" created="Wed, 25 Jul 2012 16:40:22 +0000"  >&lt;p&gt;The other scenario where this is useful is for M/R based incremental backups (as described here: &lt;a href=&quot;http://hadoop-hbase.blogspot.com/2012/04/timestamp-consistent-backups-in-hbase.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop-hbase.blogspot.com/2012/04/timestamp-consistent-backups-in-hbase.html&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The backup tools can then control exactly what data to keep, while the backups are running.&lt;br/&gt;
The actual plugged policy would probably coordinate via ZK.&lt;/p&gt;</comment>
                            <comment id="13422438" author="lhofhansl" created="Wed, 25 Jul 2012 17:32:19 +0000"  >&lt;p&gt;Upon further scrutiny, that would actually not work, because any external code would have no knowledge about the internal memstoreTSs.&lt;/p&gt;

&lt;p&gt;Perhaps a better option would be to make the expiration policy of a column family pluggable. That way TTL and # versions could be controlled from the outside.&lt;/p&gt;</comment>
                            <comment id="13422609" author="lhofhansl" created="Wed, 25 Jul 2012 21:01:51 +0000"  >&lt;p&gt;Yet another way of looking at is new coprocessor hook.&lt;br/&gt;
That would be a hook that sits before the StoreScanner is created (in Store.internalFlushCache and Store.compact) and be passed the set of scanners to use, the store and whether this is a major compaction or not (in the compaction case). Then this hook could optionally return a scanner, and if non-null scanner is return that will be used for the flush/compaction.&lt;/p&gt;

&lt;p&gt;Now, there already are preFlush and preCompact hooks (interestingly the preFlush is at the region level, whereas the preCompact is at the store level, which is not quite right I think, I wonder whether we can change that), so I&apos;m having a hard time naming these hooks accordingly. &quot;preScannerFlush&quot;, &quot;preScannerCompact&quot; doesn&apos;t quite sound right.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; Do you have an opinion?&lt;/p&gt;</comment>
                            <comment id="13422885" author="lhofhansl" created="Thu, 26 Jul 2012 04:19:21 +0000"  >&lt;p&gt;Here&apos;s an initial idea for a patch.&lt;br/&gt;
For this to work coprocessors need to have access to KeyValueScanner, StoreScanner, etc. So that is violating/leaking some of the previous abstractions.&lt;/p&gt;

&lt;p&gt;This patch would allow a coprocessor to actually produce a scanner for a flush or a compaction, while not requiring it to reimplement all the logic.&lt;br/&gt;
A coprocessor can now in fact just override the TTL and/or # versions for a flush/compaction.&lt;/p&gt;

&lt;p&gt;Please let me know what you think and how to improve this.&lt;br/&gt;
And for the love of god, please think of better names for the two new hooks.&lt;/p&gt;</comment>
                            <comment id="13423305" author="apurtell" created="Thu, 26 Jul 2012 18:06:18 +0000"  >&lt;p&gt;Or use polymorphism?&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+  public InternalScanner preFlush(final ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c,
+      Store store, KeyValueScanner scanner) throws IOException;
+
+  @Deprecated
   public void preFlush(ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; e) throws IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+  public InternalScanner preCompact(final ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c,
+      Store store, List&amp;lt;? extends KeyValueScanner&amp;gt; scanners, ScanType scanType, long earliestPutTs)
+      throws IOException;
+
+  @Deprecated
   public void preCompact(ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; e
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13423325" author="lhofhansl" created="Thu, 26 Jul 2012 18:23:29 +0000"  >&lt;p&gt;Uh... I like that.&lt;/p&gt;</comment>
                            <comment id="13423363" author="lhofhansl" created="Thu, 26 Jul 2012 19:12:05 +0000"  >&lt;p&gt;New patch&lt;/p&gt;</comment>
                            <comment id="13423365" author="lhofhansl" created="Thu, 26 Jul 2012 19:16:26 +0000"  >&lt;p&gt;The part I still have think through is how to handle actual use scans. Be default a user scan will also filter TTL/Versions, so it&apos;s one thing to prevent the KVs from being compacted away and another to actually make them visible to user scans.&lt;br/&gt;
A similar approach can be followed in preScannerOpen, as long as the coprocessor has enough access to internal region data structure to rebuild the default scanner.&lt;/p&gt;</comment>
                            <comment id="13423367" author="apurtell" created="Thu, 26 Jul 2012 19:18:27 +0000"  >&lt;p&gt;BaseRegionObserver should reimplement the default behavior in the new methods? Anybody who inherits would get it.&lt;/p&gt;</comment>
                            <comment id="13423368" author="apurtell" created="Thu, 26 Jul 2012 19:19:38 +0000"  >&lt;p&gt;Or, better yet, BaseRegionObserver calls out to a Store static method that does it, with some javadoc to make it clear what&apos;s going on?&lt;/p&gt;</comment>
                            <comment id="13423372" author="lhofhansl" created="Thu, 26 Jul 2012 19:26:49 +0000"  >&lt;p&gt;Hmm... The default behavior is followed when RegionObserver.pre&lt;/p&gt;
{flush|compact}
&lt;p&gt; return a null scanner, which is what BaseRegionObserver does by default.&lt;br/&gt;
BaseRegionObserver implementing the default behavior would not really buy anything (unless I am missing something).&lt;/p&gt;

&lt;p&gt;As for last comment above, I think we&apos;d need a preStoreScannerOpen, which would be called in Store.getScanner (right before the new StoreScanner is created) to allow the coprocessor to return a custom scanner here too.&lt;/p&gt;</comment>
                            <comment id="13423374" author="apurtell" created="Thu, 26 Jul 2012 19:29:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;The default behavior is followed when RegionObserver.pre{flush|compact} return a null scanner, which is what BaseRegionObserver does by default.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fine, I was misled by the unit test code.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think we&apos;d need a preStoreScannerOpen, which would be called in Store.getScanner (right before the new StoreScanner is created) to allow the coprocessor to return a custom scanner here too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds good to me.&lt;/p&gt;</comment>
                            <comment id="13423384" author="lhofhansl" created="Thu, 26 Jul 2012 19:41:39 +0000"  >&lt;p&gt;Of course this has to be compared to simply making the ScanInfo pluggable in Store.java. &lt;/p&gt;

&lt;p&gt;What I want to achieve here is to have an external process (backup tool, transaction engine, etc) to be able to override HBase&apos;s default TTL/#Versions with very high fidelity (i.e. not via a dynamic schema change, which is too heavyweight/slow).&lt;/p&gt;

&lt;p&gt;The coprocessor approach is nice, because it provides a lot of flexibility for other future use cases and it does not invent a new concept. At the same time it adds complexity.&lt;/p&gt;</comment>
                            <comment id="13423387" author="apurtell" created="Thu, 26 Jul 2012 19:45:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;The coprocessor approach is nice, because it provides a lot of flexibility for other future use cases and it does not invent a new concept. At the same time it adds complexity.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;On balance the API change here is nice because it extends something that was too limited to address your use case such that now it works for you, and it also admits the possibility of others.&lt;/p&gt;</comment>
                            <comment id="13423445" author="lhofhansl" created="Thu, 26 Jul 2012 20:40:14 +0000"  >&lt;p&gt;Add preStoreScannerOpen(...) to RegionObserver and related classes.&lt;/p&gt;

&lt;p&gt;Runs all of TestFromClientSide and TestCompaction with such a coprocessor.&lt;/p&gt;</comment>
                            <comment id="13423469" author="apurtell" created="Thu, 26 Jul 2012 21:11:30 +0000"  >&lt;p&gt;lgtm, good tests&lt;/p&gt;</comment>
                            <comment id="13423501" author="hadoopqa" created="Thu, 26 Jul 2012 22:01:42 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12538075/6427-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12538075/6427-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 24 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 14 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestFromClientSide&lt;br/&gt;
                  org.apache.hadoop.hbase.client.TestAdmin&lt;br/&gt;
                  org.apache.hadoop.hbase.catalog.TestMetaReaderEditor&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2440//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13423548" author="lhofhansl" created="Thu, 26 Jul 2012 23:17:31 +0000"  >&lt;p&gt;I ran the failing tests locally, and they all pass.&lt;br/&gt;
Will sit on this a bit longer, write a test that tests the actual scenario I am interested in, etc.&lt;/p&gt;</comment>
                            <comment id="13423679" author="lhofhansl" created="Fri, 27 Jul 2012 05:10:27 +0000"  >&lt;p&gt;v3... Fixes some things, and verifies the new scenarios.&lt;br/&gt;
Still not quite done, yet, just need a place to &quot;park&quot; it.&lt;br/&gt;
preStoreScannerOpen will be called for Gets (which is good), including internal Gets (or append/increment/delete/etc). I &lt;b&gt;think&lt;/b&gt; this is OK in all cases, but need to make sure.&lt;/p&gt;

&lt;p&gt;Edit: Spelling&lt;/p&gt;</comment>
                            <comment id="13423694" author="hadoopqa" created="Fri, 27 Jul 2012 06:02:36 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12538127/6427-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12538127/6427-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 27 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 14 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.replication.TestReplication&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestAssignmentManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2445//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13424235" author="lhofhansl" created="Sat, 28 Jul 2012 00:34:54 +0000"  >&lt;p&gt;This has all the functionality I want.&lt;br/&gt;
The new TTL test is subject to races if the test env is &lt;b&gt;really&lt;/b&gt; slow.&lt;/p&gt;

&lt;p&gt;Will play with EnvironmentEdgeManager to control time for these test to avoid these races.&lt;/p&gt;

&lt;p&gt;Please review the other parts of the code.&lt;br/&gt;
Is there some better refactoring I can do to StoreScanner in order to make this a bit easier on anybody who wants override some functionality?&lt;/p&gt;</comment>
                            <comment id="13424268" author="lhofhansl" created="Sat, 28 Jul 2012 05:15:14 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;used EnvironmentEdge in TestCoprocessorScanPolicy to avoid races.&lt;/li&gt;
	&lt;li&gt;added ScanType which was missing in v4&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13424270" author="zhihyu@ebaysf.com" created="Sat, 28 Jul 2012 05:24:39 +0000"  >&lt;p&gt;Some new files need license header.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class ScanPolicyCoprocessor &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; BaseRegionObserver {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This class is an observer. Suggest renaming the class.&lt;br/&gt;
Annotations for audience and stability should be added.&lt;/p&gt;

&lt;p&gt;For RegionCoprocessorHost.preCompact():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          scanner = ((RegionObserver) env.getInstance()).preCompact(ctx, store, scanners,
+              scanType, earliestPutTs);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If there&apos;re multiple RegionObserver&apos;s, it seems only the final returned scanner would be returned. Is this intentional ?&lt;br/&gt;
Similar observation for preStoreScannerOpen() and preFlush()&lt;/p&gt;</comment>
                            <comment id="13424273" author="lhofhansl" created="Sat, 28 Jul 2012 05:34:42 +0000"  >&lt;p&gt;Thanks Ted. You are right on all counts. Need to think about multiple coprocessors a bit more.&lt;/p&gt;</comment>
                            <comment id="13424275" author="lhofhansl" created="Sat, 28 Jul 2012 05:39:21 +0000"  >&lt;p&gt;The current preCompact/preScannerOpen/other hooks handle this by passing the scanner from the previous coprocessor to the next one, so that each coprocessor has all the information needed.&lt;br/&gt;
I could do something similar here, although it would quickly get inscrutable for an implemented of these hooks; but I cannot think of anything better.&lt;/p&gt;</comment>
                            <comment id="13424281" author="hadoopqa" created="Sat, 28 Jul 2012 06:12:16 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12538229/6427-v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12538229/6427-v5.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 33 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster&lt;br/&gt;
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestAssignmentManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2450//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13424367" author="zhihyu@ebaysf.com" created="Sat, 28 Jul 2012 15:44:32 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+          scanner = ((RegionObserver) env.getInstance()).preCompact(ctx, store, scanners,
+              scanType, earliestPutTs);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Maybe insert the returned scanner (if not null) into scanners ?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * @deprecated use {@link #preCompact(ObserverContext, Store, List, ScanType, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)} instead
    */
   InternalScanner preCompact(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c,
       &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; InternalScanner scanner) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Do we have to deprecate the existing API ? I feel the new API is much more involved in terms of technical internals. Maybe a poll on user mailing list would help clarify.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * @param scanners the list {@link StoreFileScanner}s to be read from
...
+  InternalScanner preCompact(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c,
+      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, List&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; KeyValueScanner&amp;gt; scanners, ScanType scanType, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; earliestPutTs)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;nit: the second line above is over 100 characters.&lt;br/&gt;
If scanners really should be StoreFileScanner&apos;s, method signature should match expectation.&lt;br/&gt;
See the following in RegionCoprocessorHost.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+   * See {@link RegionObserver#preCompact(ObserverContext, Store, InternalScanner)}
+   */
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; InternalScanner preCompact(Store store, List&amp;lt;StoreFileScanner&amp;gt; scanners,
+      ScanType scanType, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; earliestPutTs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Review board would facilitate more detailed review.&lt;/p&gt;</comment>
                            <comment id="13424416" author="zhihyu@ebaysf.com" created="Sat, 28 Jul 2012 20:25:27 +0000"  >&lt;p&gt;Looking at the changes to Compactor.compact(), the new preCompact() takes precedence over existing preCompact() method.&lt;br/&gt;
This should be documented.&lt;/p&gt;

&lt;p&gt;My comment above about scanner insertion was not valid.&lt;br/&gt;
It is not clear why more than one RegionObserver would return InternalScanner from preCompact(). For simplicity, we can break out of the loop in RegionCoprocessorHost.preCompact() when a non-null InternalScanner is returned.&lt;br/&gt;
This behavior should also be documented.&lt;/p&gt;</comment>
                            <comment id="13424425" author="lhofhansl" created="Sat, 28 Jul 2012 20:57:43 +0000"  >&lt;p&gt;I think we should what the current preScannerOpen is doing. Each RegionObserver is passed the previous InternalScanner (would be a KeyValueScanner here, but the same principle applies). A RegionObserver can break the loop via the passed Context, I do not think we should default that bevahior. I&apos;ll have a patch for that soon.&lt;/p&gt;

&lt;p&gt;As for the deprecation, I think I agree with Andy here. Having the two hooks is confusion. Everything that could be done with the old can also be done with the new hook, and coprocessors are meant for extending HBase.&lt;/p&gt;

&lt;p&gt;Re: StoreFileScanner vs ? extends KeyValueScanner... I typically prefer to express this in terms interface, rather than concrete classes. It also keep preCompact and preFlush similar (one gets a list of StoreFileScanners, the other gets a StoreScanner). I do not feel strongly about this, though.&lt;/p&gt;

&lt;p&gt;I&apos;ll change the patch and put it up on RB... Thanks for the detailed review Ted!&lt;/p&gt;</comment>
                            <comment id="13424433" author="apurtell" created="Sat, 28 Jul 2012 21:30:44 +0000"  >&lt;p&gt;Agree that scanners should be passed along.  The use case is subsequent observers wrapping scanners created by those earlier in the chain.&lt;/p&gt;

&lt;p&gt;Also we should deprecate and remove the older more limited hooks now that we have a superset interface that admits more possibilities.&lt;/p&gt;</comment>
                            <comment id="13424449" author="lhofhansl" created="Sat, 28 Jul 2012 22:35:46 +0000"  >&lt;p&gt;Interestingly I would like to have the ability to bypass the default action from both preFlush and preCompact, for example to control how the store files are written.&lt;br/&gt;
With the new hooks there is no way to indicate that (null means &quot;create the default scanner&quot;, non-null means use the returned scanner, but still follow the default action).&lt;/p&gt;

&lt;p&gt;The hook just prior to creating the scanner could create a new scanner (and hence decide how to filter the inputs) the hook right after scanner creation could then control how/where to write the store files.&lt;/p&gt;

&lt;p&gt;So maybe have a preCompactScannerOpen, and preFlushScannerOpen (similar to my initial idea), and not deprecating the existing hooks?&lt;/p&gt;</comment>
                            <comment id="13424451" author="apurtell" created="Sat, 28 Jul 2012 22:45:19 +0000"  >&lt;p&gt;Then you want to restore this behavior:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// NULL scanner returned from coprocessor hooks means skip normal processing
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Can that work? &lt;/p&gt;

&lt;p&gt;I&apos;d not be opposed to adding additional hooks but that should be after exhausting other options here, IMHO, since they would be &quot;close&quot; to each other.&lt;/p&gt;

&lt;p&gt;We could pass in the default StoreScanner. The hook could just return it if wanting default behavior. Might need to make StoreScanner lazy, move initialization out of the constructor. I&apos;m remote and just have your patch to go by at the moment.&lt;/p&gt;</comment>
                            <comment id="13424453" author="zhihyu@ebaysf.com" created="Sat, 28 Jul 2012 22:57:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;null means &quot;create the default scanner&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Maybe create a special class (called NullScanner ?) implementing InternalScanner. The class provides a singleton which can be returned by preCompact() to indicate skipping normal processing.&lt;/p&gt;</comment>
                            <comment id="13424458" author="lhofhansl" created="Sat, 28 Jul 2012 23:34:19 +0000"  >&lt;p&gt;After reviewing all the use cases I have this seems to be best proposal:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;add these
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
void postFlush(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; StoreFile resultFile) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
InternalScanner preFlush(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; InternalScanner scanner) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
InternalScanner preFlushScannerOpen(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; KeyValueScanner memstoreScanner, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; InternalScanner s) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
InternalScanner preCompactScannerOpen(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, List&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; KeyValueScanner&amp;gt; scanners, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ScanType scanType, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; earliestPutTs, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; InternalScanner s) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
KeyValueScanner preStoreScannerOpen(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Scan scan, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; NavigableSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; targetCols, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; KeyValueScanner s) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;deprecate these:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
void postFlush(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
void preFlush(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The new &lt;/p&gt;
{pre|post}Flush are called per Store in analogy to {pre|post}
&lt;p&gt;Compact.&lt;br/&gt;
pre&lt;/p&gt;
{Flush|Compact}
&lt;p&gt;ScannerOpen are called before the flush/compaction scanner is built.&lt;/p&gt;

&lt;p&gt;This is give maximum flexibility (I can control the reading scanners &lt;b&gt;and&lt;/b&gt; how the storefiles are written for both flushes and compactions), makes more sense of &lt;/p&gt;
{pre|post}
&lt;p&gt;Flush and leave existing functionality in place.&lt;/p&gt;

&lt;p&gt;This is the first proposal that really &quot;feels&quot; right to me. I&apos;ll have a patch for that soon.&lt;/p&gt;</comment>
                            <comment id="13424459" author="lhofhansl" created="Sat, 28 Jul 2012 23:41:56 +0000"  >&lt;p&gt;Here&apos;s a patch for that.&lt;br/&gt;
I&apos;ll also put that up on RB.&lt;/p&gt;</comment>
                            <comment id="13424463" author="hadoopqa" created="Sun, 29 Jul 2012 00:43:46 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12538259/6427-v7.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12538259/6427-v7.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 33 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.master.TestMasterNoCluster&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2451//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13424464" author="lhofhansl" created="Sun, 29 Jul 2012 01:00:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;d not be opposed to adding additional hooks but that should be after exhausting other options here, IMHO, since they would be &quot;close&quot; to each other.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do you think the latest proposal is too heavy handed? pre&lt;/p&gt;
{Flush|Compact}ScannerOpen would be quite close to pre{Flush|Compact}
&lt;p&gt;. My reasoning was that an implementer could still override the relatively simple pre&lt;/p&gt;
{Flush|Compact}
&lt;p&gt; hooks.&lt;br/&gt;
If these are too many, we can still have only the fewer hooks, and then we&apos;d need some &quot;NullScanner&quot; approach I think.&lt;/p&gt;</comment>
                            <comment id="13424466" author="apurtell" created="Sun, 29 Jul 2012 01:28:13 +0000"  >&lt;p&gt;It&apos;s fine. I like how you made the new APIs about opening (internal) scanners for various things. &lt;/p&gt;</comment>
                            <comment id="13424622" author="zhihyu@ebaysf.com" created="Sun, 29 Jul 2012 20:27:19 +0000"  >&lt;p&gt;Review board doesn&apos;t show correct formatting. So I put the following here.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;to make a new Interface extending both InternalScanner and KeyValueScanner&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I like the above approach.&lt;br/&gt;
Currently we have:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ find src/main -name &apos;*.java&apos; -exec grep &apos;ments.*InternalScanner&apos; {} \; -print
 * also &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; InternalScanner.  WARNING: As is, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; to use &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; KeyValueScanner, InternalScanner {
src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java
    &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; KeyValueScanner, InternalScanner, ChangedReadersObserver {
src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Combining InternalScanner and KeyValueScanner seems natural.&lt;/p&gt;</comment>
                            <comment id="13424655" author="lhofhansl" created="Mon, 30 Jul 2012 01:23:19 +0000"  >&lt;p&gt;Thinking on this more... I think the pre&lt;/p&gt;
{Flush|Compact}
&lt;p&gt;ScannerOpen hooks should just continue to return InternalScanner. Only that interface is needed by downstream code and we should not extend this only so that coprocessor chaining becomes simpler.&lt;br/&gt;
As it stands these hooks &lt;b&gt;can&lt;/b&gt; use the passed InternalScanner, but it needs some understanding of HBase... Which is needed anyway to correctly deal with chained scanners for flush or compactions.&lt;/p&gt;

&lt;p&gt;I.e. I propose leaving it with what the current patch provides. Not opposed to filing a separate ticket to bring more sense into the various scanner interfaces we have.&lt;/p&gt;</comment>
                            <comment id="13424657" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 01:37:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;to correctly deal with chained scanners&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I personally haven&apos;t seen chained scanners in action.&lt;/p&gt;

&lt;p&gt;If we don&apos;t think through how chained scanners work, I wouldn&apos;t expect HBase users to use this mechanism.&lt;/p&gt;</comment>
                            <comment id="13424658" author="lhofhansl" created="Mon, 30 Jul 2012 01:45:44 +0000"  >&lt;p&gt;It&apos;s used rarely, because coprocessors are not like store procedures, but a method to extend HBase.&lt;/p&gt;

&lt;p&gt;We &lt;b&gt;have&lt;/b&gt; through it (IMHO), and the coprocessors now can be chained, and due to the nature of these hooks that will be tricky.&lt;br/&gt;
For example even if we managed to pass in a KeyValueScanner instance, folks would be tempted to just add this one to the List of scanners down the chain (as was your first thought above), which is tempting, but will not be the right thing to do; the downstream must do some complicated logic to merge with the previous scanner in ways that we cannot anticipate.&lt;/p&gt;</comment>
                            <comment id="13424663" author="apurtell" created="Mon, 30 Jul 2012 02:16:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;I personally haven&apos;t seen chained scanners in action. If we don&apos;t think through how chained scanners work, I wouldn&apos;t expect HBase users to use this mechanism.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ted, this is a great comment, because I think it illustrates an incorrect approach to CP API design. (Not meant to be a criticism of you. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) CPs are targeted as much for HBase developers as they might be for users. The fundamental goal of CPs is to avoid needing to patch core HBase code for implementing new features or researching design alternatives. &lt;/p&gt;</comment>
                            <comment id="13424664" author="apurtell" created="Mon, 30 Jul 2012 02:20:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; A follow up JIRA to discuss refactoring the internal scanner interfaces would be reasonable. We do want for extensions to be able to wrap and merge scanners along CP chains.&lt;/p&gt;</comment>
                            <comment id="13424665" author="apurtell" created="Mon, 30 Jul 2012 02:24:03 +0000"  >&lt;p&gt;And a follow up note to my above comment: It is a goal to provide adequate extension surface (and I include here besides CPs also other pluggable interfaces where performance considerations are paramount) so new features or design alternatives require no core code patches. IMHO, the design strategy for this goal should be incremental, driven by actual use cases, but with foresight added. This issue is a good example of that I think, Lars has really improved flush and compaction hooks, and this work hasn&apos;t been done in the abstract.&lt;/p&gt;</comment>
                            <comment id="13424667" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 02:28:11 +0000"  >&lt;p&gt;I understand the goal for this JIRA and am in support of it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the downstream must do some complicated logic to merge with the previous scanner in ways that we cannot anticipate.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This illustrates the intricacies of scanner chaining. If a scanner is designed for some specific purpose, I wouldn&apos;t expect it to function correctly when an arbitrary number of scanners are chained (both) upstream and downstream.&lt;br/&gt;
In fact, chaining introduces unnecessary burden on individual scanner.&lt;/p&gt;</comment>
                            <comment id="13424669" author="apurtell" created="Mon, 30 Jul 2012 02:38:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;I understand the goal for this JIRA and am in support of it. &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt; This illustrates the intricacies of scanner chaining. If a scanner is designed for some specific purpose, I wouldn&apos;t expect it to function correctly when an arbitrary number of scanners are chained (both) upstream and downstream.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Pardon Ted but I think this is an X-Y argument. I&apos;m not sure we are discussing the chaining of &lt;em&gt;arbitrary&lt;/em&gt; scanners (unless I have this wrong.) Each CP hook is dealing with a constrained set of scanners. Flushes will be dealing with memstore scanners. Compactions will be dealing with store scanners. The question has been what kind of interface should input parameters and return types share, there&apos;s some design give-and-take there. But we are not talking about, for example, combining memstore scanners with store scanners. (At least, I am not.)&lt;/p&gt;</comment>
                            <comment id="13424671" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 02:58:41 +0000"  >&lt;p&gt;There is no intersection between memstore scanners and store scanners.&lt;/p&gt;

&lt;p&gt;The arbitrary number of scanners is due to the following construct:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (RegionEnvironment env: coprocessors) {
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (env.getInstance() &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; RegionObserver) {
+        ctx = ObserverContext.createAndPrepare(env, ctx);
+        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+          s = ((RegionObserver) env.getInstance()).preCompactScannerOpen(ctx, store, scanners,
+              scanType, earliestPutTs, s);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think we should reduce the complexity (due to scanner chaining) for preCompactScannerOpen().&lt;br/&gt;
If we don&apos;t provide a working model for scanner chaining, there is no need to introduce construct for chaining scanners.&lt;/p&gt;</comment>
                            <comment id="13424672" author="lhofhansl" created="Mon, 30 Jul 2012 03:06:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;This illustrates the intricacies of scanner chaining.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think that is a false transitive statement. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
For this particular hook chaining is hard, because this is an intricate part of the HBase code. That does not mean that chaining is generally hard (it is not).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I wouldn&apos;t expect it to function correctly when an arbitrary number of scanners are chained (both) upstream and downstream.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Same here... The point is: It is possible to chain region observers even in this case.&lt;br/&gt;
If that is not desired an implementer can break the chain (via the passed context. and by ignoring the InternalScanner argument).&lt;/p&gt;</comment>
                            <comment id="13424673" author="lhofhansl" created="Mon, 30 Jul 2012 03:11:50 +0000"  >&lt;p&gt;Also another thought: I wonder how hard it is to fold custom timestamps into this. An example of what I mean is time dimension that uses monotonically increasing transaction numbers.&lt;br/&gt;
A slight API change to the StoreScanner constructor would make it possible to handle that too: By passing in the absolute &quot;time&quot; at which a KV expires rather than the TTL (which it then internally translates to an absolute time anyway, and which in turn depends on the RegionServer&apos;s understanding of time, which is not configurable).&lt;/p&gt;</comment>
                            <comment id="13424674" author="lhofhansl" created="Mon, 30 Jul 2012 03:14:34 +0000"  >&lt;p&gt;Re: Ted&apos;s last comment. So you want to enforce that only a single coprocessor can implement these hooks? I would disagree with that.&lt;br/&gt;
The chaining is fine (if complicated), no need to mandate what an implementer can and cannot do (see my previous comment).&lt;/p&gt;</comment>
                            <comment id="13424676" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 03:18:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;If that is not desired an implementer can break the chain&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If implementer X breaks the chain, how would implementer Z know that his/her implementation is not broken by someone else ?&lt;br/&gt;
There is no deterministic order in which X and Z&apos;s observers are registered.&lt;/p&gt;</comment>
                            <comment id="13424680" author="lhofhansl" created="Mon, 30 Jul 2012 03:43:46 +0000"  >&lt;p&gt;Ted, you are trying to redesign the overall coprocessor API.&lt;br/&gt;
I would prefer that we can keep the API as is, and then work on ways to make better sense of the scanners as part of a different jira.&lt;/p&gt;

&lt;p&gt;As Andy said a major raison d&apos;etre for coprocessors is to extend HBase. Nobody would just run a 3rd party coprocessor (unless that party is highly trusted). A coprocessor could call System.exit() and shut down the RegionServer... And that was a design choice.&lt;/p&gt;</comment>
                            <comment id="13424690" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 04:26:57 +0000"  >&lt;p&gt;For preCompactScannerOpen() / preFlushScannerOpen(), they&apos;re new APIs and serve particular use case if implemented.&lt;br/&gt;
I feel there is no need to pass InternalScanner as parameter.&lt;/p&gt;

&lt;p&gt;Just my personal observation.&lt;/p&gt;</comment>
                            <comment id="13424697" author="lhofhansl" created="Mon, 30 Jul 2012 04:56:24 +0000"  >&lt;p&gt;I see your point.&lt;/p&gt;

&lt;p&gt;But then you&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;need a mechanism to only allow a single RegionObserver to implement these hooks.&lt;/li&gt;
	&lt;li&gt;placed an arbitrary limit on the API (only because it is hard to chain the hooks here, does not mean it is impossible or not useful, as I said one can always create a new implementing class of InternalScanner that does the right thing)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This follows the coprocessor API pattern. I think this should be kept.&lt;/p&gt;</comment>
                            <comment id="13425063" author="lhofhansl" created="Mon, 30 Jul 2012 18:05:48 +0000"  >&lt;p&gt;Latest patch from RB.&lt;/p&gt;

&lt;p&gt;Does this need more discussion, or is this good to go?&lt;br/&gt;
Ted, Andy?&lt;/p&gt;</comment>
                            <comment id="13425084" author="apurtell" created="Mon, 30 Jul 2012 18:19:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;There is no deterministic order in which X and Z&apos;s observers are registered.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ted, every coprocessor is registered in order of priority by design. There is always a deterministic order of observers. Frankly, this is something basic about CPs you should already understand if providing design comment on CP API.&lt;/p&gt;</comment>
                            <comment id="13425086" author="apurtell" created="Mon, 30 Jul 2012 18:19:45 +0000"  >&lt;p&gt;@Lars, lgtm.&lt;/p&gt;</comment>
                            <comment id="13425109" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 18:33:46 +0000"  >&lt;p&gt;From &lt;a href=&quot;https://blogs.apache.org/hbase/entry/coprocessor_introduction&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://blogs.apache.org/hbase/entry/coprocessor_introduction&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We have not really discussed priority, but it should be reasonably clear how the priority given to a coprocessor affects how it integrates with other coprocessors. When calling out to registered observers, the framework executes their callbacks methods in the sorted order of their priority. Ties are broken arbitrarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This means there still might be scenarios where coprocessors for the same table have the same priority.&lt;/p&gt;</comment>
                            <comment id="13425120" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 18:40:51 +0000"  >&lt;p&gt;For RegionObserver.preFlushScannerOpen(), compaction is mentioned in its javadoc several times.&lt;/p&gt;</comment>
                            <comment id="13425124" author="apurtell" created="Mon, 30 Jul 2012 18:45:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;This means there still might be scenarios where coprocessors for the same table have the same priority.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fine, that text needs update. The tie is not broken arbitrarily, it is by load order.&lt;/p&gt;

&lt;p&gt;But you are missing the larger point that both Lars and I have mentioned above, CPs are not (currently, nor likely) going to be random user modules loaded blindly with respect to each other. They are deeply embedded in HBase implementation. If as a system integrator you are deploying coprocessors, you will be engineering their load/initialization order as well as all other cluster details. Again, this is an X-Y discussion. It would be best to stick to the issues in scope to this JIRA. If there are larger design issues you&apos;d like to consider, let&apos;s open a JIRA for those.&lt;/p&gt;</comment>
                            <comment id="13425127" author="zhihyu@ebaysf.com" created="Mon, 30 Jul 2012 18:50:02 +0000"  >&lt;p&gt;I don&apos;t have further design level comments.&lt;/p&gt;</comment>
                            <comment id="13425142" author="hadoopqa" created="Mon, 30 Jul 2012 19:08:03 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12538381/6427-v10.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12538381/6427-v10.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 33 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk&apos;s current 4 warnings).&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;     -1 core tests.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/2457//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13425228" author="lhofhansl" created="Mon, 30 Jul 2012 20:56:52 +0000"  >&lt;p&gt;Thanks Ted and Andy, and thanks for the discussion.&lt;br/&gt;
I think we have two (maybe three) take-aways: (1) We need to look at the various scanner interface and see why we have so many diverging interfaces and (2) add more coprocessor documentation (maybe with some more examples) and potentially (3) think generally about what it means to extend HBase and when coprocessors are a good mechanism for that.&lt;/p&gt;

&lt;p&gt;It seems to me that coprocessors are a good solution to effect existing processing at certain (including critical) spots, but maybe not suited to replace the entire logic. In that this issue represents a corner case - which is probably what spawned the longer discussion here (the creation of the StoreScanner is replaced, and this is done in the context of a bigger operation).&lt;br/&gt;
In the future we might be able to use Guice to replace entire subsystems.&lt;/p&gt;

&lt;p&gt;For this issue I&apos;ll fix up the Javadoc issues that Ted mentions and commit this to trunk and also make a 0.94 patch.&lt;/p&gt;

&lt;p&gt;Thanks again for the review and the discussion.&lt;/p&gt;</comment>
                            <comment id="13425364" author="lhofhansl" created="Mon, 30 Jul 2012 23:16:53 +0000"  >&lt;p&gt;Committed to trunk.&lt;br/&gt;
Do we need an extra discussion about deprecating the old &lt;/p&gt;
{pre|post}
&lt;p&gt;Flush hooks in a 0.94 point release?&lt;br/&gt;
In theory we could deprecate them in 0.94 and then remove them in 0.96, but I do not feel strongly about this.&lt;/p&gt;</comment>
                            <comment id="13425387" author="apurtell" created="Mon, 30 Jul 2012 23:36:58 +0000"  >&lt;p&gt;We don&apos;t want to just yank out CP APIs, but a liberal attitude toward deprecating and removing them is fine IMO. The contract is different than with a public API. Furthermore, the interfaces haven&apos;t gelled yet. We&apos;re just starting to get interesting use cases.&lt;/p&gt;</comment>
                            <comment id="13425399" author="lhofhansl" created="Mon, 30 Jul 2012 23:45:11 +0000"  >&lt;p&gt;Fair enough.&lt;br/&gt;
Here&apos;s a patch for 0.94. Needed only slight massaging.&lt;br/&gt;
Has the old &lt;/p&gt;
{pre|post}
&lt;p&gt;Flush deprecated.&lt;/p&gt;</comment>
                            <comment id="13425470" author="hudson" created="Tue, 31 Jul 2012 02:31:34 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #116 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/116/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/116/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; Pluggable compaction and scan policies via coprocessors (Revision 1367361)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Compactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/SimpleRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/NoOpScanPolicyObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorScanPolicy.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13425474" author="hudson" created="Tue, 31 Jul 2012 02:37:19 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3185 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3185/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3185/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; Pluggable compaction and scan policies via coprocessors (Revision 1367361)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Compactor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/SimpleRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/NoOpScanPolicyObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestMemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorScanPolicy.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13425502" author="lhofhansl" created="Tue, 31 Jul 2012 04:00:53 +0000"  >&lt;p&gt;Committed to 0.94 as well.&lt;/p&gt;</comment>
                            <comment id="13425521" author="hudson" created="Tue, 31 Jul 2012 04:52:36 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #378 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/378/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/378/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; Pluggable compaction and scan policies via coprocessors (Revision 1367402)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/coprocessor/SimpleRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/NoOpScanPolicyObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestMemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorScanPolicy.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13426090" author="eclark" created="Tue, 31 Jul 2012 20:28:09 +0000"  >&lt;p&gt;An InterfaceAudience annotation slipped in here.  It breaks older hadoop versions(&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6141&quot; title=&quot;InterfaceAudience breaks 0.94 on older versions of hadoop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6141&quot;&gt;&lt;del&gt;HBASE-6141&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="13426105" author="lhofhansl" created="Tue, 31 Jul 2012 20:48:54 +0000"  >&lt;p&gt;Oops... Yes. Here&apos;s an addendum.&lt;/p&gt;</comment>
                            <comment id="13426107" author="lhofhansl" created="Tue, 31 Jul 2012 20:49:54 +0000"  >&lt;p&gt;Committed addendum, thanks for watching Elliot.&lt;/p&gt;</comment>
                            <comment id="13426114" author="eclark" created="Tue, 31 Jul 2012 20:53:05 +0000"  >&lt;p&gt;Thanks so much.&lt;/p&gt;</comment>
                            <comment id="13426167" author="hudson" created="Tue, 31 Jul 2012 22:07:17 +0000"  >&lt;p&gt;Integrated in HBase-0.94 #379 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94/379/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94/379/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; addendum (Revision 1367770)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13426193" author="lhofhansl" created="Tue, 31 Jul 2012 22:50:10 +0000"  >&lt;p&gt;I ran TestReplication locally and it passed fine. Sigh.&lt;/p&gt;</comment>
                            <comment id="13428727" author="hudson" created="Sun, 5 Aug 2012 00:51:13 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security-on-Hadoop-23 #6 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/6/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/6/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; addendum (Revision 1367770)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; Pluggable compaction and scan policies via coprocessors (Revision 1367402)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/coprocessor/SimpleRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/NoOpScanPolicyObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestMemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorScanPolicy.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13428758" author="hudson" created="Sun, 5 Aug 2012 00:58:51 +0000"  >&lt;p&gt;Integrated in HBase-0.94-security #47 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-0.94-security/47/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-0.94-security/47/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; addendum (Revision 1367770)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6427&quot; title=&quot;Pluggable compaction and scan policies via coprocessors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6427&quot;&gt;&lt;del&gt;HBASE-6427&lt;/del&gt;&lt;/a&gt; Pluggable compaction and scan policies via coprocessors (Revision 1367402)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;larsh : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/coprocessor/BaseRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/ScanType.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/coprocessor/SimpleRegionObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/HFileReadWriteTest.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/NoOpScanPolicyObserver.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionWithCoprocessor.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestMemStore.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreScanner.java&lt;/li&gt;
	&lt;li&gt;/hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorScanPolicy.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13451731" author="yuzhihong@gmail.com" created="Mon, 10 Sep 2012 01:48:23 +0000"  >&lt;p&gt;May I ask why BaseRegionObserver, a class marked with @InterfaceAudience.Public, exposes KeyValueScanner and InternalScanner which are marked @InterfaceAudience.Private ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13452487" author="lhofhansl" created="Mon, 10 Sep 2012 21:53:48 +0000"  >&lt;p&gt;Not sure. BaseRegionObserver is public, whereas KeyValueScanner and InternalScanner are not. The fact that they are in the same class file does not matter for the annotation. Right?&lt;/p&gt;</comment>
                            <comment id="13452669" author="yuzhihong@gmail.com" created="Tue, 11 Sep 2012 02:46:59 +0000"  >&lt;p&gt;In the new APIs, some return null as InternalScanner:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; InternalScanner preFlushScannerOpen(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; c,
+      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Store store, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; KeyValueScanner memstoreScanner, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; InternalScanner s)
+      &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;some return the passed in scanner:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; InternalScanner preFlush(ObserverContext&amp;lt;RegionCoprocessorEnvironment&amp;gt; e, Store store,
+      InternalScanner scanner) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; scanner;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I wonder why the difference.&lt;/p&gt;

&lt;p&gt;This feature isn&apos;t marked as incompatible feature.&lt;br/&gt;
If 0.94.1 user has some jar with custom BaseRegionObserver implementation, I wonder if he/she needs to recompile his/her code to generate new jar.&lt;/p&gt;</comment>
                            <comment id="13452681" author="lhofhansl" created="Tue, 11 Sep 2012 03:26:04 +0000"  >&lt;p&gt;We said before in various discussions that the coprocessor API is not necessarily stable, yet.&lt;br/&gt;
If you think this discussion warrants it, can you file a separate jira, please.&lt;/p&gt;</comment>
                            <comment id="13624722" author="stack" created="Sun, 7 Apr 2013 05:16:23 +0000"  >&lt;p&gt;Fix up after bulk move overwrote some 0.94.2 fix versions w/ 0.95.0 (Noticed by Lars Hofhansl)&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12599400">HBASE-6428</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12538613" name="6427-0.94-addendum.txt" size="589" author="lhofhansl" created="Tue, 31 Jul 2012 20:48:54 +0000"/>
                            <attachment id="12538457" name="6427-0.94.txt" size="59644" author="lhofhansl" created="Mon, 30 Jul 2012 23:45:10 +0000"/>
                            <attachment id="12537953" name="6427-notReady.txt" size="26885" author="lhofhansl" created="Thu, 26 Jul 2012 04:19:21 +0000"/>
                            <attachment id="12538060" name="6427-v1.txt" size="29015" author="lhofhansl" created="Thu, 26 Jul 2012 19:12:05 +0000"/>
                            <attachment id="12538381" name="6427-v10.txt" size="60540" author="lhofhansl" created="Mon, 30 Jul 2012 18:05:48 +0000"/>
                            <attachment id="12538075" name="6427-v2.txt" size="37392" author="lhofhansl" created="Thu, 26 Jul 2012 20:40:14 +0000"/>
                            <attachment id="12538127" name="6427-v3.txt" size="45394" author="lhofhansl" created="Fri, 27 Jul 2012 05:10:27 +0000"/>
                            <attachment id="12538221" name="6427-v4.txt" size="49670" author="lhofhansl" created="Sat, 28 Jul 2012 00:34:54 +0000"/>
                            <attachment id="12538229" name="6427-v5.txt" size="50342" author="lhofhansl" created="Sat, 28 Jul 2012 05:15:13 +0000"/>
                            <attachment id="12538259" name="6427-v7.txt" size="59074" author="lhofhansl" created="Sat, 28 Jul 2012 23:41:56 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12601164">HBASE-6496</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 26 Jul 2012 18:06:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>248633</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 36 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i09xcv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>55845</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>