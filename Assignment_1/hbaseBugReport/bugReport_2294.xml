<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:00:40 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-2294/HBASE-2294.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-2294] Enumerate ACID properties of HBase in a well defined spec</title>
                <link>https://issues.apache.org/jira/browse/HBASE-2294</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;It&apos;s not written down anywhere what the guarantees are for each operation in HBase with regard to the various ACID properties. I think the developers know the answers to these questions, but we need a clear spec for people building systems on top of HBase. Here are a few sample questions we should endeavor to answer:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;For a multicell put within a CF, is the update made durable atomically?&lt;/li&gt;
	&lt;li&gt;For a put across CFs, is the update made durable atomically?&lt;/li&gt;
	&lt;li&gt;Can a read see a row that hasn&apos;t been sync()ed to the HLog?&lt;/li&gt;
	&lt;li&gt;What isolation do scanners have? Somewhere between snapshot isolation and no isolation?&lt;/li&gt;
	&lt;li&gt;After a client receives a &quot;success&quot; for a write operation, is that operation guaranteed to be visible to all other clients?&lt;br/&gt;
etc&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I see this JIRA as having several points of discussion:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Evaluation of what the current state of affairs is&lt;/li&gt;
	&lt;li&gt;Evaluate whether we currently provide any guarantees that aren&apos;t useful to users of the system (perhaps we can drop in exchange for performance)&lt;/li&gt;
	&lt;li&gt;Evaluate whether we are missing any guarantees that would be useful to users of the system&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12458312">HBASE-2294</key>
            <summary>Enumerate ACID properties of HBase in a well defined spec</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/task.png">Task</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                    </labels>
                <created>Fri, 5 Mar 2010 23:25:55 +0000</created>
                <updated>Fri, 20 Nov 2015 12:42:28 +0000</updated>
                            <resolved>Tue, 20 Apr 2010 23:18:39 +0000</resolved>
                                                    <fixVersion>0.90.0</fixVersion>
                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="12845541" author="stack" created="Mon, 15 Mar 2010 21:35:47 +0000"  >&lt;p&gt;Making this a blocker on 0.21 and 0.20.4.  For 0.20.4, I think it ok if its incomplete before we release.  Not so for 0.21.&lt;/p&gt;</comment>
                            <comment id="12845575" author="ryanobjc" created="Mon, 15 Mar 2010 22:41:58 +0000"  >&lt;p&gt;So previously without durability, some of the things in here were just not applicable.  Sync = noop really doesnt lend itself to answering these questions.&lt;/p&gt;

&lt;p&gt;I have postponed commenting until I fixed 2248, but now that I have here are my suggestions on how we should do things:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Row mutate operations should be atomic. Concurrent gets/scans do not see the results of a row mutation until it is &quot;finished&quot;.  In the code, this means &quot;when rwcc.completeMemstoreInsert() is called&quot;.  This has to happen &lt;em&gt;after&lt;/em&gt; all KVs have been put in memstore.  We have to call HLog.sync() &lt;em&gt;before&lt;/em&gt; we start modifying the memstore so if there is any HLog issue we don&apos;t mutate memstore.  Thus rows become visibile &lt;em&gt;very shortly&lt;/em&gt; after a HLog.sync occurs.  The time it takes to modify in-memory structures and call rwcc.completeMemstoreInsert().&lt;/li&gt;
	&lt;li&gt;Row mutates across multiple families should be atomic. This was not too hard to implement in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt; and represents a good level of service I think.&lt;/li&gt;
	&lt;li&gt;Reads cannot see rows that have not been sync()ed to HLog.&lt;/li&gt;
	&lt;li&gt;Scanners have a weak isolation - they are continuously seeing a updated view of the table as it runs across rows.  That means a scanner can see rows inserted &lt;em&gt;after&lt;/em&gt; it&apos;s creation.  Providing stronger isolation doesn&apos;t make sense since there is no intra-row atomic guarantees.&lt;/li&gt;
	&lt;li&gt;Once a client gets a success after a mutation operation, all other clients, including itself will be able to see the new data.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In my work for HDFS-0.21, it was pretty obvious that hflush was fairly slow.  For high volume updates, with lower value data (eg: calling ICV on a row many thousands of times a seconds) it seemed to make sense to use a time-based flush.  That is the durability promise is relaxed slightly to say that the row is only durable after X milliseconds (configurable) at the most.  This is a per-table setting (see: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1944&quot; title=&quot;Add a &amp;quot;deferred log flush&amp;quot; attribute to HTD&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1944&quot;&gt;&lt;del&gt;HBASE-1944&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Right now we have the in-memory atomic reads.  The durability story is being improved in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2283&quot; title=&quot;row level atomicity &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2283&quot;&gt;&lt;del&gt;HBASE-2283&lt;/del&gt;&lt;/a&gt; with restructuring hlog appends/syncs and memstore mutations.  The performance and locking of in-memory atomic reads is being improved in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12845605" author="stack" created="Mon, 15 Mar 2010 23:57:42 +0000"  >&lt;p&gt;Above looks good to me Ryan.  Only thing I&apos;d change would be the language.  It should be rewritten in spec-speak.  For example, rather than &quot;should be atomic&quot;, in a spec., we&apos;d say &quot;are atomic&quot; (and its a bug if it ain&apos;t so).&lt;/p&gt;

&lt;p&gt;Regards scanners, we should be clearer that they&apos;ll never see partial updates to a row (even if it is made from many families), or in other words, that they respect row locks.  Also if no timestamp is specified, scanners will return the state of the row as of the time the scanner encounters the row.  Otherwise, if the scanner is opened with an explicit timestamp, they&apos;ll return the state of the row as of the specified timestamp.&lt;/p&gt;

&lt;p&gt;I think we need to probably also describe how a Scanner moves through a table explaining what rows it will return.&lt;/p&gt;

&lt;p&gt;We should probably talk up how deletes work too though I think it should be plain given the above, we probably should just spell it out in a spec.&lt;/p&gt;</comment>
                            <comment id="12845624" author="tlipcon" created="Tue, 16 Mar 2010 00:32:49 +0000"  >&lt;p&gt;Thanks for the input, guys. Also, I think we should refrain from talking about implementation details (the RWCC stuff, internal timestamps, HLog, etc). So instead of talking about hlog sync, we should say &quot;made durable&quot;.&lt;/p&gt;</comment>
                            <comment id="12845630" author="ryanobjc" created="Tue, 16 Mar 2010 00:48:07 +0000"  >&lt;p&gt;I agree on the implementation details.  I was just illustrating on how the code currently works.  It helps to have a concrete example of how things are done when writing specs.  On the plus side, what I described above I think both fits a good user experience, and is possible to implement (as evidenced by having a working implementation thereof over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I would also like to keep the term &apos;row lock&apos; out - I think we could possibly have serialized atomic updates to HBase without row locks (wow!).&lt;/p&gt;

&lt;p&gt;One point of discussion, I think it&apos;s important to have a scanner stay &apos;up to date&apos; as much as possible.  Not only would it simplify the implementation (as is), it makes no sense without a broader transaction promise to also provide a level of transaction isolation. If you are doing an aggregate scan on a table via map reduce, we already provide a mechanism for giving yourself a consistent view of the world, and that is the Scan#setTimeRange() call.  Supporting it in a Scan would require carrying the consistency view information from region to region, and without some serious changes we could not support that.  Given our existing support, I would argue it is unnecessary to do further work to promise large scale scanner consistency.&lt;/p&gt;

&lt;p&gt;Scanner consistency is already an issue in the master META scanner.  We have to double check the results of a scan to avoid problematic things such as double assignment.  Keeping the scanner more lively will help with this.&lt;/p&gt;

&lt;p&gt;One area where users could have issues would be consuming/producing rows in the same job.  The Map-reduce framework helps with this, with TIF you can read in one pass, and TOF you write in another phase that are by necessity non-overlapping.&lt;/p&gt;

&lt;p&gt;The more I think about it, the more I realize a user wants perfect isolation, they should use Scan#setTimerange() - it supports everything you want: restartable scanners, simple semantics, and cross-region support and has an existing implementation. &lt;/p&gt;
</comment>
                            <comment id="12845634" author="tlipcon" created="Tue, 16 Mar 2010 00:58:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;I would also like to keep the term &apos;row lock&apos; out - I think we could possibly have serialized atomic updates to HBase without row locks (wow!).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1. I&apos;d also love to consider dropping the user-exposed row lock feature entirely. This might be unpopular, but I think that feature is dangerous, and compareAndSwap is an equally powerful concurrency primitive that&apos;s a lot less complex. What do you guys think?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One point of discussion, I think it&apos;s important to have a scanner stay &apos;up to date&apos; as much as possible&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Also +1, I think the current compromise makes sense - don&apos;t see partial row mutations, but at the beginning of each row, the freshest data is taken.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The Map-reduce framework helps with this, with TIF you can read in one pass, and TOF you write in another phase that are by necessity non-overlapping.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not true of a map-only job, right?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The more I think about it, the more I realize a user wants perfect isolation, they should use Scan#setTimerange() - it supports everything you want: restartable scanners, simple semantics, and cross-region support and has an existing implementation&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Again +1 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12845635" author="tlipcon" created="Tue, 16 Mar 2010 01:03:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;d also love to consider dropping the user-exposed row lock feature entirely. This might be unpopular, but I think that feature is dangerous, and compareAndSwap is an equally powerful concurrency primitive that&apos;s a lot less complex.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Stated differently: the current row lock feature can be implemented on the client side through use of an atomic compareAndSet primitive. So, if we provide CAS within the region server, row lock primitives are redundant and add complexity for no apparent gain.&lt;/p&gt;</comment>
                            <comment id="12845638" author="henryr" created="Tue, 16 Mar 2010 01:08:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Stated differently: the current row lock feature can be implemented on the client side through use of an atomic compareAndSet primitive. So, if we provide CAS within the region server, row lock primitives are redundant and add complexity for no apparent gain.&lt;/p&gt;&lt;/blockquote&gt;



&lt;p&gt;The only downside of CAS compared to a lock is that the client has to handle the retry on failure. Putting CAS in a tight loop on a contended row might be painful as well. Still preferable to locks, in my opinion!&lt;/p&gt;</comment>
                            <comment id="12845640" author="tlipcon" created="Tue, 16 Mar 2010 01:11:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;The only downside of CAS compared to a lock is that the client has to handle the retry on failure&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yea, we could add a signaling primitive (eg &quot;wait for change on cell&quot;) which also allows spurious wakeup. With spurious wakeup allowed we can allow ourselves more simplicitly on the server side but still avoid busy spinning.&lt;/p&gt;</comment>
                            <comment id="12845643" author="ryanobjc" created="Tue, 16 Mar 2010 01:21:24 +0000"  >&lt;p&gt;One thing to note - rowLock/rowUnlock is not a scalable interface anyways!  If you use explicit row locks, and you have a lot of people waiting to acquire the row, you start consuming handler threads and can DOS yourself.&lt;/p&gt;

&lt;p&gt;Perhaps providing a client-only option that uses CAS to allow an atomic series of operations to occur with a retry strategy.&lt;/p&gt;
</comment>
                            <comment id="12845645" author="jdcryans" created="Tue, 16 Mar 2010 01:24:55 +0000"  >&lt;p&gt;&amp;lt;crazyidea&amp;gt;If we remove row locks from core HBase, maybe we should still support them at the HTable level but by using ZK directly instead of contacting region servers.&amp;lt;/crazyidea&amp;gt;&lt;/p&gt;</comment>
                            <comment id="12845646" author="tlipcon" created="Tue, 16 Mar 2010 01:27:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;maybe we should still support them at the HTable level but by using ZK directly instead of contacting region servers&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think that works, because you&apos;d still be able to use the non-locking calls on that row by contacting the RS. We certainly can&apos;t gate all row operations through a ZK lock.&lt;/p&gt;</comment>
                            <comment id="12845665" author="tlipcon" created="Tue, 16 Mar 2010 02:38:42 +0000"  >&lt;p&gt;Here&apos;s a first pass at some kind of spec. These aren&apos;t meant to be final - just posting for discussion. I anticipate that after we (developers) come to some kind of conclusion here we will want to run this by the user list to see if we&apos;re missing use cases, etc.&lt;/p&gt;

&lt;h1&gt;&lt;a name=&quot;Definitions&quot;&gt;&lt;/a&gt;Definitions&lt;/h1&gt;

&lt;p&gt;For the sake of common vocabulary, we define the following terms:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;ATOMICITY&lt;/b&gt;: an operation is atomic if it either completes entirely or not at all&lt;br/&gt;
&lt;b&gt;CONSISTENCY&lt;/b&gt;: all actions cause the table to transition from one valid state directly to another (eg a row will not disappear during an update,e tc)&lt;br/&gt;
&lt;b&gt;ISOLATION&lt;/b&gt;: an operation is isolated if it appears to complete independently of any other concurrent transaction&lt;br/&gt;
&lt;b&gt;DURABILITY&lt;/b&gt;: any update that reports &quot;successful&quot; to the client will not be lost&lt;br/&gt;
&lt;b&gt;VISIBILITY&lt;/b&gt;: an update is considered visible if any subsequent read will see the update as having been committed&lt;/p&gt;


&lt;h1&gt;&lt;a name=&quot;APIstoconsider&quot;&gt;&lt;/a&gt;APIs to consider&lt;/h1&gt;

&lt;ul&gt;
	&lt;li&gt;Read APIs
	&lt;ul&gt;
		&lt;li&gt;get&lt;/li&gt;
		&lt;li&gt;scan&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Write APIs
	&lt;ul&gt;
		&lt;li&gt;put&lt;/li&gt;
		&lt;li&gt;delete&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Combination (read-modify-write) APIs
	&lt;ul&gt;
		&lt;li&gt;incrementColumnValue&lt;/li&gt;
		&lt;li&gt;compareAndSet&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;&lt;a name=&quot;GuaranteesProvided&quot;&gt;&lt;/a&gt;Guarantees Provided&lt;/h1&gt;

&lt;h2&gt;&lt;a name=&quot;Atomicity&quot;&gt;&lt;/a&gt;Atomicity&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;All mutations are atomic within a row. Any put will either wholely succeed or wholely fail.
	&lt;ol&gt;
		&lt;li&gt;An operation that returns a &quot;success&quot; code has completely succeeded.&lt;/li&gt;
		&lt;li&gt;An operation that returns a &quot;failure&quot; code has completely failed.&lt;/li&gt;
		&lt;li&gt;An operation that times out may have succeeded and may have failed. However, it will not have partially succeeded or failed.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;This is true even if the mutation crosses multiple column families within a row.&lt;/li&gt;
	&lt;li&gt;APIs that mutate several rows will &lt;em&gt;not&lt;/em&gt; be atomic across the multiple rows. For example, a multiput that operates on rows &apos;a&apos;,&apos;b&apos;, and &apos;c&apos; may return having mutated some but not all of the rows. XXX: will they return failure or success or some mixed response here?&lt;/li&gt;
	&lt;li&gt;The compareAndSet API happens atomically as is typically understood by this operation.&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;&lt;a name=&quot;ConsistencyandIsolation&quot;&gt;&lt;/a&gt;Consistency and Isolation&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;All rows returned via any access API will consist of a complete row that existed at some point in the table&apos;s history.&lt;/li&gt;
	&lt;li&gt;This is true across column families - i.e a get of a full row that occurs concurrent with some mutations 1,2,3,4,5 will return a complete row that existed at some point in time between mutation i and i+1 for some i between 1 and 5.&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;&lt;a name=&quot;ConsistencyofScans&quot;&gt;&lt;/a&gt;Consistency of Scans&lt;/h3&gt;

&lt;p&gt;A scan is &lt;b&gt;not&lt;/b&gt; a consistent view of a table. Scans do &lt;b&gt;not&lt;/b&gt; exhibit &lt;em&gt;snapshot isolation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Rather, scans have the following properties:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Any row returned by the scan will be a consistent view (i.e. that version of the complete row existed at some point in time)&lt;/li&gt;
	&lt;li&gt;A scan will always reflect a version &lt;em&gt;at least as new as&lt;/em&gt; the beginning of the scan. This satisfies the visibility guarantees enumerated below.
	&lt;ol&gt;
		&lt;li&gt;For example, if client A writes data X and then communicates via a side channel to client B, any scans started by client B will contain data at least as new as X.&lt;/li&gt;
		&lt;li&gt;Scans may include data that is &lt;em&gt;newer&lt;/em&gt; than the start of the scan.&lt;/li&gt;
		&lt;li&gt;Another way of stating this is that a scan must reflect all mutations committed prior to the construction of the scanner, and &lt;em&gt;may&lt;/em&gt; reflect some mutations committed subsequent to the construction of the scanner.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Those familiar with relational databases will recognize this isolation level as &quot;read committed&quot;.&lt;/p&gt;

&lt;p&gt;XXX: Ryan has mentioned the model of &quot;scans will always get the most up-to-date version of a row when beginning a new row&quot;. Do we want to guarantee this or just leave it at &quot;some version of the row at least as new as what existed at scan start&quot;?&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Visibility&quot;&gt;&lt;/a&gt;Visibility&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;When a client receives a &quot;success&quot; response for any mutation, that mutation is immediately visible to both that client and any client with whom it later communicates through side channels.&lt;/li&gt;
	&lt;li&gt;A row will never exhibit so-called &quot;time-travel&quot; properties. That is to say, if a series of mutations moves a row sequentially through a series of states, any sequence of concurrent reads will return a subsequence of those states.
	&lt;ol&gt;
		&lt;li&gt;For example, if a row&apos;s cells are mutated using the &quot;incrementColumnValue&quot; API, a client will never see the value of any cell decrease.&lt;/li&gt;
		&lt;li&gt;This is true regardless of which read API is used to read back the mutation.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;Any version of a cell that has been returned to a read operation is guaranteed to be durably stored.&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;&lt;a name=&quot;Durability&quot;&gt;&lt;/a&gt;Durability&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;All visible data is also durable data. That is to say, a read will never return data that is not durably on disk.&lt;/li&gt;
	&lt;li&gt;Any operation that returns a &quot;success&quot; code (eg does not throw an exception) will be made durable.&lt;/li&gt;
	&lt;li&gt;Any operation that returns a &quot;failure&quot; code will not be made durable (subject to the Atomicity guarantees above)&lt;/li&gt;
	&lt;li&gt;All reasonable failure scenarios will not affect any of the guarantees of this document.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;XXX: should expand this to include the concept of tunable durability windows (this also impacts visibility since you can experience time travel during failure if some updates arent durable)&lt;/p&gt;</comment>
                            <comment id="12845669" author="kimballa" created="Tue, 16 Mar 2010 02:53:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;APIs that mutate several rows will not be atomic across the multiple rows. For example, a multiput that operates on rows &apos;a&apos;,&apos;b&apos;, and &apos;c&apos; may return having mutated some but not all of the rows. XXX: will they return failure or success or some mixed response here?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Worth pointing out for comparison that JDBC&apos;s &lt;tt&gt;Statement.executeBatch()&lt;/tt&gt; statement will return a success code iff all operations completed successfully. If some of the underlying updates in a batch failed, it will return an array of success/failure codes indicating results on a per-operation level.  Likewise, you may wish to consider returning an array of success/failed/timeout responses for each row updated in a multi-row put.&lt;/p&gt;
</comment>
                            <comment id="12845671" author="tlipcon" created="Tue, 16 Mar 2010 02:58:00 +0000"  >&lt;p&gt;Henry points out that I missed part of the definition of atomicity in the above. Namely, multiple concurrent writes will be linearized such that each takes effect in an instant of time. Thus, if I have two concurrent writes of &quot;a=1,b=1,c=1&quot; and &quot;a=2,b=2,c=2&quot; I will end up with one of the two states, but not a state the mixes 1s and 2s.&lt;/p&gt;</comment>
                            <comment id="12845676" author="tlipcon" created="Tue, 16 Mar 2010 03:10:33 +0000"  >&lt;p&gt;On further thought, the &quot;no time travel&quot; guarantee is actually a bit tricky to implement in the face of failure. For example, a RS can enter GC pause, have region reassigned, then come back to life. Before it finds out from ZK that it&apos;s been determined to be dead, it could serve some reads of stale data to a client that has cached the old region location. So we should think carefully about this requirement.&lt;/p&gt;</comment>
                            <comment id="12845704" author="stack" created="Tue, 16 Mar 2010 04:38:32 +0000"  >&lt;p&gt;Thanks for putting together first cut Todd.  Should we put it somewhere we can all hack on it?  Up on hbase wiki or over in public google doc?&lt;/p&gt;

&lt;p&gt;+ Minor: In current API its called, checkAndPut rather than compareAndSave: &lt;a href=&quot;http://su.pr/2tPOlr&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://su.pr/2tPOlr&lt;/a&gt;&lt;br/&gt;
+ &quot;XXX: will they return failure or success or some mixed response here?&quot; Failure with a list of what updates succeeded+failed (As per Aaron&apos;s JDBC illustration).&lt;br/&gt;
+ &quot;...at least as new as the beginning of the scan&quot; could confuse, or rather, to avoid confusion we need to explain all the ways in which the scanner works.  Whats being described is the case where no timestamp is specified on opening of a scan.  In this case we want to return the latest version of the row as of the time the scanner happens upon it (the row).   Even so, there is no reason why the table row data may not be older than the scan opening.  In this case we&apos;d return data older than scanner opening (Are you saying this Todd when you say &quot;at least as new..&quot;?).   Also, you can specify the timestamp range when you open a scanner and in this case, it&apos;ll return cells that lie within the bounds of the timestamp range irrepective of the time at which the scanner was opened.&lt;br/&gt;
+ On &apos;XXX: Ryan has mentioned the model of &quot;scans will always get the most up-to-date version of a row when beginning a new row&quot;. Do we want to guarantee this or just leave it at &quot;some version of the row at least as new as what existed at scan start&quot;?&apos;, I&apos;m fine with either.  The latter seems an easier guarantee.&lt;br/&gt;
+ Is this a slip on your part Todd -&amp;gt; &quot;...not durably on disk.&quot;  Maybe we should adjust your durable definition to suit what we can offer, or, maybe you intend that we adjust the filesystem to match your durability definition?&lt;br/&gt;
+ +1 on adding the Henry amendment&lt;br/&gt;
+ On the &apos;time travel&apos; requirement in the face of failure, how about we take it on (with your note that it hard to do) so if &apos;time travel&apos;, its a bug.&lt;/p&gt;</comment>
                            <comment id="12845711" author="tlipcon" created="Tue, 16 Mar 2010 05:07:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should we put it somewhere we can all hack on it? Up on hbase wiki or over in public google doc? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I made a gist: &lt;a href=&quot;http://gist.github.com/333664&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://gist.github.com/333664&lt;/a&gt;  - hopefully this is easy to hack on and also retain edit history&lt;/p&gt;

&lt;p&gt;Regarding the scan stuff, we should add some section to clarify &quot;latest&quot; with regard to timestamp versus &quot;latest&quot; with regard to the time of the edit. There&apos;s a lot of confusion over the semantics here - do timestamps just act like a &quot;z dimension&quot; or do they actually impact consistent views, etc?&lt;/p&gt;

&lt;p&gt;Will try to address your other feedback on the gist later this evening.&lt;/p&gt;</comment>
                            <comment id="12845723" author="ykulbak" created="Tue, 16 Mar 2010 05:50:34 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Ryan&amp;#93;&lt;/span&gt; One point of discussion, I think it&apos;s important to have a scanner stay &apos;up to date&apos; as much as possible&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Todd&amp;#93;&lt;/span&gt; Also +1, I think the current compromise makes sense - don&apos;t see partial row mutations, but at the beginning of each row, the freshest data is taken.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Stack&amp;#93;&lt;/span&gt; + On &apos;XXX: Ryan has mentioned the model of &quot;scans will always get the most up-to-date version of a row when beginning a new row&quot;. Do we want to guarantee this or just leave it at &quot;some version of the row at least as new as what existed at scan start&quot;?&apos;, I&apos;m fine with either. The latter seems an easier guarantee.&lt;/p&gt;

&lt;p&gt;I&apos;m basing my comment on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt; playing a major factor in enforcing the ACID properties of HBase. &lt;/p&gt;

&lt;p&gt;IMHO having the scanner stay &apos;up to date&apos; as much as possible is a nice-to-have, definitely not important enough to hurt performance. A quick look at the suggested patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt; reveals that in order to enforce the rule above the memstore scanner was reverted to using the 0.20.2-style ConcurrentSkipListSet#tailSet operation. Our experiments on 0.20.2 showed that with this style of memstore scanning it&apos;s actually 3 times slower to scan the memstore than it is to scan the store files (with block cache enabled). &lt;br/&gt;
Also, (assuming that the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt; patch is committed) I don&apos;t see any point in a &apos;best effort&apos; guarantee: e.g. since from the user&apos;s perspective &quot;&apos;up to date&apos; as much as possible&quot; is not clearly defined it&apos;s better to guarantee the clear-cut notion of seeing your own writes since it leaves leeway for future performance tweaks.&lt;/p&gt;

&lt;p&gt;I haven&apos;t performance tested any of the suggested patches for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2248&quot; title=&quot;Provide new non-copy mechanism to assure atomic reads in get and scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2248&quot;&gt;&lt;del&gt;HBASE-2248&lt;/del&gt;&lt;/a&gt;, but it seems like PE is going to be performed soon. My guess is that if the PE numbers will be compared to the existing baseline it may show a slow-down.&lt;/p&gt;

&lt;p&gt;I&apos;m not familiar with the wide range of use-cases for HBASE but my experience is that usually scanning through a single region takes less than a second. Every time the client scanner moves to a new region a new region scanner is instantiated (which grabs the latest &apos;region state&apos;) and so in most cases, the client scanner will encounter rows which are at most a couple of seconds old.   Slower scans will usually be due to the client side performing some lengthy operations during the scan. I would think that clients which do &apos;lengthy scans&apos; don&apos;t particularly care about performance and hence, if they wish to make the best effort to process up-to-date rows they can issue a GET for every row before they process it. For most cases, I would expect a row which is at most a couple of seconds old to be good enough.   &lt;/p&gt;</comment>
                            <comment id="12845736" author="tlipcon" created="Tue, 16 Mar 2010 06:31:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;IMHO having the scanner stay &apos;up to date&apos; as much as possible is a nice-to-have, definitely not important enough to hurt performance.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think I agree with you. I don&apos;t want to sidetrack this particular JIRA towards implementation details, so I&apos;ll leave it at that. Without regard to the specifics of the other JIRA, it seems likely to me that the &quot;as up to date as possible&quot; can often be implemented &lt;em&gt;more&lt;/em&gt; efficiently than the &quot;snapshot iterator&quot;. The current implementation may not be up to snuff, so I&apos;ll leave it at this: I think the scanner semantics should be as loose as possible to achieve the maximum speed, and I view &quot;up to date&quot; as &lt;em&gt;looser&lt;/em&gt; than snapshot.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I would think that clients which do &apos;lengthy scans&apos; don&apos;t particularly care about performance &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I disagree - MR jobs are a typical &quot;lengthy scan&quot; application and throughput is certainly important. Especially important is the ability to have the bulk (MR) jobs coexist with high concurrent live load on the table.&lt;/p&gt;</comment>
                            <comment id="12845738" author="ryanobjc" created="Tue, 16 Mar 2010 06:34:46 +0000"  >&lt;p&gt;I&apos;m not sure it&apos;s fair to say that a bulk job must retrieve the data twice if they want freshness.  Since everything is already in memory, it seems easy to be more live/fresh. &lt;/p&gt;</comment>
                            <comment id="12846206" author="tlipcon" created="Tue, 16 Mar 2010 23:32:07 +0000"  >&lt;p&gt;Ryan and I just discussed the snapshot vs up-to-date question on IRC. Brief summary:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;We cannot provide snapshot isolation as a guarantee, since doing so across regions is really impossible. Users can make use of timestamp range filters to get snapshot-like behavior.&lt;/li&gt;
	&lt;li&gt;People don&apos;t seem to have concrete use cases for exactly-up-to-date semantics. Thus we shouldn&apos;t provide that either.&lt;/li&gt;
	&lt;li&gt;The &quot;spec&quot; above describes the semantics as &quot;at least as new as the start of the scan and possibly newer&quot;. This permits anything from snapshot isolation all the way up to &quot;up to date&quot; semantics, but leaves us wide open for implementation paths. If we decide to go with up-to-date now, we&apos;ll have explicit documentation to say this is &lt;b&gt;not&lt;/b&gt; a feature, and anyone relying on it may be broken by implementation changes down the road.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Does that sound reasonable to you, Yoram?&lt;/p&gt;</comment>
                            <comment id="12846250" author="ykulbak" created="Wed, 17 Mar 2010 01:56:21 +0000"  >&lt;p&gt;That sounds great Todd. Cheers.&lt;/p&gt;</comment>
                            <comment id="12846758" author="tlipcon" created="Thu, 18 Mar 2010 05:51:33 +0000"  >&lt;p&gt;I pushed an update to the doc in response to Stack&apos;s comments:&lt;br/&gt;
&lt;a href=&quot;https://gist.github.com/336081/6c64c14c35fa778d74f3c7fdcfde09a38dc4b5c9&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://gist.github.com/336081/6c64c14c35fa778d74f3c7fdcfde09a38dc4b5c9&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The time-travel thing is still somewhat worrisome. I think we have a few options here:&lt;/p&gt;

&lt;p&gt;a) We allow time travel reads always (a little weak, hard to program against). To satisfy other guarantees, we know that writes and read-modify-writes won&apos;t have this property.&lt;br/&gt;
b) We disallow time travel from a single client, but different clients may be at different points in the timeline . That is to say, in the example of some set of processes incrementing a cell, a single reader will never see a cell decrease. However, a reader may see a cell at value N, communicate to a second reader, and the second reader may then see the cell at a value less than N.&lt;br/&gt;
c) We give the user a call something like &quot;ensureReadsUptodate()&quot;. This ensures that the reader will not read any data more stale than the time when this call is made. This is exactly what ZooKeeper does about the stale read problem - usually you get stale reads but don&apos;t care, and if you care, you call ZK&apos;s sync() method.&lt;br/&gt;
d) We never allow time travel reads. I think this is nearly impossible to do without killing performance (essentially the region server would have to verify that it is still in charge of a region before every read).&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="12846767" author="tlipcon" created="Thu, 18 Mar 2010 06:24:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;d) We never allow time travel reads. I think this is nearly impossible to do without killing performance (essentially the region server would have to verify that it is still in charge of a region before every read).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, after much head scratching, I take it back. If we make an assumption that the clocks of all of the nodes progress within some error threshold of the same rate, we can do this efficiently. We just need to keep track of the timestamp at which we began our last ZK write, and be careful not to serve writes if it&apos;s possible that we might have been expired. I think the assumption of equal rate clocks is an OK one (note this is different than synchronized clocks). I&apos;ll sleep on this and write up a description tomorrow to make it more clear.&lt;/p&gt;</comment>
                            <comment id="12846776" author="henryr" created="Thu, 18 Mar 2010 07:02:13 +0000"  >&lt;p&gt;Clocks, anecdotally, do progress at different rates. Also you would have to ensure that you read and test the clock atomically with the update, otherwise you can read an ok timestamp, get a gc pause and then send the update. The only thing a clock read can really tell you is that it was time X some time in the past. &lt;/p&gt;

&lt;p&gt;Wouldn&apos;t providing b and c be the best combination? But maybe parameterise the ensureUpToDate read by a logical timestamp. So if you want to maintain out-of-band causality, you have to send the timestamp to your peer for them to do the read. Makes it explicit. &lt;/p&gt;</comment>
                            <comment id="12846784" author="tlipcon" created="Thu, 18 Mar 2010 07:40:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;Clocks, anecdotally, do progress at different rates&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Certainly within a bounded amount of error for practical systems, though - we could set this error as high as 50%, and on the time scales we&apos;re talking about I dont think one node will think 5 seconds passed while another thinks 10.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also you would have to ensure that you read and test the clock atomically with the update,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think so, in this case. Let me try to work through this somewhat &lt;span class=&quot;error&quot;&gt;&amp;#91;maybe overly&amp;#93;&lt;/span&gt; formally (mostly to convince myself too!)&lt;/p&gt;

&lt;p&gt;We have the following events:&lt;/p&gt;

&lt;p&gt;1) node A reads its timestamp as T1&lt;br/&gt;
2) node A sends a sync() message to ZK&lt;br/&gt;
2a) ZK receives sync() method and responds&lt;br/&gt;
3) node A receives success from sync (ie things have been sunk)&lt;br/&gt;
3a) concurrently at some point, node A loses its connection to ZK (network partition or some such)&lt;br/&gt;
4) client C sends a request to node A (call this T2)&lt;br/&gt;
5) node A receives a request from client C (call this T3)&lt;br/&gt;
6) node A responds to C&lt;br/&gt;
7) C receives response&lt;br/&gt;
8) ZK times out session to A (call this T4)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;note that this sequence above isn&amp;#39;t a defined ordering&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Looking at &quot;happens-before&quot; relations, we know the following easily:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;1 &amp;lt; 2 &amp;lt; 3 &amp;lt; 5 &amp;lt; 6  (these are all seen by A in this order, so we know it to be true)&lt;/li&gt;
	&lt;li&gt;3 &amp;lt; 3a (the connection must have been up when we received success)&lt;/li&gt;
	&lt;li&gt;1 &amp;lt; 2a &amp;lt; 3 (causal)&lt;/li&gt;
	&lt;li&gt;4 &amp;lt; 5 &amp;lt; 6 &amp;lt; 7 (causal)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Let&apos;s say that ZK will time out a node it hasn&apos;t heard from in Z seconds. From Z&apos;s perspective, then, step 8 occurs at least Z seconds after step 2a. Since step 1 happens before 2a (see above), we know that step 8 happens at least Z seconds after step 1. If we assume that ZK&apos;s clock progresses at some error ratio of A&apos;s clock, then step 8 happens at  Z*errorRatio after it received the sync. It received the sync (2a) some unknown amount of time after T1 due to latency. So T4 from A&apos;s perspective = T1 + Z*errorRatio + latency. That is, as long as we are within Z*errorRatio seconds after &lt;em&gt;sending&lt;/em&gt; our last ZK message, we are &quot;in the clear&quot; that no one else has decided we&apos;re dead.&lt;/p&gt;

&lt;p&gt;Back to the problem at hand, to avoid &quot;time travel&quot; reads, what we need to do is make sure that when we &lt;em&gt;initiate&lt;/em&gt; the read from a client, the target region server is still holding the region (ie 4 happens before 8). We already know 4 happens before 5, so if 5 happens before 8, that&apos;s a stronger condition. We know step 5 happens before 8 if T3 &amp;lt; T4. We decided T4 &amp;gt; T1 + Z*errorRatio + latency. So if T3 &amp;lt; T1 + Z*errorRatio + latency, we are good to go. We don&apos;t know latency, but it&apos;s always positive so it only helps us.&lt;/p&gt;

&lt;p&gt;Does this sound correct?&lt;/p&gt;</comment>
                            <comment id="12848232" author="tlipcon" created="Mon, 22 Mar 2010 17:49:47 +0000"  >&lt;p&gt;Despite my length comment above, I think option (c) for stale reads is actually best. We would by default allow stale reads, and add an API (either per-Get or perhaps per-HTable instance) to say either &quot;ensure data is up to date with respect to the current instant&quot; or &quot;all further reads should be up-to-date&quot;. This will allow us to add a new feature in the future of read-only region replicas (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2357&quot; title=&quot;Coprocessors: Add read-only region replicas (slaves) for availability and fast region recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2357&quot;&gt;&lt;del&gt;HBASE-2357&lt;/del&gt;&lt;/a&gt;). I think we should, though, guarantee &quot;no time travel of a single row from the vantage point of a single client&quot;. This needs a bit more fleshing out, will think on it and add to the document this week.&lt;/p&gt;</comment>
                            <comment id="12848476" author="ryanobjc" created="Tue, 23 Mar 2010 00:49:07 +0000"  >&lt;p&gt;right now the way we implement some of this stuff is via the JMM, we use locks and other things to essentially create an order of events that a client will see.  For example in my 2248 patch, the ReadWriteConcurrencyControl uses an atomic incrementing long to move the state in one direction only.  Users won&apos;t have time travel problems in this regime.&lt;/p&gt;

&lt;p&gt;In terms of crashes and log recovery, the sequential log recovery id solves this problem, no?&lt;/p&gt;</comment>
                            <comment id="12848478" author="tlipcon" created="Tue, 23 Mar 2010 00:56:49 +0000"  >&lt;p&gt;Yea, the reason I&apos;m voting for C is not for the current model, but rather so we can add some more features down the road. The idea of a read-only replica that lags the actual region is one (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2357&quot; title=&quot;Coprocessors: Add read-only region replicas (slaves) for availability and fast region recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2357&quot;&gt;&lt;del&gt;HBASE-2357&lt;/del&gt;&lt;/a&gt;). Another is that when a region is being loaded after a failure, it could theoretically serve stale data in readonly mode from the StoreFiles while it&apos;s replaying the log into memstores. There are plenty of examples where we may want to time travel (trade off uptodate-ness for read availability), and making staleness an option opens us up to these possibilities.&lt;/p&gt;</comment>
                            <comment id="12851741" author="stack" created="Wed, 31 Mar 2010 06:30:39 +0000"  >&lt;p&gt;C. sounds good with the option per-Get/per-Scan/per-Delete to say ensure up-to-date as of &apos;now&apos; (What does this option do if a regoin is replaying WAL edits?  Block? Fail?).&lt;/p&gt;

&lt;p&gt;The document is looking healthy.  How about posting it to hbase-dev for discussion.  The kick-off might be adopt this document as dev target going forward with hbase 0.21 (0.22) gated on adherence?&lt;/p&gt;</comment>
                            <comment id="12852183" author="tlipcon" created="Wed, 31 Mar 2010 23:56:13 +0000"  >&lt;p&gt;Thanks for reviving this issue, Stack.&lt;/p&gt;

&lt;p&gt;I thought a bit more about the stale reads thing, and I think the safest bet is this: by default we do &lt;em&gt;not&lt;/em&gt; allow stale reads, but in the future we could add a flag on get() calls that explicitly allows it. I think this is more what people expect out of a datastore, and if people want to make the tradeoff they should ask for it. Since we determined above it should be perfectly efficient to be correct, we might as well be correct by default.&lt;/p&gt;

&lt;p&gt;Here&apos;s the current state of the gist:&lt;/p&gt;



&lt;p&gt;Here&apos;s a first pass at some kind of spec. These aren&apos;t meant to be final - just posting for discussion. I anticipate that after we (developers) come to some kind of conclusion here we will want to run this by the user list to see if we&apos;re missing use cases, etc.&lt;/p&gt;

&lt;h1&gt;&lt;a name=&quot;Definitions&quot;&gt;&lt;/a&gt;Definitions&lt;/h1&gt;

&lt;p&gt;For the sake of common vocabulary, we define the following terms:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;ATOMICITY&lt;/b&gt;: an operation is atomic if it either completes entirely or not at all&lt;br/&gt;
&lt;b&gt;CONSISTENCY&lt;/b&gt;: all actions cause the table to transition from one valid state directly to another (eg a row will not disappear during an update,e tc)&lt;br/&gt;
&lt;b&gt;ISOLATION&lt;/b&gt;: an operation is isolated if it appears to complete independently of any other concurrent transaction&lt;br/&gt;
&lt;b&gt;DURABILITY&lt;/b&gt;: any update that reports &quot;successful&quot; to the client will not be lost&lt;br/&gt;
&lt;b&gt;VISIBILITY&lt;/b&gt;: an update is considered visible if any subsequent read will see the update as having been committed&lt;/p&gt;

&lt;p&gt;The terms &lt;em&gt;must&lt;/em&gt; and &lt;em&gt;may&lt;/em&gt; are used as specified by RFC 2119. In short, the word &quot;must&quot; implies that, if some case exists where the statement is not true, it is a bug. The word &quot;may&quot; implies that, even if the guarantee is provided in a current release, users should not rely on it.&lt;/p&gt;

&lt;h1&gt;&lt;a name=&quot;APIstoconsider&quot;&gt;&lt;/a&gt;APIs to consider&lt;/h1&gt;

&lt;ul&gt;
	&lt;li&gt;Read APIs
	&lt;ul&gt;
		&lt;li&gt;get&lt;/li&gt;
		&lt;li&gt;scan&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Write APIs
	&lt;ul&gt;
		&lt;li&gt;put&lt;/li&gt;
		&lt;li&gt;batch put&lt;/li&gt;
		&lt;li&gt;delete&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Combination (read-modify-write) APIs
	&lt;ul&gt;
		&lt;li&gt;incrementColumnValue&lt;/li&gt;
		&lt;li&gt;checkAndPut&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;&lt;a name=&quot;GuaranteesProvided&quot;&gt;&lt;/a&gt;Guarantees Provided&lt;/h1&gt;

&lt;h2&gt;&lt;a name=&quot;Atomicity&quot;&gt;&lt;/a&gt;Atomicity&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;All mutations are atomic within a row. Any put will either wholely succeed or wholely fail.
	&lt;ol&gt;
		&lt;li&gt;An operation that returns a &quot;success&quot; code has completely succeeded.&lt;/li&gt;
		&lt;li&gt;An operation that returns a &quot;failure&quot; code has completely failed.&lt;/li&gt;
		&lt;li&gt;An operation that times out may have succeeded and may have failed. However, it will not have partially succeeded or failed.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;This is true even if the mutation crosses multiple column families within a row.&lt;/li&gt;
	&lt;li&gt;APIs that mutate several rows will &lt;em&gt;not&lt;/em&gt; be atomic across the multiple rows. For example, a multiput that operates on rows &apos;a&apos;,&apos;b&apos;, and &apos;c&apos; may return having mutated some but not all of the rows. In such cases, these APIs will return a list of success codes, each of which may be succeeded, failed, or timed out as described above.&lt;/li&gt;
	&lt;li&gt;The checkAndPut API happens atomically like the typical compareAndSet (CAS) operation found in many hardware architectures.&lt;/li&gt;
	&lt;li&gt;The order of mutations is seen to happen in a well-defined order for each row, with no interleaving. For example, if one writer issues the mutation &quot;a=1,b=1,c=1&quot; and another writer issues the mutation &quot;a=2,b=2,c=2&quot;, the row must either be &quot;a=1,b=1,c=1&quot; or &quot;a=2,b=2,c=2&quot; and must &lt;em&gt;not&lt;/em&gt; be something like &quot;a=1,b=2,c=1&quot;.
	&lt;ol&gt;
		&lt;li&gt;Please note that this is not true &lt;em&gt;across rows&lt;/em&gt; for multirow batch mutations.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;&lt;a name=&quot;ConsistencyandIsolation&quot;&gt;&lt;/a&gt;Consistency and Isolation&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;All rows returned via any access API will consist of a complete row that existed at some point in the table&apos;s history.&lt;/li&gt;
	&lt;li&gt;This is true across column families - i.e a get of a full row that occurs concurrent with some mutations 1,2,3,4,5 will return a complete row that existed at some point in time between mutation i and i+1 for some i between 1 and 5.&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;&lt;a name=&quot;ConsistencyofScans&quot;&gt;&lt;/a&gt;Consistency of Scans&lt;/h3&gt;

&lt;p&gt;A scan is &lt;b&gt;not&lt;/b&gt; a consistent view of a table. Scans do &lt;b&gt;not&lt;/b&gt; exhibit &lt;em&gt;snapshot isolation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Rather, scans have the following properties:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Any row returned by the scan will be a consistent view (i.e. that version of the complete row existed at some point in time)&lt;/li&gt;
	&lt;li&gt;A scan will always reflect a view of the data &lt;em&gt;at least as new as&lt;/em&gt; the beginning of the scan. This satisfies the visibility guarantees enumerated below.
	&lt;ol&gt;
		&lt;li&gt;For example, if client A writes data X and then communicates via a side channel to client B, any scans started by client B will contain data at least as new as X.&lt;/li&gt;
		&lt;li&gt;A scan &lt;em&gt;must&lt;/em&gt; reflect all mutations committed prior to the construction of the scanner, and &lt;em&gt;may&lt;/em&gt; reflect some mutations committed subsequent to the construction of the scanner.&lt;/li&gt;
		&lt;li&gt;Scans must include &lt;em&gt;all&lt;/em&gt; data written prior to the scan (except in the case where data is subsequently mutated, in which case it &lt;em&gt;may&lt;/em&gt; reflect the mutation)&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Those familiar with relational databases will recognize this isolation level as &quot;read committed&quot;.&lt;/p&gt;

&lt;p&gt;Please note that the guarantees listed above regarding scanner consistency are referring to &quot;transaction commit time&quot;, not the &quot;timestamp&quot; field of each cell. That is to say, a scanner started at time t may see edits with a timestamp value less than t, if those edits were committed with a &quot;backdated&quot; timestamp after the scanner was constructed.&lt;/p&gt;


&lt;h2&gt;&lt;a name=&quot;Visibility&quot;&gt;&lt;/a&gt;Visibility&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;When a client receives a &quot;success&quot; response for any mutation, that mutation is immediately visible to both that client and any client with whom it later communicates through side channels.&lt;/li&gt;
	&lt;li&gt;A row must never exhibit so-called &quot;time-travel&quot; properties. That is to say, if a series of mutations moves a row sequentially through a series of states, any sequence of concurrent reads will return a subsequence of those states.
	&lt;ol&gt;
		&lt;li&gt;For example, if a row&apos;s cells are mutated using the &quot;incrementColumnValue&quot; API, a client must never see the value of any cell decrease.&lt;/li&gt;
		&lt;li&gt;This is true regardless of which read API is used to read back the mutation.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;Any version of a cell that has been returned to a read operation is guaranteed to be durably stored.&lt;/li&gt;
&lt;/ol&gt;



&lt;h2&gt;&lt;a name=&quot;Durability&quot;&gt;&lt;/a&gt;Durability&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;All visible data is also durable data. That is to say, a read will never return data that has not been made durable on disk&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;Any operation that returns a &quot;success&quot; code (eg does not throw an exception) will be made durable.&lt;/li&gt;
	&lt;li&gt;Any operation that returns a &quot;failure&quot; code will not be made durable (subject to the Atomicity guarantees above)&lt;/li&gt;
	&lt;li&gt;All reasonable failure scenarios will not affect any of the guarantees of this document.&lt;/li&gt;
&lt;/ol&gt;



&lt;h1&gt;&lt;a name=&quot;Tunability&quot;&gt;&lt;/a&gt;Tunability&lt;/h1&gt;

&lt;p&gt;All of the above guarantees must be possible within HBase. For users who would like to trade off some guarantees for performance, HBase may offer several tuning options. For example:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Visibility may be tuned on a per-read basis to allow stale reads or time travel.&lt;/li&gt;
	&lt;li&gt;Durability may be tuned to only flush data to disk on a periodic basis&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Notes:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; In the context of HBase, &quot;durably on disk&quot; implies an hflush() call on the transaction log. This does not actually imply an fsync() to magnetic media, but rather just that the data has been written to the OS cache on all replicas of the log. In the case of a full datacenter power loss, it is possible that the edits are not truly durable.&lt;/p&gt;</comment>
                            <comment id="12852187" author="apurtell" created="Thu, 1 Apr 2010 00:09:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;by default we do not allow stale reads, but in the future we could add a flag on get() calls that explicitly allows it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If we accept a degraded mode of operation (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2183&quot; title=&quot;Ride over restart&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2183&quot;&gt;&lt;del&gt;HBASE-2183&lt;/del&gt;&lt;/a&gt;) while HDFS is unavailable or a region is taking on IOEs (switch to read only cascades from region to table), then there will be circumstances where the guarantees normally made by the system will not apply. I would expect the initial strategy to be something like:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Stop accepting writes&lt;/li&gt;
	&lt;li&gt;Serve data available in cache, set flag or field in response to indicate degraded operation&lt;/li&gt;
	&lt;li&gt;Serve data available in disk stores that can still be accessed, whichever are not throwing IOEs.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is relevant to this issue in the sense that committed data may temporarily &quot;disappear&quot;. &lt;/p&gt;</comment>
                            <comment id="12852192" author="tlipcon" created="Thu, 1 Apr 2010 00:20:21 +0000"  >&lt;p&gt;Yep, I agree for sure that we want degraded operation to be a possibility. I was thinking, though, that the client should specify &quot;I&apos;m OK with stale data&quot; rather than having to specify &quot;I&apos;m not OK with stale data&quot;. Perhaps if you&apos;ve set &quot;I&apos;m not OK with stale data&quot; (my proposed default) and the system is degraded, it would throw an exception saying &quot;DegradedModeException&quot; so users know they could try again with that flag?&lt;/p&gt;

&lt;p&gt;I&apos;m just a bit nervous about people thinking they always get up-to-date data, and then suddenly they see stale reads from the system without having to specifically OK it.&lt;/p&gt;</comment>
                            <comment id="12852194" author="apurtell" created="Thu, 1 Apr 2010 00:21:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;DegradedModeException&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12852225" author="streamy" created="Thu, 1 Apr 2010 02:35:37 +0000"  >&lt;p&gt;Awesome stuff, Todd.&lt;/p&gt;

&lt;p&gt;According to these guarantees, we would not be able to make regions of a crashed server available until after their log replay completes, correct?&lt;/p&gt;</comment>
                            <comment id="12852244" author="tlipcon" created="Thu, 1 Apr 2010 04:32:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;According to these guarantees, we would not be able to make regions of a crashed server available until after their log replay completes, correct?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yea, I think we&apos;d to make the region available in &quot;degraded/stale mode&quot; - then clients who specifically set the &quot;stale data OK&quot; flag would see it just fine. Standard clients that expect new data would get the special exception.&lt;/p&gt;</comment>
                            <comment id="12852248" author="streamy" created="Thu, 1 Apr 2010 05:00:38 +0000"  >&lt;p&gt;Right, got it.  Sounds good.&lt;/p&gt;</comment>
                            <comment id="12852576" author="stack" created="Thu, 1 Apr 2010 22:18:45 +0000"  >&lt;p&gt;.bq According to these guarantees, we would not be able to make regions of a crashed server available until after their log replay completes, correct?&lt;/p&gt;

&lt;p&gt;...but no reason we couldn&apos;t already up and taking writes in the meantime before the log replay compoletes?&lt;/p&gt;</comment>
                            <comment id="12852580" author="tlipcon" created="Thu, 1 Apr 2010 22:25:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;...but no reason we couldn&apos;t already up and taking writes in the meantime before the log replay compoletes?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Interesting... I suppose that&apos;s true, but only writes that don&apos;t require reads first (eg a delete might be problematic because we need to know the newest timestamp prior to it, right?)&lt;/p&gt;</comment>
                            <comment id="12852602" author="streamy" created="Thu, 1 Apr 2010 23:32:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;Interesting... I suppose that&apos;s true, but only writes that don&apos;t require reads first (eg a delete might be problematic because we need to know the newest timestamp prior to it, right?)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s right, so would be kind of weird.  But the thing is a majority of use cases are not using deleteLatest or checkAndPut or incrementCV, so would be unfortunate to block all writes for limited cases.&lt;/p&gt;

&lt;p&gt;Maybe writes that require reads could through the same DegradedModeException but simple writes would go through in this mode.&lt;/p&gt;</comment>
                            <comment id="12852604" author="apurtell" created="Thu, 1 Apr 2010 23:39:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe writes that require reads could through the same DegradedModeException but simple writes would go through in this mode.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12852622" author="tlipcon" created="Fri, 2 Apr 2010 00:39:01 +0000"  >&lt;p&gt;Yep, I think that makes sense. Do you think anything in this document precludes that? Basically what we&apos;re discussing here is cleverness that allows us to be more useful while maintaining the same guarantees. So long as our &quot;spec&quot; (output of this JIRA) talks about user visible properties, we can feel free to be as clever as we want underneath &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12852692" author="stack" created="Fri, 2 Apr 2010 04:01:08 +0000"  >&lt;p&gt;Some formatting mods (Minor).&lt;/p&gt;</comment>
                            <comment id="12852693" author="stack" created="Fri, 2 Apr 2010 04:07:12 +0000"  >&lt;p&gt;Minor alligning of Tunability header heading to match that that of Consistency and Visibility.&lt;/p&gt;</comment>
                            <comment id="12852694" author="stack" created="Fri, 2 Apr 2010 04:11:22 +0000"  >&lt;p&gt;I read the spec. with the onlining of regions to take writes but not reads and I do not see violation.  I did wonder though if we should have a section on what happens if you try to read and system can&apos;t give you known correct data &amp;#8211; e.g. the exception thrown if you try to read an onlined region that is replaying edits &amp;#8211; but thought this an implementation detail that didn&apos;t belong herein.&lt;/p&gt;</comment>
                            <comment id="12854272" author="tlipcon" created="Wed, 7 Apr 2010 00:17:55 +0000"  >&lt;p&gt;Here&apos;s a patch that converts the document to forrest style and includes in docs&lt;/p&gt;</comment>
                            <comment id="12854741" author="stack" created="Thu, 8 Apr 2010 00:09:34 +0000"  >&lt;p&gt;Changed my mind.  This is patch available and its blocker.  Bringing back into 0.20.4.&lt;/p&gt;</comment>
                            <comment id="12854746" author="stack" created="Thu, 8 Apr 2010 00:17:01 +0000"  >&lt;p&gt;Changed mind again.  This doc. should go into the release that includes a sync. otherwise we&apos;re no where near to what this doc describes (What you think Todd?)&lt;/p&gt;</comment>
                            <comment id="12854747" author="tlipcon" created="Thu, 8 Apr 2010 00:22:12 +0000"  >&lt;p&gt;Yep, that makes sense - we should add the unit tests that &apos;prove it&apos;, and then commit this with the tests once they pass&lt;/p&gt;</comment>
                            <comment id="12859122" author="stack" created="Tue, 20 Apr 2010 23:18:39 +0000"  >&lt;p&gt;Applied branch and trunk.  Applied as incompatible change.  Any issue found where we do not align w/ spec is a &lt;b&gt;bad, bad&lt;/b&gt; bug and needs fixing.  In trunk, site is broke so can&apos;t really see this new doc. readily but in trunk you can&apos;t see any of the old src doc.  It needs moving over.  In trunk I verified that its showing up in the left navbar on site and that it looks good.&lt;/p&gt;

&lt;p&gt;Thanks for driving this through Todd.&lt;/p&gt;</comment>
                            <comment id="12866853" author="stack" created="Wed, 12 May 2010 23:52:28 +0000"  >&lt;p&gt;Marking these as fixed against 0.21.0 rather than against 0.20.5.&lt;/p&gt;</comment>
                            <comment id="15017257" author="lars_francke" created="Fri, 20 Nov 2015 12:42:28 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12457095">HBASE-2248</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12458055">HBASE-2283</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12440573" name="formatting_mods-v2.patch" size="5480" author="stack" created="Fri, 2 Apr 2010 04:07:12 +0000"/>
                            <attachment id="12440572" name="formatting_mods.patch" size="5480" author="stack" created="Fri, 2 Apr 2010 04:01:08 +0000"/>
                            <attachment id="12440976" name="hbase-2294.patch" size="11590" author="tlipcon" created="Wed, 7 Apr 2010 00:17:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 15 Mar 2010 21:35:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>32501</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hh3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100033</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>