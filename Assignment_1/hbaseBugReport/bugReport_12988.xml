<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 20:38:29 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-12988/HBASE-12988.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-12988] [Replication]Parallel apply edits across regions</title>
                <link>https://issues.apache.org/jira/browse/HBASE-12988</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;we can apply  edits to slave cluster in parallel on table-level to speed up replication .&lt;br/&gt;
update : per conversation blow , it&apos;s better to apply edits on row-level in parallel&lt;/p&gt;</description>
                <environment></environment>
        <key id="12773387">HBASE-12988</key>
            <summary>[Replication]Parallel apply edits across regions</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lhofhansl">Lars Hofhansl</assignee>
                                    <reporter username="hongyu.bi">hongyu bi</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Feb 2015 07:45:27 +0000</created>
                <updated>Fri, 4 Dec 2015 19:38:01 +0000</updated>
                            <resolved>Fri, 4 Sep 2015 20:30:03 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>Replication</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="14313557" author="lhofhansl" created="Tue, 10 Feb 2015 04:42:19 +0000"  >&lt;p&gt;Awesome. Let&apos;s do that + a thread could limit per ReplicationSource (or region server).&lt;/p&gt;</comment>
                            <comment id="14313560" author="lhofhansl" created="Tue, 10 Feb 2015 04:46:35 +0000"  >&lt;p&gt;The tricky part might be book keeping (i.e. how far have we replicated).. If we simply allow more duplicates we can divide every chunk of edits by table and only declare the chunk successful when all table-parts shipped successfully.&lt;/p&gt;

&lt;p&gt;Also realistically in real world scenarios I&apos;d assume that often edits are very bursty per table, reducing the utility of this. &lt;/p&gt;

&lt;p&gt;Hashing by table, row might be better...?&lt;/p&gt;</comment>
                            <comment id="14313581" author="hongyu.bi" created="Tue, 10 Feb 2015 05:10:49 +0000"  >&lt;p&gt;agreed, table-level may hit hot-spot easier than row-level.&lt;br/&gt;
Title changed,&lt;br/&gt;
thanks&lt;/p&gt;</comment>
                            <comment id="14526121" author="lhofhansl" created="Mon, 4 May 2015 00:47:11 +0000"  >&lt;p&gt;Thinking on this again, it&apos;s important we do this. Otherwise replication is slow, especially across high latency links across data centers.&lt;br/&gt;
We can significantly cut this down but by having multiple smaller chunks in flight to multiple target region server instead of only a single large chunk to exactly one region server at a time.&lt;/p&gt;

&lt;p&gt;The grouping by row should be easy to do to avoid any weirdness around ordering of deletes/put for the same row.&lt;/p&gt;

&lt;p&gt;The place to do this might be HBaseInterClusterReplicationEndpoint.replication or its caller.&lt;br/&gt;
There we get one (large) chunk, and send it to exactly one peer region server. We can split the chunk up into N parts here and farm it to N region servers in parallel, if all sub chunks are success the entire large chunk is successful. We can retry individual chunks a few time and then fail the larger chunk if that failed.&lt;/p&gt;</comment>
                            <comment id="14541365" author="lhofhansl" created="Wed, 13 May 2015 05:28:31 +0000"  >&lt;p&gt;Looking into this. This is a bit more intricate than expected. An Entry in the WAL is a WALKey/WALEdit pair. The WALKey (among other stuff has table and region name), the WALEdit has the cells, which in turn have the row. A WALEdit can contain Cells for many rows.&lt;/p&gt;

&lt;p&gt;So to group by row we would need to pull WALEdits apart. I&apos;d have to think through the implication to convince myself that that&apos;s OK. On top of that after the row-grouping we&apos;d now have to build &lt;em&gt;new&lt;/em&gt; WALEdits, since they&apos;d have a different set of Cells. Ugh...&lt;/p&gt;

&lt;p&gt;Grouping entire WALEdits on the other hand is easier, but those I can only group by table, and - as discussed above - that might not be effective in many scenarios.&lt;/p&gt;

&lt;p&gt;I can easily do a size based breakup and then rely on the fact that we keep deletes around for a little bit, but that is brittle... I do have a test patch for this.&lt;/p&gt;</comment>
                            <comment id="14541369" author="lhofhansl" created="Wed, 13 May 2015 05:32:40 +0000"  >&lt;p&gt;Another potential way to speed this up (a little) is to build the next chunk of edit to send while the current chunk is in flight. We&apos;d double the required heap on the replication source, but at least we can do some work on the source while the current chunk is transmitted and applied at the source - but we&apos;d still only have exactly a single chunk outstanding at any given to guarantee order.&lt;/p&gt;

&lt;p&gt;And maybe, since we already have scenarios where edit for the same row can arrive out of order for example when a region server fails, we can just make the sink more robust and simply send edits out of order.&lt;/p&gt;</comment>
                            <comment id="14542245" author="stack" created="Wed, 13 May 2015 17:04:09 +0000"  >&lt;p&gt;Our WAL format needs to go on a diet. Objects are really fat. Plus we got pb from the wire from which we make pojos &amp;#8211; WAL* &amp;#8211; and then pb into WAL. Fun. Rethink?&lt;/p&gt;</comment>
                            <comment id="14542262" author="apurtell" created="Wed, 13 May 2015 17:15:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Our WAL format needs to go on a diet. Objects are really fat. Plus we got pb from the wire from which we make pojos &amp;#8211; WAL* &amp;#8211; and then pb into WAL. Fun. Rethink?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Rethinking is good. &lt;br/&gt;
Let&apos;s start from a radical position: we get PB from the wire for requests, so stuff requests directly into the WAL as received. Cut out the whole PB to pojo back to PB translations. Would simplify a lot but would be a big rethink too, since we&apos;d want to encode requests in such a way that they can be concatenated for group commit, at least. There would be more considerations for request encoding to be WAL- and replay-friendly. For 2.0 maybe. Would be out of scope for this issue.&lt;/p&gt;</comment>
                            <comment id="14543201" author="lhofhansl" created="Thu, 14 May 2015 05:14:30 +0000"  >&lt;p&gt;That&apos;d save CPU on the replication source. I have the feeling that would not do much to speed things up. What&apos;s slow (and I say this without having verified in detail) is the sequential reading of the WAL and non-streaming writes to the replication sink with absolutely no parallelism.&lt;br/&gt;
Maybe I&apos;ll put instrumentation in to measure exactly where it&apos;s slow, but I am fairly certain it is shipping the edit to the sink and applying them there.&lt;/p&gt;</comment>
                            <comment id="14566676" author="lhofhansl" created="Sun, 31 May 2015 18:52:10 +0000"  >&lt;p&gt;Here&apos;s a simple patch. Only so that we can perf test this, to see whether we&apos;ll see any improvement.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;doesn&apos;t do any grouping by table or row, so with badly times compaction on the sink, deleted data can resurface&lt;/li&gt;
	&lt;li&gt;fixed max parallelization, should better be scaled to the number of sink region servers available (i.e. 10% of selected servers, or something)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As I said, just for testing so that we can see what we can expect as improvement at best.&lt;/p&gt;</comment>
                            <comment id="14566948" author="lhofhansl" created="Mon, 1 Jun 2015 05:25:09 +0000"  >&lt;p&gt;Ran some replication tests. Let&apos;s see if it breaks something unexpected.&lt;br/&gt;
I&apos;ll repeat: &lt;em&gt;not ready to be used at all&lt;/em&gt;, will ship edits out of order.&lt;/p&gt;</comment>
                            <comment id="14567047" author="hadoopqa" created="Mon, 1 Jun 2015 07:59:47 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12736447/ParallelReplication-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12736447/ParallelReplication-v2.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 0e6102a68cc95f0240fa72a5f86866c07b8744b7.&lt;br/&gt;
  ATTACHMENT ID: 12736447&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1929 checkstyle errors (more than the master&apos;s current 1927 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +    this.exec = new ThreadPoolExecutor(1,  maxThreads, 60, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;());&lt;br/&gt;
+    // 2. partition by size - we know overall size, and we can count down rows until we reach 1/Nth of that&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.backup.TestHFileArchiving&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.objectweb.jtests.jms.framework.PTPTestCase.setUp(PTPTestCase.java:118)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14252//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14567593" author="lhofhansl" created="Mon, 1 Jun 2015 17:13:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt; ran some high load tests with this. Quoting his numbers here:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Max AgeOfLastShipped Op (without patch) - 1400s&lt;br/&gt;
Max AgeOfLastShipped Op (with patch) - 900s&lt;br/&gt;
35% Improvement&lt;/p&gt;

&lt;p&gt;Max AgeOfLastApplied Op (without patch) - 1330s&lt;br/&gt;
Max AgeOfLastApplied Op (with patch) - 878s&lt;br/&gt;
34% Improvement&lt;/p&gt;

&lt;p&gt;Max SizeOfLogQueue (without patch) - 38&lt;br/&gt;
Max SizeOfLogQueue (with patch) - 31&lt;br/&gt;
18.5% Improvement&lt;/p&gt;

&lt;p&gt;Total time it took for replication (without patch) - 45 mins&lt;br/&gt;
Total time it took for replication (with patch) - 32 mins&lt;br/&gt;
29% Improvement &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So it looks like at least for this scenario it&apos;s worth pursuing.&lt;/p&gt;</comment>
                            <comment id="14568576" author="lhofhansl" created="Tue, 2 Jun 2015 05:51:19 +0000"  >&lt;p&gt;Now the question is: Can we do this without rewriting every single WALEdit?&lt;/p&gt;

&lt;p&gt;The test patch I attached here simply splits the list of edits before shipping it, and ships it in smaller parts to multiple servers in the sink. It does not rearrange the edits by row or table, and hence may ship edits out of order - namely deletes and puts for the same row.&lt;/p&gt;

&lt;p&gt;Since each WALEdit may contain many cells, and each cell can in theory be for a different row, we would have disentangle the Cells from the WALEdit and write them new edits, while retaining the chain clusterIds, table name from the log key.&lt;/p&gt;

&lt;p&gt;In the case of region server failures at the source, edits can already arrive at the sink out of order, but with this we&apos;d make that the norm rather then an exception under failure. HBase can delay removal of delete markers already in order to avoid most races.&lt;/p&gt;

&lt;p&gt;We can more easily group by table, since that can be done by just looking at the HLogKey, but that will be far less efficient... In fact in Abhishek&apos;s test above will make no difference at all, since we&apos;re testing against a single table only - and I expect that will be common.&lt;/p&gt;

&lt;p&gt;Grouping by region (which is also in HLogKey) is not safe, since rows can move between regions (due to splits). Or is it? Since a split is preceded by a flush.&lt;/p&gt;</comment>
                            <comment id="14575879" author="lhofhansl" created="Sat, 6 Jun 2015 18:52:53 +0000"  >&lt;p&gt;Another observation from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt;&apos;s testing was that the majority of the time is spent at the sink applying the edits. The test was done over high latency links (~60ms), and this surprised me the most. It&apos;s not the network, it&apos;s the time spent on the sink and the fact that the source is not doing &lt;em&gt;any&lt;/em&gt; work during that time, since it synchronously waits for the sink to finish.&lt;/p&gt;</comment>
                            <comment id="14575906" author="lhofhansl" created="Sat, 6 Jun 2015 19:57:14 +0000"  >&lt;p&gt;Here&apos;s a version that groups by region instead. This should reduce out of order delivery, but obviously will not eliminate it. Regions will split and the same row may end up in two different region on the same machine.&lt;/p&gt;

&lt;p&gt;Also make sure that we do not send too few edits in an rpc request (minimum hardcoded to 100 for now).&lt;/p&gt;

&lt;p&gt;I think this is as good as we can get it, without a major rewrite, and without rewriting all the waledits at the source side.&lt;/p&gt;</comment>
                            <comment id="14575982" author="hadoopqa" created="Sat, 6 Jun 2015 22:36:37 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12738196/12988.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12738196/12988.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit c1d970b04d27f4b34a5d4ccd981b9fe8fc326148.&lt;br/&gt;
  ATTACHMENT ID: 12738196&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestRegionRebalancing&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.camel.component.jpa.JpaWithNamedQueryTest.testProducerInsertsIntoDatabaseThenConsumerFiresMessageExchange(JpaWithNamedQueryTest.java:112)&lt;br/&gt;
	at org.apache.camel.component.jpa.JpaWithNamedQueryTest.testProducerInsertsIntoDatabaseThenConsumerFiresMessageExchange(JpaWithNamedQueryTest.java:112)&lt;br/&gt;
	at org.apache.camel.test.junit4.CamelTestSupport.doStopCamelContext(CamelTestSupport.java:517)&lt;br/&gt;
	at org.apache.camel.test.junit4.CamelTestSupport.tearDown(CamelTestSupport.java:400)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14316//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14581263" author="lhofhansl" created="Thu, 11 Jun 2015 00:00:11 +0000"  >&lt;p&gt;Comments? Concerns?&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt;, any chance to run your test again with the latest patch? I assume it would not yield as good a result as we get more continuous Cells for the same regions in a batch, but it would still be interesting.&lt;/p&gt;</comment>
                            <comment id="14587351" author="apurtell" created="Tue, 16 Jun 2015 02:28:10 +0000"  >&lt;p&gt;I applied the attached backport patch for 0.98 to the head of 0.98 branch, set up two single master single RS clusters, then ran IntegrationTestReplication without YARN (so, LocalTestRunner). All test parameters were defaults. This used to work - by accident, frankly, since verification would manage to stay behind where replication was at - but now because edits will be shipped out of order we definitely have to wait for that to finish before verification can commence. I&apos;m happy to say though that after replication has synced all changes verification will pass, so the changes here do not cause any data loss.&lt;/p&gt;</comment>
                            <comment id="14587354" author="apurtell" created="Tue, 16 Jun 2015 02:30:50 +0000"  >&lt;p&gt;When running IntegrationTestReplication you can specify the amount of time to pause between generation (replication) and verification with the &apos;-t&apos; parameter. For good measure on my wimpy setup I used &apos;-t 300&apos;.&lt;/p&gt;</comment>
                            <comment id="14587403" author="lhofhansl" created="Tue, 16 Jun 2015 03:34:30 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;There&apos;s also another idea I had in the meanwhile: The sink logic I had implemented to deal with cluster ids to avoid replication cycles already groups by table and list&amp;lt;clusterid&amp;gt; and then applies this in batches. Could just do the same logic on the sink (with the addition of also grouping by row), maybe it&apos;s OK - performance wise - to break up the WALEdits and to reassemble them. That would certainly make it easier later to stream per row edits to sinks.&lt;/p&gt;</comment>
                            <comment id="14587503" author="hadoopqa" created="Tue, 16 Jun 2015 05:41:25 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12739762/HBASE-12988-0.98.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12739762/HBASE-12988-0.98.patch&lt;/a&gt;&lt;br/&gt;
  against 0.98 branch at commit cba9ea61ddce7f592c2c43ffae9bac5fa0464448.&lt;br/&gt;
  ATTACHMENT ID: 12739762&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 25 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14424//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14588528" author="apurtell" created="Tue, 16 Jun 2015 18:31:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;maybe it&apos;s OK - performance wise - to break up the WALEdits and to reassemble them. That would certainly make it easier later to stream per row edits to sinks.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s an interesting idea to try, certainly. Want to commit what we have here as a step toward that and then refine it on a follow-on issue?&lt;/p&gt;</comment>
                            <comment id="14590308" author="lhofhansl" created="Wed, 17 Jun 2015 18:46:55 +0000"  >&lt;p&gt;I&apos;d be happy to commit as is. Maybe await another test-run from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt; (although he&apos;s busy with some other stuff right now).&lt;/p&gt;</comment>
                            <comment id="14590320" author="lhofhansl" created="Wed, 17 Jun 2015 18:50:56 +0000"  >&lt;p&gt;Any comments on this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; n = &lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.maxThreads, replicationSinkMgr.getSinks().size()/100+1);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;?&lt;/p&gt;

&lt;p&gt;I&apos;m trying to avoid breaking up very small batches. I.e. if the batch has only 50 edits to ship it does not make much sense to break that up into 5 chunks of 1 edit. Even when these edits are large... In that case the network time will dominate and breaking up won&apos;t add much.&lt;br/&gt;
So I pulled 100 out of my hat.&lt;/p&gt;

&lt;p&gt;Also maybe I should add a Math.min(..., number of sinks), so that we are not using more threads than we have sinks region servers on the other side.&lt;/p&gt;</comment>
                            <comment id="14590388" author="lhofhansl" created="Wed, 17 Jun 2015 19:15:48 +0000"  >&lt;p&gt;Actually I got that wrong. Meant to do entries.size()/100+1. New patch coming up soon.&lt;/p&gt;</comment>
                            <comment id="14590413" author="apurtell" created="Wed, 17 Jun 2015 19:34:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;New patch coming up soon.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds good, and so does waiting for when &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt; gets another chance to try it out. No rush.&lt;/p&gt;</comment>
                            <comment id="14590425" author="lhofhansl" created="Wed, 17 Jun 2015 19:40:08 +0000"  >&lt;p&gt;Slightly updated patch.&lt;/p&gt;</comment>
                            <comment id="14590823" author="hadoopqa" created="Wed, 17 Jun 2015 23:15:35 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12740197/12988-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12740197/12988-v2.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 623fd63827b2953c150597f24c7205737119bebe.&lt;br/&gt;
  ATTACHMENT ID: 12740197&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.1 2.5.2 2.6.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14449//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14592742" author="lhofhansl" created="Thu, 18 Jun 2015 23:51:24 +0000"  >&lt;p&gt;Object.hashCode() can be negative, so need to abs() it in order to use as a array index.&lt;/p&gt;</comment>
                            <comment id="14592756" author="lhofhansl" created="Fri, 19 Jun 2015 00:01:39 +0000"  >&lt;p&gt;And here&apos;s yet another idea. (sorry for my public thought process here):&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;If the batch only contains one unique (table, List&amp;lt;ClusterId&amp;gt;) combination we create a fake WALKey and group by row key.&lt;/li&gt;
	&lt;li&gt;if the batch does contain edits for multiple (table, List&amp;lt;ClusterId&amp;gt;) tuples, then we group by that&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In case #1 it&apos;ll make the grouping much easier, because we do have the relate the row grouping back to the originating WALKey (which has the clusterids and table).&lt;/p&gt;</comment>
                            <comment id="14608676" author="lhofhansl" created="Tue, 30 Jun 2015 17:10:05 +0000"  >&lt;p&gt;The WALKey (formerly HLogKey) also has logSeqNum and writeTime. Right now the sink only uses the writeTime to update ageOfLastAppliedOp.&lt;br/&gt;
If ever we want to use them - for ordering or other guarantees - we cannot disentangle them from the WALEdits; i.e. we cannot regroup Cell between WALEdits.&lt;/p&gt;

&lt;p&gt;So in the end I think that we do the grouping by table or by region (as I have done here)... or don&apos;t do it at all.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hongyu.bi&quot; class=&quot;user-hover&quot; rel=&quot;hongyu.bi&quot;&gt;hongyu bi&lt;/a&gt;, comments?&lt;/p&gt;</comment>
                            <comment id="14608936" author="hadoopqa" created="Tue, 30 Jun 2015 19:37:12 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12740521/12988-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12740521/12988-v3.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit f8bd578b80b4e656d799c82ca1b6191e35bb0ae4.&lt;br/&gt;
  ATTACHMENT ID: 12740521&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14628//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14609015" author="stack" created="Tue, 30 Jun 2015 20:31:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;If ever we want to use them - for ordering or other guarantees - we cannot disentangle them from the WALEdits; i.e. we cannot regroup Cell between WALEdits.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why not &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt;? Thanks.&lt;/p&gt;</comment>
                            <comment id="14609030" author="lhofhansl" created="Tue, 30 Jun 2015 20:42:10 +0000"  >&lt;p&gt;The reason is that we&apos;d have to regroup the edits with the writetime and sequencenumber under which they originated. Since each Entry (WALKey, WALEdit pair) has a unique sequencenumber we cannot pull the edits apart... Or in other words we can only regroup &lt;em&gt;within&lt;/em&gt; a single WALEdit.&lt;/p&gt;

&lt;p&gt;In this patch I did the next best compromise and group by data in the WALKey. The region is the most diverse (or more partitioned) to use.&lt;/p&gt;</comment>
                            <comment id="14609183" author="apurtell" created="Tue, 30 Jun 2015 22:29:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;The reason is that we&apos;d have to regroup the edits with the writetime and sequencenumber under which they originated. Since each Entry (WALKey, WALEdit pair) has a unique sequencenumber we cannot pull the edits apart...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, but:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The WALKey (formerly HLogKey) also has logSeqNum and writeTime. Right now the sink only uses the writeTime to update ageOfLastAppliedOp. If ever we want to use them - for ordering or other guarantees - we cannot disentangle them from the WALEdits; i.e. we cannot regroup Cell between WALEdits.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So we are not using the WALKey sequence number. Any pressing reason why we should? If not we can deprecate and remove it. Likewise, we can document that writeTime is informational and does not provide a guarantee of ordering. &lt;/p&gt;</comment>
                            <comment id="14609311" author="lhofhansl" created="Wed, 1 Jul 2015 00:21:11 +0000"  >&lt;p&gt;We are using the writeTime on the sink to calculate ageOfLastAppliedOp, which is an important metric, I suppose we can ship the max time we&apos;ve seen in a batch and still be correct. In that case we can also optimize the replication stream and only send a WALKey once followed by all WALEdits belong to it.&lt;/p&gt;

&lt;p&gt;But... I assume at some point we&apos;ll want to make replication more &quot;consistent&quot;, ordering by seqNum (or delaying visibility by seqNum) would be a (the only?) way to do that. I do not want to design anything that prevents us from doing this going forward. Grouping by HRegion is simple (this patch is all that is needed) and (presumably) effective.&lt;/p&gt;</comment>
                            <comment id="14609317" author="apurtell" created="Wed, 1 Jul 2015 00:22:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;Grouping by HRegion is simple (this patch is all that is needed) and (presumably) effective.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure, that seems fine to me too.&lt;/p&gt;</comment>
                            <comment id="14609320" author="lhofhansl" created="Wed, 1 Jul 2015 00:24:29 +0000"  >&lt;p&gt;Maybe the best answer is to do this in two jiras.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;HRegion grouping here, with maybe a slight change to default threads to 1 at least in 0.98 and 1.0 along with some enhanced logic to deal with the single threaded cases without scheduling tasks on the threadpool.&lt;/li&gt;
	&lt;li&gt;A new jira for a more complicated refactoring of the replication code, doing what I describe above.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14610680" author="stack" created="Wed, 1 Jul 2015 17:30:26 +0000"  >&lt;p&gt;We should make use of sequence id in sink (especially when we change sort so Cell &apos;type&apos; is NOT a factor)&lt;/p&gt;

&lt;p&gt;Your breaking apart JIRA into two sounds good.&lt;/p&gt;</comment>
                            <comment id="14612555" author="lhofhansl" created="Thu, 2 Jul 2015 21:27:28 +0000"  >&lt;p&gt;Filed: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14014&quot; title=&quot;Explore row-by-row grouping options&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14014&quot;&gt;HBASE-14014&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14612560" author="lhofhansl" created="Thu, 2 Jul 2015 21:29:38 +0000"  >&lt;p&gt;Slight update. Just optimizes the case where the number of batches ends up being 1. In that case we do not need to do any grouping as the result would be the original group anyway.&lt;/p&gt;

&lt;p&gt;In 1.1+ I plan to default the number of threads to 10. Before that (1.0 and 0.98) to 1, so that the behavior and performance characteristics do not change.&lt;/p&gt;</comment>
                            <comment id="14612667" author="lhofhansl" created="Thu, 2 Jul 2015 23:14:20 +0000"  >&lt;p&gt;Good to commit this way?&lt;/p&gt;</comment>
                            <comment id="14613361" author="apurtell" created="Fri, 3 Jul 2015 17:56:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;In 1.1+ I plan to default the number of threads to 10. Before that (1.0 and 0.98) to 1, so that the behavior and performance characteristics do not change.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sounds reasonable. &lt;/p&gt;

&lt;p&gt;Can you pull this out into a constant and javadoc it? Should go into hbase-defaults.xml too I think. &lt;/p&gt;
&lt;blockquote&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;replication.source.maxthreads&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;

&lt;p&gt;What do you think about DEBUG level logging where we are submitting futures and then handling errors here?&lt;/p&gt;
&lt;blockquote&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 
+        List&amp;lt;Future&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt; futures = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;Future&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt;(entryLists.size());
+        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i=0; i&amp;lt;entryLists.size(); i++) {
+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!entryLists.get(i).isEmpty()) {
+            futures.add(exec.submit(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Replicator(entryLists.get(i), i)));
+          }
+        }
+        IOException iox = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
+        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Future&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; f : futures) {
+          &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+            &lt;span class=&quot;code-comment&quot;&gt;// wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all futures remove successful parts
&lt;/span&gt;+            entryLists.remove(f.get());
+          } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException ie) {
+            iox =  &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(ie);
+          } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (ExecutionException ee) {
+            &lt;span class=&quot;code-comment&quot;&gt;// cause must be an IOException
&lt;/span&gt;+            iox = (IOException)ee.getCause();
+          }
+        }
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (iox != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+          &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we had any exception, &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; again
&lt;/span&gt;+          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; iox;
+        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;

&lt;p&gt;Have you by chance had a chance to run ITR with the latest changes applied? It&apos;s a bit of a PITA to set up, you&apos;ll need to have two single node clusters running on the same node as minimum. If not don&apos;t worry I&apos;ll do it as part of checking the 0.98.14 RC (this change will be in it for sure).&lt;/p&gt;</comment>
                            <comment id="14613364" author="apurtell" created="Fri, 3 Jul 2015 17:58:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;If not don&apos;t worry I&apos;ll do it as part of checking the 0.98.14 RC (this change will be in it for sure).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;ll check it with the new setting at 1 (default for 0.98) and 10...&lt;/p&gt;</comment>
                            <comment id="14613401" author="lhofhansl" created="Fri, 3 Jul 2015 18:52:26 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;. Absolutely yes on the constant and hbase-defaults.xml.&lt;/p&gt;

&lt;p&gt;Not sure I follow the part with the DEBUG message. Future.get() will rethrow any error it encounters and then the outer catch will process those in the same way we do now.&lt;br/&gt;
So in effect the error handling is unchanged. The only difference is when multiple tasks encounter an exception we only remember the last one... Is that part what you meant? I wanted to give the other tasks a chance to run and then only reschedule those that actually did encounter an error.&lt;/p&gt;</comment>
                            <comment id="14613410" author="apurtell" created="Fri, 3 Jul 2015 19:05:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;Not sure I follow the part with the DEBUG message. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Oh I just mean making what&apos;s going on with the new logic available in cluster logs at DEBUG level. No need if you don&apos;t think it worth it.&lt;/p&gt;</comment>
                            <comment id="14613418" author="lhofhansl" created="Fri, 3 Jul 2015 19:24:21 +0000"  >&lt;p&gt;v5&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;constants in HConstants&lt;/li&gt;
	&lt;li&gt;default in hbase-default.xml&lt;/li&gt;
	&lt;li&gt;improved comments&lt;/li&gt;
	&lt;li&gt;trace messages when enqueueing tasks&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14613419" author="apurtell" created="Fri, 3 Jul 2015 19:27:05 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14613424" author="lhofhansl" created="Fri, 3 Jul 2015 19:51:05 +0000"  >&lt;p&gt;Just remembering now... &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt;, you had added a bunch of log messages locally to track where time is spent during replication. Should we fold those in here? Or separate jira?&lt;/p&gt;</comment>
                            <comment id="14613682" author="hadoopqa" created="Sat, 4 Jul 2015 10:45:36 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12743547/12988-v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12743547/12988-v5.txt&lt;/a&gt;&lt;br/&gt;
  against master branch at commit e640f1e76af8f32015f475629610da127897f01e.&lt;br/&gt;
  ATTACHMENT ID: 12743547&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/14658//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14615107" author="abhishek.chouhan" created="Mon, 6 Jul 2015 14:42:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; Sorry for the delay, was busy lately. Doing a performance run with patch today. Will share the numbers tomorrow.&lt;br/&gt;
As for the debug messages, i was keeping a track of the time it took for  ReplicationProtbufUtil.replicateWALEntry on the source side, we can maybe have statements at trace level to track how much time it took for all the threads to parallely apply edits (we can log just after we get all the futures). On the sink side i was keeping track of the time taken by replicateEntries(..) and then to profile further and see which part was taking the most time, was monitoring how much was being taken to batch into the sink cluster. Should we add all these at trace level (having these at debug level would be too spammy IMO).&lt;/p&gt;</comment>
                            <comment id="14620687" author="lhofhansl" created="Thu, 9 Jul 2015 15:33:40 +0000"  >&lt;p&gt;Latest data from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.chouhan&quot; class=&quot;user-hover&quot; rel=&quot;abhishek.chouhan&quot;&gt;Abhishek Singh Chouhan&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tested out the latest patch(v5) by loading the cluster using 2 clients each writing 250 million rows into two separate tables.&lt;br/&gt;
Cluster used (relvalidation &amp;lt;-----&amp;gt; hbsrcrd2) each having 7RS&lt;/p&gt;

&lt;p&gt;Results -&lt;br/&gt;
Max AgeOfLastShipped Op (without patch) - 3370s&lt;br/&gt;
Max AgeOfLastShipped Op (with patch) - 2550s&lt;br/&gt;
24.3% Improvement&lt;/p&gt;

&lt;p&gt;Max AgeOfLastApplied Op (without patch) - 3440s&lt;br/&gt;
Max AgeOfLastApplied Op (with patch) - 2590s&lt;br/&gt;
24.7% Improvement&lt;/p&gt;

&lt;p&gt;Max SizeOfLogQueue (without patch) - 79&lt;br/&gt;
Max SizeOfLogQueue (with patch) - 75&lt;br/&gt;
5% Improvement&lt;/p&gt;

&lt;p&gt;Total time it took for replication (without patch) - 110 mins&lt;br/&gt;
Total time it took for replication (with patch) - 92 mins&lt;br/&gt;
16.4% Improvement &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Abhishek! As expected the result is not quite as good as more or less random partitioning, but still a good improvement.&lt;/p&gt;</comment>
                            <comment id="14659903" author="lhofhansl" created="Thu, 6 Aug 2015 12:10:49 +0000"  >&lt;p&gt;I think we can commit this as a stop gap measure. It lays the foundation for a multithreaded replication source (or at least supports the idea).&lt;/p&gt;

&lt;p&gt;Any objections?&lt;/p&gt;</comment>
                            <comment id="14698095" author="lhofhansl" created="Sat, 15 Aug 2015 03:58:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, this is the issue I was mentioning. Check out the number from June 1st above (that was a test with maximum parallelism - not correct, but shows the potential), 3 or 5 way I think.&lt;/p&gt;

&lt;p&gt;The later number are for something that works, namely for parallelizing across regions.&lt;/p&gt;</comment>
                            <comment id="14717561" author="eclark" created="Thu, 27 Aug 2015 21:23:57 +0000"  >&lt;p&gt;Lets get this into 1.2 so that the foundation of multithreaded replication is in and tested before we try the more extreme levels.&lt;/p&gt;</comment>
                            <comment id="14720703" author="lhofhansl" created="Fri, 28 Aug 2015 22:33:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=busbey&quot; class=&quot;user-hover&quot; rel=&quot;busbey&quot;&gt;Sean Busbey&lt;/a&gt;, this the replication issue we had discussed on Wednesday. Very simple, avoid huge refactoring by breaking a batch already assembled into pieces before sending to the slave(s). Ideally we&apos;d interleave everything (reading the logs, shipping data across the wire, and applying the edits), this does only the latter two (but avoids a major refactoring).&lt;/p&gt;</comment>
                            <comment id="14720705" author="lhofhansl" created="Fri, 28 Aug 2015 22:33:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eclark&quot; class=&quot;user-hover&quot; rel=&quot;eclark&quot;&gt;Elliott Clark&lt;/a&gt;, Yeah, 2.0.0 and 1.2.x seem good targets here.&lt;/p&gt;</comment>
                            <comment id="14721564" author="eclark" created="Sun, 30 Aug 2015 15:25:51 +0000"  >&lt;p&gt;+1 from me.&lt;/p&gt;</comment>
                            <comment id="14730288" author="eclark" created="Fri, 4 Sep 2015 04:15:12 +0000"  >&lt;p&gt;Should we get this in so that the 1.2 RC testing can get it ?&lt;br/&gt;
I can commit if you are comfortable with the patch as it stands.&lt;/p&gt;</comment>
                            <comment id="14730339" author="lhofhansl" created="Fri, 4 Sep 2015 05:26:45 +0000"  >&lt;p&gt;Yeah... Lemme just check it in. Probably tomorrow. Bit swamped right now.&lt;/p&gt;</comment>
                            <comment id="14731367" author="lhofhansl" created="Fri, 4 Sep 2015 20:30:03 +0000"  >&lt;p&gt;Pushed to 1.2, 1.3, and 2.0.&lt;br/&gt;
Can backport further if needed.&lt;/p&gt;</comment>
                            <comment id="14731425" author="hudson" created="Fri, 4 Sep 2015 21:08:55 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.3-IT #133 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3-IT/133/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3-IT/133/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12988&quot; title=&quot;[Replication]Parallel apply edits across regions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12988&quot;&gt;&lt;del&gt;HBASE-12988&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Replication&amp;#93;&lt;/span&gt;Parallel apply edits across regions. (larsh: rev 16d4ed63371e5c519314e94e055f9e6e13dc1e81)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/HBaseInterClusterReplicationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14731576" author="hudson" created="Fri, 4 Sep 2015 23:05:55 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.2 #152 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.2/152/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.2/152/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12988&quot; title=&quot;[Replication]Parallel apply edits across regions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12988&quot;&gt;&lt;del&gt;HBASE-12988&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Replication&amp;#93;&lt;/span&gt;Parallel apply edits across regions. (larsh: rev f186558b3ec09b721f935930c8ae93ffb990d667)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/HBaseInterClusterReplicationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14731616" author="hudson" created="Fri, 4 Sep 2015 23:38:23 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-1.3 #150 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.3/150/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.3/150/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12988&quot; title=&quot;[Replication]Parallel apply edits across regions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12988&quot;&gt;&lt;del&gt;HBASE-12988&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Replication&amp;#93;&lt;/span&gt;Parallel apply edits across regions. (larsh: rev 16d4ed63371e5c519314e94e055f9e6e13dc1e81)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/HBaseInterClusterReplicationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14731685" author="hudson" created="Sat, 5 Sep 2015 01:20:59 +0000"  >&lt;p&gt;SUCCESS: Integrated in HBase-1.2-IT #128 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-1.2-IT/128/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-1.2-IT/128/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12988&quot; title=&quot;[Replication]Parallel apply edits across regions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12988&quot;&gt;&lt;del&gt;HBASE-12988&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Replication&amp;#93;&lt;/span&gt;Parallel apply edits across regions. (larsh: rev f186558b3ec09b721f935930c8ae93ffb990d667)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/HBaseInterClusterReplicationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14731704" author="hudson" created="Sat, 5 Sep 2015 01:59:35 +0000"  >&lt;p&gt;FAILURE: Integrated in HBase-TRUNK #6783 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/6783/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/6783/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-12988&quot; title=&quot;[Replication]Parallel apply edits across regions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-12988&quot;&gt;&lt;del&gt;HBASE-12988&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Replication&amp;#93;&lt;/span&gt;Parallel apply edits across regions. (larsh: rev 6a8ba22c1681915eb65b755234344ba58be408ee)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java&lt;/li&gt;
	&lt;li&gt;hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/HBaseInterClusterReplicationEndpoint.java&lt;/li&gt;
	&lt;li&gt;hbase-common/src/main/resources/hbase-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12911015">HBASE-14777</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12740197" name="12988-v2.txt" size="7113" author="lhofhansl" created="Wed, 17 Jun 2015 19:40:08 +0000"/>
                            <attachment id="12740521" name="12988-v3.txt" size="7123" author="lhofhansl" created="Thu, 18 Jun 2015 23:51:24 +0000"/>
                            <attachment id="12743399" name="12988-v4.txt" size="7209" author="lhofhansl" created="Thu, 2 Jul 2015 21:29:38 +0000"/>
                            <attachment id="12743547" name="12988-v5.txt" size="9693" author="lhofhansl" created="Fri, 3 Jul 2015 19:24:21 +0000"/>
                            <attachment id="12738196" name="12988.txt" size="6971" author="lhofhansl" created="Sat, 6 Jun 2015 19:57:14 +0000"/>
                            <attachment id="12739762" name="HBASE-12988-0.98.patch" size="7302" author="apurtell" created="Tue, 16 Jun 2015 02:28:10 +0000"/>
                            <attachment id="12736447" name="ParallelReplication-v2.txt" size="6950" author="lhofhansl" created="Sun, 31 May 2015 18:52:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Feb 2015 04:42:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i25cq7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>