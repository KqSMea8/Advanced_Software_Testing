<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:35:12 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6261/HBASE-6261.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6261] Better approximate high-percentile percentile latency metrics</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6261</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The existing reservoir-sampling based latency metrics in HBase are not well-suited for providing accurate estimates of high-percentile (e.g. 90th, 95th, or 99th) latency. This is a well-studied problem in the literature (see &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;), the question is determining which methods best suit our needs and then implementing it.&lt;/p&gt;

&lt;p&gt;Ideally, we should be able to estimate these high percentiles with minimal memory and CPU usage as well as minimal error (e.g. 1% error on 90th, or .1% on 99th). It&apos;s also desirable to provide this over different time-based sliding windows, e.g. last 1 min, 5 mins, 15 mins, and 1 hour.&lt;/p&gt;

&lt;p&gt;I&apos;ll note that this would also be useful in HDFS, or really anywhere latency metrics are kept.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;http://www.cs.rutgers.edu/~muthu/bquant.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.cs.rutgers.edu/~muthu/bquant.pdf&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; &lt;a href=&quot;http://infolab.stanford.edu/~manku/papers/04pods-sliding.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://infolab.stanford.edu/~manku/papers/04pods-sliding.pdf&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12595628">HBASE-6261</key>
            <summary>Better approximate high-percentile percentile latency metrics</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andrew.wang">Andrew Wang</assignee>
                                    <reporter username="andrew.wang">Andrew Wang</reporter>
                        <labels>
                            <label>metrics</label>
                    </labels>
                <created>Fri, 22 Jun 2012 20:30:43 +0000</created>
                <updated>Fri, 28 Dec 2012 15:22:08 +0000</updated>
                            <resolved>Fri, 28 Dec 2012 15:22:08 +0000</resolved>
                                                                    <component>metrics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="13401178" author="otis" created="Tue, 26 Jun 2012 05:19:59 +0000"  >&lt;p&gt;@Andrew - Ted Dunning may have thoughts on this and/or pointers to Mahout math or something else.&lt;/p&gt;</comment>
                            <comment id="13401463" author="otis" created="Tue, 26 Jun 2012 15:47:12 +0000"  >&lt;p&gt;@Andrew See &lt;a href=&quot;https://twitter.com/otisg/status/217487624804376576&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://twitter.com/otisg/status/217487624804376576&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13401512" author="apurtell" created="Tue, 26 Jun 2012 16:54:08 +0000"  >&lt;p&gt;Which provoked this response: &lt;a href=&quot;https://twitter.com/ted_dunning/status/217488314297626625&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://twitter.com/ted_dunning/status/217488314297626625&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The basic techniques from the Mahout OnlineSummarizer will work for this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Would be great if any subsequent conversation happen on this JIRA instead of in twitterspace. &lt;/p&gt;</comment>
                            <comment id="13401850" author="andrew.wang" created="Wed, 27 Jun 2012 01:06:47 +0000"  >&lt;p&gt;I&apos;ve written up a comparison of what I think are all the available options. It really just comes down to a couple questions:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Do we care about bounded error?&lt;/li&gt;
	&lt;li&gt;Do we want sliding windows (more mem), or are okay just snapshotting and starting anew every interval?&lt;/li&gt;
	&lt;li&gt;Do we care about strictly bounded memory usage, or is O(few MBs) good enough?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m hoping that we want bounded error, are okay snapshotting, and are okay with O(few MBs). I&apos;ve implemented the algo for this case and am testing it out to make sure it meets the performance requirements.&lt;/p&gt;</comment>
                            <comment id="13401946" author="zhihyu@ebaysf.com" created="Wed, 27 Jun 2012 03:57:58 +0000"  >&lt;p&gt;&quot;Approximate Counts and Quantiles over Sliding Windows&quot; is more desirable for its ability to do arbitrary percentiles for sliding time windows.&lt;/p&gt;</comment>
                            <comment id="13401978" author="eclark" created="Wed, 27 Jun 2012 05:43:21 +0000"  >&lt;p&gt;Sliding times are much less useful if they come with a big cost.  I&apos;d much rather move the moving average computation into something like OpenTSDB than to have it in hbase.  HBase should keep the least amount of history as possible.  That way people that are interested in deep metrics can get it and move that into a dedicated system; all others are able to ignore it and they don&apos;t pay a high cost.&lt;/p&gt;

&lt;p&gt;Speed &amp;gt; Memory &amp;gt; Accuracy&lt;/p&gt;</comment>
                            <comment id="13402354" author="zhihyu@ebaysf.com" created="Wed, 27 Jun 2012 16:55:47 +0000"  >&lt;p&gt;So far I think the assumption is that the new algorithm would apply to the computation of all metrics.&lt;/p&gt;

&lt;p&gt;Is it possible to configure &quot;Approximate Counts and Quantiles over Sliding Windows&quot; for a few selected metrics (to be consumed by load balancer, e.g.) while the others get computed with light weight algorithm ?&lt;/p&gt;</comment>
                            <comment id="13402429" author="andrew.wang" created="Wed, 27 Jun 2012 18:11:58 +0000"  >&lt;p&gt;@Elliot: Moving averages can be cheaply computed on the existing reservoir sample, this is more about percentiles. I&apos;m not sure how OpenTSDB factors into this, since you&apos;d have to feed the latency stream to OpenTSDB to figure out percentiles, which seems expensive. Depending on how tight your speed and memory constraints are, I think we could do this in HBase at acceptably minimal cost, or make this configurable somehow.&lt;/p&gt;

&lt;p&gt;@Ted: The additional cost to do sliding windows is somewhat significant (I think 10s of MB more memory). Both the sliding and non-sliding methods allow for arbitrary percentiles. Anyway, I think reporting the 50th, 90th, 95th, and 99th should satisfy anyone. Mixing and matching algorithms is possible and probably even advised since it&apos;s only worth doing this for high-rate streams where accuracy is important. Implementations of the cheaper and less accurate algos are already available.&lt;/p&gt;</comment>
                            <comment id="13402443" author="eclark" created="Wed, 27 Jun 2012 18:34:54 +0000"  >&lt;p&gt;Basically I&apos;m saying that I don&apos;t think that sliding windows are useful since most things that consume the metrics can do a moving average, which performs a very similar job as sliding windows.&lt;/p&gt;
</comment>
                            <comment id="13402733" author="andrew.wang" created="Thu, 28 Jun 2012 00:53:47 +0000"  >&lt;p&gt;I&apos;ve got my Java implementation of the non-sliding biased quantiles algorithm (QuantileEstimationCKMS.java) up on github:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/umbrant/QuantileEstimation&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/umbrant/QuantileEstimation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Benchmarking on my laptop, I pushed 1 million shuffled items [0, 10**9) through it in 1.2 seconds while asking it to track the 50th, 90th, 95th, and 99th percentiles with low error. It kept ~5500 samples to do this, which at ~36B per sample, is about 193KiB. Empirical error was basically 0. I also ran it for 10 million random longs, which took 19s and about 685KiB.&lt;/p&gt;

&lt;p&gt;I think this is pretty lightweight. If this sounds reasonable, I&apos;ll start working on a patch.&lt;/p&gt;</comment>
                            <comment id="13403225" author="zhihyu@ebaysf.com" created="Thu, 28 Jun 2012 17:04:06 +0000"  >&lt;p&gt;Nice work.&lt;/p&gt;

&lt;p&gt;In QuantileEstimationCKMS.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[] buffer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[500];
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think the buffer size should be configurable.&lt;br/&gt;
Can we maintain a metric for how often compress() is called ?&lt;br/&gt;
Should compress() return an int indicating how many items are removed ?&lt;br/&gt;
What if no item gets removed coming out of a call to compress() ?&lt;/p&gt;

&lt;p&gt;Please work on a patch.&lt;/p&gt;</comment>
                            <comment id="13403280" author="andrew.wang" created="Thu, 28 Jun 2012 17:41:26 +0000"  >&lt;p&gt;I don&apos;t think performance is very sensitive to the buffer size, it&apos;s just a way of batching inserts for efficiency. Definitely doesn&apos;t affect accuracy because I have it call insertBatch() on every query().&lt;/p&gt;

&lt;p&gt;We can maintain the compress count and track the # items removed, but I don&apos;t know if it&apos;s really worth exposing to the user (metrics for our metrics?). I think it&apos;s nice for testing though, so I&apos;ll try to expose it internally.&lt;/p&gt;

&lt;p&gt;I&apos;ve never seen compress() fail to remove any items, but I guess this could happen with some adversarial pattern. I don&apos;t think you can do much about it though, since the algo needs those items to maintain the error bounds.&lt;/p&gt;</comment>
                            <comment id="13403284" author="zhihyu@ebaysf.com" created="Thu, 28 Jun 2012 17:44:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;algo needs those items to maintain the error bounds.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Right. That&apos;s why I was looking for data structure that can grow in size.&lt;/p&gt;</comment>
                            <comment id="13403304" author="andrew.wang" created="Thu, 28 Jun 2012 18:01:19 +0000"  >&lt;p&gt;Yea, everything ultimately goes into the &lt;tt&gt;sample&lt;/tt&gt; LinkedList. The fixed size &lt;tt&gt;buffer&lt;/tt&gt; is just used to do more efficient batch inserts into &lt;tt&gt;sample&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="13403456" author="zhihyu@ebaysf.com" created="Thu, 28 Jun 2012 20:28:33 +0000"  >&lt;p&gt;Makes sense.&lt;br/&gt;
Looking forward to the patch.&lt;/p&gt;</comment>
                            <comment id="13403571" author="andrew.wang" created="Thu, 28 Jun 2012 23:16:04 +0000"  >&lt;p&gt;I filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8541&quot; title=&quot;Better high-percentile latency metrics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8541&quot;&gt;&lt;del&gt;HADOOP-8541&lt;/del&gt;&lt;/a&gt;, since this is going to be landing in hadoop-common&apos;s metrics2. When &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5040&quot; title=&quot;Secure HBase builds fail&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5040&quot;&gt;&lt;del&gt;HBASE-5040&lt;/del&gt;&lt;/a&gt; clears, we can look into actually hooking it up in HBase.&lt;/p&gt;</comment>
                            <comment id="13403576" author="eclark" created="Thu, 28 Jun 2012 23:24:13 +0000"  >&lt;p&gt;If it only lands in hadoop are we going to be able to use it at all?  Reflection doesn&apos;t seem like it&apos;s really viable here where we&apos;re trying to call the same method on lots of different Histogram objects; it would be pretty slow on top of the perf hit we would be taking for the added accuracy.  &lt;/p&gt;

&lt;p&gt;Can it just replace MetricsHistogram ?&lt;/p&gt;</comment>
                            <comment id="13403586" author="andrew.wang" created="Thu, 28 Jun 2012 23:44:45 +0000"  >&lt;p&gt;I think it&apos;ll be usable from common, it&apos;s going to be like the existing MutableCounter or MutableStat in that you instantiate it once then call updateMethod() a bunch. Unless HBase does it differently than the datanode, I don&apos;t think reflection is used on the hot path of tracking the stream of values, just occasionally to publish it via JMX.&lt;/p&gt;</comment>
                            <comment id="13403595" author="eclark" created="Thu, 28 Jun 2012 23:55:10 +0000"  >&lt;p&gt;But we won&apos;t be able to require the new version of hadoop that would contain the code for quite a while. So we would have to keep our current Histogram implementation, use reflection to see if hadoop jars contain UberHistogram(or whatever you plan on calling it), if so use reflection to interact with it.&lt;/p&gt;</comment>
                            <comment id="13416680" author="andrew.wang" created="Tue, 17 Jul 2012 22:45:42 +0000"  >&lt;p&gt;Sorry I haven&apos;t had time to push on this more. I talked with Jon Hsieh last week about doing a more convincing analysis of the performance of the new MutableQuantiles class from &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8541&quot; title=&quot;Better high-percentile latency metrics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8541&quot;&gt;&lt;del&gt;HADOOP-8541&lt;/del&gt;&lt;/a&gt; vs the existing reservoir-sampling histogram method. I&apos;ll try to get that done within a week.&lt;/p&gt;

&lt;p&gt;I&apos;m also not sure about the right course of action at getting it used in HBase. Stack indicated way back on the mailing list that he was okay waiting for a hadoop-common version bump, which is kind of a long timescale. If people really urgently want this, we could just copy the code over and then refactor it away when it&apos;s released in hadoop-common.&lt;/p&gt;</comment>
                            <comment id="13416706" author="zhihyu@ebaysf.com" created="Tue, 17 Jul 2012 23:22:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;copy the code over and then refactor it away&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 on above.&lt;/p&gt;</comment>
                            <comment id="13417178" author="stack" created="Wed, 18 Jul 2012 15:37:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;Stack indicated way back on the mailing list that he was okay waiting for a hadoop-common version bump, which is kind of a long timescale.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah.  Code copied in tends to never go away (For example: see MurmurHash that started out in hbase and has been in hadoop now w/ a good few years).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If people really urgently want this, we could just copy the code over and then refactor it away when it&apos;s released in hadoop-common.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds like a nice to have.  How much code would you have to copy in?  What would it be?  Thanks Andrew.&lt;/p&gt;
</comment>
                            <comment id="13417302" author="andrew.wang" created="Wed, 18 Jul 2012 17:44:03 +0000"  >&lt;p&gt;It&apos;d be these files from hadoop-common:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;src/main/java/org/apache/hadoop/metrics2/lib/MutableQuantiles.java&lt;/li&gt;
	&lt;li&gt;src/main/java/org/apache/hadoop/metrics2/lib/Quantiles.java&lt;/li&gt;
	&lt;li&gt;src/main/java/org/apache/hadoop/metrics2/util/SampleQuantiles.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;tt&gt;wc -l&lt;/tt&gt; reports it&apos;s 534 lines across those three files, heavily commented of course. &lt;tt&gt;MutableQuantiles&lt;/tt&gt; is a hadoop2 metrics2 interface for SampleQuantiles, and might need to be modified for use in HBase. I haven&apos;t looked at what Elliot&apos;s done for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4050&quot; title=&quot;Update HBase metrics framework to metrics2 framework&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4050&quot;&gt;&lt;del&gt;HBASE-4050&lt;/del&gt;&lt;/a&gt; yet.&lt;/p&gt;</comment>
                            <comment id="13417891" author="stack" created="Thu, 19 Jul 2012 00:21:50 +0000"  >&lt;p&gt;@Elliott You going to bring these files listed by Andrew above in anyways up in compat modules?&lt;/p&gt;</comment>
                            <comment id="13421031" author="andrew.wang" created="Mon, 23 Jul 2012 23:33:46 +0000"  >&lt;p&gt;Based on feedback from Elliot and Jon, I&apos;ve done some analysis of both SampleQuantiles and MetricsHistogram.&lt;/p&gt;

&lt;p&gt;For both, I tried item counts of 1k, 10k, 100k, 1M, 2.5M, 5M, and 10M. For each count, I randomly shuffled longs from &lt;tt&gt;[0, count)&lt;/tt&gt;, pushed them through the estimator, and measured the runtime, # of samples, and error for various quantiles. This was repeated ten times, giving stddev error bars for each point.&lt;/p&gt;

&lt;p&gt;MetricsHistogram was left using default settings (1028 item reservoir). SampleQuantiles was also left with default settings, tracking the same quantiles as MetricsHistogram, but with bounded error. I threw away the 0.90 quantile from SampleQuantiles since MetricsHistogram didn&apos;t have a function to compute it (though trivial).&lt;/p&gt;

&lt;p&gt;This was all run single-threaded on my couple-years-old T410s laptop.&lt;/p&gt;

&lt;p&gt;You can view the imgur album of just the plots here: &lt;a href=&quot;http://imgur.com/a/gTDYr&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://imgur.com/a/gTDYr&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Runtime&quot;&gt;&lt;/a&gt;Runtime&lt;/h2&gt;

&lt;p&gt;Note that the y-axis is log-scale in this plot. SampleQuantiles is roughly an order of magnitude slower at 10 million items (26.8s vs. 3.3s), but the scaling pattern overall looks good. It&apos;s comparable for low (&amp;lt;=10k) items.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/c6SIl.png&quot; align=&quot;absmiddle&quot; border=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Memoryusage&quot;&gt;&lt;/a&gt;Memory usage&lt;/h2&gt;

&lt;p&gt;Note that the y-axis is again log-scale in this plot.&lt;/p&gt;

&lt;p&gt;MetricsHistogram uses a flat 1028 items of storage, so it has constant memory usage. At 10 million items, SampleQuantiles uses roughly an order of magnitude more memory (19.4k items vs. 1k). Since SampleQuantiles samples are about 40B each and MetricsHistogram samples are 8B each, this is approximately 776KB vs. 8KB.&lt;/p&gt;

&lt;p&gt;This matters less for small numbers of items. The crossover point on the graph happens at between 10k and 100k items. The scaling pattern looks similar to the runtime, overall good.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/3E3RQ.png&quot; align=&quot;absmiddle&quot; border=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Errorbounds&quot;&gt;&lt;/a&gt;Error bounds&lt;/h2&gt;

&lt;p&gt;Note that for this series of plots, the y-axis is linear and the x-axis is log. This makes the actual error values easier to interpret. Error was calculated by taking the difference in the actual and the estimated rank of the percentile, and dividing by the total count.&lt;/p&gt;

&lt;p&gt;SampleQuantiles is by default configured to track 50th with 5% error, 75th with 2.5%, 95th with 0.5%, and 99th with 0.1%. We see less error at higher percentiles, and with larger sized streams. For 95th and 99th, we reach essentially 0% error at around 1 million items (0.009% for 95th, 0.004% for 99th).&lt;/p&gt;

&lt;p&gt;MetricsHistogram doesn&apos;t really provide great error, and high percentiles seem to get worse as the number of items increase. There&apos;s also large standard deviation in error, which is unfortunate if these values are going to be used for thresholding. For 95th, it looks like 0.4% to 0.6% error. For 99th, we&apos;re looking at 0.2% to 0.3%.&lt;/p&gt;

&lt;p&gt;An error of half a percent doesn&apos;t sound huge, but remember that this is error in rank, or effectively on a uniform latency distribution. To translate this, I fitted against the get latency distribution I got from running a mixed get/scan YCSB workload against CDH3u1 HBase. At the 95th percentile, an error of 0.5% translated to 137ms -3.4% and +4%. At the 99th, an error of 0.5% translated to 310ms -21.7% and +43.3%. These are just indicative numbers; the important point is that half a percent on the tail of a Zipf distribution is pretty meaningful.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/m0ERq.png&quot; align=&quot;absmiddle&quot; border=&quot;0&quot; /&gt;&lt;br/&gt;
&lt;img src=&quot;http://i.imgur.com/qvfpR.png&quot; align=&quot;absmiddle&quot; border=&quot;0&quot; /&gt;&lt;br/&gt;
&lt;img src=&quot;http://i.imgur.com/k5y5o.png&quot; align=&quot;absmiddle&quot; border=&quot;0&quot; /&gt;&lt;br/&gt;
&lt;img src=&quot;http://i.imgur.com/uyqAK.png&quot; align=&quot;absmiddle&quot; border=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Conclusion&quot;&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;For low-rate events (order 0.1s on up) like compactions or flushes, I think it can go either way. SampleQuantiles has similar CPU/memory usage up until ~10k items, but MetricsHistogram is perfectly accurate up until 1028 items, has bounded memory, and can be used to compute other statistics. The 1028 mark seems important here; just keep all the data for low-rate events.&lt;/p&gt;

&lt;p&gt;For high-rate events (order ms) like RPCs, it depends if you care at all about accuracy. The memory/CPU overhead of SampleQuantiles is high in relative terms (order of magnitude), but you need to use it if you&apos;re measuring for SLAs since MetricsHistogram basically isn&apos;t accurate. It also seems unlikely that you&apos;ll have that many 1M+ item streams you want to track, and it&apos;s just a couple hundred KB more memory. Use MetricsHistogram if accuracy isn&apos;t important, but I feel like SampleQuantiles is a pretty reasonable choice.&lt;/p&gt;

&lt;p&gt;Hopefully that was enlightening. I posted the raw data and plotting script if anyone else wants to play with it, and I can post the test code snippets used to make the data if anyone&apos;s interested in that too.&lt;/p&gt;</comment>
                            <comment id="13421063" author="eclark" created="Tue, 24 Jul 2012 00:43:23 +0000"  >&lt;p&gt;@Stack&lt;br/&gt;
Yes.  I was thinking that I would bring Andrew&apos;s quantile stuff in while working on the transition to metrics2.&lt;/p&gt;

&lt;p&gt;@Andrew&lt;br/&gt;
Wow.  That&apos;s pretty awesome stuff.  I think your final recommendations are spot on.  We should have a way for users to turn on/off these high fidelity histograms for different sets of metrics (rpc, compactions, etc).&lt;/p&gt;</comment>
                            <comment id="13540486" author="andrew.wang" created="Fri, 28 Dec 2012 15:22:08 +0000"  >&lt;p&gt;Elliot took care of this, porting the histogram from &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8541&quot; title=&quot;Better high-percentile latency metrics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8541&quot;&gt;&lt;del&gt;HADOOP-8541&lt;/del&gt;&lt;/a&gt; to HBase in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6409&quot; title=&quot;Create histogram class for metrics 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6409&quot;&gt;&lt;del&gt;HBASE-6409&lt;/del&gt;&lt;/a&gt;. Thanks!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12599178">HBASE-6409</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12596338">HADOOP-8541</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12533571" name="Latencyestimation.pdf" size="67104" author="andrew.wang" created="Wed, 27 Jun 2012 01:06:47 +0000"/>
                            <attachment id="12537623" name="MetricsHistogram.data" size="19771" author="andrew.wang" created="Mon, 23 Jul 2012 23:34:13 +0000"/>
                            <attachment id="12537625" name="SampleQuantiles.data" size="19518" author="andrew.wang" created="Mon, 23 Jul 2012 23:34:13 +0000"/>
                            <attachment id="12537624" name="parse.py" size="5549" author="andrew.wang" created="Mon, 23 Jul 2012 23:34:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 26 Jun 2012 05:19:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>256581</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 51 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0husv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>102252</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>